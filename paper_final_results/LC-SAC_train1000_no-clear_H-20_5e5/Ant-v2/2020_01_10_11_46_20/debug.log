---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019194791
Z variance train             0.6925143
KL Divergence                0.14987117
KL Loss                      0.014987118
QF Loss                      59.056892
VF Loss                      28.210007
Policy Loss                  -5.274742
Q Predictions Mean           0.00022549673
Q Predictions Std            0.0021121765
Q Predictions Max            0.005362722
Q Predictions Min            -0.0070441114
V Predictions Mean           0.00056522846
V Predictions Std            0.0016740405
V Predictions Max            0.005358889
V Predictions Min            -0.0037047223
Log Pis Mean                 -5.2930703
Log Pis Std                  0.6268485
Log Pis Max                  -3.7406893
Log Pis Min                  -7.394795
Policy mu Mean               0.00013362215
Policy mu Std                0.0017606522
Policy mu Max                0.0050060386
Policy mu Min                -0.004110857
Policy log std Mean          0.00013812652
Policy log std Std           0.0018418531
Policy log std Max           0.004510773
Policy log std Min           -0.0042383457
Z mean eval                  0.1036218
Z variance eval              0.13703023
total_rewards                [   7.16978278  -15.77445075  -19.818151    -15.19834896  -14.99872164
  -44.8018177   -23.28246923   -9.61828727 -245.81694093   10.96716269]
total_rewards_mean           -37.117224202921285
total_rewards_std            71.10562645011488
total_rewards_max            10.967162687664842
total_rewards_min            -245.81694093485157
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               33.07221370888874
(Previous) Eval Time (s)     0
Sample Time (s)              32.1721133752726
Epoch Time (s)               65.24432708416134
Total Train Time (s)         70.88295122794807
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:47:31.370435 UTC | [2020_01_10_11_46_20] Iteration #0 | Epoch Duration: 70.88659429550171
2020-01-10 11:47:31.370851 UTC | [2020_01_10_11_46_20] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.109793924
Z variance train             0.13370758
KL Divergence                2.9259753
KL Loss                      0.29259753
QF Loss                      43.10064
VF Loss                      6.688475
Policy Loss                  -9.543513
Q Predictions Mean           4.5223675
Q Predictions Std            9.153644
Q Predictions Max            30.221306
Q Predictions Min            -32.11555
V Predictions Mean           10.9587555
V Predictions Std            9.028453
V Predictions Max            38.26855
V Predictions Min            -21.95142
Log Pis Mean                 -5.1352787
Log Pis Std                  0.6418006
Log Pis Max                  -3.073444
Log Pis Min                  -7.25115
Policy mu Mean               -0.02097513
Policy mu Std                0.17610094
Policy mu Max                0.59666866
Policy mu Min                -0.5051222
Policy log std Mean          -0.26873568
Policy log std Std           0.02731786
Policy log std Max           -0.17775357
Policy log std Min           -0.36055517
Z mean eval                  0.17807524
Z variance eval              0.04019972
total_rewards                [101.91095667  39.83358521 268.80205478 233.17904245  22.28940608
  46.70624538 213.55098335  40.57031961  14.57879134  51.30124971]
total_rewards_mean           103.27226345815845
total_rewards_std            92.04378728431303
total_rewards_max            268.8020547759216
total_rewards_min            14.578791339400809
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               32.559458491858095
(Previous) Eval Time (s)     5.641716460697353
Sample Time (s)              22.481037282384932
Epoch Time (s)               60.68221223494038
Total Train Time (s)         141.89010369265452
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:48:42.378914 UTC | [2020_01_10_11_46_20] Iteration #1 | Epoch Duration: 71.00773406028748
2020-01-10 11:48:42.379153 UTC | [2020_01_10_11_46_20] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17826602
Z variance train             0.03992464
KL Divergence                5.793675
KL Loss                      0.5793675
QF Loss                      100.69536
VF Loss                      10.401926
Policy Loss                  -23.726307
Q Predictions Mean           19.277523
Q Predictions Std            14.532569
Q Predictions Max            64.71935
Q Predictions Min            -21.98042
V Predictions Mean           22.586948
V Predictions Std            13.761116
V Predictions Max            79.961914
V Predictions Min            -16.187468
Log Pis Mean                 -3.9126196
Log Pis Std                  1.459551
Log Pis Max                  -0.6702726
Log Pis Min                  -8.681753
Policy mu Mean               -0.012793997
Policy mu Std                0.23751195
Policy mu Max                0.68111366
Policy mu Min                -0.74425495
Policy log std Mean          -0.6384194
Policy log std Std           0.11397508
Policy log std Max           -0.34979826
Policy log std Min           -1.0532119
Z mean eval                  0.24992867
Z variance eval              0.024118349
total_rewards                [ 27.58064711 323.29747172 260.587704   258.38709232 266.11877182
 326.08495781 316.49732481 159.69628305 210.12734127 237.6713754 ]
total_rewards_mean           238.6048969320403
total_rewards_std            86.077907714914
total_rewards_max            326.0849578126073
total_rewards_min            27.58064711150187
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               33.927032687235624
(Previous) Eval Time (s)     15.966849911026657
Sample Time (s)              25.951128862798214
Epoch Time (s)               75.8450114610605
Total Train Time (s)         234.0138267041184
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:50:14.505221 UTC | [2020_01_10_11_46_20] Iteration #2 | Epoch Duration: 92.1258339881897
2020-01-10 11:50:14.505560 UTC | [2020_01_10_11_46_20] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2527776
Z variance train             0.024126662
KL Divergence                7.244727
KL Loss                      0.7244727
QF Loss                      99.821915
VF Loss                      16.570065
Policy Loss                  -43.108547
Q Predictions Mean           37.845024
Q Predictions Std            19.72733
Q Predictions Max            97.093895
Q Predictions Min            -25.403961
V Predictions Mean           42.689545
V Predictions Std            18.045158
V Predictions Max            98.68104
V Predictions Min            -15.860374
Log Pis Mean                 -3.2985425
Log Pis Std                  1.4158372
Log Pis Max                  0.1925229
Log Pis Min                  -7.686041
Policy mu Mean               -0.015464536
Policy mu Std                0.24683985
Policy mu Max                0.6464388
Policy mu Min                -0.9679166
Policy log std Mean          -0.73870957
Policy log std Std           0.115095615
Policy log std Max           -0.36097747
Policy log std Min           -1.0461469
Z mean eval                  0.30100018
Z variance eval              0.01580252
total_rewards                [203.80577713 208.6945755  295.83196429 230.95985319  62.69931763
  33.31381225 217.7386285  222.12485392 228.81904792 198.37253459]
total_rewards_mean           190.2360364920465
total_rewards_std            75.86311651590484
total_rewards_max            295.8319642915308
total_rewards_min            33.313812248601955
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               33.65361137315631
(Previous) Eval Time (s)     32.247098561841995
Sample Time (s)              27.94226439949125
Epoch Time (s)               93.84297433448955
Total Train Time (s)         323.1253192261793
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:51:43.616791 UTC | [2020_01_10_11_46_20] Iteration #3 | Epoch Duration: 89.11100268363953
2020-01-10 11:51:43.617002 UTC | [2020_01_10_11_46_20] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3005113
Z variance train             0.015798286
KL Divergence                8.397754
KL Loss                      0.8397754
QF Loss                      122.35182
VF Loss                      13.644373
Policy Loss                  -59.432285
Q Predictions Mean           54.421432
Q Predictions Std            21.62037
Q Predictions Max            102.7505
Q Predictions Min            -23.841904
V Predictions Mean           59.600468
V Predictions Std            19.63254
V Predictions Max            101.40035
V Predictions Min            -12.096276
Log Pis Mean                 -3.0853972
Log Pis Std                  1.6459802
Log Pis Max                  0.15777832
Log Pis Min                  -11.250278
Policy mu Mean               -0.0052570268
Policy mu Std                0.26546702
Policy mu Max                0.8128833
Policy mu Min                -0.9501136
Policy log std Mean          -0.78082454
Policy log std Std           0.10759751
Policy log std Max           -0.48548356
Policy log std Min           -1.1144195
Z mean eval                  0.36331245
Z variance eval              0.0151272295
total_rewards                [ 83.00826792 139.23410851 153.71845872 129.90427587  24.29205432
 108.58036196 127.38684248  67.41671047 159.12174239 131.46745909]
total_rewards_mean           112.41302817254663
total_rewards_std            40.2116239675642
total_rewards_max            159.1217423877746
total_rewards_min            24.29205431597694
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               33.58436168124899
(Previous) Eval Time (s)     27.514551950152963
Sample Time (s)              26.75666237482801
Epoch Time (s)               87.85557600622997
Total Train Time (s)         414.6373201161623
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:53:15.130289 UTC | [2020_01_10_11_46_20] Iteration #4 | Epoch Duration: 91.51313185691833
2020-01-10 11:53:15.130520 UTC | [2020_01_10_11_46_20] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3652271
Z variance train             0.015143415
KL Divergence                8.731325
KL Loss                      0.8731325
QF Loss                      178.41252
VF Loss                      18.013779
Policy Loss                  -79.55141
Q Predictions Mean           75.9574
Q Predictions Std            22.168295
Q Predictions Max            136.58162
Q Predictions Min            -17.832178
V Predictions Mean           78.18036
V Predictions Std            20.844852
V Predictions Max            139.77667
V Predictions Min            -13.274036
Log Pis Mean                 -3.2159743
Log Pis Std                  1.6219966
Log Pis Max                  0.48023453
Log Pis Min                  -8.111714
Policy mu Mean               -0.033056527
Policy mu Std                0.31791118
Policy mu Max                1.0645137
Policy mu Min                -1.2469944
Policy log std Mean          -0.71790135
Policy log std Std           0.10644891
Policy log std Max           -0.37895054
Policy log std Min           -1.0815663
Z mean eval                  0.430669
Z variance eval              0.01273949
total_rewards                [132.3458491   56.87147971  27.13097951  51.33837184  81.63309909
  96.67724751  54.83150798  72.49479616  72.52821907 124.44416773]
total_rewards_mean           77.02957176951313
total_rewards_std            31.31308738279618
total_rewards_max            132.3458490967039
total_rewards_min            27.130979505834024
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               33.312082442920655
(Previous) Eval Time (s)     31.171571475919336
Sample Time (s)              28.082126079127192
Epoch Time (s)               92.56577999796718
Total Train Time (s)         504.76280866749585
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:54:45.258755 UTC | [2020_01_10_11_46_20] Iteration #5 | Epoch Duration: 90.12798070907593
2020-01-10 11:54:45.259147 UTC | [2020_01_10_11_46_20] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.43001676
Z variance train             0.012712834
KL Divergence                9.474383
KL Loss                      0.94743836
QF Loss                      153.07973
VF Loss                      20.825045
Policy Loss                  -90.64323
Q Predictions Mean           86.33591
Q Predictions Std            25.331253
Q Predictions Max            135.4742
Q Predictions Min            -14.775569
V Predictions Mean           90.62309
V Predictions Std            23.30542
V Predictions Max            140.17735
V Predictions Min            -16.181938
Log Pis Mean                 -3.2312334
Log Pis Std                  1.7521762
Log Pis Max                  1.377797
Log Pis Min                  -7.7959967
Policy mu Mean               -0.017655462
Policy mu Std                0.32690978
Policy mu Max                0.89239883
Policy mu Min                -0.97399014
Policy log std Mean          -0.7172782
Policy log std Std           0.12499106
Policy log std Max           -0.40303478
Policy log std Min           -1.1200141
Z mean eval                  0.47539443
Z variance eval              0.012623471
total_rewards                [139.45364204 103.75437013  14.01686696 108.53327621  47.98966463
  48.08626388  21.99394629  67.92549957  13.3737259   -1.55968375]
total_rewards_mean           56.35675718671737
total_rewards_std            45.079468061591335
total_rewards_max            139.45364204365436
total_rewards_min            -1.559683749076311
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               33.59387164609507
(Previous) Eval Time (s)     28.733208931982517
Sample Time (s)              27.03109934134409
Epoch Time (s)               89.35817991942167
Total Train Time (s)         586.3248064490035
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:56:06.822011 UTC | [2020_01_10_11_46_20] Iteration #6 | Epoch Duration: 81.56234312057495
2020-01-10 11:56:06.822328 UTC | [2020_01_10_11_46_20] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.47662085
Z variance train             0.012620884
KL Divergence                9.712833
KL Loss                      0.9712834
QF Loss                      152.99545
VF Loss                      30.222582
Policy Loss                  -110.932556
Q Predictions Mean           106.72183
Q Predictions Std            23.10024
Q Predictions Max            157.52632
Q Predictions Min            -20.264067
V Predictions Mean           108.112625
V Predictions Std            20.683708
V Predictions Max            161.77296
V Predictions Min            -15.8464155
Log Pis Mean                 -2.9957013
Log Pis Std                  1.544691
Log Pis Max                  1.2982799
Log Pis Min                  -9.103421
Policy mu Mean               0.022197302
Policy mu Std                0.3101812
Policy mu Max                1.0232402
Policy mu Min                -1.2311513
Policy log std Mean          -0.7360428
Policy log std Std           0.1489241
Policy log std Max           -0.37898937
Policy log std Min           -1.3533754
Z mean eval                  0.5032757
Z variance eval              0.012485839
total_rewards                [ 40.0943326    8.93673883  -0.67868429  50.6611683   58.4733846
  70.33850947 225.19599833 128.61139922  95.74405278  40.40140053]
total_rewards_mean           71.77783003716819
total_rewards_std            62.57302585397132
total_rewards_max            225.19599832663357
total_rewards_min            -0.6786842877911212
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               34.01159688271582
(Previous) Eval Time (s)     20.93700543511659
Sample Time (s)              27.10660786088556
Epoch Time (s)               82.05521017871797
Total Train Time (s)         675.9398703686893
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:57:36.439693 UTC | [2020_01_10_11_46_20] Iteration #7 | Epoch Duration: 89.61708354949951
2020-01-10 11:57:36.440126 UTC | [2020_01_10_11_46_20] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5022746
Z variance train             0.012573776
KL Divergence                10.082691
KL Loss                      1.0082692
QF Loss                      184.8216
VF Loss                      34.495586
Policy Loss                  -122.97309
Q Predictions Mean           117.37806
Q Predictions Std            26.410128
Q Predictions Max            190.79976
Q Predictions Min            -18.199015
V Predictions Mean           122.962036
V Predictions Std            22.56403
V Predictions Max            190.12823
V Predictions Min            -11.408943
Log Pis Mean                 -3.1389961
Log Pis Std                  1.7875419
Log Pis Max                  3.1636577
Log Pis Min                  -9.136202
Policy mu Mean               0.01576215
Policy mu Std                0.341099
Policy mu Max                1.2579837
Policy mu Min                -1.217314
Policy log std Mean          -0.71355367
Policy log std Std           0.14653814
Policy log std Max           -0.33570755
Policy log std Min           -1.4073057
Z mean eval                  0.53494704
Z variance eval              0.01434088
total_rewards                [220.72556875  22.75133001 140.84138886 129.46397631 -16.02259231
  18.19708737 101.99497907 165.66318338   3.03455009 169.66038463]
total_rewards_mean           95.63098561613819
total_rewards_std            78.49251030492083
total_rewards_max            220.72556874878373
total_rewards_min            -16.0225923067783
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               33.121677161194384
(Previous) Eval Time (s)     28.49834117293358
Sample Time (s)              27.57266320148483
Epoch Time (s)               89.19268153561279
Total Train Time (s)         762.9070525718853
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:59:03.408386 UTC | [2020_01_10_11_46_20] Iteration #8 | Epoch Duration: 86.96806478500366
2020-01-10 11:59:03.408591 UTC | [2020_01_10_11_46_20] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.53436255
Z variance train             0.014392927
KL Divergence                10.190889
KL Loss                      1.019089
QF Loss                      155.82652
VF Loss                      24.343128
Policy Loss                  -139.70692
Q Predictions Mean           136.82178
Q Predictions Std            29.755941
Q Predictions Max            217.51595
Q Predictions Min            -13.241857
V Predictions Mean           139.42493
V Predictions Std            28.337774
V Predictions Max            219.40569
V Predictions Min            -4.9226933
Log Pis Mean                 -3.270499
Log Pis Std                  1.7336152
Log Pis Max                  1.8021749
Log Pis Min                  -7.9980063
Policy mu Mean               0.056606542
Policy mu Std                0.33667764
Policy mu Max                1.2378279
Policy mu Min                -1.1071712
Policy log std Mean          -0.7108493
Policy log std Std           0.15129355
Policy log std Max           -0.3550847
Policy log std Min           -1.4981728
Z mean eval                  0.5853712
Z variance eval              0.015926978
total_rewards                [ 49.80702594  42.38155549  19.94624316  56.43932772 156.59245102
  93.66105194  13.66319633  -5.07008793  15.25815648  30.45125975]
total_rewards_mean           47.31301798987144
total_rewards_std            44.878767080758834
total_rewards_max            156.59245101529754
total_rewards_min            -5.070087932042952
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               34.095821351744235
(Previous) Eval Time (s)     26.27314121602103
Sample Time (s)              26.452946772798896
Epoch Time (s)               86.82190934056416
Total Train Time (s)         853.5535804331303
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:00:34.055319 UTC | [2020_01_10_11_46_20] Iteration #9 | Epoch Duration: 90.6465950012207
2020-01-10 12:00:34.055523 UTC | [2020_01_10_11_46_20] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.58710515
Z variance train             0.015971683
KL Divergence                10.235356
KL Loss                      1.0235356
QF Loss                      142.75502
VF Loss                      48.098885
Policy Loss                  -154.49548
Q Predictions Mean           151.22678
Q Predictions Std            29.201357
Q Predictions Max            235.81242
Q Predictions Min            -14.091996
V Predictions Mean           149.68732
V Predictions Std            26.405413
V Predictions Max            226.76697
V Predictions Min            9.005566
Log Pis Mean                 -3.1843166
Log Pis Std                  1.6387354
Log Pis Max                  4.1449213
Log Pis Min                  -7.3881702
Policy mu Mean               0.034756526
Policy mu Std                0.33780062
Policy mu Max                1.4646865
Policy mu Min                -1.214721
Policy log std Mean          -0.68249834
Policy log std Std           0.16131403
Policy log std Max           -0.30470186
Policy log std Min           -1.6295215
Z mean eval                  0.6041424
Z variance eval              0.019324098
total_rewards                [ 47.59520667 236.85766662 -54.16485345 104.81396275  12.49006481
  64.52912636 178.68606562 -67.43705623 198.09385182  89.96695551]
total_rewards_mean           81.14309904867318
total_rewards_std            97.2503647907344
total_rewards_max            236.85766662248128
total_rewards_min            -67.43705623188309
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               31.511674069799483
(Previous) Eval Time (s)     30.097328919917345
Sample Time (s)              27.871694563888013
Epoch Time (s)               89.48069755360484
Total Train Time (s)         942.9627607860602
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:02:03.465954 UTC | [2020_01_10_11_46_20] Iteration #10 | Epoch Duration: 89.41028809547424
2020-01-10 12:02:03.466138 UTC | [2020_01_10_11_46_20] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6066634
Z variance train             0.019341107
KL Divergence                10.231831
KL Loss                      1.0231831
QF Loss                      158.24857
VF Loss                      24.022478
Policy Loss                  -165.03432
Q Predictions Mean           160.53358
Q Predictions Std            28.68444
Q Predictions Max            233.13655
Q Predictions Min            -14.346576
V Predictions Mean           163.37466
V Predictions Std            27.072569
V Predictions Max            228.89784
V Predictions Min            -4.8611937
Log Pis Mean                 -3.2166789
Log Pis Std                  1.9661125
Log Pis Max                  3.9979246
Log Pis Min                  -9.686234
Policy mu Mean               -0.019863367
Policy mu Std                0.3405643
Policy mu Max                1.2851421
Policy mu Min                -1.3935422
Policy log std Mean          -0.66370094
Policy log std Std           0.17493941
Policy log std Max           -0.33117673
Policy log std Min           -1.5801712
Z mean eval                  0.63487905
Z variance eval              0.021805018
total_rewards                [-48.01619771  29.7383874  -59.41012453 -92.69150199 -27.64735968
  23.50946314  53.3362483    1.39512728  55.34249042  74.90922528]
total_rewards_mean           1.0465757904280366
total_rewards_std            53.04545932592818
total_rewards_max            74.90922527524715
total_rewards_min            -92.69150198756955
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               31.60123951965943
(Previous) Eval Time (s)     30.026381503790617
Sample Time (s)              25.68608855223283
Epoch Time (s)               87.31370957568288
Total Train Time (s)         1029.4538239650428
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:03:29.959249 UTC | [2020_01_10_11_46_20] Iteration #11 | Epoch Duration: 86.4929792881012
2020-01-10 12:03:29.959421 UTC | [2020_01_10_11_46_20] Iteration #11 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63035196
Z variance train             0.021901712
KL Divergence                10.446472
KL Loss                      1.0446472
QF Loss                      235.48082
VF Loss                      50.763283
Policy Loss                  -171.46063
Q Predictions Mean           169.38419
Q Predictions Std            18.932905
Q Predictions Max            221.59969
Q Predictions Min            62.94615
V Predictions Mean           175.22572
V Predictions Std            17.39015
V Predictions Max            229.39168
V Predictions Min            99.511185
Log Pis Mean                 -3.102128
Log Pis Std                  1.4797878
Log Pis Max                  1.2009287
Log Pis Min                  -7.699896
Policy mu Mean               0.006612897
Policy mu Std                0.34899667
Policy mu Max                1.1551626
Policy mu Min                -1.2680215
Policy log std Mean          -0.67228746
Policy log std Std           0.13411316
Policy log std Max           -0.36341706
Policy log std Min           -1.35666
Z mean eval                  0.6602197
Z variance eval              0.017995711
total_rewards                [ 100.38674901   15.9158177    34.43032544 -108.15605145  -15.0495477
   62.00844072   78.97167925   75.80955118   84.11990344   29.47844528]
total_rewards_mean           35.79153128745287
total_rewards_std            58.65487273667514
total_rewards_max            100.38674901060429
total_rewards_min            -108.15605144905723
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               31.073673681821674
(Previous) Eval Time (s)     29.205192632973194
Sample Time (s)              25.995034779887646
Epoch Time (s)               86.27390109468251
Total Train Time (s)         1117.0825799610466
Epoch                        12
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:04:57.588616 UTC | [2020_01_10_11_46_20] Iteration #12 | Epoch Duration: 87.62905788421631
2020-01-10 12:04:57.588837 UTC | [2020_01_10_11_46_20] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6577171
Z variance train             0.017965358
KL Divergence                10.617023
KL Loss                      1.0617024
QF Loss                      159.06288
VF Loss                      53.56954
Policy Loss                  -183.75682
Q Predictions Mean           181.31897
Q Predictions Std            26.56702
Q Predictions Max            249.51476
Q Predictions Min            2.4606063
V Predictions Mean           188.79248
V Predictions Std            25.610123
V Predictions Max            262.31467
V Predictions Min            -2.0748892
Log Pis Mean                 -3.1901479
Log Pis Std                  1.5760397
Log Pis Max                  1.7726419
Log Pis Min                  -8.524544
Policy mu Mean               0.029226646
Policy mu Std                0.35074165
Policy mu Max                1.6241946
Policy mu Min                -1.2084608
Policy log std Mean          -0.6746399
Policy log std Std           0.1392165
Policy log std Max           -0.21347475
Policy log std Min           -1.4207774
Z mean eval                  0.68062556
Z variance eval              0.018102543
total_rewards                [ 95.86789828 -82.37617515  24.0821638  -15.95059141 152.82320138
  67.75545856  30.14691595 107.3349427   54.52760513  91.03804648]
total_rewards_mean           52.52494657302664
total_rewards_std            63.920814408621446
total_rewards_max            152.8232013801082
total_rewards_min            -82.37617514663008
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               31.33104939199984
(Previous) Eval Time (s)     30.559972854331136
Sample Time (s)              26.419479681178927
Epoch Time (s)               88.3105019275099
Total Train Time (s)         1197.3407683665864
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:06:17.849882 UTC | [2020_01_10_11_46_20] Iteration #13 | Epoch Duration: 80.26077365875244
2020-01-10 12:06:17.850280 UTC | [2020_01_10_11_46_20] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67794305
Z variance train             0.01808224
KL Divergence                11.609123
KL Loss                      1.1609124
QF Loss                      171.7402
VF Loss                      43.785595
Policy Loss                  -187.6713
Q Predictions Mean           184.00055
Q Predictions Std            33.84461
Q Predictions Max            254.4391
Q Predictions Min            -21.835981
V Predictions Mean           190.01959
V Predictions Std            31.848495
V Predictions Max            256.07666
V Predictions Min            -25.869764
Log Pis Mean                 -3.2455235
Log Pis Std                  1.6600273
Log Pis Max                  3.427099
Log Pis Min                  -9.396261
Policy mu Mean               0.038991876
Policy mu Std                0.34225434
Policy mu Max                2.093422
Policy mu Min                -1.312103
Policy log std Mean          -0.66106856
Policy log std Std           0.1307904
Policy log std Max           -0.29897606
Policy log std Min           -1.6277167
Z mean eval                  0.684559
Z variance eval              0.022148643
total_rewards                [131.43507496 104.75520788  96.87894503  50.21188937 324.40955157
  96.76710851 117.87547568  39.15779707  58.975903   201.63287727]
total_rewards_mean           122.2099830335213
total_rewards_std            80.60407087087495
total_rewards_max            324.40955157052707
total_rewards_min            39.15779706819994
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               31.710738537367433
(Previous) Eval Time (s)     22.509760228917003
Sample Time (s)              25.095596980303526
Epoch Time (s)               79.31609574658796
Total Train Time (s)         1286.8723560925573
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:07:47.381555 UTC | [2020_01_10_11_46_20] Iteration #14 | Epoch Duration: 89.53106570243835
2020-01-10 12:07:47.381775 UTC | [2020_01_10_11_46_20] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6844163
Z variance train             0.02231461
KL Divergence                11.513906
KL Loss                      1.1513906
QF Loss                      245.06737
VF Loss                      50.095062
Policy Loss                  -206.5638
Q Predictions Mean           203.64015
Q Predictions Std            33.942673
Q Predictions Max            266.1325
Q Predictions Min            0.8557741
V Predictions Mean           207.95337
V Predictions Std            30.712452
V Predictions Max            269.108
V Predictions Min            6.4120693
Log Pis Mean                 -3.3067837
Log Pis Std                  1.9492531
Log Pis Max                  5.7757263
Log Pis Min                  -8.207351
Policy mu Mean               0.007424785
Policy mu Std                0.33346692
Policy mu Max                1.3512204
Policy mu Min                -1.8045807
Policy log std Mean          -0.7049585
Policy log std Std           0.1575039
Policy log std Max           -0.38815105
Policy log std Min           -1.6331275
Z mean eval                  0.75514555
Z variance eval              0.017405024
total_rewards                [  20.7236471    31.94175791 -100.16365763    8.73541546  199.36927979
   44.01967015    4.1741712   117.89350337   88.6606694    29.09107077]
total_rewards_mean           44.44455275137513
total_rewards_std            74.90979653664216
total_rewards_max            199.36927979281938
total_rewards_min            -100.16365762998502
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.5015710121952
(Previous) Eval Time (s)     32.724396497011185
Sample Time (s)              25.734309914521873
Epoch Time (s)               89.96027742372826
Total Train Time (s)         1359.6340510449372
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:09:00.144437 UTC | [2020_01_10_11_46_20] Iteration #15 | Epoch Duration: 72.76248788833618
2020-01-10 12:09:00.144653 UTC | [2020_01_10_11_46_20] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7523587
Z variance train             0.017352795
KL Divergence                12.592857
KL Loss                      1.2592858
QF Loss                      169.89178
VF Loss                      76.01126
Policy Loss                  -216.84393
Q Predictions Mean           214.72874
Q Predictions Std            30.270401
Q Predictions Max            268.86963
Q Predictions Min            -3.5327702
V Predictions Mean           221.87299
V Predictions Std            29.573906
V Predictions Max            287.2383
V Predictions Min            -3.9958432
Log Pis Mean                 -3.3893015
Log Pis Std                  1.7323241
Log Pis Max                  3.3238218
Log Pis Min                  -9.450984
Policy mu Mean               0.017799165
Policy mu Std                0.3223268
Policy mu Max                1.109927
Policy mu Min                -1.3469741
Policy log std Mean          -0.6708884
Policy log std Std           0.1360411
Policy log std Max           -0.259254
Policy log std Min           -1.50627
Z mean eval                  0.7390099
Z variance eval              0.018964529
total_rewards                [-136.07993346  104.29241594   47.03916078  211.56866403   38.71969519
  129.11025385    6.7481619    66.79910485  107.16128268   37.38361422]
total_rewards_mean           61.27424199679226
total_rewards_std            86.24425597915402
total_rewards_max            211.568664026363
total_rewards_min            -136.07993345946954
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               31.75325516797602
(Previous) Eval Time (s)     15.526068781036884
Sample Time (s)              25.437275075819343
Epoch Time (s)               72.71659902483225
Total Train Time (s)         1444.3966880445369
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:10:24.908564 UTC | [2020_01_10_11_46_20] Iteration #16 | Epoch Duration: 84.76371216773987
2020-01-10 12:10:24.908831 UTC | [2020_01_10_11_46_20] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73987305
Z variance train             0.018983945
KL Divergence                12.829302
KL Loss                      1.2829303
QF Loss                      185.08118
VF Loss                      49.745396
Policy Loss                  -216.02301
Q Predictions Mean           213.76077
Q Predictions Std            29.700863
Q Predictions Max            276.27008
Q Predictions Min            5.87749
V Predictions Mean           213.46623
V Predictions Std            28.104925
V Predictions Max            274.63663
V Predictions Min            1.0534816
Log Pis Mean                 -3.2441692
Log Pis Std                  1.5575461
Log Pis Max                  4.1848364
Log Pis Min                  -7.365921
Policy mu Mean               -0.04436087
Policy mu Std                0.3372206
Policy mu Max                1.6049845
Policy mu Min                -1.398229
Policy log std Mean          -0.68322295
Policy log std Std           0.13845602
Policy log std Max           -0.2826414
Policy log std Min           -1.569634
Z mean eval                  0.75651944
Z variance eval              0.019665502
total_rewards                [329.34715398 232.90509778 332.36802905 201.47947969 142.95095023
 146.16346366 162.60348184 269.53776586 189.46202203 109.81053206]
total_rewards_mean           211.66279761768578
total_rewards_std            73.89781016823021
total_rewards_max            332.36802904877266
total_rewards_min            109.81053206126889
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.760948188137263
(Previous) Eval Time (s)     27.57281913701445
Sample Time (s)              25.224479772616178
Epoch Time (s)               84.55824709776789
Total Train Time (s)         1533.285748553928
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:11:53.798871 UTC | [2020_01_10_11_46_20] Iteration #17 | Epoch Duration: 88.88988971710205
2020-01-10 12:11:53.799078 UTC | [2020_01_10_11_46_20] Iteration #17 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75210035
Z variance train             0.019670065
KL Divergence                13.284742
KL Loss                      1.3284743
QF Loss                      174.8915
VF Loss                      38.752014
Policy Loss                  -220.14513
Q Predictions Mean           219.09558
Q Predictions Std            34.36534
Q Predictions Max            268.7624
Q Predictions Min            -3.8336756
V Predictions Mean           221.64062
V Predictions Std            35.320625
V Predictions Max            280.1453
V Predictions Min            -23.928259
Log Pis Mean                 -3.2421212
Log Pis Std                  1.7784281
Log Pis Max                  6.419895
Log Pis Min                  -9.762993
Policy mu Mean               0.04553356
Policy mu Std                0.34392723
Policy mu Max                1.9243592
Policy mu Min                -1.6724222
Policy log std Mean          -0.7408235
Policy log std Std           0.1398503
Policy log std Max           -0.070256636
Policy log std Min           -1.4222236
Z mean eval                  0.7828978
Z variance eval              0.018957425
total_rewards                [203.43973814  20.18297496 215.17047063 -12.99555072 218.4483445
 209.35135928  85.50698047  57.05940721 167.36590121  40.93690549]
total_rewards_mean           120.4466531172116
total_rewards_std            86.59699674868777
total_rewards_max            218.4483445032508
total_rewards_min            -12.995550720431353
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               31.30377912009135
(Previous) Eval Time (s)     31.904097237158567
Sample Time (s)              26.211585932411253
Epoch Time (s)               89.41946228966117
Total Train Time (s)         1619.1217264081351
Epoch                        18
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:13:19.635831 UTC | [2020_01_10_11_46_20] Iteration #18 | Epoch Duration: 85.83660674095154
2020-01-10 12:13:19.636025 UTC | [2020_01_10_11_46_20] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7834927
Z variance train             0.018964086
KL Divergence                13.848221
KL Loss                      1.3848221
QF Loss                      216.6043
VF Loss                      142.17348
Policy Loss                  -230.14948
Q Predictions Mean           226.66783
Q Predictions Std            32.274498
Q Predictions Max            278.53772
Q Predictions Min            1.6160554
V Predictions Mean           230.99576
V Predictions Std            22.281008
V Predictions Max            281.32532
V Predictions Min            89.30192
Log Pis Mean                 -3.3821948
Log Pis Std                  1.8910502
Log Pis Max                  6.3589063
Log Pis Min                  -14.244859
Policy mu Mean               0.000808476
Policy mu Std                0.33925188
Policy mu Max                1.4793862
Policy mu Min                -1.488542
Policy log std Mean          -0.68676025
Policy log std Std           0.14141783
Policy log std Max           -0.40792644
Policy log std Min           -1.7860391
Z mean eval                  0.76933956
Z variance eval              0.020666363
total_rewards                [ 178.94757857   91.74606448  252.97955816  172.93893398   86.21234047
  176.46044058  162.12986625 -117.23580784   56.33093356   20.35949613]
total_rewards_mean           108.08694043483447
total_rewards_std            99.85344616030403
total_rewards_max            252.97955815784056
total_rewards_min            -117.2358078382522
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               31.940246979240328
(Previous) Eval Time (s)     28.320865703746676
Sample Time (s)              25.673391133081168
Epoch Time (s)               85.93450381606817
Total Train Time (s)         1706.7067982214503
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:14:47.222205 UTC | [2020_01_10_11_46_20] Iteration #19 | Epoch Duration: 87.58603835105896
2020-01-10 12:14:47.222397 UTC | [2020_01_10_11_46_20] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7734389
Z variance train             0.020611737
KL Divergence                13.3935795
KL Loss                      1.339358
QF Loss                      150.72357
VF Loss                      128.43416
Policy Loss                  -241.5443
Q Predictions Mean           237.24297
Q Predictions Std            35.874
Q Predictions Max            302.81747
Q Predictions Min            -29.100498
V Predictions Mean           234.01219
V Predictions Std            30.963135
V Predictions Max            303.43298
V Predictions Min            -4.178366
Log Pis Mean                 -3.2678967
Log Pis Std                  1.7275892
Log Pis Max                  6.960741
Log Pis Min                  -7.8825707
Policy mu Mean               -0.029268336
Policy mu Std                0.33196458
Policy mu Max                1.699712
Policy mu Min                -1.3707902
Policy log std Mean          -0.70212865
Policy log std Std           0.14175035
Policy log std Max           -0.37384543
Policy log std Min           -1.673566
Z mean eval                  0.7587701
Z variance eval              0.02447489
total_rewards                [107.24508319 262.58324746 127.19518156 268.43494011 156.91223992
 113.08072031 196.89823808  67.42420077 453.37808262 141.90626078]
total_rewards_mean           189.50581947782197
total_rewards_std            107.69194809041437
total_rewards_max            453.37808262465416
total_rewards_min            67.42420076547415
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               31.53637536568567
(Previous) Eval Time (s)     29.972081744112074
Sample Time (s)              25.653093345928937
Epoch Time (s)               87.16155045572668
Total Train Time (s)         1796.2893923544325
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:16:16.806590 UTC | [2020_01_10_11_46_20] Iteration #20 | Epoch Duration: 89.58405303955078
2020-01-10 12:16:16.806813 UTC | [2020_01_10_11_46_20] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.761655
Z variance train             0.024432398
KL Divergence                13.636572
KL Loss                      1.3636572
QF Loss                      178.9338
VF Loss                      29.908602
Policy Loss                  -240.44899
Q Predictions Mean           236.59857
Q Predictions Std            29.225767
Q Predictions Max            306.4288
Q Predictions Min            9.93992
V Predictions Mean           238.18582
V Predictions Std            29.828573
V Predictions Max            313.17062
V Predictions Min            -7.237958
Log Pis Mean                 -3.1168442
Log Pis Std                  1.8273413
Log Pis Max                  7.0333424
Log Pis Min                  -9.377454
Policy mu Mean               -0.0230062
Policy mu Std                0.3375621
Policy mu Max                1.5412384
Policy mu Min                -1.8747969
Policy log std Mean          -0.7456578
Policy log std Std           0.1417503
Policy log std Max           -0.062444597
Policy log std Min           -1.6638379
Z mean eval                  0.76903665
Z variance eval              0.0233845
total_rewards                [152.19520168  43.71743828 190.80075545 193.08267871  76.44500177
  76.15271186 225.93436784 158.22671704 -64.23091384  70.02972789]
total_rewards_mean           112.23536866879564
total_rewards_std            83.39516927380618
total_rewards_max            225.93436784346414
total_rewards_min            -64.23091384428618
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               31.65362794464454
(Previous) Eval Time (s)     32.39423673180863
Sample Time (s)              25.10790224932134
Epoch Time (s)               89.15576692577451
Total Train Time (s)         1883.0150497630239
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:17:43.533142 UTC | [2020_01_10_11_46_20] Iteration #21 | Epoch Duration: 86.72619652748108
2020-01-10 12:17:43.533327 UTC | [2020_01_10_11_46_20] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77182806
Z variance train             0.023375664
KL Divergence                14.0203905
KL Loss                      1.402039
QF Loss                      128.77173
VF Loss                      89.05797
Policy Loss                  -248.49008
Q Predictions Mean           243.81357
Q Predictions Std            35.343307
Q Predictions Max            310.74512
Q Predictions Min            -3.8384576
V Predictions Mean           241.19617
V Predictions Std            33.73402
V Predictions Max            317.69418
V Predictions Min            5.997246
Log Pis Mean                 -3.1652584
Log Pis Std                  1.7910098
Log Pis Max                  4.6364107
Log Pis Min                  -9.603905
Policy mu Mean               -0.024317812
Policy mu Std                0.32302228
Policy mu Max                1.4771215
Policy mu Min                -1.0773793
Policy log std Mean          -0.74280334
Policy log std Std           0.1412009
Policy log std Max           -0.25060448
Policy log std Min           -1.6002508
Z mean eval                  0.7851663
Z variance eval              0.019479018
total_rewards                [ 87.29097014 307.89913907 211.77290202 141.85154273 175.53866439
  53.26010766 222.21505421 156.29215181 124.95490329 163.34123709]
total_rewards_mean           164.44166724071016
total_rewards_std            68.36074359629043
total_rewards_max            307.8991390677035
total_rewards_min            53.26010765994141
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               31.4401527158916
(Previous) Eval Time (s)     29.964299152139574
Sample Time (s)              25.529769094660878
Epoch Time (s)               86.93422096269205
Total Train Time (s)         1969.5912335012108
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:19:10.110682 UTC | [2020_01_10_11_46_20] Iteration #22 | Epoch Duration: 86.57722187042236
2020-01-10 12:19:10.110876 UTC | [2020_01_10_11_46_20] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7825261
Z variance train             0.019448403
KL Divergence                13.992525
KL Loss                      1.3992525
QF Loss                      146.74399
VF Loss                      33.776215
Policy Loss                  -256.16156
Q Predictions Mean           252.49017
Q Predictions Std            32.413147
Q Predictions Max            305.92947
Q Predictions Min            -2.050353
V Predictions Mean           259.9487
V Predictions Std            30.549938
V Predictions Max            310.13074
V Predictions Min            -1.0755527
Log Pis Mean                 -3.0468469
Log Pis Std                  1.7095923
Log Pis Max                  7.090576
Log Pis Min                  -8.723038
Policy mu Mean               0.008694153
Policy mu Std                0.3406216
Policy mu Max                1.7379097
Policy mu Min                -1.3858559
Policy log std Mean          -0.7351
Policy log std Std           0.12539378
Policy log std Max           -0.26961705
Policy log std Min           -1.5091896
Z mean eval                  0.7773944
Z variance eval              0.01994864
total_rewards                [130.92397269 201.44707796 128.47786107 233.61049937 256.88425745
 206.35143931 217.72763853 205.42933464 207.28884084 244.87231508]
total_rewards_mean           203.30132369382653
total_rewards_std            40.738488506721836
total_rewards_max            256.88425745002235
total_rewards_min            128.47786106959447
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               31.83815266098827
(Previous) Eval Time (s)     29.60691240010783
Sample Time (s)              25.74959726072848
Epoch Time (s)               87.19466232182458
Total Train Time (s)         2059.793727074284
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:20:40.315053 UTC | [2020_01_10_11_46_20] Iteration #23 | Epoch Duration: 90.20400810241699
2020-01-10 12:20:40.315880 UTC | [2020_01_10_11_46_20] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78018683
Z variance train             0.020007197
KL Divergence                14.777434
KL Loss                      1.4777435
QF Loss                      152.04816
VF Loss                      99.80323
Policy Loss                  -261.65518
Q Predictions Mean           256.66406
Q Predictions Std            24.919474
Q Predictions Max            317.5767
Q Predictions Min            0.0550026
V Predictions Mean           252.83891
V Predictions Std            24.03308
V Predictions Max            306.81195
V Predictions Min            -2.7987468
Log Pis Mean                 -3.0485554
Log Pis Std                  1.6943395
Log Pis Max                  1.976294
Log Pis Min                  -8.662716
Policy mu Mean               -0.050583437
Policy mu Std                0.32917252
Policy mu Max                1.167773
Policy mu Min                -1.6611398
Policy log std Mean          -0.7342723
Policy log std Std           0.119403325
Policy log std Max           -0.20026009
Policy log std Min           -1.2461829
Z mean eval                  0.77876073
Z variance eval              0.016503533
total_rewards                [302.84790536 223.22390966 193.19219905 171.8949144   19.45761097
 372.69239833 169.3323472   67.67734072  26.16822422 105.63780256]
total_rewards_mean           165.21246524796203
total_rewards_std            109.4720412746044
total_rewards_max            372.69239833467566
total_rewards_min            19.457610969551194
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               31.48277643788606
(Previous) Eval Time (s)     32.61588716879487
Sample Time (s)              26.52057500416413
Epoch Time (s)               90.61923861084506
Total Train Time (s)         2142.58825889742
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:22:03.110542 UTC | [2020_01_10_11_46_20] Iteration #24 | Epoch Duration: 82.79428911209106
2020-01-10 12:22:03.110747 UTC | [2020_01_10_11_46_20] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77730656
Z variance train             0.016535925
KL Divergence                14.844028
KL Loss                      1.4844029
QF Loss                      271.63544
VF Loss                      46.882854
Policy Loss                  -267.85223
Q Predictions Mean           266.97058
Q Predictions Std            29.660547
Q Predictions Max            332.82794
Q Predictions Min            -8.268416
V Predictions Mean           271.54553
V Predictions Std            28.15175
V Predictions Max            346.89816
V Predictions Min            30.531975
Log Pis Mean                 -2.9238167
Log Pis Std                  1.5210022
Log Pis Max                  4.466731
Log Pis Min                  -7.8910675
Policy mu Mean               0.04673437
Policy mu Std                0.3248652
Policy mu Max                1.5888426
Policy mu Min                -1.1037115
Policy log std Mean          -0.7407758
Policy log std Std           0.123766616
Policy log std Max           -0.42123246
Policy log std Min           -2.1033652
Z mean eval                  0.787704
Z variance eval              0.014989274
total_rewards                [259.93823092 493.06893591 405.81570519 266.36622977 151.58584737
 145.85352195 179.49332223 278.35911107 141.46415388   6.26923115]
total_rewards_mean           232.82142894408236
total_rewards_std            133.5172697295124
total_rewards_max            493.0689359097398
total_rewards_min            6.2692311525876505
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               31.28440061630681
(Previous) Eval Time (s)     24.79061235114932
Sample Time (s)              25.315469258930534
Epoch Time (s)               81.39048222638667
Total Train Time (s)         2229.2460819147527
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:23:29.769693 UTC | [2020_01_10_11_46_20] Iteration #25 | Epoch Duration: 86.65878558158875
2020-01-10 12:23:29.769915 UTC | [2020_01_10_11_46_20] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7880949
Z variance train             0.015025103
KL Divergence                15.540205
KL Loss                      1.5540205
QF Loss                      138.64078
VF Loss                      77.81068
Policy Loss                  -276.19016
Q Predictions Mean           272.401
Q Predictions Std            27.67199
Q Predictions Max            386.1247
Q Predictions Min            28.121246
V Predictions Mean           270.23715
V Predictions Std            27.856176
V Predictions Max            375.6656
V Predictions Min            29.446404
Log Pis Mean                 -2.9891362
Log Pis Std                  1.7210181
Log Pis Max                  2.7739632
Log Pis Min                  -8.159666
Policy mu Mean               0.02060658
Policy mu Std                0.3349782
Policy mu Max                1.4258684
Policy mu Min                -1.5280375
Policy log std Mean          -0.75200856
Policy log std Std           0.114791766
Policy log std Max           -0.392016
Policy log std Min           -1.2504838
Z mean eval                  0.79362947
Z variance eval              0.014153337
total_rewards                [239.53323597 180.90124471 -53.15946044 118.34478224 370.56830939
  87.66923787  66.98457763 154.01502642 104.30260945 147.26413557]
total_rewards_mean           141.6423698809835
total_rewards_std            105.87130248184933
total_rewards_max            370.56830938621545
total_rewards_min            -53.159460440643116
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               31.412808693945408
(Previous) Eval Time (s)     30.05854006111622
Sample Time (s)              26.31489101005718
Epoch Time (s)               87.78623976511881
Total Train Time (s)         2318.110482491087
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:24:58.636185 UTC | [2020_01_10_11_46_20] Iteration #26 | Epoch Duration: 88.86604952812195
2020-01-10 12:24:58.636479 UTC | [2020_01_10_11_46_20] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7944902
Z variance train             0.014173609
KL Divergence                16.038235
KL Loss                      1.6038235
QF Loss                      143.6789
VF Loss                      27.769503
Policy Loss                  -281.6076
Q Predictions Mean           278.7246
Q Predictions Std            31.556583
Q Predictions Max            342.67947
Q Predictions Min            10.358164
V Predictions Mean           280.77594
V Predictions Std            29.172724
V Predictions Max            340.1082
V Predictions Min            14.889045
Log Pis Mean                 -3.1381257
Log Pis Std                  1.7057241
Log Pis Max                  7.401764
Log Pis Min                  -9.007908
Policy mu Mean               0.05335912
Policy mu Std                0.33004308
Policy mu Max                1.9067006
Policy mu Min                -1.2024215
Policy log std Mean          -0.7354622
Policy log std Std           0.12654762
Policy log std Max           -0.3894676
Policy log std Min           -1.5976338
Z mean eval                  0.79412663
Z variance eval              0.015195143
total_rewards                [411.99904504 202.74859751 198.14816751 282.23329126 349.78772486
  46.82917375 400.53870247 195.26651865 191.69766382 276.09552354]
total_rewards_mean           255.53444084118237
total_rewards_std            106.24097666059838
total_rewards_max            411.999045038029
total_rewards_min            46.82917375429373
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               32.05816919589415
(Previous) Eval Time (s)     31.13794685807079
Sample Time (s)              26.49775077169761
Epoch Time (s)               89.69386682566255
Total Train Time (s)         2404.4797633956186
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:26:25.006549 UTC | [2020_01_10_11_46_20] Iteration #27 | Epoch Duration: 86.36989784240723
2020-01-10 12:26:25.007004 UTC | [2020_01_10_11_46_20] Iteration #27 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7934794
Z variance train             0.015181452
KL Divergence                15.553318
KL Loss                      1.5553318
QF Loss                      243.34224
VF Loss                      128.33826
Policy Loss                  -282.02695
Q Predictions Mean           279.6908
Q Predictions Std            46.170612
Q Predictions Max            353.18863
Q Predictions Min            -4.6832376
V Predictions Mean           279.16974
V Predictions Std            48.072987
V Predictions Max            355.12283
V Predictions Min            -6.278426
Log Pis Mean                 -2.9931395
Log Pis Std                  1.925573
Log Pis Max                  5.9715376
Log Pis Min                  -11.9734535
Policy mu Mean               0.0074127866
Policy mu Std                0.31503293
Policy mu Max                1.4561361
Policy mu Min                -1.4745978
Policy log std Mean          -0.756189
Policy log std Std           0.13956754
Policy log std Max           -0.26068428
Policy log std Min           -1.7139859
Z mean eval                  0.8128931
Z variance eval              0.01747339
total_rewards                [262.48116003 200.57345821 197.91242938 234.45098862 100.9594315
 310.38097276  53.08733757 338.34883728 381.94504092 366.68899221]
total_rewards_mean           244.68286484727741
total_rewards_std            104.27646485438632
total_rewards_max            381.9450409159997
total_rewards_min            53.08733757019356
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               31.799292679410428
(Previous) Eval Time (s)     27.813534328714013
Sample Time (s)              26.496915717609227
Epoch Time (s)               86.10974272573367
Total Train Time (s)         2491.783760036342
Epoch                        28
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:27:52.312566 UTC | [2020_01_10_11_46_20] Iteration #28 | Epoch Duration: 87.30530095100403
2020-01-10 12:27:52.312855 UTC | [2020_01_10_11_46_20] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81343377
Z variance train             0.017436326
KL Divergence                15.987415
KL Loss                      1.5987415
QF Loss                      213.10098
VF Loss                      23.30725
Policy Loss                  -293.23965
Q Predictions Mean           290.1249
Q Predictions Std            34.261646
Q Predictions Max            364.79364
Q Predictions Min            14.539595
V Predictions Mean           293.408
V Predictions Std            34.250546
V Predictions Max            357.89276
V Predictions Min            1.2413958
Log Pis Mean                 -2.965229
Log Pis Std                  1.6072669
Log Pis Max                  1.7394879
Log Pis Min                  -7.604542
Policy mu Mean               0.062402338
Policy mu Std                0.33166343
Policy mu Max                1.4850713
Policy mu Min                -1.3298867
Policy log std Mean          -0.7423511
Policy log std Std           0.12819192
Policy log std Max           0.11337742
Policy log std Min           -1.5046501
Z mean eval                  0.80420554
Z variance eval              0.016921964
total_rewards                [187.60251377 143.83959684  18.76959939  68.72437026 261.17459584
 145.14010227 188.35130453 170.26580129 325.21464603 228.86377901]
total_rewards_mean           173.79463092335715
total_rewards_std            84.1438075469493
total_rewards_max            325.21464602916575
total_rewards_min            18.769599388784652
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               31.28151032468304
(Previous) Eval Time (s)     29.008676039986312
Sample Time (s)              26.04361549159512
Epoch Time (s)               86.33380185626447
Total Train Time (s)         2575.2307824054733
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:29:15.761273 UTC | [2020_01_10_11_46_20] Iteration #29 | Epoch Duration: 83.44822335243225
2020-01-10 12:29:15.761585 UTC | [2020_01_10_11_46_20] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80915546
Z variance train             0.017079696
KL Divergence                15.810673
KL Loss                      1.5810673
QF Loss                      225.12679
VF Loss                      161.63167
Policy Loss                  -298.65826
Q Predictions Mean           294.42224
Q Predictions Std            31.952421
Q Predictions Max            365.62134
Q Predictions Min            27.508293
V Predictions Mean           286.73975
V Predictions Std            30.81342
V Predictions Max            349.86426
V Predictions Min            15.900182
Log Pis Mean                 -2.7213578
Log Pis Std                  2.0103047
Log Pis Max                  7.304549
Log Pis Min                  -8.5784855
Policy mu Mean               0.043685958
Policy mu Std                0.32434046
Policy mu Max                1.5140654
Policy mu Min                -2.1540506
Policy log std Mean          -0.7794534
Policy log std Std           0.14183824
Policy log std Max           -0.3333901
Policy log std Min           -1.6743796
Z mean eval                  0.7916734
Z variance eval              0.016295409
total_rewards                [163.92598166 276.81330992 428.29980072 368.1926817  207.35048743
  96.27304985 301.52531735  14.0600978  238.01333546 247.06507373]
total_rewards_mean           234.1519135625534
total_rewards_std            116.3194508894248
total_rewards_max            428.29980072482965
total_rewards_min            14.060097798116594
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.5730669349432
(Previous) Eval Time (s)     26.122724147047848
Sample Time (s)              25.13215986499563
Epoch Time (s)               82.82795094698668
Total Train Time (s)         2658.173816775903
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:30:38.706777 UTC | [2020_01_10_11_46_20] Iteration #30 | Epoch Duration: 82.94495797157288
2020-01-10 12:30:38.707017 UTC | [2020_01_10_11_46_20] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7944985
Z variance train             0.01629759
KL Divergence                15.535534
KL Loss                      1.5535535
QF Loss                      153.41043
VF Loss                      58.851646
Policy Loss                  -301.49158
Q Predictions Mean           296.32825
Q Predictions Std            32.273575
Q Predictions Max            373.846
Q Predictions Min            -12.555385
V Predictions Mean           299.2005
V Predictions Std            31.031073
V Predictions Max            378.71796
V Predictions Min            -2.2916672
Log Pis Mean                 -3.050792
Log Pis Std                  1.7242606
Log Pis Max                  3.1494508
Log Pis Min                  -10.372768
Policy mu Mean               -0.0063272635
Policy mu Std                0.3148825
Policy mu Max                1.0213566
Policy mu Min                -1.6696541
Policy log std Mean          -0.78948975
Policy log std Std           0.12635593
Policy log std Max           -0.40112287
Policy log std Min           -1.6565255
Z mean eval                  0.8020333
Z variance eval              0.018452307
total_rewards                [135.63365155 300.50618219 193.58953633 372.55217086  20.62227752
 350.8014722  422.75657619 188.32563535 365.4236419  505.06783336]
total_rewards_mean           285.52789774541077
total_rewards_std            140.00544663393975
total_rewards_max            505.0678333622908
total_rewards_min            20.622277523395606
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.790988652966917
(Previous) Eval Time (s)     26.23937413096428
Sample Time (s)              26.153727791272104
Epoch Time (s)               84.1840905752033
Total Train Time (s)         2744.6798380697146
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:32:05.212690 UTC | [2020_01_10_11_46_20] Iteration #31 | Epoch Duration: 86.50552606582642
2020-01-10 12:32:05.212880 UTC | [2020_01_10_11_46_20] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7998437
Z variance train             0.018454432
KL Divergence                15.202576
KL Loss                      1.5202576
QF Loss                      199.58405
VF Loss                      100.19698
Policy Loss                  -302.61865
Q Predictions Mean           300.0055
Q Predictions Std            48.130756
Q Predictions Max            370.90234
Q Predictions Min            -24.223404
V Predictions Mean           307.40268
V Predictions Std            42.102013
V Predictions Max            373.8994
V Predictions Min            6.48389
Log Pis Mean                 -2.7553551
Log Pis Std                  1.7468195
Log Pis Max                  6.0357356
Log Pis Min                  -7.8533287
Policy mu Mean               -0.006087539
Policy mu Std                0.3520496
Policy mu Max                2.000029
Policy mu Min                -1.4966184
Policy log std Mean          -0.74813354
Policy log std Std           0.13043864
Policy log std Max           -0.20437548
Policy log std Min           -1.449558
Z mean eval                  0.797552
Z variance eval              0.020112433
total_rewards                [471.30536456 207.56942786 177.85072022  62.89176832  47.72095456
 136.28878404 255.96085467 287.45574062  95.14185813 400.58543463]
total_rewards_mean           214.27709076211778
total_rewards_std            134.22842422735724
total_rewards_max            471.3053645641653
total_rewards_min            47.72095455920895
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.47823476791382
(Previous) Eval Time (s)     28.560376754030585
Sample Time (s)              25.685671601910144
Epoch Time (s)               85.72428312385455
Total Train Time (s)         2831.11144767981
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:33:31.645957 UTC | [2020_01_10_11_46_20] Iteration #32 | Epoch Duration: 86.43295335769653
2020-01-10 12:33:31.646125 UTC | [2020_01_10_11_46_20] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79502875
Z variance train             0.020128172
KL Divergence                15.394001
KL Loss                      1.5394001
QF Loss                      174.74619
VF Loss                      41.646027
Policy Loss                  -305.36868
Q Predictions Mean           302.3593
Q Predictions Std            25.574598
Q Predictions Max            373.15262
Q Predictions Min            220.1105
V Predictions Mean           309.95016
V Predictions Std            25.312782
V Predictions Max            381.5151
V Predictions Min            246.38936
Log Pis Mean                 -2.906861
Log Pis Std                  1.6466309
Log Pis Max                  2.6846132
Log Pis Min                  -8.532969
Policy mu Mean               0.0023011912
Policy mu Std                0.32469842
Policy mu Max                1.2666733
Policy mu Min                -1.1073489
Policy log std Mean          -0.7700639
Policy log std Std           0.13236201
Policy log std Max           -0.43016547
Policy log std Min           -1.3557417
Z mean eval                  0.8246004
Z variance eval              0.013212624
total_rewards                [353.55651476 399.48070957 164.32394925 202.92001782 191.81838539
 135.64383981 418.17942481 367.80807963 316.54885129 185.89245196]
total_rewards_mean           273.61722242830575
total_rewards_std            102.08409976754166
total_rewards_max            418.1794248058374
total_rewards_min            135.64383981288813
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.288928505964577
(Previous) Eval Time (s)     29.26864477293566
Sample Time (s)              25.199678343255073
Epoch Time (s)               85.75725162215531
Total Train Time (s)         2920.1294193179347
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:35:00.664921 UTC | [2020_01_10_11_46_20] Iteration #33 | Epoch Duration: 89.0186710357666
2020-01-10 12:35:00.665250 UTC | [2020_01_10_11_46_20] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8210476
Z variance train             0.013221653
KL Divergence                15.720476
KL Loss                      1.5720476
QF Loss                      350.78607
VF Loss                      185.34103
Policy Loss                  -309.72278
Q Predictions Mean           306.24683
Q Predictions Std            37.131012
Q Predictions Max            389.77994
Q Predictions Min            17.60843
V Predictions Mean           315.8827
V Predictions Std            33.245773
V Predictions Max            393.41327
V Predictions Min            70.6326
Log Pis Mean                 -2.8397965
Log Pis Std                  1.7636799
Log Pis Max                  4.929561
Log Pis Min                  -9.803341
Policy mu Mean               -0.0025320717
Policy mu Std                0.33383316
Policy mu Max                1.1540478
Policy mu Min                -2.1200373
Policy log std Mean          -0.775115
Policy log std Std           0.16445428
Policy log std Max           -0.4616089
Policy log std Min           -1.7723173
Z mean eval                  0.8121751
Z variance eval              0.010985513
total_rewards                [535.79316593  28.33997368 267.16323877 416.30521758 191.04475013
 318.28248113 184.28910901 233.68982108  89.29184221 226.45379672]
total_rewards_mean           249.06533962384384
total_rewards_std            140.6619581603848
total_rewards_max            535.7931659269047
total_rewards_min            28.339973679887777
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               31.79684521909803
(Previous) Eval Time (s)     32.529679032973945
Sample Time (s)              25.429658740293235
Epoch Time (s)               89.75618299236521
Total Train Time (s)         3001.848700765986
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:36:22.385797 UTC | [2020_01_10_11_46_20] Iteration #34 | Epoch Duration: 81.7204065322876
2020-01-10 12:36:22.386012 UTC | [2020_01_10_11_46_20] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8145386
Z variance train             0.010983584
KL Divergence                15.969432
KL Loss                      1.5969433
QF Loss                      167.25385
VF Loss                      31.807352
Policy Loss                  -313.79236
Q Predictions Mean           309.03064
Q Predictions Std            47.71538
Q Predictions Max            378.77023
Q Predictions Min            -7.0470457
V Predictions Mean           313.7738
V Predictions Std            40.19338
V Predictions Max            374.75336
V Predictions Min            17.917683
Log Pis Mean                 -2.80154
Log Pis Std                  1.6479528
Log Pis Max                  4.122653
Log Pis Min                  -9.625193
Policy mu Mean               0.06457294
Policy mu Std                0.32673153
Policy mu Max                1.7248592
Policy mu Min                -2.5368354
Policy log std Mean          -0.77001864
Policy log std Std           0.14428762
Policy log std Max           -0.4046294
Policy log std Min           -1.7009679
Z mean eval                  0.8250386
Z variance eval              0.009673415
total_rewards                [320.65458016  21.39799807 147.48652638 223.81708524 432.98815046
  57.91689683 245.52103588 342.44434903 207.61315877 350.71973197]
total_rewards_mean           235.0559512782605
total_rewards_std            125.33952513145003
total_rewards_max            432.9881504648838
total_rewards_min            21.397998067952383
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.795607211999595
(Previous) Eval Time (s)     24.493512144777924
Sample Time (s)              26.249944830778986
Epoch Time (s)               81.5390641875565
Total Train Time (s)         3084.6931583611295
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:37:45.231683 UTC | [2020_01_10_11_46_20] Iteration #35 | Epoch Duration: 82.84552454948425
2020-01-10 12:37:45.231875 UTC | [2020_01_10_11_46_20] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82523125
Z variance train             0.009670772
KL Divergence                16.68169
KL Loss                      1.668169
QF Loss                      336.8959
VF Loss                      93.18206
Policy Loss                  -323.71988
Q Predictions Mean           319.43484
Q Predictions Std            34.29688
Q Predictions Max            371.13226
Q Predictions Min            -20.461422
V Predictions Mean           319.9986
V Predictions Std            32.023655
V Predictions Max            365.19052
V Predictions Min            9.630059
Log Pis Mean                 -2.7841966
Log Pis Std                  1.8191807
Log Pis Max                  4.4961915
Log Pis Min                  -9.681262
Policy mu Mean               0.086703435
Policy mu Std                0.33782744
Policy mu Max                1.3760141
Policy mu Min                -1.6639545
Policy log std Mean          -0.7860067
Policy log std Std           0.15568256
Policy log std Max           -0.23440601
Policy log std Min           -1.9183186
Z mean eval                  0.8104273
Z variance eval              0.009684543
total_rewards                [ 99.35895592 167.67991307 304.07556269 275.74808805 365.58013982
 173.20961593 258.6504544  244.81240458  22.04102837 241.72711714]
total_rewards_mean           215.28832799748238
total_rewards_std            96.12411576365017
total_rewards_max            365.58013982154864
total_rewards_min            22.041028365062985
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.94799457071349
(Previous) Eval Time (s)     25.799676580820233
Sample Time (s)              24.483660424593836
Epoch Time (s)               82.23133157612756
Total Train Time (s)         3169.1949320519343
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:39:09.734592 UTC | [2020_01_10_11_46_20] Iteration #36 | Epoch Duration: 84.50258278846741
2020-01-10 12:39:09.734770 UTC | [2020_01_10_11_46_20] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81031024
Z variance train             0.009670441
KL Divergence                16.356949
KL Loss                      1.6356949
QF Loss                      177.31546
VF Loss                      27.992224
Policy Loss                  -325.79193
Q Predictions Mean           322.14417
Q Predictions Std            37.06214
Q Predictions Max            415.33624
Q Predictions Min            3.880943
V Predictions Mean           328.03128
V Predictions Std            34.316284
V Predictions Max            415.95853
V Predictions Min            -1.1075333
Log Pis Mean                 -3.1203904
Log Pis Std                  1.5482557
Log Pis Max                  1.1057032
Log Pis Min                  -10.188981
Policy mu Mean               0.070887096
Policy mu Std                0.3134901
Policy mu Max                1.0945905
Policy mu Min                -1.948403
Policy log std Mean          -0.7375766
Policy log std Std           0.12559405
Policy log std Max           -0.44372818
Policy log std Min           -1.3839369
Z mean eval                  0.8208906
Z variance eval              0.009311105
total_rewards                [547.6104639  195.57312772 272.50651262 244.66097761 200.60680301
 453.83834111 262.09705852 217.24349055 117.99973219  42.71994049]
total_rewards_mean           255.48564477183882
total_rewards_std            140.48721530913778
total_rewards_max            547.6104638961451
total_rewards_min            42.7199404907098
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               32.39676887122914
(Previous) Eval Time (s)     28.07055546808988
Sample Time (s)              25.249364469666034
Epoch Time (s)               85.71668880898505
Total Train Time (s)         3254.7484409599565
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:40:35.289652 UTC | [2020_01_10_11_46_20] Iteration #37 | Epoch Duration: 85.55475211143494
2020-01-10 12:40:35.289827 UTC | [2020_01_10_11_46_20] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8233287
Z variance train             0.009302358
KL Divergence                16.708271
KL Loss                      1.6708272
QF Loss                      516.9001
VF Loss                      29.830658
Policy Loss                  -327.65396
Q Predictions Mean           324.1826
Q Predictions Std            36.60222
Q Predictions Max            411.33624
Q Predictions Min            -20.62156
V Predictions Mean           323.75034
V Predictions Std            34.755756
V Predictions Max            405.8674
V Predictions Min            -8.687068
Log Pis Mean                 -2.968061
Log Pis Std                  1.5188243
Log Pis Max                  1.1664824
Log Pis Min                  -7.56897
Policy mu Mean               0.05084149
Policy mu Std                0.32582322
Policy mu Max                1.2670851
Policy mu Min                -1.5087441
Policy log std Mean          -0.76232386
Policy log std Std           0.12973201
Policy log std Max           -0.15245846
Policy log std Min           -1.239236
Z mean eval                  0.8251885
Z variance eval              0.009377855
total_rewards                [275.7662533  405.63933091 310.65125585 319.2054998  497.83862998
 299.75962303 170.71154283 165.03509314 208.34868836 283.7300622 ]
total_rewards_mean           293.6685979395631
total_rewards_std            97.24415818012152
total_rewards_max            497.8386299776673
total_rewards_min            165.0350931446918
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               32.04952980298549
(Previous) Eval Time (s)     27.908252703025937
Sample Time (s)              25.483196804765612
Epoch Time (s)               85.44097931077704
Total Train Time (s)         3345.0626123645343
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:42:05.605274 UTC | [2020_01_10_11_46_20] Iteration #38 | Epoch Duration: 90.3153166770935
2020-01-10 12:42:05.605454 UTC | [2020_01_10_11_46_20] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8265554
Z variance train             0.00941327
KL Divergence                16.223133
KL Loss                      1.6223134
QF Loss                      162.0289
VF Loss                      107.89728
Policy Loss                  -333.9776
Q Predictions Mean           330.90927
Q Predictions Std            29.77217
Q Predictions Max            390.08347
Q Predictions Min            165.47278
V Predictions Mean           337.27383
V Predictions Std            31.11849
V Predictions Max            391.58923
V Predictions Min            175.42303
Log Pis Mean                 -2.4542906
Log Pis Std                  1.8654469
Log Pis Max                  9.059326
Log Pis Min                  -9.100908
Policy mu Mean               0.052148517
Policy mu Std                0.32886535
Policy mu Max                1.9878253
Policy mu Min                -0.97826385
Policy log std Mean          -0.8233959
Policy log std Std           0.15124212
Policy log std Max           -0.38032454
Policy log std Min           -1.6729965
Z mean eval                  0.82692844
Z variance eval              0.0093768705
total_rewards                [163.54142213 149.48071765  67.26538329 179.37882214 550.65625011
 168.26096791 393.96773509 386.82965662 744.17017776 217.10407817]
total_rewards_mean           302.06552108824474
total_rewards_std            202.64775791939906
total_rewards_max            744.17017776327
total_rewards_min            67.2653832886327
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               33.569431921932846
(Previous) Eval Time (s)     32.78223577328026
Sample Time (s)              27.149572126101702
Epoch Time (s)               93.50123982131481
Total Train Time (s)         3438.473333835136
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:43:39.017454 UTC | [2020_01_10_11_46_20] Iteration #39 | Epoch Duration: 93.41187024116516
2020-01-10 12:43:39.017638 UTC | [2020_01_10_11_46_20] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.824916
Z variance train             0.009357248
KL Divergence                17.051802
KL Loss                      1.7051802
QF Loss                      238.74887
VF Loss                      54.25579
Policy Loss                  -337.51843
Q Predictions Mean           335.27448
Q Predictions Std            38.586266
Q Predictions Max            425.32266
Q Predictions Min            -2.1421404
V Predictions Mean           341.64117
V Predictions Std            34.926567
V Predictions Max            423.2476
V Predictions Min            77.37313
Log Pis Mean                 -2.970822
Log Pis Std                  1.7239547
Log Pis Max                  5.9674444
Log Pis Min                  -8.891405
Policy mu Mean               -0.009380359
Policy mu Std                0.3284811
Policy mu Max                1.4172347
Policy mu Min                -2.1258059
Policy log std Mean          -0.76630825
Policy log std Std           0.14486378
Policy log std Max           -0.34730864
Policy log std Min           -1.9078162
Z mean eval                  0.84158343
Z variance eval              0.011256305
total_rewards                [242.63316286 557.18249456 453.90969814 240.52465728 267.43126389
 532.88984109 127.15177456 325.84836908 394.50717289 444.34247666]
total_rewards_mean           358.64209109982846
total_rewards_std            133.37156997279837
total_rewards_max            557.1824945582298
total_rewards_min            127.15177455904335
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               34.240939397364855
(Previous) Eval Time (s)     32.692445397842675
Sample Time (s)              26.94331480236724
Epoch Time (s)               93.87669959757477
Total Train Time (s)         3535.7528473278508
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:45:16.298742 UTC | [2020_01_10_11_46_20] Iteration #40 | Epoch Duration: 97.28097224235535
2020-01-10 12:45:16.298940 UTC | [2020_01_10_11_46_20] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8412925
Z variance train             0.011198802
KL Divergence                17.306896
KL Loss                      1.7306896
QF Loss                      318.14917
VF Loss                      102.134735
Policy Loss                  -335.02066
Q Predictions Mean           333.3879
Q Predictions Std            41.959576
Q Predictions Max            408.6287
Q Predictions Min            20.743689
V Predictions Mean           335.37494
V Predictions Std            49.00561
V Predictions Max            413.8776
V Predictions Min            -3.071846
Log Pis Mean                 -2.7787945
Log Pis Std                  1.7648518
Log Pis Max                  8.2460985
Log Pis Min                  -8.978215
Policy mu Mean               0.0125035895
Policy mu Std                0.33811983
Policy mu Max                1.706611
Policy mu Min                -1.6499717
Policy log std Mean          -0.7856099
Policy log std Std           0.15252611
Policy log std Max           -0.39981416
Policy log std Min           -1.8929486
Z mean eval                  0.8552702
Z variance eval              0.011270001
total_rewards                [292.63321853 330.79259935 297.28664725 208.48300396 498.60234964
 319.68401409 427.96972583 250.6112754  256.50464874 613.97295951]
total_rewards_mean           349.65404423213533
total_rewards_std            119.93608749309533
total_rewards_max            613.9729595117584
total_rewards_min            208.48300396445887
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               34.75772553216666
(Previous) Eval Time (s)     36.096301512327045
Sample Time (s)              26.773081093560904
Epoch Time (s)               97.62710813805461
Total Train Time (s)         3633.2132125180215
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:46:53.759279 UTC | [2020_01_10_11_46_20] Iteration #41 | Epoch Duration: 97.46021342277527
2020-01-10 12:46:53.759530 UTC | [2020_01_10_11_46_20] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8574853
Z variance train             0.011253446
KL Divergence                17.668028
KL Loss                      1.7668028
QF Loss                      405.4391
VF Loss                      373.08755
Policy Loss                  -339.87845
Q Predictions Mean           335.6096
Q Predictions Std            36.975044
Q Predictions Max            405.50876
Q Predictions Min            18.267546
V Predictions Mean           333.46777
V Predictions Std            42.752666
V Predictions Max            405.22925
V Predictions Min            9.959421
Log Pis Mean                 -2.6105127
Log Pis Std                  1.8781308
Log Pis Max                  9.832766
Log Pis Min                  -8.993772
Policy mu Mean               0.03629276
Policy mu Std                0.34169757
Policy mu Max                1.643494
Policy mu Min                -1.7964875
Policy log std Mean          -0.79094875
Policy log std Std           0.16719444
Policy log std Max           -0.38306308
Policy log std Min           -1.8523595
Z mean eval                  0.84035903
Z variance eval              0.012036225
total_rewards                [117.16167311 193.24242459  68.46755319 160.85279609 246.08739308
 416.21202824 154.41107597 230.04017081 304.14236255  60.0942495 ]
total_rewards_mean           195.07117271243754
total_rewards_std            103.81228708327947
total_rewards_max            416.2120282422272
total_rewards_min            60.09424950310906
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               34.41230630176142
(Previous) Eval Time (s)     35.928948048036546
Sample Time (s)              27.107641275040805
Epoch Time (s)               97.44889562483877
Total Train Time (s)         3719.169291670434
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:48:19.718978 UTC | [2020_01_10_11_46_20] Iteration #42 | Epoch Duration: 85.95925092697144
2020-01-10 12:48:19.719310 UTC | [2020_01_10_11_46_20] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8423276
Z variance train             0.011949054
KL Divergence                17.420456
KL Loss                      1.7420456
QF Loss                      122.57927
VF Loss                      74.07428
Policy Loss                  -352.50116
Q Predictions Mean           348.37994
Q Predictions Std            42.74972
Q Predictions Max            436.72705
Q Predictions Min            -25.681849
V Predictions Mean           344.86322
V Predictions Std            40.016308
V Predictions Max            435.13937
V Predictions Min            3.3004844
Log Pis Mean                 -2.772731
Log Pis Std                  1.5300683
Log Pis Max                  1.2755718
Log Pis Min                  -7.945243
Policy mu Mean               0.033794627
Policy mu Std                0.34044167
Policy mu Max                2.0339336
Policy mu Min                -1.4441215
Policy log std Mean          -0.77491057
Policy log std Std           0.13179532
Policy log std Max           -0.4116676
Policy log std Min           -1.2014575
Z mean eval                  0.8403629
Z variance eval              0.016634202
total_rewards                [285.25446475 179.12191668 254.99607809 115.19853    134.04100544
 309.00719606 172.07989976  -1.79097383 539.64319989 444.46965644]
total_rewards_mean           243.20209732959447
total_rewards_std            152.35191726135724
total_rewards_max            539.643199890337
total_rewards_min            -1.7909738287044517
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               34.368021921720356
(Previous) Eval Time (s)     24.43888383405283
Sample Time (s)              26.571026915684342
Epoch Time (s)               85.37793267145753
Total Train Time (s)         3808.8985433587804
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:49:49.449702 UTC | [2020_01_10_11_46_20] Iteration #43 | Epoch Duration: 89.73022270202637
2020-01-10 12:49:49.450004 UTC | [2020_01_10_11_46_20] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8413542
Z variance train             0.016642418
KL Divergence                17.464245
KL Loss                      1.7464246
QF Loss                      188.51016
VF Loss                      66.69853
Policy Loss                  -347.49774
Q Predictions Mean           343.95807
Q Predictions Std            42.686512
Q Predictions Max            425.23935
Q Predictions Min            17.117754
V Predictions Mean           345.91602
V Predictions Std            39.028976
V Predictions Max            419.99023
V Predictions Min            13.853744
Log Pis Mean                 -3.0313988
Log Pis Std                  1.7508737
Log Pis Max                  5.3248205
Log Pis Min                  -8.364524
Policy mu Mean               0.02442878
Policy mu Std                0.3246299
Policy mu Max                1.4263148
Policy mu Min                -1.0811566
Policy log std Mean          -0.7501817
Policy log std Std           0.15155534
Policy log std Max           -0.36727157
Policy log std Min           -1.8121271
Z mean eval                  0.83645123
Z variance eval              0.017960409
total_rewards                [516.31124785 379.30499471 185.84000579 232.41211801 228.63531271
 274.3712966  233.63335174 322.24343199 469.53318069  65.31236688]
total_rewards_mean           290.7597306966137
total_rewards_std            128.17779613766032
total_rewards_max            516.3112478491652
total_rewards_min            65.31236687505728
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               33.7795583200641
(Previous) Eval Time (s)     28.790764632169157
Sample Time (s)              26.58023655693978
Epoch Time (s)               89.15055950917304
Total Train Time (s)         3898.601967439521
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:51:19.154737 UTC | [2020_01_10_11_46_20] Iteration #44 | Epoch Duration: 89.70455646514893
2020-01-10 12:51:19.154942 UTC | [2020_01_10_11_46_20] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8363131
Z variance train             0.017979082
KL Divergence                16.16293
KL Loss                      1.616293
QF Loss                      152.84967
VF Loss                      63.047764
Policy Loss                  -347.42432
Q Predictions Mean           344.816
Q Predictions Std            38.924366
Q Predictions Max            429.58475
Q Predictions Min            5.7750087
V Predictions Mean           349.21533
V Predictions Std            39.13752
V Predictions Max            431.8232
V Predictions Min            30.663353
Log Pis Mean                 -2.7903366
Log Pis Std                  1.8149276
Log Pis Max                  5.360153
Log Pis Min                  -8.654646
Policy mu Mean               -0.08196975
Policy mu Std                0.35159397
Policy mu Max                0.9713485
Policy mu Min                -1.746795
Policy log std Mean          -0.78324556
Policy log std Std           0.15863289
Policy log std Max           -0.37611645
Policy log std Min           -1.9021671
Z mean eval                  0.8583535
Z variance eval              0.014936836
total_rewards                [  1.48237567 164.66242043 259.22731462  83.9450356  228.04451765
 111.3941621  193.01395796 265.76074782 151.50208723 171.51966911]
total_rewards_mean           163.05522881731343
total_rewards_std            77.56249550404732
total_rewards_max            265.7607478166014
total_rewards_min            1.4823756738945235
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               35.28731327690184
(Previous) Eval Time (s)     29.34434890607372
Sample Time (s)              27.094283311162144
Epoch Time (s)               91.7259454941377
Total Train Time (s)         3987.7649790043943
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:52:48.318684 UTC | [2020_01_10_11_46_20] Iteration #45 | Epoch Duration: 89.1636049747467
2020-01-10 12:52:48.318861 UTC | [2020_01_10_11_46_20] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8581028
Z variance train             0.0149053335
KL Divergence                16.760101
KL Loss                      1.6760101
QF Loss                      116.67264
VF Loss                      25.899006
Policy Loss                  -357.37485
Q Predictions Mean           354.12317
Q Predictions Std            28.787748
Q Predictions Max            435.14844
Q Predictions Min            264.35144
V Predictions Mean           354.84076
V Predictions Std            28.146208
V Predictions Max            435.43698
V Predictions Min            270.84982
Log Pis Mean                 -2.7815409
Log Pis Std                  1.5966158
Log Pis Max                  1.3307053
Log Pis Min                  -9.500671
Policy mu Mean               0.08629151
Policy mu Std                0.33928818
Policy mu Max                1.5080618
Policy mu Min                -0.9313311
Policy log std Mean          -0.7863151
Policy log std Std           0.1417392
Policy log std Max           -0.3477543
Policy log std Min           -1.3537949
Z mean eval                  0.84437
Z variance eval              0.017685903
total_rewards                [411.3157135  455.394845   334.37856872 615.6509457  314.83911872
 743.16478318 167.21634836 315.84229647 376.77565659 659.40103356]
total_rewards_mean           439.3979309802391
total_rewards_std            171.05543697348932
total_rewards_max            743.164783184646
total_rewards_min            167.21634835995727
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               33.91424666205421
(Previous) Eval Time (s)     26.781582727096975
Sample Time (s)              27.968561238143593
Epoch Time (s)               88.66439062729478
Total Train Time (s)         4085.90909264097
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:54:26.464740 UTC | [2020_01_10_11_46_20] Iteration #46 | Epoch Duration: 98.14574432373047
2020-01-10 12:54:26.464946 UTC | [2020_01_10_11_46_20] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84385765
Z variance train             0.017626505
KL Divergence                16.629387
KL Loss                      1.6629387
QF Loss                      248.73355
VF Loss                      49.372097
Policy Loss                  -360.49146
Q Predictions Mean           356.0638
Q Predictions Std            39.387016
Q Predictions Max            411.51852
Q Predictions Min            5.055933
V Predictions Mean           357.08365
V Predictions Std            37.099537
V Predictions Max            426.58142
V Predictions Min            9.441518
Log Pis Mean                 -2.6644373
Log Pis Std                  1.6836677
Log Pis Max                  6.9115744
Log Pis Min                  -8.145118
Policy mu Mean               0.018851347
Policy mu Std                0.34236857
Policy mu Max                1.5223967
Policy mu Min                -1.0094982
Policy log std Mean          -0.77329046
Policy log std Std           0.1546038
Policy log std Max           -0.29919848
Policy log std Min           -1.6454194
Z mean eval                  0.8699298
Z variance eval              0.015185034
total_rewards                [336.52891521 290.10332027  57.54255234 185.79182905 293.15424827
 284.57591453 260.13521218 557.46994334 148.43592892 666.02971731]
total_rewards_mean           307.97675814250135
total_rewards_std            172.55123900124792
total_rewards_max            666.0297173134686
total_rewards_min            57.542552338133376
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               34.32341186795384
(Previous) Eval Time (s)     36.262456610798836
Sample Time (s)              25.79893293697387
Epoch Time (s)               96.38480141572654
Total Train Time (s)         4177.555286471266
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:55:58.112338 UTC | [2020_01_10_11_46_20] Iteration #47 | Epoch Duration: 91.64725494384766
2020-01-10 12:55:58.112539 UTC | [2020_01_10_11_46_20] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8702458
Z variance train             0.015177771
KL Divergence                16.2969
KL Loss                      1.62969
QF Loss                      196.2416
VF Loss                      26.024963
Policy Loss                  -366.2852
Q Predictions Mean           361.03766
Q Predictions Std            45.533684
Q Predictions Max            460.92664
Q Predictions Min            -1.2404139
V Predictions Mean           367.57117
V Predictions Std            37.19544
V Predictions Max            466.82968
V Predictions Min            210.00969
Log Pis Mean                 -3.026998
Log Pis Std                  1.8742467
Log Pis Max                  7.0568204
Log Pis Min                  -10.109619
Policy mu Mean               0.004942161
Policy mu Std                0.34271902
Policy mu Max                1.5068369
Policy mu Min                -1.6070879
Policy log std Mean          -0.74810374
Policy log std Std           0.15872367
Policy log std Max           -0.37578
Policy log std Min           -1.8943315
Z mean eval                  0.8613864
Z variance eval              0.0122638885
total_rewards                [441.89867125 153.09309669 198.34020691 347.96272627 254.49898394
 508.47327886 361.52501309 257.37406882 689.45997796  21.44860202]
total_rewards_mean           323.4074625809002
total_rewards_std            181.45980772647775
total_rewards_max            689.459977962102
total_rewards_min            21.44860201786153
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               31.9790118932724
(Previous) Eval Time (s)     31.524518988095224
Sample Time (s)              26.53004899295047
Epoch Time (s)               90.0335798743181
Total Train Time (s)         4265.7382255923
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:57:26.297071 UTC | [2020_01_10_11_46_20] Iteration #48 | Epoch Duration: 88.18439674377441
2020-01-10 12:57:26.297259 UTC | [2020_01_10_11_46_20] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8616578
Z variance train             0.012233885
KL Divergence                16.833649
KL Loss                      1.6833649
QF Loss                      231.76993
VF Loss                      41.24954
Policy Loss                  -359.307
Q Predictions Mean           356.04437
Q Predictions Std            42.35104
Q Predictions Max            435.39838
Q Predictions Min            4.098427
V Predictions Mean           362.0421
V Predictions Std            41.992065
V Predictions Max            445.14597
V Predictions Min            16.302746
Log Pis Mean                 -2.6605434
Log Pis Std                  1.8425367
Log Pis Max                  3.6255498
Log Pis Min                  -8.517117
Policy mu Mean               0.055155136
Policy mu Std                0.3506914
Policy mu Max                1.4220808
Policy mu Min                -1.1206616
Policy log std Mean          -0.7919146
Policy log std Std           0.16784015
Policy log std Max           -0.27193236
Policy log std Min           -1.6693256
Z mean eval                  0.8725489
Z variance eval              0.020501945
total_rewards                [293.98303735 453.97868229 467.42900866 438.17675529 182.56437451
 320.01886584 323.6511907  369.78391379 436.94434298 187.20089432]
total_rewards_mean           347.373106572633
total_rewards_std            99.7633503354403
total_rewards_max            467.429008658636
total_rewards_min            182.56437451299686
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               31.99853071803227
(Previous) Eval Time (s)     29.674911057110876
Sample Time (s)              26.4055236116983
Epoch Time (s)               88.07896538684145
Total Train Time (s)         4357.660945579875
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:58:58.221474 UTC | [2020_01_10_11_46_20] Iteration #49 | Epoch Duration: 91.92408061027527
2020-01-10 12:58:58.221704 UTC | [2020_01_10_11_46_20] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87463534
Z variance train             0.02049415
KL Divergence                16.08139
KL Loss                      1.608139
QF Loss                      180.71912
VF Loss                      110.11161
Policy Loss                  -367.7351
Q Predictions Mean           364.87506
Q Predictions Std            55.643932
Q Predictions Max            467.9027
Q Predictions Min            -46.89206
V Predictions Mean           366.9824
V Predictions Std            51.37159
V Predictions Max            467.71707
V Predictions Min            -5.1407595
Log Pis Mean                 -2.5553222
Log Pis Std                  1.9151479
Log Pis Max                  6.6194344
Log Pis Min                  -9.554241
Policy mu Mean               0.010625212
Policy mu Std                0.34073657
Policy mu Max                1.5083067
Policy mu Min                -1.686827
Policy log std Mean          -0.80632305
Policy log std Std           0.1828064
Policy log std Max           -0.24763373
Policy log std Min           -2.0979738
Z mean eval                  0.86780846
Z variance eval              0.022952162
total_rewards                [322.01131662 238.27111418 720.99330389 457.92704499 673.22169376
 379.40888941 198.32935474 224.59485255 410.73024177 438.66450684]
total_rewards_mean           406.4152318745378
total_rewards_std            169.21623556688198
total_rewards_max            720.993303887564
total_rewards_min            198.32935473605724
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               31.893571950029582
(Previous) Eval Time (s)     33.51964148320258
Sample Time (s)              27.326054280623794
Epoch Time (s)               92.73926771385595
Total Train Time (s)         4445.7395666283555
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:00:26.301660 UTC | [2020_01_10_11_46_20] Iteration #50 | Epoch Duration: 88.07980155944824
2020-01-10 13:00:26.301841 UTC | [2020_01_10_11_46_20] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8670599
Z variance train             0.022901814
KL Divergence                16.206314
KL Loss                      1.6206315
QF Loss                      196.66269
VF Loss                      52.1005
Policy Loss                  -365.6691
Q Predictions Mean           363.91956
Q Predictions Std            46.694637
Q Predictions Max            475.84964
Q Predictions Min            15.94366
V Predictions Mean           369.90802
V Predictions Std            48.55192
V Predictions Max            474.7774
V Predictions Min            22.024618
Log Pis Mean                 -2.4286802
Log Pis Std                  1.8064067
Log Pis Max                  5.113868
Log Pis Min                  -9.026776
Policy mu Mean               0.010798343
Policy mu Std                0.37311816
Policy mu Max                1.4395107
Policy mu Min                -1.3292726
Policy log std Mean          -0.79383445
Policy log std Std           0.16559118
Policy log std Max           -0.37997434
Policy log std Min           -1.7987647
Z mean eval                  0.8693577
Z variance eval              0.012296707
total_rewards                [ 28.72237953 275.27154844 316.40196079 286.71262077 391.27493438
 144.38832598  81.20357629 205.37550218 429.310188   193.89634427]
total_rewards_mean           235.2557380634486
total_rewards_std            122.50767965336416
total_rewards_max            429.31018799877944
total_rewards_min            28.72237953240355
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               31.650846930220723
(Previous) Eval Time (s)     28.859739569947124
Sample Time (s)              26.335494892206043
Epoch Time (s)               86.84608139237389
Total Train Time (s)         4523.8806048003025
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:01:44.443847 UTC | [2020_01_10_11_46_20] Iteration #51 | Epoch Duration: 78.14188194274902
2020-01-10 13:01:44.444018 UTC | [2020_01_10_11_46_20] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8698532
Z variance train             0.012290666
KL Divergence                16.785978
KL Loss                      1.6785978
QF Loss                      122.32676
VF Loss                      21.038576
Policy Loss                  -381.4646
Q Predictions Mean           379.76297
Q Predictions Std            38.271767
Q Predictions Max            495.69693
Q Predictions Min            279.12442
V Predictions Mean           381.13687
V Predictions Std            36.341923
V Predictions Max            485.41953
V Predictions Min            282.94592
Log Pis Mean                 -2.7845907
Log Pis Std                  1.673969
Log Pis Max                  1.3260667
Log Pis Min                  -9.37089
Policy mu Mean               -0.0018415437
Policy mu Std                0.32771984
Policy mu Max                1.0243508
Policy mu Min                -1.1420652
Policy log std Mean          -0.7958392
Policy log std Std           0.1484735
Policy log std Max           -0.4440679
Policy log std Min           -1.2558331
Z mean eval                  0.8555236
Z variance eval              0.015131848
total_rewards                [349.83909777 220.68801553 664.82753954 718.86349471 662.67799832
 140.18983738 183.36273267 226.94976982 788.64259464 246.22864717]
total_rewards_mean           420.22697275502026
total_rewards_std            242.9923842554842
total_rewards_max            788.6425946404331
total_rewards_min            140.1898373792983
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               32.46551186591387
(Previous) Eval Time (s)     20.155157530214638
Sample Time (s)              25.7406591065228
Epoch Time (s)               78.3613285026513
Total Train Time (s)         4614.732441277243
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:03:15.297031 UTC | [2020_01_10_11_46_20] Iteration #52 | Epoch Duration: 90.8528904914856
2020-01-10 13:03:15.297193 UTC | [2020_01_10_11_46_20] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8541253
Z variance train             0.015162868
KL Divergence                16.237774
KL Loss                      1.6237774
QF Loss                      214.05005
VF Loss                      72.74283
Policy Loss                  -366.42575
Q Predictions Mean           362.9972
Q Predictions Std            52.530514
Q Predictions Max            461.29712
Q Predictions Min            -9.439743
V Predictions Mean           363.83527
V Predictions Std            47.253647
V Predictions Max            454.85275
V Predictions Min            0.035629153
Log Pis Mean                 -2.4865217
Log Pis Std                  1.7013757
Log Pis Max                  4.010396
Log Pis Min                  -8.066638
Policy mu Mean               0.02846348
Policy mu Std                0.3429594
Policy mu Max                1.4888532
Policy mu Min                -1.8089405
Policy log std Mean          -0.7976062
Policy log std Std           0.18244687
Policy log std Max           -0.3941512
Policy log std Min           -1.8986782
Z mean eval                  0.87575924
Z variance eval              0.012890475
total_rewards                [188.21197663 189.50528563 325.27176167 384.07918281 449.05566569
 357.33431703 258.38635374 190.2886918  260.97432358 323.69862415]
total_rewards_mean           292.68061827282406
total_rewards_std            85.57779606458406
total_rewards_max            449.0556656850581
total_rewards_min            188.21197663096018
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               32.50301228277385
(Previous) Eval Time (s)     32.64636654034257
Sample Time (s)              25.89106347085908
Epoch Time (s)               91.0404422939755
Total Train Time (s)         4702.442482749
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:04:43.009397 UTC | [2020_01_10_11_46_20] Iteration #53 | Epoch Duration: 87.71206855773926
2020-01-10 13:04:43.009838 UTC | [2020_01_10_11_46_20] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87177163
Z variance train             0.012912231
KL Divergence                17.177841
KL Loss                      1.7177842
QF Loss                      165.10358
VF Loss                      34.56708
Policy Loss                  -376.427
Q Predictions Mean           371.8319
Q Predictions Std            39.353775
Q Predictions Max            461.45978
Q Predictions Min            227.23718
V Predictions Mean           376.50665
V Predictions Std            38.78946
V Predictions Max            462.16544
V Predictions Min            246.58707
Log Pis Mean                 -2.7365088
Log Pis Std                  1.6651628
Log Pis Max                  3.2050226
Log Pis Min                  -10.226701
Policy mu Mean               -0.05645914
Policy mu Std                0.3274131
Policy mu Max                1.1627889
Policy mu Min                -1.1509693
Policy log std Mean          -0.8066739
Policy log std Std           0.15427798
Policy log std Max           -0.43366313
Policy log std Min           -1.6175435
Z mean eval                  0.8876046
Z variance eval              0.018560883
total_rewards                [211.16678667 351.86508044 395.94360303 451.87479357 196.27756201
 286.83487946 273.62512782 665.63928412 365.84910566 192.34865923]
total_rewards_mean           339.14248819978604
total_rewards_std            137.39556427317694
total_rewards_max            665.6392841205972
total_rewards_min            192.34865923221597
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               31.76992569118738
(Previous) Eval Time (s)     29.317596822045743
Sample Time (s)              25.163088597822934
Epoch Time (s)               86.25061111105606
Total Train Time (s)         4792.0575509243645
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:06:12.627659 UTC | [2020_01_10_11_46_20] Iteration #54 | Epoch Duration: 89.61737585067749
2020-01-10 13:06:12.628071 UTC | [2020_01_10_11_46_20] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.887263
Z variance train             0.018661175
KL Divergence                16.653692
KL Loss                      1.6653693
QF Loss                      152.57843
VF Loss                      38.149982
Policy Loss                  -387.92456
Q Predictions Mean           385.69537
Q Predictions Std            53.03628
Q Predictions Max            495.19672
Q Predictions Min            -19.799519
V Predictions Mean           391.8083
V Predictions Std            51.61231
V Predictions Max            500.24115
V Predictions Min            23.089363
Log Pis Mean                 -2.7500303
Log Pis Std                  1.6743258
Log Pis Max                  2.0207546
Log Pis Min                  -9.193373
Policy mu Mean               -0.009991877
Policy mu Std                0.33000657
Policy mu Max                1.1871489
Policy mu Min                -1.1972954
Policy log std Mean          -0.81271744
Policy log std Std           0.15535949
Policy log std Max           -0.36923397
Policy log std Min           -1.6181431
Z mean eval                  0.86632997
Z variance eval              0.015820922
total_rewards                [112.59611999 168.45525574 295.15081022 750.70885466 299.65188026
 158.91739956 438.78073091 232.89251919 255.08145149 235.45978884]
total_rewards_mean           294.7694810851787
total_rewards_std            174.68934668635129
total_rewards_max            750.7088546576675
total_rewards_min            112.59611999300947
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               32.30339303938672
(Previous) Eval Time (s)     32.68392200907692
Sample Time (s)              24.381657240446657
Epoch Time (s)               89.3689722889103
Total Train Time (s)         4884.296375363134
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:07:44.867636 UTC | [2020_01_10_11_46_20] Iteration #55 | Epoch Duration: 92.23934864997864
2020-01-10 13:07:44.867865 UTC | [2020_01_10_11_46_20] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8673705
Z variance train             0.01580377
KL Divergence                17.131676
KL Loss                      1.7131675
QF Loss                      116.392
VF Loss                      117.38811
Policy Loss                  -379.6792
Q Predictions Mean           376.0318
Q Predictions Std            57.59073
Q Predictions Max            470.00092
Q Predictions Min            -11.640484
V Predictions Mean           375.76633
V Predictions Std            52.327953
V Predictions Max            467.1223
V Predictions Min            19.508892
Log Pis Mean                 -2.692577
Log Pis Std                  1.7556133
Log Pis Max                  13.362753
Log Pis Min                  -6.799618
Policy mu Mean               -0.011161708
Policy mu Std                0.33239445
Policy mu Max                2.45682
Policy mu Min                -1.5980159
Policy log std Mean          -0.77781284
Policy log std Std           0.16530693
Policy log std Max           -0.31965244
Policy log std Min           -2.0151653
Z mean eval                  0.8827261
Z variance eval              0.017193982
total_rewards                [173.92964615 477.70083371 359.97574025 373.50495022 360.80253649
 325.58755145 117.79316233 225.63801716 216.73941095 155.20724694]
total_rewards_mean           278.68790956556614
total_rewards_std            110.86356931090457
total_rewards_max            477.7008337109342
total_rewards_min            117.79316232992265
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               32.43507182691246
(Previous) Eval Time (s)     35.5539051219821
Sample Time (s)              26.005305520258844
Epoch Time (s)               93.9942824691534
Total Train Time (s)         4976.363597228192
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:09:16.936506 UTC | [2020_01_10_11_46_20] Iteration #56 | Epoch Duration: 92.06846165657043
2020-01-10 13:09:16.936724 UTC | [2020_01_10_11_46_20] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.882398
Z variance train             0.017261852
KL Divergence                16.858406
KL Loss                      1.6858406
QF Loss                      179.60835
VF Loss                      34.13985
Policy Loss                  -388.56866
Q Predictions Mean           384.8
Q Predictions Std            59.34865
Q Predictions Max            471.3106
Q Predictions Min            -14.555197
V Predictions Mean           388.5222
V Predictions Std            53.854324
V Predictions Max            468.83972
V Predictions Min            -5.9465284
Log Pis Mean                 -2.6677935
Log Pis Std                  1.9831241
Log Pis Max                  9.562279
Log Pis Min                  -8.319251
Policy mu Mean               0.026087947
Policy mu Std                0.33526242
Policy mu Max                1.8555678
Policy mu Min                -1.63333
Policy log std Mean          -0.8153172
Policy log std Std           0.184328
Policy log std Max           -0.25893953
Policy log std Min           -2.2377918
Z mean eval                  0.8656684
Z variance eval              0.014077691
total_rewards                [260.22340379 766.67168807 142.26803247 256.62750515 280.62911086
 602.63098282 372.29435051 231.76875971 540.62223267 222.37560555]
total_rewards_mean           367.6111671600086
total_rewards_std            191.3582539469477
total_rewards_max            766.6716880689155
total_rewards_min            142.26803246800102
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               32.32928706379607
(Previous) Eval Time (s)     33.62766703823581
Sample Time (s)              25.067148050758988
Epoch Time (s)               91.02410215279087
Total Train Time (s)         5066.915731446352
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:10:47.491636 UTC | [2020_01_10_11_46_20] Iteration #57 | Epoch Duration: 90.55472183227539
2020-01-10 13:10:47.491992 UTC | [2020_01_10_11_46_20] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8642216
Z variance train             0.014070764
KL Divergence                16.582092
KL Loss                      1.6582092
QF Loss                      147.13965
VF Loss                      34.160145
Policy Loss                  -391.30005
Q Predictions Mean           389.40576
Q Predictions Std            37.81817
Q Predictions Max            473.2192
Q Predictions Min            284.7548
V Predictions Mean           393.12024
V Predictions Std            37.650032
V Predictions Max            481.6317
V Predictions Min            286.52884
Log Pis Mean                 -2.5715904
Log Pis Std                  1.8224486
Log Pis Max                  2.1499019
Log Pis Min                  -11.075532
Policy mu Mean               -0.008445098
Policy mu Std                0.3451542
Policy mu Max                1.2419562
Policy mu Min                -1.147232
Policy log std Mean          -0.77903074
Policy log std Std           0.1668509
Policy log std Max           -0.30062962
Policy log std Min           -1.5658163
Z mean eval                  0.88843566
Z variance eval              0.013374275
total_rewards                [562.80235429 945.57635861 139.3407591  400.19329313 350.23686726
 720.79503928 736.57175557 181.06301733  28.57534816 202.31887625]
total_rewards_mean           426.74736689874874
total_rewards_std            287.8508476311896
total_rewards_max            945.5763586101805
total_rewards_min            28.575348161673737
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               32.17979758000001
(Previous) Eval Time (s)     33.157785184681416
Sample Time (s)              25.342269466724247
Epoch Time (s)               90.67985223140568
Total Train Time (s)         5155.230513536837
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:12:15.806790 UTC | [2020_01_10_11_46_20] Iteration #58 | Epoch Duration: 88.314617395401
2020-01-10 13:12:15.806999 UTC | [2020_01_10_11_46_20] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8880271
Z variance train             0.013343945
KL Divergence                16.634243
KL Loss                      1.6634244
QF Loss                      132.51541
VF Loss                      30.015057
Policy Loss                  -391.71683
Q Predictions Mean           389.54547
Q Predictions Std            49.39765
Q Predictions Max            468.36377
Q Predictions Min            -21.272604
V Predictions Mean           392.2343
V Predictions Std            46.75564
V Predictions Max            472.20355
V Predictions Min            37.79342
Log Pis Mean                 -2.4143426
Log Pis Std                  1.6451027
Log Pis Max                  4.76378
Log Pis Min                  -8.11466
Policy mu Mean               -0.0011073342
Policy mu Std                0.36017025
Policy mu Max                1.4537476
Policy mu Min                -1.3320565
Policy log std Mean          -0.79962116
Policy log std Std           0.16347606
Policy log std Max           -0.41758528
Policy log std Min           -1.5617898
Z mean eval                  0.87305385
Z variance eval              0.01157552
total_rewards                [298.2724399  175.16650269 398.31777103 119.94363583 559.23117281
 232.00327301 638.89644687  97.3570112   20.95853203 867.17056767]
total_rewards_mean           340.7317353032971
total_rewards_std            258.5281908043238
total_rewards_max            867.1705676667925
total_rewards_min            20.958532026978467
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               32.377342669293284
(Previous) Eval Time (s)     30.79218555893749
Sample Time (s)              25.332856906112283
Epoch Time (s)               88.50238513434306
Total Train Time (s)         5241.974466984626
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:13:42.552599 UTC | [2020_01_10_11_46_20] Iteration #59 | Epoch Duration: 86.74544525146484
2020-01-10 13:13:42.552806 UTC | [2020_01_10_11_46_20] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8739109
Z variance train             0.011609824
KL Divergence                17.180946
KL Loss                      1.7180947
QF Loss                      428.53098
VF Loss                      52.461807
Policy Loss                  -394.29718
Q Predictions Mean           390.16168
Q Predictions Std            49.67395
Q Predictions Max            523.2678
Q Predictions Min            14.287926
V Predictions Mean           394.23544
V Predictions Std            49.818897
V Predictions Max            516.93
V Predictions Min            13.937482
Log Pis Mean                 -2.4465134
Log Pis Std                  1.7348846
Log Pis Max                  5.4898186
Log Pis Min                  -7.6685257
Policy mu Mean               0.032442585
Policy mu Std                0.35201463
Policy mu Max                1.4838132
Policy mu Min                -1.0915493
Policy log std Mean          -0.803699
Policy log std Std           0.178224
Policy log std Max           -0.40334368
Policy log std Min           -1.915184
Z mean eval                  0.86889714
Z variance eval              0.013800247
total_rewards                [151.87778883 176.87016645 126.1479848  205.37872918 171.13111735
 158.17489564 251.22246231 805.20390039 797.62973597 103.06236364]
total_rewards_mean           294.66991445652843
total_rewards_std            256.27062265178716
total_rewards_max            805.2039003939125
total_rewards_min            103.0623636446377
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               32.429127301089466
(Previous) Eval Time (s)     29.034873811062425
Sample Time (s)              26.303206221200526
Epoch Time (s)               87.76720733335242
Total Train Time (s)         5330.3330243052915
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:15:10.913183 UTC | [2020_01_10_11_46_20] Iteration #60 | Epoch Duration: 88.36014008522034
2020-01-10 13:15:10.913466 UTC | [2020_01_10_11_46_20] Iteration #60 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8704723
Z variance train             0.013783701
KL Divergence                16.954687
KL Loss                      1.6954688
QF Loss                      156.63303
VF Loss                      21.594147
Policy Loss                  -403.78693
Q Predictions Mean           400.63977
Q Predictions Std            54.530746
Q Predictions Max            495.89948
Q Predictions Min            -31.147554
V Predictions Mean           405.18008
V Predictions Std            52.820976
V Predictions Max            501.00778
V Predictions Min            4.6136246
Log Pis Mean                 -2.4755707
Log Pis Std                  1.6876489
Log Pis Max                  1.2137113
Log Pis Min                  -8.811138
Policy mu Mean               0.026319884
Policy mu Std                0.34797144
Policy mu Max                1.200874
Policy mu Min                -1.5020663
Policy log std Mean          -0.80824995
Policy log std Std           0.16778581
Policy log std Max           -0.074341476
Policy log std Min           -1.8259594
Z mean eval                  0.875531
Z variance eval              0.013174327
total_rewards                [863.96417201  88.92563509 413.387988   286.55813194 862.2248906
 515.38072555 928.38908982 839.91733967 982.86354168 251.57020623]
total_rewards_mean           603.3181720590618
total_rewards_std            311.95251038649195
total_rewards_max            982.8635416804213
total_rewards_min            88.92563509261858
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               31.807827645912766
(Previous) Eval Time (s)     29.627422442659736
Sample Time (s)              26.839364282786846
Epoch Time (s)               88.27461437135935
Total Train Time (s)         5422.78442156408
Epoch                        61
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:16:43.365576 UTC | [2020_01_10_11_46_20] Iteration #61 | Epoch Duration: 92.4519693851471
2020-01-10 13:16:43.365744 UTC | [2020_01_10_11_46_20] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8712338
Z variance train             0.013194026
KL Divergence                17.313053
KL Loss                      1.7313054
QF Loss                      152.04361
VF Loss                      26.914864
Policy Loss                  -398.29233
Q Predictions Mean           394.93805
Q Predictions Std            46.082043
Q Predictions Max            485.2176
Q Predictions Min            280.7735
V Predictions Mean           400.08496
V Predictions Std            45.653343
V Predictions Max            486.93665
V Predictions Min            281.05725
Log Pis Mean                 -2.7419803
Log Pis Std                  1.6557355
Log Pis Max                  7.4422846
Log Pis Min                  -7.2167673
Policy mu Mean               -0.027810948
Policy mu Std                0.3460132
Policy mu Max                1.0796444
Policy mu Min                -1.2379026
Policy log std Mean          -0.7790968
Policy log std Std           0.1589989
Policy log std Max           -0.39186725
Policy log std Min           -1.925226
Z mean eval                  0.8897193
Z variance eval              0.013657716
total_rewards                [144.82456541 571.12993566 837.59794643 737.32593653 662.69025041
 451.88534047  54.00794739 151.27475461 342.95321412 374.40254715]
total_rewards_mean           432.809243818106
total_rewards_std            254.18473841421124
total_rewards_max            837.5979464314607
total_rewards_min            54.007947387828764
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               32.144811027217656
(Previous) Eval Time (s)     33.80438036704436
Sample Time (s)              25.692265029530972
Epoch Time (s)               91.64145642379299
Total Train Time (s)         5508.748262546025
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:18:09.336447 UTC | [2020_01_10_11_46_20] Iteration #62 | Epoch Duration: 85.9705638885498
2020-01-10 13:18:09.336666 UTC | [2020_01_10_11_46_20] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89328134
Z variance train             0.013628095
KL Divergence                17.196442
KL Loss                      1.7196442
QF Loss                      165.40645
VF Loss                      69.550934
Policy Loss                  -405.5536
Q Predictions Mean           403.2977
Q Predictions Std            50.442295
Q Predictions Max            506.70557
Q Predictions Min            3.2041612
V Predictions Mean           411.24207
V Predictions Std            50.509876
V Predictions Max            516.9867
V Predictions Min            0.54149705
Log Pis Mean                 -2.6380093
Log Pis Std                  1.8801394
Log Pis Max                  3.1734023
Log Pis Min                  -10.87112
Policy mu Mean               0.019421905
Policy mu Std                0.35172805
Policy mu Max                1.4648653
Policy mu Min                -1.0867162
Policy log std Mean          -0.7977133
Policy log std Std           0.15646355
Policy log std Max           -0.35950464
Policy log std Min           -1.598153
Z mean eval                  0.88565123
Z variance eval              0.010562324
total_rewards                [285.76685023 958.77820567 422.12737238 238.3329417  274.13295398
 220.95621042 169.97685772 425.26532005 622.19749558 734.88754456]
total_rewards_mean           435.24217522961044
total_rewards_std            245.450119906303
total_rewards_max            958.7782056707149
total_rewards_min            169.97685772384202
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               32.22992697870359
(Previous) Eval Time (s)     28.133076906204224
Sample Time (s)              24.849264608696103
Epoch Time (s)               85.21226849360391
Total Train Time (s)         5593.522447717376
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:19:34.107634 UTC | [2020_01_10_11_46_20] Iteration #63 | Epoch Duration: 84.7707908153534
2020-01-10 13:19:34.107845 UTC | [2020_01_10_11_46_20] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.885338
Z variance train             0.010560116
KL Divergence                17.4067
KL Loss                      1.7406701
QF Loss                      178.83133
VF Loss                      30.134106
Policy Loss                  -410.1489
Q Predictions Mean           406.2059
Q Predictions Std            47.895767
Q Predictions Max            486.1308
Q Predictions Min            -4.458806
V Predictions Mean           409.94522
V Predictions Std            47.27024
V Predictions Max            495.44983
V Predictions Min            22.840834
Log Pis Mean                 -2.5805035
Log Pis Std                  1.6894624
Log Pis Max                  1.479971
Log Pis Min                  -8.334144
Policy mu Mean               -0.018779851
Policy mu Std                0.35459864
Policy mu Max                1.330102
Policy mu Min                -1.0536127
Policy log std Mean          -0.8162781
Policy log std Std           0.16644047
Policy log std Max           -0.36521247
Policy log std Min           -1.6603572
Z mean eval                  0.89931405
Z variance eval              0.009994132
total_rewards                [335.74455158 189.32825854 292.18546781  97.08626424 731.15923866
 357.15328377 116.99858076 127.44110062 702.80963887 131.01726875]
total_rewards_mean           308.0923653601629
total_rewards_std            223.0129465701709
total_rewards_max            731.159238656356
total_rewards_min            97.08626424038523
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               31.8858117046766
(Previous) Eval Time (s)     27.69128311937675
Sample Time (s)              26.293694328982383
Epoch Time (s)               85.87078915303573
Total Train Time (s)         5672.662834872957
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:20:53.253686 UTC | [2020_01_10_11_46_20] Iteration #64 | Epoch Duration: 79.1456937789917
2020-01-10 13:20:53.253894 UTC | [2020_01_10_11_46_20] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89893454
Z variance train             0.009974967
KL Divergence                17.652882
KL Loss                      1.7652882
QF Loss                      218.17883
VF Loss                      55.44613
Policy Loss                  -407.45807
Q Predictions Mean           402.312
Q Predictions Std            57.004795
Q Predictions Max            493.6883
Q Predictions Min            -43.997646
V Predictions Mean           408.07324
V Predictions Std            51.99394
V Predictions Max            495.98312
V Predictions Min            17.656994
Log Pis Mean                 -2.28048
Log Pis Std                  1.7742873
Log Pis Max                  5.1545596
Log Pis Min                  -7.170105
Policy mu Mean               0.033252873
Policy mu Std                0.38810807
Policy mu Max                1.7941307
Policy mu Min                -1.3000579
Policy log std Mean          -0.8099839
Policy log std Std           0.18370801
Policy log std Max           -0.3349483
Policy log std Min           -1.8632321
Z mean eval                  0.90698576
Z variance eval              0.010200149
total_rewards                [ 847.21722507 1127.67114385   43.44229206   29.00728458   58.84436494
  452.94412104  287.86673597  389.73809805  620.02800345  212.6168057 ]
total_rewards_mean           406.937607473374
total_rewards_std            347.73415659461625
total_rewards_max            1127.6711438509662
total_rewards_min            29.007284582238267
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               32.19044262263924
(Previous) Eval Time (s)     20.965793465729803
Sample Time (s)              25.48515216447413
Epoch Time (s)               78.64138825284317
Total Train Time (s)         5755.245659662876
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:22:15.834636 UTC | [2020_01_10_11_46_20] Iteration #65 | Epoch Duration: 82.58057880401611
2020-01-10 13:22:15.834859 UTC | [2020_01_10_11_46_20] Iteration #65 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9068216
Z variance train             0.010201758
KL Divergence                17.494207
KL Loss                      1.7494208
QF Loss                      529.0411
VF Loss                      85.61749
Policy Loss                  -411.40704
Q Predictions Mean           409.00317
Q Predictions Std            58.610157
Q Predictions Max            492.29898
Q Predictions Min            -3.6491609
V Predictions Mean           414.9166
V Predictions Std            60.048798
V Predictions Max            511.20248
V Predictions Min            0.76527095
Log Pis Mean                 -2.317984
Log Pis Std                  1.8109628
Log Pis Max                  6.515542
Log Pis Min                  -7.926849
Policy mu Mean               0.047222257
Policy mu Std                0.37692708
Policy mu Max                1.4552771
Policy mu Min                -1.2657448
Policy log std Mean          -0.81669414
Policy log std Std           0.16920993
Policy log std Max           -0.39754835
Policy log std Min           -1.8703696
Z mean eval                  0.9205033
Z variance eval              0.013044581
total_rewards                [232.34641787 256.75946598  66.14091242 245.47625875 220.44021968
 495.57551444 522.03267487 929.81684383  39.30253523 418.2141187 ]
total_rewards_mean           342.6104961765933
total_rewards_std            248.68417124875458
total_rewards_max            929.81684383496
total_rewards_min            39.302535225989935
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               32.08865064801648
(Previous) Eval Time (s)     24.90460950927809
Sample Time (s)              26.455946892965585
Epoch Time (s)               83.44920705026016
Total Train Time (s)         5837.233047042042
Epoch                        66
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:23:37.824227 UTC | [2020_01_10_11_46_20] Iteration #66 | Epoch Duration: 81.98913812637329
2020-01-10 13:23:37.824526 UTC | [2020_01_10_11_46_20] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9194721
Z variance train             0.01297538
KL Divergence                17.151989
KL Loss                      1.7151989
QF Loss                      190.26062
VF Loss                      100.90816
Policy Loss                  -415.87665
Q Predictions Mean           414.6029
Q Predictions Std            65.46522
Q Predictions Max            510.1655
Q Predictions Min            -28.684502
V Predictions Mean           419.71887
V Predictions Std            63.325794
V Predictions Max            519.4369
V Predictions Min            6.8857727
Log Pis Mean                 -2.1100163
Log Pis Std                  1.9555198
Log Pis Max                  9.722687
Log Pis Min                  -9.347441
Policy mu Mean               0.010092574
Policy mu Std                0.42137417
Policy mu Max                2.6598163
Policy mu Min                -1.5377995
Policy log std Mean          -0.8092202
Policy log std Std           0.16682872
Policy log std Max           0.031689018
Policy log std Min           -1.5890231
Z mean eval                  0.9047961
Z variance eval              0.017226461
total_rewards                [ 452.54361488  373.15900289 1036.79621339  464.94691624  382.49263802
  357.01825055  176.27542381  317.63261727  580.35636347  309.34711374]
total_rewards_mean           445.05681542737375
total_rewards_std            221.95607619975854
total_rewards_max            1036.7962133939084
total_rewards_min            176.27542380843803
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               32.17296402622014
(Previous) Eval Time (s)     23.444101313129067
Sample Time (s)              26.959476564545184
Epoch Time (s)               82.5765419038944
Total Train Time (s)         5927.435291434638
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:25:08.027904 UTC | [2020_01_10_11_46_20] Iteration #67 | Epoch Duration: 90.20321035385132
2020-01-10 13:25:08.028124 UTC | [2020_01_10_11_46_20] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9087137
Z variance train             0.01728343
KL Divergence                16.888142
KL Loss                      1.6888142
QF Loss                      152.7619
VF Loss                      72.12579
Policy Loss                  -425.05756
Q Predictions Mean           422.82663
Q Predictions Std            45.7086
Q Predictions Max            506.69614
Q Predictions Min            291.48218
V Predictions Mean           427.95935
V Predictions Std            46.571278
V Predictions Max            512.91693
V Predictions Min            255.2446
Log Pis Mean                 -2.489923
Log Pis Std                  1.9501376
Log Pis Max                  2.6754727
Log Pis Min                  -9.561211
Policy mu Mean               -0.0056954543
Policy mu Std                0.40095478
Policy mu Max                1.251358
Policy mu Min                -1.42837
Policy log std Mean          -0.81414807
Policy log std Std           0.16392246
Policy log std Max           -0.36136502
Policy log std Min           -1.5887523
Z mean eval                  0.9047201
Z variance eval              0.013954515
total_rewards                [ 301.17938989  134.4239904   232.23898185 1037.23561275 1037.58422319
  449.07284032  252.12133048   79.75978902  144.93676244  670.6608181 ]
total_rewards_mean           433.9213738441148
total_rewards_std            342.73323908571354
total_rewards_max            1037.5842231882805
total_rewards_min            79.75978902238785
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               31.59458307083696
(Previous) Eval Time (s)     31.070366667117923
Sample Time (s)              26.258964932523668
Epoch Time (s)               88.92391467047855
Total Train Time (s)         6014.911369047128
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:26:35.505501 UTC | [2020_01_10_11_46_20] Iteration #68 | Epoch Duration: 87.47721266746521
2020-01-10 13:26:35.505696 UTC | [2020_01_10_11_46_20] Iteration #68 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9065237
Z variance train             0.013958004
KL Divergence                17.924086
KL Loss                      1.7924086
QF Loss                      191.81317
VF Loss                      60.53836
Policy Loss                  -430.065
Q Predictions Mean           426.77783
Q Predictions Std            55.466305
Q Predictions Max            551.5016
Q Predictions Min            20.614595
V Predictions Mean           435.574
V Predictions Std            53.68439
V Predictions Max            560.39575
V Predictions Min            111.04678
Log Pis Mean                 -2.2947402
Log Pis Std                  2.0307708
Log Pis Max                  6.6233497
Log Pis Min                  -9.54424
Policy mu Mean               0.023075704
Policy mu Std                0.38054097
Policy mu Max                1.8777068
Policy mu Min                -1.088638
Policy log std Mean          -0.81697774
Policy log std Std           0.19677822
Policy log std Max           -0.35712564
Policy log std Min           -1.9141698
Z mean eval                  0.9174007
Z variance eval              0.011408759
total_rewards                [968.87881807 236.60850852 671.7411808  184.19396112 320.74529135
 256.05508037 492.98866685 119.58298223 130.12625621 293.96294436]
total_rewards_mean           367.4883689879985
total_rewards_std            256.6170459838284
total_rewards_max            968.8788180689198
total_rewards_min            119.58298222657314
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               32.159114378038794
(Previous) Eval Time (s)     29.6232822611928
Sample Time (s)              24.363743612077087
Epoch Time (s)               86.14614025130868
Total Train Time (s)         6102.5736352331005
Epoch                        69
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:28:03.169848 UTC | [2020_01_10_11_46_20] Iteration #69 | Epoch Duration: 87.66394662857056
2020-01-10 13:28:03.170131 UTC | [2020_01_10_11_46_20] Iteration #69 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9119595
Z variance train             0.011413154
KL Divergence                18.277214
KL Loss                      1.8277215
QF Loss                      265.2984
VF Loss                      66.78619
Policy Loss                  -419.62653
Q Predictions Mean           415.22757
Q Predictions Std            70.60254
Q Predictions Max            574.2331
Q Predictions Min            -9.094055
V Predictions Mean           415.6974
V Predictions Std            66.743416
V Predictions Max            559.13293
V Predictions Min            -2.6149597
Log Pis Mean                 -2.1212173
Log Pis Std                  1.6545771
Log Pis Max                  4.1574416
Log Pis Min                  -8.623024
Policy mu Mean               -0.004331267
Policy mu Std                0.3759066
Policy mu Max                1.5559429
Policy mu Min                -1.684592
Policy log std Mean          -0.82944626
Policy log std Std           0.18516348
Policy log std Max           -0.3695621
Policy log std Min           -1.8096987
Z mean eval                  0.89685905
Z variance eval              0.009618893
total_rewards                [279.26274416 140.54050222 562.23202993 174.4605459  282.85634801
 243.19954204 128.50058066 334.76920587 284.6920789  246.1103146 ]
total_rewards_mean           267.66238922980125
total_rewards_std            117.13476108476871
total_rewards_max            562.232029931059
total_rewards_min            128.50058066335774
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               32.472920787055045
(Previous) Eval Time (s)     31.140775977168232
Sample Time (s)              26.02445412473753
Epoch Time (s)               89.63815088896081
Total Train Time (s)         6189.662359294482
Epoch                        70
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:29:30.260213 UTC | [2020_01_10_11_46_20] Iteration #70 | Epoch Duration: 87.08989810943604
2020-01-10 13:29:30.260443 UTC | [2020_01_10_11_46_20] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8969576
Z variance train             0.009628011
KL Divergence                17.62684
KL Loss                      1.7626841
QF Loss                      316.08292
VF Loss                      71.141045
Policy Loss                  -435.0945
Q Predictions Mean           432.42783
Q Predictions Std            58.79586
Q Predictions Max            576.4788
Q Predictions Min            52.321777
V Predictions Mean           431.51254
V Predictions Std            54.2963
V Predictions Max            569.5467
V Predictions Min            112.478935
Log Pis Mean                 -2.357773
Log Pis Std                  2.022975
Log Pis Max                  7.366563
Log Pis Min                  -6.7241063
Policy mu Mean               0.039546542
Policy mu Std                0.3859327
Policy mu Max                2.0657163
Policy mu Min                -1.1768749
Policy log std Mean          -0.83293545
Policy log std Std           0.20809695
Policy log std Max           -0.3815006
Policy log std Min           -2.060332
Z mean eval                  0.91889536
Z variance eval              0.012082893
total_rewards                [ 366.61563935  980.67039658  234.15573286  324.11092341  269.21764308
  430.67321053  323.61691896  219.98734122  151.25057435 1018.82103715]
total_rewards_mean           431.91194174791144
total_rewards_std            293.6787247184287
total_rewards_max            1018.8210371505418
total_rewards_min            151.25057434947868
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               32.12367171095684
(Previous) Eval Time (s)     28.592091206926852
Sample Time (s)              26.901888952124864
Epoch Time (s)               87.61765187000856
Total Train Time (s)         6279.5368310301565
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:31:00.144279 UTC | [2020_01_10_11_46_20] Iteration #71 | Epoch Duration: 89.88367104530334
2020-01-10 13:31:00.144488 UTC | [2020_01_10_11_46_20] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9204853
Z variance train             0.012034156
KL Divergence                17.430838
KL Loss                      1.7430838
QF Loss                      447.4178
VF Loss                      80.01307
Policy Loss                  -434.8861
Q Predictions Mean           429.16962
Q Predictions Std            55.296978
Q Predictions Max            550.9991
Q Predictions Min            75.56461
V Predictions Mean           431.6314
V Predictions Std            55.71805
V Predictions Max            546.17737
V Predictions Min            32.238873
Log Pis Mean                 -2.0969057
Log Pis Std                  1.9217324
Log Pis Max                  5.682617
Log Pis Min                  -7.865304
Policy mu Mean               -0.004743682
Policy mu Std                0.39592975
Policy mu Max                1.3088146
Policy mu Min                -1.6885564
Policy log std Mean          -0.8310535
Policy log std Std           0.18849456
Policy log std Max           -0.33577156
Policy log std Min           -1.9983265
Z mean eval                  0.91291445
Z variance eval              0.008694889
total_rewards                [ 90.46164796 287.76247727 942.03871322 293.33825114 402.50767729
 332.66436016 459.30898356 156.35330933 431.89139636 256.69621975]
total_rewards_mean           365.3023036052076
total_rewards_std            221.4789659709504
total_rewards_max            942.0387132200768
total_rewards_min            90.46164796430747
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               32.823349109850824
(Previous) Eval Time (s)     30.85762097593397
Sample Time (s)              25.862520995549858
Epoch Time (s)               89.54349108133465
Total Train Time (s)         6367.064900759142
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:32:27.665732 UTC | [2020_01_10_11_46_20] Iteration #72 | Epoch Duration: 87.52111315727234
2020-01-10 13:32:27.665898 UTC | [2020_01_10_11_46_20] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91332483
Z variance train             0.008660105
KL Divergence                17.513493
KL Loss                      1.7513493
QF Loss                      202.5993
VF Loss                      74.81963
Policy Loss                  -437.55377
Q Predictions Mean           435.7219
Q Predictions Std            57.769447
Q Predictions Max            541.0179
Q Predictions Min            56.36603
V Predictions Mean           441.1742
V Predictions Std            55.435253
V Predictions Max            542.88196
V Predictions Min            173.42886
Log Pis Mean                 -2.1123755
Log Pis Std                  1.7800581
Log Pis Max                  1.7799885
Log Pis Min                  -8.717033
Policy mu Mean               0.010427281
Policy mu Std                0.39441794
Policy mu Max                1.46292
Policy mu Min                -1.4052525
Policy log std Mean          -0.8506036
Policy log std Std           0.17668474
Policy log std Max           -0.2562133
Policy log std Min           -1.7504745
Z mean eval                  0.91594076
Z variance eval              0.008557497
total_rewards                [1257.71211747  282.80374593  589.5675848    96.70582648 1237.48909332
  262.44054551  798.43800892 1392.01489307  242.28615217 1128.6631271 ]
total_rewards_mean           728.812109476737
total_rewards_std            470.65218797887076
total_rewards_max            1392.0148930706714
total_rewards_min            96.70582647574086
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               32.30030895397067
(Previous) Eval Time (s)     28.834910213947296
Sample Time (s)              25.95654616318643
Epoch Time (s)               87.0917653311044
Total Train Time (s)         6457.446317342576
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:33:58.048799 UTC | [2020_01_10_11_46_20] Iteration #73 | Epoch Duration: 90.3827793598175
2020-01-10 13:33:58.048957 UTC | [2020_01_10_11_46_20] Iteration #73 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9180139
Z variance train             0.008537087
KL Divergence                17.68608
KL Loss                      1.7686081
QF Loss                      205.53683
VF Loss                      205.85553
Policy Loss                  -433.6834
Q Predictions Mean           430.1695
Q Predictions Std            61.54065
Q Predictions Max            536.7997
Q Predictions Min            37.15789
V Predictions Mean           426.5428
V Predictions Std            56.91054
V Predictions Max            537.9497
V Predictions Min            229.03874
Log Pis Mean                 -2.2802541
Log Pis Std                  2.1162581
Log Pis Max                  5.405172
Log Pis Min                  -11.031643
Policy mu Mean               0.0067452546
Policy mu Std                0.3888421
Policy mu Max                1.8455858
Policy mu Min                -1.4353855
Policy log std Mean          -0.8268398
Policy log std Std           0.19646199
Policy log std Max           -0.3042376
Policy log std Min           -1.6704334
Z mean eval                  0.9408318
Z variance eval              0.006888704
total_rewards                [184.9856258  837.15106458 734.03548276 685.43513887 555.87567433
 174.32299589  15.81434986 114.37368718 186.36999437  65.14763441]
total_rewards_mean           355.3511648048388
total_rewards_std            295.4017938690705
total_rewards_max            837.1510645803176
total_rewards_min            15.814349861163677
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               32.13591478485614
(Previous) Eval Time (s)     32.12542482605204
Sample Time (s)              25.04534467915073
Epoch Time (s)               89.30668429005891
Total Train Time (s)         6539.715659820009
Epoch                        74
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:35:20.320127 UTC | [2020_01_10_11_46_20] Iteration #74 | Epoch Duration: 82.27103424072266
2020-01-10 13:35:20.320336 UTC | [2020_01_10_11_46_20] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94241226
Z variance train             0.0068975897
KL Divergence                18.746765
KL Loss                      1.8746766
QF Loss                      171.1282
VF Loss                      23.734222
Policy Loss                  -453.26105
Q Predictions Mean           450.9119
Q Predictions Std            55.12842
Q Predictions Max            539.15247
Q Predictions Min            285.78784
V Predictions Mean           454.65857
V Predictions Std            54.81475
V Predictions Max            546.3775
V Predictions Min            287.10025
Log Pis Mean                 -2.2987905
Log Pis Std                  1.8908267
Log Pis Max                  1.8889619
Log Pis Min                  -9.686573
Policy mu Mean               0.018407308
Policy mu Std                0.39884788
Policy mu Max                1.2308204
Policy mu Min                -1.1468741
Policy log std Mean          -0.82629025
Policy log std Std           0.16463599
Policy log std Max           -0.45226425
Policy log std Min           -1.3991895
Z mean eval                  0.9167148
Z variance eval              0.008716049
total_rewards                [1143.61075591 1418.42441736  591.00016414  112.33698187  365.40260346
  770.18307482 1352.8100972   579.41692604  316.6785764   339.16068343]
total_rewards_mean           698.9024280622008
total_rewards_std            436.4474304345599
total_rewards_max            1418.4244173576735
total_rewards_min            112.33698186952286
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               32.11265064775944
(Previous) Eval Time (s)     25.089405694045126
Sample Time (s)              26.254670552909374
Epoch Time (s)               83.45672689471394
Total Train Time (s)         6625.387232455891
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:36:45.993578 UTC | [2020_01_10_11_46_20] Iteration #75 | Epoch Duration: 85.67309522628784
2020-01-10 13:36:45.993770 UTC | [2020_01_10_11_46_20] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91719264
Z variance train             0.008730786
KL Divergence                18.421799
KL Loss                      1.8421799
QF Loss                      169.4278
VF Loss                      61.083385
Policy Loss                  -437.68646
Q Predictions Mean           435.23212
Q Predictions Std            70.56885
Q Predictions Max            568.6277
Q Predictions Min            -13.655567
V Predictions Mean           443.44397
V Predictions Std            69.24215
V Predictions Max            569.9631
V Predictions Min            0.5112817
Log Pis Mean                 -2.1396093
Log Pis Std                  1.8778206
Log Pis Max                  7.6684666
Log Pis Min                  -7.4479218
Policy mu Mean               0.020164192
Policy mu Std                0.38972282
Policy mu Max                1.8087195
Policy mu Min                -1.3421389
Policy log std Mean          -0.841017
Policy log std Std           0.21018508
Policy log std Max           -0.31385148
Policy log std Min           -2.04318
Z mean eval                  0.9248182
Z variance eval              0.013839893
total_rewards                [ 149.45677175  286.20503295  721.61637577  875.40967188   72.53497385
  850.79978401  253.55436211 1232.4250307   269.20474738  390.14503952]
total_rewards_mean           510.13517899312865
total_rewards_std            364.13062766896394
total_rewards_max            1232.4250306967951
total_rewards_min            72.53497385440429
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               34.15913534164429
(Previous) Eval Time (s)     27.305380051024258
Sample Time (s)              26.13059341069311
Epoch Time (s)               87.59510880336165
Total Train Time (s)         6714.96751002688
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:38:15.576004 UTC | [2020_01_10_11_46_20] Iteration #76 | Epoch Duration: 89.5820825099945
2020-01-10 13:38:15.576253 UTC | [2020_01_10_11_46_20] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92462
Z variance train             0.013821205
KL Divergence                17.744654
KL Loss                      1.7744654
QF Loss                      199.43855
VF Loss                      77.45876
Policy Loss                  -457.10556
Q Predictions Mean           453.73697
Q Predictions Std            69.72636
Q Predictions Max            605.99335
Q Predictions Min            -14.383617
V Predictions Mean           457.49442
V Predictions Std            63.720776
V Predictions Max            603.1544
V Predictions Min            96.317696
Log Pis Mean                 -1.7686709
Log Pis Std                  2.030477
Log Pis Max                  9.382593
Log Pis Min                  -7.265172
Policy mu Mean               0.02854813
Policy mu Std                0.41349524
Policy mu Max                1.8194094
Policy mu Min                -1.6437612
Policy log std Mean          -0.852126
Policy log std Std           0.19069786
Policy log std Max           -0.23968947
Policy log std Min           -1.9310452
Z mean eval                  0.9160302
Z variance eval              0.010750421
total_rewards                [ 170.25188776  142.38884512 1261.57451633  987.6788233  1363.42223451
  308.61184605  814.7815361   212.89593384  219.55621595  171.23683729]
total_rewards_mean           565.2398676262267
total_rewards_std            465.00118332290947
total_rewards_max            1363.4222345107012
total_rewards_min            142.388845117759
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               34.052704534027725
(Previous) Eval Time (s)     29.291895111091435
Sample Time (s)              25.43910070275888
Epoch Time (s)               88.78370034787804
Total Train Time (s)         6803.270002253354
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:39:43.902788 UTC | [2020_01_10_11_46_20] Iteration #77 | Epoch Duration: 88.32631945610046
2020-01-10 13:39:43.903399 UTC | [2020_01_10_11_46_20] Iteration #77 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9157709
Z variance train             0.010748976
KL Divergence                17.878746
KL Loss                      1.7878746
QF Loss                      204.46689
VF Loss                      58.183483
Policy Loss                  -449.7041
Q Predictions Mean           446.62537
Q Predictions Std            75.858604
Q Predictions Max            576.96344
Q Predictions Min            -5.848298
V Predictions Mean           449.8853
V Predictions Std            74.381714
V Predictions Max            569.61725
V Predictions Min            -0.50634384
Log Pis Mean                 -2.2213352
Log Pis Std                  1.9202063
Log Pis Max                  4.476557
Log Pis Min                  -9.222727
Policy mu Mean               0.04741172
Policy mu Std                0.38765284
Policy mu Max                1.5924671
Policy mu Min                -3.574035
Policy log std Mean          -0.850507
Policy log std Std           0.21220541
Policy log std Max           -0.02296251
Policy log std Min           -2.114361
Z mean eval                  0.942145
Z variance eval              0.012383495
total_rewards                [731.52599224 509.51597624 203.90839835 760.57485988 285.78737244
 535.92240103 300.59263894 513.31806727 717.67260188 650.21144336]
total_rewards_mean           520.9029751630712
total_rewards_std            190.25192875268186
total_rewards_max            760.5748598825555
total_rewards_min            203.90839834849862
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               35.04167858697474
(Previous) Eval Time (s)     28.834082442335784
Sample Time (s)              27.885405311360955
Epoch Time (s)               91.76116634067148
Total Train Time (s)         6894.99246621877
Epoch                        78
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:41:15.606026 UTC | [2020_01_10_11_46_20] Iteration #78 | Epoch Duration: 91.70219230651855
2020-01-10 13:41:15.606333 UTC | [2020_01_10_11_46_20] Iteration #78 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94472533
Z variance train             0.012383847
KL Divergence                18.352491
KL Loss                      1.8352492
QF Loss                      322.9337
VF Loss                      188.01772
Policy Loss                  -467.05798
Q Predictions Mean           463.01703
Q Predictions Std            66.4567
Q Predictions Max            591.4307
Q Predictions Min            139.5429
V Predictions Mean           469.3542
V Predictions Std            67.43646
V Predictions Max            603.57635
V Predictions Min            97.73087
Log Pis Mean                 -2.245486
Log Pis Std                  2.0835443
Log Pis Max                  7.987022
Log Pis Min                  -10.178995
Policy mu Mean               0.06647755
Policy mu Std                0.38111794
Policy mu Max                1.9819367
Policy mu Min                -1.490399
Policy log std Mean          -0.84558284
Policy log std Std           0.19144268
Policy log std Max           -0.36524627
Policy log std Min           -2.0833316
Z mean eval                  0.9197257
Z variance eval              0.013353999
total_rewards                [ 796.55641949  246.69049732 1460.42029807 1025.43066621  254.2220698
  824.90494995  600.48656246  449.88124947  203.49269964  202.04463495]
total_rewards_mean           606.413004736384
total_rewards_std            399.0779506371571
total_rewards_max            1460.4202980701086
total_rewards_min            202.04463495226568
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               34.67854860285297
(Previous) Eval Time (s)     28.7745840549469
Sample Time (s)              26.733750937972218
Epoch Time (s)               90.18688359577209
Total Train Time (s)         6988.429775488097
Epoch                        79
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:42:49.045292 UTC | [2020_01_10_11_46_20] Iteration #79 | Epoch Duration: 93.43876099586487
2020-01-10 13:42:49.045601 UTC | [2020_01_10_11_46_20] Iteration #79 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92096674
Z variance train             0.013321926
KL Divergence                17.694958
KL Loss                      1.7694958
QF Loss                      240.3576
VF Loss                      49.33436
Policy Loss                  -461.83005
Q Predictions Mean           457.56354
Q Predictions Std            76.191444
Q Predictions Max            569.5827
Q Predictions Min            -14.698362
V Predictions Mean           460.73785
V Predictions Std            77.14709
V Predictions Max            576.98065
V Predictions Min            -3.0277712
Log Pis Mean                 -1.9440026
Log Pis Std                  1.8722756
Log Pis Max                  4.458003
Log Pis Min                  -8.404905
Policy mu Mean               0.024054354
Policy mu Std                0.39103806
Policy mu Max                1.4319733
Policy mu Min                -1.5334847
Policy log std Mean          -0.8746276
Policy log std Std           0.19822562
Policy log std Max           -0.27225175
Policy log std Min           -1.8648012
Z mean eval                  0.9241355
Z variance eval              0.01197567
total_rewards                [421.01160928 446.20764132 332.5892363  258.44992514 185.18127834
  35.97495801 381.4784823  559.7674424  318.16877214 749.26535207]
total_rewards_mean           368.80946973020383
total_rewards_std            187.25421475953243
total_rewards_max            749.2653520670565
total_rewards_min            35.97495801279264
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               34.861776212695986
(Previous) Eval Time (s)     32.025994623079896
Sample Time (s)              26.001070550177246
Epoch Time (s)               92.88884138595313
Total Train Time (s)         7077.000738726463
Epoch                        80
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:44:17.617474 UTC | [2020_01_10_11_46_20] Iteration #80 | Epoch Duration: 88.57171177864075
2020-01-10 13:44:17.617657 UTC | [2020_01_10_11_46_20] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9226037
Z variance train             0.011971229
KL Divergence                18.242962
KL Loss                      1.8242962
QF Loss                      259.81107
VF Loss                      38.71159
Policy Loss                  -457.89587
Q Predictions Mean           453.91467
Q Predictions Std            79.06768
Q Predictions Max            586.56226
Q Predictions Min            -33.507023
V Predictions Mean           458.39697
V Predictions Std            76.51189
V Predictions Max            590.17035
V Predictions Min            -0.667925
Log Pis Mean                 -2.1868238
Log Pis Std                  2.0418215
Log Pis Max                  7.5130343
Log Pis Min                  -7.406563
Policy mu Mean               0.054722123
Policy mu Std                0.40228778
Policy mu Max                1.398426
Policy mu Min                -1.6161559
Policy log std Mean          -0.8431397
Policy log std Std           0.20103967
Policy log std Max           -0.37354243
Policy log std Min           -2.0306869
Z mean eval                  0.9230987
Z variance eval              0.013344906
total_rewards                [722.00896591 230.40528687 816.08303139 252.74941653 316.01738383
 805.39935516  94.84356484 442.24021438 142.98549756 629.18158005]
total_rewards_mean           445.19142965120454
total_rewards_std            263.00653314328883
total_rewards_max            816.0830313874669
total_rewards_min            94.84356484053313
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               33.80412239488214
(Previous) Eval Time (s)     27.70843052584678
Sample Time (s)              27.595683760475367
Epoch Time (s)               89.10823668120429
Total Train Time (s)         7174.577434264589
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:45:55.196323 UTC | [2020_01_10_11_46_20] Iteration #81 | Epoch Duration: 97.5785276889801
2020-01-10 13:45:55.196557 UTC | [2020_01_10_11_46_20] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92308396
Z variance train             0.013370427
KL Divergence                17.875248
KL Loss                      1.7875248
QF Loss                      232.39983
VF Loss                      48.56245
Policy Loss                  -466.33755
Q Predictions Mean           462.36145
Q Predictions Std            76.17401
Q Predictions Max            625.44055
Q Predictions Min            -87.299774
V Predictions Mean           463.36908
V Predictions Std            69.72766
V Predictions Max            613.6304
V Predictions Min            15.615763
Log Pis Mean                 -2.115293
Log Pis Std                  2.132394
Log Pis Max                  8.127383
Log Pis Min                  -7.1784534
Policy mu Mean               0.045507528
Policy mu Std                0.43033436
Policy mu Max                2.878039
Policy mu Min                -1.5400188
Policy log std Mean          -0.8238719
Policy log std Std           0.20302807
Policy log std Max           -0.18841457
Policy log std Min           -1.9114971
Z mean eval                  0.93262875
Z variance eval              0.013555979
total_rewards                [ 290.69041798  761.77238296  698.72030501  945.2883601   334.17349276
  566.2647892  1062.45684268  525.8079255   771.60757719  167.48224726]
total_rewards_mean           612.4264340631477
total_rewards_std            275.12936369410244
total_rewards_max            1062.4568426838503
total_rewards_min            167.48224725830687
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               34.86087840003893
(Previous) Eval Time (s)     36.17829548800364
Sample Time (s)              26.62837592512369
Epoch Time (s)               97.66754981316626
Total Train Time (s)         7263.223305089399
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:47:23.843921 UTC | [2020_01_10_11_46_20] Iteration #82 | Epoch Duration: 88.64721918106079
2020-01-10 13:47:23.844111 UTC | [2020_01_10_11_46_20] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9321602
Z variance train             0.013493384
KL Divergence                17.96548
KL Loss                      1.7965481
QF Loss                      437.14133
VF Loss                      125.170296
Policy Loss                  -467.1094
Q Predictions Mean           465.93878
Q Predictions Std            75.23894
Q Predictions Max            575.2364
Q Predictions Min            70.55603
V Predictions Mean           470.90875
V Predictions Std            73.647095
V Predictions Max            578.8706
V Predictions Min            122.71235
Log Pis Mean                 -1.9063989
Log Pis Std                  2.305519
Log Pis Max                  7.993125
Log Pis Min                  -11.34977
Policy mu Mean               0.019670818
Policy mu Std                0.42025116
Policy mu Max                1.7416173
Policy mu Min                -1.3598669
Policy log std Mean          -0.8558561
Policy log std Std           0.21019562
Policy log std Max           -0.24708077
Policy log std Min           -1.9669588
Z mean eval                  0.9579663
Z variance eval              0.015117037
total_rewards                [ 931.03275825  714.89188425 1203.96371672  234.09436746 1309.59542799
  613.50923796  192.87106237  939.55091408  299.10609047 1022.75955039]
total_rewards_mean           746.1375009934601
total_rewards_std            382.34800790177826
total_rewards_max            1309.59542799121
total_rewards_min            192.87106236597666
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               36.11335641564801
(Previous) Eval Time (s)     27.157530082855374
Sample Time (s)              26.242666626814753
Epoch Time (s)               89.51355312531814
Total Train Time (s)         7359.201274657622
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:48:59.824408 UTC | [2020_01_10_11_46_20] Iteration #83 | Epoch Duration: 95.98015093803406
2020-01-10 13:48:59.824686 UTC | [2020_01_10_11_46_20] Iteration #83 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95798576
Z variance train             0.015136276
KL Divergence                17.977575
KL Loss                      1.7977575
QF Loss                      249.78456
VF Loss                      178.71689
Policy Loss                  -482.23157
Q Predictions Mean           478.7995
Q Predictions Std            72.14192
Q Predictions Max            608.55054
Q Predictions Min            45.048485
V Predictions Mean           486.79883
V Predictions Std            71.13368
V Predictions Max            603.7131
V Predictions Min            52.60851
Log Pis Mean                 -1.7290686
Log Pis Std                  2.1963813
Log Pis Max                  12.979124
Log Pis Min                  -9.574727
Policy mu Mean               0.03528287
Policy mu Std                0.42727026
Policy mu Max                1.7420036
Policy mu Min                -1.6785039
Policy log std Mean          -0.869403
Policy log std Std           0.18930738
Policy log std Max           -0.3049127
Policy log std Min           -2.259686
Z mean eval                  0.9406436
Z variance eval              0.024926413
total_rewards                [659.27131106 120.16727011 572.9135514  269.1115601   57.27665346
 430.29254521  47.68336295 560.10411555 218.92711154 747.08508584]
total_rewards_mean           368.2832567217239
total_rewards_std            245.7421514990927
total_rewards_max            747.0850858395545
total_rewards_min            47.68336294808154
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               34.00025940919295
(Previous) Eval Time (s)     33.623671928886324
Sample Time (s)              26.3343063169159
Epoch Time (s)               93.95823765499517
Total Train Time (s)         7449.579001873732
Epoch                        84
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:50:30.203129 UTC | [2020_01_10_11_46_20] Iteration #84 | Epoch Duration: 90.37827038764954
2020-01-10 13:50:30.203325 UTC | [2020_01_10_11_46_20] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94120276
Z variance train             0.024979243
KL Divergence                17.81607
KL Loss                      1.781607
QF Loss                      246.52483
VF Loss                      74.72741
Policy Loss                  -467.82642
Q Predictions Mean           465.31546
Q Predictions Std            84.03421
Q Predictions Max            611.241
Q Predictions Min            -9.1232605
V Predictions Mean           469.87756
V Predictions Std            80.85338
V Predictions Max            610.4547
V Predictions Min            11.406357
Log Pis Mean                 -1.9109575
Log Pis Std                  2.0727506
Log Pis Max                  10.338043
Log Pis Min                  -6.9941053
Policy mu Mean               0.011853021
Policy mu Std                0.42422724
Policy mu Max                2.5432045
Policy mu Min                -1.8449159
Policy log std Mean          -0.85997367
Policy log std Std           0.2046247
Policy log std Max           -0.3535465
Policy log std Min           -1.8736793
Z mean eval                  0.9515767
Z variance eval              0.016870074
total_rewards                [ 753.72099564  240.47926759   67.89306579  195.82175663  552.31009327
 1451.72163805  359.3209687  1453.4105506   532.0094538   379.6618919 ]
total_rewards_mean           598.6349681955403
total_rewards_std            465.4542025198048
total_rewards_max            1453.4105506005203
total_rewards_min            67.89306578625792
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               35.27018839819357
(Previous) Eval Time (s)     30.04327835282311
Sample Time (s)              27.774162861984223
Epoch Time (s)               93.0876296130009
Total Train Time (s)         7543.731736083049
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:52:04.359522 UTC | [2020_01_10_11_46_20] Iteration #85 | Epoch Duration: 94.156081199646
2020-01-10 13:52:04.359692 UTC | [2020_01_10_11_46_20] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9562849
Z variance train             0.016849536
KL Divergence                18.09946
KL Loss                      1.8099461
QF Loss                      225.93558
VF Loss                      120.73357
Policy Loss                  -489.17767
Q Predictions Mean           483.94855
Q Predictions Std            68.00067
Q Predictions Max            602.5507
Q Predictions Min            311.7087
V Predictions Mean           480.12305
V Predictions Std            66.60958
V Predictions Max            600.4354
V Predictions Min            307.1761
Log Pis Mean                 -1.8682401
Log Pis Std                  1.9663513
Log Pis Max                  4.7398252
Log Pis Min                  -7.9311895
Policy mu Mean               0.045061775
Policy mu Std                0.42276078
Policy mu Max                1.2988569
Policy mu Min                -1.3338033
Policy log std Mean          -0.85127985
Policy log std Std           0.18615232
Policy log std Max           -0.32454064
Policy log std Min           -1.7079339
Z mean eval                  0.95695907
Z variance eval              0.011453615
total_rewards                [ 203.59350145  477.11049962  398.8806599   802.3030892   714.83401541
 1331.6876175   461.70708771 1111.84417863   91.10850379  997.35107291]
total_rewards_mean           659.0420226122654
total_rewards_std            382.7894080896512
total_rewards_max            1331.6876174997694
total_rewards_min            91.10850378968173
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               32.56411164999008
(Previous) Eval Time (s)     31.11130800889805
Sample Time (s)              25.349156108219177
Epoch Time (s)               89.02457576710731
Total Train Time (s)         7629.845308529679
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:53:30.474222 UTC | [2020_01_10_11_46_20] Iteration #86 | Epoch Duration: 86.11437392234802
2020-01-10 13:53:30.474515 UTC | [2020_01_10_11_46_20] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9593288
Z variance train             0.011458128
KL Divergence                18.472904
KL Loss                      1.8472904
QF Loss                      258.27588
VF Loss                      47.481743
Policy Loss                  -492.37878
Q Predictions Mean           489.73077
Q Predictions Std            74.35657
Q Predictions Max            615.8417
Q Predictions Min            57.572914
V Predictions Mean           496.05734
V Predictions Std            70.77543
V Predictions Max            618.3643
V Predictions Min            205.2616
Log Pis Mean                 -2.1328273
Log Pis Std                  1.9943545
Log Pis Max                  7.2312226
Log Pis Min                  -9.520467
Policy mu Mean               0.041715838
Policy mu Std                0.40312037
Policy mu Max                1.7252711
Policy mu Min                -1.2770445
Policy log std Mean          -0.8728266
Policy log std Std           0.21200694
Policy log std Max           -0.2753641
Policy log std Min           -2.090579
Z mean eval                  0.9725462
Z variance eval              0.017137526
total_rewards                [ 119.83928395  452.12982869  218.01720175  612.94654358  284.95405486
 1318.10103608  239.10909867 1012.80202294  508.03791314  262.41468821]
total_rewards_mean           502.83516718755425
total_rewards_std            366.34409932799326
total_rewards_max            1318.1010360780033
total_rewards_min            119.83928394630979
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               33.0525337299332
(Previous) Eval Time (s)     28.2007405878976
Sample Time (s)              25.058317862451077
Epoch Time (s)               86.31159218028188
Total Train Time (s)         7720.681963744573
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:55:01.310396 UTC | [2020_01_10_11_46_20] Iteration #87 | Epoch Duration: 90.83570075035095
2020-01-10 13:55:01.310542 UTC | [2020_01_10_11_46_20] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744574
Z variance train             0.017098067
KL Divergence                16.997421
KL Loss                      1.6997422
QF Loss                      265.19867
VF Loss                      52.616528
Policy Loss                  -481.75897
Q Predictions Mean           477.8923
Q Predictions Std            81.5195
Q Predictions Max            604.90173
Q Predictions Min            60.683273
V Predictions Mean           486.21564
V Predictions Std            82.91834
V Predictions Max            619.0132
V Predictions Min            20.891356
Log Pis Mean                 -1.5532944
Log Pis Std                  2.23284
Log Pis Max                  8.276395
Log Pis Min                  -9.703636
Policy mu Mean               0.019151729
Policy mu Std                0.44280586
Policy mu Max                2.1646018
Policy mu Min                -1.5929897
Policy log std Mean          -0.8767242
Policy log std Std           0.21106273
Policy log std Max           -0.321188
Policy log std Min           -2.0925064
Z mean eval                  0.9344021
Z variance eval              0.019084994
total_rewards                [1458.66104226 1307.66159013  242.42134489  751.36881017 1384.61993962
  263.67737529  569.53441675  601.16786036  850.53158683  246.11226493]
total_rewards_mean           767.5756231238636
total_rewards_std            450.0795825744146
total_rewards_max            1458.661042262621
total_rewards_min            242.42134489482441
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               33.209682315122336
(Previous) Eval Time (s)     32.72450927225873
Sample Time (s)              23.31620624801144
Epoch Time (s)               89.2503978353925
Total Train Time (s)         7812.1603841041215
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:56:32.792337 UTC | [2020_01_10_11_46_20] Iteration #88 | Epoch Duration: 91.48168635368347
2020-01-10 13:56:32.792542 UTC | [2020_01_10_11_46_20] Iteration #88 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9334782
Z variance train             0.01904036
KL Divergence                16.336367
KL Loss                      1.6336367
QF Loss                      201.49652
VF Loss                      78.47218
Policy Loss                  -469.8234
Q Predictions Mean           469.13568
Q Predictions Std            80.43425
Q Predictions Max            603.10236
Q Predictions Min            46.742332
V Predictions Mean           474.27286
V Predictions Std            78.71016
V Predictions Max            602.6934
V Predictions Min            104.2348
Log Pis Mean                 -1.9430474
Log Pis Std                  2.0784705
Log Pis Max                  5.915074
Log Pis Min                  -11.499357
Policy mu Mean               -0.0041657826
Policy mu Std                0.41249332
Policy mu Max                1.9856122
Policy mu Min                -1.4278992
Policy log std Mean          -0.8534547
Policy log std Std           0.22832166
Policy log std Max           -0.19919813
Policy log std Min           -2.1587956
Z mean eval                  0.95814216
Z variance eval              0.022144001
total_rewards                [ 122.9604334   248.75186025  401.8211465   746.10291819 1384.6331207
  228.22672519  221.10979815 1247.31400743  795.96991916  544.01476901]
total_rewards_mean           594.090469797029
total_rewards_std            420.6173992516925
total_rewards_max            1384.6331207001795
total_rewards_min            122.96043339725588
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               32.75950595503673
(Previous) Eval Time (s)     34.95549349626526
Sample Time (s)              26.868983002379537
Epoch Time (s)               94.58398245368153
Total Train Time (s)         7901.9698259239085
Epoch                        89
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:58:02.602857 UTC | [2020_01_10_11_46_20] Iteration #89 | Epoch Duration: 89.8101716041565
2020-01-10 13:58:02.603027 UTC | [2020_01_10_11_46_20] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9569212
Z variance train             0.022157218
KL Divergence                16.618858
KL Loss                      1.6618859
QF Loss                      283.2461
VF Loss                      63.932552
Policy Loss                  -486.77988
Q Predictions Mean           484.33972
Q Predictions Std            76.9431
Q Predictions Max            615.5252
Q Predictions Min            310.39117
V Predictions Mean           491.58606
V Predictions Std            76.414314
V Predictions Max            626.8919
V Predictions Min            316.96585
Log Pis Mean                 -1.9483542
Log Pis Std                  1.9815571
Log Pis Max                  5.895405
Log Pis Min                  -7.3987017
Policy mu Mean               0.044966925
Policy mu Std                0.42141053
Policy mu Max                1.4555222
Policy mu Min                -1.5433792
Policy log std Mean          -0.8560752
Policy log std Std           0.22762875
Policy log std Max           -0.28712383
Policy log std Min           -1.9387586
Z mean eval                  0.93718654
Z variance eval              0.018233087
total_rewards                [ 368.72712521  473.7126679   480.21257345 1412.3816639   518.54884505
 1545.11751131  448.58493026  622.95379446   55.11382216 1614.98760968]
total_rewards_mean           754.0340543382339
total_rewards_std            525.0637413458873
total_rewards_max            1614.9876096782496
total_rewards_min            55.11382216446705
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               32.81468694889918
(Previous) Eval Time (s)     30.181210345122963
Sample Time (s)              25.385809677187353
Epoch Time (s)               88.3817069712095
Total Train Time (s)         7987.378067868762
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:59:28.012838 UTC | [2020_01_10_11_46_20] Iteration #90 | Epoch Duration: 85.40968537330627
2020-01-10 13:59:28.013007 UTC | [2020_01_10_11_46_20] Iteration #90 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9378899
Z variance train             0.01826969
KL Divergence                17.025366
KL Loss                      1.7025366
QF Loss                      348.74655
VF Loss                      27.967793
Policy Loss                  -486.66003
Q Predictions Mean           483.76447
Q Predictions Std            82.70628
Q Predictions Max            625.583
Q Predictions Min            5.8220773
V Predictions Mean           485.65012
V Predictions Std            81.722916
V Predictions Max            616.64044
V Predictions Min            4.7559133
Log Pis Mean                 -1.92346
Log Pis Std                  1.9278183
Log Pis Max                  3.4078503
Log Pis Min                  -9.539125
Policy mu Mean               0.0032816343
Policy mu Std                0.4186636
Policy mu Max                1.2589234
Policy mu Min                -1.3960289
Policy log std Mean          -0.8420427
Policy log std Std           0.20132002
Policy log std Max           -0.18375438
Policy log std Min           -1.3596077
Z mean eval                  0.9543489
Z variance eval              0.021009773
total_rewards                [ 480.96599056  313.2254806  1322.41859083  880.54448398  998.553365
  155.12657272  346.71079318 1052.03029922  917.52845426  192.74693857]
total_rewards_mean           665.9850968913954
total_rewards_std            393.113922188234
total_rewards_max            1322.4185908258507
total_rewards_min            155.1265727221673
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.41891431994736
(Previous) Eval Time (s)     27.20876476028934
Sample Time (s)              24.52272154483944
Epoch Time (s)               84.15040062507614
Total Train Time (s)         8075.458744262345
Epoch                        91
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:00:56.096143 UTC | [2020_01_10_11_46_20] Iteration #91 | Epoch Duration: 88.08296203613281
2020-01-10 14:00:56.096526 UTC | [2020_01_10_11_46_20] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9525455
Z variance train             0.020944823
KL Divergence                16.867382
KL Loss                      1.6867383
QF Loss                      358.79855
VF Loss                      53.78704
Policy Loss                  -497.08655
Q Predictions Mean           496.2774
Q Predictions Std            87.46039
Q Predictions Max            646.6763
Q Predictions Min            49.901405
V Predictions Mean           494.1765
V Predictions Std            89.09782
V Predictions Max            651.2106
V Predictions Min            5.9276714
Log Pis Mean                 -2.039802
Log Pis Std                  2.1593103
Log Pis Max                  8.730057
Log Pis Min                  -11.393851
Policy mu Mean               -0.019551018
Policy mu Std                0.4365547
Policy mu Max                1.5328633
Policy mu Min                -2.0420916
Policy log std Mean          -0.8239844
Policy log std Std           0.21250872
Policy log std Max           -0.29092318
Policy log std Min           -2.0730038
Z mean eval                  0.9473591
Z variance eval              0.022749096
total_rewards                [ 827.63113637  512.24310016 1576.29577977 1360.74565898 1529.43817483
 1546.12630183 1507.55709485  183.33840476  541.93140174  334.74557239]
total_rewards_mean           992.0052625689344
total_rewards_std            537.0970391681889
total_rewards_max            1576.2957797713477
total_rewards_min            183.33840476234064
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               32.73487380100414
(Previous) Eval Time (s)     31.140924906823784
Sample Time (s)              25.87304392270744
Epoch Time (s)               89.74884263053536
Total Train Time (s)         8166.231374209747
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:02:26.870443 UTC | [2020_01_10_11_46_20] Iteration #92 | Epoch Duration: 90.77367568016052
2020-01-10 14:02:26.870642 UTC | [2020_01_10_11_46_20] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94602555
Z variance train             0.022779481
KL Divergence                17.020903
KL Loss                      1.7020903
QF Loss                      209.49551
VF Loss                      75.13934
Policy Loss                  -499.97998
Q Predictions Mean           495.70645
Q Predictions Std            87.97399
Q Predictions Max            636.94916
Q Predictions Min            -17.419067
V Predictions Mean           498.61984
V Predictions Std            84.50162
V Predictions Max            633.684
V Predictions Min            51.314407
Log Pis Mean                 -1.983486
Log Pis Std                  2.0495903
Log Pis Max                  8.246115
Log Pis Min                  -8.056786
Policy mu Mean               0.0064167604
Policy mu Std                0.42040247
Policy mu Max                1.280539
Policy mu Min                -1.4863545
Policy log std Mean          -0.8761801
Policy log std Std           0.20355563
Policy log std Max           -0.32787308
Policy log std Min           -2.225951
Z mean eval                  0.95847416
Z variance eval              0.022508983
total_rewards                [ 572.42710939 1513.74066314 1509.85417701  687.8239929   480.15657136
 1398.87362576 1745.99474263  414.11324297  747.78882371  182.40082641]
total_rewards_mean           925.3173775279759
total_rewards_std            530.0533878580609
total_rewards_max            1745.9947426320107
total_rewards_min            182.40082641365214
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               32.65238374378532
(Previous) Eval Time (s)     32.165395153686404
Sample Time (s)              25.47243703948334
Epoch Time (s)               90.29021593695506
Total Train Time (s)         8255.67102848133
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:03:56.312198 UTC | [2020_01_10_11_46_20] Iteration #93 | Epoch Duration: 89.44142746925354
2020-01-10 14:03:56.312373 UTC | [2020_01_10_11_46_20] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9583729
Z variance train             0.02251148
KL Divergence                17.72786
KL Loss                      1.772786
QF Loss                      223.98593
VF Loss                      32.14291
Policy Loss                  -519.5821
Q Predictions Mean           517.53577
Q Predictions Std            80.946304
Q Predictions Max            654.81116
Q Predictions Min            283.16418
V Predictions Mean           518.8424
V Predictions Std            79.91434
V Predictions Max            655.13837
V Predictions Min            295.56384
Log Pis Mean                 -1.7539072
Log Pis Std                  2.1333008
Log Pis Max                  8.904322
Log Pis Min                  -7.3416405
Policy mu Mean               0.030945957
Policy mu Std                0.4381821
Policy mu Max                1.6795259
Policy mu Min                -1.4678547
Policy log std Mean          -0.8737917
Policy log std Std           0.21409658
Policy log std Max           -0.2923524
Policy log std Min           -2.2249293
Z mean eval                  0.94714296
Z variance eval              0.015881147
total_rewards                [ 126.45157981  130.96721434   82.05570958  678.35256729  123.86678475
  533.36996987  960.45453022  631.59729201 1487.7217329   953.16476095]
total_rewards_mean           570.8002141717842
total_rewards_std            445.5291773149749
total_rewards_max            1487.7217329041823
total_rewards_min            82.05570958392552
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               32.04518684186041
(Previous) Eval Time (s)     31.316245106980205
Sample Time (s)              26.580141682177782
Epoch Time (s)               89.9415736310184
Total Train Time (s)         8342.461237810086
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:05:23.109573 UTC | [2020_01_10_11_46_20] Iteration #94 | Epoch Duration: 86.7970757484436
2020-01-10 14:05:23.109744 UTC | [2020_01_10_11_46_20] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94754475
Z variance train             0.01588962
KL Divergence                18.736176
KL Loss                      1.8736175
QF Loss                      251.0189
VF Loss                      43.16005
Policy Loss                  -506.63232
Q Predictions Mean           504.92697
Q Predictions Std            81.02077
Q Predictions Max            650.9242
Q Predictions Min            187.1105
V Predictions Mean           507.25812
V Predictions Std            79.81826
V Predictions Max            654.9971
V Predictions Min            259.81747
Log Pis Mean                 -1.8126388
Log Pis Std                  2.035872
Log Pis Max                  5.292164
Log Pis Min                  -9.640289
Policy mu Mean               0.01919182
Policy mu Std                0.4151508
Policy mu Max                1.399598
Policy mu Min                -1.4392204
Policy log std Mean          -0.8904146
Policy log std Std           0.2014567
Policy log std Max           -0.3456208
Policy log std Min           -1.8537278
Z mean eval                  0.969423
Z variance eval              0.013691557
total_rewards                [1067.76007789  342.93935087  123.96653018  331.84190557  204.70322638
 1717.00539802  508.49919534  350.29155111   92.97541173  282.59718987]
total_rewards_mean           502.25798369658025
total_rewards_std            481.7018850288908
total_rewards_max            1717.0053980189366
total_rewards_min            92.97541173079367
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               32.14021294284612
(Previous) Eval Time (s)     28.171380145009607
Sample Time (s)              25.046035326551646
Epoch Time (s)               85.35762841440737
Total Train Time (s)         8432.543423641007
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:06:53.192415 UTC | [2020_01_10_11_46_20] Iteration #95 | Epoch Duration: 90.0825583934784
2020-01-10 14:06:53.192537 UTC | [2020_01_10_11_46_20] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9627851
Z variance train             0.013697001
KL Divergence                18.786007
KL Loss                      1.8786007
QF Loss                      235.76816
VF Loss                      59.22367
Policy Loss                  -489.08777
Q Predictions Mean           485.1502
Q Predictions Std            94.60157
Q Predictions Max            632.6993
Q Predictions Min            18.575596
V Predictions Mean           488.89966
V Predictions Std            90.86453
V Predictions Max            632.9814
V Predictions Min            11.731257
Log Pis Mean                 -1.7212353
Log Pis Std                  2.3163784
Log Pis Max                  12.075483
Log Pis Min                  -8.344127
Policy mu Mean               0.007236627
Policy mu Std                0.44214788
Policy mu Max                1.5270909
Policy mu Min                -1.6551548
Policy log std Mean          -0.8561827
Policy log std Std           0.2162644
Policy log std Max           -0.31371397
Policy log std Min           -2.155421
Z mean eval                  0.96618545
Z variance eval              0.01711858
total_rewards                [ 580.3246232  1660.18403247 1248.2786561   202.12845852  648.25864174
 1630.92155    1475.68738002  319.73898584  512.34358917  648.61514984]
total_rewards_mean           892.6481066917756
total_rewards_std            526.0289897546626
total_rewards_max            1660.1840324684254
total_rewards_min            202.12845852418687
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               32.93043276993558
(Previous) Eval Time (s)     32.895955754909664
Sample Time (s)              24.881062424276024
Epoch Time (s)               90.70745094912127
Total Train Time (s)         8524.02508023195
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:08:24.676835 UTC | [2020_01_10_11_46_20] Iteration #96 | Epoch Duration: 91.48418641090393
2020-01-10 14:08:24.677057 UTC | [2020_01_10_11_46_20] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.965085
Z variance train             0.017127784
KL Divergence                19.029049
KL Loss                      1.9029049
QF Loss                      265.72284
VF Loss                      61.86715
Policy Loss                  -515.30164
Q Predictions Mean           512.77594
Q Predictions Std            98.94834
Q Predictions Max            673.89886
Q Predictions Min            -19.093964
V Predictions Mean           514.64844
V Predictions Std            93.9878
V Predictions Max            674.6995
V Predictions Min            85.284485
Log Pis Mean                 -1.8488126
Log Pis Std                  2.2979343
Log Pis Max                  7.056775
Log Pis Min                  -9.010961
Policy mu Mean               0.017049812
Policy mu Std                0.45550123
Policy mu Max                1.5388446
Policy mu Min                -1.4399923
Policy log std Mean          -0.8663945
Policy log std Std           0.2069514
Policy log std Max           -0.2357686
Policy log std Min           -1.4906716
Z mean eval                  0.9636623
Z variance eval              0.017005812
total_rewards                [ 288.13264257 1753.81115963 1202.58536887  647.84630547  571.60179818
 1521.0395091   991.75943259  569.6462646   483.76814449 1564.69974132]
total_rewards_mean           959.4890366808188
total_rewards_std            494.902882805598
total_rewards_max            1753.8111596276833
total_rewards_min            288.1326425697296
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               32.96439873473719
(Previous) Eval Time (s)     33.6722738458775
Sample Time (s)              25.674877488054335
Epoch Time (s)               92.31155006866902
Total Train Time (s)         8615.674199472181
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:09:56.328220 UTC | [2020_01_10_11_46_20] Iteration #97 | Epoch Duration: 91.65101456642151
2020-01-10 14:09:56.328462 UTC | [2020_01_10_11_46_20] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9637701
Z variance train             0.017023712
KL Divergence                19.414894
KL Loss                      1.9414895
QF Loss                      257.30908
VF Loss                      96.01134
Policy Loss                  -523.8955
Q Predictions Mean           521.8148
Q Predictions Std            81.90756
Q Predictions Max            663.08356
Q Predictions Min            313.46088
V Predictions Mean           529.6446
V Predictions Std            83.14293
V Predictions Max            678.32745
V Predictions Min            322.23004
Log Pis Mean                 -1.8558884
Log Pis Std                  1.9491527
Log Pis Max                  3.5825095
Log Pis Min                  -6.438545
Policy mu Mean               0.03662328
Policy mu Std                0.4489732
Policy mu Max                1.5185732
Policy mu Min                -1.4853193
Policy log std Mean          -0.84119225
Policy log std Std           0.20594168
Policy log std Max           -0.28720438
Policy log std Min           -1.8076894
Z mean eval                  0.9608444
Z variance eval              0.012831355
total_rewards                [ 706.56410017  388.75460226 1612.0934709    75.66091923  372.63298012
 1593.89675037 1122.81553521  972.73670055  742.34221459 1656.34102772]
total_rewards_mean           924.3838301136624
total_rewards_std            537.6717786364492
total_rewards_max            1656.3410277232088
total_rewards_min            75.66091923447017
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               32.50904992688447
(Previous) Eval Time (s)     33.011383175849915
Sample Time (s)              25.354953070171177
Epoch Time (s)               90.87538617290556
Total Train Time (s)         8704.904289387167
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:11:25.560291 UTC | [2020_01_10_11_46_20] Iteration #98 | Epoch Duration: 89.23167967796326
2020-01-10 14:11:25.560474 UTC | [2020_01_10_11_46_20] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9617697
Z variance train             0.012831176
KL Divergence                19.423777
KL Loss                      1.9423777
QF Loss                      316.6895
VF Loss                      415.25104
Policy Loss                  -519.3392
Q Predictions Mean           515.3906
Q Predictions Std            103.70952
Q Predictions Max            652.3098
Q Predictions Min            -47.231827
V Predictions Mean           523.32275
V Predictions Std            93.44173
V Predictions Max            653.22125
V Predictions Min            37.546288
Log Pis Mean                 -1.5871459
Log Pis Std                  2.1995158
Log Pis Max                  6.7205405
Log Pis Min                  -7.8798037
Policy mu Mean               0.02542777
Policy mu Std                0.45620915
Policy mu Max                2.3040423
Policy mu Min                -1.430478
Policy log std Mean          -0.8938093
Policy log std Std           0.22466597
Policy log std Max           -0.27886993
Policy log std Min           -2.1186285
Z mean eval                  0.96799135
Z variance eval              0.015047966
total_rewards                [1439.64752969  225.80834769  389.0304067   892.9790249   444.20530649
 1556.08400826 1073.81613602  449.45823616  668.17432698 1514.23187827]
total_rewards_mean           865.3435201157399
total_rewards_std            479.301705122983
total_rewards_max            1556.0840082626069
total_rewards_min            225.80834768674555
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               32.763053494971246
(Previous) Eval Time (s)     31.367346324026585
Sample Time (s)              26.17721997294575
Epoch Time (s)               90.30761979194358
Total Train Time (s)         8797.24843313219
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:12:57.905670 UTC | [2020_01_10_11_46_20] Iteration #99 | Epoch Duration: 92.3450665473938
2020-01-10 14:12:57.905844 UTC | [2020_01_10_11_46_20] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.969813
Z variance train             0.015057137
KL Divergence                18.63303
KL Loss                      1.8633031
QF Loss                      616.4042
VF Loss                      129.24484
Policy Loss                  -515.2372
Q Predictions Mean           512.117
Q Predictions Std            101.756226
Q Predictions Max            656.3643
Q Predictions Min            2.6974344
V Predictions Mean           519.7229
V Predictions Std            99.20997
V Predictions Max            676.70703
V Predictions Min            -9.010024
Log Pis Mean                 -1.6129242
Log Pis Std                  2.1018555
Log Pis Max                  8.659292
Log Pis Min                  -7.740821
Policy mu Mean               -0.020885259
Policy mu Std                0.44063762
Policy mu Max                1.9125422
Policy mu Min                -1.376321
Policy log std Mean          -0.8808781
Policy log std Std           0.22279106
Policy log std Max           -0.16627604
Policy log std Min           -2.220284
Z mean eval                  0.96137017
Z variance eval              0.016710227
total_rewards                [ 183.70282294 1706.05719648 1696.71606053  989.79890018  797.74191911
 1362.88815598 1050.21150909  510.25903851  354.3852847   553.61891088]
total_rewards_mean           920.5379798405709
total_rewards_std            511.69043750122404
total_rewards_max            1706.0571964813648
total_rewards_min            183.7028229448805
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               32.77008736692369
(Previous) Eval Time (s)     33.404376349877566
Sample Time (s)              25.998839278705418
Epoch Time (s)               92.17330299550667
Total Train Time (s)         8891.728078126907
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:14:32.387846 UTC | [2020_01_10_11_46_20] Iteration #100 | Epoch Duration: 94.48187041282654
2020-01-10 14:14:32.388044 UTC | [2020_01_10_11_46_20] Iteration #100 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9573778
Z variance train             0.016713973
KL Divergence                18.389563
KL Loss                      1.8389562
QF Loss                      242.57193
VF Loss                      33.577293
Policy Loss                  -520.57275
Q Predictions Mean           516.9885
Q Predictions Std            99.284706
Q Predictions Max            684.47504
Q Predictions Min            261.72574
V Predictions Mean           523.32935
V Predictions Std            98.22842
V Predictions Max            688.7088
V Predictions Min            265.4333
Log Pis Mean                 -1.8522466
Log Pis Std                  2.1321933
Log Pis Max                  6.056465
Log Pis Min                  -7.2862797
Policy mu Mean               0.01936964
Policy mu Std                0.45418954
Policy mu Max                1.7753794
Policy mu Min                -1.7525057
Policy log std Mean          -0.8447205
Policy log std Std           0.21957242
Policy log std Max           -0.22204989
Policy log std Min           -1.5735605
Z mean eval                  0.958755
Z variance eval              0.01537741
total_rewards                [485.9707834  407.925292   301.75262892 138.35727077 681.74113688
 469.28199899 598.05185911 557.56678622  89.26822542 184.20638194]
total_rewards_mean           391.41223636475087
total_rewards_std            193.9527696706209
total_rewards_max            681.7411368815334
total_rewards_min            89.26822542355607
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               32.69827075721696
(Previous) Eval Time (s)     35.71250216057524
Sample Time (s)              25.60128982551396
Epoch Time (s)               94.01206274330616
Total Train Time (s)         8981.888504169416
Epoch                        101
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:16:02.550266 UTC | [2020_01_10_11_46_20] Iteration #101 | Epoch Duration: 90.16207814216614
2020-01-10 14:16:02.550496 UTC | [2020_01_10_11_46_20] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9593962
Z variance train             0.015389679
KL Divergence                19.125496
KL Loss                      1.9125496
QF Loss                      204.92012
VF Loss                      55.627865
Policy Loss                  -521.1868
Q Predictions Mean           516.795
Q Predictions Std            99.1601
Q Predictions Max            656.4299
Q Predictions Min            23.7478
V Predictions Mean           518.4042
V Predictions Std            98.75955
V Predictions Max            657.50037
V Predictions Min            21.39007
Log Pis Mean                 -1.7144759
Log Pis Std                  2.284601
Log Pis Max                  3.7746453
Log Pis Min                  -7.7081566
Policy mu Mean               0.04363256
Policy mu Std                0.46883017
Policy mu Max                1.7698442
Policy mu Min                -1.6467557
Policy log std Mean          -0.8539919
Policy log std Std           0.21929988
Policy log std Max           -0.22617838
Policy log std Min           -1.8459909
Z mean eval                  0.9491474
Z variance eval              0.01203447
total_rewards                [ 549.7793291   178.5199371   242.50244189 1712.64544795  327.9766118
   36.22480181  624.48127559  740.61916206  363.9607114   443.49060292]
total_rewards_mean           522.0200321605886
total_rewards_std            444.69823687631185
total_rewards_max            1712.64544794565
total_rewards_min            36.22480181179606
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               32.543238893616945
(Previous) Eval Time (s)     31.862157316878438
Sample Time (s)              26.045958967413753
Epoch Time (s)               90.45135517790914
Total Train Time (s)         9075.446120827924
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:17:36.109548 UTC | [2020_01_10_11_46_20] Iteration #102 | Epoch Duration: 93.55889701843262
2020-01-10 14:17:36.109755 UTC | [2020_01_10_11_46_20] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9514941
Z variance train             0.012065455
KL Divergence                19.438408
KL Loss                      1.9438409
QF Loss                      229.55038
VF Loss                      93.42676
Policy Loss                  -537.5923
Q Predictions Mean           534.14496
Q Predictions Std            114.095116
Q Predictions Max            691.2602
Q Predictions Min            -1.5988287
V Predictions Mean           532.5946
V Predictions Std            109.17593
V Predictions Max            690.97046
V Predictions Min            3.7355647
Log Pis Mean                 -1.8773314
Log Pis Std                  2.2810028
Log Pis Max                  10.42045
Log Pis Min                  -8.249665
Policy mu Mean               0.0039936095
Policy mu Std                0.42607006
Policy mu Max                1.6329904
Policy mu Min                -1.9152372
Policy log std Mean          -0.87532705
Policy log std Std           0.2323816
Policy log std Max           -0.285478
Policy log std Min           -2.347207
Z mean eval                  0.98622274
Z variance eval              0.011796353
total_rewards                [-124.40307505  250.83131748 1026.93835308  744.47549502  470.15388153
  584.58012023  311.19777782 1806.61160702  436.59390775  520.21549388]
total_rewards_mean           602.7194878761198
total_rewards_std            493.8863587041692
total_rewards_max            1806.6116070207845
total_rewards_min            -124.40307504716007
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               33.00016883574426
(Previous) Eval Time (s)     34.969260967336595
Sample Time (s)              25.0850804108195
Epoch Time (s)               93.05451021390036
Total Train Time (s)         9159.512079850305
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:19:00.177512 UTC | [2020_01_10_11_46_20] Iteration #103 | Epoch Duration: 84.067617893219
2020-01-10 14:19:00.177699 UTC | [2020_01_10_11_46_20] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9857831
Z variance train             0.011738891
KL Divergence                18.946823
KL Loss                      1.8946823
QF Loss                      279.14392
VF Loss                      67.181175
Policy Loss                  -545.77386
Q Predictions Mean           542.8499
Q Predictions Std            95.29836
Q Predictions Max            668.04724
Q Predictions Min            -11.713826
V Predictions Mean           547.0286
V Predictions Std            93.798256
V Predictions Max            670.51575
V Predictions Min            -4.0563207
Log Pis Mean                 -1.3325951
Log Pis Std                  2.1179142
Log Pis Max                  4.8398666
Log Pis Min                  -9.121684
Policy mu Mean               0.006214317
Policy mu Std                0.47534993
Policy mu Max                1.695449
Policy mu Min                -1.7146574
Policy log std Mean          -0.8712103
Policy log std Std           0.22508445
Policy log std Max           -0.1766069
Policy log std Min           -1.590875
Z mean eval                  0.9783719
Z variance eval              0.01214689
total_rewards                [ 144.220371    398.42043346 1669.69218075 1590.13001883 1230.88603244
 1072.44545529 1036.98410047 1719.65911594  582.72854808  380.30276163]
total_rewards_mean           982.5469017880603
total_rewards_std            549.9023186563059
total_rewards_max            1719.6591159363434
total_rewards_min            144.22037099564773
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               32.663054917007685
(Previous) Eval Time (s)     25.982002324890345
Sample Time (s)              25.095533679239452
Epoch Time (s)               83.74059092113748
Total Train Time (s)         9253.042636392172
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:20:33.710001 UTC | [2020_01_10_11_46_20] Iteration #104 | Epoch Duration: 93.53216123580933
2020-01-10 14:20:33.710197 UTC | [2020_01_10_11_46_20] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9838762
Z variance train             0.012090999
KL Divergence                19.719715
KL Loss                      1.9719715
QF Loss                      1676.0767
VF Loss                      90.07442
Policy Loss                  -524.6382
Q Predictions Mean           520.0563
Q Predictions Std            103.02192
Q Predictions Max            686.8213
Q Predictions Min            267.59082
V Predictions Mean           517.82776
V Predictions Std            100.56782
V Predictions Max            677.7641
V Predictions Min            270.36578
Log Pis Mean                 -1.7774632
Log Pis Std                  2.0180092
Log Pis Max                  4.071371
Log Pis Min                  -8.778206
Policy mu Mean               -0.021594755
Policy mu Std                0.4603852
Policy mu Max                1.3368938
Policy mu Min                -1.7454507
Policy log std Mean          -0.86165446
Policy log std Std           0.20444201
Policy log std Max           -0.28053468
Policy log std Min           -1.4202907
Z mean eval                  0.9588628
Z variance eval              0.013586399
total_rewards                [ 465.75218474 1630.79972349 1759.02825192 1528.5486061   303.82508269
  224.78068473  140.84447401 1188.21192055  715.62070878  552.52630118]
total_rewards_mean           850.9937938194687
total_rewards_std            587.9701336131221
total_rewards_max            1759.0282519161985
total_rewards_min            140.84447401305073
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               32.346444295253605
(Previous) Eval Time (s)     35.77322207111865
Sample Time (s)              26.507159100845456
Epoch Time (s)               94.62682546721771
Total Train Time (s)         9346.36273564957
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:22:07.032936 UTC | [2020_01_10_11_46_20] Iteration #105 | Epoch Duration: 93.32258224487305
2020-01-10 14:22:07.033147 UTC | [2020_01_10_11_46_20] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95788926
Z variance train             0.013573093
KL Divergence                19.361237
KL Loss                      1.9361237
QF Loss                      287.2093
VF Loss                      29.832067
Policy Loss                  -543.50836
Q Predictions Mean           540.814
Q Predictions Std            101.39495
Q Predictions Max            676.60535
Q Predictions Min            21.357407
V Predictions Mean           543.46185
V Predictions Std            101.35448
V Predictions Max            677.6266
V Predictions Min            8.700986
Log Pis Mean                 -1.3134053
Log Pis Std                  2.1446912
Log Pis Max                  4.79213
Log Pis Min                  -7.75992
Policy mu Mean               0.03970564
Policy mu Std                0.4612479
Policy mu Max                1.3635277
Policy mu Min                -1.4094269
Policy log std Mean          -0.8945274
Policy log std Std           0.19820255
Policy log std Max           -0.29440197
Policy log std Min           -1.4262669
Z mean eval                  0.9578622
Z variance eval              0.011607878
total_rewards                [ 755.33992621 1655.45092721  457.83257746  374.72420181 1060.84736881
   53.65923875  897.96802664  163.40179301  379.4498552    10.6353586 ]
total_rewards_mean           580.9309273695227
total_rewards_std            489.0497039460322
total_rewards_max            1655.4509272127584
total_rewards_min            10.635358600002881
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               32.86329381912947
(Previous) Eval Time (s)     34.46857039537281
Sample Time (s)              26.25226254714653
Epoch Time (s)               93.5841267616488
Total Train Time (s)         9436.761520227883
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:23:37.433603 UTC | [2020_01_10_11_46_20] Iteration #106 | Epoch Duration: 90.40030097961426
2020-01-10 14:23:37.433789 UTC | [2020_01_10_11_46_20] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95750654
Z variance train             0.011583676
KL Divergence                18.872782
KL Loss                      1.8872782
QF Loss                      553.6127
VF Loss                      94.97321
Policy Loss                  -561.77734
Q Predictions Mean           559.2738
Q Predictions Std            93.69661
Q Predictions Max            717.902
Q Predictions Min            286.36536
V Predictions Mean           563.3036
V Predictions Std            92.03772
V Predictions Max            717.49054
V Predictions Min            294.42902
Log Pis Mean                 -1.3306918
Log Pis Std                  2.1346302
Log Pis Max                  9.249084
Log Pis Min                  -10.789107
Policy mu Mean               -0.015448617
Policy mu Std                0.47840792
Policy mu Max                2.8854063
Policy mu Min                -1.6314329
Policy log std Mean          -0.8849668
Policy log std Std           0.21755777
Policy log std Max           -0.2623624
Policy log std Min           -2.0603313
Z mean eval                  0.97401124
Z variance eval              0.009377735
total_rewards                [1635.7820816    38.49916355 1247.45725687    7.71939789  421.11540756
  494.77994758  499.84949981  234.27934511  662.3067902   387.89311687]
total_rewards_mean           562.9682007032844
total_rewards_std            487.8663261939155
total_rewards_max            1635.782081597897
total_rewards_min            7.719397892297774
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               33.282567931804806
(Previous) Eval Time (s)     31.28439590567723
Sample Time (s)              26.638764636125416
Epoch Time (s)               91.20572847360745
Total Train Time (s)         9527.89810609864
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:25:08.572014 UTC | [2020_01_10_11_46_20] Iteration #107 | Epoch Duration: 91.13810515403748
2020-01-10 14:25:08.572194 UTC | [2020_01_10_11_46_20] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97237617
Z variance train             0.009369928
KL Divergence                18.16283
KL Loss                      1.8162831
QF Loss                      409.53726
VF Loss                      73.103294
Policy Loss                  -553.91785
Q Predictions Mean           550.0932
Q Predictions Std            109.519905
Q Predictions Max            697.1722
Q Predictions Min            10.892209
V Predictions Mean           556.5863
V Predictions Std            107.63056
V Predictions Max            693.9152
V Predictions Min            11.411316
Log Pis Mean                 -1.753334
Log Pis Std                  2.111067
Log Pis Max                  3.9541645
Log Pis Min                  -9.607637
Policy mu Mean               0.017439745
Policy mu Std                0.44278577
Policy mu Max                1.6209271
Policy mu Min                -1.6832017
Policy log std Mean          -0.8744966
Policy log std Std           0.22675578
Policy log std Max           -0.24955603
Policy log std Min           -1.9936215
Z mean eval                  0.9571929
Z variance eval              0.009494848
total_rewards                [ 255.26526351 1347.27874857  778.39833396 1710.47083058 1064.44498015
  304.44644184  789.1746541   488.92912485  128.591273     11.1720639 ]
total_rewards_mean           687.8171714463017
total_rewards_std            527.7546591294838
total_rewards_max            1710.4708305828026
total_rewards_min            11.172063898743957
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               32.60807997500524
(Previous) Eval Time (s)     31.216409613844007
Sample Time (s)              25.054935329593718
Epoch Time (s)               88.87942491844296
Total Train Time (s)         9615.34892710764
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:26:36.024657 UTC | [2020_01_10_11_46_20] Iteration #108 | Epoch Duration: 87.4523377418518
2020-01-10 14:26:36.024835 UTC | [2020_01_10_11_46_20] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9548179
Z variance train             0.009478586
KL Divergence                18.282139
KL Loss                      1.8282139
QF Loss                      280.41602
VF Loss                      59.721767
Policy Loss                  -545.936
Q Predictions Mean           541.4724
Q Predictions Std            117.49663
Q Predictions Max            713.9986
Q Predictions Min            -80.16178
V Predictions Mean           545.5602
V Predictions Std            113.525894
V Predictions Max            720.6811
V Predictions Min            -11.937159
Log Pis Mean                 -1.3301026
Log Pis Std                  2.2565289
Log Pis Max                  6.6508307
Log Pis Min                  -8.463704
Policy mu Mean               -0.04498306
Policy mu Std                0.47759503
Policy mu Max                2.0338652
Policy mu Min                -1.6451818
Policy log std Mean          -0.8797507
Policy log std Std           0.22396712
Policy log std Max           -0.2566333
Policy log std Min           -1.8587267
Z mean eval                  0.95112455
Z variance eval              0.011288421
total_rewards                [ 163.71921444 1338.81076481 -172.97906756  324.40913564  287.57958002
  103.4880945  1743.92081653  847.67740503  307.47218455  673.587077  ]
total_rewards_mean           561.7685204964447
total_rewards_std            565.6880656780921
total_rewards_max            1743.9208165333248
total_rewards_min            -172.97906756333978
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               32.95536049408838
(Previous) Eval Time (s)     29.788955261930823
Sample Time (s)              25.37114873016253
Epoch Time (s)               88.11546448618174
Total Train Time (s)         9705.442400802858
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:28:06.120218 UTC | [2020_01_10_11_46_20] Iteration #109 | Epoch Duration: 90.09525299072266
2020-01-10 14:28:06.120414 UTC | [2020_01_10_11_46_20] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9522003
Z variance train             0.011276139
KL Divergence                18.661066
KL Loss                      1.8661066
QF Loss                      316.5478
VF Loss                      121.774345
Policy Loss                  -557.0618
Q Predictions Mean           557.6669
Q Predictions Std            109.31748
Q Predictions Max            696.3859
Q Predictions Min            12.10056
V Predictions Mean           565.1746
V Predictions Std            109.89839
V Predictions Max            716.1025
V Predictions Min            0.515524
Log Pis Mean                 -1.6952451
Log Pis Std                  2.2701
Log Pis Max                  5.5023823
Log Pis Min                  -8.577852
Policy mu Mean               0.010386452
Policy mu Std                0.46986663
Policy mu Max                1.903935
Policy mu Min                -1.4878318
Policy log std Mean          -0.8703499
Policy log std Std           0.22446918
Policy log std Max           -0.16453353
Policy log std Min           -1.9121553
Z mean eval                  0.9613267
Z variance eval              0.011429817
total_rewards                [ 146.96402798  188.05380396  459.39007749   88.53939654 1070.69934114
  370.51553897  128.93007416 1788.10115954 1820.21029349 1928.46531273]
total_rewards_mean           798.9869026008388
total_rewards_std            736.3281850455954
total_rewards_max            1928.4653127288661
total_rewards_min            88.53939653877208
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               33.10782252904028
(Previous) Eval Time (s)     31.768350057769567
Sample Time (s)              25.327670958358794
Epoch Time (s)               90.20384354516864
Total Train Time (s)         9791.123237395193
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:29:31.803684 UTC | [2020_01_10_11_46_20] Iteration #110 | Epoch Duration: 85.68311977386475
2020-01-10 14:29:31.803949 UTC | [2020_01_10_11_46_20] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9612317
Z variance train             0.011394074
KL Divergence                18.246746
KL Loss                      1.8246746
QF Loss                      477.76962
VF Loss                      92.83864
Policy Loss                  -552.4808
Q Predictions Mean           547.1133
Q Predictions Std            118.0293
Q Predictions Max            769.7293
Q Predictions Min            -49.382446
V Predictions Mean           545.71277
V Predictions Std            114.33109
V Predictions Max            754.2108
V Predictions Min            12.168749
Log Pis Mean                 -1.628893
Log Pis Std                  2.1912372
Log Pis Max                  8.211992
Log Pis Min                  -7.924393
Policy mu Mean               0.007049155
Policy mu Std                0.48586774
Policy mu Max                2.7865887
Policy mu Min                -2.2220073
Policy log std Mean          -0.8614694
Policy log std Std           0.22714509
Policy log std Max           -0.16877651
Policy log std Min           -2.09378
Z mean eval                  0.96073467
Z variance eval              0.009354359
total_rewards                [  41.96916429  968.16754306 1727.76954177 1761.52678066  639.02176334
 1379.32603766 1738.46632039  611.39165853 1728.30023782 1663.30513686]
total_rewards_mean           1225.924418435448
total_rewards_std            588.1264254560259
total_rewards_max            1761.5267806570666
total_rewards_min            41.96916428769606
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               32.32795960223302
(Previous) Eval Time (s)     27.247257688082755
Sample Time (s)              26.133959490340203
Epoch Time (s)               85.70917678065598
Total Train Time (s)         9883.295743800234
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:31:03.977797 UTC | [2020_01_10_11_46_20] Iteration #111 | Epoch Duration: 92.17370080947876
2020-01-10 14:31:03.977983 UTC | [2020_01_10_11_46_20] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9630879
Z variance train             0.009340659
KL Divergence                19.07313
KL Loss                      1.907313
QF Loss                      329.6371
VF Loss                      33.9433
Policy Loss                  -565.46173
Q Predictions Mean           562.00104
Q Predictions Std            97.87237
Q Predictions Max            743.2885
Q Predictions Min            294.2074
V Predictions Mean           565.6628
V Predictions Std            97.94672
V Predictions Max            727.4178
V Predictions Min            281.80432
Log Pis Mean                 -1.5323908
Log Pis Std                  2.1675048
Log Pis Max                  4.2402983
Log Pis Min                  -7.7279253
Policy mu Mean               -0.0067839995
Policy mu Std                0.47513774
Policy mu Max                1.8592687
Policy mu Min                -1.4724473
Policy log std Mean          -0.8929373
Policy log std Std           0.20831656
Policy log std Max           -0.31190422
Policy log std Min           -1.8322403
Z mean eval                  0.9781162
Z variance eval              0.011785072
total_rewards                [ 391.00366719   72.85066822  589.08814349  802.54942317 1104.55027624
   96.81050299  483.52934636  350.38358361 1187.87489451  608.26219438]
total_rewards_mean           568.6902700165048
total_rewards_std            358.0806900350402
total_rewards_max            1187.8748945138402
total_rewards_min            72.8506682172219
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               32.52572629507631
(Previous) Eval Time (s)     33.71138081001118
Sample Time (s)              26.56138574751094
Epoch Time (s)               92.79849285259843
Total Train Time (s)         9976.245636041742
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:32:36.930272 UTC | [2020_01_10_11_46_20] Iteration #112 | Epoch Duration: 92.9521586894989
2020-01-10 14:32:36.930462 UTC | [2020_01_10_11_46_20] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97976893
Z variance train             0.011784964
KL Divergence                18.496815
KL Loss                      1.8496815
QF Loss                      350.95877
VF Loss                      60.306442
Policy Loss                  -563.9003
Q Predictions Mean           561.71045
Q Predictions Std            119.54759
Q Predictions Max            751.43805
Q Predictions Min            42.879128
V Predictions Mean           560.759
V Predictions Std            114.9618
V Predictions Max            744.5279
V Predictions Min            -0.39735144
Log Pis Mean                 -1.4691566
Log Pis Std                  2.238607
Log Pis Max                  11.62541
Log Pis Min                  -10.79472
Policy mu Mean               0.033452913
Policy mu Std                0.46219608
Policy mu Max                1.9000077
Policy mu Min                -1.5751904
Policy log std Mean          -0.8803008
Policy log std Std           0.23532994
Policy log std Max           -0.21964389
Policy log std Min           -2.4030108
Z mean eval                  0.95563346
Z variance eval              0.011051908
total_rewards                [ 269.12243481  729.02714664 1577.13846502 1350.33041574  284.53878068
  340.84832208  572.50581715  858.80459424  348.03432168 1498.12074355]
total_rewards_mean           782.8471041596733
total_rewards_std            491.33607027241516
total_rewards_max            1577.1384650152136
total_rewards_min            269.12243481405557
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               34.688518116250634
(Previous) Eval Time (s)     33.864719653036445
Sample Time (s)              26.300330309662968
Epoch Time (s)               94.85356807895005
Total Train Time (s)         10066.651489008684
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:34:07.337604 UTC | [2020_01_10_11_46_20] Iteration #113 | Epoch Duration: 90.40701484680176
2020-01-10 14:34:07.337783 UTC | [2020_01_10_11_46_20] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95406216
Z variance train             0.011041233
KL Divergence                19.241661
KL Loss                      1.9241661
QF Loss                      428.08548
VF Loss                      99.43483
Policy Loss                  -575.5983
Q Predictions Mean           573.457
Q Predictions Std            121.256
Q Predictions Max            740.1753
Q Predictions Min            20.347685
V Predictions Mean           576.98535
V Predictions Std            118.139465
V Predictions Max            735.78644
V Predictions Min            8.540428
Log Pis Mean                 -1.3371367
Log Pis Std                  2.4006052
Log Pis Max                  10.91436
Log Pis Min                  -10.379895
Policy mu Mean               0.05449113
Policy mu Std                0.47250614
Policy mu Max                1.6622769
Policy mu Min                -1.4319459
Policy log std Mean          -0.8904681
Policy log std Std           0.22666135
Policy log std Max           -0.34546214
Policy log std Min           -2.2113602
Z mean eval                  0.9653373
Z variance eval              0.010216619
total_rewards                [ 162.15504104  694.45558198  344.72454701 1413.80248018  355.12193404
  384.82826084   90.12211914  673.38992734  153.70597278  217.17330099]
total_rewards_mean           448.94791653472237
total_rewards_std            376.46554942686146
total_rewards_max            1413.8024801775546
total_rewards_min            90.12211913664375
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               34.81779260421172
(Previous) Eval Time (s)     29.417789450846612
Sample Time (s)              27.341010802891105
Epoch Time (s)               91.57659285794944
Total Train Time (s)         10148.108932491392
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:35:28.800170 UTC | [2020_01_10_11_46_20] Iteration #114 | Epoch Duration: 81.46221256256104
2020-01-10 14:35:28.800509 UTC | [2020_01_10_11_46_20] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9642483
Z variance train             0.010330274
KL Divergence                19.557362
KL Loss                      1.9557362
QF Loss                      196.51157
VF Loss                      126.11287
Policy Loss                  -570.08905
Q Predictions Mean           566.5399
Q Predictions Std            120.19584
Q Predictions Max            725.7059
Q Predictions Min            17.31582
V Predictions Mean           576.25977
V Predictions Std            115.86622
V Predictions Max            727.6693
V Predictions Min            10.548201
Log Pis Mean                 -1.4524208
Log Pis Std                  2.3535614
Log Pis Max                  10.51132
Log Pis Min                  -10.559418
Policy mu Mean               0.05099927
Policy mu Std                0.49608997
Policy mu Max                1.6845675
Policy mu Min                -2.5426872
Policy log std Mean          -0.8374715
Policy log std Std           0.22995773
Policy log std Max           -0.27280712
Policy log std Min           -2.4322662
Z mean eval                  0.9912807
Z variance eval              0.011923859
total_rewards                [1574.63804419  518.09545227  232.37688797 1735.64058817  404.13889121
  957.46644389  926.92349983  349.24900846  281.07745524  263.5238826 ]
total_rewards_mean           724.3130153820196
total_rewards_std            527.0430102249738
total_rewards_max            1735.6405881716357
total_rewards_min            232.37688796605255
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               36.01098641008139
(Previous) Eval Time (s)     19.302910746075213
Sample Time (s)              27.038018577266484
Epoch Time (s)               82.35191573342308
Total Train Time (s)         10238.487950915005
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:36:59.180857 UTC | [2020_01_10_11_46_20] Iteration #115 | Epoch Duration: 90.3801281452179
2020-01-10 14:36:59.181040 UTC | [2020_01_10_11_46_20] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9913174
Z variance train             0.0119136665
KL Divergence                19.734797
KL Loss                      1.9734796
QF Loss                      1296.6432
VF Loss                      90.44936
Policy Loss                  -578.7135
Q Predictions Mean           576.1957
Q Predictions Std            121.06805
Q Predictions Max            734.6808
Q Predictions Min            31.996794
V Predictions Mean           582.80756
V Predictions Std            119.68567
V Predictions Max            730.52386
V Predictions Min            1.7241247
Log Pis Mean                 -1.1939564
Log Pis Std                  2.2490263
Log Pis Max                  13.6493635
Log Pis Min                  -8.528907
Policy mu Mean               -0.032825388
Policy mu Std                0.49030188
Policy mu Max                2.1044939
Policy mu Min                -1.8357266
Policy log std Mean          -0.899304
Policy log std Std           0.2421694
Policy log std Max           -0.25810218
Policy log std Min           -2.471155
Z mean eval                  0.9725174
Z variance eval              0.0178273
total_rewards                [ 271.87907176 1711.80650365 1887.73902617 1659.40315423 1539.97681194
  272.39346053  293.48262116  165.73026075 1537.40922186  177.54638399]
total_rewards_mean           951.7366516031465
total_rewards_std            722.3451969497825
total_rewards_max            1887.7390261683254
total_rewards_min            165.73026074619273
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               34.913688770029694
(Previous) Eval Time (s)     27.330658656079322
Sample Time (s)              26.71919585298747
Epoch Time (s)               88.96354327909648
Total Train Time (s)         10332.422701769043
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:38:33.117962 UTC | [2020_01_10_11_46_20] Iteration #116 | Epoch Duration: 93.9367790222168
2020-01-10 14:38:33.118191 UTC | [2020_01_10_11_46_20] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97330314
Z variance train             0.017790737
KL Divergence                19.207405
KL Loss                      1.9207405
QF Loss                      246.9295
VF Loss                      76.6169
Policy Loss                  -579.5489
Q Predictions Mean           575.8281
Q Predictions Std            129.93855
Q Predictions Max            753.0342
Q Predictions Min            8.327755
V Predictions Mean           575.12244
V Predictions Std            129.93294
V Predictions Max            746.18286
V Predictions Min            -1.5854242
Log Pis Mean                 -1.3252606
Log Pis Std                  2.1371734
Log Pis Max                  6.7961626
Log Pis Min                  -6.78468
Policy mu Mean               0.009717548
Policy mu Std                0.4883186
Policy mu Max                1.9371002
Policy mu Min                -2.3491495
Policy log std Mean          -0.88004804
Policy log std Std           0.22012685
Policy log std Max           0.3417682
Policy log std Min           -1.6849833
Z mean eval                  0.97509223
Z variance eval              0.017340843
total_rewards                [ 282.21806303 1623.23149585  273.60288943 1883.85834843  368.45309449
  638.71050469  550.2254133    63.94052714  207.45074292  927.9675533 ]
total_rewards_mean           681.9658632587586
total_rewards_std            586.7059514444612
total_rewards_max            1883.8583484348574
total_rewards_min            63.9405271363185
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               35.911403090227395
(Previous) Eval Time (s)     32.303469894919544
Sample Time (s)              26.28751903306693
Epoch Time (s)               94.50239201821387
Total Train Time (s)         10427.1683166367
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:40:07.866029 UTC | [2020_01_10_11_46_20] Iteration #117 | Epoch Duration: 94.74769568443298
2020-01-10 14:40:07.866258 UTC | [2020_01_10_11_46_20] Iteration #117 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97473943
Z variance train             0.01734564
KL Divergence                18.810904
KL Loss                      1.8810904
QF Loss                      1252.3909
VF Loss                      209.91376
Policy Loss                  -574.0346
Q Predictions Mean           572.2364
Q Predictions Std            128.1298
Q Predictions Max            747.5311
Q Predictions Min            51.152954
V Predictions Mean           572.7604
V Predictions Std            126.1158
V Predictions Max            736.9165
V Predictions Min            39.428173
Log Pis Mean                 -1.5477985
Log Pis Std                  2.2121027
Log Pis Max                  4.2850237
Log Pis Min                  -8.272978
Policy mu Mean               0.032294422
Policy mu Std                0.47648615
Policy mu Max                1.7678319
Policy mu Min                -1.4720299
Policy log std Mean          -0.86153984
Policy log std Std           0.22734605
Policy log std Max           -0.16582376
Policy log std Min           -2.3072865
Z mean eval                  0.9916676
Z variance eval              0.019372232
total_rewards                [ 101.40693182   52.48668409  911.40509399  111.07793906  959.0127369
  600.74873415  352.56605141  973.7762477  1861.20783827 1789.7495585 ]
total_rewards_mean           771.3437815882877
total_rewards_std            626.6393739175224
total_rewards_max            1861.207838266202
total_rewards_min            52.486684092419125
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               34.817402539774776
(Previous) Eval Time (s)     32.54827971709892
Sample Time (s)              27.11275773262605
Epoch Time (s)               94.47843998949975
Total Train Time (s)         10512.696195305325
Epoch                        118
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:41:33.396228 UTC | [2020_01_10_11_46_20] Iteration #118 | Epoch Duration: 85.52979516983032
2020-01-10 14:41:33.396531 UTC | [2020_01_10_11_46_20] Iteration #118 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9953143
Z variance train             0.019301351
KL Divergence                18.073536
KL Loss                      1.8073536
QF Loss                      469.29373
VF Loss                      100.803024
Policy Loss                  -598.16675
Q Predictions Mean           594.14026
Q Predictions Std            119.107666
Q Predictions Max            754.8411
Q Predictions Min            315.85287
V Predictions Mean           590.5137
V Predictions Std            117.30481
V Predictions Max            740.5474
V Predictions Min            309.56668
Log Pis Mean                 -1.6972183
Log Pis Std                  2.0843215
Log Pis Max                  4.4543495
Log Pis Min                  -9.8652935
Policy mu Mean               0.052996375
Policy mu Std                0.4767485
Policy mu Max                1.7306799
Policy mu Min                -1.610097
Policy log std Mean          -0.8392502
Policy log std Std           0.21373543
Policy log std Max           -0.07853544
Policy log std Min           -1.4829848
Z mean eval                  0.9626768
Z variance eval              0.01564374
total_rewards                [ 82.91063443 711.9172162  527.60757627 789.79828278 893.5825761
  72.71664852 539.76154839  52.3657838   36.15629805 538.89877337]
total_rewards_mean           424.57153379055217
total_rewards_std            316.6737921802284
total_rewards_max            893.5825761045855
total_rewards_min            36.15629804728391
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               35.33044672710821
(Previous) Eval Time (s)     23.59919241676107
Sample Time (s)              25.4427910563536
Epoch Time (s)               84.37243020022288
Total Train Time (s)         10607.253287876956
Epoch                        119
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:43:07.955927 UTC | [2020_01_10_11_46_20] Iteration #119 | Epoch Duration: 94.55921602249146
2020-01-10 14:43:07.956215 UTC | [2020_01_10_11_46_20] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96224415
Z variance train             0.01564842
KL Divergence                18.759264
KL Loss                      1.8759264
QF Loss                      259.29846
VF Loss                      43.86444
Policy Loss                  -588.7148
Q Predictions Mean           586.47644
Q Predictions Std            122.81977
Q Predictions Max            748.8806
Q Predictions Min            246.01083
V Predictions Mean           591.0375
V Predictions Std            122.20289
V Predictions Max            751.95465
V Predictions Min            254.30072
Log Pis Mean                 -1.5503125
Log Pis Std                  2.1239426
Log Pis Max                  6.143508
Log Pis Min                  -9.073556
Policy mu Mean               0.04818157
Policy mu Std                0.4569558
Policy mu Max                1.6983293
Policy mu Min                -1.4084795
Policy log std Mean          -0.87446856
Policy log std Std           0.21735214
Policy log std Max           -0.12811929
Policy log std Min           -1.642041
Z mean eval                  0.9683302
Z variance eval              0.013754587
total_rewards                [ 600.1982492   487.75951896 1248.97545054  705.07005295  857.58355262
  164.4802526  1727.54928387  175.85247017 1917.06269687  139.23070286]
total_rewards_mean           802.3762230650739
total_rewards_std            607.412808882571
total_rewards_max            1917.062696871977
total_rewards_min            139.23070286108856
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               35.69206463638693
(Previous) Eval Time (s)     33.785572552122176
Sample Time (s)              27.726043910253793
Epoch Time (s)               97.2036810987629
Total Train Time (s)         10700.414835789707
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:44:41.118891 UTC | [2020_01_10_11_46_20] Iteration #120 | Epoch Duration: 93.16252613067627
2020-01-10 14:44:41.119060 UTC | [2020_01_10_11_46_20] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96749955
Z variance train             0.013762432
KL Divergence                18.86958
KL Loss                      1.886958
QF Loss                      281.39407
VF Loss                      45.758835
Policy Loss                  -586.22986
Q Predictions Mean           583.908
Q Predictions Std            120.73172
Q Predictions Max            740.704
Q Predictions Min            53.488235
V Predictions Mean           588.4284
V Predictions Std            121.33457
V Predictions Max            734.53595
V Predictions Min            0.47038883
Log Pis Mean                 -1.4550033
Log Pis Std                  2.4030714
Log Pis Max                  5.4104013
Log Pis Min                  -11.982295
Policy mu Mean               0.05673921
Policy mu Std                0.4892873
Policy mu Max                1.6588509
Policy mu Min                -2.498236
Policy log std Mean          -0.8576734
Policy log std Std           0.20281562
Policy log std Max           -0.27521098
Policy log std Min           -1.569006
Z mean eval                  0.9778803
Z variance eval              0.011484178
total_rewards                [ 295.45241139  865.54902725  349.28107714  -15.31865612 1334.58436146
  148.3006508   139.47737893  187.62789222  373.527446    105.89915386]
total_rewards_mean           378.4380742936677
total_rewards_std            391.7970733746981
total_rewards_max            1334.5843614563921
total_rewards_min            -15.318656120645251
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               34.849327228963375
(Previous) Eval Time (s)     29.74396377010271
Sample Time (s)              25.591353500727564
Epoch Time (s)               90.18464449979365
Total Train Time (s)         10789.691293136682
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:46:10.397427 UTC | [2020_01_10_11_46_20] Iteration #121 | Epoch Duration: 89.27823734283447
2020-01-10 14:46:10.397620 UTC | [2020_01_10_11_46_20] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9778172
Z variance train             0.011567158
KL Divergence                19.854692
KL Loss                      1.9854692
QF Loss                      487.85648
VF Loss                      225.87009
Policy Loss                  -593.04535
Q Predictions Mean           587.4811
Q Predictions Std            133.096
Q Predictions Max            745.00867
Q Predictions Min            87.45311
V Predictions Mean           581.65466
V Predictions Std            132.7311
V Predictions Max            736.72485
V Predictions Min            69.71923
Log Pis Mean                 -1.4567543
Log Pis Std                  2.2186813
Log Pis Max                  5.818342
Log Pis Min                  -7.9193068
Policy mu Mean               0.054894265
Policy mu Std                0.47886834
Policy mu Max                1.8621918
Policy mu Min                -2.0557897
Policy log std Mean          -0.8711879
Policy log std Std           0.23310204
Policy log std Max           -0.25974822
Policy log std Min           -2.0967183
Z mean eval                  0.9804953
Z variance eval              0.012639297
total_rewards                [1567.69828431   33.16656433  592.11415329  127.49921902  956.62169406
   81.34469451  254.15696504  971.91822332 1808.55590544  171.45282309]
total_rewards_mean           656.4528526404522
total_rewards_std            612.1734255751742
total_rewards_max            1808.5559054365658
total_rewards_min            33.16656432987547
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               35.335021521896124
(Previous) Eval Time (s)     28.837162613868713
Sample Time (s)              27.53985797613859
Epoch Time (s)               91.71204211190343
Total Train Time (s)         10882.066251353826
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:47:42.773343 UTC | [2020_01_10_11_46_20] Iteration #122 | Epoch Duration: 92.3756034374237
2020-01-10 14:47:42.773484 UTC | [2020_01_10_11_46_20] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9796791
Z variance train             0.012622167
KL Divergence                19.21035
KL Loss                      1.921035
QF Loss                      470.9954
VF Loss                      169.01892
Policy Loss                  -600.5034
Q Predictions Mean           597.3906
Q Predictions Std            133.84332
Q Predictions Max            792.19006
Q Predictions Min            -1.3518637
V Predictions Mean           598.40356
V Predictions Std            131.90526
V Predictions Max            779.22205
V Predictions Min            3.8419633
Log Pis Mean                 -1.5674987
Log Pis Std                  2.2495153
Log Pis Max                  5.5434647
Log Pis Min                  -9.143261
Policy mu Mean               -0.0082618315
Policy mu Std                0.48566914
Policy mu Max                2.6519601
Policy mu Min                -1.7669405
Policy log std Mean          -0.8723462
Policy log std Std           0.23466496
Policy log std Max           0.19025046
Policy log std Min           -1.9819822
Z mean eval                  0.9872676
Z variance eval              0.018498298
total_rewards                [1768.6761376   136.78828077 1752.65585042  162.29874899  756.99974816
 1806.5503795  1791.38161605  719.25829325 1072.50092448    7.73683183]
total_rewards_mean           997.4846811066694
total_rewards_std            707.7205951292686
total_rewards_max            1806.5503794972115
total_rewards_min            7.736831833441009
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               33.235696787945926
(Previous) Eval Time (s)     29.500266384333372
Sample Time (s)              26.101168784778565
Epoch Time (s)               88.83713195705786
Total Train Time (s)         10972.362565199379
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:49:13.072538 UTC | [2020_01_10_11_46_20] Iteration #123 | Epoch Duration: 90.29893708229065
2020-01-10 14:49:13.072743 UTC | [2020_01_10_11_46_20] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98814076
Z variance train             0.018568158
KL Divergence                19.577599
KL Loss                      1.9577599
QF Loss                      499.48914
VF Loss                      55.584423
Policy Loss                  -604.67053
Q Predictions Mean           602.65753
Q Predictions Std            126.04611
Q Predictions Max            776.715
Q Predictions Min            281.39877
V Predictions Mean           600.5454
V Predictions Std            125.35353
V Predictions Max            759.24884
V Predictions Min            264.3764
Log Pis Mean                 -1.5487695
Log Pis Std                  2.1547992
Log Pis Max                  4.913952
Log Pis Min                  -7.435068
Policy mu Mean               0.0077913245
Policy mu Std                0.48367724
Policy mu Max                1.5269119
Policy mu Min                -1.5607982
Policy log std Mean          -0.863894
Policy log std Std           0.22968662
Policy log std Max           -0.11089301
Policy log std Min           -1.9633427
Z mean eval                  0.98561287
Z variance eval              0.016959088
total_rewards                [1960.66210217  429.0253013   -61.63982367   20.61695146  160.94664324
  588.76431761  917.61166717  361.53310262 1714.41527201  284.79540985]
total_rewards_mean           637.6730943774904
total_rewards_std            658.164577574835
total_rewards_max            1960.6621021722005
total_rewards_min            -61.639823668880936
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.90659188805148
(Previous) Eval Time (s)     30.96168918395415
Sample Time (s)              26.261292982380837
Epoch Time (s)               90.12957405438647
Total Train Time (s)         11064.034728689585
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:50:44.747559 UTC | [2020_01_10_11_46_20] Iteration #124 | Epoch Duration: 91.67467308044434
2020-01-10 14:50:44.747766 UTC | [2020_01_10_11_46_20] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98546773
Z variance train             0.017015938
KL Divergence                19.753342
KL Loss                      1.9753342
QF Loss                      659.85474
VF Loss                      173.82222
Policy Loss                  -604.99146
Q Predictions Mean           602.96454
Q Predictions Std            133.61832
Q Predictions Max            772.07495
Q Predictions Min            -60.404568
V Predictions Mean           601.81335
V Predictions Std            130.46777
V Predictions Max            771.305
V Predictions Min            4.943845
Log Pis Mean                 -1.3464038
Log Pis Std                  2.2782729
Log Pis Max                  8.183086
Log Pis Min                  -9.08054
Policy mu Mean               -0.019346276
Policy mu Std                0.52926683
Policy mu Max                1.7692876
Policy mu Min                -2.063979
Policy log std Mean          -0.87017715
Policy log std Std           0.24703148
Policy log std Max           -0.1651671
Policy log std Min           -2.0039134
Z mean eval                  0.96755886
Z variance eval              0.013807635
total_rewards                [1257.69936579  -38.45750708 1660.90074887  820.63564885  169.05688808
 1192.77359384  918.07998326  621.99885776 2003.07062475  411.06239145]
total_rewards_mean           901.6820595575973
total_rewards_std            612.1537555817847
total_rewards_max            2003.070624745604
total_rewards_min            -38.45750707709143
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               33.22752808779478
(Previous) Eval Time (s)     32.50638021202758
Sample Time (s)              26.73792741028592
Epoch Time (s)               92.47183571010828
Total Train Time (s)         11155.364763629623
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:52:16.078727 UTC | [2020_01_10_11_46_20] Iteration #125 | Epoch Duration: 91.33078050613403
2020-01-10 14:52:16.078896 UTC | [2020_01_10_11_46_20] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96769637
Z variance train             0.013794606
KL Divergence                19.887352
KL Loss                      1.9887352
QF Loss                      341.0368
VF Loss                      72.037865
Policy Loss                  -595.8327
Q Predictions Mean           593.79083
Q Predictions Std            130.06815
Q Predictions Max            769.7605
Q Predictions Min            254.75342
V Predictions Mean           596.2113
V Predictions Std            129.54852
V Predictions Max            775.5516
V Predictions Min            272.18677
Log Pis Mean                 -1.2929472
Log Pis Std                  2.3662806
Log Pis Max                  7.872628
Log Pis Min                  -7.4418993
Policy mu Mean               0.036429375
Policy mu Std                0.49882722
Policy mu Max                2.1380966
Policy mu Min                -2.0660255
Policy log std Mean          -0.87314487
Policy log std Std           0.23554473
Policy log std Max           -0.18817627
Policy log std Min           -1.8222362
Z mean eval                  0.96560705
Z variance eval              0.011939715
total_rewards                [-114.2322645  1718.79386499  821.94252633 1339.37663888  231.59685728
  152.46780613 1862.86664598 1794.7502647   171.07373042 1837.40624089]
total_rewards_mean           981.6042311087571
total_rewards_std            772.9789193420006
total_rewards_max            1862.866645981264
total_rewards_min            -114.23226449947558
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               33.447223018389195
(Previous) Eval Time (s)     31.36497239395976
Sample Time (s)              25.906978344079107
Epoch Time (s)               90.71917375642806
Total Train Time (s)         11241.490212542936
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:53:42.211302 UTC | [2020_01_10_11_46_20] Iteration #126 | Epoch Duration: 86.13227653503418
2020-01-10 14:53:42.211482 UTC | [2020_01_10_11_46_20] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9650278
Z variance train             0.0119453
KL Divergence                20.222925
KL Loss                      2.0222926
QF Loss                      594.97644
VF Loss                      96.101494
Policy Loss                  -613.3552
Q Predictions Mean           611.5372
Q Predictions Std            128.41481
Q Predictions Max            814.6398
Q Predictions Min            14.462916
V Predictions Mean           611.9248
V Predictions Std            125.02511
V Predictions Max            800.52094
V Predictions Min            118.411995
Log Pis Mean                 -1.3365958
Log Pis Std                  2.2658753
Log Pis Max                  5.151985
Log Pis Min                  -7.0786886
Policy mu Mean               0.01392773
Policy mu Std                0.49696228
Policy mu Max                1.5147325
Policy mu Min                -1.7420193
Policy log std Mean          -0.89454454
Policy log std Std           0.24513724
Policy log std Max           -0.12110591
Policy log std Min           -2.1882339
Z mean eval                  0.9817851
Z variance eval              0.013811936
total_rewards                [1408.17133042  811.7092052   845.54621915  118.20955793 1763.44106027
  120.44439734   61.17381072 1792.06516656  694.13847844  162.88600978]
total_rewards_mean           777.778523581657
total_rewards_std            645.6916463873001
total_rewards_max            1792.065166562259
total_rewards_min            61.173810717771744
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.944201031234115
(Previous) Eval Time (s)     26.77773059112951
Sample Time (s)              26.037577908020467
Epoch Time (s)               85.7595095303841
Total Train Time (s)         11332.310423548799
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:55:13.031221 UTC | [2020_01_10_11_46_20] Iteration #127 | Epoch Duration: 90.81953239440918
2020-01-10 14:55:13.031522 UTC | [2020_01_10_11_46_20] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98165905
Z variance train             0.013841626
KL Divergence                19.381695
KL Loss                      1.9381695
QF Loss                      373.9317
VF Loss                      67.721634
Policy Loss                  -598.5131
Q Predictions Mean           598.25684
Q Predictions Std            145.9613
Q Predictions Max            770.02814
Q Predictions Min            1.2993791
V Predictions Mean           600.7837
V Predictions Std            145.57634
V Predictions Max            779.6203
V Predictions Min            -3.4491348
Log Pis Mean                 -1.37533
Log Pis Std                  2.277128
Log Pis Max                  12.115089
Log Pis Min                  -7.965484
Policy mu Mean               0.019423548
Policy mu Std                0.4927297
Policy mu Max                2.1557562
Policy mu Min                -1.734704
Policy log std Mean          -0.86524105
Policy log std Std           0.24068792
Policy log std Max           -0.28751495
Policy log std Min           -2.542541
Z mean eval                  0.98240125
Z variance eval              0.017103259
total_rewards                [ 683.63899429 1638.33419461  396.94772464 1843.38022786  342.46319564
   68.90582755 1684.79847134  374.08278548 1851.22786494 1746.68689155]
total_rewards_mean           1063.0466177896012
total_rewards_std            706.0390095647288
total_rewards_max            1851.2278649426535
total_rewards_min            68.90582754570443
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               33.185793904121965
(Previous) Eval Time (s)     31.83735166816041
Sample Time (s)              26.272793288808316
Epoch Time (s)               91.29593886109069
Total Train Time (s)         11421.865469415672
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:56:42.587469 UTC | [2020_01_10_11_46_20] Iteration #128 | Epoch Duration: 89.55575203895569
2020-01-10 14:56:42.587668 UTC | [2020_01_10_11_46_20] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98218536
Z variance train             0.017141845
KL Divergence                18.923992
KL Loss                      1.8923992
QF Loss                      566.3832
VF Loss                      66.386
Policy Loss                  -606.1558
Q Predictions Mean           602.9264
Q Predictions Std            145.44923
Q Predictions Max            804.7504
Q Predictions Min            230.02185
V Predictions Mean           609.1807
V Predictions Std            144.39127
V Predictions Max            803.25366
V Predictions Min            251.55563
Log Pis Mean                 -1.4537702
Log Pis Std                  2.2382944
Log Pis Max                  4.795004
Log Pis Min                  -8.624277
Policy mu Mean               0.012737807
Policy mu Std                0.48903012
Policy mu Max                1.7510321
Policy mu Min                -1.7344034
Policy log std Mean          -0.86323595
Policy log std Std           0.22913022
Policy log std Max           -0.23762468
Policy log std Min           -1.9437383
Z mean eval                  0.97828245
Z variance eval              0.01412487
total_rewards                [ 597.66518023  120.53265584  888.8761132  1699.22379541  311.55209496
 1552.69157159 1043.05607956 1737.16126914 1213.68172291  472.79137676]
total_rewards_mean           963.723185959311
total_rewards_std            554.2324732138394
total_rewards_max            1737.1612691353278
total_rewards_min            120.53265584126233
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               32.56873372523114
(Previous) Eval Time (s)     30.09674450336024
Sample Time (s)              25.794212269596756
Epoch Time (s)               88.45969049818814
Total Train Time (s)         11512.944290464278
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:58:13.669030 UTC | [2020_01_10_11_46_20] Iteration #129 | Epoch Duration: 91.08122205734253
2020-01-10 14:58:13.669243 UTC | [2020_01_10_11_46_20] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97697574
Z variance train             0.014143413
KL Divergence                19.910793
KL Loss                      1.9910793
QF Loss                      414.0283
VF Loss                      121.16773
Policy Loss                  -603.70654
Q Predictions Mean           601.3987
Q Predictions Std            143.87079
Q Predictions Max            793.3895
Q Predictions Min            -10.860687
V Predictions Mean           600.6402
V Predictions Std            142.19858
V Predictions Max            784.421
V Predictions Min            10.072728
Log Pis Mean                 -1.4300755
Log Pis Std                  2.3756988
Log Pis Max                  9.374809
Log Pis Min                  -8.952957
Policy mu Mean               -0.000930354
Policy mu Std                0.50479466
Policy mu Max                1.8092414
Policy mu Min                -2.3811371
Policy log std Mean          -0.87247956
Policy log std Std           0.24622343
Policy log std Max           0.12373716
Policy log std Min           -2.2756934
Z mean eval                  0.9642971
Z variance eval              0.009507319
total_rewards                [ 608.1303911  1732.95132042  202.1668574  1216.43500444 1773.13396611
  446.74081965  273.83462948  340.11627255 1778.61275833  806.31563627]
total_rewards_mean           917.8437655746441
total_rewards_std            617.8196163926023
total_rewards_max            1778.6127583304678
total_rewards_min            202.1668574009845
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               32.66012056590989
(Previous) Eval Time (s)     32.71795081580058
Sample Time (s)              24.550231717992574
Epoch Time (s)               89.92830309970304
Total Train Time (s)         11600.65715641994
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:59:41.383530 UTC | [2020_01_10_11_46_20] Iteration #130 | Epoch Duration: 87.71413826942444
2020-01-10 14:59:41.383730 UTC | [2020_01_10_11_46_20] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9651283
Z variance train             0.009507893
KL Divergence                20.869535
KL Loss                      2.0869536
QF Loss                      275.89807
VF Loss                      77.63634
Policy Loss                  -609.3813
Q Predictions Mean           605.58093
Q Predictions Std            143.19936
Q Predictions Max            780.0524
Q Predictions Min            73.911865
V Predictions Mean           604.16235
V Predictions Std            141.2665
V Predictions Max            775.2971
V Predictions Min            89.53387
Log Pis Mean                 -1.5019085
Log Pis Std                  2.2443755
Log Pis Max                  8.201616
Log Pis Min                  -8.666187
Policy mu Mean               0.057566434
Policy mu Std                0.48421994
Policy mu Max                1.8435955
Policy mu Min                -1.5440732
Policy log std Mean          -0.86723447
Policy log std Std           0.23594806
Policy log std Max           -0.17015913
Policy log std Min           -1.8818839
Z mean eval                  0.96348095
Z variance eval              0.00917883
total_rewards                [1491.04395725  836.38129499  658.78609852  386.92033663  109.54104288
 1168.48082023  397.14386308  594.58686933  204.23000082 1855.65424976]
total_rewards_mean           770.2768533476661
total_rewards_std            542.8585417840692
total_rewards_max            1855.6542497597707
total_rewards_min            109.54104287843731
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               33.04367966996506
(Previous) Eval Time (s)     30.503418704960495
Sample Time (s)              24.097708945628256
Epoch Time (s)               87.64480732055381
Total Train Time (s)         11692.960834253114
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:01:13.689654 UTC | [2020_01_10_11_46_20] Iteration #131 | Epoch Duration: 92.30576348304749
2020-01-10 15:01:13.689891 UTC | [2020_01_10_11_46_20] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96406305
Z variance train             0.009178349
KL Divergence                20.908567
KL Loss                      2.0908568
QF Loss                      418.06427
VF Loss                      368.79642
Policy Loss                  -618.19165
Q Predictions Mean           615.18384
Q Predictions Std            140.30914
Q Predictions Max            797.5041
Q Predictions Min            21.653671
V Predictions Mean           613.36414
V Predictions Std            135.3199
V Predictions Max            786.85175
V Predictions Min            -1.2068824
Log Pis Mean                 -0.9631493
Log Pis Std                  2.4023213
Log Pis Max                  13.589905
Log Pis Min                  -7.12033
Policy mu Mean               0.019172229
Policy mu Std                0.48266658
Policy mu Max                2.1519582
Policy mu Min                -2.0285482
Policy log std Mean          -0.9216602
Policy log std Std           0.2491205
Policy log std Max           -0.15052426
Policy log std Min           -2.3312807
Z mean eval                  0.99014664
Z variance eval              0.009575369
total_rewards                [1679.35967112 1336.95707269 1655.11853102 1515.56286402 1647.52226598
 1609.59510718 1721.1837389    63.73379795 1719.70806145  103.72031903]
total_rewards_mean           1305.2461429337861
total_rewards_std            620.2573285732424
total_rewards_max            1721.1837389002062
total_rewards_min            63.73379795322774
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               33.39252061629668
(Previous) Eval Time (s)     35.16399629181251
Sample Time (s)              25.018714044243097
Epoch Time (s)               93.57523095235229
Total Train Time (s)         11786.678217803128
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:02:47.410226 UTC | [2020_01_10_11_46_20] Iteration #132 | Epoch Duration: 93.72010827064514
2020-01-10 15:02:47.410531 UTC | [2020_01_10_11_46_20] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98876536
Z variance train             0.00960903
KL Divergence                20.898567
KL Loss                      2.0898569
QF Loss                      1374.3035
VF Loss                      52.148144
Policy Loss                  -619.78613
Q Predictions Mean           618.3473
Q Predictions Std            136.71983
Q Predictions Max            785.5255
Q Predictions Min            237.34177
V Predictions Mean           617.89343
V Predictions Std            136.21725
V Predictions Max            779.7769
V Predictions Min            240.14919
Log Pis Mean                 -1.8720133
Log Pis Std                  2.4323232
Log Pis Max                  5.933222
Log Pis Min                  -9.885024
Policy mu Mean               0.021687616
Policy mu Std                0.49993637
Policy mu Max                1.6787939
Policy mu Min                -1.7909745
Policy log std Mean          -0.82229555
Policy log std Std           0.23092659
Policy log std Max           -0.15418291
Policy log std Min           -2.1073165
Z mean eval                  0.9622878
Z variance eval              0.012344686
total_rewards                [  13.49542072 1931.90918926  694.39905854 1868.11171194  540.05771836
  777.31752655  140.76110532 1841.09392064  449.2543604   208.63390872]
total_rewards_mean           846.5033920469472
total_rewards_std            713.4065960675046
total_rewards_max            1931.9091892638476
total_rewards_min            13.49542072206042
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               33.02195265609771
(Previous) Eval Time (s)     35.308424436021596
Sample Time (s)              26.161348785739392
Epoch Time (s)               94.4917258778587
Total Train Time (s)         11875.743390187155
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:04:16.482239 UTC | [2020_01_10_11_46_20] Iteration #133 | Epoch Duration: 89.07152390480042
2020-01-10 15:04:16.482615 UTC | [2020_01_10_11_46_20] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9619756
Z variance train             0.012373589
KL Divergence                21.283691
KL Loss                      2.128369
QF Loss                      260.5655
VF Loss                      63.63897
Policy Loss                  -634.30914
Q Predictions Mean           633.3946
Q Predictions Std            127.45091
Q Predictions Max            793.6809
Q Predictions Min            -32.52505
V Predictions Mean           636.6726
V Predictions Std            125.68918
V Predictions Max            802.9778
V Predictions Min            12.152546
Log Pis Mean                 -0.9331779
Log Pis Std                  2.2574053
Log Pis Max                  6.8016195
Log Pis Min                  -8.378333
Policy mu Mean               -0.006038877
Policy mu Std                0.53076994
Policy mu Max                1.836777
Policy mu Min                -2.1213923
Policy log std Mean          -0.8991521
Policy log std Std           0.22988424
Policy log std Max           -0.20226616
Policy log std Min           -1.7643545
Z mean eval                  0.944715
Z variance eval              0.009323048
total_rewards                [1789.39024681 1210.58255937 1758.10093107 2004.15137703 1838.98819053
 1928.69531158 2045.0002469   404.94150675 1993.93186373 1914.78647833]
total_rewards_mean           1688.856871210767
total_rewards_std            483.99506591410903
total_rewards_max            2045.0002468997113
total_rewards_min            404.94150675395656
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               32.937335915863514
(Previous) Eval Time (s)     29.88783248513937
Sample Time (s)              26.452851878944784
Epoch Time (s)               89.27802027994767
Total Train Time (s)         11968.980704379734
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:05:49.717245 UTC | [2020_01_10_11_46_20] Iteration #134 | Epoch Duration: 93.23426485061646
2020-01-10 15:05:49.717576 UTC | [2020_01_10_11_46_20] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9435215
Z variance train             0.009305165
KL Divergence                20.734169
KL Loss                      2.073417
QF Loss                      390.1597
VF Loss                      104.62749
Policy Loss                  -634.16315
Q Predictions Mean           630.2015
Q Predictions Std            134.2036
Q Predictions Max            775.7074
Q Predictions Min            37.6255
V Predictions Mean           628.1609
V Predictions Std            131.9089
V Predictions Max            765.7752
V Predictions Min            41.836723
Log Pis Mean                 -1.2499526
Log Pis Std                  2.260384
Log Pis Max                  7.260805
Log Pis Min                  -8.085828
Policy mu Mean               0.008895848
Policy mu Std                0.46831197
Policy mu Max                1.8798931
Policy mu Min                -1.746172
Policy log std Mean          -0.9329165
Policy log std Std           0.24142699
Policy log std Max           -0.31763232
Policy log std Min           -1.7140388
Z mean eval                  0.96467876
Z variance eval              0.01236524
total_rewards                [ -20.82928906  335.7693687  1865.16835256 1796.30885429 1702.29839987
  141.02512534 1211.76611608  840.36321018  984.06160065 1316.99565975]
total_rewards_mean           1017.2927398368889
total_rewards_std            653.074145969429
total_rewards_max            1865.1683525564008
total_rewards_min            -20.829289055233577
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               33.225393728818744
(Previous) Eval Time (s)     33.843659814912826
Sample Time (s)              26.442525171674788
Epoch Time (s)               93.51157871540636
Total Train Time (s)         12057.84942515567
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:07:18.587622 UTC | [2020_01_10_11_46_20] Iteration #135 | Epoch Duration: 88.86987018585205
2020-01-10 15:07:18.587821 UTC | [2020_01_10_11_46_20] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9680557
Z variance train             0.012248807
KL Divergence                20.054874
KL Loss                      2.0054874
QF Loss                      802.65436
VF Loss                      70.78271
Policy Loss                  -625.3148
Q Predictions Mean           620.8174
Q Predictions Std            148.16473
Q Predictions Max            800.4099
Q Predictions Min            16.174055
V Predictions Mean           623.7727
V Predictions Std            143.22722
V Predictions Max            793.617
V Predictions Min            228.59065
Log Pis Mean                 -1.2922176
Log Pis Std                  2.3717527
Log Pis Max                  7.915214
Log Pis Min                  -7.1538353
Policy mu Mean               0.039420426
Policy mu Std                0.5161557
Policy mu Max                1.86632
Policy mu Min                -2.1002166
Policy log std Mean          -0.8549437
Policy log std Std           0.23165414
Policy log std Max           -0.18049419
Policy log std Min           -1.8627799
Z mean eval                  0.9527895
Z variance eval              0.011564841
total_rewards                [  54.32305429 1938.70475262   71.54814446 1849.10799691 1864.60072598
  749.18078482 1900.70601125 1683.57023335 1829.99797602  360.41553109]
total_rewards_mean           1230.2155210788992
total_rewards_std            775.5924242158665
total_rewards_max            1938.7047526170225
total_rewards_min            54.323054292187265
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               32.8784450199455
(Previous) Eval Time (s)     29.201578055974096
Sample Time (s)              26.133144783321768
Epoch Time (s)               88.21316785924137
Total Train Time (s)         12148.379634109791
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:08:49.120042 UTC | [2020_01_10_11_46_20] Iteration #136 | Epoch Duration: 90.53208470344543
2020-01-10 15:08:49.120234 UTC | [2020_01_10_11_46_20] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95264596
Z variance train             0.011558014
KL Divergence                19.988861
KL Loss                      1.9988861
QF Loss                      497.4475
VF Loss                      150.55203
Policy Loss                  -630.9076
Q Predictions Mean           625.42847
Q Predictions Std            138.33426
Q Predictions Max            786.53314
Q Predictions Min            -4.6816483
V Predictions Mean           629.36194
V Predictions Std            136.92711
V Predictions Max            777.24756
V Predictions Min            -0.92929864
Log Pis Mean                 -1.2250952
Log Pis Std                  2.4311182
Log Pis Max                  5.917115
Log Pis Min                  -8.124357
Policy mu Mean               0.007990144
Policy mu Std                0.53283757
Policy mu Max                3.9928834
Policy mu Min                -1.9804435
Policy log std Mean          -0.87320185
Policy log std Std           0.24162784
Policy log std Max           -0.12870675
Policy log std Min           -1.934752
Z mean eval                  0.97423095
Z variance eval              0.0084048575
total_rewards                [1719.95071393 1714.88606385  793.47546072 1741.9958659  1742.34151524
 1803.43910951 1115.15333764 1662.17405194  552.13343509  844.3392104 ]
total_rewards_mean           1368.9888764220173
total_rewards_std            461.9749226351234
total_rewards_max            1803.439109511349
total_rewards_min            552.1334350869665
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               32.98152204602957
(Previous) Eval Time (s)     31.52007023897022
Sample Time (s)              26.50859590061009
Epoch Time (s)               91.01018818560988
Total Train Time (s)         12241.506406278815
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:10:22.248138 UTC | [2020_01_10_11_46_20] Iteration #137 | Epoch Duration: 93.12778568267822
2020-01-10 15:10:22.248258 UTC | [2020_01_10_11_46_20] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97519237
Z variance train             0.008379112
KL Divergence                20.320425
KL Loss                      2.0320425
QF Loss                      497.34955
VF Loss                      103.806404
Policy Loss                  -651.74396
Q Predictions Mean           646.8685
Q Predictions Std            128.65608
Q Predictions Max            797.96356
Q Predictions Min            146.97842
V Predictions Mean           647.24207
V Predictions Std            123.86341
V Predictions Max            791.6024
V Predictions Min            261.8846
Log Pis Mean                 -1.307557
Log Pis Std                  2.379695
Log Pis Max                  11.454442
Log Pis Min                  -7.399081
Policy mu Mean               0.011459315
Policy mu Std                0.5233134
Policy mu Max                1.8442665
Policy mu Min                -1.8317786
Policy log std Mean          -0.8674121
Policy log std Std           0.22485025
Policy log std Max           -0.3366946
Policy log std Min           -2.222707
Z mean eval                  0.9727092
Z variance eval              0.0069263102
total_rewards                [1906.78999813 1917.46098919  629.27691305  400.98145126  501.81020904
  173.92708421  444.99631496 1815.39976864  573.88064964 1777.83193448]
total_rewards_mean           1014.2355312595179
total_rewards_std            696.2995558668172
total_rewards_max            1917.4609891882658
total_rewards_min            173.92708420905893
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               33.11569229699671
(Previous) Eval Time (s)     33.63729228684679
Sample Time (s)              25.909924581181258
Epoch Time (s)               92.66290916502476
Total Train Time (s)         12332.917416679207
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:11:53.662288 UTC | [2020_01_10_11_46_20] Iteration #138 | Epoch Duration: 91.41390347480774
2020-01-10 15:11:53.662500 UTC | [2020_01_10_11_46_20] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96909124
Z variance train             0.0069168583
KL Divergence                20.637444
KL Loss                      2.0637443
QF Loss                      1052.7725
VF Loss                      89.43567
Policy Loss                  -643.6231
Q Predictions Mean           643.6523
Q Predictions Std            143.08734
Q Predictions Max            840.2897
Q Predictions Min            9.80732
V Predictions Mean           648.26984
V Predictions Std            141.38214
V Predictions Max            838.7304
V Predictions Min            32.817154
Log Pis Mean                 -1.1469193
Log Pis Std                  2.339057
Log Pis Max                  8.514239
Log Pis Min                  -10.638169
Policy mu Mean               0.011564186
Policy mu Std                0.51702607
Policy mu Max                2.2714632
Policy mu Min                -2.2736425
Policy log std Mean          -0.9016869
Policy log std Std           0.23806237
Policy log std Max           -0.33354467
Policy log std Min           -1.7634
Z mean eval                  0.97830707
Z variance eval              0.0067097032
total_rewards                [ 858.0494002   825.31122987  614.22718233 2060.50444039  -34.66368546
  223.71404097 1986.5589398  1312.31384439  972.51003818  451.82588213]
total_rewards_mean           927.0351312807812
total_rewards_std            656.9745524936213
total_rewards_max            2060.5044403881334
total_rewards_min            -34.663685455055614
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               32.46730869496241
(Previous) Eval Time (s)     32.38791250437498
Sample Time (s)              27.018751044757664
Epoch Time (s)               91.87397224409506
Total Train Time (s)         12425.132817099337
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:13:25.879594 UTC | [2020_01_10_11_46_20] Iteration #139 | Epoch Duration: 92.21695709228516
2020-01-10 15:13:25.879768 UTC | [2020_01_10_11_46_20] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9765838
Z variance train             0.0067235166
KL Divergence                20.697653
KL Loss                      2.0697653
QF Loss                      440.48846
VF Loss                      171.6114
Policy Loss                  -621.4906
Q Predictions Mean           620.67346
Q Predictions Std            164.28813
Q Predictions Max            807.8845
Q Predictions Min            -13.178317
V Predictions Mean           630.9448
V Predictions Std            162.72552
V Predictions Max            823.54926
V Predictions Min            5.9384103
Log Pis Mean                 -1.0946145
Log Pis Std                  2.6137228
Log Pis Max                  12.128421
Log Pis Min                  -10.506441
Policy mu Mean               0.017560037
Policy mu Std                0.5254323
Policy mu Max                2.598766
Policy mu Min                -1.8770387
Policy log std Mean          -0.88234806
Policy log std Std           0.25325716
Policy log std Max           -0.12869549
Policy log std Min           -2.2323122
Z mean eval                  0.946838
Z variance eval              0.007234192
total_rewards                [1883.47115371 1309.29363916 1824.19872691 1781.30013296 1934.52796296
 1946.48796154 1662.31927684 1706.34975687  713.00441549  337.54091176]
total_rewards_mean           1509.8493938196839
total_rewards_std            528.6256253353607
total_rewards_max            1946.4879615424682
total_rewards_min            337.5409117571333
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               33.0862703602761
(Previous) Eval Time (s)     32.730501770973206
Sample Time (s)              25.028654554393142
Epoch Time (s)               90.84542668564245
Total Train Time (s)         12512.47452716576
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:14:53.223771 UTC | [2020_01_10_11_46_20] Iteration #140 | Epoch Duration: 87.34387826919556
2020-01-10 15:14:53.223949 UTC | [2020_01_10_11_46_20] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94704276
Z variance train             0.0072738873
KL Divergence                20.564114
KL Loss                      2.0564115
QF Loss                      265.25772
VF Loss                      120.63454
Policy Loss                  -647.8568
Q Predictions Mean           646.4098
Q Predictions Std            141.87013
Q Predictions Max            815.364
Q Predictions Min            179.70975
V Predictions Mean           655.83704
V Predictions Std            140.91006
V Predictions Max            837.83966
V Predictions Min            193.52126
Log Pis Mean                 -1.4628701
Log Pis Std                  2.3140442
Log Pis Max                  5.7483134
Log Pis Min                  -8.446831
Policy mu Mean               0.011440897
Policy mu Std                0.50552815
Policy mu Max                1.8137138
Policy mu Min                -1.644007
Policy log std Mean          -0.8776982
Policy log std Std           0.24018538
Policy log std Max           -0.14263535
Policy log std Min           -2.1948268
Z mean eval                  0.9476737
Z variance eval              0.00864952
total_rewards                [ 989.22194283  141.58003365 1949.86573381 2069.11593946  169.78081976
 1698.92942086 1817.00453568 1487.63795757  804.67685893 2046.89424016]
total_rewards_mean           1317.4707482712631
total_rewards_std            706.510448643468
total_rewards_max            2069.1159394629262
total_rewards_min            141.58003365468414
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               32.65924996510148
(Previous) Eval Time (s)     29.228660456370562
Sample Time (s)              24.143403637688607
Epoch Time (s)               86.03131405916065
Total Train Time (s)         12601.44360388117
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:16:22.195473 UTC | [2020_01_10_11_46_20] Iteration #141 | Epoch Duration: 88.97136354446411
2020-01-10 15:16:22.195688 UTC | [2020_01_10_11_46_20] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94329274
Z variance train             0.00864842
KL Divergence                20.56844
KL Loss                      2.056844
QF Loss                      361.8172
VF Loss                      141.19585
Policy Loss                  -643.8534
Q Predictions Mean           643.5344
Q Predictions Std            138.21735
Q Predictions Max            814.1129
Q Predictions Min            194.05733
V Predictions Mean           653.3706
V Predictions Std            135.83353
V Predictions Max            814.73505
V Predictions Min            245.63368
Log Pis Mean                 -1.219153
Log Pis Std                  2.358359
Log Pis Max                  7.8770347
Log Pis Min                  -7.3935866
Policy mu Mean               0.047050633
Policy mu Std                0.5181131
Policy mu Max                2.094665
Policy mu Min                -2.088603
Policy log std Mean          -0.88614523
Policy log std Std           0.2569771
Policy log std Max           -0.07264161
Policy log std Min           -2.4166236
Z mean eval                  0.95360965
Z variance eval              0.006937001
total_rewards                [-157.76599215  929.41480443 1946.62322647 1892.39646571 1695.03975705
 1872.67602746 1943.37493075 2049.6445864  2010.32597769 1861.88384639]
total_rewards_mean           1604.3613630199936
total_rewards_std            662.2160412277243
total_rewards_max            2049.644586398631
total_rewards_min            -157.7659921538089
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               33.41138852201402
(Previous) Eval Time (s)     32.16839148988947
Sample Time (s)              25.470154121518135
Epoch Time (s)               91.04993413342163
Total Train Time (s)         12692.706224549096
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:17:53.460154 UTC | [2020_01_10_11_46_20] Iteration #142 | Epoch Duration: 91.2642810344696
2020-01-10 15:17:53.460431 UTC | [2020_01_10_11_46_20] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95385015
Z variance train             0.006939709
KL Divergence                20.7194
KL Loss                      2.0719402
QF Loss                      315.4502
VF Loss                      82.03099
Policy Loss                  -634.06836
Q Predictions Mean           632.0638
Q Predictions Std            156.28015
Q Predictions Max            839.7042
Q Predictions Min            18.577673
V Predictions Mean           632.52856
V Predictions Std            154.79819
V Predictions Max            843.36816
V Predictions Min            100.22349
Log Pis Mean                 -1.725038
Log Pis Std                  2.3966784
Log Pis Max                  9.619428
Log Pis Min                  -7.7871056
Policy mu Mean               0.015047341
Policy mu Std                0.5035485
Policy mu Max                1.9835835
Policy mu Min                -1.889819
Policy log std Mean          -0.829723
Policy log std Std           0.23538323
Policy log std Max           -0.029538095
Policy log std Min           -2.0416412
Z mean eval                  0.9487916
Z variance eval              0.007518047
total_rewards                [  10.11924484   36.70079283 1981.68369604 1625.21143723 1733.32256287
 1787.49807686  281.20473949 1775.9028327  1574.59436369  178.19265567]
total_rewards_mean           1098.4430402219955
total_rewards_std            802.970995688292
total_rewards_max            1981.6836960376281
total_rewards_min            10.119244841596142
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               32.15679711988196
(Previous) Eval Time (s)     32.382382126990706
Sample Time (s)              26.308115538675338
Epoch Time (s)               90.847294785548
Total Train Time (s)         12783.214193870313
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:19:23.969994 UTC | [2020_01_10_11_46_20] Iteration #143 | Epoch Duration: 90.50938272476196
2020-01-10 15:19:23.970163 UTC | [2020_01_10_11_46_20] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94929266
Z variance train             0.007517293
KL Divergence                21.123362
KL Loss                      2.1123362
QF Loss                      552.78577
VF Loss                      57.348553
Policy Loss                  -641.37115
Q Predictions Mean           639.30096
Q Predictions Std            137.08516
Q Predictions Max            799.778
Q Predictions Min            215.62807
V Predictions Mean           642.76935
V Predictions Std            137.82535
V Predictions Max            793.6728
V Predictions Min            224.45456
Log Pis Mean                 -1.0350156
Log Pis Std                  2.4892716
Log Pis Max                  7.736468
Log Pis Min                  -8.078312
Policy mu Mean               0.016214063
Policy mu Std                0.5377148
Policy mu Max                4.211533
Policy mu Min                -1.9117281
Policy log std Mean          -0.86817825
Policy log std Std           0.24520639
Policy log std Max           -0.12017837
Policy log std Min           -1.8741734
Z mean eval                  0.9308426
Z variance eval              0.0130824465
total_rewards                [1758.89473567  368.71175608  312.22232811 1420.12335025 2157.15762639
 1904.05926903 1953.21816333  630.61680042 1522.10486772 1988.03601062]
total_rewards_mean           1401.514490763211
total_rewards_std            667.9867782845294
total_rewards_max            2157.157626386826
total_rewards_min            312.2223281119435
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               32.956126778852195
(Previous) Eval Time (s)     32.04417141294107
Sample Time (s)              26.24938741698861
Epoch Time (s)               91.24968560878187
Total Train Time (s)         12874.000155652873
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:20:54.758571 UTC | [2020_01_10_11_46_20] Iteration #144 | Epoch Duration: 90.78828358650208
2020-01-10 15:20:54.758739 UTC | [2020_01_10_11_46_20] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9292242
Z variance train             0.0131172
KL Divergence                20.450344
KL Loss                      2.0450344
QF Loss                      343.86884
VF Loss                      34.100433
Policy Loss                  -650.8385
Q Predictions Mean           647.9178
Q Predictions Std            147.42924
Q Predictions Max            818.31976
Q Predictions Min            216.7001
V Predictions Mean           652.6097
V Predictions Std            147.53874
V Predictions Max            818.19824
V Predictions Min            209.7783
Log Pis Mean                 -1.5277538
Log Pis Std                  2.3412833
Log Pis Max                  5.2931767
Log Pis Min                  -11.955401
Policy mu Mean               -0.02484341
Policy mu Std                0.5057446
Policy mu Max                1.8291613
Policy mu Min                -1.8857955
Policy log std Mean          -0.8647841
Policy log std Std           0.2367797
Policy log std Max           -0.14872694
Policy log std Min           -1.9124727
Z mean eval                  0.9317834
Z variance eval              0.01018185
total_rewards                [1883.73616918 2033.56488967 1948.97695139 1948.09925187 1894.49922413
  923.25425018  155.64317443 1891.87509762 1750.69008938  625.03395993]
total_rewards_mean           1505.5373057769834
total_rewards_std            641.2136399403224
total_rewards_max            2033.564889668587
total_rewards_min            155.6431744252074
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               32.857772663235664
(Previous) Eval Time (s)     31.58237571408972
Sample Time (s)              27.011231779586524
Epoch Time (s)               91.45138015691191
Total Train Time (s)         12967.84058405552
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:22:28.604390 UTC | [2020_01_10_11_46_20] Iteration #145 | Epoch Duration: 93.84547138214111
2020-01-10 15:22:28.604689 UTC | [2020_01_10_11_46_20] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93275034
Z variance train             0.010193961
KL Divergence                20.017172
KL Loss                      2.0017173
QF Loss                      359.29834
VF Loss                      101.874054
Policy Loss                  -644.47565
Q Predictions Mean           644.03827
Q Predictions Std            141.22838
Q Predictions Max            809.88617
Q Predictions Min            211.42555
V Predictions Mean           651.6575
V Predictions Std            141.26949
V Predictions Max            813.7525
V Predictions Min            216.84935
Log Pis Mean                 -1.3742356
Log Pis Std                  2.2905715
Log Pis Max                  6.294504
Log Pis Min                  -9.733291
Policy mu Mean               0.042286526
Policy mu Std                0.5314782
Policy mu Max                1.9568186
Policy mu Min                -1.746769
Policy log std Mean          -0.85789657
Policy log std Std           0.22199918
Policy log std Max           -0.1246171
Policy log std Min           -1.7030653
Z mean eval                  0.9370958
Z variance eval              0.011904034
total_rewards                [1052.17629605 1839.10872057 1256.44061635  385.01886332 1315.4491835
 1503.82102194 1825.52907468 1745.75287053 1879.89240378 1311.81461852]
total_rewards_mean           1411.500366924079
total_rewards_std            438.1657545166362
total_rewards_max            1879.8924037788715
total_rewards_min            385.0188633235559
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               33.302043919917196
(Previous) Eval Time (s)     33.97602366982028
Sample Time (s)              26.294943413697183
Epoch Time (s)               93.57301100343466
Total Train Time (s)         13062.48652857868
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:24:03.251991 UTC | [2020_01_10_11_46_20] Iteration #146 | Epoch Duration: 94.64708232879639
2020-01-10 15:24:03.252199 UTC | [2020_01_10_11_46_20] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9371668
Z variance train             0.0118779
KL Divergence                20.091753
KL Loss                      2.0091753
QF Loss                      368.6108
VF Loss                      63.509045
Policy Loss                  -655.7301
Q Predictions Mean           651.7793
Q Predictions Std            160.44545
Q Predictions Max            841.46857
Q Predictions Min            9.414284
V Predictions Mean           651.43445
V Predictions Std            158.9046
V Predictions Max            837.8115
V Predictions Min            31.906729
Log Pis Mean                 -1.235168
Log Pis Std                  2.304798
Log Pis Max                  6.195131
Log Pis Min                  -9.537879
Policy mu Mean               0.017363975
Policy mu Std                0.5022681
Policy mu Max                1.7253759
Policy mu Min                -1.9668922
Policy log std Mean          -0.8852812
Policy log std Std           0.24808045
Policy log std Max           -0.32440275
Policy log std Min           -1.8262751
Z mean eval                  0.9180414
Z variance eval              0.011578883
total_rewards                [ 548.77873561 1868.49865396 1703.59407287 1141.87221149 1256.27889667
 1699.20405979 1836.54998037 1817.68842337  616.25931076 1975.27777015]
total_rewards_mean           1446.4002115048424
total_rewards_std            500.1750153551919
total_rewards_max            1975.2777701547352
total_rewards_min            548.7787356063683
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               32.97298931609839
(Previous) Eval Time (s)     35.049731492996216
Sample Time (s)              25.774539003148675
Epoch Time (s)               93.79725981224328
Total Train Time (s)         13155.550642538816
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:25:36.319102 UTC | [2020_01_10_11_46_20] Iteration #147 | Epoch Duration: 93.06673860549927
2020-01-10 15:25:36.319389 UTC | [2020_01_10_11_46_20] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9185754
Z variance train             0.011612207
KL Divergence                20.524166
KL Loss                      2.0524166
QF Loss                      608.221
VF Loss                      110.274666
Policy Loss                  -659.85345
Q Predictions Mean           655.44666
Q Predictions Std            148.33595
Q Predictions Max            824.9911
Q Predictions Min            51.248432
V Predictions Mean           653.5998
V Predictions Std            148.15877
V Predictions Max            819.8889
V Predictions Min            7.652068
Log Pis Mean                 -1.3375663
Log Pis Std                  2.521529
Log Pis Max                  11.895904
Log Pis Min                  -9.917146
Policy mu Mean               0.06138287
Policy mu Std                0.5096721
Policy mu Max                2.7085571
Policy mu Min                -1.5446467
Policy log std Mean          -0.8971614
Policy log std Std           0.24795803
Policy log std Max           -0.16334927
Policy log std Min           -2.2317634
Z mean eval                  0.94218856
Z variance eval              0.009487586
total_rewards                [ -21.77565942 1884.7112804  1904.28789764 1003.4184656  2005.0661601
 1435.4223958   524.77694779 1986.53906773 2032.0979542   225.36008766]
total_rewards_mean           1297.990459749779
total_rewards_std            762.9315045177608
total_rewards_max            2032.0979541989295
total_rewards_min            -21.775659416057408
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               32.84604359604418
(Previous) Eval Time (s)     34.31883508199826
Sample Time (s)              25.77481051022187
Epoch Time (s)               92.93968918826431
Total Train Time (s)         13245.537365111988
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:27:06.306688 UTC | [2020_01_10_11_46_20] Iteration #148 | Epoch Duration: 89.98711133003235
2020-01-10 15:27:06.306874 UTC | [2020_01_10_11_46_20] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9442166
Z variance train             0.009480026
KL Divergence                20.83442
KL Loss                      2.083442
QF Loss                      433.7476
VF Loss                      261.78464
Policy Loss                  -655.0402
Q Predictions Mean           650.7809
Q Predictions Std            170.46634
Q Predictions Max            851.3498
Q Predictions Min            -3.0288563
V Predictions Mean           653.9834
V Predictions Std            168.20639
V Predictions Max            845.7169
V Predictions Min            30.46497
Log Pis Mean                 -1.2842425
Log Pis Std                  2.3724737
Log Pis Max                  8.338027
Log Pis Min                  -7.899789
Policy mu Mean               -0.01771567
Policy mu Std                0.5236302
Policy mu Max                1.9308085
Policy mu Min                -1.9450808
Policy log std Mean          -0.87793624
Policy log std Std           0.25872752
Policy log std Max           -0.13001627
Policy log std Min           -2.3599727
Z mean eval                  0.9666287
Z variance eval              0.010642412
total_rewards                [1835.29867306 1906.72853487 1307.78333397 1881.27983796  955.51636115
  143.64208991 1935.37235322 1248.98810593  789.57626314 2060.40683703]
total_rewards_mean           1406.4592390240605
total_rewards_std            598.3443074170231
total_rewards_max            2060.406837033746
total_rewards_min            143.64208990833006
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               32.76113535603508
(Previous) Eval Time (s)     31.365857107564807
Sample Time (s)              25.937090049497783
Epoch Time (s)               90.06408251309767
Total Train Time (s)         13333.048962547444
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:28:33.821237 UTC | [2020_01_10_11_46_20] Iteration #149 | Epoch Duration: 87.51419949531555
2020-01-10 15:28:33.821560 UTC | [2020_01_10_11_46_20] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9661725
Z variance train             0.010653903
KL Divergence                20.67371
KL Loss                      2.0673711
QF Loss                      252.07947
VF Loss                      112.016266
Policy Loss                  -655.6642
Q Predictions Mean           653.1084
Q Predictions Std            160.65144
Q Predictions Max            865.63074
Q Predictions Min            35.55683
V Predictions Mean           659.4626
V Predictions Std            161.67696
V Predictions Max            861.7772
V Predictions Min            9.320135
Log Pis Mean                 -1.4571861
Log Pis Std                  2.3874173
Log Pis Max                  5.7948904
Log Pis Min                  -9.266632
Policy mu Mean               0.018003963
Policy mu Std                0.49814707
Policy mu Max                1.8801202
Policy mu Min                -2.3602507
Policy log std Mean          -0.8629405
Policy log std Std           0.2331974
Policy log std Max           -0.27385858
Policy log std Min           -1.751544
Z mean eval                  0.94330823
Z variance eval              0.011592003
total_rewards                [1793.41257109  601.58133273 1932.6576573   314.76673233 1782.86934048
  116.76031043 1487.30895367  267.28342108 1878.10068395 1837.13221521]
total_rewards_mean           1201.187321825913
total_rewards_std            732.261156031431
total_rewards_max            1932.6576572960914
total_rewards_min            116.76031042844994
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.88007959909737
(Previous) Eval Time (s)     28.815567271318287
Sample Time (s)              26.995975336059928
Epoch Time (s)               90.69162220647559
Total Train Time (s)         13424.588906406425
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:30:05.361887 UTC | [2020_01_10_11_46_20] Iteration #150 | Epoch Duration: 91.54011464118958
2020-01-10 15:30:05.362025 UTC | [2020_01_10_11_46_20] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94481057
Z variance train             0.0115769785
KL Divergence                20.122732
KL Loss                      2.0122733
QF Loss                      343.74426
VF Loss                      313.54907
Policy Loss                  -648.19666
Q Predictions Mean           645.4353
Q Predictions Std            170.33849
Q Predictions Max            832.1374
Q Predictions Min            -51.89698
V Predictions Mean           645.3455
V Predictions Std            163.41107
V Predictions Max            824.94727
V Predictions Min            6.2055564
Log Pis Mean                 -1.3488333
Log Pis Std                  2.3387449
Log Pis Max                  9.582729
Log Pis Min                  -7.7652225
Policy mu Mean               -0.012425794
Policy mu Std                0.5180196
Policy mu Max                1.9239229
Policy mu Min                -2.3073163
Policy log std Mean          -0.87586844
Policy log std Std           0.23805247
Policy log std Max           -0.22976428
Policy log std Min           -2.2001336
Z mean eval                  0.92544365
Z variance eval              0.008730163
total_rewards                [1705.57412105 1875.31486948 1739.15843552  827.93580668 1930.55860114
 1853.64436403 1781.68721182 1740.09812201  424.23600683 2034.66487014]
total_rewards_mean           1591.2872408712183
total_rewards_std            499.9229876037138
total_rewards_max            2034.6648701385366
total_rewards_min            424.2360068342205
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               35.7893669931218
(Previous) Eval Time (s)     29.663659137208015
Sample Time (s)              27.882186222355813
Epoch Time (s)               93.33521235268563
Total Train Time (s)         13521.945341499988
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:31:42.721450 UTC | [2020_01_10_11_46_20] Iteration #151 | Epoch Duration: 97.35931277275085
2020-01-10 15:31:42.721644 UTC | [2020_01_10_11_46_20] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92174405
Z variance train             0.008783107
KL Divergence                20.81838
KL Loss                      2.0818381
QF Loss                      268.28232
VF Loss                      153.58322
Policy Loss                  -660.1595
Q Predictions Mean           660.58356
Q Predictions Std            163.38423
Q Predictions Max            831.3987
Q Predictions Min            206.69884
V Predictions Mean           670.33307
V Predictions Std            163.84825
V Predictions Max            846.9636
V Predictions Min            208.36743
Log Pis Mean                 -0.92983264
Log Pis Std                  2.3801844
Log Pis Max                  6.6649876
Log Pis Min                  -7.378178
Policy mu Mean               0.0016828419
Policy mu Std                0.55488145
Policy mu Max                2.1299813
Policy mu Min                -1.6872311
Policy log std Mean          -0.87590176
Policy log std Std           0.2531263
Policy log std Max           -0.010740459
Policy log std Min           -1.910187
Z mean eval                  0.9306637
Z variance eval              0.010808704
total_rewards                [1036.18633066  490.39901589  867.64271295  518.64323167  599.40925417
  530.55590675 1946.01168936  139.17506443 1961.73706782 1725.66477389]
total_rewards_mean           981.5425047584665
total_rewards_std            630.4882673127537
total_rewards_max            1961.7370678212792
total_rewards_min            139.17506443027492
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               34.76469543995336
(Previous) Eval Time (s)     33.687267360743135
Sample Time (s)              28.247092307545245
Epoch Time (s)               96.69905510824174
Total Train Time (s)         13613.431873158552
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:33:14.210373 UTC | [2020_01_10_11_46_20] Iteration #152 | Epoch Duration: 91.48858904838562
2020-01-10 15:33:14.210574 UTC | [2020_01_10_11_46_20] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9315933
Z variance train             0.010824792
KL Divergence                20.14017
KL Loss                      2.0140169
QF Loss                      522.05725
VF Loss                      115.52796
Policy Loss                  -654.10724
Q Predictions Mean           650.96765
Q Predictions Std            168.52777
Q Predictions Max            812.145
Q Predictions Min            51.95106
V Predictions Mean           653.2388
V Predictions Std            165.00522
V Predictions Max            813.6996
V Predictions Min            173.415
Log Pis Mean                 -1.1717298
Log Pis Std                  2.5233572
Log Pis Max                  7.156417
Log Pis Min                  -8.395369
Policy mu Mean               0.04183026
Policy mu Std                0.53266114
Policy mu Max                1.6923229
Policy mu Min                -2.004964
Policy log std Mean          -0.8733856
Policy log std Std           0.25585306
Policy log std Max           -0.23423165
Policy log std Min           -1.9696846
Z mean eval                  0.9048666
Z variance eval              0.008700063
total_rewards                [1797.41865599  908.31303236 1908.0273655    68.37308288  428.78432146
 1975.51169508  767.57337377  942.42585019 1774.22308747 2017.894794  ]
total_rewards_mean           1258.8545258692247
total_rewards_std            680.9880546168976
total_rewards_max            2017.8947940039593
total_rewards_min            68.37308288404147
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               35.86320550274104
(Previous) Eval Time (s)     28.476324460934848
Sample Time (s)              26.480809601955116
Epoch Time (s)               90.820339565631
Total Train Time (s)         13710.2856727154
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:34:51.069288 UTC | [2020_01_10_11_46_20] Iteration #153 | Epoch Duration: 96.85855102539062
2020-01-10 15:34:51.069589 UTC | [2020_01_10_11_46_20] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.907359
Z variance train             0.00869984
KL Divergence                20.351357
KL Loss                      2.0351357
QF Loss                      953.07263
VF Loss                      209.28412
Policy Loss                  -664.30096
Q Predictions Mean           658.00836
Q Predictions Std            156.75023
Q Predictions Max            843.2135
Q Predictions Min            126.41666
V Predictions Mean           660.2588
V Predictions Std            156.05026
V Predictions Max            834.49506
V Predictions Min            70.84164
Log Pis Mean                 -0.9815754
Log Pis Std                  2.5065591
Log Pis Max                  6.5059195
Log Pis Min                  -8.99432
Policy mu Mean               0.08781825
Policy mu Std                0.533396
Policy mu Max                2.1146398
Policy mu Min                -1.7205211
Policy log std Mean          -0.89481556
Policy log std Std           0.25678957
Policy log std Max           -0.15545529
Policy log std Min           -1.9313517
Z mean eval                  0.89665186
Z variance eval              0.009343928
total_rewards                [1567.03501613 2143.48456124  801.97155202  613.03152432   84.95521503
 1988.55553598  588.42966971   68.21363114  686.5775369  2173.08567602]
total_rewards_mean           1071.5339918500308
total_rewards_std            780.6025251460269
total_rewards_max            2173.0856760214856
total_rewards_min            68.2136311424874
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               34.760079281870276
(Previous) Eval Time (s)     34.51402848120779
Sample Time (s)              27.760185821913183
Epoch Time (s)               97.03429358499125
Total Train Time (s)         13807.499259081203
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:36:28.284249 UTC | [2020_01_10_11_46_20] Iteration #154 | Epoch Duration: 97.2144832611084
2020-01-10 15:36:28.284452 UTC | [2020_01_10_11_46_20] Iteration #154 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89624226
Z variance train             0.00934429
KL Divergence                20.151543
KL Loss                      2.0151544
QF Loss                      744.6658
VF Loss                      90.339905
Policy Loss                  -647.7698
Q Predictions Mean           644.02
Q Predictions Std            168.22958
Q Predictions Max            822.8783
Q Predictions Min            133.17593
V Predictions Mean           653.85706
V Predictions Std            167.45605
V Predictions Max            828.3876
V Predictions Min            131.35269
Log Pis Mean                 -1.4964589
Log Pis Std                  2.3578317
Log Pis Max                  7.739522
Log Pis Min                  -8.050541
Policy mu Mean               0.0053780153
Policy mu Std                0.50913715
Policy mu Max                1.5886312
Policy mu Min                -1.717865
Policy log std Mean          -0.87345153
Policy log std Std           0.24702062
Policy log std Max           -0.27272278
Policy log std Min           -1.8474264
Z mean eval                  0.90103304
Z variance eval              0.00976623
total_rewards                [ -24.2164687  1761.93656418 1800.22823861 1866.01130606 1878.97206
   63.47499735 1676.15401836 1885.86342127  534.71201673 1803.12817563]
total_rewards_mean           1324.6264329481473
total_rewards_std            756.2540117840912
total_rewards_max            1885.8634212713773
total_rewards_min            -24.216468703966136
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               35.43807310285047
(Previous) Eval Time (s)     34.693755857180804
Sample Time (s)              27.102837386075407
Epoch Time (s)               97.23466634610668
Total Train Time (s)         13903.357938962989
Epoch                        155
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:38:04.145420 UTC | [2020_01_10_11_46_20] Iteration #155 | Epoch Duration: 95.86082315444946
2020-01-10 15:38:04.145626 UTC | [2020_01_10_11_46_20] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8998971
Z variance train             0.009818146
KL Divergence                19.966599
KL Loss                      1.9966599
QF Loss                      903.12085
VF Loss                      187.68994
Policy Loss                  -642.8304
Q Predictions Mean           641.83374
Q Predictions Std            183.76585
Q Predictions Max            849.41943
Q Predictions Min            -11.050302
V Predictions Mean           641.6181
V Predictions Std            184.16551
V Predictions Max            853.6768
V Predictions Min            -6.166661
Log Pis Mean                 -1.5057648
Log Pis Std                  2.5050435
Log Pis Max                  6.480279
Log Pis Min                  -8.326996
Policy mu Mean               0.0058985325
Policy mu Std                0.5374563
Policy mu Max                2.038787
Policy mu Min                -1.593654
Policy log std Mean          -0.8238693
Policy log std Std           0.24297534
Policy log std Max           -0.17058396
Policy log std Min           -2.3782258
Z mean eval                  0.9119829
Z variance eval              0.01275284
total_rewards                [1828.08024151 1794.92005119   59.6897745  1912.91124181  654.9033369
 1851.43004069 1635.61128231  178.08407449  655.18531492 1802.80604531]
total_rewards_mean           1237.3621403624843
total_rewards_std            718.2453757819587
total_rewards_max            1912.9112418147517
total_rewards_min            59.68977449522466
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               36.412261127028614
(Previous) Eval Time (s)     33.31949596712366
Sample Time (s)              28.08352264901623
Epoch Time (s)               97.8152797431685
Total Train Time (s)         13997.556442231871
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:39:38.347980 UTC | [2020_01_10_11_46_20] Iteration #156 | Epoch Duration: 94.20217657089233
2020-01-10 15:39:38.348355 UTC | [2020_01_10_11_46_20] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9107653
Z variance train             0.012740912
KL Divergence                19.930462
KL Loss                      1.9930462
QF Loss                      322.0285
VF Loss                      74.49778
Policy Loss                  -666.9656
Q Predictions Mean           666.52167
Q Predictions Std            160.54579
Q Predictions Max            847.8692
Q Predictions Min            186.57898
V Predictions Mean           664.8075
V Predictions Std            159.48294
V Predictions Max            840.19904
V Predictions Min            186.78513
Log Pis Mean                 -1.1826488
Log Pis Std                  2.2060065
Log Pis Max                  6.708846
Log Pis Min                  -6.9538198
Policy mu Mean               0.0026599444
Policy mu Std                0.5316943
Policy mu Max                2.4436507
Policy mu Min                -1.7599101
Policy log std Mean          -0.85166603
Policy log std Std           0.25120804
Policy log std Max           -0.21100807
Policy log std Min           -2.1704183
Z mean eval                  0.87819064
Z variance eval              0.009740115
total_rewards                [ 355.57479854 1789.43824622  313.3776759   984.92846172 1844.64095153
  536.27836303 1918.20449272 1916.28247122 2007.78780909 1994.65241621]
total_rewards_mean           1366.116568617859
total_rewards_std            691.7990591374294
total_rewards_max            2007.787809092087
total_rewards_min            313.3776759045019
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               35.16358065325767
(Previous) Eval Time (s)     29.70586152607575
Sample Time (s)              26.49277105089277
Epoch Time (s)               91.36221323022619
Total Train Time (s)         14094.554379862268
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:41:15.348516 UTC | [2020_01_10_11_46_20] Iteration #157 | Epoch Duration: 96.99997305870056
2020-01-10 15:41:15.348718 UTC | [2020_01_10_11_46_20] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.878965
Z variance train             0.009724163
KL Divergence                20.492558
KL Loss                      2.0492558
QF Loss                      379.82358
VF Loss                      104.18508
Policy Loss                  -678.1533
Q Predictions Mean           674.0682
Q Predictions Std            152.29468
Q Predictions Max            828.41504
Q Predictions Min            208.67622
V Predictions Mean           672.2584
V Predictions Std            150.49564
V Predictions Max            823.21674
V Predictions Min            214.5153
Log Pis Mean                 -1.2923858
Log Pis Std                  2.2288775
Log Pis Max                  5.913808
Log Pis Min                  -7.074346
Policy mu Mean               0.03252756
Policy mu Std                0.51361454
Policy mu Max                1.8891947
Policy mu Min                -1.9192288
Policy log std Mean          -0.87625337
Policy log std Std           0.2463247
Policy log std Max           -0.21372682
Policy log std Min           -1.9448416
Z mean eval                  0.8962394
Z variance eval              0.0135408845
total_rewards                [ 541.290143    589.15982799  807.07654213 2038.09268884 2093.47535445
  181.0469318   508.25625778 1145.83449172 1900.04406295 1307.84918045]
total_rewards_mean           1111.2125481107391
total_rewards_std            663.6776688512733
total_rewards_max            2093.475354451386
total_rewards_min            181.0469318017188
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               35.847592844162136
(Previous) Eval Time (s)     35.34320067567751
Sample Time (s)              28.161726490594447
Epoch Time (s)               99.35252001043409
Total Train Time (s)         14191.317617724184
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:42:52.114070 UTC | [2020_01_10_11_46_20] Iteration #158 | Epoch Duration: 96.76519799232483
2020-01-10 15:42:52.114278 UTC | [2020_01_10_11_46_20] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89557093
Z variance train             0.013593796
KL Divergence                20.221842
KL Loss                      2.0221841
QF Loss                      426.16907
VF Loss                      57.537666
Policy Loss                  -672.63416
Q Predictions Mean           669.3264
Q Predictions Std            155.86256
Q Predictions Max            852.8147
Q Predictions Min            201.63956
V Predictions Mean           674.83307
V Predictions Std            156.32773
V Predictions Max            858.1348
V Predictions Min            207.07603
Log Pis Mean                 -1.346257
Log Pis Std                  2.571179
Log Pis Max                  5.284053
Log Pis Min                  -10.070186
Policy mu Mean               0.029273933
Policy mu Std                0.5328412
Policy mu Max                1.8116871
Policy mu Min                -2.1400125
Policy log std Mean          -0.85502315
Policy log std Std           0.23663417
Policy log std Max           -0.061201394
Policy log std Min           -1.758602
Z mean eval                  0.89594346
Z variance eval              0.015257986
total_rewards                [1623.86886272 1617.16265412  976.94365899  512.84658889 2046.45730326
 1825.48432454   57.97061986 1689.9343062  1228.12186224 1730.65185181]
total_rewards_mean           1330.9442032635438
total_rewards_std            603.2022176448073
total_rewards_max            2046.457303263271
total_rewards_min            57.97061985805939
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               33.07678568502888
(Previous) Eval Time (s)     32.75541236391291
Sample Time (s)              26.1576483505778
Epoch Time (s)               91.98984639951959
Total Train Time (s)         14278.157418634277
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:44:18.956884 UTC | [2020_01_10_11_46_20] Iteration #159 | Epoch Duration: 86.84243583679199
2020-01-10 15:44:18.957127 UTC | [2020_01_10_11_46_20] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8966304
Z variance train             0.015282473
KL Divergence                20.094753
KL Loss                      2.0094755
QF Loss                      270.97028
VF Loss                      78.47957
Policy Loss                  -673.72186
Q Predictions Mean           669.92957
Q Predictions Std            162.11821
Q Predictions Max            851.1055
Q Predictions Min            38.785004
V Predictions Mean           669.8895
V Predictions Std            157.46089
V Predictions Max            851.025
V Predictions Min            106.936195
Log Pis Mean                 -0.7481493
Log Pis Std                  2.425304
Log Pis Max                  6.280428
Log Pis Min                  -7.105404
Policy mu Mean               0.049740765
Policy mu Std                0.5655316
Policy mu Max                2.0597446
Policy mu Min                -2.0581346
Policy log std Mean          -0.8696048
Policy log std Std           0.2453466
Policy log std Max           -0.30403757
Policy log std Min           -2.4197495
Z mean eval                  0.8956299
Z variance eval              0.020250004
total_rewards                [ -18.58463835  986.77186995    9.26644327 2070.37597024 1943.3595965
 2098.77237502  964.14407818  288.81174051 1252.60945754 1894.11491885]
total_rewards_mean           1148.9641811702663
total_rewards_std            800.6621977100215
total_rewards_max            2098.7723750247596
total_rewards_min            -18.584638348414156
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               34.141108848154545
(Previous) Eval Time (s)     27.607625593896955
Sample Time (s)              26.52246670657769
Epoch Time (s)               88.27120114862919
Total Train Time (s)         14366.559154746588
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:45:47.360703 UTC | [2020_01_10_11_46_20] Iteration #160 | Epoch Duration: 88.40342330932617
2020-01-10 15:45:47.360885 UTC | [2020_01_10_11_46_20] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.896478
Z variance train             0.020464707
KL Divergence                19.271496
KL Loss                      1.9271497
QF Loss                      391.88318
VF Loss                      69.88752
Policy Loss                  -674.8767
Q Predictions Mean           670.6894
Q Predictions Std            160.67307
Q Predictions Max            842.98193
Q Predictions Min            184.03719
V Predictions Mean           672.6106
V Predictions Std            157.94724
V Predictions Max            832.1867
V Predictions Min            191.598
Log Pis Mean                 -1.200259
Log Pis Std                  2.410085
Log Pis Max                  5.1313477
Log Pis Min                  -8.094713
Policy mu Mean               -0.047871668
Policy mu Std                0.52332217
Policy mu Max                1.678991
Policy mu Min                -2.0143025
Policy log std Mean          -0.8750664
Policy log std Std           0.2408381
Policy log std Max           -0.3100926
Policy log std Min           -1.8516946
Z mean eval                  0.8710019
Z variance eval              0.018315885
total_rewards                [1851.42263007 1956.2580426  1952.97280119 1775.63628455 1949.66071109
  492.6947852   881.69546833 1914.75134231 1859.17976408  875.53025936]
total_rewards_mean           1550.9802088773465
total_rewards_std            536.3757498209686
total_rewards_max            1956.2580426026154
total_rewards_min            492.69478519891993
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               33.188287679106
(Previous) Eval Time (s)     27.739420772064477
Sample Time (s)              25.585308549925685
Epoch Time (s)               86.51301700109616
Total Train Time (s)         14459.460396197159
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:47:20.264617 UTC | [2020_01_10_11_46_20] Iteration #161 | Epoch Duration: 92.9035952091217
2020-01-10 15:47:20.264798 UTC | [2020_01_10_11_46_20] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87218696
Z variance train             0.018345382
KL Divergence                19.018543
KL Loss                      1.9018544
QF Loss                      256.97766
VF Loss                      43.418392
Policy Loss                  -667.73315
Q Predictions Mean           663.6102
Q Predictions Std            171.98898
Q Predictions Max            857.9113
Q Predictions Min            150.54254
V Predictions Mean           667.07336
V Predictions Std            171.1928
V Predictions Max            856.70557
V Predictions Min            170.73305
Log Pis Mean                 -1.124317
Log Pis Std                  2.4278054
Log Pis Max                  9.897152
Log Pis Min                  -7.2592955
Policy mu Mean               0.0014939854
Policy mu Std                0.5116983
Policy mu Max                2.2539737
Policy mu Min                -1.8557801
Policy log std Mean          -0.8764149
Policy log std Std           0.23043714
Policy log std Max           0.07735646
Policy log std Min           -1.7714789
Z mean eval                  0.87652063
Z variance eval              0.015690804
total_rewards                [ 413.78064997  943.17151681 2077.13197619 1256.19389167 2030.02986176
 2041.75259048 1125.93367155 2072.69906726 2009.23967756 1765.34205359]
total_rewards_mean           1573.5274956836824
total_rewards_std            565.7259994243948
total_rewards_max            2077.1319761909544
total_rewards_min            413.7806499653319
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               33.56727986084297
(Previous) Eval Time (s)     34.12956944294274
Sample Time (s)              26.613721147645265
Epoch Time (s)               94.31057045143098
Total Train Time (s)         14552.873051146977
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:48:53.679440 UTC | [2020_01_10_11_46_20] Iteration #162 | Epoch Duration: 93.41450762748718
2020-01-10 15:48:53.679627 UTC | [2020_01_10_11_46_20] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8764676
Z variance train             0.01571836
KL Divergence                19.347126
KL Loss                      1.9347126
QF Loss                      391.98047
VF Loss                      66.10339
Policy Loss                  -661.2612
Q Predictions Mean           658.84973
Q Predictions Std            160.2188
Q Predictions Max            842.784
Q Predictions Min            179.2483
V Predictions Mean           664.21204
V Predictions Std            160.1065
V Predictions Max            847.98334
V Predictions Min            180.54343
Log Pis Mean                 -1.213202
Log Pis Std                  2.4361565
Log Pis Max                  6.6683264
Log Pis Min                  -10.516875
Policy mu Mean               0.03637176
Policy mu Std                0.51062745
Policy mu Max                1.9190166
Policy mu Min                -1.5979154
Policy log std Mean          -0.88989127
Policy log std Std           0.24588695
Policy log std Max           -0.23262179
Policy log std Min           -2.0378509
Z mean eval                  0.8833785
Z variance eval              0.013444131
total_rewards                [1166.15677091 1950.35983854 1675.4471757    85.43761345 1325.62762366
 1601.95048133 1999.03038027  292.53907368 1391.89699756 1999.23821983]
total_rewards_mean           1348.7684174944402
total_rewards_std            642.343500145161
total_rewards_max            1999.2382198286978
total_rewards_min            85.43761344665661
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               33.405144948046654
(Previous) Eval Time (s)     33.23311860859394
Sample Time (s)              26.59703817497939
Epoch Time (s)               93.23530173161998
Total Train Time (s)         14646.502353467047
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:50:27.314978 UTC | [2020_01_10_11_46_20] Iteration #163 | Epoch Duration: 93.6352162361145
2020-01-10 15:50:27.315260 UTC | [2020_01_10_11_46_20] Iteration #163 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8832799
Z variance train             0.013469527
KL Divergence                19.841467
KL Loss                      1.9841467
QF Loss                      442.5254
VF Loss                      99.15997
Policy Loss                  -696.3045
Q Predictions Mean           692.5592
Q Predictions Std            163.0752
Q Predictions Max            879.98376
Q Predictions Min            23.436253
V Predictions Mean           692.63025
V Predictions Std            160.95189
V Predictions Max            882.01434
V Predictions Min            -8.6765
Log Pis Mean                 -1.2922015
Log Pis Std                  2.4972007
Log Pis Max                  11.502053
Log Pis Min                  -8.405877
Policy mu Mean               0.045783263
Policy mu Std                0.52997744
Policy mu Max                2.2455068
Policy mu Min                -2.4580863
Policy log std Mean          -0.8746058
Policy log std Std           0.24458618
Policy log std Max           0.043926537
Policy log std Min           -1.713598
Z mean eval                  0.89002895
Z variance eval              0.020019367
total_rewards                [1870.87330451 1453.54821421 1694.87696878 2069.87083178 2097.344508
 1179.36631816 1831.4857306  1864.11666101  378.9068221  1867.92457567]
total_rewards_mean           1630.8313934808903
total_rewards_std            492.5012281766566
total_rewards_max            2097.3445079953963
total_rewards_min            378.9068221046958
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               33.4053124752827
(Previous) Eval Time (s)     33.63262421404943
Sample Time (s)              25.809808848425746
Epoch Time (s)               92.84774553775787
Total Train Time (s)         14740.080252878834
Epoch                        164
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:52:00.890329 UTC | [2020_01_10_11_46_20] Iteration #164 | Epoch Duration: 93.57487463951111
2020-01-10 15:52:00.890446 UTC | [2020_01_10_11_46_20] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8886207
Z variance train             0.020012455
KL Divergence                19.148108
KL Loss                      1.9148108
QF Loss                      425.33035
VF Loss                      171.6661
Policy Loss                  -664.27026
Q Predictions Mean           662.3251
Q Predictions Std            184.64471
Q Predictions Max            874.4812
Q Predictions Min            -8.381901
V Predictions Mean           670.7163
V Predictions Std            179.08441
V Predictions Max            867.90173
V Predictions Min            -0.22660446
Log Pis Mean                 -1.3239383
Log Pis Std                  2.8240125
Log Pis Max                  13.503668
Log Pis Min                  -12.8662815
Policy mu Mean               0.03403743
Policy mu Std                0.548081
Policy mu Max                1.9529493
Policy mu Min                -2.8338714
Policy log std Mean          -0.85447776
Policy log std Std           0.25598013
Policy log std Max           0.1674453
Policy log std Min           -1.9678824
Z mean eval                  0.8951751
Z variance eval              0.021983262
total_rewards                [1814.84117212 1872.18429349 1408.43964383 1967.41618696 2088.64988139
 1429.12648701    8.49591061 1335.1785706  1873.78837668   60.94098239]
total_rewards_mean           1385.9061505085313
total_rewards_std            717.5112636334046
total_rewards_max            2088.649881386467
total_rewards_min            8.495910607489652
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               33.2778020282276
(Previous) Eval Time (s)     34.35935379890725
Sample Time (s)              25.243727786000818
Epoch Time (s)               92.88088361313567
Total Train Time (s)         14824.98484194465
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:53:25.797942 UTC | [2020_01_10_11_46_20] Iteration #165 | Epoch Duration: 84.9073839187622
2020-01-10 15:53:25.798133 UTC | [2020_01_10_11_46_20] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8959195
Z variance train             0.021938423
KL Divergence                19.158413
KL Loss                      1.9158413
QF Loss                      321.4544
VF Loss                      75.68063
Policy Loss                  -680.7557
Q Predictions Mean           678.8871
Q Predictions Std            175.53648
Q Predictions Max            874.4548
Q Predictions Min            -4.40156
V Predictions Mean           677.81067
V Predictions Std            173.72638
V Predictions Max            868.6905
V Predictions Min            27.689358
Log Pis Mean                 -1.280513
Log Pis Std                  2.4483912
Log Pis Max                  6.233071
Log Pis Min                  -9.172368
Policy mu Mean               0.033550896
Policy mu Std                0.5280198
Policy mu Max                1.9058038
Policy mu Min                -1.8097316
Policy log std Mean          -0.8435586
Policy log std Std           0.2426179
Policy log std Max           -0.2360861
Policy log std Min           -2.0076623
Z mean eval                  0.8943945
Z variance eval              0.017348845
total_rewards                [ 634.15450921 1088.55560239 2152.95635684 1973.25124335  448.70557098
  417.38899776 2007.4673055  1046.72121537 2040.97950396  211.44068152]
total_rewards_mean           1202.162098688066
total_rewards_std            733.1790175175126
total_rewards_max            2152.956356840168
total_rewards_min            211.44068152192634
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               32.988365438301116
(Previous) Eval Time (s)     26.38546631904319
Sample Time (s)              25.748450215440243
Epoch Time (s)               85.12228197278455
Total Train Time (s)         14914.781336876564
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:54:55.596229 UTC | [2020_01_10_11_46_20] Iteration #166 | Epoch Duration: 89.79797291755676
2020-01-10 15:54:55.596396 UTC | [2020_01_10_11_46_20] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89356124
Z variance train             0.01736259
KL Divergence                19.582155
KL Loss                      1.9582156
QF Loss                      279.22586
VF Loss                      46.78221
Policy Loss                  -696.7106
Q Predictions Mean           694.02924
Q Predictions Std            184.61314
Q Predictions Max            881.1938
Q Predictions Min            -0.6329043
V Predictions Mean           696.98694
V Predictions Std            185.34332
V Predictions Max            880.63727
V Predictions Min            -6.5637655
Log Pis Mean                 -1.3286673
Log Pis Std                  2.4607663
Log Pis Max                  7.4602623
Log Pis Min                  -8.964357
Policy mu Mean               0.0070879385
Policy mu Std                0.533172
Policy mu Max                1.9396014
Policy mu Min                -1.7528379
Policy log std Mean          -0.87863266
Policy log std Std           0.24649373
Policy log std Max           -0.062325656
Policy log std Min           -2.0930772
Z mean eval                  0.89708775
Z variance eval              0.017254788
total_rewards                [ 864.60760506 1640.43166011 1906.1530661   213.34777804  179.0392411
 1075.86704309 1935.87362385  976.4585016  1642.68092792 1775.01807756]
total_rewards_mean           1220.947752442083
total_rewards_std            628.4964303618347
total_rewards_max            1935.8736238472247
total_rewards_min            179.03924110416625
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.7569924662821
(Previous) Eval Time (s)     31.060768756084144
Sample Time (s)              26.230352178681642
Epoch Time (s)               90.04811340104789
Total Train Time (s)         15002.713494243566
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:56:23.532945 UTC | [2020_01_10_11_46_20] Iteration #167 | Epoch Duration: 87.9364321231842
2020-01-10 15:56:23.533130 UTC | [2020_01_10_11_46_20] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8963335
Z variance train             0.017228317
KL Divergence                19.731812
KL Loss                      1.9731811
QF Loss                      1407.7332
VF Loss                      87.731384
Policy Loss                  -685.09326
Q Predictions Mean           679.4108
Q Predictions Std            182.1241
Q Predictions Max            869.2152
Q Predictions Min            181.2549
V Predictions Mean           681.58716
V Predictions Std            180.93597
V Predictions Max            862.7856
V Predictions Min            171.54633
Log Pis Mean                 -1.296772
Log Pis Std                  2.5574198
Log Pis Max                  5.7801332
Log Pis Min                  -8.21301
Policy mu Mean               0.059446476
Policy mu Std                0.5287585
Policy mu Max                2.0333142
Policy mu Min                -1.811635
Policy log std Mean          -0.8683349
Policy log std Std           0.23883386
Policy log std Max           -0.23319104
Policy log std Min           -1.7238309
Z mean eval                  0.9005679
Z variance eval              0.012748063
total_rewards                [ 495.10865133 2043.99376616  805.28078786 2070.54926808 2007.26942811
 2209.71338301 2076.12076012 2033.45752157  592.85915992  792.74574794]
total_rewards_mean           1512.7098474081308
total_rewards_std            693.7508332368429
total_rewards_max            2209.713383013275
total_rewards_min            495.1086513260075
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               33.41829828778282
(Previous) Eval Time (s)     28.948668425902724
Sample Time (s)              26.138477813918144
Epoch Time (s)               88.50544452760369
Total Train Time (s)         15088.72535560606
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:57:49.547563 UTC | [2020_01_10_11_46_20] Iteration #168 | Epoch Duration: 86.01430225372314
2020-01-10 15:57:49.547723 UTC | [2020_01_10_11_46_20] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90053254
Z variance train             0.01275917
KL Divergence                20.118494
KL Loss                      2.0118494
QF Loss                      732.21594
VF Loss                      497.93057
Policy Loss                  -684.18115
Q Predictions Mean           681.714
Q Predictions Std            173.744
Q Predictions Max            879.0028
Q Predictions Min            173.10606
V Predictions Mean           690.1221
V Predictions Std            170.0321
V Predictions Max            900.4658
V Predictions Min            177.07649
Log Pis Mean                 -1.1549513
Log Pis Std                  2.7019362
Log Pis Max                  9.1071825
Log Pis Min                  -8.727099
Policy mu Mean               0.06496697
Policy mu Std                0.5482125
Policy mu Max                2.001621
Policy mu Min                -1.8055203
Policy log std Mean          -0.865891
Policy log std Std           0.25324705
Policy log std Max           -0.2633525
Policy log std Min           -2.518193
Z mean eval                  0.874973
Z variance eval              0.011276035
total_rewards                [-153.46253464 2047.01822539 1930.04737443 2042.20516065 1854.98455242
 2092.42158992 1036.93527268 2184.54256171 1686.63862128 2032.76579747]
total_rewards_mean           1675.4096621309982
total_rewards_std            684.3308542089104
total_rewards_max            2184.5425617145597
total_rewards_min            -153.46253464162635
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               33.08627702202648
(Previous) Eval Time (s)     26.457101409789175
Sample Time (s)              25.48660916602239
Epoch Time (s)               85.02998759783804
Total Train Time (s)         15182.586106474046
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:59:23.410236 UTC | [2020_01_10_11_46_20] Iteration #169 | Epoch Duration: 93.86239218711853
2020-01-10 15:59:23.410407 UTC | [2020_01_10_11_46_20] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87538034
Z variance train             0.011287732
KL Divergence                20.097363
KL Loss                      2.0097363
QF Loss                      366.22424
VF Loss                      130.36311
Policy Loss                  -696.04663
Q Predictions Mean           694.70703
Q Predictions Std            168.28209
Q Predictions Max            862.5216
Q Predictions Min            159.43791
V Predictions Mean           695.2864
V Predictions Std            166.52519
V Predictions Max            869.20386
V Predictions Min            163.43799
Log Pis Mean                 -0.95603096
Log Pis Std                  2.4207106
Log Pis Max                  10.552656
Log Pis Min                  -6.746687
Policy mu Mean               0.049148843
Policy mu Std                0.53849596
Policy mu Max                2.079614
Policy mu Min                -1.8286092
Policy log std Mean          -0.87399316
Policy log std Std           0.2419376
Policy log std Max           -0.26746216
Policy log std Min           -1.9226909
Z mean eval                  0.8962196
Z variance eval              0.012527155
total_rewards                [1869.64197694 2035.30182612 2081.35391651 2158.0198894  2168.87822383
 2158.93167208 1996.1374959  1939.63309136 2164.2530672  2025.44151762]
total_rewards_mean           2059.7592676958348
total_rewards_std            99.58967411233445
total_rewards_max            2168.8782238267354
total_rewards_min            1869.6419769449403
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               33.62652168003842
(Previous) Eval Time (s)     35.289128746371716
Sample Time (s)              25.250911401119083
Epoch Time (s)               94.16656182752922
Total Train Time (s)         15275.782397000119
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:00:56.609074 UTC | [2020_01_10_11_46_20] Iteration #170 | Epoch Duration: 93.19854140281677
2020-01-10 16:00:56.609246 UTC | [2020_01_10_11_46_20] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8959047
Z variance train             0.0125122275
KL Divergence                19.821192
KL Loss                      1.9821192
QF Loss                      663.20154
VF Loss                      142.26135
Policy Loss                  -692.0102
Q Predictions Mean           694.0766
Q Predictions Std            171.23685
Q Predictions Max            876.882
Q Predictions Min            200.79547
V Predictions Mean           699.40247
V Predictions Std            172.45963
V Predictions Max            876.8401
V Predictions Min            124.9878
Log Pis Mean                 -0.90627325
Log Pis Std                  2.3732603
Log Pis Max                  7.3130426
Log Pis Min                  -9.02479
Policy mu Mean               0.04644788
Policy mu Std                0.5373544
Policy mu Max                2.1598735
Policy mu Min                -1.6330603
Policy log std Mean          -0.9024648
Policy log std Std           0.2539662
Policy log std Max           -0.36733365
Policy log std Min           -2.373933
Z mean eval                  0.9114958
Z variance eval              0.015324034
total_rewards                [ -13.96365928 1982.1235013  1794.80915165 2019.23009213 1930.62943219
 1990.60669162 2026.19045254 1605.82669192  320.94322492 2120.01593037]
total_rewards_mean           1577.6411509366565
total_rewards_std            728.6677446525366
total_rewards_max            2120.0159303714017
total_rewards_min            -13.963659275564924
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               33.367473979946226
(Previous) Eval Time (s)     34.320719372015446
Sample Time (s)              25.787222829647362
Epoch Time (s)               93.47541618160903
Total Train Time (s)         15366.139821637888
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:02:26.969378 UTC | [2020_01_10_11_46_20] Iteration #171 | Epoch Duration: 90.35997271537781
2020-01-10 16:02:26.969601 UTC | [2020_01_10_11_46_20] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9126717
Z variance train             0.015298298
KL Divergence                19.349415
KL Loss                      1.9349415
QF Loss                      570.41345
VF Loss                      129.0682
Policy Loss                  -708.2089
Q Predictions Mean           705.53174
Q Predictions Std            175.42477
Q Predictions Max            899.6676
Q Predictions Min            151.3631
V Predictions Mean           708.7046
V Predictions Std            174.79851
V Predictions Max            908.422
V Predictions Min            165.63896
Log Pis Mean                 -1.1868309
Log Pis Std                  2.3873558
Log Pis Max                  4.177231
Log Pis Min                  -7.32183
Policy mu Mean               0.020772088
Policy mu Std                0.54692155
Policy mu Max                2.1200688
Policy mu Min                -2.228482
Policy log std Mean          -0.86228967
Policy log std Std           0.23466922
Policy log std Max           -0.22183502
Policy log std Min           -1.9818411
Z mean eval                  0.8981126
Z variance eval              0.013109243
total_rewards                [1669.83037542 1714.10642336  458.46979701 2156.55439104 2074.53228296
 1985.18624642 2021.50396453 2008.69289737 2001.63698613  203.6923232 ]
total_rewards_mean           1629.4205687430501
total_rewards_std            667.181913605984
total_rewards_max            2156.5543910369774
total_rewards_min            203.69232320358236
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               33.159325597807765
(Previous) Eval Time (s)     31.204887309111655
Sample Time (s)              26.709704326931387
Epoch Time (s)               91.0739172338508
Total Train Time (s)         15461.104214779101
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:04:01.936986 UTC | [2020_01_10_11_46_20] Iteration #172 | Epoch Duration: 94.96716475486755
2020-01-10 16:04:01.937309 UTC | [2020_01_10_11_46_20] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8968798
Z variance train             0.013109298
KL Divergence                19.63186
KL Loss                      1.9631861
QF Loss                      1168.915
VF Loss                      76.9954
Policy Loss                  -695.5908
Q Predictions Mean           690.3054
Q Predictions Std            170.6974
Q Predictions Max            872.0738
Q Predictions Min            160.72688
V Predictions Mean           691.34595
V Predictions Std            169.91415
V Predictions Max            866.218
V Predictions Min            165.07066
Log Pis Mean                 -1.1986548
Log Pis Std                  2.5580301
Log Pis Max                  5.782739
Log Pis Min                  -10.556219
Policy mu Mean               0.008478999
Policy mu Std                0.5542853
Policy mu Max                1.8983667
Policy mu Min                -1.9554108
Policy log std Mean          -0.8721148
Policy log std Std           0.24499592
Policy log std Max           -0.30780166
Policy log std Min           -1.9290006
Z mean eval                  0.905371
Z variance eval              0.00847563
total_rewards                [2035.28298897 1854.47013437 1977.62872349 1004.10804864 2052.94616671
 2083.32485697 1994.91771459 2055.54977373  258.38070631  361.29612591]
total_rewards_mean           1567.7905239698816
total_rewards_std            698.435455760363
total_rewards_max            2083.3248569736415
total_rewards_min            258.3807063105231
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               33.098606436979026
(Previous) Eval Time (s)     35.097761961165816
Sample Time (s)              25.88055933220312
Epoch Time (s)               94.07692773034796
Total Train Time (s)         15553.460959386546
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:05:34.295620 UTC | [2020_01_10_11_46_20] Iteration #173 | Epoch Duration: 92.3581109046936
2020-01-10 16:05:34.295855 UTC | [2020_01_10_11_46_20] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90607727
Z variance train             0.008480728
KL Divergence                20.533596
KL Loss                      2.0533597
QF Loss                      354.54498
VF Loss                      111.37489
Policy Loss                  -728.55035
Q Predictions Mean           724.5491
Q Predictions Std            171.87839
Q Predictions Max            915.5632
Q Predictions Min            92.03622
V Predictions Mean           723.6331
V Predictions Std            170.75893
V Predictions Max            905.9559
V Predictions Min            84.29711
Log Pis Mean                 -0.966213
Log Pis Std                  2.5322828
Log Pis Max                  7.4102488
Log Pis Min                  -7.714592
Policy mu Mean               0.09920123
Policy mu Std                0.5566564
Policy mu Max                2.7981796
Policy mu Min                -2.497728
Policy log std Mean          -0.87594587
Policy log std Std           0.24775696
Policy log std Max           -0.1191895
Policy log std Min           -1.8783526
Z mean eval                  0.9253408
Z variance eval              0.012642746
total_rewards                [1858.93233895 2004.20002473 1930.53212124 1855.57907658 1987.26180781
 1995.4934233  2086.28008399 2178.81997101 2024.7825763  2075.48118112]
total_rewards_mean           1999.736260500993
total_rewards_std            95.66358210429742
total_rewards_max            2178.81997100887
total_rewards_min            1855.5790765765562
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               33.117688555736095
(Previous) Eval Time (s)     33.37855855515227
Sample Time (s)              26.57753404043615
Epoch Time (s)               93.07378115132451
Total Train Time (s)         15647.73866597144
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:07:08.576081 UTC | [2020_01_10_11_46_20] Iteration #174 | Epoch Duration: 94.27993655204773
2020-01-10 16:07:08.576336 UTC | [2020_01_10_11_46_20] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92545587
Z variance train             0.012700233
KL Divergence                20.349144
KL Loss                      2.0349145
QF Loss                      395.52576
VF Loss                      62.766388
Policy Loss                  -739.27045
Q Predictions Mean           739.6882
Q Predictions Std            157.47371
Q Predictions Max            906.0702
Q Predictions Min            -9.4700985
V Predictions Mean           741.7935
V Predictions Std            157.33406
V Predictions Max            901.8821
V Predictions Min            2.5066807
Log Pis Mean                 -1.3531168
Log Pis Std                  2.3549116
Log Pis Max                  5.4695063
Log Pis Min                  -7.5514946
Policy mu Mean               -0.033321403
Policy mu Std                0.545995
Policy mu Max                2.1073363
Policy mu Min                -1.8021834
Policy log std Mean          -0.87000275
Policy log std Std           0.23993894
Policy log std Max           -0.19460374
Policy log std Min           -1.8177543
Z mean eval                  0.9222437
Z variance eval              0.0130377235
total_rewards                [1998.28380507 2047.74841741 1339.85319489 1969.73101047 1986.00751504
 2018.52131069 1334.11559729 2002.6275659  1479.52117114 2045.33686723]
total_rewards_mean           1822.1746455134012
total_rewards_std            289.77158573727587
total_rewards_max            2047.7484174111587
total_rewards_min            1334.1155972945808
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               32.95836262498051
(Previous) Eval Time (s)     34.584472252987325
Sample Time (s)              25.667747444007546
Epoch Time (s)               93.21058232197538
Total Train Time (s)         15738.822332271375
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:08:39.661795 UTC | [2020_01_10_11_46_20] Iteration #175 | Epoch Duration: 91.08531093597412
2020-01-10 16:08:39.661967 UTC | [2020_01_10_11_46_20] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9222205
Z variance train             0.013038513
KL Divergence                19.720602
KL Loss                      1.9720602
QF Loss                      470.42722
VF Loss                      252.37772
Policy Loss                  -716.7301
Q Predictions Mean           716.66986
Q Predictions Std            169.3833
Q Predictions Max            903.2647
Q Predictions Min            155.18346
V Predictions Mean           712.1675
V Predictions Std            172.73949
V Predictions Max            894.37305
V Predictions Min            143.04228
Log Pis Mean                 -1.1289138
Log Pis Std                  2.5646188
Log Pis Max                  6.8444304
Log Pis Min                  -9.060198
Policy mu Mean               0.0104895495
Policy mu Std                0.5832536
Policy mu Max                2.0182362
Policy mu Min                -2.0157852
Policy log std Mean          -0.857455
Policy log std Std           0.24516053
Policy log std Max           -0.06466347
Policy log std Min           -2.0674613
Z mean eval                  0.8821796
Z variance eval              0.011891583
total_rewards                [1333.87810241 2235.82095926  680.68703065  435.32352127 1021.89625408
 2360.33238618 2067.53571033  414.461431   2198.65946268 2028.96148666]
total_rewards_mean           1477.7556344521813
total_rewards_std            748.7363801833479
total_rewards_max            2360.3323861807376
total_rewards_min            414.4614309962513
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               32.82524145999923
(Previous) Eval Time (s)     32.45887485006824
Sample Time (s)              26.28525183768943
Epoch Time (s)               91.5693681477569
Total Train Time (s)         15826.543239884079
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:10:07.386222 UTC | [2020_01_10_11_46_20] Iteration #176 | Epoch Duration: 87.72410774230957
2020-01-10 16:10:07.386454 UTC | [2020_01_10_11_46_20] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8814074
Z variance train             0.011889337
KL Divergence                19.793846
KL Loss                      1.9793847
QF Loss                      373.75592
VF Loss                      467.0086
Policy Loss                  -686.4649
Q Predictions Mean           689.00476
Q Predictions Std            197.98575
Q Predictions Max            922.0689
Q Predictions Min            78.01744
V Predictions Mean           705.8345
V Predictions Std            199.51593
V Predictions Max            934.3038
V Predictions Min            142.34642
Log Pis Mean                 -0.9214647
Log Pis Std                  2.5907202
Log Pis Max                  7.1971426
Log Pis Min                  -6.083194
Policy mu Mean               0.04121039
Policy mu Std                0.52431494
Policy mu Max                1.9143419
Policy mu Min                -1.8923125
Policy log std Mean          -0.89072245
Policy log std Std           0.27849612
Policy log std Max           -0.23487973
Policy log std Min           -2.0287447
Z mean eval                  0.92008543
Z variance eval              0.01828879
total_rewards                [2091.65284933 2004.83378473  306.7607064  2115.67474882 2019.24177966
 1957.99554452 1211.36495736 1676.37034339 1970.41770961 1894.82429131]
total_rewards_mean           1724.9136715139223
total_rewards_std            535.9936314052313
total_rewards_max            2115.6747488215506
total_rewards_min            306.7607063975172
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               33.00405262084678
(Previous) Eval Time (s)     28.613252853043377
Sample Time (s)              24.9305361318402
Epoch Time (s)               86.54784160573035
Total Train Time (s)         15913.769384971354
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:11:34.614970 UTC | [2020_01_10_11_46_20] Iteration #177 | Epoch Duration: 87.22837018966675
2020-01-10 16:11:34.615141 UTC | [2020_01_10_11_46_20] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92026556
Z variance train             0.018264463
KL Divergence                19.18396
KL Loss                      1.918396
QF Loss                      461.30206
VF Loss                      97.34099
Policy Loss                  -707.4787
Q Predictions Mean           705.12946
Q Predictions Std            198.16238
Q Predictions Max            907.61847
Q Predictions Min            31.486437
V Predictions Mean           713.29456
V Predictions Std            197.87932
V Predictions Max            914.20306
V Predictions Min            22.658617
Log Pis Mean                 -0.89340496
Log Pis Std                  2.4769983
Log Pis Max                  5.407476
Log Pis Min                  -8.629667
Policy mu Mean               -0.021606313
Policy mu Std                0.55043644
Policy mu Max                2.3895376
Policy mu Min                -1.9591633
Policy log std Mean          -0.85783285
Policy log std Std           0.24711712
Policy log std Max           -0.13192809
Policy log std Min           -1.7726797
Z mean eval                  0.8971413
Z variance eval              0.020456055
total_rewards                [ -20.25294097 2173.35014152   19.49253689 2249.77471416   99.09080031
  981.29607074 2394.04448656  409.35839735 2335.75014678 2349.01228262]
total_rewards_mean           1299.0916635958151
total_rewards_std            1037.0490565470163
total_rewards_max            2394.0444865621294
total_rewards_min            -20.25294097244817
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               33.73085593665019
(Previous) Eval Time (s)     29.2932463362813
Sample Time (s)              24.79231923725456
Epoch Time (s)               87.81642151018605
Total Train Time (s)         15999.685545131098
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:13:00.531734 UTC | [2020_01_10_11_46_20] Iteration #178 | Epoch Duration: 85.91647410392761
2020-01-10 16:13:00.531875 UTC | [2020_01_10_11_46_20] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89819944
Z variance train             0.02040539
KL Divergence                19.090376
KL Loss                      1.9090376
QF Loss                      602.3313
VF Loss                      89.43536
Policy Loss                  -741.26514
Q Predictions Mean           739.41486
Q Predictions Std            168.1622
Q Predictions Max            909.2943
Q Predictions Min            152.17592
V Predictions Mean           747.4253
V Predictions Std            165.2311
V Predictions Max            920.8915
V Predictions Min            155.39151
Log Pis Mean                 -1.1758986
Log Pis Std                  2.4818037
Log Pis Max                  6.2146883
Log Pis Min                  -9.276619
Policy mu Mean               -0.015240394
Policy mu Std                0.52295077
Policy mu Max                1.9803696
Policy mu Min                -1.6705005
Policy log std Mean          -0.9152026
Policy log std Std           0.24473101
Policy log std Max           -0.25760585
Policy log std Min           -2.0661325
Z mean eval                  0.9119035
Z variance eval              0.020845419
total_rewards                [2088.56867938 2139.96797369  103.97578088  606.7547397  2168.30263773
  619.29999343 2028.68301699 2308.99617386 2065.12124308 2202.58748075]
total_rewards_mean           1633.225771947599
total_rewards_std            793.377866872979
total_rewards_max            2308.996173855061
total_rewards_min            103.97578087708595
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               32.84842339064926
(Previous) Eval Time (s)     27.392907991074026
Sample Time (s)              26.088151738978922
Epoch Time (s)               86.3294831207022
Total Train Time (s)         16088.461873722263
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:14:29.311823 UTC | [2020_01_10_11_46_20] Iteration #179 | Epoch Duration: 88.77982568740845
2020-01-10 16:14:29.312061 UTC | [2020_01_10_11_46_20] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9111215
Z variance train             0.02082077
KL Divergence                18.989338
KL Loss                      1.8989338
QF Loss                      696.0332
VF Loss                      79.15761
Policy Loss                  -717.7238
Q Predictions Mean           715.99426
Q Predictions Std            187.71756
Q Predictions Max            911.56915
Q Predictions Min            144.84233
V Predictions Mean           721.5976
V Predictions Std            185.32597
V Predictions Max            914.6426
V Predictions Min            166.07123
Log Pis Mean                 -0.94191176
Log Pis Std                  2.4945552
Log Pis Max                  7.294641
Log Pis Min                  -6.47297
Policy mu Mean               0.009892209
Policy mu Std                0.5803156
Policy mu Max                1.9243027
Policy mu Min                -1.7272723
Policy log std Mean          -0.87099934
Policy log std Std           0.2650209
Policy log std Max           -0.18516639
Policy log std Min           -2.060707
Z mean eval                  0.9185359
Z variance eval              0.0153133925
total_rewards                [1024.86957603 2189.6845173  2255.61448056 2196.90295987 2182.26205338
 2137.21259957 2352.88951042 -100.70761171 2181.76004035 2022.26440892]
total_rewards_mean           1844.2752534700492
total_rewards_std            739.6992481777015
total_rewards_max            2352.889510417448
total_rewards_min            -100.70761171316047
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               32.9983972790651
(Previous) Eval Time (s)     29.842877177055925
Sample Time (s)              24.322804931551218
Epoch Time (s)               87.16407938767225
Total Train Time (s)         16180.078818225302
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:16:00.930771 UTC | [2020_01_10_11_46_20] Iteration #180 | Epoch Duration: 91.61856770515442
2020-01-10 16:16:00.930944 UTC | [2020_01_10_11_46_20] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91533244
Z variance train             0.015331408
KL Divergence                19.484612
KL Loss                      1.9484612
QF Loss                      397.41998
VF Loss                      98.8658
Policy Loss                  -719.9687
Q Predictions Mean           715.9702
Q Predictions Std            196.2382
Q Predictions Max            927.4783
Q Predictions Min            67.991745
V Predictions Mean           723.7515
V Predictions Std            193.57185
V Predictions Max            940.82214
V Predictions Min            56.663433
Log Pis Mean                 -0.99973357
Log Pis Std                  2.4641771
Log Pis Max                  8.056545
Log Pis Min                  -8.417016
Policy mu Mean               0.05102268
Policy mu Std                0.5692322
Policy mu Max                1.9549285
Policy mu Min                -2.3518097
Policy log std Mean          -0.8487795
Policy log std Std           0.254702
Policy log std Max           -0.20402473
Policy log std Min           -2.2643964
Z mean eval                  0.9033577
Z variance eval              0.013456091
total_rewards                [2163.77721428 1983.61648175  764.43516398 2273.69067334 1581.42565601
 2144.71035468 2295.88795452 2364.0490259  1800.24825905  470.98513363]
total_rewards_mean           1784.2825917134403
total_rewards_std            629.0701554316628
total_rewards_max            2364.049025898584
total_rewards_min            470.9851336336847
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               33.61861295485869
(Previous) Eval Time (s)     34.297051567118615
Sample Time (s)              25.21934060426429
Epoch Time (s)               93.1350051262416
Total Train Time (s)         16272.021032857243
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:17:32.875310 UTC | [2020_01_10_11_46_20] Iteration #181 | Epoch Duration: 91.94424510002136
2020-01-10 16:17:32.875482 UTC | [2020_01_10_11_46_20] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.905049
Z variance train             0.01344662
KL Divergence                19.893927
KL Loss                      1.9893926
QF Loss                      328.98074
VF Loss                      144.38239
Policy Loss                  -728.2497
Q Predictions Mean           723.8037
Q Predictions Std            190.9229
Q Predictions Max            912.34924
Q Predictions Min            -34.158276
V Predictions Mean           721.72107
V Predictions Std            186.98822
V Predictions Max            902.8492
V Predictions Min            -18.340136
Log Pis Mean                 -0.9163867
Log Pis Std                  2.618474
Log Pis Max                  7.262369
Log Pis Min                  -8.464299
Policy mu Mean               0.043635637
Policy mu Std                0.5502888
Policy mu Max                2.2831113
Policy mu Min                -1.8525501
Policy log std Mean          -0.88760686
Policy log std Std           0.26700553
Policy log std Max           -0.07599068
Policy log std Min           -2.114885
Z mean eval                  0.90891695
Z variance eval              0.015040249
total_rewards                [2136.27180485 2058.01129178 1475.02498047  198.47397995 1883.75588425
 2076.85172719 2172.55993589 2120.70357332 2196.69307585 1953.23874773]
total_rewards_mean           1827.1585001272626
total_rewards_std            578.6992477406558
total_rewards_max            2196.6930758483973
total_rewards_min            198.47397994651104
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               33.57767737377435
(Previous) Eval Time (s)     33.10590993799269
Sample Time (s)              26.348687963560224
Epoch Time (s)               93.03227527532727
Total Train Time (s)         16362.881978251971
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:19:03.740040 UTC | [2020_01_10_11_46_20] Iteration #182 | Epoch Duration: 90.86433911323547
2020-01-10 16:19:03.740255 UTC | [2020_01_10_11_46_20] Iteration #182 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90640175
Z variance train             0.0152039705
KL Divergence                19.255402
KL Loss                      1.9255402
QF Loss                      250.4594
VF Loss                      51.104076
Policy Loss                  -736.34985
Q Predictions Mean           733.10065
Q Predictions Std            185.48709
Q Predictions Max            907.0895
Q Predictions Min            153.61668
V Predictions Mean           734.2561
V Predictions Std            183.49466
V Predictions Max            901.24274
V Predictions Min            160.02298
Log Pis Mean                 -1.0286202
Log Pis Std                  2.5029402
Log Pis Max                  7.332876
Log Pis Min                  -7.48548
Policy mu Mean               -0.06421092
Policy mu Std                0.5619955
Policy mu Max                1.8411747
Policy mu Min                -1.822123
Policy log std Mean          -0.86319554
Policy log std Std           0.24315083
Policy log std Max           -0.27975556
Policy log std Min           -1.9504256
Z mean eval                  0.8869324
Z variance eval              0.016622167
total_rewards                [2140.25395054 2076.61744599 2291.62767508 2047.19798174 2083.5049955
 2051.94430398 2096.59669641 2220.66939501 2117.1791092  2032.28325357]
total_rewards_mean           2115.7874807021003
total_rewards_std            78.24237847060309
total_rewards_max            2291.6276750794223
total_rewards_min            2032.2832535674497
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               33.01823591301218
(Previous) Eval Time (s)     30.93752636713907
Sample Time (s)              26.846740138251334
Epoch Time (s)               90.80250241840258
Total Train Time (s)         16457.556317495648
Epoch                        183
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:20:38.417598 UTC | [2020_01_10_11_46_20] Iteration #183 | Epoch Duration: 94.67710638046265
2020-01-10 16:20:38.417927 UTC | [2020_01_10_11_46_20] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8858673
Z variance train             0.01659825
KL Divergence                19.4259
KL Loss                      1.94259
QF Loss                      877.6355
VF Loss                      165.08736
Policy Loss                  -745.1621
Q Predictions Mean           741.5984
Q Predictions Std            175.83742
Q Predictions Max            929.5348
Q Predictions Min            -4.8114104
V Predictions Mean           739.18567
V Predictions Std            175.43364
V Predictions Max            920.1269
V Predictions Min            -5.625531
Log Pis Mean                 -1.1123428
Log Pis Std                  2.5271304
Log Pis Max                  9.836623
Log Pis Min                  -7.7252297
Policy mu Mean               -0.022505179
Policy mu Std                0.5418731
Policy mu Max                1.8756862
Policy mu Min                -1.8908722
Policy log std Mean          -0.88635325
Policy log std Std           0.2537835
Policy log std Max           -0.29749453
Policy log std Min           -2.4152622
Z mean eval                  0.9175075
Z variance eval              0.011013793
total_rewards                [1488.06742132 2157.72658004  304.96078054 2176.64435869  808.43355167
  500.86973642 2273.19538438  235.4903261  1008.63195863 2109.18243842]
total_rewards_mean           1306.3202536217862
total_rewards_std            789.2706489138628
total_rewards_max            2273.195384383348
total_rewards_min            235.49032610427932
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               33.06232785014436
(Previous) Eval Time (s)     34.81167731899768
Sample Time (s)              26.000720955897123
Epoch Time (s)               93.87472612503916
Total Train Time (s)         16542.900083414745
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:22:03.761998 UTC | [2020_01_10_11_46_20] Iteration #184 | Epoch Duration: 85.3439245223999
2020-01-10 16:22:03.762134 UTC | [2020_01_10_11_46_20] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9168652
Z variance train             0.01101117
KL Divergence                20.317398
KL Loss                      2.03174
QF Loss                      278.66272
VF Loss                      66.94409
Policy Loss                  -740.3924
Q Predictions Mean           739.4866
Q Predictions Std            179.92232
Q Predictions Max            984.0465
Q Predictions Min            184.00072
V Predictions Mean           744.577
V Predictions Std            179.65758
V Predictions Max            981.5089
V Predictions Min            184.05621
Log Pis Mean                 -0.84738004
Log Pis Std                  2.3469748
Log Pis Max                  5.409837
Log Pis Min                  -6.7233315
Policy mu Mean               -0.01762469
Policy mu Std                0.5589637
Policy mu Max                2.0779378
Policy mu Min                -2.2677288
Policy log std Mean          -0.8667395
Policy log std Std           0.2536651
Policy log std Max           -0.22196233
Policy log std Min           -2.0848975
Z mean eval                  0.8988117
Z variance eval              0.008249697
total_rewards                [2227.83618899 2173.98735726  145.68549604 1930.43259628 2167.37082643
 2089.41478466 2269.55774011 2180.82047725   -8.75700192 2015.91495014]
total_rewards_mean           1719.226341524291
total_rewards_std            831.4979107435234
total_rewards_max            2269.5577401079763
total_rewards_min            -8.757001916285201
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               33.62231457885355
(Previous) Eval Time (s)     26.28051355527714
Sample Time (s)              25.29518312960863
Epoch Time (s)               85.19801126373932
Total Train Time (s)         16636.417394865304
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:23:37.282626 UTC | [2020_01_10_11_46_20] Iteration #185 | Epoch Duration: 93.52037072181702
2020-01-10 16:23:37.282841 UTC | [2020_01_10_11_46_20] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8987193
Z variance train             0.008257173
KL Divergence                20.80885
KL Loss                      2.080885
QF Loss                      346.5711
VF Loss                      97.56282
Policy Loss                  -716.6808
Q Predictions Mean           715.08923
Q Predictions Std            194.55002
Q Predictions Max            906.333
Q Predictions Min            143.28035
V Predictions Mean           722.9393
V Predictions Std            193.64487
V Predictions Max            912.0956
V Predictions Min            154.95856
Log Pis Mean                 -1.4943795
Log Pis Std                  2.4737973
Log Pis Max                  5.7669687
Log Pis Min                  -7.390543
Policy mu Mean               0.0377722
Policy mu Std                0.52778554
Policy mu Max                1.9574779
Policy mu Min                -1.7143829
Policy log std Mean          -0.86464345
Policy log std Std           0.24225745
Policy log std Max           -0.22576147
Policy log std Min           -1.9629183
Z mean eval                  0.9076406
Z variance eval              0.008731891
total_rewards                [ 586.4267519  2231.76080114 2207.27051303 1026.08059525 1766.46319268
 2211.04094949 2339.11153793  849.88519599 2231.05819683 2246.21303091]
total_rewards_mean           1769.5310765156996
total_rewards_std            645.2185978011656
total_rewards_max            2339.111537934547
total_rewards_min            586.4267519049832
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               34.9740912085399
(Previous) Eval Time (s)     34.60248776618391
Sample Time (s)              26.851115773897618
Epoch Time (s)               96.42769474862143
Total Train Time (s)         16729.006365203764
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:25:09.874790 UTC | [2020_01_10_11_46_20] Iteration #186 | Epoch Duration: 92.59173512458801
2020-01-10 16:25:09.875094 UTC | [2020_01_10_11_46_20] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90885735
Z variance train             0.00872496
KL Divergence                21.545378
KL Loss                      2.154538
QF Loss                      525.08704
VF Loss                      113.979744
Policy Loss                  -720.8835
Q Predictions Mean           717.7716
Q Predictions Std            203.91374
Q Predictions Max            931.76953
Q Predictions Min            164.52492
V Predictions Mean           727.60693
V Predictions Std            203.58987
V Predictions Max            932.9928
V Predictions Min            163.77559
Log Pis Mean                 -1.4122629
Log Pis Std                  2.735423
Log Pis Max                  7.3807225
Log Pis Min                  -8.153862
Policy mu Mean               0.0006041927
Policy mu Std                0.55021954
Policy mu Max                2.2008753
Policy mu Min                -1.6953049
Policy log std Mean          -0.8346125
Policy log std Std           0.25063682
Policy log std Max           -0.2980944
Policy log std Min           -2.0474281
Z mean eval                  0.9456247
Z variance eval              0.006467686
total_rewards                [2036.47201082 2276.56928427 1616.82279943 2108.43766545 2247.55445829
 2060.8196745  1962.33675978 2161.30503627 1614.98392332 2026.93325432]
total_rewards_mean           2011.2234866448293
total_rewards_std            218.29508947230843
total_rewards_max            2276.569284269505
total_rewards_min            1614.9839233194232
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               36.34325062483549
(Previous) Eval Time (s)     30.766141884960234
Sample Time (s)              27.11421458935365
Epoch Time (s)               94.22360709914938
Total Train Time (s)         16827.39517243672
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:26:48.265639 UTC | [2020_01_10_11_46_20] Iteration #187 | Epoch Duration: 98.39034795761108
2020-01-10 16:26:48.265824 UTC | [2020_01_10_11_46_20] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9480028
Z variance train             0.006461716
KL Divergence                22.314953
KL Loss                      2.2314954
QF Loss                      717.02
VF Loss                      393.09024
Policy Loss                  -773.07275
Q Predictions Mean           767.1748
Q Predictions Std            168.954
Q Predictions Max            932.1892
Q Predictions Min            108.84167
V Predictions Mean           755.9106
V Predictions Std            164.21362
V Predictions Max            933.6194
V Predictions Min            142.57591
Log Pis Mean                 -0.6831291
Log Pis Std                  2.7775724
Log Pis Max                  6.754839
Log Pis Min                  -8.094645
Policy mu Mean               0.060371608
Policy mu Std                0.62295675
Policy mu Max                2.1378171
Policy mu Min                -1.8012516
Policy log std Mean          -0.8597697
Policy log std Std           0.26448798
Policy log std Max           -0.24019986
Policy log std Min           -1.9882334
Z mean eval                  0.9373859
Z variance eval              0.0065194345
total_rewards                [ 877.80491921 2424.64489538 1346.86518994 2198.15557553  676.26067188
 2081.39253878 2344.57531438 2101.2453841   787.27415415 1140.36177337]
total_rewards_mean           1597.8580416716807
total_rewards_std            662.2604804322367
total_rewards_max            2424.644895382789
total_rewards_min            676.2606718750097
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               35.82177894702181
(Previous) Eval Time (s)     34.93247222388163
Sample Time (s)              26.387386155314744
Epoch Time (s)               97.14163732621819
Total Train Time (s)         16920.75976903364
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:28:21.633949 UTC | [2020_01_10_11_46_20] Iteration #188 | Epoch Duration: 93.36798071861267
2020-01-10 16:28:21.634206 UTC | [2020_01_10_11_46_20] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9398365
Z variance train             0.006507213
KL Divergence                22.143002
KL Loss                      2.2143002
QF Loss                      1020.35876
VF Loss                      172.44759
Policy Loss                  -767.53845
Q Predictions Mean           763.5771
Q Predictions Std            178.202
Q Predictions Max            954.1427
Q Predictions Min            143.02281
V Predictions Mean           763.9246
V Predictions Std            173.19228
V Predictions Max            949.5115
V Predictions Min            147.98077
Log Pis Mean                 -0.9093384
Log Pis Std                  2.5535164
Log Pis Max                  6.780176
Log Pis Min                  -7.9073243
Policy mu Mean               -0.012346252
Policy mu Std                0.5671143
Policy mu Max                2.0522292
Policy mu Min                -2.1301796
Policy log std Mean          -0.8763232
Policy log std Std           0.25077665
Policy log std Max           -0.35614187
Policy log std Min           -2.0083084
Z mean eval                  0.91339034
Z variance eval              0.009792295
total_rewards                [ 116.89802381 2005.92625009  199.63851078  559.64605423 2356.72613796
 2198.15799244  971.25248669 2195.49613    2300.0443782  2027.44330471]
total_rewards_mean           1493.122926891107
total_rewards_std            874.4498588256964
total_rewards_max            2356.726137955109
total_rewards_min            116.8980238135477
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               36.03024202026427
(Previous) Eval Time (s)     31.158387045841664
Sample Time (s)              27.02795839589089
Epoch Time (s)               94.21658746199682
Total Train Time (s)         17015.24277726561
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:29:56.119414 UTC | [2020_01_10_11_46_20] Iteration #189 | Epoch Duration: 94.48501396179199
2020-01-10 16:29:56.119617 UTC | [2020_01_10_11_46_20] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9123403
Z variance train             0.00982063
KL Divergence                21.157022
KL Loss                      2.1157024
QF Loss                      400.28394
VF Loss                      59.566128
Policy Loss                  -740.7705
Q Predictions Mean           738.0073
Q Predictions Std            190.1264
Q Predictions Max            932.0252
Q Predictions Min            -47.956577
V Predictions Mean           743.9397
V Predictions Std            189.21606
V Predictions Max            926.7494
V Predictions Min            6.9484982
Log Pis Mean                 -1.0853623
Log Pis Std                  2.3719704
Log Pis Max                  5.285795
Log Pis Min                  -8.984848
Policy mu Mean               0.024489176
Policy mu Std                0.5519287
Policy mu Max                1.8717136
Policy mu Min                -2.5163352
Policy log std Mean          -0.856023
Policy log std Std           0.24082738
Policy log std Max           -0.0035779476
Policy log std Min           -1.9889847
Z mean eval                  0.958693
Z variance eval              0.009226221
total_rewards                [2121.8873057  1410.91232779 2165.12378626 2175.24567035  279.10774579
   36.04811984 1270.03596462 2317.34419937 2064.33672801  492.31338568]
total_rewards_mean           1433.2355233395556
total_rewards_std            832.8882340479083
total_rewards_max            2317.344199365432
total_rewards_min            36.04811983867595
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               36.11458501173183
(Previous) Eval Time (s)     31.42640885198489
Sample Time (s)              25.927449638023973
Epoch Time (s)               93.4684435017407
Total Train Time (s)         17102.51210347656
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:31:23.391256 UTC | [2020_01_10_11_46_20] Iteration #190 | Epoch Duration: 87.27151322364807
2020-01-10 16:31:23.391428 UTC | [2020_01_10_11_46_20] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9615003
Z variance train             0.0091996435
KL Divergence                22.122437
KL Loss                      2.2122438
QF Loss                      550.8555
VF Loss                      82.912994
Policy Loss                  -738.6203
Q Predictions Mean           734.67346
Q Predictions Std            209.53767
Q Predictions Max            929.4296
Q Predictions Min            -1.57728
V Predictions Mean           733.1269
V Predictions Std            207.07979
V Predictions Max            918.91656
V Predictions Min            17.36655
Log Pis Mean                 -1.1824892
Log Pis Std                  2.4683967
Log Pis Max                  7.8978386
Log Pis Min                  -9.499752
Policy mu Mean               0.019206852
Policy mu Std                0.5543038
Policy mu Max                2.0811281
Policy mu Min                -1.8848436
Policy log std Mean          -0.8369169
Policy log std Std           0.24113433
Policy log std Max           -0.26021743
Policy log std Min           -1.7900963
Z mean eval                  0.91794044
Z variance eval              0.008756986
total_rewards                [1643.94331955 1941.66607967 1917.63884581 1940.10297801 1819.79189366
 2023.37228756 1625.88011532  111.10491896 1961.45396447 1990.48305779]
total_rewards_mean           1697.5437460782189
total_rewards_std            544.8155902052939
total_rewards_max            2023.372287555778
total_rewards_min            111.10491896064828
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               35.494526245165616
(Previous) Eval Time (s)     25.22904563974589
Sample Time (s)              25.56004813266918
Epoch Time (s)               86.28362001758069
Total Train Time (s)         17199.120737278834
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:33:00.004271 UTC | [2020_01_10_11_46_20] Iteration #191 | Epoch Duration: 96.61269283294678
2020-01-10 16:33:00.004566 UTC | [2020_01_10_11_46_20] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91793644
Z variance train             0.008757642
KL Divergence                22.163786
KL Loss                      2.2163787
QF Loss                      685.9099
VF Loss                      164.69435
Policy Loss                  -731.01807
Q Predictions Mean           728.8844
Q Predictions Std            210.48294
Q Predictions Max            931.8644
Q Predictions Min            27.233082
V Predictions Mean           725.5856
V Predictions Std            209.93019
V Predictions Max            931.6651
V Predictions Min            -24.41089
Log Pis Mean                 -0.6934117
Log Pis Std                  3.0259268
Log Pis Max                  7.7498593
Log Pis Min                  -12.163922
Policy mu Mean               0.0030195266
Policy mu Std                0.6208877
Policy mu Max                2.7116585
Policy mu Min                -2.038304
Policy log std Mean          -0.8652872
Policy log std Std           0.29578564
Policy log std Max           -0.19394839
Policy log std Min           -2.399836
Z mean eval                  0.92465717
Z variance eval              0.0069658803
total_rewards                [ 229.72884601  695.18074436 1237.30148245 2108.52755966 1000.86064597
 2162.82442239 2098.06411776 1881.23048764 2066.09989153  469.24452886]
total_rewards_mean           1394.9062726644186
total_rewards_std            718.6523385783294
total_rewards_max            2162.824422393985
total_rewards_min            229.7288460092941
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               36.30927918991074
(Previous) Eval Time (s)     35.557738862000406
Sample Time (s)              27.730093059595674
Epoch Time (s)               99.59711111150682
Total Train Time (s)         17296.057974715717
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:34:36.944175 UTC | [2020_01_10_11_46_20] Iteration #192 | Epoch Duration: 96.93943047523499
2020-01-10 16:34:36.944410 UTC | [2020_01_10_11_46_20] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9227969
Z variance train             0.006957587
KL Divergence                21.92338
KL Loss                      2.192338
QF Loss                      688.9791
VF Loss                      141.88321
Policy Loss                  -760.0892
Q Predictions Mean           758.20044
Q Predictions Std            178.21205
Q Predictions Max            974.90454
Q Predictions Min            161.71579
V Predictions Mean           757.01855
V Predictions Std            178.41817
V Predictions Max            971.17474
V Predictions Min            171.70892
Log Pis Mean                 -0.8426138
Log Pis Std                  2.4261973
Log Pis Max                  7.997049
Log Pis Min                  -7.0549135
Policy mu Mean               0.053877857
Policy mu Std                0.5681277
Policy mu Max                2.020014
Policy mu Min                -1.9081776
Policy log std Mean          -0.86786515
Policy log std Std           0.26276413
Policy log std Max           -0.23356771
Policy log std Min           -1.9329839
Z mean eval                  0.93966216
Z variance eval              0.008494775
total_rewards                [2068.02267035  155.76846303  688.34240077  116.57340429 1974.04948237
 2113.70354318 2019.06862599  953.34464717 2220.66643313  851.56347746]
total_rewards_mean           1316.110314775036
total_rewards_std            804.5843967729826
total_rewards_max            2220.6664331334605
total_rewards_min            116.5734042871014
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               35.662478615064174
(Previous) Eval Time (s)     32.89964067470282
Sample Time (s)              26.848589620552957
Epoch Time (s)               95.41070891031995
Total Train Time (s)         17392.918451200705
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:36:13.808619 UTC | [2020_01_10_11_46_20] Iteration #193 | Epoch Duration: 96.8640239238739
2020-01-10 16:36:13.808978 UTC | [2020_01_10_11_46_20] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94014055
Z variance train             0.008555
KL Divergence                21.889744
KL Loss                      2.1889744
QF Loss                      475.0462
VF Loss                      97.08185
Policy Loss                  -738.5244
Q Predictions Mean           736.6345
Q Predictions Std            194.08992
Q Predictions Max            978.7119
Q Predictions Min            19.873537
V Predictions Mean           741.1256
V Predictions Std            191.9414
V Predictions Max            972.5853
V Predictions Min            85.23111
Log Pis Mean                 -0.8178639
Log Pis Std                  2.7225828
Log Pis Max                  9.610723
Log Pis Min                  -8.663059
Policy mu Mean               0.005794768
Policy mu Std                0.58501494
Policy mu Max                2.138361
Policy mu Min                -2.7508395
Policy log std Mean          -0.8599545
Policy log std Std           0.2663784
Policy log std Max           0.1982323
Policy log std Min           -2.0394266
Z mean eval                  0.93950003
Z variance eval              0.0107515035
total_rewards                [2285.66667246 2382.56554913 2347.44989953 2361.31037008 2352.99617215
 2242.76610035 2210.24924388 2322.93079966 2209.4038475  2193.7074281 ]
total_rewards_mean           2290.9046082847317
total_rewards_std            68.10052432866836
total_rewards_max            2382.5655491310736
total_rewards_min            2193.70742810237
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               36.52444510208443
(Previous) Eval Time (s)     34.352533074095845
Sample Time (s)              27.475286749657243
Epoch Time (s)               98.35226492583752
Total Train Time (s)         17490.335256111808
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:37:51.227312 UTC | [2020_01_10_11_46_20] Iteration #194 | Epoch Duration: 97.41804480552673
2020-01-10 16:37:51.227617 UTC | [2020_01_10_11_46_20] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9410099
Z variance train             0.010797866
KL Divergence                21.552338
KL Loss                      2.1552339
QF Loss                      557.3149
VF Loss                      171.16063
Policy Loss                  -756.50916
Q Predictions Mean           754.0073
Q Predictions Std            197.1327
Q Predictions Max            973.5755
Q Predictions Min            20.291895
V Predictions Mean           753.995
V Predictions Std            196.23659
V Predictions Max            965.113
V Predictions Min            -6.8596315
Log Pis Mean                 -1.0539958
Log Pis Std                  2.3677673
Log Pis Max                  7.5020633
Log Pis Min                  -7.914028
Policy mu Mean               0.07563538
Policy mu Std                0.5468814
Policy mu Max                2.3013175
Policy mu Min                -1.8787324
Policy log std Mean          -0.90420055
Policy log std Std           0.2622816
Policy log std Max           -0.14710772
Policy log std Min           -2.1521683
Z mean eval                  0.9464716
Z variance eval              0.014912237
total_rewards                [2246.51540404 1885.50618779 1039.57639367 2212.89222329  448.04441517
  188.9247795  2384.16084399 2161.06950608 2293.54677631 2239.19026357]
total_rewards_mean           1709.9426793414482
total_rewards_std            787.7656384131409
total_rewards_max            2384.1608439924057
total_rewards_min            188.92477949702078
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               33.05780667997897
(Previous) Eval Time (s)     33.41781878704205
Sample Time (s)              26.23141783149913
Epoch Time (s)               92.70704329852015
Total Train Time (s)         17580.044682565145
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:39:20.939307 UTC | [2020_01_10_11_46_20] Iteration #195 | Epoch Duration: 89.71151232719421
2020-01-10 16:39:20.939499 UTC | [2020_01_10_11_46_20] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94544744
Z variance train             0.014839716
KL Divergence                21.09188
KL Loss                      2.109188
QF Loss                      501.93076
VF Loss                      109.29606
Policy Loss                  -751.15515
Q Predictions Mean           747.7999
Q Predictions Std            196.20003
Q Predictions Max            989.7312
Q Predictions Min            -8.023002
V Predictions Mean           751.4731
V Predictions Std            193.1079
V Predictions Max            974.2599
V Predictions Min            4.8666873
Log Pis Mean                 -0.8275932
Log Pis Std                  2.5534441
Log Pis Max                  8.983711
Log Pis Min                  -6.556288
Policy mu Mean               0.01526764
Policy mu Std                0.565767
Policy mu Max                1.9979706
Policy mu Min                -2.1976492
Policy log std Mean          -0.86038685
Policy log std Std           0.2611021
Policy log std Max           -0.24561489
Policy log std Min           -1.9319638
Z mean eval                  0.92504805
Z variance eval              0.017640647
total_rewards                [2049.46351274  486.4450793   664.39852466 2223.09220381 2190.93475954
 2327.9373475  2248.4615733   993.06778151 2101.89879215 2038.2598784 ]
total_rewards_mean           1732.3959452914987
total_rewards_std            681.3419906990506
total_rewards_max            2327.9373475014154
total_rewards_min            486.44507930030534
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               33.37981231696904
(Previous) Eval Time (s)     30.42197898030281
Sample Time (s)              25.577156262937933
Epoch Time (s)               89.37894756020978
Total Train Time (s)         17671.118902669754
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:40:52.016247 UTC | [2020_01_10_11_46_20] Iteration #196 | Epoch Duration: 91.07661437988281
2020-01-10 16:40:52.016431 UTC | [2020_01_10_11_46_20] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92416346
Z variance train             0.017751137
KL Divergence                20.932232
KL Loss                      2.0932233
QF Loss                      505.7912
VF Loss                      72.42089
Policy Loss                  -760.82526
Q Predictions Mean           757.6919
Q Predictions Std            196.24156
Q Predictions Max            957.2184
Q Predictions Min            126.79815
V Predictions Mean           759.87537
V Predictions Std            195.48897
V Predictions Max            978.8414
V Predictions Min            139.07864
Log Pis Mean                 -1.1235077
Log Pis Std                  2.5773692
Log Pis Max                  5.8837647
Log Pis Min                  -9.883211
Policy mu Mean               -0.030153578
Policy mu Std                0.5544694
Policy mu Max                2.1434004
Policy mu Min                -2.5756557
Policy log std Mean          -0.88004524
Policy log std Std           0.23896837
Policy log std Max           -0.2830515
Policy log std Min           -1.849472
Z mean eval                  0.94369775
Z variance eval              0.015438514
total_rewards                [ 913.52540487 1782.81763088  567.10969098 2211.37209644 2121.23250673
 2373.49017303 2309.84417201   13.63813343 1496.81310324 2119.27012977]
total_rewards_mean           1590.9113041378428
total_rewards_std            781.9951368269157
total_rewards_max            2373.49017303203
total_rewards_min            13.638133428618142
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               33.68203336186707
(Previous) Eval Time (s)     32.119276554789394
Sample Time (s)              25.492271587252617
Epoch Time (s)               91.29358150390908
Total Train Time (s)         17760.479588636197
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:42:21.379342 UTC | [2020_01_10_11_46_20] Iteration #197 | Epoch Duration: 89.36277508735657
2020-01-10 16:42:21.379529 UTC | [2020_01_10_11_46_20] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9483514
Z variance train             0.015505971
KL Divergence                21.049095
KL Loss                      2.1049097
QF Loss                      529.86273
VF Loss                      137.13467
Policy Loss                  -744.3298
Q Predictions Mean           739.2732
Q Predictions Std            208.465
Q Predictions Max            978.47534
Q Predictions Min            120.9929
V Predictions Mean           735.841
V Predictions Std            207.54825
V Predictions Max            971.7627
V Predictions Min            130.50485
Log Pis Mean                 -1.0659838
Log Pis Std                  2.384808
Log Pis Max                  7.2520404
Log Pis Min                  -9.401977
Policy mu Mean               -0.023294382
Policy mu Std                0.56115216
Policy mu Max                2.012149
Policy mu Min                -2.1392868
Policy log std Mean          -0.84092575
Policy log std Std           0.23904711
Policy log std Max           -0.2766906
Policy log std Min           -2.0070996
Z mean eval                  0.93017894
Z variance eval              0.012571717
total_rewards                [-142.37182008 2268.82782064 1298.43379188 1539.94569383 1995.58279974
  216.90485474 1400.24646556 2292.27412236 2320.43705012 1122.37823729]
total_rewards_mean           1431.265901608591
total_rewards_std            814.1720892871194
total_rewards_max            2320.4370501180715
total_rewards_min            -142.37182008160485
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               33.473054540809244
(Previous) Eval Time (s)     30.18813747726381
Sample Time (s)              26.590057774912566
Epoch Time (s)               90.25124979298562
Total Train Time (s)         17851.72989264829
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:43:52.631986 UTC | [2020_01_10_11_46_20] Iteration #198 | Epoch Duration: 91.25231289863586
2020-01-10 16:43:52.632157 UTC | [2020_01_10_11_46_20] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92874277
Z variance train             0.01256078
KL Divergence                21.114948
KL Loss                      2.1114948
QF Loss                      497.44904
VF Loss                      109.17952
Policy Loss                  -762.1429
Q Predictions Mean           760.99756
Q Predictions Std            190.29123
Q Predictions Max            964.4402
Q Predictions Min            170.83208
V Predictions Mean           767.49255
V Predictions Std            189.44444
V Predictions Max            956.43176
V Predictions Min            178.59225
Log Pis Mean                 -0.6370373
Log Pis Std                  2.4646277
Log Pis Max                  7.8816657
Log Pis Min                  -6.843858
Policy mu Mean               0.041004702
Policy mu Std                0.57503664
Policy mu Max                1.9569539
Policy mu Min                -1.7066472
Policy log std Mean          -0.88223493
Policy log std Std           0.27772877
Policy log std Max           -0.24183428
Policy log std Min           -1.9867076
Z mean eval                  0.95225763
Z variance eval              0.018779442
total_rewards                [2069.63413476 2074.82300346 2248.63750094 2143.53178639 2327.77570744
 2293.8511076  2318.39260257 1072.6587208  2386.82166427 2213.26163342]
total_rewards_mean           2114.9387861647965
total_rewards_std            362.07633712229614
total_rewards_max            2386.8216642735515
total_rewards_min            1072.658720801111
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               33.84022909542546
(Previous) Eval Time (s)     31.188858069013804
Sample Time (s)              24.947413652203977
Epoch Time (s)               89.97650081664324
Total Train Time (s)         17944.72239140654
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:45:25.627307 UTC | [2020_01_10_11_46_20] Iteration #199 | Epoch Duration: 92.99502229690552
2020-01-10 16:45:25.627496 UTC | [2020_01_10_11_46_20] Iteration #199 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9521095
Z variance train             0.0186922
KL Divergence                20.497627
KL Loss                      2.0497627
QF Loss                      473.13367
VF Loss                      73.2452
Policy Loss                  -757.47034
Q Predictions Mean           753.1743
Q Predictions Std            202.48727
Q Predictions Max            960.88605
Q Predictions Min            130.71
V Predictions Mean           758.49274
V Predictions Std            199.99171
V Predictions Max            953.5546
V Predictions Min            134.3877
Log Pis Mean                 -1.2836156
Log Pis Std                  2.3962178
Log Pis Max                  5.6057806
Log Pis Min                  -7.5380507
Policy mu Mean               -0.031587046
Policy mu Std                0.53345484
Policy mu Max                1.6743819
Policy mu Min                -2.3564062
Policy log std Mean          -0.863457
Policy log std Std           0.24737711
Policy log std Max           -0.14937884
Policy log std Min           -1.8978071
Z mean eval                  0.9106207
Z variance eval              0.015373999
total_rewards                [ -14.95122112  987.81765783 2113.84118623 1850.92511773 2190.1162064
  885.86009769  219.22045492 1440.34021757 1337.94731435 1367.11361202]
total_rewards_mean           1237.823064361373
total_rewards_std            700.8062167306807
total_rewards_max            2190.116206400853
total_rewards_min            -14.951221120180621
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               33.25487871095538
(Previous) Eval Time (s)     34.20695231994614
Sample Time (s)              25.061533383093774
Epoch Time (s)               92.5233644139953
Total Train Time (s)         18026.22404531343
Epoch                        200
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:46:47.132269 UTC | [2020_01_10_11_46_20] Iteration #200 | Epoch Duration: 81.50463461875916
2020-01-10 16:46:47.132501 UTC | [2020_01_10_11_46_20] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9105166
Z variance train             0.015362215
KL Divergence                20.23398
KL Loss                      2.0233982
QF Loss                      403.21594
VF Loss                      123.37395
Policy Loss                  -765.5691
Q Predictions Mean           762.6459
Q Predictions Std            208.25958
Q Predictions Max            973.8583
Q Predictions Min            171.66197
V Predictions Mean           769.87897
V Predictions Std            208.73311
V Predictions Max            979.5246
V Predictions Min            164.23817
Log Pis Mean                 -1.063948
Log Pis Std                  2.2982233
Log Pis Max                  5.8822494
Log Pis Min                  -7.4676313
Policy mu Mean               0.02417814
Policy mu Std                0.5382652
Policy mu Max                1.7845324
Policy mu Min                -1.9669235
Policy log std Mean          -0.8758263
Policy log std Std           0.257779
Policy log std Max           -0.24334025
Policy log std Min           -1.8029006
Z mean eval                  0.93111384
Z variance eval              0.015577095
total_rewards                [-194.11454681  322.38539999 2240.49643163 2349.74062903 1510.16043136
 2376.67924214 2280.6499255  1761.36690164   69.83734346 2208.53161112]
total_rewards_mean           1492.5733369072364
total_rewards_std            975.7264858578534
total_rewards_max            2376.679242139714
total_rewards_min            -194.11454680846995
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               34.23053485015407
(Previous) Eval Time (s)     23.187874873634428
Sample Time (s)              25.442923245951533
Epoch Time (s)               82.86133296974003
Total Train Time (s)         18113.093604379334
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:48:14.007916 UTC | [2020_01_10_11_46_20] Iteration #201 | Epoch Duration: 86.87510442733765
2020-01-10 16:48:14.008234 UTC | [2020_01_10_11_46_20] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93291557
Z variance train             0.015576502
KL Divergence                20.290691
KL Loss                      2.0290692
QF Loss                      363.20874
VF Loss                      88.01991
Policy Loss                  -789.98584
Q Predictions Mean           786.5774
Q Predictions Std            194.14026
Q Predictions Max            996.3745
Q Predictions Min            139.87364
V Predictions Mean           785.4938
V Predictions Std            192.44955
V Predictions Max            978.84906
V Predictions Min            137.64545
Log Pis Mean                 -1.2347975
Log Pis Std                  2.457529
Log Pis Max                  8.143928
Log Pis Min                  -7.868603
Policy mu Mean               0.030734465
Policy mu Std                0.5484338
Policy mu Max                1.7191308
Policy mu Min                -1.7913015
Policy log std Mean          -0.8640915
Policy log std Std           0.2500719
Policy log std Max           -0.24163255
Policy log std Min           -2.0600543
Z mean eval                  0.9434191
Z variance eval              0.0153684635
total_rewards                [ -98.13214687 2189.11880779  -24.12379015  732.17851775 1218.40015052
 1705.11372684 1451.72431676  328.09188033 1174.83378236  235.26569692]
total_rewards_mean           891.2470942248535
total_rewards_std            737.425824656627
total_rewards_max            2189.1188077909437
total_rewards_min            -98.13214687142204
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               33.9364229273051
(Previous) Eval Time (s)     27.20135430339724
Sample Time (s)              25.877877103630453
Epoch Time (s)               87.0156543343328
Total Train Time (s)         18199.93103752006
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:49:40.847394 UTC | [2020_01_10_11_46_20] Iteration #202 | Epoch Duration: 86.83875942230225
2020-01-10 16:49:40.847589 UTC | [2020_01_10_11_46_20] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94303834
Z variance train             0.015357356
KL Divergence                19.786697
KL Loss                      1.9786698
QF Loss                      432.88577
VF Loss                      104.09117
Policy Loss                  -771.8417
Q Predictions Mean           768.70715
Q Predictions Std            196.95305
Q Predictions Max            949.5746
Q Predictions Min            151.74161
V Predictions Mean           772.5465
V Predictions Std            196.20326
V Predictions Max            960.5237
V Predictions Min            144.84953
Log Pis Mean                 -0.93923473
Log Pis Std                  2.5322309
Log Pis Max                  5.524355
Log Pis Min                  -6.8216305
Policy mu Mean               0.068404496
Policy mu Std                0.5800038
Policy mu Max                2.2907372
Policy mu Min                -1.6177742
Policy log std Mean          -0.8481031
Policy log std Std           0.26350358
Policy log std Max           -0.14552408
Policy log std Min           -1.9203699
Z mean eval                  0.954003
Z variance eval              0.01972647
total_rewards                [ -30.26683061  357.66826285  123.96181019 2240.10118959 2209.76931215
 2315.27376014 2173.59677838 2152.28169997   -7.46082244 2291.29556377]
total_rewards_mean           1382.62207240072
total_rewards_std            1043.8547829640945
total_rewards_max            2315.273760142643
total_rewards_min            -30.26683060558416
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               33.664162831846625
(Previous) Eval Time (s)     27.024266762193292
Sample Time (s)              24.61148675251752
Epoch Time (s)               85.29991634655744
Total Train Time (s)         18286.278388695326
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:51:07.197804 UTC | [2020_01_10_11_46_20] Iteration #203 | Epoch Duration: 86.35008025169373
2020-01-10 16:51:07.197987 UTC | [2020_01_10_11_46_20] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9540515
Z variance train             0.019737234
KL Divergence                19.742775
KL Loss                      1.9742775
QF Loss                      499.9587
VF Loss                      106.39654
Policy Loss                  -793.64844
Q Predictions Mean           790.97375
Q Predictions Std            185.86363
Q Predictions Max            968.8498
Q Predictions Min            144.92314
V Predictions Mean           790.325
V Predictions Std            182.94807
V Predictions Max            968.65765
V Predictions Min            157.78694
Log Pis Mean                 -1.0058578
Log Pis Std                  2.6134968
Log Pis Max                  7.5154223
Log Pis Min                  -8.086581
Policy mu Mean               -0.015848275
Policy mu Std                0.5897419
Policy mu Max                1.8475156
Policy mu Min                -1.9583632
Policy log std Mean          -0.86961335
Policy log std Std           0.2492386
Policy log std Max           -0.24366453
Policy log std Min           -1.8191556
Z mean eval                  0.96614885
Z variance eval              0.025096497
total_rewards                [2109.28898181 2185.65463049 1489.10584295 2050.72505809 2149.29835309
  878.57703212 2210.0823677  2313.79200406 2102.4024384  2246.47897746]
total_rewards_mean           1973.5405686168874
total_rewards_std            423.8766588731774
total_rewards_max            2313.7920040597137
total_rewards_min            878.5770321231842
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               33.18274121917784
(Previous) Eval Time (s)     28.07403303682804
Sample Time (s)              25.73880383791402
Epoch Time (s)               86.9955780939199
Total Train Time (s)         18379.511706426274
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:52:40.433862 UTC | [2020_01_10_11_46_20] Iteration #204 | Epoch Duration: 93.23573994636536
2020-01-10 16:52:40.434048 UTC | [2020_01_10_11_46_20] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.965516
Z variance train             0.025092255
KL Divergence                19.394007
KL Loss                      1.9394007
QF Loss                      420.4546
VF Loss                      107.30525
Policy Loss                  -807.73413
Q Predictions Mean           805.317
Q Predictions Std            189.71217
Q Predictions Max            996.3848
Q Predictions Min            157.22034
V Predictions Mean           813.8613
V Predictions Std            189.75467
V Predictions Max            1001.9205
V Predictions Min            165.50229
Log Pis Mean                 -1.2371497
Log Pis Std                  2.369964
Log Pis Max                  6.1345572
Log Pis Min                  -8.502966
Policy mu Mean               0.023703802
Policy mu Std                0.54144025
Policy mu Max                2.7366579
Policy mu Min                -2.286309
Policy log std Mean          -0.8558792
Policy log std Std           0.2486835
Policy log std Max           0.29458457
Policy log std Min           -1.7666261
Z mean eval                  0.9464499
Z variance eval              0.020681059
total_rewards                [2227.41719651 2233.43790453 1079.55651057 2422.28560569 2442.09061573
 2421.17569457  552.74873534 1382.24867686  482.69410375  369.49983648]
total_rewards_mean           1561.3154880031473
total_rewards_std            837.6781088492326
total_rewards_max            2442.0906157310046
total_rewards_min            369.4998364760261
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               33.61688958480954
(Previous) Eval Time (s)     34.313868823926896
Sample Time (s)              25.71073933504522
Epoch Time (s)               93.64149774378166
Total Train Time (s)         18467.22386795981
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:54:08.149863 UTC | [2020_01_10_11_46_20] Iteration #205 | Epoch Duration: 87.71566653251648
2020-01-10 16:54:08.150123 UTC | [2020_01_10_11_46_20] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9456154
Z variance train             0.020674914
KL Divergence                19.78452
KL Loss                      1.978452
QF Loss                      774.41626
VF Loss                      95.27222
Policy Loss                  -783.4344
Q Predictions Mean           779.76935
Q Predictions Std            203.79697
Q Predictions Max            972.3772
Q Predictions Min            -18.378311
V Predictions Mean           781.0233
V Predictions Std            201.78656
V Predictions Max            966.38837
V Predictions Min            -7.2102504
Log Pis Mean                 -1.1194533
Log Pis Std                  2.355072
Log Pis Max                  6.786688
Log Pis Min                  -7.267616
Policy mu Mean               0.037348457
Policy mu Std                0.56373376
Policy mu Max                3.0577893
Policy mu Min                -1.6487536
Policy log std Mean          -0.87431955
Policy log std Std           0.25546578
Policy log std Max           -0.2113738
Policy log std Min           -1.9193559
Z mean eval                  0.9497119
Z variance eval              0.018852327
total_rewards                [-160.03744871 1858.2994109   664.75477244 2278.4771599  2397.44054414
 2379.96549796 2429.70638765 2521.62391532 2362.63593703 2288.29524096]
total_rewards_mean           1902.1161417590433
total_rewards_std            861.6349870571689
total_rewards_max            2521.6239153175043
total_rewards_min            -160.0374487080793
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               33.43945687683299
(Previous) Eval Time (s)     28.387684741988778
Sample Time (s)              25.619345649611205
Epoch Time (s)               87.44648726843297
Total Train Time (s)         18557.574894364458
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:55:38.502267 UTC | [2020_01_10_11_46_20] Iteration #206 | Epoch Duration: 90.35200810432434
2020-01-10 16:55:38.502449 UTC | [2020_01_10_11_46_20] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9513873
Z variance train             0.018854028
KL Divergence                20.006573
KL Loss                      2.0006573
QF Loss                      584.9863
VF Loss                      106.43151
Policy Loss                  -773.3639
Q Predictions Mean           769.7018
Q Predictions Std            224.11926
Q Predictions Max            981.88965
Q Predictions Min            18.979986
V Predictions Mean           772.74915
V Predictions Std            221.08603
V Predictions Max            977.54205
V Predictions Min            61.948875
Log Pis Mean                 -0.9349954
Log Pis Std                  2.5205543
Log Pis Max                  6.67559
Log Pis Min                  -8.1160965
Policy mu Mean               0.023652427
Policy mu Std                0.5570932
Policy mu Max                2.0708427
Policy mu Min                -2.5642695
Policy log std Mean          -0.88245654
Policy log std Std           0.25857586
Policy log std Max           -0.24943465
Policy log std Min           -2.1117723
Z mean eval                  0.96034354
Z variance eval              0.017192692
total_rewards                [2283.30870234 2356.08611205 2206.7272603  1714.74690653 2341.8097806
 2443.72769366 2366.72808284 2478.18257798 2378.75483456  622.22614575]
total_rewards_mean           2119.229809663015
total_rewards_std            539.2217936455656
total_rewards_max            2478.1825779786855
total_rewards_min            622.2261457459374
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               34.05342783220112
(Previous) Eval Time (s)     31.292866660282016
Sample Time (s)              25.101222986821085
Epoch Time (s)               90.44751747930422
Total Train Time (s)         18649.73179733986
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:57:10.662058 UTC | [2020_01_10_11_46_20] Iteration #207 | Epoch Duration: 92.15946984291077
2020-01-10 16:57:10.662283 UTC | [2020_01_10_11_46_20] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96345365
Z variance train             0.017105017
KL Divergence                20.003975
KL Loss                      2.0003974
QF Loss                      443.94357
VF Loss                      240.08403
Policy Loss                  -789.4728
Q Predictions Mean           782.99396
Q Predictions Std            208.77382
Q Predictions Max            994.27606
Q Predictions Min            -24.039303
V Predictions Mean           776.8578
V Predictions Std            205.40154
V Predictions Max            990.446
V Predictions Min            15.951501
Log Pis Mean                 -0.87957937
Log Pis Std                  2.6022768
Log Pis Max                  7.050437
Log Pis Min                  -11.362107
Policy mu Mean               0.044796616
Policy mu Std                0.5474156
Policy mu Max                2.0710392
Policy mu Min                -2.1108868
Policy log std Mean          -0.91379243
Policy log std Std           0.26591983
Policy log std Max           -0.24792817
Policy log std Min           -2.1943421
Z mean eval                  0.954906
Z variance eval              0.017147455
total_rewards                [  70.126331   2528.10200739 2328.70211916 2531.54794424 1131.60252505
 1260.85654361 2436.89813955 2389.65038874 2321.29014524 2456.27014932]
total_rewards_mean           1945.5046293303908
total_rewards_std            794.9062456946319
total_rewards_max            2531.5479442428646
total_rewards_min            70.12633099645248
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               33.99954902892932
(Previous) Eval Time (s)     33.00448636198416
Sample Time (s)              24.96054207254201
Epoch Time (s)               91.9645774634555
Total Train Time (s)         18742.412018679082
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:58:43.345059 UTC | [2020_01_10_11_46_20] Iteration #208 | Epoch Duration: 92.68262648582458
2020-01-10 16:58:43.345269 UTC | [2020_01_10_11_46_20] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95465726
Z variance train             0.017145924
KL Divergence                19.798443
KL Loss                      1.9798443
QF Loss                      723.3556
VF Loss                      209.85286
Policy Loss                  -781.12384
Q Predictions Mean           778.32837
Q Predictions Std            202.17819
Q Predictions Max            977.0483
Q Predictions Min            105.37319
V Predictions Mean           781.32666
V Predictions Std            201.00111
V Predictions Max            978.07025
V Predictions Min            123.50974
Log Pis Mean                 -0.8940435
Log Pis Std                  2.6506355
Log Pis Max                  8.601416
Log Pis Min                  -6.8058724
Policy mu Mean               0.023421273
Policy mu Std                0.5619346
Policy mu Max                2.3349586
Policy mu Min                -2.2808776
Policy log std Mean          -0.88598037
Policy log std Std           0.27159628
Policy log std Max           -0.2380338
Policy log std Min           -2.9057066
Z mean eval                  0.9456712
Z variance eval              0.021534868
total_rewards                [ 836.4760685  2266.70623746 2477.91012629 2349.13092748 1278.82493818
 2167.03608093 1043.47095452  241.86766357 2331.85474317 2280.70471449]
total_rewards_mean           1727.398245458939
total_rewards_std            759.9334076406357
total_rewards_max            2477.910126292074
total_rewards_min            241.86766357176086
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               33.56676515843719
(Previous) Eval Time (s)     33.722131370101124
Sample Time (s)              26.153162873350084
Epoch Time (s)               93.4420594018884
Total Train Time (s)         18833.41080785636
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:00:14.345695 UTC | [2020_01_10_11_46_20] Iteration #209 | Epoch Duration: 91.00029611587524
2020-01-10 17:00:14.345852 UTC | [2020_01_10_11_46_20] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9461314
Z variance train             0.021593701
KL Divergence                19.934387
KL Loss                      1.9934387
QF Loss                      375.58505
VF Loss                      136.3674
Policy Loss                  -797.6744
Q Predictions Mean           792.368
Q Predictions Std            196.02925
Q Predictions Max            979.4767
Q Predictions Min            154.18001
V Predictions Mean           788.8779
V Predictions Std            192.8413
V Predictions Max            976.9712
V Predictions Min            149.96823
Log Pis Mean                 -1.0700047
Log Pis Std                  2.5638154
Log Pis Max                  5.745859
Log Pis Min                  -7.8489785
Policy mu Mean               0.07732863
Policy mu Std                0.5903736
Policy mu Max                2.25906
Policy mu Min                -2.1070611
Policy log std Mean          -0.85903376
Policy log std Std           0.24608833
Policy log std Max           -0.16259491
Policy log std Min           -2.0321503
Z mean eval                  0.95572054
Z variance eval              0.01842276
total_rewards                [ -58.25362637 2380.96297608 2284.66975081  829.15466528 2312.63626989
   83.32213528  178.65568438 2389.29713193  134.76524471  243.39088651]
total_rewards_mean           1077.86011184942
total_rewards_std            1055.227739805796
total_rewards_max            2389.297131929238
total_rewards_min            -58.25362637102308
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               33.80888371402398
(Previous) Eval Time (s)     31.280038530007005
Sample Time (s)              26.57336592953652
Epoch Time (s)               91.6622881735675
Total Train Time (s)         18919.52337151114
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:01:40.461595 UTC | [2020_01_10_11_46_20] Iteration #210 | Epoch Duration: 86.11562967300415
2020-01-10 17:01:40.461781 UTC | [2020_01_10_11_46_20] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9562542
Z variance train             0.01843248
KL Divergence                19.846214
KL Loss                      1.9846214
QF Loss                      1193.6547
VF Loss                      323.45703
Policy Loss                  -776.50574
Q Predictions Mean           774.05853
Q Predictions Std            241.3402
Q Predictions Max            987.9545
Q Predictions Min            -4.4700503
V Predictions Mean           771.1837
V Predictions Std            235.20076
V Predictions Max            983.97
V Predictions Min            8.001771
Log Pis Mean                 -1.0017178
Log Pis Std                  2.565625
Log Pis Max                  10.470539
Log Pis Min                  -7.8654323
Policy mu Mean               0.06678492
Policy mu Std                0.590113
Policy mu Max                2.1456864
Policy mu Min                -2.145945
Policy log std Mean          -0.87187445
Policy log std Std           0.28163773
Policy log std Max           -0.27897006
Policy log std Min           -2.7019527
Z mean eval                  0.9418663
Z variance eval              0.015796807
total_rewards                [2272.22637956 2267.37460141  585.65621049 2306.65087317  962.4878622
 2274.9338482  2406.07709499 2277.05467531 2332.31883117  359.19839041]
total_rewards_mean           1804.397876692277
total_rewards_std            778.0579201098097
total_rewards_max            2406.0770949911766
total_rewards_min            359.19839040934824
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               33.63663003174588
(Previous) Eval Time (s)     25.732975761871785
Sample Time (s)              26.063810656312853
Epoch Time (s)               85.43341644993052
Total Train Time (s)         19009.609419147484
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:03:10.551160 UTC | [2020_01_10_11_46_20] Iteration #211 | Epoch Duration: 90.08923196792603
2020-01-10 17:03:10.551393 UTC | [2020_01_10_11_46_20] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94142705
Z variance train             0.015756613
KL Divergence                20.158783
KL Loss                      2.0158784
QF Loss                      315.28177
VF Loss                      68.03826
Policy Loss                  -819.553
Q Predictions Mean           815.92444
Q Predictions Std            184.26845
Q Predictions Max            999.6464
Q Predictions Min            112.859604
V Predictions Mean           821.9297
V Predictions Std            184.81128
V Predictions Max            992.4958
V Predictions Min            119.02816
Log Pis Mean                 -0.7789155
Log Pis Std                  2.5946255
Log Pis Max                  6.9005613
Log Pis Min                  -8.1441765
Policy mu Mean               0.03322154
Policy mu Std                0.57670814
Policy mu Max                1.9274029
Policy mu Min                -2.4087152
Policy log std Mean          -0.8763387
Policy log std Std           0.24813522
Policy log std Max           -0.25131854
Policy log std Min           -2.0250385
Z mean eval                  0.9479014
Z variance eval              0.013889479
total_rewards                [2414.05173538 1473.70363621 2516.82822536 2404.60265459 2304.58328545
 2327.45683381  972.18081179  244.30818148 2223.04457442 1108.30710139]
total_rewards_mean           1798.9067039861952
total_rewards_std            752.2357606734889
total_rewards_max            2516.828225356318
total_rewards_min            244.30818148437172
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               33.52427964005619
(Previous) Eval Time (s)     30.388423318974674
Sample Time (s)              24.996457275934517
Epoch Time (s)               88.90916023496538
Total Train Time (s)         19098.345949496143
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:04:39.292016 UTC | [2020_01_10_11_46_20] Iteration #212 | Epoch Duration: 88.74046564102173
2020-01-10 17:04:39.292274 UTC | [2020_01_10_11_46_20] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9485362
Z variance train             0.013855617
KL Divergence                20.352808
KL Loss                      2.035281
QF Loss                      3243.4854
VF Loss                      176.17519
Policy Loss                  -795.6887
Q Predictions Mean           794.06726
Q Predictions Std            224.3939
Q Predictions Max            1017.8069
Q Predictions Min            93.688614
V Predictions Mean           803.76294
V Predictions Std            225.35321
V Predictions Max            1028.6721
V Predictions Min            95.74538
Log Pis Mean                 -1.0560246
Log Pis Std                  2.3697195
Log Pis Max                  5.9383917
Log Pis Min                  -7.812172
Policy mu Mean               0.032616332
Policy mu Std                0.57066464
Policy mu Max                2.092786
Policy mu Min                -2.104286
Policy log std Mean          -0.85062444
Policy log std Std           0.24813902
Policy log std Max           -0.31149453
Policy log std Min           -1.9701558
Z mean eval                  0.93080854
Z variance eval              0.019250821
total_rewards                [ 573.11083302  960.76918039 2223.05001874  357.87792823  587.60427497
 2314.07219473 2251.81410276  569.2806632  2301.0608509  2072.73686478]
total_rewards_mean           1421.137691170716
total_rewards_std            825.3068128268882
total_rewards_max            2314.0721947270035
total_rewards_min            357.8779282300234
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               33.85627509886399
(Previous) Eval Time (s)     30.219358400907367
Sample Time (s)              25.62412729067728
Epoch Time (s)               89.69976079044864
Total Train Time (s)         19184.776381261647
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:06:05.724110 UTC | [2020_01_10_11_46_20] Iteration #213 | Epoch Duration: 86.43168473243713
2020-01-10 17:06:05.724278 UTC | [2020_01_10_11_46_20] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93301046
Z variance train             0.019244712
KL Divergence                19.99662
KL Loss                      1.999662
QF Loss                      527.22815
VF Loss                      154.96469
Policy Loss                  -809.4416
Q Predictions Mean           806.292
Q Predictions Std            215.79655
Q Predictions Max            1011.03143
Q Predictions Min            -64.554115
V Predictions Mean           812.1693
V Predictions Std            211.46878
V Predictions Max            1017.77386
V Predictions Min            151.00116
Log Pis Mean                 -0.9449392
Log Pis Std                  2.6871755
Log Pis Max                  8.111768
Log Pis Min                  -10.072248
Policy mu Mean               0.050538953
Policy mu Std                0.5783926
Policy mu Max                2.5790334
Policy mu Min                -2.1113486
Policy log std Mean          -0.8804117
Policy log std Std           0.2640409
Policy log std Max           -0.24608561
Policy log std Min           -2.1352706
Z mean eval                  0.9539822
Z variance eval              0.019377792
total_rewards                [  43.87903719 2329.27519386 2220.5809518  1655.38145252  929.02708896
  476.30601107   29.79065623 1763.8147319  1397.92287593  922.46192442]
total_rewards_mean           1176.8439923887927
total_rewards_std            790.9558142017082
total_rewards_max            2329.2751938558304
total_rewards_min            29.790656234558355
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               33.60063298884779
(Previous) Eval Time (s)     26.95090372627601
Sample Time (s)              25.686728740110993
Epoch Time (s)               86.2382654552348
Total Train Time (s)         19273.978097597137
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:07:34.929207 UTC | [2020_01_10_11_46_20] Iteration #214 | Epoch Duration: 89.20479202270508
2020-01-10 17:07:34.929386 UTC | [2020_01_10_11_46_20] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9534124
Z variance train             0.019415569
KL Divergence                20.511677
KL Loss                      2.0511677
QF Loss                      266.77185
VF Loss                      172.95844
Policy Loss                  -810.4085
Q Predictions Mean           807.15234
Q Predictions Std            219.25473
Q Predictions Max            992.80646
Q Predictions Min            36.405067
V Predictions Mean           805.0978
V Predictions Std            214.08734
V Predictions Max            995.7342
V Predictions Min            119.1864
Log Pis Mean                 -0.65682817
Log Pis Std                  2.7639267
Log Pis Max                  9.275833
Log Pis Min                  -6.785762
Policy mu Mean               0.023851234
Policy mu Std                0.5941472
Policy mu Max                2.3094318
Policy mu Min                -2.2774172
Policy log std Mean          -0.8814786
Policy log std Std           0.2657551
Policy log std Max           -0.30434927
Policy log std Min           -2.3025866
Z mean eval                  0.9396737
Z variance eval              0.019298118
total_rewards                [2328.01800269 2278.58021316 2496.53397787 2316.88862984 2223.63531487
 1184.37415523  -95.75337758 1671.59247596 2154.54093198 2501.03374088]
total_rewards_mean           1905.944406491522
total_rewards_std            770.3189142687481
total_rewards_max            2501.033740882158
total_rewards_min            -95.75337757826364
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               33.646218332927674
(Previous) Eval Time (s)     29.917082134634256
Sample Time (s)              25.30428568692878
Epoch Time (s)               88.86758615449071
Total Train Time (s)         19367.20496403519
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:09:08.158873 UTC | [2020_01_10_11_46_20] Iteration #215 | Epoch Duration: 93.22935748100281
2020-01-10 17:09:08.159051 UTC | [2020_01_10_11_46_20] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94162226
Z variance train             0.019276315
KL Divergence                19.631449
KL Loss                      1.9631449
QF Loss                      640.5433
VF Loss                      100.50143
Policy Loss                  -803.1597
Q Predictions Mean           799.8066
Q Predictions Std            227.42267
Q Predictions Max            998.7333
Q Predictions Min            -11.329132
V Predictions Mean           802.90356
V Predictions Std            225.47974
V Predictions Max            991.1388
V Predictions Min            37.0132
Log Pis Mean                 -0.82854
Log Pis Std                  2.4926038
Log Pis Max                  5.237004
Log Pis Min                  -8.858461
Policy mu Mean               0.009370214
Policy mu Std                0.55550265
Policy mu Max                2.138048
Policy mu Min                -1.9037739
Policy log std Mean          -0.8804876
Policy log std Std           0.25971565
Policy log std Max           -0.2333025
Policy log std Min           -2.1412735
Z mean eval                  0.9522902
Z variance eval              0.021066051
total_rewards                [2385.83117512 2490.1303394   485.19438168 2347.15402063  831.02309303
 1964.45545103 2439.6439286  1621.8756356  2330.94477753 2342.38893754]
total_rewards_mean           1923.8641740165608
total_rewards_std            683.8909747815176
total_rewards_max            2490.1303394029337
total_rewards_min            485.1943816771109
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               34.0356270680204
(Previous) Eval Time (s)     34.27850452484563
Sample Time (s)              25.70233886409551
Epoch Time (s)               94.01647045696154
Total Train Time (s)         19459.930872432422
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:10:40.887293 UTC | [2020_01_10_11_46_20] Iteration #216 | Epoch Duration: 92.7281084060669
2020-01-10 17:10:40.887481 UTC | [2020_01_10_11_46_20] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.951841
Z variance train             0.021035265
KL Divergence                19.476479
KL Loss                      1.9476479
QF Loss                      842.33167
VF Loss                      175.58252
Policy Loss                  -833.27277
Q Predictions Mean           834.3026
Q Predictions Std            179.63077
Q Predictions Max            1005.55426
Q Predictions Min            130.17712
V Predictions Mean           835.28467
V Predictions Std            180.14767
V Predictions Max            1012.6111
V Predictions Min            129.67517
Log Pis Mean                 -1.1740593
Log Pis Std                  2.5232227
Log Pis Max                  6.6612186
Log Pis Min                  -9.073852
Policy mu Mean               0.039837025
Policy mu Std                0.5665133
Policy mu Max                2.1048481
Policy mu Min                -2.019126
Policy log std Mean          -0.8720571
Policy log std Std           0.2636276
Policy log std Max           -0.26911932
Policy log std Min           -2.3117201
Z mean eval                  0.93700916
Z variance eval              0.017646652
total_rewards                [1471.56793498 2337.5304772  1682.62808023 2143.31352253 1398.77039594
 2369.3982353  2205.57024615 1990.10026916  148.06160352 1349.18565742]
total_rewards_mean           1709.6126422435111
total_rewards_std            637.5505589985319
total_rewards_max            2369.3982353018246
total_rewards_min            148.0616035245864
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               33.20794721785933
(Previous) Eval Time (s)     32.98979900823906
Sample Time (s)              26.099386512301862
Epoch Time (s)               92.29713273840025
Total Train Time (s)         19547.03648446221
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:12:07.995934 UTC | [2020_01_10_11_46_20] Iteration #217 | Epoch Duration: 87.1083128452301
2020-01-10 17:12:07.996142 UTC | [2020_01_10_11_46_20] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93830377
Z variance train             0.017650733
KL Divergence                19.873014
KL Loss                      1.9873015
QF Loss                      554.6605
VF Loss                      92.76391
Policy Loss                  -809.7749
Q Predictions Mean           805.86255
Q Predictions Std            226.37405
Q Predictions Max            1001.5279
Q Predictions Min            -52.720665
V Predictions Mean           811.2721
V Predictions Std            223.37373
V Predictions Max            1012.3847
V Predictions Min            -11.634554
Log Pis Mean                 -1.0301718
Log Pis Std                  2.5389423
Log Pis Max                  5.824153
Log Pis Min                  -8.400827
Policy mu Mean               0.025826143
Policy mu Std                0.54473704
Policy mu Max                1.958511
Policy mu Min                -1.7425973
Policy log std Mean          -0.87885624
Policy log std Std           0.26726672
Policy log std Max           -0.2838943
Policy log std Min           -2.15268
Z mean eval                  0.9587757
Z variance eval              0.016550723
total_rewards                [1693.76133565 1160.54504175 1833.09028801 2502.40455865  572.4992918
  917.2176802  2200.66466668 2304.37291212  558.67611208 1975.24015228]
total_rewards_mean           1571.8472039228393
total_rewards_std            683.1325181203885
total_rewards_max            2502.4045586526618
total_rewards_min            558.676112077803
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               33.8930150908418
(Previous) Eval Time (s)     27.80057335877791
Sample Time (s)              25.11236757878214
Epoch Time (s)               86.80595602840185
Total Train Time (s)         19632.45943508437
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:13:33.421330 UTC | [2020_01_10_11_46_20] Iteration #218 | Epoch Duration: 85.42505812644958
2020-01-10 17:13:33.421507 UTC | [2020_01_10_11_46_20] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9580425
Z variance train             0.016517032
KL Divergence                19.919268
KL Loss                      1.9919268
QF Loss                      587.9552
VF Loss                      175.53278
Policy Loss                  -817.3859
Q Predictions Mean           816.2539
Q Predictions Std            197.21555
Q Predictions Max            1003.5839
Q Predictions Min            110.25757
V Predictions Mean           824.2049
V Predictions Std            196.70102
V Predictions Max            1009.98926
V Predictions Min            108.36149
Log Pis Mean                 -0.88559306
Log Pis Std                  2.2115393
Log Pis Max                  5.748624
Log Pis Min                  -6.7081404
Policy mu Mean               -0.062343545
Policy mu Std                0.56509954
Policy mu Max                2.1427042
Policy mu Min                -2.3278131
Policy log std Mean          -0.87936074
Policy log std Std           0.24205062
Policy log std Max           -0.28342953
Policy log std Min           -1.8866234
Z mean eval                  0.9471405
Z variance eval              0.014487453
total_rewards                [2340.25500002 2341.45427806 2398.78197714  620.61980033 2299.28964228
 2469.31642107 2455.1445476  2258.82730686 1286.6742016  2291.30349162]
total_rewards_mean           2076.1666666571864
total_rewards_std            584.2721475828637
total_rewards_max            2469.3164210660084
total_rewards_min            620.6198003334684
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               32.77381675411016
(Previous) Eval Time (s)     26.41935680480674
Sample Time (s)              25.50662697479129
Epoch Time (s)               84.69980053370818
Total Train Time (s)         19722.84569296753
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:15:03.810237 UTC | [2020_01_10_11_46_20] Iteration #219 | Epoch Duration: 90.38860082626343
2020-01-10 17:15:03.810420 UTC | [2020_01_10_11_46_20] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94768095
Z variance train             0.014500109
KL Divergence                20.563236
KL Loss                      2.0563238
QF Loss                      973.8104
VF Loss                      121.89154
Policy Loss                  -845.9075
Q Predictions Mean           845.9739
Q Predictions Std            182.5199
Q Predictions Max            1031.4343
Q Predictions Min            -16.847687
V Predictions Mean           849.2997
V Predictions Std            180.308
V Predictions Max            1031.3915
V Predictions Min            120.42173
Log Pis Mean                 -0.91260093
Log Pis Std                  2.4014485
Log Pis Max                  6.1483526
Log Pis Min                  -8.798601
Policy mu Mean               -0.027366769
Policy mu Std                0.55594516
Policy mu Max                1.8798028
Policy mu Min                -2.160025
Policy log std Mean          -0.8910253
Policy log std Std           0.25247735
Policy log std Max           -0.31969643
Policy log std Min           -1.9159536
Z mean eval                  0.94924986
Z variance eval              0.014856011
total_rewards                [ 354.83967713 2451.72734621 2474.78721744 1752.93146627  714.88392162
 2494.17397943 1052.72921364 1186.0282208   -52.1210686   766.62840488]
total_rewards_mean           1319.6608378817643
total_rewards_std            880.7083353220454
total_rewards_max            2494.173979428009
total_rewards_min            -52.121068599893775
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               34.20215968322009
(Previous) Eval Time (s)     32.10785146476701
Sample Time (s)              25.345435350202024
Epoch Time (s)               91.65544649818912
Total Train Time (s)         19811.06690155994
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:16:32.034108 UTC | [2020_01_10_11_46_20] Iteration #220 | Epoch Duration: 88.22356033325195
2020-01-10 17:16:32.034287 UTC | [2020_01_10_11_46_20] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9494726
Z variance train             0.014875894
KL Divergence                20.748466
KL Loss                      2.0748467
QF Loss                      714.8958
VF Loss                      136.23209
Policy Loss                  -820.1368
Q Predictions Mean           815.9374
Q Predictions Std            221.24075
Q Predictions Max            1021.7982
Q Predictions Min            71.47345
V Predictions Mean           813.4763
V Predictions Std            218.85963
V Predictions Max            1015.11584
V Predictions Min            111.17873
Log Pis Mean                 -0.9588126
Log Pis Std                  2.613445
Log Pis Max                  7.6409006
Log Pis Min                  -7.5331783
Policy mu Mean               0.023164535
Policy mu Std                0.58383286
Policy mu Max                2.7439106
Policy mu Min                -2.2287538
Policy log std Mean          -0.89078987
Policy log std Std           0.26167414
Policy log std Max           -0.2933298
Policy log std Min           -2.0252872
Z mean eval                  0.9610735
Z variance eval              0.021513723
total_rewards                [2495.27750797 1427.74213965 1195.11058869  526.52224494 2455.06220156
 2619.0994706  2319.98877343 2459.54426638 1624.40501754  406.15985043]
total_rewards_mean           1752.8912061205592
total_rewards_std            797.9017790746772
total_rewards_max            2619.099470604516
total_rewards_min            406.15985042717966
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               33.33055615099147
(Previous) Eval Time (s)     28.675633722916245
Sample Time (s)              24.662418928928673
Epoch Time (s)               86.66860880283639
Total Train Time (s)         19896.42980510881
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:17:57.399915 UTC | [2020_01_10_11_46_20] Iteration #221 | Epoch Duration: 85.36550045013428
2020-01-10 17:17:57.400093 UTC | [2020_01_10_11_46_20] Iteration #221 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9623705
Z variance train             0.021493757
KL Divergence                20.482922
KL Loss                      2.0482922
QF Loss                      391.938
VF Loss                      101.585594
Policy Loss                  -811.5407
Q Predictions Mean           807.5438
Q Predictions Std            239.54863
Q Predictions Max            1051.204
Q Predictions Min            64.50879
V Predictions Mean           804.6444
V Predictions Std            236.45781
V Predictions Max            1041.493
V Predictions Min            62.064266
Log Pis Mean                 -0.92486066
Log Pis Std                  2.584725
Log Pis Max                  8.458929
Log Pis Min                  -6.9113493
Policy mu Mean               0.014795497
Policy mu Std                0.5717983
Policy mu Max                2.2051146
Policy mu Min                -2.7693028
Policy log std Mean          -0.87576973
Policy log std Std           0.2606649
Policy log std Max           -0.23150012
Policy log std Min           -2.0328887
Z mean eval                  0.9492895
Z variance eval              0.022612205
total_rewards                [2203.30065502  506.82837609   73.65838491  581.09013788 2642.0385427
 2023.6100575   386.38591344  778.0339261   618.51821295  916.90531539]
total_rewards_mean           1073.0369521978453
total_rewards_std            836.2830504550548
total_rewards_max            2642.0385427032934
total_rewards_min            73.65838490503128
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               35.43744862778112
(Previous) Eval Time (s)     27.372180526144803
Sample Time (s)              25.289378568995744
Epoch Time (s)               88.09900772292167
Total Train Time (s)         19975.507727697026
Epoch                        222
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:19:16.481746 UTC | [2020_01_10_11_46_20] Iteration #222 | Epoch Duration: 79.0814962387085
2020-01-10 17:19:16.482000 UTC | [2020_01_10_11_46_20] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.947549
Z variance train             0.022650747
KL Divergence                19.495173
KL Loss                      1.9495173
QF Loss                      1397.313
VF Loss                      152.96323
Policy Loss                  -832.0117
Q Predictions Mean           829.92896
Q Predictions Std            202.15001
Q Predictions Max            1021.8213
Q Predictions Min            149.52692
V Predictions Mean           823.9254
V Predictions Std            200.5874
V Predictions Max            1003.66046
V Predictions Min            140.93709
Log Pis Mean                 -1.0636871
Log Pis Std                  2.4408472
Log Pis Max                  7.9782887
Log Pis Min                  -9.37109
Policy mu Mean               0.016606936
Policy mu Std                0.6047236
Policy mu Max                2.4463665
Policy mu Min                -1.9061228
Policy log std Mean          -0.84930146
Policy log std Std           0.24930519
Policy log std Max           -0.2460711
Policy log std Min           -2.0104299
Z mean eval                  0.9650054
Z variance eval              0.030749042
total_rewards                [2217.67306752 2519.81799866 2394.1360728  2317.49873669 2416.11873904
 2052.84420435 2366.51223297 1519.55342191 2284.59483523 2298.12907268]
total_rewards_mean           2238.687838185057
total_rewards_std            267.3957324283748
total_rewards_max            2519.817998664682
total_rewards_min            1519.5534219095748
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               35.511519718915224
(Previous) Eval Time (s)     18.354265647940338
Sample Time (s)              25.729730249382555
Epoch Time (s)               79.59551561623812
Total Train Time (s)         20073.275421120692
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:20:54.253261 UTC | [2020_01_10_11_46_20] Iteration #223 | Epoch Duration: 97.77112030982971
2020-01-10 17:20:54.253399 UTC | [2020_01_10_11_46_20] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9660489
Z variance train             0.030697808
KL Divergence                18.980677
KL Loss                      1.8980677
QF Loss                      506.20312
VF Loss                      104.78352
Policy Loss                  -813.1765
Q Predictions Mean           812.19885
Q Predictions Std            219.41039
Q Predictions Max            1032.0017
Q Predictions Min            -43.504128
V Predictions Mean           812.34534
V Predictions Std            216.60637
V Predictions Max            1028.524
V Predictions Min            74.46675
Log Pis Mean                 -0.5150286
Log Pis Std                  2.90026
Log Pis Max                  12.200203
Log Pis Min                  -7.5716386
Policy mu Mean               0.05301062
Policy mu Std                0.6075126
Policy mu Max                2.0167181
Policy mu Min                -2.8047514
Policy log std Mean          -0.88999295
Policy log std Std           0.26098585
Policy log std Max           -0.087314904
Policy log std Min           -2.2027159
Z mean eval                  0.9384246
Z variance eval              0.026406884
total_rewards                [2212.45492312 2305.97825308 1516.61780907  233.18454668 2202.44042498
 2243.6074125  2530.3964579  2464.80766479 2268.057296   2269.62611466]
total_rewards_mean           2024.7170902774378
total_rewards_std            650.3992504107731
total_rewards_max            2530.3964578950445
total_rewards_min            233.18454667500535
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               36.502852629870176
(Previous) Eval Time (s)     36.5295247877948
Sample Time (s)              26.245531945489347
Epoch Time (s)               99.27790936315432
Total Train Time (s)         20168.684083133936
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:22:29.666454 UTC | [2020_01_10_11_46_20] Iteration #224 | Epoch Duration: 95.4129421710968
2020-01-10 17:22:29.666668 UTC | [2020_01_10_11_46_20] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9390815
Z variance train             0.026541287
KL Divergence                19.9063
KL Loss                      1.99063
QF Loss                      1320.7909
VF Loss                      144.76625
Policy Loss                  -833.24396
Q Predictions Mean           831.0864
Q Predictions Std            224.7866
Q Predictions Max            1029.4528
Q Predictions Min            151.5802
V Predictions Mean           836.71124
V Predictions Std            221.94034
V Predictions Max            1024.2893
V Predictions Min            151.08147
Log Pis Mean                 -1.0825738
Log Pis Std                  2.8189802
Log Pis Max                  10.215923
Log Pis Min                  -9.220401
Policy mu Mean               0.0069952565
Policy mu Std                0.5874668
Policy mu Max                2.460551
Policy mu Min                -3.128475
Policy log std Mean          -0.8738396
Policy log std Std           0.28280967
Policy log std Max           -0.27239177
Policy log std Min           -2.5631416
Z mean eval                  0.9579337
Z variance eval              0.02732782
total_rewards                [ -15.73535575 1048.96242971 2315.85440177 2336.86944669 2384.11762374
 2280.17692143  793.024543   2424.75460605 2474.78193853 2547.39673388]
total_rewards_mean           1859.0203289050091
total_rewards_std            858.5142161815652
total_rewards_max            2547.3967338756975
total_rewards_min            -15.735355746450848
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               35.17969151074067
(Previous) Eval Time (s)     32.664120947010815
Sample Time (s)              25.979504079092294
Epoch Time (s)               93.82331653684378
Total Train Time (s)         20257.217594955582
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:23:58.203469 UTC | [2020_01_10_11_46_20] Iteration #225 | Epoch Duration: 88.53651642799377
2020-01-10 17:23:58.203675 UTC | [2020_01_10_11_46_20] Iteration #225 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9559921
Z variance train             0.027354335
KL Divergence                19.715256
KL Loss                      1.9715255
QF Loss                      349.02133
VF Loss                      97.669
Policy Loss                  -840.94806
Q Predictions Mean           839.5471
Q Predictions Std            223.8463
Q Predictions Max            1031.0383
Q Predictions Min            16.247255
V Predictions Mean           845.98816
V Predictions Std            225.51619
V Predictions Max            1034.7814
V Predictions Min            22.681538
Log Pis Mean                 -0.9425688
Log Pis Std                  2.6477735
Log Pis Max                  8.551403
Log Pis Min                  -8.543349
Policy mu Mean               0.021682069
Policy mu Std                0.5681604
Policy mu Max                1.9936376
Policy mu Min                -1.7844929
Policy log std Mean          -0.88037586
Policy log std Std           0.27051198
Policy log std Max           -0.2769324
Policy log std Min           -1.9506756
Z mean eval                  0.9845847
Z variance eval              0.024774468
total_rewards                [2238.0090258  2218.90198242  148.76903588 2444.63492478 1644.694576
 2448.81220075 2188.58067094 2165.08972698 2289.46876342 2345.32345429]
total_rewards_mean           2013.2284361277748
total_rewards_std            657.3511112218124
total_rewards_max            2448.812200753112
total_rewards_min            148.7690358830071
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               36.38800316490233
(Previous) Eval Time (s)     27.376906618010253
Sample Time (s)              27.559546968434006
Epoch Time (s)               91.32445675134659
Total Train Time (s)         20355.70943329949
Epoch                        226
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:25:36.700315 UTC | [2020_01_10_11_46_20] Iteration #226 | Epoch Duration: 98.4963915348053
2020-01-10 17:25:36.700791 UTC | [2020_01_10_11_46_20] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9842148
Z variance train             0.024750806
KL Divergence                19.817343
KL Loss                      1.9817343
QF Loss                      392.01404
VF Loss                      94.1727
Policy Loss                  -850.4976
Q Predictions Mean           847.7197
Q Predictions Std            197.32553
Q Predictions Max            1052.0497
Q Predictions Min            -36.85477
V Predictions Mean           852.9679
V Predictions Std            195.05835
V Predictions Max            1053.7001
V Predictions Min            37.51716
Log Pis Mean                 -0.40270674
Log Pis Std                  2.7934496
Log Pis Max                  9.616783
Log Pis Min                  -10.609797
Policy mu Mean               0.009757394
Policy mu Std                0.6122278
Policy mu Max                2.4010675
Policy mu Min                -1.9697136
Policy log std Mean          -0.8738773
Policy log std Std           0.247717
Policy log std Max           -0.33244488
Policy log std Min           -2.2737923
Z mean eval                  0.97366315
Z variance eval              0.024507044
total_rewards                [2215.85958421 1961.10363303 2479.18665172 2354.01600576 2329.32702763
   44.35402381 2312.44189511 1065.97286061 2426.75771249  345.16840121]
total_rewards_mean           1753.418779557295
total_rewards_std            872.8491484798892
total_rewards_max            2479.186651720534
total_rewards_min            44.35402380787201
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               35.50052346708253
(Previous) Eval Time (s)     34.548372123390436
Sample Time (s)              25.572586155496538
Epoch Time (s)               95.6214817459695
Total Train Time (s)         20446.783622581046
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:27:07.777135 UTC | [2020_01_10_11_46_20] Iteration #227 | Epoch Duration: 91.07603931427002
2020-01-10 17:27:07.777482 UTC | [2020_01_10_11_46_20] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97252244
Z variance train             0.024466107
KL Divergence                19.582699
KL Loss                      1.95827
QF Loss                      296.1891
VF Loss                      67.28653
Policy Loss                  -829.9786
Q Predictions Mean           828.5576
Q Predictions Std            230.10005
Q Predictions Max            1054.281
Q Predictions Min            116.14103
V Predictions Mean           829.6759
V Predictions Std            228.61804
V Predictions Max            1041.4882
V Predictions Min            120.58957
Log Pis Mean                 -1.1369584
Log Pis Std                  2.2762356
Log Pis Max                  7.225792
Log Pis Min                  -6.289958
Policy mu Mean               -0.08508664
Policy mu Std                0.5535535
Policy mu Max                1.8805938
Policy mu Min                -2.1726391
Policy log std Mean          -0.87143826
Policy log std Std           0.24222925
Policy log std Max           -0.27675462
Policy log std Min           -1.8746743
Z mean eval                  0.94809866
Z variance eval              0.022118744
total_rewards                [2365.98455642 2362.18513355 1457.08580654 1243.64380615  670.60686829
 2638.10090563  541.03983295 2631.22262682 2583.92099144  778.18775902]
total_rewards_mean           1727.1978286832232
total_rewards_std            832.0455244550269
total_rewards_max            2638.100905626703
total_rewards_min            541.0398329549602
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               35.96699581295252
(Previous) Eval Time (s)     30.002520686015487
Sample Time (s)              27.35933136800304
Epoch Time (s)               93.32884786697105
Total Train Time (s)         20543.367231159005
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:28:44.364631 UTC | [2020_01_10_11_46_20] Iteration #228 | Epoch Duration: 96.58679056167603
2020-01-10 17:28:44.365060 UTC | [2020_01_10_11_46_20] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9468924
Z variance train             0.022180203
KL Divergence                19.82175
KL Loss                      1.9821751
QF Loss                      368.9491
VF Loss                      75.73159
Policy Loss                  -858.3358
Q Predictions Mean           855.85565
Q Predictions Std            207.72641
Q Predictions Max            1046.9003
Q Predictions Min            -15.717909
V Predictions Mean           861.49316
V Predictions Std            208.04451
V Predictions Max            1046.4012
V Predictions Min            14.351725
Log Pis Mean                 -0.88672787
Log Pis Std                  2.351604
Log Pis Max                  6.763907
Log Pis Min                  -7.337335
Policy mu Mean               -0.022020783
Policy mu Std                0.5667368
Policy mu Max                1.9219055
Policy mu Min                -1.9549088
Policy log std Mean          -0.8856969
Policy log std Std           0.25988412
Policy log std Max           -0.22573286
Policy log std Min           -2.1431804
Z mean eval                  0.9540696
Z variance eval              0.021827249
total_rewards                [2616.5187354  2468.7555663  2655.96053498 2748.65672227 1971.52700361
 2668.82497573 2076.29550677 2117.21548509 1334.28446826 2538.8098074 ]
total_rewards_mean           2319.684880580456
total_rewards_std            420.69053070937986
total_rewards_max            2748.656722267051
total_rewards_min            1334.2844682644075
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               36.50721093919128
(Previous) Eval Time (s)     33.2600300591439
Sample Time (s)              25.678990096319467
Epoch Time (s)               95.44623109465465
Total Train Time (s)         20637.477153048385
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:30:18.476967 UTC | [2020_01_10_11_46_20] Iteration #229 | Epoch Duration: 94.11170530319214
2020-01-10 17:30:18.477251 UTC | [2020_01_10_11_46_20] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9542864
Z variance train             0.021753704
KL Divergence                19.578667
KL Loss                      1.9578667
QF Loss                      664.11975
VF Loss                      96.35463
Policy Loss                  -858.9138
Q Predictions Mean           858.8312
Q Predictions Std            209.29077
Q Predictions Max            1044.6593
Q Predictions Min            109.201485
V Predictions Mean           861.2318
V Predictions Std            208.9356
V Predictions Max            1048.3278
V Predictions Min            111.93076
Log Pis Mean                 -0.79849935
Log Pis Std                  2.5372412
Log Pis Max                  8.432933
Log Pis Min                  -7.0592833
Policy mu Mean               0.014556786
Policy mu Std                0.5973597
Policy mu Max                2.2582812
Policy mu Min                -1.9751253
Policy log std Mean          -0.8790313
Policy log std Std           0.24757321
Policy log std Max           -0.2672229
Policy log std Min           -2.1968482
Z mean eval                  1.001627
Z variance eval              0.020987924
total_rewards                [ 654.9784543  2160.44676985 1423.83904751 2555.72761901  863.58075094
 2325.95735988 2406.89692384 2486.08757799 2379.06295049 1689.091751  ]
total_rewards_mean           1894.5669204794863
total_rewards_std            663.6531640414549
total_rewards_max            2555.7276190054017
total_rewards_min            654.9784542977604
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               35.79995354171842
(Previous) Eval Time (s)     31.92510442668572
Sample Time (s)              25.635867230594158
Epoch Time (s)               93.3609251989983
Total Train Time (s)         20729.152461738326
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:31:50.155390 UTC | [2020_01_10_11_46_20] Iteration #230 | Epoch Duration: 91.67797327041626
2020-01-10 17:31:50.155606 UTC | [2020_01_10_11_46_20] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99475783
Z variance train             0.021039568
KL Divergence                19.940466
KL Loss                      1.9940466
QF Loss                      1252.6349
VF Loss                      251.89099
Policy Loss                  -844.56323
Q Predictions Mean           846.0165
Q Predictions Std            237.65015
Q Predictions Max            1054.2184
Q Predictions Min            90.18924
V Predictions Mean           851.2279
V Predictions Std            237.72177
V Predictions Max            1052.7345
V Predictions Min            84.21815
Log Pis Mean                 -0.62779605
Log Pis Std                  2.7724066
Log Pis Max                  7.756669
Log Pis Min                  -9.52546
Policy mu Mean               -0.001277278
Policy mu Std                0.62963307
Policy mu Max                2.3662374
Policy mu Min                -1.9842796
Policy log std Mean          -0.8664049
Policy log std Std           0.27438667
Policy log std Max           -0.14108664
Policy log std Min           -2.0074403
Z mean eval                  0.96640885
Z variance eval              0.020234514
total_rewards                [1121.77944541 1785.39712325 1927.44008289  232.74345959 2151.72428144
  438.3282491   683.77753483 1929.13699305  691.82846643 1141.54853672]
total_rewards_mean           1210.3704172716873
total_rewards_std            660.1659877583159
total_rewards_max            2151.7242814398983
total_rewards_min            232.74345959383982
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               35.74096374679357
(Previous) Eval Time (s)     30.241751566063613
Sample Time (s)              27.68714537192136
Epoch Time (s)               93.66986068477854
Total Train Time (s)         20817.167376660742
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:33:18.173232 UTC | [2020_01_10_11_46_20] Iteration #231 | Epoch Duration: 88.01748061180115
2020-01-10 17:33:18.173446 UTC | [2020_01_10_11_46_20] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96757877
Z variance train             0.020185929
KL Divergence                19.582104
KL Loss                      1.9582103
QF Loss                      1047.5137
VF Loss                      170.64478
Policy Loss                  -848.32623
Q Predictions Mean           848.4618
Q Predictions Std            208.08665
Q Predictions Max            1019.96747
Q Predictions Min            86.544876
V Predictions Mean           851.0432
V Predictions Std            209.14377
V Predictions Max            1032.5995
V Predictions Min            92.212616
Log Pis Mean                 -0.95798385
Log Pis Std                  2.6512065
Log Pis Max                  9.873369
Log Pis Min                  -9.019809
Policy mu Mean               -0.0066873287
Policy mu Std                0.5851628
Policy mu Max                3.0474663
Policy mu Min                -1.8512309
Policy log std Mean          -0.90964234
Policy log std Std           0.2690263
Policy log std Max           -0.26310116
Policy log std Min           -2.114673
Z mean eval                  0.9935826
Z variance eval              0.022163536
total_rewards                [2278.33620885 -105.5879478  2558.7460488  2182.55118348  256.56238191
 2326.51660783   80.36399633 1324.3665564  2386.39471513 2101.29315159]
total_rewards_mean           1538.954290251846
total_rewards_std            1008.865412552772
total_rewards_max            2558.746048802184
total_rewards_min            -105.58794779787146
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               33.761465860996395
(Previous) Eval Time (s)     24.588899909052998
Sample Time (s)              24.52465301984921
Epoch Time (s)               82.8750187898986
Total Train Time (s)         20904.01422545081
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:34:45.023051 UTC | [2020_01_10_11_46_20] Iteration #232 | Epoch Duration: 86.84946322441101
2020-01-10 17:34:45.023287 UTC | [2020_01_10_11_46_20] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9925481
Z variance train             0.02215476
KL Divergence                19.730785
KL Loss                      1.9730786
QF Loss                      645.3185
VF Loss                      120.89525
Policy Loss                  -846.31085
Q Predictions Mean           844.8528
Q Predictions Std            233.32793
Q Predictions Max            1033.7706
Q Predictions Min            98.2568
V Predictions Mean           844.9912
V Predictions Std            231.06364
V Predictions Max            1036.843
V Predictions Min            99.73766
Log Pis Mean                 -0.87722945
Log Pis Std                  2.7030494
Log Pis Max                  7.763338
Log Pis Min                  -8.014829
Policy mu Mean               0.01615972
Policy mu Std                0.5761038
Policy mu Max                2.1903465
Policy mu Min                -2.0941668
Policy log std Mean          -0.86378694
Policy log std Std           0.27790403
Policy log std Max           -0.25482327
Policy log std Min           -2.4010928
Z mean eval                  0.9582497
Z variance eval              0.020948617
total_rewards                [2454.64296821 2479.37281946 1059.58465719 2468.90113415  143.71821576
 2544.09288665 2720.12466618 2032.80465192 2456.81765308  343.06943472]
total_rewards_mean           1870.3129087331085
total_rewards_std            926.721990724092
total_rewards_max            2720.124666183626
total_rewards_min            143.71821575916323
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               33.296611099969596
(Previous) Eval Time (s)     28.56302604591474
Sample Time (s)              24.596089154481888
Epoch Time (s)               86.45572630036622
Total Train Time (s)         20991.502074921038
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:36:12.513830 UTC | [2020_01_10_11_46_20] Iteration #233 | Epoch Duration: 87.49038863182068
2020-01-10 17:36:12.514023 UTC | [2020_01_10_11_46_20] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9583375
Z variance train             0.02096666
KL Divergence                20.075603
KL Loss                      2.0075605
QF Loss                      324.5771
VF Loss                      76.983215
Policy Loss                  -880.04034
Q Predictions Mean           877.5103
Q Predictions Std            211.76627
Q Predictions Max            1062.5201
Q Predictions Min            82.13226
V Predictions Mean           874.87286
V Predictions Std            211.91476
V Predictions Max            1063.231
V Predictions Min            48.618225
Log Pis Mean                 -0.7419846
Log Pis Std                  2.6605942
Log Pis Max                  10.615229
Log Pis Min                  -6.774155
Policy mu Mean               0.03057905
Policy mu Std                0.58535814
Policy mu Max                1.9545587
Policy mu Min                -1.9727955
Policy log std Mean          -0.9145683
Policy log std Std           0.24705403
Policy log std Max           -0.2759742
Policy log std Min           -2.0179949
Z mean eval                  0.94712555
Z variance eval              0.017846074
total_rewards                [ 207.85564089 2500.35309496 2581.34012671 2476.18851947 1257.51298864
 2402.67737396 2601.45518827 2229.29393788  738.33557245 2735.83562478]
total_rewards_mean           1973.0848067993234
total_rewards_std            853.2651096634573
total_rewards_max            2735.835624780593
total_rewards_min            207.85564088948186
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               33.08988253492862
(Previous) Eval Time (s)     29.597313764039427
Sample Time (s)              23.261713415849954
Epoch Time (s)               85.948909714818
Total Train Time (s)         21074.29362237593
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:37:35.308636 UTC | [2020_01_10_11_46_20] Iteration #234 | Epoch Duration: 82.79446840286255
2020-01-10 17:37:35.308867 UTC | [2020_01_10_11_46_20] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9492425
Z variance train             0.017803181
KL Divergence                19.593447
KL Loss                      1.9593447
QF Loss                      588.82874
VF Loss                      249.29102
Policy Loss                  -832.2904
Q Predictions Mean           833.6202
Q Predictions Std            257.84607
Q Predictions Max            1039.9917
Q Predictions Min            0.5700022
V Predictions Mean           845.3269
V Predictions Std            262.0726
V Predictions Max            1045.6704
V Predictions Min            -12.130879
Log Pis Mean                 -0.5602689
Log Pis Std                  2.793105
Log Pis Max                  9.653895
Log Pis Min                  -7.9378614
Policy mu Mean               0.020729765
Policy mu Std                0.5850397
Policy mu Max                2.0160677
Policy mu Min                -2.9709756
Policy log std Mean          -0.9163406
Policy log std Std           0.2771226
Policy log std Max           -0.21676448
Policy log std Min           -2.3251958
Z mean eval                  0.9514233
Z variance eval              0.017449861
total_rewards                [-145.65818079 2183.21159838 2264.62516068  818.48995475 2278.63237894
 2757.71279744 2428.89858118 2378.4071744  2502.57590204 2020.27686584]
total_rewards_mean           1948.7172232846303
total_rewards_std            854.9276639911894
total_rewards_max            2757.712797435369
total_rewards_min            -145.65818079472797
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               33.363245831336826
(Previous) Eval Time (s)     26.442589388228953
Sample Time (s)              25.100154682062566
Epoch Time (s)               84.90598990162835
Total Train Time (s)         21167.13927720394
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:39:08.157233 UTC | [2020_01_10_11_46_20] Iteration #235 | Epoch Duration: 92.84820556640625
2020-01-10 17:39:08.157442 UTC | [2020_01_10_11_46_20] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9477741
Z variance train             0.017445628
KL Divergence                19.529177
KL Loss                      1.9529177
QF Loss                      556.27856
VF Loss                      81.060875
Policy Loss                  -863.9154
Q Predictions Mean           862.4287
Q Predictions Std            226.68143
Q Predictions Max            1045.4022
Q Predictions Min            94.0287
V Predictions Mean           859.93677
V Predictions Std            225.85562
V Predictions Max            1043.3105
V Predictions Min            89.99284
Log Pis Mean                 -0.9218643
Log Pis Std                  2.7449057
Log Pis Max                  8.142019
Log Pis Min                  -8.070655
Policy mu Mean               -0.0518807
Policy mu Std                0.57435703
Policy mu Max                1.8920753
Policy mu Min                -2.1988914
Policy log std Mean          -0.90399873
Policy log std Std           0.26894963
Policy log std Max           -0.20153362
Policy log std Min           -1.9722192
Z mean eval                  1.0142723
Z variance eval              0.012901032
total_rewards                [1330.98177185  411.78416421 1834.79238607  985.64063258 1034.75058012
   98.61065339 2169.11825235 2623.28350432 2682.83456505  941.22507849]
total_rewards_mean           1411.3021588414413
total_rewards_std            843.3220327059172
total_rewards_max            2682.834565049246
total_rewards_min            98.61065338675223
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               33.8130823452957
(Previous) Eval Time (s)     34.38442902592942
Sample Time (s)              26.180854040198028
Epoch Time (s)               94.37836541142315
Total Train Time (s)         21248.97609031666
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:40:29.996611 UTC | [2020_01_10_11_46_20] Iteration #236 | Epoch Duration: 81.83902525901794
2020-01-10 17:40:29.996810 UTC | [2020_01_10_11_46_20] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0139667
Z variance train             0.012921351
KL Divergence                20.43222
KL Loss                      2.0432222
QF Loss                      925.9003
VF Loss                      156.92082
Policy Loss                  -865.08154
Q Predictions Mean           863.4331
Q Predictions Std            228.72508
Q Predictions Max            1069.3092
Q Predictions Min            77.09514
V Predictions Mean           865.64343
V Predictions Std            227.35631
V Predictions Max            1072.3685
V Predictions Min            84.508095
Log Pis Mean                 -0.6809763
Log Pis Std                  2.8675435
Log Pis Max                  9.171507
Log Pis Min                  -8.72954
Policy mu Mean               0.034313884
Policy mu Std                0.5904157
Policy mu Max                2.0439546
Policy mu Min                -3.1071892
Policy log std Mean          -0.8982483
Policy log std Std           0.2815176
Policy log std Max           -0.20320916
Policy log std Min           -2.364419
Z mean eval                  1.0075859
Z variance eval              0.010434742
total_rewards                [2662.48814676  741.80561224 1104.55744356  305.25085494 2418.44302077
 1176.18141977 2608.84273613 2607.8308825  2618.20884578 2620.35900099]
total_rewards_mean           1886.396796343382
total_rewards_std            890.3833871259806
total_rewards_max            2662.488146764852
total_rewards_min            305.2508549377435
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               33.60463827010244
(Previous) Eval Time (s)     21.84472001483664
Sample Time (s)              25.745701326988637
Epoch Time (s)               81.19505961192772
Total Train Time (s)         21338.5817575017
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:41:59.606099 UTC | [2020_01_10_11_46_20] Iteration #237 | Epoch Duration: 89.60914397239685
2020-01-10 17:41:59.606288 UTC | [2020_01_10_11_46_20] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.010207
Z variance train             0.010462692
KL Divergence                20.855066
KL Loss                      2.0855067
QF Loss                      505.07104
VF Loss                      131.18092
Policy Loss                  -872.4489
Q Predictions Mean           872.48376
Q Predictions Std            238.90475
Q Predictions Max            1086.6118
Q Predictions Min            -30.534796
V Predictions Mean           877.9521
V Predictions Std            240.05936
V Predictions Max            1083.331
V Predictions Min            1.3483808
Log Pis Mean                 -0.61552703
Log Pis Std                  2.9269545
Log Pis Max                  8.200149
Log Pis Min                  -8.764735
Policy mu Mean               -0.00053760316
Policy mu Std                0.5836227
Policy mu Max                2.1173048
Policy mu Min                -2.150689
Policy log std Mean          -0.90979624
Policy log std Std           0.28910002
Policy log std Max           -0.29303205
Policy log std Min           -2.1298063
Z mean eval                  0.9649374
Z variance eval              0.014487453
total_rewards                [ -30.23442435 1284.24433649 1154.89097054 2652.21869444 2580.77292796
  878.77137019 1387.48473256 2452.33909253 2529.62396219 2568.10503052]
total_rewards_mean           1745.821669307335
total_rewards_std            889.1103168573442
total_rewards_max            2652.21869443957
total_rewards_min            -30.23442434543388
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               34.24187934072688
(Previous) Eval Time (s)     30.258448360022157
Sample Time (s)              25.281624370720237
Epoch Time (s)               89.78195207146928
Total Train Time (s)         21424.93851671135
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:43:25.964731 UTC | [2020_01_10_11_46_20] Iteration #238 | Epoch Duration: 86.358314037323
2020-01-10 17:43:25.964909 UTC | [2020_01_10_11_46_20] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9651089
Z variance train             0.0144765135
KL Divergence                20.326807
KL Loss                      2.0326807
QF Loss                      622.32196
VF Loss                      74.65666
Policy Loss                  -899.26263
Q Predictions Mean           897.4667
Q Predictions Std            205.73645
Q Predictions Max            1090.6464
Q Predictions Min            69.596535
V Predictions Mean           894.78125
V Predictions Std            206.52165
V Predictions Max            1092.1934
V Predictions Min            48.721584
Log Pis Mean                 -0.6593479
Log Pis Std                  2.4519048
Log Pis Max                  9.249712
Log Pis Min                  -6.6364713
Policy mu Mean               0.00018825755
Policy mu Std                0.57670915
Policy mu Max                2.0838525
Policy mu Min                -2.8539805
Policy log std Mean          -0.88587403
Policy log std Std           0.2532439
Policy log std Max           -0.2925467
Policy log std Min           -2.3246531
Z mean eval                  0.97374666
Z variance eval              0.011823485
total_rewards                [2276.4277933   205.67272441 1953.34915183 1084.92177779 2521.95805542
 2411.3072582  1861.79591239 2623.87763671 2471.49743134 2438.57798716]
total_rewards_mean           1984.9385728550938
total_rewards_std            734.7037982486598
total_rewards_max            2623.877636709832
total_rewards_min            205.67272441473867
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               33.79547020513564
(Previous) Eval Time (s)     26.834451344795525
Sample Time (s)              24.92199765658006
Epoch Time (s)               85.55191920651123
Total Train Time (s)         21517.63936827611
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:44:58.669976 UTC | [2020_01_10_11_46_20] Iteration #239 | Epoch Duration: 92.7049126625061
2020-01-10 17:44:58.670461 UTC | [2020_01_10_11_46_20] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9718971
Z variance train             0.011794791
KL Divergence                20.616695
KL Loss                      2.0616696
QF Loss                      641.47546
VF Loss                      108.28927
Policy Loss                  -859.44635
Q Predictions Mean           857.7334
Q Predictions Std            241.68407
Q Predictions Max            1055.5424
Q Predictions Min            29.79404
V Predictions Mean           863.98175
V Predictions Std            243.0892
V Predictions Max            1065.1226
V Predictions Min            38.14527
Log Pis Mean                 -0.84301484
Log Pis Std                  2.3309631
Log Pis Max                  6.5385323
Log Pis Min                  -7.9621487
Policy mu Mean               -0.01854654
Policy mu Std                0.5664853
Policy mu Max                1.9583106
Policy mu Min                -2.1486278
Policy log std Mean          -0.89930034
Policy log std Std           0.24921958
Policy log std Max           -0.27677253
Policy log std Min           -2.1265588
Z mean eval                  1.0171093
Z variance eval              0.014657391
total_rewards                [2034.03297814 2535.89558228 1922.26196878  463.20222753  704.45166561
 1058.30691469  906.434103   2475.68359446 1583.19052017   26.23221708]
total_rewards_mean           1370.9691771724767
total_rewards_std            821.962113675412
total_rewards_max            2535.895582275527
total_rewards_min            26.23221707603784
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               33.549160826951265
(Previous) Eval Time (s)     33.98709278320894
Sample Time (s)              25.68322140071541
Epoch Time (s)               93.21947501087561
Total Train Time (s)         21603.86735731177
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:46:24.900269 UTC | [2020_01_10_11_46_20] Iteration #240 | Epoch Duration: 86.22945857048035
2020-01-10 17:46:24.900488 UTC | [2020_01_10_11_46_20] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0172424
Z variance train             0.01462138
KL Divergence                20.203152
KL Loss                      2.0203152
QF Loss                      502.79095
VF Loss                      117.81951
Policy Loss                  -885.252
Q Predictions Mean           884.2875
Q Predictions Std            219.72061
Q Predictions Max            1065.4326
Q Predictions Min            81.48816
V Predictions Mean           887.4484
V Predictions Std            219.71469
V Predictions Max            1069.7904
V Predictions Min            79.414345
Log Pis Mean                 -0.90223277
Log Pis Std                  2.2486565
Log Pis Max                  10.908801
Log Pis Min                  -6.2249117
Policy mu Mean               0.03538147
Policy mu Std                0.5578362
Policy mu Max                2.0837336
Policy mu Min                -2.0198352
Policy log std Mean          -0.8808771
Policy log std Std           0.24921317
Policy log std Max           -0.3298873
Policy log std Min           -2.2309613
Z mean eval                  0.9802438
Z variance eval              0.014290893
total_rewards                [2490.84989327 2379.64562552 2448.50652957 2831.35649568 2342.16845958
  153.51357677 2334.39763959  838.60627223  336.28159862 1306.73455299]
total_rewards_mean           1746.20606438209
total_rewards_std            941.758300648159
total_rewards_max            2831.3564956849214
total_rewards_min            153.51357676946026
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               33.313584216404706
(Previous) Eval Time (s)     26.99674221407622
Sample Time (s)              25.60405341349542
Epoch Time (s)               85.91437984397635
Total Train Time (s)         21689.67490295507
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:47:50.711680 UTC | [2020_01_10_11_46_20] Iteration #241 | Epoch Duration: 85.8109622001648
2020-01-10 17:47:50.712037 UTC | [2020_01_10_11_46_20] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9790455
Z variance train             0.014287367
KL Divergence                20.175564
KL Loss                      2.0175564
QF Loss                      1106.6045
VF Loss                      99.66409
Policy Loss                  -892.4169
Q Predictions Mean           892.57324
Q Predictions Std            201.10252
Q Predictions Max            1098.3073
Q Predictions Min            55.201523
V Predictions Mean           896.7388
V Predictions Std            199.9507
V Predictions Max            1109.5405
V Predictions Min            77.479515
Log Pis Mean                 -0.7062918
Log Pis Std                  2.5192413
Log Pis Max                  11.36926
Log Pis Min                  -8.325424
Policy mu Mean               0.07588396
Policy mu Std                0.54550743
Policy mu Max                2.5762382
Policy mu Min                -1.9100732
Policy log std Mean          -0.91317356
Policy log std Std           0.26212242
Policy log std Max           -0.25524962
Policy log std Min           -2.2910013
Z mean eval                  0.97066486
Z variance eval              0.0109276865
total_rewards                [ 600.20810741 2488.45324809  972.44676045   95.19716821  868.29704543
 2511.98089552 2397.16033013 1261.80731753 2611.65652459 2429.28037172]
total_rewards_mean           1623.6487769090274
total_rewards_std            909.3781994118594
total_rewards_max            2611.6565245882507
total_rewards_min            95.19716821325953
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               33.60566781833768
(Previous) Eval Time (s)     26.892939758021384
Sample Time (s)              25.785625546704978
Epoch Time (s)               86.28423312306404
Total Train Time (s)         21773.877833116334
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:49:14.916701 UTC | [2020_01_10_11_46_20] Iteration #242 | Epoch Duration: 84.20448422431946
2020-01-10 17:49:14.916885 UTC | [2020_01_10_11_46_20] Iteration #242 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97083634
Z variance train             0.010910579
KL Divergence                20.290741
KL Loss                      2.0290742
QF Loss                      486.8325
VF Loss                      89.7197
Policy Loss                  -885.3152
Q Predictions Mean           881.8672
Q Predictions Std            242.9754
Q Predictions Max            1080.1882
Q Predictions Min            70.660805
V Predictions Mean           883.19775
V Predictions Std            241.54956
V Predictions Max            1080.2064
V Predictions Min            83.599945
Log Pis Mean                 -0.50418043
Log Pis Std                  2.5250442
Log Pis Max                  5.5137563
Log Pis Min                  -6.2290688
Policy mu Mean               0.018911459
Policy mu Std                0.597264
Policy mu Max                2.1088982
Policy mu Min                -2.2196255
Policy log std Mean          -0.90107566
Policy log std Std           0.25648847
Policy log std Max           -0.19551939
Policy log std Min           -1.965419
Z mean eval                  0.9994792
Z variance eval              0.024718069
total_rewards                [2625.44832539 2547.84381815  335.47850396  207.94644784 2481.3994
  853.29466618 2583.84750759 1407.16382822 2398.9440086  2288.95388526]
total_rewards_mean           1773.0320391187647
total_rewards_std            929.5118860006718
total_rewards_max            2625.4483253898607
total_rewards_min            207.94644783501727
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               33.698404762893915
(Previous) Eval Time (s)     24.812825626693666
Sample Time (s)              26.20289094746113
Epoch Time (s)               84.71412133704871
Total Train Time (s)         21861.882303370163
Epoch                        243
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:50:42.924180 UTC | [2020_01_10_11_46_20] Iteration #243 | Epoch Duration: 88.00717258453369
2020-01-10 17:50:42.924330 UTC | [2020_01_10_11_46_20] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0008066
Z variance train             0.024706999
KL Divergence                20.130339
KL Loss                      2.0130339
QF Loss                      812.9598
VF Loss                      104.83934
Policy Loss                  -895.5621
Q Predictions Mean           891.32385
Q Predictions Std            222.43301
Q Predictions Max            1099.0089
Q Predictions Min            -15.227353
V Predictions Mean           896.303
V Predictions Std            222.30305
V Predictions Max            1106.8281
V Predictions Min            6.3934436
Log Pis Mean                 -0.79701924
Log Pis Std                  2.3749168
Log Pis Max                  8.442252
Log Pis Min                  -7.1192446
Policy mu Mean               0.026063144
Policy mu Std                0.58634746
Policy mu Max                1.9858729
Policy mu Min                -2.226748
Policy log std Mean          -0.8893844
Policy log std Std           0.24217822
Policy log std Max           -0.19309616
Policy log std Min           -2.4878373
Z mean eval                  0.97725356
Z variance eval              0.018804345
total_rewards                [2567.14307732 2502.36876855 2259.05089007 2468.15177176 2399.06782637
 2516.83766571 2452.26153871  974.37570421 2578.64064017 2485.37594908]
total_rewards_mean           2320.3273831947017
total_rewards_std            456.8850589819721
total_rewards_max            2578.6406401666177
total_rewards_min            974.3757042136716
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               33.91315203811973
(Previous) Eval Time (s)     28.10549200605601
Sample Time (s)              25.41538618505001
Epoch Time (s)               87.43403022922575
Total Train Time (s)         21954.102409042418
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:52:15.148147 UTC | [2020_01_10_11_46_20] Iteration #244 | Epoch Duration: 92.22370100021362
2020-01-10 17:52:15.148344 UTC | [2020_01_10_11_46_20] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9781005
Z variance train             0.01882593
KL Divergence                20.221756
KL Loss                      2.0221756
QF Loss                      769.633
VF Loss                      104.01834
Policy Loss                  -896.504
Q Predictions Mean           895.0364
Q Predictions Std            203.73866
Q Predictions Max            1076.4735
Q Predictions Min            62.59643
V Predictions Mean           896.78094
V Predictions Std            203.48045
V Predictions Max            1078.3501
V Predictions Min            70.02704
Log Pis Mean                 -0.91413176
Log Pis Std                  2.6152225
Log Pis Max                  10.447153
Log Pis Min                  -8.239297
Policy mu Mean               0.05687586
Policy mu Std                0.55436146
Policy mu Max                2.046681
Policy mu Min                -2.18372
Policy log std Mean          -0.9051597
Policy log std Std           0.27042124
Policy log std Max           -0.21133393
Policy log std Min           -2.5243826
Z mean eval                  1.0003934
Z variance eval              0.01864834
total_rewards                [1597.56025058 2594.35475103 2637.88077993 2660.49668255  490.76959576
 2262.39069819 1768.38095057 1709.73976094 1924.04312834 2593.19986969]
total_rewards_mean           2023.8816467589527
total_rewards_std            647.6757647394386
total_rewards_max            2660.496682552577
total_rewards_min            490.76959575985904
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               33.25959703698754
(Previous) Eval Time (s)     32.89479945739731
Sample Time (s)              25.377798749133945
Epoch Time (s)               91.5321952435188
Total Train Time (s)         22038.578936033417
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:53:39.628449 UTC | [2020_01_10_11_46_20] Iteration #245 | Epoch Duration: 84.47989201545715
2020-01-10 17:53:39.628751 UTC | [2020_01_10_11_46_20] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0008644
Z variance train             0.01864684
KL Divergence                20.23442
KL Loss                      2.023442
QF Loss                      995.9955
VF Loss                      148.96843
Policy Loss                  -886.527
Q Predictions Mean           881.59265
Q Predictions Std            242.5901
Q Predictions Max            1072.0343
Q Predictions Min            -40.516026
V Predictions Mean           879.7025
V Predictions Std            239.41368
V Predictions Max            1080.2584
V Predictions Min            9.992139
Log Pis Mean                 -0.63878584
Log Pis Std                  2.579542
Log Pis Max                  7.0621195
Log Pis Min                  -9.793134
Policy mu Mean               0.0032524308
Policy mu Std                0.6024549
Policy mu Max                2.4727898
Policy mu Min                -2.5623164
Policy log std Mean          -0.8838955
Policy log std Std           0.2742983
Policy log std Max           -0.08326393
Policy log std Min           -2.3444703
Z mean eval                  0.98999655
Z variance eval              0.01581646
total_rewards                [2274.54008219 1070.24931319 2554.27472926 2220.7583537  2371.75716261
 1564.08909307 2459.46456345 2341.96757413 2364.10518386 2336.92464089]
total_rewards_mean           2155.813069634162
total_rewards_std            442.19319397775155
total_rewards_max            2554.274729261919
total_rewards_min            1070.2493131885853
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               33.569535008165985
(Previous) Eval Time (s)     25.84213845198974
Sample Time (s)              25.211774241179228
Epoch Time (s)               84.62344770133495
Total Train Time (s)         22130.054694634862
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:55:11.107412 UTC | [2020_01_10_11_46_20] Iteration #246 | Epoch Duration: 91.47849655151367
2020-01-10 17:55:11.107666 UTC | [2020_01_10_11_46_20] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9917321
Z variance train             0.015821692
KL Divergence                20.447618
KL Loss                      2.044762
QF Loss                      529.1668
VF Loss                      220.66441
Policy Loss                  -869.06104
Q Predictions Mean           865.0035
Q Predictions Std            271.74295
Q Predictions Max            1106.7336
Q Predictions Min            67.26044
V Predictions Mean           865.3849
V Predictions Std            270.94656
V Predictions Max            1106.8517
V Predictions Min            66.005745
Log Pis Mean                 -0.64957285
Log Pis Std                  2.7114933
Log Pis Max                  7.8587475
Log Pis Min                  -7.452834
Policy mu Mean               -0.009601059
Policy mu Std                0.5791139
Policy mu Max                1.9528825
Policy mu Min                -1.8990237
Policy log std Mean          -0.89451367
Policy log std Std           0.28317472
Policy log std Max           -0.22341925
Policy log std Min           -2.308113
Z mean eval                  0.9717639
Z variance eval              0.029619396
total_rewards                [2549.71450146 2612.70450008 2547.98305384 2633.16145709 2490.12056975
  821.25258139 2425.85029517 2705.5461974  2619.79436646  684.40149795]
total_rewards_mean           2209.0529020601352
total_rewards_std            732.4952267840348
total_rewards_max            2705.546197404222
total_rewards_min            684.4014979479491
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               33.267913127783686
(Previous) Eval Time (s)     32.69683205103502
Sample Time (s)              26.432301001623273
Epoch Time (s)               92.39704618044198
Total Train Time (s)         22217.346965576522
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:56:38.401770 UTC | [2020_01_10_11_46_20] Iteration #247 | Epoch Duration: 87.29395914077759
2020-01-10 17:56:38.401888 UTC | [2020_01_10_11_46_20] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97331667
Z variance train             0.029561128
KL Divergence                19.419224
KL Loss                      1.9419224
QF Loss                      1170.2268
VF Loss                      307.29
Policy Loss                  -899.19025
Q Predictions Mean           897.77606
Q Predictions Std            236.57391
Q Predictions Max            1101.8317
Q Predictions Min            79.97473
V Predictions Mean           898.6054
V Predictions Std            236.88165
V Predictions Max            1093.6495
V Predictions Min            67.44116
Log Pis Mean                 -0.81708914
Log Pis Std                  2.782706
Log Pis Max                  13.642157
Log Pis Min                  -9.061188
Policy mu Mean               0.012010462
Policy mu Std                0.5774457
Policy mu Max                2.1737788
Policy mu Min                -2.2311842
Policy log std Mean          -0.8701241
Policy log std Std           0.25601113
Policy log std Max           -0.25751203
Policy log std Min           -2.2766519
Z mean eval                  0.96668786
Z variance eval              0.026773889
total_rewards                [2619.27223563  430.74672725  -61.75662116 2391.73311099   66.45462619
 1776.22215014  687.12353771 2410.35723015 1160.7280665  2272.52071638]
total_rewards_mean           1375.3401779800681
total_rewards_std            990.3386803495712
total_rewards_max            2619.272235633541
total_rewards_min            -61.75662115930632
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               33.078661791048944
(Previous) Eval Time (s)     27.593433367088437
Sample Time (s)              24.67855172045529
Epoch Time (s)               85.35064687859267
Total Train Time (s)         22305.18135190569
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:58:06.239945 UTC | [2020_01_10_11_46_20] Iteration #248 | Epoch Duration: 87.83796334266663
2020-01-10 17:58:06.240112 UTC | [2020_01_10_11_46_20] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9657912
Z variance train             0.02681398
KL Divergence                19.82584
KL Loss                      1.982584
QF Loss                      1463.9674
VF Loss                      152.16484
Policy Loss                  -918.20996
Q Predictions Mean           917.0552
Q Predictions Std            218.18282
Q Predictions Max            1103.3818
Q Predictions Min            71.31942
V Predictions Mean           919.1173
V Predictions Std            216.95091
V Predictions Max            1105.7686
V Predictions Min            72.05714
Log Pis Mean                 -0.5297351
Log Pis Std                  2.715684
Log Pis Max                  9.617489
Log Pis Min                  -7.84748
Policy mu Mean               0.0015728087
Policy mu Std                0.6246396
Policy mu Max                2.2998114
Policy mu Min                -2.7621715
Policy log std Mean          -0.8767272
Policy log std Std           0.2746748
Policy log std Max           -0.022576928
Policy log std Min           -1.9737289
Z mean eval                  1.0007515
Z variance eval              0.0236332
total_rewards                [2511.32093278 2452.29987085 2037.0370093  1062.18374771 2393.71796291
  491.21321585 1818.55775581  370.61443261  424.04950941 2449.01594729]
total_rewards_mean           1601.00103845291
total_rewards_std            869.4480374722497
total_rewards_max            2511.3209327841714
total_rewards_min            370.614432614541
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               34.252954073715955
(Previous) Eval Time (s)     30.080434835981578
Sample Time (s)              25.466532416641712
Epoch Time (s)               89.79992132633924
Total Train Time (s)         22396.79659260111
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:59:37.858091 UTC | [2020_01_10_11_46_20] Iteration #249 | Epoch Duration: 91.61783933639526
2020-01-10 17:59:37.858332 UTC | [2020_01_10_11_46_20] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99899733
Z variance train             0.023702968
KL Divergence                20.41489
KL Loss                      2.0414891
QF Loss                      1247.3204
VF Loss                      167.47382
Policy Loss                  -910.25
Q Predictions Mean           907.5802
Q Predictions Std            244.26114
Q Predictions Max            1100.9431
Q Predictions Min            61.172905
V Predictions Mean           911.81287
V Predictions Std            243.02362
V Predictions Max            1087.963
V Predictions Min            63.45789
Log Pis Mean                 -0.49041468
Log Pis Std                  2.7541738
Log Pis Max                  10.549419
Log Pis Min                  -12.814472
Policy mu Mean               0.1216287
Policy mu Std                0.5882464
Policy mu Max                3.361469
Policy mu Min                -1.8701748
Policy log std Mean          -0.8954289
Policy log std Std           0.26677224
Policy log std Max           -0.2899618
Policy log std Min           -2.288165
Z mean eval                  0.9754842
Z variance eval              0.025611544
total_rewards                [2616.06499656 2509.9759901  2760.02273311 2763.41717177 -135.66451178
 2088.62185648 2841.55710943 2666.38389859 1080.10913642 2598.9564543 ]
total_rewards_mean           2178.944483498816
total_rewards_std            916.8419321694626
total_rewards_max            2841.5571094309885
total_rewards_min            -135.66451178288366
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               33.18877941928804
(Previous) Eval Time (s)     31.898037931881845
Sample Time (s)              25.95094931125641
Epoch Time (s)               91.0377666624263
Total Train Time (s)         22489.247509845067
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:01:10.311730 UTC | [2020_01_10_11_46_20] Iteration #250 | Epoch Duration: 92.4532539844513
2020-01-10 18:01:10.311900 UTC | [2020_01_10_11_46_20] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97494614
Z variance train             0.025628924
KL Divergence                20.589052
KL Loss                      2.0589054
QF Loss                      453.61087
VF Loss                      229.41924
Policy Loss                  -927.15094
Q Predictions Mean           923.75146
Q Predictions Std            225.65242
Q Predictions Max            1110.1636
Q Predictions Min            47.55212
V Predictions Mean           916.1846
V Predictions Std            218.33273
V Predictions Max            1098.7946
V Predictions Min            69.52945
Log Pis Mean                 -0.42123735
Log Pis Std                  2.7126498
Log Pis Max                  10.253916
Log Pis Min                  -6.949561
Policy mu Mean               0.03724443
Policy mu Std                0.59806144
Policy mu Max                2.4425392
Policy mu Min                -2.042965
Policy log std Mean          -0.92474854
Policy log std Std           0.27628395
Policy log std Max           -0.1923073
Policy log std Min           -2.5577598
Z mean eval                  0.9996564
Z variance eval              0.017795945
total_rewards                [1107.68350779  631.7857033   566.7707582   595.40621719 2498.31224026
 2326.62653131 1212.15284246  544.10004439 2825.49838841 1598.05979567]
total_rewards_mean           1390.639602896567
total_rewards_std            831.8905711639094
total_rewards_max            2825.498388405805
total_rewards_min            544.1000443883547
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               33.30417075799778
(Previous) Eval Time (s)     33.313220540992916
Sample Time (s)              26.72494131932035
Epoch Time (s)               93.34233261831105
Total Train Time (s)         22573.857250839006
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:02:34.924947 UTC | [2020_01_10_11_46_20] Iteration #251 | Epoch Duration: 84.61290502548218
2020-01-10 18:02:34.925154 UTC | [2020_01_10_11_46_20] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99907225
Z variance train             0.017757082
KL Divergence                21.420338
KL Loss                      2.1420338
QF Loss                      1263.4227
VF Loss                      244.98085
Policy Loss                  -924.1319
Q Predictions Mean           921.72144
Q Predictions Std            215.51588
Q Predictions Max            1089.1132
Q Predictions Min            85.28468
V Predictions Mean           926.5919
V Predictions Std            209.84747
V Predictions Max            1087.794
V Predictions Min            91.67926
Log Pis Mean                 -0.55376124
Log Pis Std                  2.6898358
Log Pis Max                  13.154371
Log Pis Min                  -11.620642
Policy mu Mean               0.06804336
Policy mu Std                0.6031442
Policy mu Max                2.635911
Policy mu Min                -4.2996254
Policy log std Mean          -0.9101677
Policy log std Std           0.25782233
Policy log std Max           -0.014767528
Policy log std Min           -2.0195103
Z mean eval                  0.9749524
Z variance eval              0.014744891
total_rewards                [1854.43566867 2282.4466983  1598.83948866 2564.70811559  387.65040886
  -82.50138147 2855.72227285 2730.89469694  943.98697214 2003.37016004]
total_rewards_mean           1713.9553100565804
total_rewards_std            952.9270813811588
total_rewards_max            2855.7222728501724
total_rewards_min            -82.50138146705379
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               33.27494212985039
(Previous) Eval Time (s)     24.583479619119316
Sample Time (s)              24.59749914612621
Epoch Time (s)               82.45592089509591
Total Train Time (s)         22656.83719667606
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:03:57.907872 UTC | [2020_01_10_11_46_20] Iteration #252 | Epoch Duration: 82.98257541656494
2020-01-10 18:03:57.908067 UTC | [2020_01_10_11_46_20] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97505105
Z variance train             0.01475462
KL Divergence                20.679678
KL Loss                      2.067968
QF Loss                      1727.3248
VF Loss                      170.17795
Policy Loss                  -935.48065
Q Predictions Mean           935.6189
Q Predictions Std            223.21765
Q Predictions Max            1091.3105
Q Predictions Min            37.40608
V Predictions Mean           932.65295
V Predictions Std            225.5133
V Predictions Max            1097.9257
V Predictions Min            0.24647671
Log Pis Mean                 -0.7710397
Log Pis Std                  2.8271189
Log Pis Max                  12.346344
Log Pis Min                  -8.8678465
Policy mu Mean               0.06399044
Policy mu Std                0.60750294
Policy mu Max                2.2672842
Policy mu Min                -2.2288792
Policy log std Mean          -0.9031236
Policy log std Std           0.26513308
Policy log std Max           -0.12499654
Policy log std Min           -2.2685497
Z mean eval                  1.0123756
Z variance eval              0.016403625
total_rewards                [2466.12484408 2576.05944039 2598.99807054 2690.32880921 2581.45462854
 2364.27957428 1150.13298551 2402.14209193 1959.4780117  2374.12553413]
total_rewards_mean           2316.3123990306076
total_rewards_std            433.62741025012286
total_rewards_max            2690.3288092118096
total_rewards_min            1150.1329855067956
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               32.631422786042094
(Previous) Eval Time (s)     25.109796491917223
Sample Time (s)              24.81970396824181
Epoch Time (s)               82.56092324620113
Total Train Time (s)         22747.172967566643
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:05:28.246492 UTC | [2020_01_10_11_46_20] Iteration #253 | Epoch Duration: 90.33829426765442
2020-01-10 18:05:28.246659 UTC | [2020_01_10_11_46_20] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0131574
Z variance train             0.01643492
KL Divergence                21.081896
KL Loss                      2.1081896
QF Loss                      685.1034
VF Loss                      87.685486
Policy Loss                  -926.8015
Q Predictions Mean           926.1676
Q Predictions Std            232.1296
Q Predictions Max            1112.8997
Q Predictions Min            74.399055
V Predictions Mean           925.1432
V Predictions Std            229.81084
V Predictions Max            1103.4441
V Predictions Min            76.00865
Log Pis Mean                 -0.5743599
Log Pis Std                  2.734128
Log Pis Max                  7.2211847
Log Pis Min                  -6.9609475
Policy mu Mean               -0.016921172
Policy mu Std                0.6106923
Policy mu Max                2.3407233
Policy mu Min                -1.919349
Policy log std Mean          -0.89584637
Policy log std Std           0.25836942
Policy log std Max           -0.24712414
Policy log std Min           -2.1415668
Z mean eval                  0.98965025
Z variance eval              0.0166064
total_rewards                [1732.46086212 2155.9696857  1985.94131274  329.93452825  562.50431621
 2736.13462469 2605.32102629  706.40999057 1417.22774305   58.59525711]
total_rewards_mean           1429.04993467182
total_rewards_std            915.5398872761954
total_rewards_max            2736.1346246874755
total_rewards_min            58.595257107698785
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               33.69878712389618
(Previous) Eval Time (s)     32.88685317710042
Sample Time (s)              26.300523398444057
Epoch Time (s)               92.88616369944066
Total Train Time (s)         22829.340906037018
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:06:50.417467 UTC | [2020_01_10_11_46_20] Iteration #254 | Epoch Duration: 82.17068147659302
2020-01-10 18:06:50.417658 UTC | [2020_01_10_11_46_20] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98791075
Z variance train             0.016578158
KL Divergence                20.608303
KL Loss                      2.0608304
QF Loss                      1250.8345
VF Loss                      504.1111
Policy Loss                  -899.0465
Q Predictions Mean           901.0486
Q Predictions Std            266.50162
Q Predictions Max            1129.2715
Q Predictions Min            67.26793
V Predictions Mean           902.3891
V Predictions Std            265.90866
V Predictions Max            1127.3853
V Predictions Min            76.72577
Log Pis Mean                 -0.7764124
Log Pis Std                  2.7145872
Log Pis Max                  10.59903
Log Pis Min                  -7.325884
Policy mu Mean               0.072025955
Policy mu Std                0.5709857
Policy mu Max                3.014307
Policy mu Min                -2.4548523
Policy log std Mean          -0.89318544
Policy log std Std           0.2798692
Policy log std Max           0.2712294
Policy log std Min           -2.3283126
Z mean eval                  0.95513725
Z variance eval              0.015060413
total_rewards                [1507.94873824 2791.98217485  773.9107949  2411.6729833  2295.63836877
 2548.75557836 1348.26945912 1916.99103215 2575.28916394 1381.63054379]
total_rewards_mean           1955.2088837419992
total_rewards_std            636.8338461187346
total_rewards_max            2791.9821748548147
total_rewards_min            773.9107948963192
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               33.9498147550039
(Previous) Eval Time (s)     22.17098684143275
Sample Time (s)              25.208261240273714
Epoch Time (s)               81.32906283671036
Total Train Time (s)         22915.677509581205
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:08:16.757219 UTC | [2020_01_10_11_46_20] Iteration #255 | Epoch Duration: 86.33942723274231
2020-01-10 18:08:16.757399 UTC | [2020_01_10_11_46_20] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95434856
Z variance train             0.015096272
KL Divergence                21.261852
KL Loss                      2.1261852
QF Loss                      640.469
VF Loss                      173.99042
Policy Loss                  -934.455
Q Predictions Mean           932.9439
Q Predictions Std            219.70279
Q Predictions Max            1111.2975
Q Predictions Min            101.80856
V Predictions Mean           933.1132
V Predictions Std            215.64273
V Predictions Max            1105.7681
V Predictions Min            101.26405
Log Pis Mean                 -0.6794584
Log Pis Std                  2.643345
Log Pis Max                  6.6079984
Log Pis Min                  -7.3315496
Policy mu Mean               0.026930556
Policy mu Std                0.5719573
Policy mu Max                2.1373556
Policy mu Min                -2.4904723
Policy log std Mean          -0.9120078
Policy log std Std           0.2563427
Policy log std Max           -0.2689703
Policy log std Min           -1.9924185
Z mean eval                  0.99379796
Z variance eval              0.013896393
total_rewards                [2382.76356979 2631.22540963 2960.96033213 1995.3356373  1616.13145049
 2668.20448489 2534.49066907 2192.00040121 1998.39676168 1293.3725255 ]
total_rewards_mean           2227.288124167972
total_rewards_std            486.57401850521194
total_rewards_max            2960.9603321264967
total_rewards_min            1293.3725255000688
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               33.558134254068136
(Previous) Eval Time (s)     27.18098895298317
Sample Time (s)              25.497915957588702
Epoch Time (s)               86.23703916464001
Total Train Time (s)         23007.876223789994
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:09:48.959315 UTC | [2020_01_10_11_46_20] Iteration #256 | Epoch Duration: 92.20177912712097
2020-01-10 18:09:48.959542 UTC | [2020_01_10_11_46_20] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9932817
Z variance train             0.013862801
KL Divergence                21.770102
KL Loss                      2.1770103
QF Loss                      537.65515
VF Loss                      139.13873
Policy Loss                  -926.3506
Q Predictions Mean           924.7761
Q Predictions Std            247.40479
Q Predictions Max            1109.0226
Q Predictions Min            70.56258
V Predictions Mean           922.1527
V Predictions Std            247.68681
V Predictions Max            1113.1877
V Predictions Min            53.531403
Log Pis Mean                 -0.4752692
Log Pis Std                  2.5534718
Log Pis Max                  7.418046
Log Pis Min                  -7.146971
Policy mu Mean               0.021465052
Policy mu Std                0.6064634
Policy mu Max                2.6044536
Policy mu Min                -1.9225603
Policy log std Mean          -0.8862847
Policy log std Std           0.25897887
Policy log std Max           -0.15874165
Policy log std Min           -2.1473584
Z mean eval                  1.0141397
Z variance eval              0.017808754
total_rewards                [2571.52333447  497.60284627  366.26170951 1090.64903715 1945.90500056
 1253.13484124 1017.08412304 1344.90075221  281.93892324   74.09577274]
total_rewards_mean           1044.3096340427119
total_rewards_std            745.87323219179
total_rewards_max            2571.5233344652534
total_rewards_min            74.09577273509746
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               33.33428515633568
(Previous) Eval Time (s)     33.145390695892274
Sample Time (s)              25.225006390362978
Epoch Time (s)               91.70468224259093
Total Train Time (s)         23082.613172642887
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:11:03.700675 UTC | [2020_01_10_11_46_20] Iteration #257 | Epoch Duration: 74.74096894264221
2020-01-10 18:11:03.700899 UTC | [2020_01_10_11_46_20] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0156914
Z variance train             0.017792804
KL Divergence                21.711407
KL Loss                      2.1711407
QF Loss                      1318.1782
VF Loss                      177.06114
Policy Loss                  -938.2801
Q Predictions Mean           937.2822
Q Predictions Std            236.73457
Q Predictions Max            1151.7202
Q Predictions Min            63.92644
V Predictions Mean           940.6953
V Predictions Std            236.65349
V Predictions Max            1141.0173
V Predictions Min            65.169495
Log Pis Mean                 -0.6044787
Log Pis Std                  2.8716168
Log Pis Max                  10.931517
Log Pis Min                  -6.9826303
Policy mu Mean               -0.008008812
Policy mu Std                0.599402
Policy mu Max                2.9228473
Policy mu Min                -3.2575014
Policy log std Mean          -0.89623904
Policy log std Std           0.26425192
Policy log std Max           -0.24282998
Policy log std Min           -2.256654
Z mean eval                  1.012057
Z variance eval              0.014588843
total_rewards                [2621.65824344 1068.99273127 2768.51695518 2753.94332589 1503.50587819
 2593.1472851  2647.01859588 2604.4782399  2598.55844193 2792.88730799]
total_rewards_mean           2395.270700476114
total_rewards_std            567.3793000181311
total_rewards_max            2792.8873079857717
total_rewards_min            1068.9927312666034
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               33.57521881908178
(Previous) Eval Time (s)     16.18125032586977
Sample Time (s)              25.753210356924683
Epoch Time (s)               75.50967950187624
Total Train Time (s)         23172.973306394182
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:12:34.063120 UTC | [2020_01_10_11_46_20] Iteration #258 | Epoch Duration: 90.36205744743347
2020-01-10 18:12:34.063435 UTC | [2020_01_10_11_46_20] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0123098
Z variance train             0.014552338
KL Divergence                21.697758
KL Loss                      2.1697757
QF Loss                      603.1341
VF Loss                      301.2908
Policy Loss                  -901.34045
Q Predictions Mean           901.0907
Q Predictions Std            287.37668
Q Predictions Max            1121.896
Q Predictions Min            39.702904
V Predictions Mean           906.5066
V Predictions Std            288.00983
V Predictions Max            1133.7019
V Predictions Min            52.875576
Log Pis Mean                 -0.7079378
Log Pis Std                  2.69057
Log Pis Max                  9.299467
Log Pis Min                  -7.7178626
Policy mu Mean               -0.009073362
Policy mu Std                0.58638525
Policy mu Max                2.165884
Policy mu Min                -2.3433933
Policy log std Mean          -0.8858359
Policy log std Std           0.26494515
Policy log std Max           -0.223438
Policy log std Min           -2.3889017
Z mean eval                  1.0315685
Z variance eval              0.009986499
total_rewards                [2261.95012007  308.24933049  262.83788127 1025.51769114  150.96986428
 1492.14553505  150.29175311  846.35298806 2848.2181977  2532.92802862]
total_rewards_mean           1187.9461389780727
total_rewards_std            986.7273422763965
total_rewards_max            2848.2181977000673
total_rewards_min            150.29175310971183
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               33.11675996426493
(Previous) Eval Time (s)     31.033228762913495
Sample Time (s)              25.145684079267085
Epoch Time (s)               89.29567280644551
Total Train Time (s)         23248.23118007928
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:13:49.324203 UTC | [2020_01_10_11_46_20] Iteration #259 | Epoch Duration: 75.26058149337769
2020-01-10 18:13:49.324393 UTC | [2020_01_10_11_46_20] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0314051
Z variance train             0.009978391
KL Divergence                22.721289
KL Loss                      2.2721288
QF Loss                      401.38348
VF Loss                      255.85172
Policy Loss                  -959.40393
Q Predictions Mean           956.51086
Q Predictions Std            213.06628
Q Predictions Max            1119.8705
Q Predictions Min            118.95474
V Predictions Mean           949.0335
V Predictions Std            209.42859
V Predictions Max            1105.27
V Predictions Min            125.41772
Log Pis Mean                 -0.6087463
Log Pis Std                  2.647287
Log Pis Max                  10.628367
Log Pis Min                  -7.325638
Policy mu Mean               0.0037684808
Policy mu Std                0.60332817
Policy mu Max                2.6834338
Policy mu Min                -2.2165754
Policy log std Mean          -0.9047638
Policy log std Std           0.25347555
Policy log std Max           -0.214203
Policy log std Min           -2.3592453
Z mean eval                  0.9850876
Z variance eval              0.009047205
total_rewards                [2320.69522619 2618.07188133  980.7694748  2647.32512446 1872.73142782
 1624.60494024 2569.94975399 2477.1993895  2597.36126776 2272.26582027]
total_rewards_mean           2198.0974306363855
total_rewards_std            518.7429921922906
total_rewards_max            2647.3251244559683
total_rewards_min            980.7694747983049
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               35.19400143623352
(Previous) Eval Time (s)     16.99780035810545
Sample Time (s)              25.839552846271545
Epoch Time (s)               78.03135464061052
Total Train Time (s)         23340.751774787437
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:15:21.846027 UTC | [2020_01_10_11_46_20] Iteration #260 | Epoch Duration: 92.52150869369507
2020-01-10 18:15:21.846168 UTC | [2020_01_10_11_46_20] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98548853
Z variance train             0.00905992
KL Divergence                22.661419
KL Loss                      2.266142
QF Loss                      513.76483
VF Loss                      157.64795
Policy Loss                  -953.1437
Q Predictions Mean           951.87555
Q Predictions Std            225.6389
Q Predictions Max            1119.3795
Q Predictions Min            -27.546738
V Predictions Mean           957.64874
V Predictions Std            219.31802
V Predictions Max            1122.2295
V Predictions Min            81.71114
Log Pis Mean                 -0.7870426
Log Pis Std                  2.6441436
Log Pis Max                  11.231414
Log Pis Min                  -8.390444
Policy mu Mean               0.032536298
Policy mu Std                0.58742774
Policy mu Max                2.1017902
Policy mu Min                -1.7973444
Policy log std Mean          -0.89915216
Policy log std Std           0.27458584
Policy log std Max           -0.13561332
Policy log std Min           -3.0245485
Z mean eval                  0.9776331
Z variance eval              0.011862978
total_rewards                [2538.87100389 2936.93990968 1858.54393858 2667.02478666 2601.99535519
 2545.64385804 1123.25836219 2761.24738013 2504.97911655 2444.53848272]
total_rewards_mean           2398.304219363498
total_rewards_std            500.76193908506144
total_rewards_max            2936.9399096759826
total_rewards_min            1123.258362193279
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               35.39576538139954
(Previous) Eval Time (s)     31.48760368814692
Sample Time (s)              26.46197649696842
Epoch Time (s)               93.34534556651488
Total Train Time (s)         23435.795204389375
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:16:56.893343 UTC | [2020_01_10_11_46_20] Iteration #261 | Epoch Duration: 95.04704546928406
2020-01-10 18:16:56.893603 UTC | [2020_01_10_11_46_20] Iteration #261 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97725326
Z variance train             0.011857097
KL Divergence                21.89249
KL Loss                      2.189249
QF Loss                      638.9818
VF Loss                      97.43494
Policy Loss                  -971.11017
Q Predictions Mean           970.81213
Q Predictions Std            190.50131
Q Predictions Max            1161.7743
Q Predictions Min            77.40324
V Predictions Mean           971.1522
V Predictions Std            193.67285
V Predictions Max            1167.3087
V Predictions Min            36.04667
Log Pis Mean                 -0.49103117
Log Pis Std                  2.4569287
Log Pis Max                  6.7152004
Log Pis Min                  -10.728796
Policy mu Mean               0.002520145
Policy mu Std                0.60054916
Policy mu Max                1.9555188
Policy mu Min                -2.166389
Policy log std Mean          -0.90322405
Policy log std Std           0.24708086
Policy log std Max           -0.28068948
Policy log std Min           -2.0166943
Z mean eval                  1.0381775
Z variance eval              0.011781463
total_rewards                [  23.78828375  770.40714438  417.96087    2307.7634847  1910.3427983
 1242.85609287  789.19449384  527.596232   2623.96737061 2489.20016808]
total_rewards_mean           1310.307693852949
total_rewards_std            900.116823614184
total_rewards_max            2623.9673706057015
total_rewards_min            23.788283746789475
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               36.98928703088313
(Previous) Eval Time (s)     33.18886824278161
Sample Time (s)              27.72080965945497
Epoch Time (s)               97.89896493311971
Total Train Time (s)         23521.66619484406
Epoch                        262
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:18:22.767580 UTC | [2020_01_10_11_46_20] Iteration #262 | Epoch Duration: 85.87382817268372
2020-01-10 18:18:22.767778 UTC | [2020_01_10_11_46_20] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0393002
Z variance train             0.0117746275
KL Divergence                21.673754
KL Loss                      2.1673753
QF Loss                      792.5237
VF Loss                      371.76984
Policy Loss                  -970.16656
Q Predictions Mean           967.68713
Q Predictions Std            198.4621
Q Predictions Max            1177.2698
Q Predictions Min            86.17739
V Predictions Mean           970.652
V Predictions Std            193.94847
V Predictions Max            1180.1248
V Predictions Min            76.44371
Log Pis Mean                 -0.6814452
Log Pis Std                  2.8258476
Log Pis Max                  12.939787
Log Pis Min                  -8.027373
Policy mu Mean               0.04005412
Policy mu Std                0.5796671
Policy mu Max                2.2247508
Policy mu Min                -2.0610623
Policy log std Mean          -0.9247788
Policy log std Std           0.27801108
Policy log std Max           -0.30021012
Policy log std Min           -2.6045964
Z mean eval                  1.0192269
Z variance eval              0.017332729
total_rewards                [ 680.41250695 1890.55411573 1283.03086305  935.48646606   21.59014359
  486.08706475  187.06295398 2705.18484251  184.1368872  1439.80426752]
total_rewards_mean           981.3350111339348
total_rewards_std            813.9399362852001
total_rewards_max            2705.184842513769
total_rewards_min            21.59014358941138
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               35.505994024686515
(Previous) Eval Time (s)     21.163267454132438
Sample Time (s)              26.078953902237117
Epoch Time (s)               82.74821538105607
Total Train Time (s)         23600.899024485145
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:19:42.003588 UTC | [2020_01_10_11_46_20] Iteration #263 | Epoch Duration: 79.23567628860474
2020-01-10 18:19:42.003766 UTC | [2020_01_10_11_46_20] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0167164
Z variance train             0.017381774
KL Divergence                21.098291
KL Loss                      2.1098292
QF Loss                      784.5349
VF Loss                      144.90602
Policy Loss                  -970.1688
Q Predictions Mean           966.62537
Q Predictions Std            201.65732
Q Predictions Max            1143.8003
Q Predictions Min            97.77099
V Predictions Mean           963.6156
V Predictions Std            203.5746
V Predictions Max            1136.2704
V Predictions Min            106.65788
Log Pis Mean                 -0.685867
Log Pis Std                  2.5259526
Log Pis Max                  8.669655
Log Pis Min                  -7.187154
Policy mu Mean               0.016731542
Policy mu Std                0.5917233
Policy mu Max                2.0897171
Policy mu Min                -3.3072853
Policy log std Mean          -0.90215766
Policy log std Std           0.2508717
Policy log std Max           -0.1853633
Policy log std Min           -2.2900372
Z mean eval                  0.97607356
Z variance eval              0.025517022
total_rewards                [2632.20912642 2625.02371557 2670.181906   2678.40315071 2719.97133119
 2535.64500386 2603.03345898 2802.3625818  2618.32827385 2671.2101351 ]
total_rewards_mean           2655.63686834863
total_rewards_std            68.3248623318719
total_rewards_max            2802.36258180426
total_rewards_min            2535.645003864695
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               36.11519679101184
(Previous) Eval Time (s)     17.650301687885076
Sample Time (s)              26.799134893808514
Epoch Time (s)               80.56463337270543
Total Train Time (s)         23700.032352713402
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:21:21.141048 UTC | [2020_01_10_11_46_20] Iteration #264 | Epoch Duration: 99.13713717460632
2020-01-10 18:21:21.141259 UTC | [2020_01_10_11_46_20] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9793993
Z variance train             0.025536263
KL Divergence                20.580688
KL Loss                      2.058069
QF Loss                      987.19696
VF Loss                      326.02493
Policy Loss                  -970.30084
Q Predictions Mean           974.0571
Q Predictions Std            226.02873
Q Predictions Max            1164.3712
Q Predictions Min            -19.020855
V Predictions Mean           984.9816
V Predictions Std            227.95561
V Predictions Max            1183.1774
V Predictions Min            27.7954
Log Pis Mean                 -0.78719735
Log Pis Std                  2.667765
Log Pis Max                  9.955952
Log Pis Min                  -8.55333
Policy mu Mean               0.040710837
Policy mu Std                0.5590868
Policy mu Max                2.192526
Policy mu Min                -1.9449072
Policy log std Mean          -0.9165565
Policy log std Std           0.27151433
Policy log std Max           -0.2505147
Policy log std Min           -2.1869776
Z mean eval                  1.0035646
Z variance eval              0.023418522
total_rewards                [ 178.2785888  2738.32523427 2611.04739616 2357.81447659 2575.38755008
 2695.83690094 2575.86121604 2674.99204108 2542.57495829 2410.33376183]
total_rewards_mean           2336.0452124071167
total_rewards_std            728.0927774929264
total_rewards_max            2738.3252342679802
total_rewards_min            178.27858880270944
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               35.56079536024481
(Previous) Eval Time (s)     36.222315846942365
Sample Time (s)              26.13725305488333
Epoch Time (s)               97.9203642620705
Total Train Time (s)         23794.441166263074
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:22:55.554035 UTC | [2020_01_10_11_46_20] Iteration #265 | Epoch Duration: 94.41253304481506
2020-01-10 18:22:55.554432 UTC | [2020_01_10_11_46_20] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068102
Z variance train             0.023368483
KL Divergence                20.948414
KL Loss                      2.0948415
QF Loss                      516.8462
VF Loss                      121.88037
Policy Loss                  -951.4052
Q Predictions Mean           949.3325
Q Predictions Std            245.12827
Q Predictions Max            1161.9062
Q Predictions Min            85.49429
V Predictions Mean           946.26434
V Predictions Std            243.53795
V Predictions Max            1152.9714
V Predictions Min            87.03657
Log Pis Mean                 -1.106108
Log Pis Std                  2.5679314
Log Pis Max                  7.3546395
Log Pis Min                  -9.6461115
Policy mu Mean               0.026876057
Policy mu Std                0.5588423
Policy mu Max                3.2438307
Policy mu Min                -1.7686914
Policy log std Mean          -0.88767403
Policy log std Std           0.26232433
Policy log std Max           -0.18074575
Policy log std Min           -2.5223007
Z mean eval                  0.9902865
Z variance eval              0.019706301
total_rewards                [2616.83619999  649.78929296 1013.37881349 2683.76959497  516.14474238
 2714.52306854 2709.34050094 2948.47855389 2417.92530914 1886.72200545]
total_rewards_mean           2015.690808174642
total_rewards_std            891.3301679871278
total_rewards_max            2948.4785538927576
total_rewards_min            516.1447423838849
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               36.48937467392534
(Previous) Eval Time (s)     32.71409270958975
Sample Time (s)              27.231851031072438
Epoch Time (s)               96.43531841458753
Total Train Time (s)         23884.27388707176
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:25.389364 UTC | [2020_01_10_11_46_20] Iteration #266 | Epoch Duration: 89.83474588394165
2020-01-10 18:24:25.389556 UTC | [2020_01_10_11_46_20] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99198514
Z variance train             0.019693187
KL Divergence                20.508764
KL Loss                      2.0508764
QF Loss                      1943.947
VF Loss                      288.01065
Policy Loss                  -964.6401
Q Predictions Mean           966.395
Q Predictions Std            231.61812
Q Predictions Max            1155.6053
Q Predictions Min            85.87115
V Predictions Mean           978.14685
V Predictions Std            232.3419
V Predictions Max            1171.3446
V Predictions Min            94.90305
Log Pis Mean                 -0.62863004
Log Pis Std                  2.5511131
Log Pis Max                  8.7802925
Log Pis Min                  -6.27715
Policy mu Mean               0.068186685
Policy mu Std                0.5662842
Policy mu Max                2.1550791
Policy mu Min                -2.8946736
Policy log std Mean          -0.9107231
Policy log std Std           0.2592266
Policy log std Max           -0.2203219
Policy log std Min           -2.2696738
Z mean eval                  0.9979497
Z variance eval              0.017251866
total_rewards                [ -65.28492056 2590.50460183 2673.39574441 2451.12145125 1229.03959824
  828.13081537   55.76184069 2696.76645157 2510.91565544 1319.13604047]
total_rewards_mean           1628.9487278712827
total_rewards_std            1041.7337850065517
total_rewards_max            2696.7664515717706
total_rewards_min            -65.28492055743648
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               36.62552215065807
(Previous) Eval Time (s)     26.11309408582747
Sample Time (s)              26.815977196674794
Epoch Time (s)               89.55459343316033
Total Train Time (s)         23974.66589228902
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:25:55.784651 UTC | [2020_01_10_11_46_20] Iteration #267 | Epoch Duration: 90.39494633674622
2020-01-10 18:25:55.784868 UTC | [2020_01_10_11_46_20] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9944273
Z variance train             0.01722812
KL Divergence                20.76434
KL Loss                      2.076434
QF Loss                      915.06683
VF Loss                      230.90823
Policy Loss                  -971.0789
Q Predictions Mean           970.5447
Q Predictions Std            233.24101
Q Predictions Max            1176.9441
Q Predictions Min            80.29206
V Predictions Mean           967.5349
V Predictions Std            232.47943
V Predictions Max            1160.4832
V Predictions Min            71.45922
Log Pis Mean                 -0.47409242
Log Pis Std                  2.571913
Log Pis Max                  10.69456
Log Pis Min                  -8.722419
Policy mu Mean               0.029032335
Policy mu Std                0.5321334
Policy mu Max                2.2733865
Policy mu Min                -2.6622071
Policy log std Mean          -0.9448203
Policy log std Std           0.26673144
Policy log std Max           -0.33457828
Policy log std Min           -2.325876
Z mean eval                  0.9922048
Z variance eval              0.015317583
total_rewards                [ 242.03523845 2505.22797049 2672.15299153 2631.1148719  2474.80101448
 2607.26574641 1359.2180346  2596.41721317 2464.92960554 2510.10044053]
total_rewards_mean           2206.326312710541
total_rewards_std            748.7970529054151
total_rewards_max            2672.1529915296123
total_rewards_min            242.03523845202199
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               35.5606628311798
(Previous) Eval Time (s)     26.953007224947214
Sample Time (s)              26.445310211274773
Epoch Time (s)               88.95898026740178
Total Train Time (s)         24073.60761116864
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:34.729632 UTC | [2020_01_10_11_46_20] Iteration #268 | Epoch Duration: 98.94459509849548
2020-01-10 18:27:34.729860 UTC | [2020_01_10_11_46_20] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99001807
Z variance train             0.015340852
KL Divergence                21.24448
KL Loss                      2.124448
QF Loss                      1446.5952
VF Loss                      700.26855
Policy Loss                  -956.35144
Q Predictions Mean           948.8755
Q Predictions Std            243.36479
Q Predictions Max            1163.0906
Q Predictions Min            -75.15278
V Predictions Mean           945.2322
V Predictions Std            236.20518
V Predictions Max            1178.9735
V Predictions Min            7.0227413
Log Pis Mean                 -0.35385293
Log Pis Std                  3.144086
Log Pis Max                  20.398035
Log Pis Min                  -9.227647
Policy mu Mean               -0.0008726646
Policy mu Std                0.6130552
Policy mu Max                2.5910168
Policy mu Min                -4.1881533
Policy log std Mean          -0.9333556
Policy log std Std           0.29998118
Policy log std Max           -0.18581343
Policy log std Min           -3.0793757
Z mean eval                  1.0398805
Z variance eval              0.013887556
total_rewards                [1858.19384383 2630.4435069   731.90773149 2669.3575315  2546.08041616
 2670.48970066 2544.01400158 2838.21535627 1047.49337983 2853.66505245]
total_rewards_mean           2238.986052068397
total_rewards_std            726.9698437469077
total_rewards_max            2853.665052447891
total_rewards_min            731.9077314934666
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               35.61848757136613
(Previous) Eval Time (s)     36.93817452387884
Sample Time (s)              28.17527351854369
Epoch Time (s)               100.73193561378866
Total Train Time (s)         24168.40973312594
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:29:09.535066 UTC | [2020_01_10_11_46_20] Iteration #269 | Epoch Duration: 94.8050708770752
2020-01-10 18:29:09.535299 UTC | [2020_01_10_11_46_20] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0402203
Z variance train             0.013904038
KL Divergence                21.789667
KL Loss                      2.1789668
QF Loss                      364.58807
VF Loss                      93.40181
Policy Loss                  -978.0855
Q Predictions Mean           977.7341
Q Predictions Std            232.6221
Q Predictions Max            1171.3772
Q Predictions Min            28.459953
V Predictions Mean           982.0781
V Predictions Std            232.09428
V Predictions Max            1180.8406
V Predictions Min            12.972765
Log Pis Mean                 -0.3244261
Log Pis Std                  2.6425364
Log Pis Max                  8.69887
Log Pis Min                  -7.5323143
Policy mu Mean               0.11721639
Policy mu Std                0.6072227
Policy mu Max                2.171589
Policy mu Min                -2.0169382
Policy log std Mean          -0.9068847
Policy log std Std           0.27591717
Policy log std Max           0.20412076
Policy log std Min           -2.3492286
Z mean eval                  0.99493253
Z variance eval              0.016616913
total_rewards                [ -21.01930101 2736.37792357 2608.19281833  229.23803589 2470.32762814
  586.46471372 1658.67390261 1072.78136432   11.82766211   13.66533408]
total_rewards_mean           1136.6530081761746
total_rewards_std            1085.0101498548618
total_rewards_max            2736.3779235664
total_rewards_min            -21.019301007140132
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               33.1943952110596
(Previous) Eval Time (s)     31.010835986118764
Sample Time (s)              26.297333729453385
Epoch Time (s)               90.50256492663175
Total Train Time (s)         24247.000611376017
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:28.129278 UTC | [2020_01_10_11_46_20] Iteration #270 | Epoch Duration: 78.59385180473328
2020-01-10 18:30:28.129399 UTC | [2020_01_10_11_46_20] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9940154
Z variance train             0.016629007
KL Divergence                21.930569
KL Loss                      2.1930568
QF Loss                      764.96875
VF Loss                      322.5546
Policy Loss                  -984.29395
Q Predictions Mean           984.3593
Q Predictions Std            230.86484
Q Predictions Max            1189.7045
Q Predictions Min            15.620865
V Predictions Mean           994.1044
V Predictions Std            233.23932
V Predictions Max            1176.1156
V Predictions Min            18.664423
Log Pis Mean                 -0.5805072
Log Pis Std                  2.6982608
Log Pis Max                  9.022335
Log Pis Min                  -9.6013565
Policy mu Mean               0.055698548
Policy mu Std                0.6186199
Policy mu Max                2.333411
Policy mu Min                -2.768101
Policy log std Mean          -0.91192967
Policy log std Std           0.2661628
Policy log std Max           -0.29528606
Policy log std Min           -2.1961021
Z mean eval                  1.0292206
Z variance eval              0.012454299
total_rewards                [2521.53609397 2203.59045227 2606.49360354  242.75725632 2768.66063905
 2672.18905426 2813.35904292 2683.52136215 2661.96054943 2248.59414164]
total_rewards_mean           2342.2662195539524
total_rewards_std            725.8888602679287
total_rewards_max            2813.359042918185
total_rewards_min            242.75725631756714
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               33.94409492518753
(Previous) Eval Time (s)     19.101823078934103
Sample Time (s)              26.125665862113237
Epoch Time (s)               79.17158386623487
Total Train Time (s)         24337.442657705862
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:31:58.579338 UTC | [2020_01_10_11_46_20] Iteration #271 | Epoch Duration: 90.44981336593628
2020-01-10 18:31:58.579618 UTC | [2020_01_10_11_46_20] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0283773
Z variance train             0.0124568995
KL Divergence                21.632893
KL Loss                      2.1632893
QF Loss                      1191.7869
VF Loss                      251.29645
Policy Loss                  -961.7385
Q Predictions Mean           959.9992
Q Predictions Std            251.62596
Q Predictions Max            1155.3027
Q Predictions Min            42.057125
V Predictions Mean           957.3034
V Predictions Std            250.62527
V Predictions Max            1153.5239
V Predictions Min            44.926533
Log Pis Mean                 -0.8883394
Log Pis Std                  2.7199388
Log Pis Max                  10.693034
Log Pis Min                  -6.8125005
Policy mu Mean               -0.020696435
Policy mu Std                0.5737253
Policy mu Max                2.0886664
Policy mu Min                -2.993032
Policy log std Mean          -0.91564405
Policy log std Std           0.2729951
Policy log std Max           -0.2675773
Policy log std Min           -2.3611329
Z mean eval                  0.9994645
Z variance eval              0.013041973
total_rewards                [1989.28707818 2646.02862078 2553.27800837 1432.64964455  935.35383513
 2523.28830435 2573.35178587 2800.21474319 2557.58827195 2488.33434638]
total_rewards_mean           2249.937463874687
total_rewards_std            578.4925663962044
total_rewards_max            2800.214743188912
total_rewards_min            935.3538351250256
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               33.84077051002532
(Previous) Eval Time (s)     30.379686838015914
Sample Time (s)              25.879006979987025
Epoch Time (s)               90.09946432802826
Total Train Time (s)         24430.016509650275
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:31.155993 UTC | [2020_01_10_11_46_20] Iteration #272 | Epoch Duration: 92.57618689537048
2020-01-10 18:33:31.156158 UTC | [2020_01_10_11_46_20] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99907255
Z variance train             0.013048257
KL Divergence                21.58355
KL Loss                      2.158355
QF Loss                      741.22546
VF Loss                      70.59791
Policy Loss                  -971.8101
Q Predictions Mean           968.7975
Q Predictions Std            247.01468
Q Predictions Max            1164.2623
Q Predictions Min            72.16641
V Predictions Mean           973.5166
V Predictions Std            242.96826
V Predictions Max            1163.9891
V Predictions Min            80.47351
Log Pis Mean                 -0.8137679
Log Pis Std                  2.6863127
Log Pis Max                  6.9252
Log Pis Min                  -9.161362
Policy mu Mean               0.08349158
Policy mu Std                0.5587553
Policy mu Max                2.2022624
Policy mu Min                -3.7019641
Policy log std Mean          -0.87922245
Policy log std Std           0.25781223
Policy log std Max           -0.20822453
Policy log std Min           -2.4589348
Z mean eval                  0.9927678
Z variance eval              0.010594092
total_rewards                [2546.12084229 2536.01302918  160.63712251 2712.01467264 2586.30059092
  676.48203833 1257.15785789 2475.7563757  2448.28869345 2526.93381389]
total_rewards_mean           1992.570503678915
total_rewards_std            884.7290776621229
total_rewards_max            2712.0146726364183
total_rewards_min            160.63712250646242
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               33.226331621874124
(Previous) Eval Time (s)     32.856067039072514
Sample Time (s)              25.46523313364014
Epoch Time (s)               91.54763179458678
Total Train Time (s)         24514.40572860604
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:34:55.548633 UTC | [2020_01_10_11_46_20] Iteration #273 | Epoch Duration: 84.39234662055969
2020-01-10 18:34:55.548810 UTC | [2020_01_10_11_46_20] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99387884
Z variance train             0.0105844755
KL Divergence                21.890736
KL Loss                      2.1890736
QF Loss                      560.17065
VF Loss                      108.52187
Policy Loss                  -990.838
Q Predictions Mean           988.32007
Q Predictions Std            222.45715
Q Predictions Max            1173.0483
Q Predictions Min            85.39222
V Predictions Mean           995.036
V Predictions Std            223.03455
V Predictions Max            1171.79
V Predictions Min            84.68924
Log Pis Mean                 -0.70403695
Log Pis Std                  2.33047
Log Pis Max                  5.8778477
Log Pis Min                  -7.472421
Policy mu Mean               0.050840482
Policy mu Std                0.57425505
Policy mu Max                1.8508772
Policy mu Min                -2.8770425
Policy log std Mean          -0.92481077
Policy log std Std           0.2413178
Policy log std Max           -0.27641308
Policy log std Min           -1.8924568
Z mean eval                  1.0274975
Z variance eval              0.008773265
total_rewards                [2807.18208015 2827.84478648  735.85451477  560.56242166 2841.59557124
 2954.87760909 1526.85895431 2879.04676415  813.14151737 3123.8329476 ]
total_rewards_mean           2107.0797166822194
total_rewards_std            1008.9869752367744
total_rewards_max            3123.8329475967785
total_rewards_min            560.5624216631807
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               33.33078190404922
(Previous) Eval Time (s)     25.700390567071736
Sample Time (s)              26.218259978108108
Epoch Time (s)               85.24943244922906
Total Train Time (s)         24602.1319121751
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:36:23.277880 UTC | [2020_01_10_11_46_20] Iteration #274 | Epoch Duration: 87.72894501686096
2020-01-10 18:36:23.278051 UTC | [2020_01_10_11_46_20] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279874
Z variance train             0.008755008
KL Divergence                22.679087
KL Loss                      2.2679088
QF Loss                      890.62634
VF Loss                      372.68808
Policy Loss                  -988.7632
Q Predictions Mean           983.46173
Q Predictions Std            239.4478
Q Predictions Max            1186.4048
Q Predictions Min            61.315483
V Predictions Mean           994.76587
V Predictions Std            234.45247
V Predictions Max            1190.8773
V Predictions Min            80.52726
Log Pis Mean                 -0.6312291
Log Pis Std                  2.5410523
Log Pis Max                  15.673885
Log Pis Min                  -9.665889
Policy mu Mean               0.018606167
Policy mu Std                0.6072196
Policy mu Max                2.010186
Policy mu Min                -4.3813024
Policy log std Mean          -0.87028277
Policy log std Std           0.26224115
Policy log std Max           -0.20906138
Policy log std Min           -2.752807
Z mean eval                  1.0078306
Z variance eval              0.0072322055
total_rewards                [ 735.72266455 2279.37033703 2962.16060254 2966.0566356    11.42082719
 2594.31911474  535.80460774   17.42081811 2562.08686799 1101.40801121]
total_rewards_mean           1576.5770486683266
total_rewards_std            1151.0062277263494
total_rewards_max            2966.0566356030495
total_rewards_min            11.420827189025953
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               33.57335219485685
(Previous) Eval Time (s)     28.179567189887166
Sample Time (s)              25.67898520641029
Epoch Time (s)               87.43190459115431
Total Train Time (s)         24684.441697005183
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:45.590908 UTC | [2020_01_10_11_46_20] Iteration #275 | Epoch Duration: 82.31272649765015
2020-01-10 18:37:45.591111 UTC | [2020_01_10_11_46_20] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0080317
Z variance train             0.007227668
KL Divergence                23.111967
KL Loss                      2.3111968
QF Loss                      315.38678
VF Loss                      70.02672
Policy Loss                  -989.9183
Q Predictions Mean           988.98157
Q Predictions Std            257.3036
Q Predictions Max            1185.5311
Q Predictions Min            53.79209
V Predictions Mean           986.5309
V Predictions Std            255.10225
V Predictions Max            1177.611
V Predictions Min            62.911728
Log Pis Mean                 -0.65085745
Log Pis Std                  2.7649727
Log Pis Max                  7.3388343
Log Pis Min                  -7.682768
Policy mu Mean               0.037833244
Policy mu Std                0.60139215
Policy mu Max                2.1293662
Policy mu Min                -1.981326
Policy log std Mean          -0.8892319
Policy log std Std           0.2622293
Policy log std Max           -0.23940676
Policy log std Min           -2.0196834
Z mean eval                  1.0270078
Z variance eval              0.011944654
total_rewards                [1734.99885362 1129.98518002 2752.93482774 2550.77997462 2534.89709889
 2727.88997228 2572.7459376  2717.58916694 2703.91047457 1051.52399326]
total_rewards_mean           2247.725547954695
total_rewards_std            643.2533629919783
total_rewards_max            2752.9348277352265
total_rewards_min            1051.5239932649433
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               33.43726439308375
(Previous) Eval Time (s)     23.060059652663767
Sample Time (s)              25.578858853317797
Epoch Time (s)               82.07618289906532
Total Train Time (s)         24775.34451290127
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:39:16.496582 UTC | [2020_01_10_11_46_20] Iteration #276 | Epoch Duration: 90.90533208847046
2020-01-10 18:39:16.496746 UTC | [2020_01_10_11_46_20] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0233577
Z variance train             0.01195929
KL Divergence                22.306246
KL Loss                      2.2306247
QF Loss                      1019.8433
VF Loss                      159.4318
Policy Loss                  -1005.88025
Q Predictions Mean           1004.0906
Q Predictions Std            225.3701
Q Predictions Max            1205.9482
Q Predictions Min            70.098305
V Predictions Mean           1008.1299
V Predictions Std            228.79256
V Predictions Max            1191.2185
V Predictions Min            65.76152
Log Pis Mean                 -0.6194053
Log Pis Std                  2.4171197
Log Pis Max                  6.5545106
Log Pis Min                  -6.3013277
Policy mu Mean               -0.010105884
Policy mu Std                0.5842835
Policy mu Max                2.0629244
Policy mu Min                -2.9396641
Policy log std Mean          -0.9184632
Policy log std Std           0.27328646
Policy log std Max           -0.22855777
Policy log std Min           -2.176977
Z mean eval                  0.99345857
Z variance eval              0.016313177
total_rewards                [2660.94769609 1984.99311744 1432.57949954 2642.52283448 1882.18930367
 2706.04887403 2658.35296416 2690.07688037  303.24275019  114.64109334]
total_rewards_mean           1907.5595013309692
total_rewards_std            945.621948421378
total_rewards_max            2706.048874031532
total_rewards_min            114.64109334074352
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               33.68727088579908
(Previous) Eval Time (s)     31.888872076757252
Sample Time (s)              25.368172670248896
Epoch Time (s)               90.94431563280523
Total Train Time (s)         24862.710506295785
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:43.865825 UTC | [2020_01_10_11_46_20] Iteration #277 | Epoch Duration: 87.36895203590393
2020-01-10 18:40:43.866000 UTC | [2020_01_10_11_46_20] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99415684
Z variance train             0.01632186
KL Divergence                21.926914
KL Loss                      2.1926916
QF Loss                      657.7354
VF Loss                      63.96501
Policy Loss                  -1010.9861
Q Predictions Mean           1007.0299
Q Predictions Std            226.2681
Q Predictions Max            1189.8085
Q Predictions Min            74.61703
V Predictions Mean           1012.7741
V Predictions Std            225.41963
V Predictions Max            1193.9232
V Predictions Min            73.40512
Log Pis Mean                 -0.9136694
Log Pis Std                  2.575438
Log Pis Max                  10.1475
Log Pis Min                  -7.245798
Policy mu Mean               -0.024391867
Policy mu Std                0.56405735
Policy mu Max                1.8206499
Policy mu Min                -3.391049
Policy log std Mean          -0.90114534
Policy log std Std           0.25143558
Policy log std Max           -0.28561014
Policy log std Min           -2.127844
Z mean eval                  1.0221348
Z variance eval              0.027723646
total_rewards                [2221.39825496  635.35953314 2780.79446614 2467.56325202 2469.45065699
 1589.8243551  2195.71857332 2705.20453531 2850.78013896 2696.60578755]
total_rewards_mean           2261.2699553500725
total_rewards_std            647.3198538661987
total_rewards_max            2850.7801389618503
total_rewards_min            635.3595331409475
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               32.82431597402319
(Previous) Eval Time (s)     28.313190698157996
Sample Time (s)              24.22616438101977
Epoch Time (s)               85.36367105320096
Total Train Time (s)         24952.218624845147
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:42:13.377117 UTC | [2020_01_10_11_46_20] Iteration #278 | Epoch Duration: 89.51098561286926
2020-01-10 18:42:13.377295 UTC | [2020_01_10_11_46_20] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0208154
Z variance train             0.027656535
KL Divergence                21.462242
KL Loss                      2.1462243
QF Loss                      459.8444
VF Loss                      352.80176
Policy Loss                  -1022.1104
Q Predictions Mean           1022.5382
Q Predictions Std            198.35126
Q Predictions Max            1185.1981
Q Predictions Min            167.3539
V Predictions Mean           1023.21735
V Predictions Std            194.9222
V Predictions Max            1183.8429
V Predictions Min            154.4232
Log Pis Mean                 -0.7288904
Log Pis Std                  2.3654013
Log Pis Max                  8.758102
Log Pis Min                  -6.135153
Policy mu Mean               0.028474718
Policy mu Std                0.5738565
Policy mu Max                2.189746
Policy mu Min                -3.395998
Policy log std Mean          -0.940366
Policy log std Std           0.24405845
Policy log std Max           -0.22836149
Policy log std Min           -2.0512576
Z mean eval                  1.0036218
Z variance eval              0.023711052
total_rewards                [2037.28300946 1429.03085304 2862.67079939 2734.75855293 1489.25410516
 2943.31676735 2895.18864    2858.17264147 2762.81965531 3018.65356997]
total_rewards_mean           2503.1148594076744
total_rewards_std            582.091144905442
total_rewards_max            3018.653569969114
total_rewards_min            1429.0308530409097
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               33.02891284413636
(Previous) Eval Time (s)     32.460224808659405
Sample Time (s)              25.998036259785295
Epoch Time (s)               91.48717391258106
Total Train Time (s)         25042.338597939815
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:43:43.502040 UTC | [2020_01_10_11_46_20] Iteration #279 | Epoch Duration: 90.12458920478821
2020-01-10 18:43:43.502328 UTC | [2020_01_10_11_46_20] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0033154
Z variance train             0.023742773
KL Divergence                21.431984
KL Loss                      2.1431985
QF Loss                      590.2737
VF Loss                      77.153465
Policy Loss                  -1003.7249
Q Predictions Mean           1002.5874
Q Predictions Std            207.34518
Q Predictions Max            1177.9485
Q Predictions Min            101.20822
V Predictions Mean           1006.3019
V Predictions Std            206.8408
V Predictions Max            1171.5219
V Predictions Min            103.78071
Log Pis Mean                 -0.48399606
Log Pis Std                  2.4201834
Log Pis Max                  6.426524
Log Pis Min                  -7.945755
Policy mu Mean               -0.0059612086
Policy mu Std                0.5985117
Policy mu Max                2.3765707
Policy mu Min                -2.0331175
Policy log std Mean          -0.90861285
Policy log std Std           0.26385015
Policy log std Max           -0.12665528
Policy log std Min           -2.2802532
Z mean eval                  1.001082
Z variance eval              0.024266671
total_rewards                [  48.23819566 2443.59744225 1679.13835494 2459.19115741 2976.00480146
  316.56838806 2829.06595631 1983.31750318 2898.35223987 1661.13789478]
total_rewards_mean           1929.4611933903739
total_rewards_std            983.1695996624433
total_rewards_max            2976.004801462058
total_rewards_min            48.2381956558105
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               33.107075524982065
(Previous) Eval Time (s)     31.097246339078993
Sample Time (s)              25.589565441478044
Epoch Time (s)               89.7938873055391
Total Train Time (s)         25129.925328115467
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:45:11.092081 UTC | [2020_01_10_11_46_20] Iteration #280 | Epoch Duration: 87.5892379283905
2020-01-10 18:45:11.092457 UTC | [2020_01_10_11_46_20] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0009111
Z variance train             0.024215449
KL Divergence                21.465998
KL Loss                      2.1465998
QF Loss                      1117.0071
VF Loss                      249.62955
Policy Loss                  -1027.8579
Q Predictions Mean           1027.8457
Q Predictions Std            194.50566
Q Predictions Max            1199.9707
Q Predictions Min            65.72405
V Predictions Mean           1029.0576
V Predictions Std            190.83897
V Predictions Max            1199.5143
V Predictions Min            75.6369
Log Pis Mean                 -0.64295876
Log Pis Std                  2.6948175
Log Pis Max                  10.744514
Log Pis Min                  -7.164896
Policy mu Mean               0.002656689
Policy mu Std                0.58406323
Policy mu Max                2.462801
Policy mu Min                -2.1397288
Policy log std Mean          -0.9134996
Policy log std Std           0.26404342
Policy log std Max           -0.22518337
Policy log std Min           -2.6046777
Z mean eval                  1.0096322
Z variance eval              0.021440666
total_rewards                [2513.10876757 2781.30558848 2733.72650987 2655.54531593 2730.13463438
 2566.93281154 1249.77686919 2582.99489003   48.71872297 2623.86986541]
total_rewards_mean           2248.6113975362723
total_rewards_std            847.2116871582849
total_rewards_max            2781.305588475202
total_rewards_min            48.718722972253495
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               33.96148382732645
(Previous) Eval Time (s)     28.89226578688249
Sample Time (s)              25.890096633229405
Epoch Time (s)               88.74384624743834
Total Train Time (s)         25221.532663065474
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:46:42.707497 UTC | [2020_01_10_11_46_20] Iteration #281 | Epoch Duration: 91.61478638648987
2020-01-10 18:46:42.708143 UTC | [2020_01_10_11_46_20] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0107626
Z variance train             0.021419853
KL Divergence                22.074171
KL Loss                      2.2074172
QF Loss                      958.69727
VF Loss                      141.63475
Policy Loss                  -1018.17834
Q Predictions Mean           1015.93054
Q Predictions Std            223.13383
Q Predictions Max            1202.727
Q Predictions Min            18.030205
V Predictions Mean           1015.7582
V Predictions Std            221.37985
V Predictions Max            1202.7686
V Predictions Min            16.74778
Log Pis Mean                 -0.7088511
Log Pis Std                  2.6506014
Log Pis Max                  12.437389
Log Pis Min                  -8.2079
Policy mu Mean               0.055743568
Policy mu Std                0.55813867
Policy mu Max                2.0295608
Policy mu Min                -2.1070452
Policy log std Mean          -0.92304516
Policy log std Std           0.2767827
Policy log std Max           0.04288262
Policy log std Min           -2.653745
Z mean eval                  1.0365529
Z variance eval              0.024901694
total_rewards                [ 236.89341677  496.73014782  463.54414084 2751.53187828 2801.92693847
  721.63346293 2570.83326851  898.28618531 2919.53871034 2716.79387568]
total_rewards_mean           1657.7712024945881
total_rewards_std            1109.0055461013224
total_rewards_max            2919.5387103425373
total_rewards_min            236.89341676543398
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               34.07947629923001
(Previous) Eval Time (s)     31.76282010693103
Sample Time (s)              26.83702919492498
Epoch Time (s)               92.67932560108602
Total Train Time (s)         25308.464735463727
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:48:09.649645 UTC | [2020_01_10_11_46_20] Iteration #282 | Epoch Duration: 86.94115972518921
2020-01-10 18:48:09.650034 UTC | [2020_01_10_11_46_20] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.037474
Z variance train             0.024961114
KL Divergence                22.135548
KL Loss                      2.2135549
QF Loss                      457.78055
VF Loss                      390.39978
Policy Loss                  -1018.2793
Q Predictions Mean           1015.3424
Q Predictions Std            232.97803
Q Predictions Max            1208.8143
Q Predictions Min            55.755733
V Predictions Mean           1003.5598
V Predictions Std            227.61568
V Predictions Max            1192.0076
V Predictions Min            51.363182
Log Pis Mean                 -0.6720562
Log Pis Std                  2.476392
Log Pis Max                  7.5375633
Log Pis Min                  -7.409933
Policy mu Mean               0.0061591156
Policy mu Std                0.61748457
Policy mu Max                2.3928711
Policy mu Min                -2.3980107
Policy log std Mean          -0.8975011
Policy log std Std           0.24761309
Policy log std Max           -0.30061966
Policy log std Min           -2.06076
Z mean eval                  1.0106496
Z variance eval              0.019168142
total_rewards                [ 742.37015418 2716.0016879  2886.24048877  106.67974071  558.33515813
 2628.12494824 1570.82573937 2737.11969577 1361.63745066 1218.9651138 ]
total_rewards_mean           1652.6300177525918
total_rewards_std            973.4327252190296
total_rewards_max            2886.2404887663997
total_rewards_min            106.67974071190332
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               33.54590390389785
(Previous) Eval Time (s)     26.024243056308478
Sample Time (s)              25.52633744897321
Epoch Time (s)               85.09648440917954
Total Train Time (s)         25388.97087732004
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:49:30.157927 UTC | [2020_01_10_11_46_20] Iteration #283 | Epoch Duration: 80.50758814811707
2020-01-10 18:49:30.158192 UTC | [2020_01_10_11_46_20] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.011003
Z variance train             0.019220581
KL Divergence                22.265821
KL Loss                      2.2265823
QF Loss                      578.15924
VF Loss                      165.6805
Policy Loss                  -999.04816
Q Predictions Mean           998.4879
Q Predictions Std            223.31929
Q Predictions Max            1179.0374
Q Predictions Min            9.835424
V Predictions Mean           1007.1744
V Predictions Std            223.75638
V Predictions Max            1184.6599
V Predictions Min            12.412059
Log Pis Mean                 -0.6969701
Log Pis Std                  2.3543558
Log Pis Max                  6.252055
Log Pis Min                  -7.4418006
Policy mu Mean               -0.01893061
Policy mu Std                0.5759462
Policy mu Max                2.4550822
Policy mu Min                -1.7884411
Policy log std Mean          -0.9044588
Policy log std Std           0.2463066
Policy log std Max           -0.24364284
Policy log std Min           -1.9657739
Z mean eval                  1.0011938
Z variance eval              0.018893247
total_rewards                [ -13.55787395   11.5068907  2672.93192813  396.05173797 3099.17236223
 2968.88034077 2974.63407319  480.58169639 2946.2978558  2894.27851037]
total_rewards_mean           1843.077752159196
total_rewards_std            1337.4762759228274
total_rewards_max            3099.1723622326967
total_rewards_min            -13.557873951423737
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               33.65291078109294
(Previous) Eval Time (s)     21.434961538761854
Sample Time (s)              25.881085491739213
Epoch Time (s)               80.96895781159401
Total Train Time (s)         25472.8258019262
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:50:54.012593 UTC | [2020_01_10_11_46_20] Iteration #284 | Epoch Duration: 83.85422992706299
2020-01-10 18:50:54.012719 UTC | [2020_01_10_11_46_20] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0025344
Z variance train             0.018897314
KL Divergence                22.48489
KL Loss                      2.2484891
QF Loss                      941.99817
VF Loss                      86.06622
Policy Loss                  -1001.42114
Q Predictions Mean           1000.6428
Q Predictions Std            236.40108
Q Predictions Max            1209.8132
Q Predictions Min            -1.2114809
V Predictions Mean           1003.19055
V Predictions Std            235.68903
V Predictions Max            1192.7039
V Predictions Min            46.145523
Log Pis Mean                 -0.4396196
Log Pis Std                  2.8252084
Log Pis Max                  12.15484
Log Pis Min                  -6.227247
Policy mu Mean               0.014985377
Policy mu Std                0.5919059
Policy mu Max                2.168655
Policy mu Min                -1.8867477
Policy log std Mean          -0.9264184
Policy log std Std           0.28623527
Policy log std Max           -0.24251986
Policy log std Min           -2.6440978
Z mean eval                  1.0184188
Z variance eval              0.0136038195
total_rewards                [2640.65161669 1382.85450602 1266.02426195 2135.70419173 2699.90498023
 1640.64892771  989.788064   1772.28414824 2701.63468234 2457.2980796 ]
total_rewards_mean           1968.6793458526602
total_rewards_std            610.853896853696
total_rewards_max            2701.6346823441518
total_rewards_min            989.7880640021901
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               33.08948115538806
(Previous) Eval Time (s)     24.31988879106939
Sample Time (s)              24.14127910649404
Epoch Time (s)               81.55064905295148
Total Train Time (s)         25555.849036851432
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:52:17.041476 UTC | [2020_01_10_11_46_20] Iteration #285 | Epoch Duration: 83.02867364883423
2020-01-10 18:52:17.041599 UTC | [2020_01_10_11_46_20] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0202689
Z variance train             0.013607303
KL Divergence                23.647556
KL Loss                      2.3647556
QF Loss                      380.6189
VF Loss                      124.6359
Policy Loss                  -1017.28143
Q Predictions Mean           1018.6331
Q Predictions Std            241.51651
Q Predictions Max            1220.9315
Q Predictions Min            -5.6891627
V Predictions Mean           1022.6432
V Predictions Std            240.9966
V Predictions Max            1214.7041
V Predictions Min            60.21104
Log Pis Mean                 -0.51437443
Log Pis Std                  2.6015773
Log Pis Max                  5.877261
Log Pis Min                  -8.454955
Policy mu Mean               0.04542464
Policy mu Std                0.57811314
Policy mu Max                2.6158342
Policy mu Min                -2.0743315
Policy log std Mean          -0.9259324
Policy log std Std           0.2609303
Policy log std Max           -0.24109638
Policy log std Min           -2.1648114
Z mean eval                  1.0299662
Z variance eval              0.015746718
total_rewards                [ 797.21085953  129.00924215  442.81101331  893.73753132 1992.53802166
 1552.69064161 1031.46428349  947.54377801 1448.38897074 2520.70424922]
total_rewards_mean           1175.60985910325
total_rewards_std            679.7827445255938
total_rewards_max            2520.7042492168985
total_rewards_min            129.00924214600283
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               33.841559070162475
(Previous) Eval Time (s)     25.79754871316254
Sample Time (s)              25.897926810197532
Epoch Time (s)               85.53703459352255
Total Train Time (s)         25640.285795124248
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:53:41.482624 UTC | [2020_01_10_11_46_20] Iteration #286 | Epoch Duration: 84.44093060493469
2020-01-10 18:53:41.482793 UTC | [2020_01_10_11_46_20] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0302408
Z variance train             0.015755877
KL Divergence                23.070217
KL Loss                      2.3070219
QF Loss                      480.59344
VF Loss                      61.40025
Policy Loss                  -1051.0277
Q Predictions Mean           1050.1738
Q Predictions Std            197.85274
Q Predictions Max            1227.2631
Q Predictions Min            45.349983
V Predictions Mean           1048.9397
V Predictions Std            195.20822
V Predictions Max            1226.201
V Predictions Min            57.210613
Log Pis Mean                 -0.6852357
Log Pis Std                  2.6330767
Log Pis Max                  6.811424
Log Pis Min                  -9.971074
Policy mu Mean               0.035495285
Policy mu Std                0.6044781
Policy mu Max                2.1701832
Policy mu Min                -2.0574281
Policy log std Mean          -0.92968005
Policy log std Std           0.23063083
Policy log std Max           -0.3237871
Policy log std Min           -2.009466
Z mean eval                  0.999695
Z variance eval              0.017758654
total_rewards                [1355.80936611 2876.23418439 2581.38346315  895.28863846  505.85001966
 2708.37696541 2969.09982946 2908.21515849 2780.12724026 1298.84347871]
total_rewards_mean           2087.922834410368
total_rewards_std            908.9756825635308
total_rewards_max            2969.099829462634
total_rewards_min            505.8500196579745
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               33.60272586485371
(Previous) Eval Time (s)     24.701053824741393
Sample Time (s)              24.525661842897534
Epoch Time (s)               82.82944153249264
Total Train Time (s)         25726.53254566202
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:07.732687 UTC | [2020_01_10_11_46_20] Iteration #287 | Epoch Duration: 86.24976968765259
2020-01-10 18:55:07.732876 UTC | [2020_01_10_11_46_20] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99849427
Z variance train             0.017751098
KL Divergence                22.407639
KL Loss                      2.240764
QF Loss                      625.24963
VF Loss                      225.61234
Policy Loss                  -1020.7405
Q Predictions Mean           1018.22815
Q Predictions Std            224.8684
Q Predictions Max            1209.6628
Q Predictions Min            51.462154
V Predictions Mean           1017.8227
V Predictions Std            221.91782
V Predictions Max            1213.6948
V Predictions Min            36.765965
Log Pis Mean                 -0.24938518
Log Pis Std                  2.4626904
Log Pis Max                  13.427934
Log Pis Min                  -7.119783
Policy mu Mean               0.01780617
Policy mu Std                0.5967029
Policy mu Max                1.9910982
Policy mu Min                -1.811124
Policy log std Mean          -0.9408353
Policy log std Std           0.27723944
Policy log std Max           -0.14688963
Policy log std Min           -2.8034694
Z mean eval                  1.0122043
Z variance eval              0.018737597
total_rewards                [2835.18945399  931.78684585 2762.46465733 2679.9810221  2782.73510331
 2704.59987195 2754.92615043 2786.94239134 2872.41040038 2824.28048513]
total_rewards_mean           2593.531638182521
total_rewards_std            556.6340379363397
total_rewards_max            2872.4104003822263
total_rewards_min            931.7868458492464
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               33.39276064094156
(Previous) Eval Time (s)     28.121081358287483
Sample Time (s)              25.823650517500937
Epoch Time (s)               87.33749251672998
Total Train Time (s)         25819.643064375967
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:56:40.846547 UTC | [2020_01_10_11_46_20] Iteration #288 | Epoch Duration: 93.11353850364685
2020-01-10 18:56:40.846735 UTC | [2020_01_10_11_46_20] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0128996
Z variance train             0.01887902
KL Divergence                22.28546
KL Loss                      2.228546
QF Loss                      702.6437
VF Loss                      157.42062
Policy Loss                  -1039.9999
Q Predictions Mean           1039.0101
Q Predictions Std            208.36931
Q Predictions Max            1231.2559
Q Predictions Min            67.42829
V Predictions Mean           1042.2424
V Predictions Std            212.00163
V Predictions Max            1240.317
V Predictions Min            63.341938
Log Pis Mean                 -0.6489266
Log Pis Std                  2.2751975
Log Pis Max                  6.84836
Log Pis Min                  -7.518508
Policy mu Mean               0.025128905
Policy mu Std                0.52313894
Policy mu Max                2.3251987
Policy mu Min                -1.827584
Policy log std Mean          -0.9553473
Policy log std Std           0.26343584
Policy log std Max           -0.2932277
Policy log std Min           -2.18433
Z mean eval                  1.0307479
Z variance eval              0.016836919
total_rewards                [2857.81436191 1257.19802347 2902.2306626  1273.87361595  840.80074196
 1764.99619496  308.28672892 2625.92573148 1358.86140819 2260.51561117]
total_rewards_mean           1745.050308061846
total_rewards_std            843.2354412899482
total_rewards_max            2902.2306626036925
total_rewards_min            308.2867289185192
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               33.04561579087749
(Previous) Eval Time (s)     33.89682964608073
Sample Time (s)              25.453716673888266
Epoch Time (s)               92.39616211084649
Total Train Time (s)         25907.069575270172
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:08.277313 UTC | [2020_01_10_11_46_20] Iteration #289 | Epoch Duration: 87.4304268360138
2020-01-10 18:58:08.277546 UTC | [2020_01_10_11_46_20] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0306695
Z variance train             0.016800543
KL Divergence                22.77956
KL Loss                      2.277956
QF Loss                      702.01746
VF Loss                      283.72726
Policy Loss                  -1029.7437
Q Predictions Mean           1025.1462
Q Predictions Std            228.85243
Q Predictions Max            1198.4637
Q Predictions Min            -40.96409
V Predictions Mean           1030.2526
V Predictions Std            217.82762
V Predictions Max            1187.689
V Predictions Min            44.218937
Log Pis Mean                 -0.4958257
Log Pis Std                  2.583508
Log Pis Max                  12.504055
Log Pis Min                  -7.870268
Policy mu Mean               0.0034584869
Policy mu Std                0.5606885
Policy mu Max                1.934581
Policy mu Min                -1.8593298
Policy log std Mean          -0.93307275
Policy log std Std           0.30025208
Policy log std Max           -0.13794094
Policy log std Min           -2.8540828
Z mean eval                  1.0040569
Z variance eval              0.018880205
total_rewards                [2136.53802791 2743.31683295 2830.01545718 2804.56756948  678.49190103
  258.21145383 2371.10480504 2815.27688554 2890.45625388 2983.76065834]
total_rewards_mean           2251.1739845179036
total_rewards_std            928.4307739326291
total_rewards_max            2983.7606583363468
total_rewards_min            258.2114538286972
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               33.08623787295073
(Previous) Eval Time (s)     28.93076995201409
Sample Time (s)              24.478246082086116
Epoch Time (s)               86.49525390705094
Total Train Time (s)         25990.907258152496
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:59:32.117627 UTC | [2020_01_10_11_46_20] Iteration #290 | Epoch Duration: 83.83992767333984
2020-01-10 18:59:32.117804 UTC | [2020_01_10_11_46_20] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0043406
Z variance train             0.018901473
KL Divergence                22.56963
KL Loss                      2.256963
QF Loss                      372.551
VF Loss                      122.74647
Policy Loss                  -1044.9425
Q Predictions Mean           1042.0846
Q Predictions Std            208.86272
Q Predictions Max            1219.5117
Q Predictions Min            -19.243279
V Predictions Mean           1047.5643
V Predictions Std            202.97307
V Predictions Max            1202.3927
V Predictions Min            17.869648
Log Pis Mean                 -0.72131497
Log Pis Std                  2.7036006
Log Pis Max                  13.700989
Log Pis Min                  -8.444038
Policy mu Mean               0.11696918
Policy mu Std                0.597387
Policy mu Max                2.5296154
Policy mu Min                -1.7712641
Policy log std Mean          -0.8984874
Policy log std Std           0.26418263
Policy log std Max           -0.20361573
Policy log std Min           -2.6794193
Z mean eval                  1.0149167
Z variance eval              0.011802417
total_rewards                [2706.00825079  494.08104125 2796.74802033  120.64455305 2499.06803276
 1347.04999277 1243.4998901  1375.28647664  597.77537483 1007.28448832]
total_rewards_mean           1418.7446120857228
total_rewards_std            902.4486471221579
total_rewards_max            2796.7480203312334
total_rewards_min            120.64455305476254
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               33.351575625129044
(Previous) Eval Time (s)     26.275086952373385
Sample Time (s)              26.282314596232027
Epoch Time (s)               85.90897717373446
Total Train Time (s)         26072.955335380975
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:00:54.168989 UTC | [2020_01_10_11_46_20] Iteration #291 | Epoch Duration: 82.05105686187744
2020-01-10 19:00:54.169162 UTC | [2020_01_10_11_46_20] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0159461
Z variance train             0.011766332
KL Divergence                23.671103
KL Loss                      2.3671103
QF Loss                      2429.9045
VF Loss                      87.19933
Policy Loss                  -1053.5626
Q Predictions Mean           1054.3611
Q Predictions Std            207.71117
Q Predictions Max            1254.8463
Q Predictions Min            66.23808
V Predictions Mean           1056.0718
V Predictions Std            206.7393
V Predictions Max            1248.2417
V Predictions Min            63.302032
Log Pis Mean                 -0.32590383
Log Pis Std                  2.7439187
Log Pis Max                  9.274233
Log Pis Min                  -8.57302
Policy mu Mean               0.051363185
Policy mu Std                0.6418821
Policy mu Max                2.2095888
Policy mu Min                -1.9404802
Policy log std Mean          -0.90129876
Policy log std Std           0.2863098
Policy log std Max           -0.10427415
Policy log std Min           -2.3123002
Z mean eval                  1.0314428
Z variance eval              0.01562553
total_rewards                [ 488.85286067 2701.11988141 2828.91167449 2960.4159481  2779.26965657
 1042.10826982 2910.31855982 2862.66296355 2748.57096243 2831.00801263]
total_rewards_mean           2415.323878947266
total_rewards_std            837.1563004793484
total_rewards_max            2960.4159480994176
total_rewards_min            488.85286066522315
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               33.60118342889473
(Previous) Eval Time (s)     22.416819382924587
Sample Time (s)              24.433227153960615
Epoch Time (s)               80.45122996577993
Total Train Time (s)         26160.101961187553
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:02:21.321013 UTC | [2020_01_10_11_46_20] Iteration #292 | Epoch Duration: 87.15169501304626
2020-01-10 19:02:21.321281 UTC | [2020_01_10_11_46_20] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0307688
Z variance train             0.015597448
KL Divergence                23.660894
KL Loss                      2.3660896
QF Loss                      1464.7668
VF Loss                      103.522675
Policy Loss                  -1052.0905
Q Predictions Mean           1049.8157
Q Predictions Std            206.06348
Q Predictions Max            1225.6504
Q Predictions Min            -18.520964
V Predictions Mean           1049.8313
V Predictions Std            206.20857
V Predictions Max            1215.8347
V Predictions Min            -6.1289105
Log Pis Mean                 -0.14643125
Log Pis Std                  2.585333
Log Pis Max                  11.314519
Log Pis Min                  -6.3397875
Policy mu Mean               -0.026226088
Policy mu Std                0.6314784
Policy mu Max                2.4916744
Policy mu Min                -2.2089293
Policy log std Mean          -0.9107591
Policy log std Std           0.24958266
Policy log std Max           -0.19217134
Policy log std Min           -2.3407013
Z mean eval                  1.0550306
Z variance eval              0.016642373
total_rewards                [ 730.73414729  727.48521251 1419.94431678  559.44093694 1290.21993556
 1035.21353555 1948.71678843 2618.57188472 2540.55551193  390.23522835]
total_rewards_mean           1326.1117498064846
total_rewards_std            761.8500934766838
total_rewards_max            2618.571884724993
total_rewards_min            390.2352283499505
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               33.65253424504772
(Previous) Eval Time (s)     29.116911913268268
Sample Time (s)              25.438744151964784
Epoch Time (s)               88.20819031028077
Total Train Time (s)         26240.40813090792
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:41.630163 UTC | [2020_01_10_11_46_20] Iteration #293 | Epoch Duration: 80.30870151519775
2020-01-10 19:03:41.630342 UTC | [2020_01_10_11_46_20] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0547671
Z variance train             0.016634708
KL Divergence                23.691467
KL Loss                      2.3691468
QF Loss                      405.555
VF Loss                      68.25903
Policy Loss                  -1040.2616
Q Predictions Mean           1038.7832
Q Predictions Std            241.02628
Q Predictions Max            1230.4222
Q Predictions Min            2.4281538
V Predictions Mean           1038.0645
V Predictions Std            238.83139
V Predictions Max            1228.7205
V Predictions Min            37.831085
Log Pis Mean                 -0.6489083
Log Pis Std                  2.832441
Log Pis Max                  10.017654
Log Pis Min                  -7.926642
Policy mu Mean               -0.015443617
Policy mu Std                0.6188816
Policy mu Max                2.5886323
Policy mu Min                -2.0441158
Policy log std Mean          -0.8663968
Policy log std Std           0.2675677
Policy log std Max           -0.2789442
Policy log std Min           -2.0603118
Z mean eval                  1.048011
Z variance eval              0.02106027
total_rewards                [1286.51786144 2847.37958728 1712.03324747 2931.45855563 2786.99066353
 2869.2838414  2918.26454142 2896.99174542 3042.38737365 2971.77947762]
total_rewards_mean           2626.30868948849
total_rewards_std            575.2184388375049
total_rewards_max            3042.387373652682
total_rewards_min            1286.5178614449626
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               33.14784710900858
(Previous) Eval Time (s)     21.217055363114923
Sample Time (s)              24.876195409800857
Epoch Time (s)               79.24109788192436
Total Train Time (s)         26330.107429144904
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:05:11.332800 UTC | [2020_01_10_11_46_20] Iteration #294 | Epoch Duration: 89.70231819152832
2020-01-10 19:05:11.332995 UTC | [2020_01_10_11_46_20] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.045726
Z variance train             0.021119649
KL Divergence                23.130585
KL Loss                      2.3130586
QF Loss                      725.59814
VF Loss                      132.6312
Policy Loss                  -1055.5774
Q Predictions Mean           1056.616
Q Predictions Std            206.68834
Q Predictions Max            1226.2758
Q Predictions Min            56.69956
V Predictions Mean           1061.4142
V Predictions Std            203.31378
V Predictions Max            1232.8564
V Predictions Min            52.915165
Log Pis Mean                 -0.64242923
Log Pis Std                  2.4287431
Log Pis Max                  6.8957047
Log Pis Min                  -8.298499
Policy mu Mean               -0.013612664
Policy mu Std                0.5809745
Policy mu Max                1.9084105
Policy mu Min                -1.9392134
Policy log std Mean          -0.93049157
Policy log std Std           0.2605882
Policy log std Max           -0.24950418
Policy log std Min           -2.364849
Z mean eval                  1.0333984
Z variance eval              0.015871605
total_rewards                [  56.14523938  544.7843518  2302.13334838  394.00233179  264.23750052
 -146.62338241  515.74875653  370.62300643 1224.92729341 2663.88665168]
total_rewards_mean           818.986509751554
total_rewards_std            902.1655097802832
total_rewards_max            2663.886651679424
total_rewards_min            -146.6233824093365
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               33.967566180974245
(Previous) Eval Time (s)     31.677920441608876
Sample Time (s)              25.368908013682812
Epoch Time (s)               91.01439463626593
Total Train Time (s)         26411.826017739717
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:33.054940 UTC | [2020_01_10_11_46_20] Iteration #295 | Epoch Duration: 81.72179865837097
2020-01-10 19:06:33.055135 UTC | [2020_01_10_11_46_20] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0324482
Z variance train             0.015855428
KL Divergence                23.930286
KL Loss                      2.3930287
QF Loss                      1926.3182
VF Loss                      158.03876
Policy Loss                  -1035.8652
Q Predictions Mean           1035.4734
Q Predictions Std            255.01282
Q Predictions Max            1259.2423
Q Predictions Min            41.144306
V Predictions Mean           1033.3799
V Predictions Std            254.64445
V Predictions Max            1255.2692
V Predictions Min            46.131897
Log Pis Mean                 -0.6159294
Log Pis Std                  2.6534674
Log Pis Max                  7.315298
Log Pis Min                  -7.85079
Policy mu Mean               0.086638644
Policy mu Std                0.6025611
Policy mu Max                2.2903948
Policy mu Min                -2.0115244
Policy log std Mean          -0.87130153
Policy log std Std           0.24869196
Policy log std Max           -0.196679
Policy log std Min           -2.123341
Z mean eval                  1.0512238
Z variance eval              0.01267161
total_rewards                [ 892.11729499 1431.37781703 2937.2389338  2890.34986707 2946.88545152
 2428.35968858 2384.30698769   95.99921802  685.00880639 2413.3502501 ]
total_rewards_mean           1910.4994315196502
total_rewards_std            994.7274325384741
total_rewards_max            2946.8854515180888
total_rewards_min            95.9992180230897
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               33.07966720033437
(Previous) Eval Time (s)     22.384984909091145
Sample Time (s)              24.85105253243819
Epoch Time (s)               80.3157046418637
Total Train Time (s)         26499.73427045392
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:08:00.966474 UTC | [2020_01_10_11_46_20] Iteration #296 | Epoch Duration: 87.91119527816772
2020-01-10 19:08:00.966657 UTC | [2020_01_10_11_46_20] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0528356
Z variance train             0.012661283
KL Divergence                23.471455
KL Loss                      2.3471456
QF Loss                      666.0609
VF Loss                      401.09357
Policy Loss                  -1068.7445
Q Predictions Mean           1064.4247
Q Predictions Std            201.07448
Q Predictions Max            1204.8862
Q Predictions Min            -32.534824
V Predictions Mean           1056.3569
V Predictions Std            192.90723
V Predictions Max            1187.513
V Predictions Min            44.58599
Log Pis Mean                 -0.63963914
Log Pis Std                  2.3074667
Log Pis Max                  11.402896
Log Pis Min                  -6.0661182
Policy mu Mean               0.029342642
Policy mu Std                0.5660329
Policy mu Max                2.2316182
Policy mu Min                -2.2855966
Policy log std Mean          -0.94041646
Policy log std Std           0.2544934
Policy log std Max           -0.24236739
Policy log std Min           -2.5229592
Z mean eval                  1.0511018
Z variance eval              0.012286255
total_rewards                [ 440.53417213  358.53628742 2597.94072515  710.76072129 2212.11055918
  940.15836541 1167.6926072   329.70393706 1415.496431   1284.39074432]
total_rewards_mean           1145.7324550161188
total_rewards_std            731.63503026651
total_rewards_max            2597.9407251484013
total_rewards_min            329.7039370620335
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               33.63171827606857
(Previous) Eval Time (s)     29.98015780793503
Sample Time (s)              25.536500410642475
Epoch Time (s)               89.14837649464607
Total Train Time (s)         26577.72798200557
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:09:18.964422 UTC | [2020_01_10_11_46_20] Iteration #297 | Epoch Duration: 77.99761462211609
2020-01-10 19:09:18.964655 UTC | [2020_01_10_11_46_20] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0514218
Z variance train             0.012280644
KL Divergence                24.506834
KL Loss                      2.4506834
QF Loss                      695.07623
VF Loss                      129.41821
Policy Loss                  -1054.8679
Q Predictions Mean           1053.2515
Q Predictions Std            221.28139
Q Predictions Max            1236.2357
Q Predictions Min            22.038168
V Predictions Mean           1055.8694
V Predictions Std            220.65945
V Predictions Max            1229.0247
V Predictions Min            -22.569675
Log Pis Mean                 -0.38415986
Log Pis Std                  3.0941086
Log Pis Max                  18.618052
Log Pis Min                  -9.388855
Policy mu Mean               0.051590614
Policy mu Std                0.5974846
Policy mu Max                3.900614
Policy mu Min                -3.0888367
Policy log std Mean          -0.94710636
Policy log std Std           0.3020001
Policy log std Max           0.07949823
Policy log std Min           -2.6545038
Z mean eval                  1.0205767
Z variance eval              0.01495665
total_rewards                [2758.37529693 2529.16994501 2406.02841006 2882.99700414  358.83600696
 1729.0426651  2868.44932305 1753.24452637 1520.26540816  308.07963214]
total_rewards_mean           1911.448821791401
total_rewards_std            916.2943314691652
total_rewards_max            2882.9970041413508
total_rewards_min            308.0796321358384
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               35.04749856889248
(Previous) Eval Time (s)     18.829051890876144
Sample Time (s)              26.46558650629595
Epoch Time (s)               80.34213696606457
Total Train Time (s)         26664.784090197645
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:46.027011 UTC | [2020_01_10_11_46_20] Iteration #298 | Epoch Duration: 87.06217384338379
2020-01-10 19:10:46.027329 UTC | [2020_01_10_11_46_20] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0187287
Z variance train             0.014909843
KL Divergence                23.758547
KL Loss                      2.3758547
QF Loss                      716.2566
VF Loss                      205.59784
Policy Loss                  -1039.6133
Q Predictions Mean           1036.8599
Q Predictions Std            254.12068
Q Predictions Max            1231.9065
Q Predictions Min            -3.391819
V Predictions Mean           1046.1538
V Predictions Std            251.7238
V Predictions Max            1238.5671
V Predictions Min            15.114084
Log Pis Mean                 -0.6783748
Log Pis Std                  2.4816961
Log Pis Max                  6.1750445
Log Pis Min                  -7.0478344
Policy mu Mean               0.05048892
Policy mu Std                0.5794736
Policy mu Max                2.1762593
Policy mu Min                -2.2411823
Policy log std Mean          -0.9072083
Policy log std Std           0.25112772
Policy log std Max           -0.20322853
Policy log std Min           -1.9322586
Z mean eval                  1.0509827
Z variance eval              0.018272277
total_rewards                [2511.74664158 2755.04147781  204.32074053  678.71390423  151.41138473
 2814.3710202   846.55515781   73.14838365 1827.47865537 2519.0544723 ]
total_rewards_mean           1438.1841838225805
total_rewards_std            1098.5770995731425
total_rewards_max            2814.371020196653
total_rewards_min            73.1483836530426
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               35.333126387093216
(Previous) Eval Time (s)     25.54870733898133
Sample Time (s)              25.64702876796946
Epoch Time (s)               86.528862494044
Total Train Time (s)         26746.08885859931
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:12:07.335285 UTC | [2020_01_10_11_46_20] Iteration #299 | Epoch Duration: 81.3077437877655
2020-01-10 19:12:07.335497 UTC | [2020_01_10_11_46_20] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0526812
Z variance train             0.01825108
KL Divergence                23.954979
KL Loss                      2.395498
QF Loss                      764.1234
VF Loss                      287.92642
Policy Loss                  -1055.5679
Q Predictions Mean           1051.4427
Q Predictions Std            229.4525
Q Predictions Max            1274.8274
Q Predictions Min            29.692518
V Predictions Mean           1049.6179
V Predictions Std            221.70512
V Predictions Max            1267.7241
V Predictions Min            6.332958
Log Pis Mean                 -0.6355436
Log Pis Std                  2.6259553
Log Pis Max                  10.362259
Log Pis Min                  -8.407083
Policy mu Mean               0.077687904
Policy mu Std                0.59158474
Policy mu Max                2.8089278
Policy mu Min                -3.3579545
Policy log std Mean          -0.93284905
Policy log std Std           0.2800732
Policy log std Max           -0.11566776
Policy log std Min           -2.5928223
Z mean eval                  1.0360314
Z variance eval              0.01482289
total_rewards                [2741.21239231 3048.05167533 1037.33143916 2953.25481935  -73.80684828
 2752.23474217 2860.63782531 2411.25983596 1262.58571776 1797.80554258]
total_rewards_mean           2079.056714164417
total_rewards_std            989.0278300112707
total_rewards_max            3048.051675325095
total_rewards_min            -73.80684828398738
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               36.72489020600915
(Previous) Eval Time (s)     20.327223093248904
Sample Time (s)              27.78800102043897
Epoch Time (s)               84.84011431969702
Total Train Time (s)         26841.39678021893
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:13:42.646821 UTC | [2020_01_10_11_46_20] Iteration #300 | Epoch Duration: 95.31116533279419
2020-01-10 19:13:42.647035 UTC | [2020_01_10_11_46_20] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0359254
Z variance train             0.0148133505
KL Divergence                24.286825
KL Loss                      2.4286826
QF Loss                      774.1644
VF Loss                      107.969604
Policy Loss                  -1066.2882
Q Predictions Mean           1064.6774
Q Predictions Std            211.84946
Q Predictions Max            1256.8433
Q Predictions Min            41.272434
V Predictions Mean           1060.4194
V Predictions Std            209.39256
V Predictions Max            1242.0922
V Predictions Min            47.779472
Log Pis Mean                 -0.7769673
Log Pis Std                  2.6633008
Log Pis Max                  10.7142315
Log Pis Min                  -9.182975
Policy mu Mean               0.050331846
Policy mu Std                0.5695761
Policy mu Max                2.2809691
Policy mu Min                -2.1643832
Policy log std Mean          -0.9342332
Policy log std Std           0.25856054
Policy log std Max           -0.1759848
Policy log std Min           -1.9998547
Z mean eval                  1.017648
Z variance eval              0.012042144
total_rewards                [2891.30432145 1067.27448005 2749.80438079 1194.56397674 3010.36578836
 2885.13630231 1304.55201836 2971.33099345 2680.61402165 2120.96660275]
total_rewards_mean           2287.591288592642
total_rewards_std            758.7853486120949
total_rewards_max            3010.3657883562455
total_rewards_min            1067.2744800526152
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               35.868532163091004
(Previous) Eval Time (s)     30.797852323390543
Sample Time (s)              26.329941221978515
Epoch Time (s)               92.99632570846006
Total Train Time (s)         26933.912379189394
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:15.165972 UTC | [2020_01_10_11_46_20] Iteration #301 | Epoch Duration: 92.51878952980042
2020-01-10 19:15:15.166180 UTC | [2020_01_10_11_46_20] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0177033
Z variance train             0.012077267
KL Divergence                24.660938
KL Loss                      2.4660938
QF Loss                      1188.2124
VF Loss                      289.28348
Policy Loss                  -1059.462
Q Predictions Mean           1059.5701
Q Predictions Std            215.30577
Q Predictions Max            1227.9307
Q Predictions Min            68.07291
V Predictions Mean           1065.2352
V Predictions Std            218.61935
V Predictions Max            1230.492
V Predictions Min            55.503033
Log Pis Mean                 -0.3266647
Log Pis Std                  2.899318
Log Pis Max                  9.490742
Log Pis Min                  -8.418445
Policy mu Mean               0.08705096
Policy mu Std                0.62319684
Policy mu Max                2.7472327
Policy mu Min                -1.7632331
Policy log std Mean          -0.929544
Policy log std Std           0.2817094
Policy log std Max           -0.27119493
Policy log std Min           -2.299394
Z mean eval                  1.0211403
Z variance eval              0.011469577
total_rewards                [ -22.39828775 3094.14575197 2867.23646502 2044.84798801  597.04388401
 2880.46295771 1274.15147902 2820.981514   3112.45052429 2395.53017206]
total_rewards_mean           2106.4452448346174
total_rewards_std            1061.4335673384946
total_rewards_max            3112.450524292907
total_rewards_min            -22.398287754105624
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               36.57771523296833
(Previous) Eval Time (s)     30.31986377108842
Sample Time (s)              26.262376501690596
Epoch Time (s)               93.15995550574735
Total Train Time (s)         27020.98083061818
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:16:42.238036 UTC | [2020_01_10_11_46_20] Iteration #302 | Epoch Duration: 87.0717043876648
2020-01-10 19:16:42.238262 UTC | [2020_01_10_11_46_20] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0270703
Z variance train             0.011475936
KL Divergence                25.26996
KL Loss                      2.5269961
QF Loss                      459.8533
VF Loss                      215.64587
Policy Loss                  -1074.9694
Q Predictions Mean           1074.1641
Q Predictions Std            204.5681
Q Predictions Max            1248.4575
Q Predictions Min            36.431953
V Predictions Mean           1063.2236
V Predictions Std            204.05013
V Predictions Max            1234.6326
V Predictions Min            32.940025
Log Pis Mean                 -0.41249788
Log Pis Std                  2.28004
Log Pis Max                  4.729248
Log Pis Min                  -9.129719
Policy mu Mean               0.0005439196
Policy mu Std                0.58868575
Policy mu Max                2.12378
Policy mu Min                -2.1595092
Policy log std Mean          -0.9274105
Policy log std Std           0.23403166
Policy log std Max           0.04876381
Policy log std Min           -1.881347
Z mean eval                  1.0184966
Z variance eval              0.0114999125
total_rewards                [1904.0479602  3078.8513101  2879.43280768  393.00686061  914.12232039
 2958.34695514 3020.3786192   462.69112646 1055.73035919 1041.97893206]
total_rewards_mean           1770.8587251036818
total_rewards_std            1063.7386220187775
total_rewards_max            3078.8513101003587
total_rewards_min            393.00686061487676
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               35.01582541083917
(Previous) Eval Time (s)     24.231219321954995
Sample Time (s)              26.977549572940916
Epoch Time (s)               86.22459430573508
Total Train Time (s)         27105.64023469854
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:18:06.901413 UTC | [2020_01_10_11_46_20] Iteration #303 | Epoch Duration: 84.66297316551208
2020-01-10 19:18:06.901669 UTC | [2020_01_10_11_46_20] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0186749
Z variance train             0.01150394
KL Divergence                25.331642
KL Loss                      2.5331643
QF Loss                      496.74847
VF Loss                      598.3866
Policy Loss                  -1078.1976
Q Predictions Mean           1076.7875
Q Predictions Std            190.67401
Q Predictions Max            1235.4542
Q Predictions Min            22.158127
V Predictions Mean           1081.2074
V Predictions Std            190.97856
V Predictions Max            1246.8226
V Predictions Min            32.232983
Log Pis Mean                 -0.44556558
Log Pis Std                  2.4244936
Log Pis Max                  10.724945
Log Pis Min                  -7.131244
Policy mu Mean               0.06104398
Policy mu Std                0.60329545
Policy mu Max                2.4645724
Policy mu Min                -1.9772569
Policy log std Mean          -0.9463396
Policy log std Std           0.26158637
Policy log std Max           -0.13345933
Policy log std Min           -2.4230022
Z mean eval                  1.0339147
Z variance eval              0.012056904
total_rewards                [ -14.216447   -203.38853604 2818.1371072  2918.7744222  1631.26618376
 3098.31571331 1001.65586248 2967.48252854 2832.86419952 2866.79794293]
total_rewards_mean           1991.7688976904356
total_rewards_std            1230.641423515592
total_rewards_max            3098.315713305151
total_rewards_min            -203.3885360438105
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               36.0248550157994
(Previous) Eval Time (s)     22.66919987089932
Sample Time (s)              27.191813179757446
Epoch Time (s)               85.88586806645617
Total Train Time (s)         27196.931441247463
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:19:38.196647 UTC | [2020_01_10_11_46_20] Iteration #304 | Epoch Duration: 91.2947781085968
2020-01-10 19:19:38.196987 UTC | [2020_01_10_11_46_20] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0329548
Z variance train             0.012030758
KL Divergence                24.880993
KL Loss                      2.4880993
QF Loss                      384.54034
VF Loss                      599.2321
Policy Loss                  -1028.9922
Q Predictions Mean           1031.1768
Q Predictions Std            284.20343
Q Predictions Max            1256.6212
Q Predictions Min            35.33386
V Predictions Mean           1036.7938
V Predictions Std            287.49603
V Predictions Max            1262.641
V Predictions Min            8.454658
Log Pis Mean                 -0.50394005
Log Pis Std                  2.5877275
Log Pis Max                  6.9771366
Log Pis Min                  -7.715504
Policy mu Mean               0.0548308
Policy mu Std                0.5961577
Policy mu Max                2.324557
Policy mu Min                -2.6040194
Policy log std Mean          -0.9172568
Policy log std Std           0.26769236
Policy log std Max           0.49883205
Policy log std Min           -1.9501257
Z mean eval                  1.0152715
Z variance eval              0.013079074
total_rewards                [ -22.29031708  279.43743871 3088.19411622 2141.12028646 2987.76180265
  239.65630992 2863.09458027  532.4738344  2847.00171645  233.32083276]
total_rewards_mean           1518.977060075955
total_rewards_std            1294.2897709235
total_rewards_max            3088.1941162200405
total_rewards_min            -22.290317076399095
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               36.9620321188122
(Previous) Eval Time (s)     28.07766465190798
Sample Time (s)              27.7830475801602
Epoch Time (s)               92.82274435088038
Total Train Time (s)         27281.412199083716
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:21:02.680316 UTC | [2020_01_10_11_46_20] Iteration #305 | Epoch Duration: 84.48314809799194
2020-01-10 19:21:02.680492 UTC | [2020_01_10_11_46_20] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0160795
Z variance train             0.013084404
KL Divergence                23.975992
KL Loss                      2.3975992
QF Loss                      578.9736
VF Loss                      99.05568
Policy Loss                  -1067.5319
Q Predictions Mean           1067.9275
Q Predictions Std            208.77458
Q Predictions Max            1252.8403
Q Predictions Min            33.51157
V Predictions Mean           1071.4224
V Predictions Std            207.61913
V Predictions Max            1250.8779
V Predictions Min            32.551064
Log Pis Mean                 -0.7149675
Log Pis Std                  2.6161447
Log Pis Max                  9.979736
Log Pis Min                  -10.684099
Policy mu Mean               0.040711157
Policy mu Std                0.5741614
Policy mu Max                2.80172
Policy mu Min                -2.337818
Policy log std Mean          -0.9415654
Policy log std Std           0.26128888
Policy log std Max           -0.22101963
Policy log std Min           -2.4917605
Z mean eval                  1.0324142
Z variance eval              0.015640903
total_rewards                [2610.59818925 2775.40035418 3043.24242494 2960.28437266 2956.67500884
 1945.73405676 2952.84701238  987.94314069 2807.467932    621.09430821]
total_rewards_mean           2366.128679989724
total_rewards_std            839.5122594158571
total_rewards_max            3043.242424943188
total_rewards_min            621.0943082090258
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               35.564145100302994
(Previous) Eval Time (s)     19.737682928331196
Sample Time (s)              26.210134075954556
Epoch Time (s)               81.51196210458875
Total Train Time (s)         27376.782392893918
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:22:38.053301 UTC | [2020_01_10_11_46_20] Iteration #306 | Epoch Duration: 95.37264060974121
2020-01-10 19:22:38.053443 UTC | [2020_01_10_11_46_20] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0346711
Z variance train             0.015564529
KL Divergence                24.091312
KL Loss                      2.4091313
QF Loss                      904.624
VF Loss                      354.96155
Policy Loss                  -1104.9055
Q Predictions Mean           1102.3182
Q Predictions Std            190.56967
Q Predictions Max            1282.099
Q Predictions Min            24.872326
V Predictions Mean           1091.7893
V Predictions Std            186.81029
V Predictions Max            1266.4885
V Predictions Min            41.446518
Log Pis Mean                 -0.28425765
Log Pis Std                  2.6402595
Log Pis Max                  11.175589
Log Pis Min                  -6.5414686
Policy mu Mean               0.042556494
Policy mu Std                0.6195836
Policy mu Max                2.432167
Policy mu Min                -1.9768215
Policy log std Mean          -0.9088539
Policy log std Std           0.24890548
Policy log std Max           -0.26982605
Policy log std Min           -2.4123025
Z mean eval                  1.0379124
Z variance eval              0.024283305
total_rewards                [ 329.28452029  356.41842217 2428.51603638  129.59773139 1142.10331425
 3037.29177173 2709.89535005  123.2062127   995.75661587  383.06555583]
total_rewards_mean           1163.5135530663097
total_rewards_std            1078.8343033309238
total_rewards_max            3037.2917717295077
total_rewards_min            123.20621269925685
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               36.663847615011036
(Previous) Eval Time (s)     33.5979392179288
Sample Time (s)              26.417501842137426
Epoch Time (s)               96.67928867507726
Total Train Time (s)         27455.14562648954
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:23:56.420942 UTC | [2020_01_10_11_46_20] Iteration #307 | Epoch Duration: 78.3673677444458
2020-01-10 19:23:56.421151 UTC | [2020_01_10_11_46_20] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0383791
Z variance train             0.02430442
KL Divergence                24.912632
KL Loss                      2.4912632
QF Loss                      434.03442
VF Loss                      127.7375
Policy Loss                  -1078.2975
Q Predictions Mean           1078.6705
Q Predictions Std            211.63733
Q Predictions Max            1250.7725
Q Predictions Min            31.478565
V Predictions Mean           1080.4651
V Predictions Std            214.10815
V Predictions Max            1243.0588
V Predictions Min            36.281128
Log Pis Mean                 -0.11699431
Log Pis Std                  2.638807
Log Pis Max                  11.587698
Log Pis Min                  -5.605199
Policy mu Mean               0.017029107
Policy mu Std                0.6096186
Policy mu Max                2.7418556
Policy mu Min                -2.5444725
Policy log std Mean          -0.9505893
Policy log std Std           0.2696497
Policy log std Max           -0.14253324
Policy log std Min           -2.419756
Z mean eval                  1.0510442
Z variance eval              0.020266468
total_rewards                [2853.81215339  864.51651404 3139.15088149 2988.7951722  2884.3637189
 2957.54394694 1238.61725734 2942.0014661  2854.03514549 3000.61085517]
total_rewards_mean           2572.344711106035
total_rewards_std            769.0625484345198
total_rewards_max            3139.1508814895574
total_rewards_min            864.5165140364729
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               33.926170522812754
(Previous) Eval Time (s)     15.285588982980698
Sample Time (s)              26.401977457106113
Epoch Time (s)               75.61373696289957
Total Train Time (s)         27544.861657354515
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:25:26.140563 UTC | [2020_01_10_11_46_20] Iteration #308 | Epoch Duration: 89.71927666664124
2020-01-10 19:25:26.140745 UTC | [2020_01_10_11_46_20] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495808
Z variance train             0.020197343
KL Divergence                24.76099
KL Loss                      2.476099
QF Loss                      967.68
VF Loss                      640.1511
Policy Loss                  -1057.8203
Q Predictions Mean           1057.0945
Q Predictions Std            262.29398
Q Predictions Max            1248.7865
Q Predictions Min            29.602589
V Predictions Mean           1041.939
V Predictions Std            256.227
V Predictions Max            1244.7694
V Predictions Min            23.033947
Log Pis Mean                 -0.32679075
Log Pis Std                  3.0068843
Log Pis Max                  16.610998
Log Pis Min                  -8.415264
Policy mu Mean               0.06475339
Policy mu Std                0.5833303
Policy mu Max                2.0732071
Policy mu Min                -2.0208337
Policy log std Mean          -0.9569417
Policy log std Std           0.3056239
Policy log std Max           -0.23612362
Policy log std Min           -3.24439
Z mean eval                  1.0603621
Z variance eval              0.018014135
total_rewards                [2592.98307218 3007.12012062 2926.45203494 1515.8963852    73.37112988
 3174.42679429  204.1575481  3137.56903399 1731.99130956  131.76013663]
total_rewards_mean           1849.5727565391662
total_rewards_std            1241.1585455190511
total_rewards_max            3174.4267942881825
total_rewards_min            73.37112987624238
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               33.60631379298866
(Previous) Eval Time (s)     29.390765878837556
Sample Time (s)              25.40119837736711
Epoch Time (s)               88.39827804919332
Total Train Time (s)         27630.43428043509
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:26:51.716839 UTC | [2020_01_10_11_46_20] Iteration #309 | Epoch Duration: 85.57595801353455
2020-01-10 19:26:51.717020 UTC | [2020_01_10_11_46_20] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.05519
Z variance train             0.017928008
KL Divergence                24.885971
KL Loss                      2.4885972
QF Loss                      531.9416
VF Loss                      104.00078
Policy Loss                  -1045.5448
Q Predictions Mean           1041.9175
Q Predictions Std            251.41896
Q Predictions Max            1271.4495
Q Predictions Min            20.176352
V Predictions Mean           1045.8853
V Predictions Std            251.82066
V Predictions Max            1273.5833
V Predictions Min            28.857
Log Pis Mean                 -0.525638
Log Pis Std                  2.4696486
Log Pis Max                  8.47194
Log Pis Min                  -7.4564495
Policy mu Mean               0.031233588
Policy mu Std                0.6017551
Policy mu Max                2.0666218
Policy mu Min                -1.862508
Policy log std Mean          -0.9214102
Policy log std Std           0.2607627
Policy log std Max           -0.25552207
Policy log std Min           -2.2227368
Z mean eval                  1.0344074
Z variance eval              0.014473443
total_rewards                [2995.74134253 2945.03666902 2827.28378609 1293.12383738 2918.68550551
  637.38253049 1003.4800714  2640.59569538 2638.8980476   937.54958646]
total_rewards_mean           2083.7777071855107
total_rewards_std            929.4942868333166
total_rewards_max            2995.7413425275936
total_rewards_min            637.3825304897896
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               33.487251648679376
(Previous) Eval Time (s)     26.56812033802271
Sample Time (s)              25.713123075198382
Epoch Time (s)               85.76849506190047
Total Train Time (s)         27716.468638831284
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:28:17.754469 UTC | [2020_01_10_11_46_20] Iteration #310 | Epoch Duration: 86.03731393814087
2020-01-10 19:28:17.754641 UTC | [2020_01_10_11_46_20] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0349431
Z variance train             0.014474295
KL Divergence                24.848347
KL Loss                      2.4848347
QF Loss                      1531.2567
VF Loss                      158.96854
Policy Loss                  -1079.5787
Q Predictions Mean           1079.9973
Q Predictions Std            224.51477
Q Predictions Max            1251.8228
Q Predictions Min            -21.868073
V Predictions Mean           1075.8794
V Predictions Std            223.88844
V Predictions Max            1237.3093
V Predictions Min            13.62837
Log Pis Mean                 -0.3828751
Log Pis Std                  2.6269996
Log Pis Max                  11.764074
Log Pis Min                  -11.499688
Policy mu Mean               0.06033887
Policy mu Std                0.57347584
Policy mu Max                2.6677692
Policy mu Min                -2.121359
Policy log std Mean          -0.9521949
Policy log std Std           0.26908758
Policy log std Max           -0.1961177
Policy log std Min           -2.6452768
Z mean eval                  1.0467336
Z variance eval              0.016490962
total_rewards                [2875.07992375   57.98320951 1515.83774217 2922.10976192 2583.16318843
 1833.3346457   346.66682904 1548.65586784  705.53549172 2921.91010703]
total_rewards_mean           1731.0276767132466
total_rewards_std            1035.8121373400668
total_rewards_max            2922.1097619246884
total_rewards_min            57.983209510934984
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               33.877029404975474
(Previous) Eval Time (s)     26.836620565969497
Sample Time (s)              26.137389479670674
Epoch Time (s)               86.85103945061564
Total Train Time (s)         27802.414326102007
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:29:43.703979 UTC | [2020_01_10_11_46_20] Iteration #311 | Epoch Duration: 85.949214220047
2020-01-10 19:29:43.704158 UTC | [2020_01_10_11_46_20] Iteration #311 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0451095
Z variance train             0.016472682
KL Divergence                24.433817
KL Loss                      2.4433818
QF Loss                      900.0166
VF Loss                      160.26308
Policy Loss                  -1082.2556
Q Predictions Mean           1084.4088
Q Predictions Std            217.08112
Q Predictions Max            1281.8448
Q Predictions Min            40.416637
V Predictions Mean           1091.4572
V Predictions Std            219.51276
V Predictions Max            1282.1226
V Predictions Min            42.08991
Log Pis Mean                 -0.60782915
Log Pis Std                  2.6987166
Log Pis Max                  13.1578665
Log Pis Min                  -8.22986
Policy mu Mean               0.020171318
Policy mu Std                0.59034693
Policy mu Max                2.219742
Policy mu Min                -1.8625207
Policy log std Mean          -0.9557339
Policy log std Std           0.25616163
Policy log std Max           -0.22254235
Policy log std Min           -2.554748
Z mean eval                  1.1007061
Z variance eval              0.020136774
total_rewards                [2122.88778789  619.96385872  112.16568421  906.68333801  387.588702
 2568.7941137    71.29037408 1265.62894387  381.31325002 2926.54091745]
total_rewards_mean           1136.2856969963268
total_rewards_std            993.9859349065283
total_rewards_max            2926.540917448184
total_rewards_min            71.29037408450944
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               33.84595552412793
(Previous) Eval Time (s)     25.93445599405095
Sample Time (s)              26.019719280302525
Epoch Time (s)               85.8001307984814
Total Train Time (s)         27885.61227971036
Epoch                        312
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:31:06.906111 UTC | [2020_01_10_11_46_20] Iteration #312 | Epoch Duration: 83.20179438591003
2020-01-10 19:31:06.906330 UTC | [2020_01_10_11_46_20] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0994828
Z variance train             0.020040296
KL Divergence                24.925068
KL Loss                      2.4925067
QF Loss                      1641.9297
VF Loss                      168.49727
Policy Loss                  -1094.2302
Q Predictions Mean           1093.136
Q Predictions Std            237.33018
Q Predictions Max            1332.331
Q Predictions Min            47.564793
V Predictions Mean           1089.9849
V Predictions Std            235.12941
V Predictions Max            1316.6746
V Predictions Min            41.608
Log Pis Mean                 -0.08020732
Log Pis Std                  2.9162116
Log Pis Max                  10.784107
Log Pis Min                  -6.6252723
Policy mu Mean               0.13364619
Policy mu Std                0.632355
Policy mu Max                2.8252108
Policy mu Min                -1.7617769
Policy log std Mean          -0.92404175
Policy log std Std           0.2567579
Policy log std Max           -0.28679365
Policy log std Min           -1.9083531
Z mean eval                  1.0317515
Z variance eval              0.009545883
total_rewards                [-104.99833085 1492.34571932 2309.877046    940.08378068  253.20327534
  306.20147471 1004.23598238  275.73013306 1447.68616886  347.0671741 ]
total_rewards_mean           827.1432423599105
total_rewards_std            712.347497163832
total_rewards_max            2309.8770459966986
total_rewards_min            -104.9983308482218
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               33.12377725215629
(Previous) Eval Time (s)     23.335716143250465
Sample Time (s)              25.572466736193746
Epoch Time (s)               82.0319601316005
Total Train Time (s)         27965.191986733582
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:32:26.490576 UTC | [2020_01_10_11_46_20] Iteration #313 | Epoch Duration: 79.58405184745789
2020-01-10 19:32:26.490834 UTC | [2020_01_10_11_46_20] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.03049
Z variance train             0.009546759
KL Divergence                25.79075
KL Loss                      2.579075
QF Loss                      610.1492
VF Loss                      114.60041
Policy Loss                  -1099.5367
Q Predictions Mean           1098.4607
Q Predictions Std            198.59715
Q Predictions Max            1277.2198
Q Predictions Min            -7.161324
V Predictions Mean           1104.3579
V Predictions Std            197.97821
V Predictions Max            1279.9193
V Predictions Min            35.41022
Log Pis Mean                 -0.53541625
Log Pis Std                  2.610641
Log Pis Max                  8.264186
Log Pis Min                  -9.16057
Policy mu Mean               0.03285872
Policy mu Std                0.57713276
Policy mu Max                2.4469752
Policy mu Min                -2.0013056
Policy log std Mean          -0.9337095
Policy log std Std           0.24915881
Policy log std Max           -0.06345433
Policy log std Min           -2.1789432
Z mean eval                  1.0361518
Z variance eval              0.0065867812
total_rewards                [ 642.65196579 3067.03522357 2924.36247518 2831.50546901 1584.09734788
 2890.01765168 3019.82630278 2968.56619326 2227.69078866 2990.71986361]
total_rewards_mean           2514.647328142707
total_rewards_std            765.1684781485237
total_rewards_max            3067.0352235738087
total_rewards_min            642.6519657852436
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               33.86154521116987
(Previous) Eval Time (s)     20.887400314211845
Sample Time (s)              25.805154100991786
Epoch Time (s)               80.5540996263735
Total Train Time (s)         28053.76634670794
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:33:55.068084 UTC | [2020_01_10_11_46_20] Iteration #314 | Epoch Duration: 88.57706832885742
2020-01-10 19:33:55.068305 UTC | [2020_01_10_11_46_20] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0341656
Z variance train             0.0065923817
KL Divergence                26.529186
KL Loss                      2.6529186
QF Loss                      394.33386
VF Loss                      236.27855
Policy Loss                  -1079.2242
Q Predictions Mean           1080.0586
Q Predictions Std            254.1269
Q Predictions Max            1272.0869
Q Predictions Min            -102.576645
V Predictions Mean           1073.2571
V Predictions Std            250.64717
V Predictions Max            1270.2498
V Predictions Min            56.10217
Log Pis Mean                 -0.48001856
Log Pis Std                  2.4706619
Log Pis Max                  8.784021
Log Pis Min                  -7.170787
Policy mu Mean               -0.025275711
Policy mu Std                0.55617404
Policy mu Max                2.1487052
Policy mu Min                -2.051887
Policy log std Mean          -0.97346556
Policy log std Std           0.2586765
Policy log std Max           -0.24409717
Policy log std Min           -2.0137925
Z mean eval                  1.042309
Z variance eval              0.0062561287
total_rewards                [2851.20537543 2933.94670374 2966.58753145  802.38814032 1543.11654506
  252.43511597  555.08563487 1360.03716508 2314.96721389  588.00503397]
total_rewards_mean           1616.7774459781522
total_rewards_std            1017.3380459662256
total_rewards_max            2966.587531450061
total_rewards_min            252.4351159741512
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               33.376129305921495
(Previous) Eval Time (s)     28.9099928769283
Sample Time (s)              25.59204036789015
Epoch Time (s)               87.87816255073994
Total Train Time (s)         28132.94057913171
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:35:14.247579 UTC | [2020_01_10_11_46_20] Iteration #315 | Epoch Duration: 79.17904710769653
2020-01-10 19:35:14.247887 UTC | [2020_01_10_11_46_20] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0423076
Z variance train             0.006277097
KL Divergence                26.786457
KL Loss                      2.6786458
QF Loss                      716.3014
VF Loss                      115.295
Policy Loss                  -1090.6665
Q Predictions Mean           1089.6123
Q Predictions Std            227.99431
Q Predictions Max            1277.7078
Q Predictions Min            57.348537
V Predictions Mean           1092.1167
V Predictions Std            228.98647
V Predictions Max            1268.8054
V Predictions Min            44.247242
Log Pis Mean                 -0.7171935
Log Pis Std                  2.5621614
Log Pis Max                  9.109371
Log Pis Min                  -8.647628
Policy mu Mean               0.011450728
Policy mu Std                0.5759494
Policy mu Max                2.5657446
Policy mu Min                -1.8449149
Policy log std Mean          -0.9212879
Policy log std Std           0.26727304
Policy log std Max           -0.17944854
Policy log std Min           -2.5185413
Z mean eval                  1.0427308
Z variance eval              0.0058794906
total_rewards                [ 383.81261358 2669.70581652 1260.42547723  258.78151268 2168.99291931
  719.97311673 1117.43355874 1263.23360001 2241.45677613 1040.61631078]
total_rewards_mean           1312.4431701702908
total_rewards_std            766.7809347865901
total_rewards_max            2669.7058165187586
total_rewards_min            258.78151267834164
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               33.644499665591866
(Previous) Eval Time (s)     20.21049055084586
Sample Time (s)              25.43058965355158
Epoch Time (s)               79.2855798699893
Total Train Time (s)         28209.08245996991
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:36:30.392533 UTC | [2020_01_10_11_46_20] Iteration #316 | Epoch Duration: 76.14447546005249
2020-01-10 19:36:30.392754 UTC | [2020_01_10_11_46_20] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0430379
Z variance train             0.0058870455
KL Divergence                26.75933
KL Loss                      2.6759331
QF Loss                      700.6533
VF Loss                      107.080376
Policy Loss                  -1092.3295
Q Predictions Mean           1092.8086
Q Predictions Std            219.33871
Q Predictions Max            1272.5687
Q Predictions Min            105.041435
V Predictions Mean           1091.5068
V Predictions Std            217.76941
V Predictions Max            1271.8833
V Predictions Min            109.651596
Log Pis Mean                 -0.4542151
Log Pis Std                  3.029987
Log Pis Max                  17.033981
Log Pis Min                  -7.5447993
Policy mu Mean               0.010067277
Policy mu Std                0.6252691
Policy mu Max                3.060341
Policy mu Min                -3.7250488
Policy log std Mean          -0.92211425
Policy log std Std           0.275928
Policy log std Max           -0.19718605
Policy log std Min           -2.2672048
Z mean eval                  1.0040768
Z variance eval              0.012334315
total_rewards                [2150.74056078  956.99146922 1405.11551913   58.98574751  837.98375486
  318.86947759 3087.53174875 1666.00452158  995.36798877 2988.36632354]
total_rewards_mean           1446.595711171693
total_rewards_std            981.1403394002342
total_rewards_max            3087.531748754714
total_rewards_min            58.98574750809153
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               33.6296946471557
(Previous) Eval Time (s)     17.069047804921865
Sample Time (s)              25.667686987668276
Epoch Time (s)               76.36642943974584
Total Train Time (s)         28288.102285326924
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:37:49.416152 UTC | [2020_01_10_11_46_20] Iteration #317 | Epoch Duration: 79.02324795722961
2020-01-10 19:37:49.416369 UTC | [2020_01_10_11_46_20] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0016851
Z variance train             0.012479279
KL Divergence                25.714653
KL Loss                      2.5714653
QF Loss                      480.30402
VF Loss                      144.57335
Policy Loss                  -1109.773
Q Predictions Mean           1108.5676
Q Predictions Std            206.05783
Q Predictions Max            1306.4572
Q Predictions Min            22.889217
V Predictions Mean           1113.3567
V Predictions Std            206.68301
V Predictions Max            1313.061
V Predictions Min            13.772679
Log Pis Mean                 -0.02482915
Log Pis Std                  2.7479079
Log Pis Max                  7.6225977
Log Pis Min                  -7.0867
Policy mu Mean               -0.017713435
Policy mu Std                0.6275692
Policy mu Max                2.5552254
Policy mu Min                -1.717755
Policy log std Mean          -0.9802555
Policy log std Std           0.26539266
Policy log std Max           -0.1609832
Policy log std Min           -2.2621295
Z mean eval                  1.0642278
Z variance eval              0.01385666
total_rewards                [ 885.30196761 2858.58275972 3006.40470072 1342.53655304   13.4528052
 2929.86121699 1799.17213012 2878.28911139 1232.19102384 2783.31121041]
total_rewards_mean           1972.9103479036633
total_rewards_std            1012.0933002773494
total_rewards_max            3006.4047007228146
total_rewards_min            13.45280520191209
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               33.60399331105873
(Previous) Eval Time (s)     19.725472658872604
Sample Time (s)              25.87538437731564
Epoch Time (s)               79.20485034724697
Total Train Time (s)         28373.63200893812
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:39:14.949986 UTC | [2020_01_10_11_46_20] Iteration #318 | Epoch Duration: 85.53346538543701
2020-01-10 19:39:14.950238 UTC | [2020_01_10_11_46_20] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0631299
Z variance train             0.013830192
KL Divergence                25.80859
KL Loss                      2.580859
QF Loss                      545.343
VF Loss                      118.75246
Policy Loss                  -1097.5651
Q Predictions Mean           1095.2655
Q Predictions Std            234.9315
Q Predictions Max            1294.694
Q Predictions Min            44.726967
V Predictions Mean           1098.2318
V Predictions Std            236.56717
V Predictions Max            1277.4644
V Predictions Min            32.646927
Log Pis Mean                 -0.17542142
Log Pis Std                  2.5238822
Log Pis Max                  6.5807667
Log Pis Min                  -7.5553045
Policy mu Mean               0.022633173
Policy mu Std                0.6280225
Policy mu Max                2.5802453
Policy mu Min                -2.285115
Policy log std Mean          -0.9430349
Policy log std Std           0.26931512
Policy log std Max           -0.23197624
Policy log std Min           -2.008097
Z mean eval                  1.0424981
Z variance eval              0.017948145
total_rewards                [2871.59903756 2880.78928478  519.65087768 2857.92300061 2951.31530814
 2962.27065885   62.24359728 2334.70708357 1151.62135049  547.76536137]
total_rewards_mean           1913.9885560318428
total_rewards_std            1136.4676186983668
total_rewards_max            2962.270658851994
total_rewards_min            62.24359727570255
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               33.682842834386975
(Previous) Eval Time (s)     26.053711835294962
Sample Time (s)              25.5232772375457
Epoch Time (s)               85.25983190722764
Total Train Time (s)         28459.305062917992
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:40:40.630413 UTC | [2020_01_10_11_46_20] Iteration #319 | Epoch Duration: 85.67998766899109
2020-01-10 19:40:40.630732 UTC | [2020_01_10_11_46_20] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.044577
Z variance train             0.018009577
KL Divergence                25.35846
KL Loss                      2.535846
QF Loss                      911.78
VF Loss                      525.78687
Policy Loss                  -1105.0144
Q Predictions Mean           1100.4924
Q Predictions Std            241.1362
Q Predictions Max            1291.5961
Q Predictions Min            36.272663
V Predictions Mean           1089.8202
V Predictions Std            236.33907
V Predictions Max            1271.7632
V Predictions Min            71.266174
Log Pis Mean                 -0.15261477
Log Pis Std                  2.4671009
Log Pis Max                  8.85956
Log Pis Min                  -7.5982246
Policy mu Mean               -0.057744794
Policy mu Std                0.59652704
Policy mu Max                2.1295137
Policy mu Min                -2.879436
Policy log std Mean          -0.9694675
Policy log std Std           0.27163944
Policy log std Max           -0.26887184
Policy log std Min           -2.6169224
Z mean eval                  1.0660695
Z variance eval              0.017193772
total_rewards                [3040.80841434  973.22256284 2801.71079414 2961.68917611 2163.3487151
 2758.50237485 2930.63188329 2834.66514375  130.46834466 1685.12128615]
total_rewards_mean           2228.016869522744
total_rewards_std            945.7415543568251
total_rewards_max            3040.8084143416577
total_rewards_min            130.4683446573172
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               33.81823507184163
(Previous) Eval Time (s)     26.473516306839883
Sample Time (s)              25.33724257349968
Epoch Time (s)               85.62899395218119
Total Train Time (s)         28548.976132687647
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:10.305063 UTC | [2020_01_10_11_46_20] Iteration #320 | Epoch Duration: 89.67407774925232
2020-01-10 19:42:10.305449 UTC | [2020_01_10_11_46_20] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0643299
Z variance train             0.017252931
KL Divergence                25.564539
KL Loss                      2.556454
QF Loss                      534.26904
VF Loss                      242.75378
Policy Loss                  -1103.7654
Q Predictions Mean           1104.8495
Q Predictions Std            266.92877
Q Predictions Max            1296.46
Q Predictions Min            25.5786
V Predictions Mean           1116.513
V Predictions Std            267.68085
V Predictions Max            1307.3573
V Predictions Min            38.096973
Log Pis Mean                 -0.22664538
Log Pis Std                  2.7617917
Log Pis Max                  8.175671
Log Pis Min                  -7.720912
Policy mu Mean               0.092958644
Policy mu Std                0.62135243
Policy mu Max                2.8687103
Policy mu Min                -1.9838731
Policy log std Mean          -0.92524683
Policy log std Std           0.25565028
Policy log std Max           -0.18927664
Policy log std Min           -1.880521
Z mean eval                  1.0465899
Z variance eval              0.02599805
total_rewards                [2889.21421442 2898.9477205  3065.46308033 3009.75399074 2864.18096237
  127.47587049 1304.64360346  543.64849483 1664.91400565 1355.86654263]
total_rewards_mean           1972.4108485406773
total_rewards_std            1055.0278725491007
total_rewards_max            3065.463080329706
total_rewards_min            127.47587048714679
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               33.14735444588587
(Previous) Eval Time (s)     30.518183392938226
Sample Time (s)              26.719673776533455
Epoch Time (s)               90.38521161535755
Total Train Time (s)         28632.29072160367
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:43:33.623331 UTC | [2020_01_10_11_46_20] Iteration #321 | Epoch Duration: 83.3176040649414
2020-01-10 19:43:33.623526 UTC | [2020_01_10_11_46_20] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0473263
Z variance train             0.026062688
KL Divergence                24.458738
KL Loss                      2.445874
QF Loss                      857.9977
VF Loss                      142.99646
Policy Loss                  -1119.819
Q Predictions Mean           1117.374
Q Predictions Std            227.14256
Q Predictions Max            1311.7238
Q Predictions Min            -4.851355
V Predictions Mean           1123.7462
V Predictions Std            220.57646
V Predictions Max            1309.0433
V Predictions Min            4.3755927
Log Pis Mean                 -0.22811829
Log Pis Std                  2.6724575
Log Pis Max                  15.200621
Log Pis Min                  -6.2695603
Policy mu Mean               0.034511022
Policy mu Std                0.5998767
Policy mu Max                2.3018806
Policy mu Min                -2.7141528
Policy log std Mean          -0.9700639
Policy log std Std           0.27092287
Policy log std Max           -0.21976984
Policy log std Min           -2.399998
Z mean eval                  1.0615358
Z variance eval              0.019075181
total_rewards                [1054.08616348  841.16111644 3086.50822077 3277.40787429   19.69815398
 3296.6562912  3175.46404063 3138.9854845  1846.80890097 3011.12361458]
total_rewards_mean           2274.7899860849207
total_rewards_std            1167.158568110354
total_rewards_max            3296.656291200462
total_rewards_min            19.698153978507428
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               33.544001078698784
(Previous) Eval Time (s)     23.449931003153324
Sample Time (s)              24.70422930130735
Epoch Time (s)               81.69816138315946
Total Train Time (s)         28718.27376731392
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:44:59.610196 UTC | [2020_01_10_11_46_20] Iteration #322 | Epoch Duration: 85.98647141456604
2020-01-10 19:44:59.610452 UTC | [2020_01_10_11_46_20] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623915
Z variance train             0.019131234
KL Divergence                25.287321
KL Loss                      2.528732
QF Loss                      595.4925
VF Loss                      98.120094
Policy Loss                  -1121.224
Q Predictions Mean           1120.228
Q Predictions Std            217.67584
Q Predictions Max            1296.6973
Q Predictions Min            31.543688
V Predictions Mean           1124.9802
V Predictions Std            216.69643
V Predictions Max            1301.7294
V Predictions Min            46.43726
Log Pis Mean                 -0.27016145
Log Pis Std                  2.8636727
Log Pis Max                  17.88553
Log Pis Min                  -13.58437
Policy mu Mean               -0.006292989
Policy mu Std                0.5770708
Policy mu Max                3.0284324
Policy mu Min                -2.9826376
Policy log std Mean          -0.9889434
Policy log std Std           0.26467827
Policy log std Max           -0.012122035
Policy log std Min           -2.2222555
Z mean eval                  1.0395341
Z variance eval              0.0151865035
total_rewards                [2031.51673828  565.25517626 2767.04110482  491.7696076  1134.03181223
  637.59880142  410.26043655  893.15625583 2977.04638571  747.23920584]
total_rewards_mean           1265.4915524530652
total_rewards_std            917.06120411164
total_rewards_max            2977.046385712973
total_rewards_min            410.260436551636
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               33.609692476224154
(Previous) Eval Time (s)     27.737925203051418
Sample Time (s)              25.252545964438468
Epoch Time (s)               86.60016364371404
Total Train Time (s)         28794.87234058231
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:46:16.221232 UTC | [2020_01_10_11_46_20] Iteration #323 | Epoch Duration: 76.6106436252594
2020-01-10 19:46:16.221423 UTC | [2020_01_10_11_46_20] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0392663
Z variance train             0.015290143
KL Divergence                25.380219
KL Loss                      2.5380218
QF Loss                      4700.3833
VF Loss                      297.3235
Policy Loss                  -1129.8701
Q Predictions Mean           1131.3961
Q Predictions Std            185.30765
Q Predictions Max            1289.3274
Q Predictions Min            44.994244
V Predictions Mean           1132.5586
V Predictions Std            186.735
V Predictions Max            1288.702
V Predictions Min            35.649498
Log Pis Mean                 -0.07779987
Log Pis Std                  2.644728
Log Pis Max                  8.521703
Log Pis Min                  -6.914027
Policy mu Mean               -0.030905103
Policy mu Std                0.61153305
Policy mu Max                2.4999313
Policy mu Min                -2.205214
Policy log std Mean          -0.9697433
Policy log std Std           0.26892498
Policy log std Max           -0.19744402
Policy log std Min           -2.5315838
Z mean eval                  1.0477655
Z variance eval              0.018595178
total_rewards                [ 701.10973111  764.72522261 2936.37250285 1126.4314749   205.51505079
 3082.60636491 3025.87677568  223.60794409 3040.6123465   646.81341584]
total_rewards_mean           1575.3670829271819
total_rewards_std            1206.8138486316589
total_rewards_max            3082.6063649063553
total_rewards_min            205.51505078767923
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               33.49606697214767
(Previous) Eval Time (s)     17.748056342359632
Sample Time (s)              25.219392555300146
Epoch Time (s)               76.46351586980745
Total Train Time (s)         28877.809186745435
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:47:39.153125 UTC | [2020_01_10_11_46_20] Iteration #324 | Epoch Duration: 82.93156862258911
2020-01-10 19:47:39.153318 UTC | [2020_01_10_11_46_20] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0506777
Z variance train             0.018527405
KL Divergence                24.649244
KL Loss                      2.4649246
QF Loss                      1108.9155
VF Loss                      248.97821
Policy Loss                  -1110.5597
Q Predictions Mean           1111.0676
Q Predictions Std            189.15253
Q Predictions Max            1287.6978
Q Predictions Min            22.183012
V Predictions Mean           1117.6655
V Predictions Std            185.54036
V Predictions Max            1281.8005
V Predictions Min            33.990227
Log Pis Mean                 0.08957089
Log Pis Std                  2.7124305
Log Pis Max                  10.602124
Log Pis Min                  -7.5974803
Policy mu Mean               0.037210077
Policy mu Std                0.6187078
Policy mu Max                2.8571057
Policy mu Min                -1.9220742
Policy log std Mean          -0.9719372
Policy log std Std           0.27183968
Policy log std Max           -0.33392337
Policy log std Min           -2.6438103
Z mean eval                  1.0696896
Z variance eval              0.01461353
total_rewards                [2895.62784569 1660.05182235  363.61216751   86.90488532 2982.81263923
 2918.00332493 1182.83581477 1946.0590145   960.15735014  458.79340197]
total_rewards_mean           1545.485826640449
total_rewards_std            1054.7743340637844
total_rewards_max            2982.812639227974
total_rewards_min            86.90488532156618
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               33.899925988167524
(Previous) Eval Time (s)     24.215726256836206
Sample Time (s)              25.539273135364056
Epoch Time (s)               83.65492538036779
Total Train Time (s)         28959.073982492555
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:00.421104 UTC | [2020_01_10_11_46_20] Iteration #325 | Epoch Duration: 81.26764011383057
2020-01-10 19:49:00.421273 UTC | [2020_01_10_11_46_20] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0705179
Z variance train             0.014607839
KL Divergence                25.057606
KL Loss                      2.5057607
QF Loss                      395.424
VF Loss                      158.47672
Policy Loss                  -1119.0178
Q Predictions Mean           1118.6871
Q Predictions Std            213.12929
Q Predictions Max            1341.7477
Q Predictions Min            18.878117
V Predictions Mean           1114.1731
V Predictions Std            214.06036
V Predictions Max            1321.1581
V Predictions Min            8.322306
Log Pis Mean                 -0.25121748
Log Pis Std                  2.7278087
Log Pis Max                  8.060694
Log Pis Min                  -7.3403416
Policy mu Mean               0.07821955
Policy mu Std                0.6142446
Policy mu Max                2.2229848
Policy mu Min                -2.6066928
Policy log std Mean          -0.9540888
Policy log std Std           0.2730261
Policy log std Max           -0.21511525
Policy log std Min           -2.2438862
Z mean eval                  1.0578363
Z variance eval              0.012675026
total_rewards                [ 139.5150453  3134.70644781  888.62271055 3051.17457923 3228.71443984
 2131.53430849 3291.84949675 2999.8120145  3040.88474923 1285.56262455]
total_rewards_mean           2319.2376416254237
total_rewards_std            1089.0071260910913
total_rewards_max            3291.8494967490096
total_rewards_min            139.5150453016538
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               34.16080040577799
(Previous) Eval Time (s)     21.828072960022837
Sample Time (s)              26.251548753120005
Epoch Time (s)               82.24042211892083
Total Train Time (s)         29047.611494585406
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:50:28.962826 UTC | [2020_01_10_11_46_20] Iteration #326 | Epoch Duration: 88.54142093658447
2020-01-10 19:50:28.963076 UTC | [2020_01_10_11_46_20] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0583646
Z variance train             0.012650964
KL Divergence                24.84804
KL Loss                      2.484804
QF Loss                      3253.7642
VF Loss                      94.287254
Policy Loss                  -1110.7473
Q Predictions Mean           1111.8699
Q Predictions Std            229.92781
Q Predictions Max            1319.4476
Q Predictions Min            5.357835
V Predictions Mean           1112.8483
V Predictions Std            228.48094
V Predictions Max            1310.5015
V Predictions Min            12.955042
Log Pis Mean                 -0.4225543
Log Pis Std                  2.720331
Log Pis Max                  8.209934
Log Pis Min                  -11.604749
Policy mu Mean               0.084052846
Policy mu Std                0.59519625
Policy mu Max                2.6964107
Policy mu Min                -2.0547583
Policy log std Mean          -0.9377303
Policy log std Std           0.2601166
Policy log std Max           -0.20346802
Policy log std Min           -2.3373587
Z mean eval                  1.0432259
Z variance eval              0.015054835
total_rewards                [ 284.62691357  235.05588384  180.69277432 2274.73400174 1196.95186231
 2914.69046658  336.90933965 3009.42701725   93.21223146  770.32661654]
total_rewards_mean           1129.6627107254458
total_rewards_std            1108.2560522710169
total_rewards_max            3009.4270172494353
total_rewards_min            93.2122314586774
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               33.656233387067914
(Previous) Eval Time (s)     28.128729599993676
Sample Time (s)              25.517079181969166
Epoch Time (s)               87.30204216903076
Total Train Time (s)         29122.326285534073
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:51:43.681162 UTC | [2020_01_10_11_46_20] Iteration #327 | Epoch Duration: 74.71794080734253
2020-01-10 19:51:43.681348 UTC | [2020_01_10_11_46_20] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0447484
Z variance train             0.015021244
KL Divergence                24.692434
KL Loss                      2.4692435
QF Loss                      548.44653
VF Loss                      125.61956
Policy Loss                  -1106.8264
Q Predictions Mean           1106.6141
Q Predictions Std            229.53288
Q Predictions Max            1306.7415
Q Predictions Min            19.819153
V Predictions Mean           1103.0115
V Predictions Std            227.17336
V Predictions Max            1287.2367
V Predictions Min            16.063694
Log Pis Mean                 -0.33694494
Log Pis Std                  2.5975215
Log Pis Max                  15.862568
Log Pis Min                  -7.9177732
Policy mu Mean               0.0143415425
Policy mu Std                0.59779793
Policy mu Max                2.5868537
Policy mu Min                -2.2763064
Policy log std Mean          -0.9557871
Policy log std Std           0.24484909
Policy log std Max           -0.15316504
Policy log std Min           -1.8851727
Z mean eval                  1.0473964
Z variance eval              0.014428447
total_rewards                [2900.9050139   482.43814862  305.39657497 3099.14579483 2980.10586491
 3085.7461013   630.12775395 3023.80254217 2976.88318143 3253.24099336]
total_rewards_mean           2273.779196944327
total_rewards_std            1184.650287334567
total_rewards_max            3253.240993358519
total_rewards_min            305.3965749730856
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               34.18968162685633
(Previous) Eval Time (s)     15.544304230250418
Sample Time (s)              25.35300664929673
Epoch Time (s)               75.08699250640348
Total Train Time (s)         29211.771199710667
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:53:13.129711 UTC | [2020_01_10_11_46_20] Iteration #328 | Epoch Duration: 89.44823408126831
2020-01-10 19:53:13.129909 UTC | [2020_01_10_11_46_20] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0476913
Z variance train             0.014414725
KL Divergence                24.493378
KL Loss                      2.4493377
QF Loss                      2403.2756
VF Loss                      138.36693
Policy Loss                  -1130.7056
Q Predictions Mean           1130.6864
Q Predictions Std            215.38878
Q Predictions Max            1337.9528
Q Predictions Min            36.180267
V Predictions Mean           1130.5774
V Predictions Std            214.93301
V Predictions Max            1333.1787
V Predictions Min            12.495739
Log Pis Mean                 -0.3134469
Log Pis Std                  2.7880409
Log Pis Max                  23.727686
Log Pis Min                  -8.946016
Policy mu Mean               0.0076442976
Policy mu Std                0.59015423
Policy mu Max                3.510612
Policy mu Min                -2.5627105
Policy log std Mean          -0.96564317
Policy log std Std           0.2587803
Policy log std Max           -0.14389712
Policy log std Min           -2.3086705
Z mean eval                  1.049155
Z variance eval              0.018252078
total_rewards                [ -36.0668552   362.66863937 2983.28109143 3091.40263085 2846.51524289
 3114.35862306 2014.11930054 2873.29042462 3413.34856677  472.20045968]
total_rewards_mean           2113.5118124003297
total_rewards_std            1261.2897620851916
total_rewards_max            3413.348566769484
total_rewards_min            -36.0668552001236
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               33.62727566668764
(Previous) Eval Time (s)     29.905208490788937
Sample Time (s)              26.415803232695907
Epoch Time (s)               89.94828739017248
Total Train Time (s)         29299.381515855435
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:54:40.743540 UTC | [2020_01_10_11_46_20] Iteration #329 | Epoch Duration: 87.61350297927856
2020-01-10 19:54:40.743712 UTC | [2020_01_10_11_46_20] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0507288
Z variance train             0.018357866
KL Divergence                24.207344
KL Loss                      2.4207344
QF Loss                      855.86035
VF Loss                      555.6165
Policy Loss                  -1106.7627
Q Predictions Mean           1106.9568
Q Predictions Std            250.02429
Q Predictions Max            1290.9303
Q Predictions Min            14.594742
V Predictions Mean           1112.5386
V Predictions Std            252.62776
V Predictions Max            1302.7637
V Predictions Min            29.813948
Log Pis Mean                 -0.13095167
Log Pis Std                  2.985979
Log Pis Max                  15.724059
Log Pis Min                  -8.332558
Policy mu Mean               0.026093666
Policy mu Std                0.59963655
Policy mu Max                3.594707
Policy mu Min                -1.8769729
Policy log std Mean          -0.996979
Policy log std Std           0.31911004
Policy log std Max           -0.24940899
Policy log std Min           -2.8133175
Z mean eval                  1.0566679
Z variance eval              0.015104426
total_rewards                [2960.37793796 1018.40999454  697.3737387  3400.47287941  931.50512007
 2200.71045516  946.73529498 3108.17681219 1574.91784593 3247.37718784]
total_rewards_mean           2008.6057266774199
total_rewards_std            1039.1966448851979
total_rewards_max            3400.472879406585
total_rewards_min            697.373738702749
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               34.03759472211823
(Previous) Eval Time (s)     27.570036041084677
Sample Time (s)              25.18508590152487
Epoch Time (s)               86.79271666472778
Total Train Time (s)         29381.502899525687
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:02.868560 UTC | [2020_01_10_11_46_20] Iteration #330 | Epoch Duration: 82.12471580505371
2020-01-10 19:56:02.868745 UTC | [2020_01_10_11_46_20] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0589736
Z variance train             0.015033563
KL Divergence                24.283865
KL Loss                      2.4283864
QF Loss                      1908.3225
VF Loss                      136.66293
Policy Loss                  -1112.5326
Q Predictions Mean           1110.4631
Q Predictions Std            257.6585
Q Predictions Max            1329.6644
Q Predictions Min            95.11573
V Predictions Mean           1107.2524
V Predictions Std            251.83675
V Predictions Max            1308.235
V Predictions Min            95.113655
Log Pis Mean                 -0.11493869
Log Pis Std                  2.9546525
Log Pis Max                  10.240366
Log Pis Min                  -9.150832
Policy mu Mean               0.078293204
Policy mu Std                0.61886567
Policy mu Max                2.4896283
Policy mu Min                -1.9556382
Policy log std Mean          -0.96263397
Policy log std Std           0.28170785
Policy log std Max           -0.24390754
Policy log std Min           -2.583125
Z mean eval                  1.0689508
Z variance eval              0.012241488
total_rewards                [1120.2720599   686.46263753 2989.46743292 3118.16831559 2970.41034885
  439.61732774 1073.04505172  934.09190062  470.47538631 1424.57360739]
total_rewards_mean           1522.65840685646
total_rewards_std            1024.3317249447757
total_rewards_max            3118.1683155898218
total_rewards_min            439.6173277372783
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               33.40355573268607
(Previous) Eval Time (s)     22.901729995850474
Sample Time (s)              25.97687189048156
Epoch Time (s)               82.28215761901811
Total Train Time (s)         29459.760549605824
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:57:21.131348 UTC | [2020_01_10_11_46_20] Iteration #331 | Epoch Duration: 78.26243138313293
2020-01-10 19:57:21.131641 UTC | [2020_01_10_11_46_20] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0733428
Z variance train             0.012227273
KL Divergence                24.567295
KL Loss                      2.4567297
QF Loss                      2496.9924
VF Loss                      724.93
Policy Loss                  -1134.2987
Q Predictions Mean           1134.5127
Q Predictions Std            218.6635
Q Predictions Max            1324.41
Q Predictions Min            31.84345
V Predictions Mean           1128.7504
V Predictions Std            220.9515
V Predictions Max            1338.2765
V Predictions Min            16.198154
Log Pis Mean                 -0.27411717
Log Pis Std                  2.6011136
Log Pis Max                  8.398345
Log Pis Min                  -10.113779
Policy mu Mean               0.055415466
Policy mu Std                0.60412264
Policy mu Max                2.4352589
Policy mu Min                -2.575939
Policy log std Mean          -0.9681258
Policy log std Std           0.2655269
Policy log std Max           0.24430531
Policy log std Min           -2.0463321
Z mean eval                  1.0477096
Z variance eval              0.017028367
total_rewards                [ 840.845869   1633.58922172  664.10032002  167.57976536  364.27085068
  330.4876678  3280.11439086  499.19321673 3162.23902148 2663.91823543]
total_rewards_mean           1360.6338559079143
total_rewards_std            1169.5288993928068
total_rewards_max            3280.114390861872
total_rewards_min            167.57976535745874
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               33.35094487527385
(Previous) Eval Time (s)     18.881539694964886
Sample Time (s)              25.71340220514685
Epoch Time (s)               77.94588677538559
Total Train Time (s)         29536.348443524446
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:58:37.722246 UTC | [2020_01_10_11_46_20] Iteration #332 | Epoch Duration: 76.59044814109802
2020-01-10 19:58:37.722416 UTC | [2020_01_10_11_46_20] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0485622
Z variance train             0.01701063
KL Divergence                23.511585
KL Loss                      2.3511586
QF Loss                      699.97296
VF Loss                      225.75687
Policy Loss                  -1133.2598
Q Predictions Mean           1132.8928
Q Predictions Std            216.02391
Q Predictions Max            1316.0814
Q Predictions Min            -16.021412
V Predictions Mean           1128.066
V Predictions Std            216.30133
V Predictions Max            1307.4148
V Predictions Min            -21.324375
Log Pis Mean                 -0.07604347
Log Pis Std                  3.0287223
Log Pis Max                  13.740835
Log Pis Min                  -7.4577427
Policy mu Mean               0.059996594
Policy mu Std                0.60509104
Policy mu Max                2.4852822
Policy mu Min                -2.8540418
Policy log std Mean          -0.98021066
Policy log std Std           0.2771457
Policy log std Max           0.50239444
Policy log std Min           -1.9664453
Z mean eval                  1.0445907
Z variance eval              0.019746562
total_rewards                [ -21.33316529 3056.34986555 2970.20713404 1197.49266412 3183.31612723
 1750.91165762 2653.49320658 2921.86815058  759.78719016 1082.36852524]
total_rewards_mean           1955.446135582183
total_rewards_std            1090.2515258803637
total_rewards_max            3183.3161272286275
total_rewards_min            -21.33316529413543
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               33.494698502123356
(Previous) Eval Time (s)     17.525808761361986
Sample Time (s)              25.374643698800355
Epoch Time (s)               76.3951509622857
Total Train Time (s)         29618.71914960025
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:00:00.096564 UTC | [2020_01_10_11_46_20] Iteration #333 | Epoch Duration: 82.37402415275574
2020-01-10 20:00:00.096743 UTC | [2020_01_10_11_46_20] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.043864
Z variance train             0.019723142
KL Divergence                23.497374
KL Loss                      2.3497374
QF Loss                      1215.0886
VF Loss                      151.16594
Policy Loss                  -1130.8878
Q Predictions Mean           1127.3884
Q Predictions Std            219.31424
Q Predictions Max            1316.4208
Q Predictions Min            140.91536
V Predictions Mean           1125.5198
V Predictions Std            219.70059
V Predictions Max            1315.9468
V Predictions Min            132.34155
Log Pis Mean                 -0.40630567
Log Pis Std                  2.7917266
Log Pis Max                  12.575277
Log Pis Min                  -6.658536
Policy mu Mean               -0.00162931
Policy mu Std                0.6032764
Policy mu Max                3.0297701
Policy mu Min                -2.2750053
Policy log std Mean          -0.9562715
Policy log std Std           0.2657422
Policy log std Max           -0.19475996
Policy log std Min           -2.4763205
Z mean eval                  1.0489115
Z variance eval              0.014310179
total_rewards                [3031.66896282  587.79733157 3219.70368768 3107.33545865 3341.52920818
 3147.29488635 2903.64743999 3176.70313894 3106.41554132   42.12805779]
total_rewards_mean           2566.422371329209
total_rewards_std            1137.4882917944199
total_rewards_max            3341.529208176051
total_rewards_min            42.128057786145085
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               33.10672013415024
(Previous) Eval Time (s)     23.50430261902511
Sample Time (s)              26.02298722276464
Epoch Time (s)               82.63400997593999
Total Train Time (s)         29705.887730246875
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:01:27.272332 UTC | [2020_01_10_11_46_20] Iteration #334 | Epoch Duration: 87.17543435096741
2020-01-10 20:01:27.272608 UTC | [2020_01_10_11_46_20] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487187
Z variance train             0.014313893
KL Divergence                24.550228
KL Loss                      2.4550228
QF Loss                      650.2372
VF Loss                      137.52658
Policy Loss                  -1148.5829
Q Predictions Mean           1146.9807
Q Predictions Std            193.52374
Q Predictions Max            1348.9464
Q Predictions Min            104.06043
V Predictions Mean           1142.9805
V Predictions Std            192.43657
V Predictions Max            1347.2386
V Predictions Min            101.52477
Log Pis Mean                 -0.10403503
Log Pis Std                  2.5558422
Log Pis Max                  10.311451
Log Pis Min                  -7.3813624
Policy mu Mean               -0.01833734
Policy mu Std                0.62585884
Policy mu Max                2.1998942
Policy mu Min                -2.370435
Policy log std Mean          -0.9363082
Policy log std Std           0.25272933
Policy log std Max           -0.13906783
Policy log std Min           -2.5820713
Z mean eval                  1.0571281
Z variance eval              0.014834577
total_rewards                [3044.3979316  2089.84416671 2945.85075419 2060.28978116 3087.85859883
 3241.93725243 1846.68425143 3231.73470148 3058.60273479 3073.11865761]
total_rewards_mean           2768.0318830232372
total_rewards_std            513.5291378634573
total_rewards_max            3241.9372524296873
total_rewards_min            1846.684251432822
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               33.79426114121452
(Previous) Eval Time (s)     28.045374311041087
Sample Time (s)              25.8683043285273
Epoch Time (s)               87.70793978078291
Total Train Time (s)         29796.080318599008
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:02:57.468587 UTC | [2020_01_10_11_46_20] Iteration #335 | Epoch Duration: 90.19578695297241
2020-01-10 20:02:57.468772 UTC | [2020_01_10_11_46_20] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0568357
Z variance train             0.014860228
KL Divergence                24.05403
KL Loss                      2.405403
QF Loss                      1361.2952
VF Loss                      172.84285
Policy Loss                  -1126.3911
Q Predictions Mean           1127.4403
Q Predictions Std            253.70967
Q Predictions Max            1321.097
Q Predictions Min            -17.066082
V Predictions Mean           1132.5261
V Predictions Std            253.87675
V Predictions Max            1329.5828
V Predictions Min            -42.35401
Log Pis Mean                 0.08335145
Log Pis Std                  2.9062822
Log Pis Max                  17.690506
Log Pis Min                  -6.4281864
Policy mu Mean               0.040572073
Policy mu Std                0.61734354
Policy mu Max                2.3310955
Policy mu Min                -2.4973485
Policy log std Mean          -0.99395305
Policy log std Std           0.30680478
Policy log std Max           -0.16688848
Policy log std Min           -2.9291906
Z mean eval                  1.0723084
Z variance eval              0.01491183
total_rewards                [ 408.94912277 1373.16815453 3316.90947503 3376.88051208 3087.73791208
 3395.00330434 3340.21944062 3196.88610376 3288.41255242 1009.00560496]
total_rewards_mean           2579.3172182585904
total_rewards_std            1104.460793683076
total_rewards_max            3395.0033043424437
total_rewards_min            408.9491227652244
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               33.62797860102728
(Previous) Eval Time (s)     30.532851188909262
Sample Time (s)              26.37556412164122
Epoch Time (s)               90.53639391157776
Total Train Time (s)         29884.72314476967
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:04:26.115393 UTC | [2020_01_10_11_46_20] Iteration #336 | Epoch Duration: 88.64648962020874
2020-01-10 20:04:26.115573 UTC | [2020_01_10_11_46_20] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0713849
Z variance train             0.014931726
KL Divergence                24.257187
KL Loss                      2.4257188
QF Loss                      1194.7698
VF Loss                      443.35486
Policy Loss                  -1111.3286
Q Predictions Mean           1111.55
Q Predictions Std            266.16885
Q Predictions Max            1302.4147
Q Predictions Min            -2.4961696
V Predictions Mean           1111.593
V Predictions Std            268.06296
V Predictions Max            1300.6038
V Predictions Min            21.882261
Log Pis Mean                 -0.28978482
Log Pis Std                  3.2957654
Log Pis Max                  15.388416
Log Pis Min                  -11.1505165
Policy mu Mean               0.027480181
Policy mu Std                0.6277532
Policy mu Max                3.400083
Policy mu Min                -4.9558334
Policy log std Mean          -0.96198046
Policy log std Std           0.32775536
Policy log std Max           -0.13239062
Policy log std Min           -2.857794
Z mean eval                  1.0410324
Z variance eval              0.015339127
total_rewards                [3316.44453498 3297.34850403  368.5148811  3401.80013035 3312.62741434
 3175.27351991 3157.28256287  470.80099109 1067.74297507 1147.05140784]
total_rewards_mean           2271.4886921572825
total_rewards_std            1252.3777836400207
total_rewards_max            3401.8001303504016
total_rewards_min            368.51488110289745
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               35.410611658822745
(Previous) Eval Time (s)     28.64258584473282
Sample Time (s)              25.369399702642113
Epoch Time (s)               89.42259720619768
Total Train Time (s)         29973.012325998396
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:05:54.408282 UTC | [2020_01_10_11_46_20] Iteration #337 | Epoch Duration: 88.29257488250732
2020-01-10 20:05:54.408478 UTC | [2020_01_10_11_46_20] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0383226
Z variance train             0.015339267
KL Divergence                23.882576
KL Loss                      2.3882577
QF Loss                      1205.4707
VF Loss                      667.54175
Policy Loss                  -1130.1154
Q Predictions Mean           1131.3387
Q Predictions Std            223.35797
Q Predictions Max            1333.4113
Q Predictions Min            24.124102
V Predictions Mean           1137.0491
V Predictions Std            227.46655
V Predictions Max            1315.0972
V Predictions Min            17.395512
Log Pis Mean                 -0.42078996
Log Pis Std                  2.5396821
Log Pis Max                  12.307825
Log Pis Min                  -8.12011
Policy mu Mean               0.03130822
Policy mu Std                0.56754804
Policy mu Max                2.161656
Policy mu Min                -1.9016638
Policy log std Mean          -0.97044176
Policy log std Std           0.2777963
Policy log std Max           -0.04609257
Policy log std Min           -2.7900424
Z mean eval                  1.035779
Z variance eval              0.014805758
total_rewards                [3000.24166381 1800.65802133 3271.71410931  601.50348032 3221.4095737
 3002.58803545  610.39912692 3199.71412572 3054.30416586 2947.80615299]
total_rewards_mean           2471.0338455403867
total_rewards_std            1013.4970907061409
total_rewards_max            3271.714109309521
total_rewards_min            601.5034803158887
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               35.685493021737784
(Previous) Eval Time (s)     27.51218867022544
Sample Time (s)              26.12678088620305
Epoch Time (s)               89.32446257816628
Total Train Time (s)         30066.740416331682
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:07:28.141780 UTC | [2020_01_10_11_46_20] Iteration #338 | Epoch Duration: 93.73311471939087
2020-01-10 20:07:28.142229 UTC | [2020_01_10_11_46_20] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0347912
Z variance train             0.014814663
KL Divergence                24.35364
KL Loss                      2.435364
QF Loss                      568.7346
VF Loss                      106.58662
Policy Loss                  -1166.8928
Q Predictions Mean           1163.5875
Q Predictions Std            192.36604
Q Predictions Max            1308.3606
Q Predictions Min            27.781616
V Predictions Mean           1164.3508
V Predictions Std            190.82501
V Predictions Max            1308.7045
V Predictions Min            24.689001
Log Pis Mean                 -0.12594573
Log Pis Std                  2.6672559
Log Pis Max                  9.454349
Log Pis Min                  -7.8623705
Policy mu Mean               0.043678258
Policy mu Std                0.63385314
Policy mu Max                3.2618387
Policy mu Min                -2.2321925
Policy log std Mean          -0.9581021
Policy log std Std           0.24666442
Policy log std Max           -0.1891548
Policy log std Min           -2.1095095
Z mean eval                  1.0609201
Z variance eval              0.013362208
total_rewards                [2695.97150702 2054.3438774  1798.65637601 3070.57126291 2324.43656543
  438.27101734 3019.38065655 2575.63954034 3179.71153066 1144.03975504]
total_rewards_mean           2230.1022088700875
total_rewards_std            847.5649210747204
total_rewards_max            3179.7115306608425
total_rewards_min            438.2710173378523
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               37.057961259037256
(Previous) Eval Time (s)     31.920461581088603
Sample Time (s)              26.71084238216281
Epoch Time (s)               95.68926522228867
Total Train Time (s)         30157.427158752922
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:08:58.832337 UTC | [2020_01_10_11_46_20] Iteration #339 | Epoch Duration: 90.68973302841187
2020-01-10 20:08:58.832654 UTC | [2020_01_10_11_46_20] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0591139
Z variance train             0.013414262
KL Divergence                24.477262
KL Loss                      2.4477262
QF Loss                      1580.4258
VF Loss                      372.69067
Policy Loss                  -1149.4662
Q Predictions Mean           1151.9535
Q Predictions Std            225.0821
Q Predictions Max            1404.69
Q Predictions Min            22.514732
V Predictions Mean           1157.6047
V Predictions Std            227.69225
V Predictions Max            1378.8857
V Predictions Min            7.8406086
Log Pis Mean                 -0.41561377
Log Pis Std                  2.5490968
Log Pis Max                  13.766553
Log Pis Min                  -9.398883
Policy mu Mean               0.059312016
Policy mu Std                0.58435273
Policy mu Max                2.3620892
Policy mu Min                -2.0116944
Policy log std Mean          -0.9394026
Policy log std Std           0.2445555
Policy log std Max           -0.056974232
Policy log std Min           -1.8362834
Z mean eval                  1.0749316
Z variance eval              0.015451908
total_rewards                [3071.28168524 1387.82195827 1706.05942105 3118.5343687  3021.62888349
  304.46216251 3273.4402944  1248.54382254 3085.2801047  3176.93276189]
total_rewards_mean           2339.39854627924
total_rewards_std            1018.6229530733489
total_rewards_max            3273.440294395551
total_rewards_min            304.462162511256
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               35.86644565826282
(Previous) Eval Time (s)     26.920532342977822
Sample Time (s)              26.14873771602288
Epoch Time (s)               88.93571571726352
Total Train Time (s)         30250.49453593092
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:10:31.903992 UTC | [2020_01_10_11_46_20] Iteration #340 | Epoch Duration: 93.07115840911865
2020-01-10 20:10:31.904272 UTC | [2020_01_10_11_46_20] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.076902
Z variance train             0.015436175
KL Divergence                23.21675
KL Loss                      2.321675
QF Loss                      7068.9443
VF Loss                      178.19536
Policy Loss                  -1129.1125
Q Predictions Mean           1128.648
Q Predictions Std            279.39822
Q Predictions Max            1357.0122
Q Predictions Min            -0.40065265
V Predictions Mean           1123.2031
V Predictions Std            281.27588
V Predictions Max            1349.6671
V Predictions Min            -4.788397
Log Pis Mean                 -0.4903722
Log Pis Std                  2.5826654
Log Pis Max                  11.887934
Log Pis Min                  -6.427859
Policy mu Mean               -0.04012295
Policy mu Std                0.58186775
Policy mu Max                2.208601
Policy mu Min                -2.8389635
Policy log std Mean          -0.94900405
Policy log std Std           0.28484958
Policy log std Max           0.061805487
Policy log std Min           -2.405488
Z mean eval                  1.0556443
Z variance eval              0.01257561
total_rewards                [3044.56237724  375.68176118 2266.82516022 3155.58219022    6.20753027
  731.74994362 1452.20861672   54.46364542 3053.61429079 2922.46193907]
total_rewards_mean           1706.3357454746715
total_rewards_std            1261.0944472469048
total_rewards_max            3155.5821902165735
total_rewards_min            6.207530270803567
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               36.61634197598323
(Previous) Eval Time (s)     31.05560657987371
Sample Time (s)              27.60538387717679
Epoch Time (s)               95.27733243303373
Total Train Time (s)         30341.477063729428
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:12:02.889404 UTC | [2020_01_10_11_46_20] Iteration #341 | Epoch Duration: 90.9849419593811
2020-01-10 20:12:02.889619 UTC | [2020_01_10_11_46_20] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0535166
Z variance train             0.0125819715
KL Divergence                24.200989
KL Loss                      2.420099
QF Loss                      524.0449
VF Loss                      175.32922
Policy Loss                  -1172.8828
Q Predictions Mean           1173.0948
Q Predictions Std            165.6575
Q Predictions Max            1373.2949
Q Predictions Min            52.59879
V Predictions Mean           1178.0782
V Predictions Std            164.45462
V Predictions Max            1375.7332
V Predictions Min            58.475662
Log Pis Mean                 -0.41093838
Log Pis Std                  2.7625005
Log Pis Max                  8.630009
Log Pis Min                  -10.198547
Policy mu Mean               0.05136393
Policy mu Std                0.6134466
Policy mu Max                2.2580245
Policy mu Min                -2.0502264
Policy log std Mean          -0.92215085
Policy log std Std           0.25748795
Policy log std Max           -0.084101796
Policy log std Min           -2.9909205
Z mean eval                  1.0733287
Z variance eval              0.010709862
total_rewards                [3015.66060178  689.16719909 3087.63594375 3029.44193896 2113.30985057
 1328.63632395  710.26362254 3100.75128805  236.38914029 3068.05243864]
total_rewards_mean           2037.9308347620663
total_rewards_std            1121.0649028910013
total_rewards_max            3100.751288051408
total_rewards_min            236.3891402899888
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               35.74882940715179
(Previous) Eval Time (s)     26.76284244004637
Sample Time (s)              26.16414031945169
Epoch Time (s)               88.67581216664985
Total Train Time (s)         30432.159333206713
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:13:33.576750 UTC | [2020_01_10_11_46_20] Iteration #342 | Epoch Duration: 90.68692278862
2020-01-10 20:13:33.577042 UTC | [2020_01_10_11_46_20] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0714831
Z variance train             0.0106904255
KL Divergence                24.301834
KL Loss                      2.4301834
QF Loss                      444.69797
VF Loss                      149.74554
Policy Loss                  -1163.2648
Q Predictions Mean           1165.2959
Q Predictions Std            216.6423
Q Predictions Max            1350.6448
Q Predictions Min            -9.170752
V Predictions Mean           1168.5493
V Predictions Std            213.00499
V Predictions Max            1341.6326
V Predictions Min            3.9407904
Log Pis Mean                 -0.15321107
Log Pis Std                  2.6303666
Log Pis Max                  9.074274
Log Pis Min                  -10.978348
Policy mu Mean               0.031299982
Policy mu Std                0.6077334
Policy mu Max                2.2451417
Policy mu Min                -1.9392335
Policy log std Mean          -0.93559897
Policy log std Std           0.26509848
Policy log std Max           -0.16988772
Policy log std Min           -2.381292
Z mean eval                  1.0533402
Z variance eval              0.011970614
total_rewards                [3105.21795792 3112.86525699 2208.17683877 1803.16883449 1900.73534956
 1219.08372256  127.48734656 3055.49677534  676.48731377 3179.03592842]
total_rewards_mean           2038.7755324381637
total_rewards_std            1044.4564535607262
total_rewards_max            3179.0359284189544
total_rewards_min            127.48734655935817
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               36.45844185585156
(Previous) Eval Time (s)     28.773529816884547
Sample Time (s)              25.770521487575024
Epoch Time (s)               91.00249316031113
Total Train Time (s)         30520.17409471469
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:15:01.594783 UTC | [2020_01_10_11_46_20] Iteration #343 | Epoch Duration: 88.01758527755737
2020-01-10 20:15:01.594995 UTC | [2020_01_10_11_46_20] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0522102
Z variance train             0.011989723
KL Divergence                24.721367
KL Loss                      2.4721367
QF Loss                      613.91016
VF Loss                      137.60027
Policy Loss                  -1170.4976
Q Predictions Mean           1172.5713
Q Predictions Std            208.30344
Q Predictions Max            1346.6042
Q Predictions Min            -9.469241
V Predictions Mean           1167.5945
V Predictions Std            207.41933
V Predictions Max            1326.5045
V Predictions Min            5.0284486
Log Pis Mean                 -0.21987793
Log Pis Std                  3.0029309
Log Pis Max                  13.957124
Log Pis Min                  -8.775311
Policy mu Mean               0.073750846
Policy mu Std                0.6438086
Policy mu Max                3.6873658
Policy mu Min                -2.3855758
Policy log std Mean          -0.9591559
Policy log std Std           0.25142908
Policy log std Max           -0.25468922
Policy log std Min           -2.2427053
Z mean eval                  1.0797975
Z variance eval              0.011069799
total_rewards                [ -26.32352541 -111.16105214 2903.44079119 3029.257361   3058.78815788
 2829.169191   2884.03167035 1145.47329129 2975.94749784 1424.32333367]
total_rewards_mean           2011.294671668599
total_rewards_std            1226.4357807610238
total_rewards_max            3058.788157884556
total_rewards_min            -111.16105213562508
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               36.555913518648595
(Previous) Eval Time (s)     25.788206957746297
Sample Time (s)              26.574592739343643
Epoch Time (s)               88.91871321573853
Total Train Time (s)         30611.087500350084
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:16:32.513720 UTC | [2020_01_10_11_46_20] Iteration #344 | Epoch Duration: 90.91856956481934
2020-01-10 20:16:32.513928 UTC | [2020_01_10_11_46_20] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0792053
Z variance train             0.011058142
KL Divergence                24.779501
KL Loss                      2.47795
QF Loss                      1384.3289
VF Loss                      195.17618
Policy Loss                  -1131.3013
Q Predictions Mean           1131.7764
Q Predictions Std            264.8604
Q Predictions Max            1369.1635
Q Predictions Min            13.64634
V Predictions Mean           1126.9271
V Predictions Std            264.31198
V Predictions Max            1356.975
V Predictions Min            12.767878
Log Pis Mean                 -0.061031736
Log Pis Std                  2.8955412
Log Pis Max                  11.678882
Log Pis Min                  -6.116633
Policy mu Mean               -0.0013328844
Policy mu Std                0.6043023
Policy mu Max                2.067367
Policy mu Min                -2.4575691
Policy log std Mean          -0.9672257
Policy log std Std           0.26985297
Policy log std Max           -0.12331343
Policy log std Min           -2.7697752
Z mean eval                  1.0519216
Z variance eval              0.011768292
total_rewards                [1688.53571347  116.2253219  2664.70966937 3165.27352808  980.79370943
 3564.49189152  502.79060043 3064.15860417 3267.47093753 2114.98243802]
total_rewards_mean           2112.943241393799
total_rewards_std            1174.6465861077547
total_rewards_max            3564.4918915241715
total_rewards_min            116.2253219038017
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               36.22483533900231
(Previous) Eval Time (s)     27.787636660039425
Sample Time (s)              26.007341222837567
Epoch Time (s)               90.0198132218793
Total Train Time (s)         30702.734097679146
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:18:04.163899 UTC | [2020_01_10_11_46_20] Iteration #345 | Epoch Duration: 91.64978861808777
2020-01-10 20:18:04.164292 UTC | [2020_01_10_11_46_20] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0533764
Z variance train             0.01175239
KL Divergence                24.840153
KL Loss                      2.4840152
QF Loss                      698.63275
VF Loss                      183.1121
Policy Loss                  -1159.4283
Q Predictions Mean           1160.0104
Q Predictions Std            208.60893
Q Predictions Max            1319.8252
Q Predictions Min            17.848186
V Predictions Mean           1151.4929
V Predictions Std            207.98392
V Predictions Max            1308.6936
V Predictions Min            8.761555
Log Pis Mean                 -0.24982937
Log Pis Std                  2.5763311
Log Pis Max                  7.1314435
Log Pis Min                  -7.3743005
Policy mu Mean               0.021296674
Policy mu Std                0.59335434
Policy mu Max                2.024055
Policy mu Min                -1.9999897
Policy log std Mean          -0.98213744
Policy log std Std           0.24561812
Policy log std Max           -0.07326865
Policy log std Min           -1.9737437
Z mean eval                  1.0826721
Z variance eval              0.011856118
total_rewards                [1000.52051606  552.83607787 2807.71521636 1396.85248563 2483.09447501
 1575.74922193 3185.84542868 2609.857696     86.86235562  770.44411801]
total_rewards_mean           1646.9777591166119
total_rewards_std            1011.2672507032181
total_rewards_max            3185.845428683577
total_rewards_min            86.86235561960012
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               35.961579551920295
(Previous) Eval Time (s)     29.417202507145703
Sample Time (s)              26.72163642477244
Epoch Time (s)               92.10041848383844
Total Train Time (s)         30783.84440497961
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:19:25.278358 UTC | [2020_01_10_11_46_20] Iteration #346 | Epoch Duration: 81.11381363868713
2020-01-10 20:19:25.278570 UTC | [2020_01_10_11_46_20] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0832249
Z variance train             0.011858565
KL Divergence                24.28257
KL Loss                      2.428257
QF Loss                      3516.5261
VF Loss                      128.52869
Policy Loss                  -1176.1025
Q Predictions Mean           1176.5155
Q Predictions Std            182.5128
Q Predictions Max            1339.9542
Q Predictions Min            -12.964376
V Predictions Mean           1179.2472
V Predictions Std            180.44002
V Predictions Max            1326.1228
V Predictions Min            -15.10385
Log Pis Mean                 0.20840971
Log Pis Std                  2.5588865
Log Pis Max                  9.603031
Log Pis Min                  -8.668945
Policy mu Mean               0.017764729
Policy mu Std                0.62512666
Policy mu Max                2.7135727
Policy mu Min                -1.9700253
Policy log std Mean          -0.9850893
Policy log std Std           0.2606078
Policy log std Max           -0.046402454
Policy log std Min           -2.372317
Z mean eval                  1.0993955
Z variance eval              0.012135375
total_rewards                [3184.72645585 3190.70335106 3186.86001228 3149.32666876 3236.05235114
  592.10971354 3312.19616801 3228.16427925 3094.93079249  350.51084406]
total_rewards_mean           2652.5580636442705
total_rewards_std            1093.276457761571
total_rewards_max            3312.1961680140034
total_rewards_min            350.51084406481067
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               33.89073122991249
(Previous) Eval Time (s)     18.430197085253894
Sample Time (s)              25.32038858300075
Epoch Time (s)               77.64131689816713
Total Train Time (s)         30877.470476755407
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:20:58.909623 UTC | [2020_01_10_11_46_20] Iteration #347 | Epoch Duration: 93.6308171749115
2020-01-10 20:20:58.909948 UTC | [2020_01_10_11_46_20] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0951178
Z variance train             0.012182112
KL Divergence                24.310217
KL Loss                      2.4310217
QF Loss                      632.1537
VF Loss                      196.2231
Policy Loss                  -1154.2228
Q Predictions Mean           1155.6771
Q Predictions Std            233.44783
Q Predictions Max            1391.4869
Q Predictions Min            20.08324
V Predictions Mean           1159.6587
V Predictions Std            233.26402
V Predictions Max            1403.7039
V Predictions Min            26.213116
Log Pis Mean                 0.00033339858
Log Pis Std                  2.7156222
Log Pis Max                  16.020586
Log Pis Min                  -7.613368
Policy mu Mean               -0.052819256
Policy mu Std                0.6121035
Policy mu Max                3.028209
Policy mu Min                -1.8560449
Policy log std Mean          -0.97272205
Policy log std Std           0.27506635
Policy log std Max           -0.053846896
Policy log std Min           -2.8041096
Z mean eval                  1.0580271
Z variance eval              0.015687635
total_rewards                [2972.95282764 2849.53120186 1931.39367653 3167.76152269 3192.95830818
 3339.37833733 3130.16276859 2008.44076536 2899.17505932 2930.08510126]
total_rewards_mean           2842.1839568758983
total_rewards_std            459.56209216269224
total_rewards_max            3339.3783373338047
total_rewards_min            1931.3936765290855
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               33.79180827597156
(Previous) Eval Time (s)     34.41928095277399
Sample Time (s)              24.200557899661362
Epoch Time (s)               92.41164712840691
Total Train Time (s)         30967.602088612504
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:22:29.044542 UTC | [2020_01_10_11_46_20] Iteration #348 | Epoch Duration: 90.1344084739685
2020-01-10 20:22:29.044738 UTC | [2020_01_10_11_46_20] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0535382
Z variance train             0.01569722
KL Divergence                24.376806
KL Loss                      2.4376807
QF Loss                      838.45544
VF Loss                      210.60559
Policy Loss                  -1113.5646
Q Predictions Mean           1113.4628
Q Predictions Std            295.04645
Q Predictions Max            1335.0149
Q Predictions Min            -44.917118
V Predictions Mean           1117.8193
V Predictions Std            291.21802
V Predictions Max            1338.8422
V Predictions Min            -4.9212217
Log Pis Mean                 -0.34975797
Log Pis Std                  3.0330486
Log Pis Max                  12.1575165
Log Pis Min                  -8.139011
Policy mu Mean               0.063451156
Policy mu Std                0.58985096
Policy mu Max                2.5774603
Policy mu Min                -1.9755985
Policy log std Mean          -0.9681083
Policy log std Std           0.30357653
Policy log std Max           -0.2586313
Policy log std Min           -2.831121
Z mean eval                  1.0753945
Z variance eval              0.013865639
total_rewards                [3049.99350363 3071.2990406  2846.86641417 2894.63196189 3224.27118977
  941.17507749 3366.9017558  3183.77891063 3277.5265066    80.42091763]
total_rewards_mean           2593.6865278209966
total_rewards_std            1070.0299547210927
total_rewards_max            3366.901755797448
total_rewards_min            80.4209176291058
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               33.29726597806439
(Previous) Eval Time (s)     32.141794034745544
Sample Time (s)              25.1056361021474
Epoch Time (s)               90.54469611495733
Total Train Time (s)         31055.271660306957
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:23:56.718406 UTC | [2020_01_10_11_46_20] Iteration #349 | Epoch Duration: 87.67344045639038
2020-01-10 20:23:56.718705 UTC | [2020_01_10_11_46_20] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0757596
Z variance train             0.0138342725
KL Divergence                24.896757
KL Loss                      2.4896758
QF Loss                      1455.8071
VF Loss                      105.838326
Policy Loss                  -1120.2548
Q Predictions Mean           1120.002
Q Predictions Std            298.53354
Q Predictions Max            1341.7278
Q Predictions Min            -5.2031827
V Predictions Mean           1122.8759
V Predictions Std            297.9455
V Predictions Max            1348.2518
V Predictions Min            7.0915046
Log Pis Mean                 -0.026156113
Log Pis Std                  2.8536296
Log Pis Max                  10.931335
Log Pis Min                  -7.6160793
Policy mu Mean               -0.0031713955
Policy mu Std                0.6460887
Policy mu Max                2.666152
Policy mu Min                -2.594358
Policy log std Mean          -0.9464628
Policy log std Std           0.28396463
Policy log std Max           -0.08641362
Policy log std Min           -2.3861718
Z mean eval                  1.0988863
Z variance eval              0.021307625
total_rewards                [ 878.11266622 3168.19261805 1844.75937096 3258.41041946 1086.42181849
 3208.44901721 3109.56815154 3181.29410601 1271.90681896 3153.2630027 ]
total_rewards_mean           2416.0377989599237
total_rewards_std            963.4227379529979
total_rewards_max            3258.4104194640868
total_rewards_min            878.112666222108
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               33.60826674615964
(Previous) Eval Time (s)     29.270192297641188
Sample Time (s)              25.332531848922372
Epoch Time (s)               88.2109908927232
Total Train Time (s)         31143.27278111549
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:25:24.722792 UTC | [2020_01_10_11_46_20] Iteration #350 | Epoch Duration: 88.0039291381836
2020-01-10 20:25:24.723025 UTC | [2020_01_10_11_46_20] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.098706
Z variance train             0.021299917
KL Divergence                24.907204
KL Loss                      2.4907205
QF Loss                      1389.4585
VF Loss                      400.87546
Policy Loss                  -1155.1805
Q Predictions Mean           1153.4092
Q Predictions Std            218.2894
Q Predictions Max            1321.8046
Q Predictions Min            24.500658
V Predictions Mean           1155.9324
V Predictions Std            215.8871
V Predictions Max            1330.5013
V Predictions Min            19.97675
Log Pis Mean                 -0.17925416
Log Pis Std                  2.735132
Log Pis Max                  9.754106
Log Pis Min                  -7.15607
Policy mu Mean               -0.03765966
Policy mu Std                0.59118724
Policy mu Max                2.3613524
Policy mu Min                -2.0734613
Policy log std Mean          -0.96952033
Policy log std Std           0.2739898
Policy log std Max           -0.20613503
Policy log std Min           -2.5054533
Z mean eval                  1.0718402
Z variance eval              0.019745592
total_rewards                [3318.96945944 3455.78489835 1861.71710788 3193.42180177 3360.15510278
  356.88207397 3491.67520606   15.51409036 3206.78839086 3439.64637631]
total_rewards_mean           2570.055450776406
total_rewards_std            1276.510605843665
total_rewards_max            3491.6752060573126
total_rewards_min            15.51409035907713
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               33.949734115973115
(Previous) Eval Time (s)     29.06283475132659
Sample Time (s)              25.9244363643229
Epoch Time (s)               88.9370052316226
Total Train Time (s)         31228.952151148114
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:26:50.406687 UTC | [2020_01_10_11_46_20] Iteration #351 | Epoch Duration: 85.68351411819458
2020-01-10 20:26:50.406886 UTC | [2020_01_10_11_46_20] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0706717
Z variance train             0.019734597
KL Divergence                24.600115
KL Loss                      2.4600115
QF Loss                      671.42834
VF Loss                      260.39526
Policy Loss                  -1181.5134
Q Predictions Mean           1182.1005
Q Predictions Std            237.66696
Q Predictions Max            1400.6576
Q Predictions Min            -1.9673108
V Predictions Mean           1169.9424
V Predictions Std            235.21083
V Predictions Max            1381.4287
V Predictions Min            -1.163422
Log Pis Mean                 -0.33162716
Log Pis Std                  2.6534412
Log Pis Max                  7.1675506
Log Pis Min                  -7.1458073
Policy mu Mean               0.016173068
Policy mu Std                0.58081543
Policy mu Max                1.97933
Policy mu Min                -1.9663466
Policy log std Mean          -0.9736189
Policy log std Std           0.26408744
Policy log std Max           -0.124810934
Policy log std Min           -2.3257847
Z mean eval                  1.0833654
Z variance eval              0.016988082
total_rewards                [3052.94367068 2412.34650315 2779.75555277 3303.66861482 3072.0963373
 3191.33940459 3083.20538537 3083.86188578 1141.12132009  208.55419752]
total_rewards_mean           2532.8892872066244
total_rewards_std            980.3214750881504
total_rewards_max            3303.668614820679
total_rewards_min            208.5541975187919
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               33.581721984781325
(Previous) Eval Time (s)     25.80905710393563
Sample Time (s)              25.44712372822687
Epoch Time (s)               84.83790281694382
Total Train Time (s)         31316.796944877133
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:28:18.256027 UTC | [2020_01_10_11_46_20] Iteration #352 | Epoch Duration: 87.84900140762329
2020-01-10 20:28:18.256217 UTC | [2020_01_10_11_46_20] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0837982
Z variance train             0.0169227
KL Divergence                24.77058
KL Loss                      2.4770582
QF Loss                      1440.2949
VF Loss                      2421.6023
Policy Loss                  -1163.4574
Q Predictions Mean           1163.1063
Q Predictions Std            245.5107
Q Predictions Max            1389.318
Q Predictions Min            -27.747095
V Predictions Mean           1174.1204
V Predictions Std            231.4263
V Predictions Max            1397.1733
V Predictions Min            -6.944276
Log Pis Mean                 0.17370781
Log Pis Std                  2.891843
Log Pis Max                  18.82486
Log Pis Min                  -7.0758557
Policy mu Mean               0.024715796
Policy mu Std                0.6118172
Policy mu Max                3.8134234
Policy mu Min                -3.283392
Policy log std Mean          -0.9993441
Policy log std Std           0.28179413
Policy log std Max           0.88189363
Policy log std Min           -2.5038588
Z mean eval                  1.0902004
Z variance eval              0.01356263
total_rewards                [  95.65457716  106.81651368 1898.54967576 1272.15884746  329.27437939
 3176.48541883 2333.3657383  3144.84653327 3151.79029863 2527.66905827]
total_rewards_mean           1803.6611040746836
total_rewards_std            1206.960411977949
total_rewards_max            3176.485418828622
total_rewards_min            95.6545771647609
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               33.8026171727106
(Previous) Eval Time (s)     28.819774193689227
Sample Time (s)              24.24214225774631
Epoch Time (s)               86.86453362414613
Total Train Time (s)         31397.37021951191
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:29:38.832635 UTC | [2020_01_10_11_46_20] Iteration #353 | Epoch Duration: 80.57628917694092
2020-01-10 20:29:38.832806 UTC | [2020_01_10_11_46_20] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0895
Z variance train             0.013561343
KL Divergence                25.469803
KL Loss                      2.5469804
QF Loss                      401.33353
VF Loss                      92.70753
Policy Loss                  -1177.8527
Q Predictions Mean           1176.376
Q Predictions Std            262.1145
Q Predictions Max            1366.4071
Q Predictions Min            -46.308872
V Predictions Mean           1178.9268
V Predictions Std            261.531
V Predictions Max            1383.5465
V Predictions Min            -64.89719
Log Pis Mean                 -0.027456477
Log Pis Std                  2.7383013
Log Pis Max                  10.116548
Log Pis Min                  -6.874606
Policy mu Mean               0.058248032
Policy mu Std                0.60973126
Policy mu Max                2.8795462
Policy mu Min                -1.9556496
Policy log std Mean          -0.9380142
Policy log std Std           0.2644971
Policy log std Max           -0.22085863
Policy log std Min           -2.2597888
Z mean eval                  1.0482638
Z variance eval              0.010358562
total_rewards                [ 386.13831674 3410.08756696 2491.24256772 1043.03398379  162.36225123
 3225.39524305  293.13241901 3077.67891871  746.98162635 3284.5383895 ]
total_rewards_mean           1812.0591283057888
total_rewards_std            1325.525204974424
total_rewards_max            3410.0875669586753
total_rewards_min            162.3622512287724
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               34.084048592019826
(Previous) Eval Time (s)     22.531237267889082
Sample Time (s)              23.878438108600676
Epoch Time (s)               80.49372396850958
Total Train Time (s)         31476.07742181979
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:30:57.548062 UTC | [2020_01_10_11_46_20] Iteration #354 | Epoch Duration: 78.71513795852661
2020-01-10 20:30:57.548274 UTC | [2020_01_10_11_46_20] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0470401
Z variance train             0.010325706
KL Divergence                24.48022
KL Loss                      2.4480221
QF Loss                      630.379
VF Loss                      83.25532
Policy Loss                  -1151.1703
Q Predictions Mean           1149.7797
Q Predictions Std            269.85925
Q Predictions Max            1336.6991
Q Predictions Min            -29.822319
V Predictions Mean           1150.8894
V Predictions Std            269.77008
V Predictions Max            1338.0782
V Predictions Min            -3.1935208
Log Pis Mean                 -0.27880383
Log Pis Std                  2.6820664
Log Pis Max                  7.7406883
Log Pis Min                  -10.575627
Policy mu Mean               0.05429583
Policy mu Std                0.61045486
Policy mu Max                2.6230555
Policy mu Min                -1.8637663
Policy log std Mean          -0.9559207
Policy log std Std           0.26480493
Policy log std Max           -0.18652418
Policy log std Min           -2.0181515
Z mean eval                  1.0728611
Z variance eval              0.010286584
total_rewards                [3052.97560311 2917.32141648 2967.36494341 3172.2133341  3232.86890006
 3072.09689828  799.45413958 3183.92071608 3178.90663573 3123.96203385]
total_rewards_mean           2870.1084620673746
total_rewards_std            696.7550141140115
total_rewards_max            3232.8689000619074
total_rewards_min            799.4541395757428
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               33.9870447400026
(Previous) Eval Time (s)     20.75230368413031
Sample Time (s)              25.316248128656298
Epoch Time (s)               80.05559655278921
Total Train Time (s)         31566.887046266813
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:32:28.357838 UTC | [2020_01_10_11_46_20] Iteration #355 | Epoch Duration: 90.8093466758728
2020-01-10 20:32:28.358188 UTC | [2020_01_10_11_46_20] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0722773
Z variance train             0.010348409
KL Divergence                25.23592
KL Loss                      2.523592
QF Loss                      5041.225
VF Loss                      191.93752
Policy Loss                  -1183.2642
Q Predictions Mean           1184.085
Q Predictions Std            207.98434
Q Predictions Max            1396.8799
Q Predictions Min            -8.20136
V Predictions Mean           1179.2948
V Predictions Std            208.90367
V Predictions Max            1407.2788
V Predictions Min            5.162557
Log Pis Mean                 0.31175658
Log Pis Std                  2.9708605
Log Pis Max                  14.754896
Log Pis Min                  -6.7127895
Policy mu Mean               0.040332347
Policy mu Std                0.62831515
Policy mu Max                2.5371892
Policy mu Min                -2.2731864
Policy log std Mean          -0.9632636
Policy log std Std           0.284238
Policy log std Max           -0.11107063
Policy log std Min           -2.341438
Z mean eval                  1.0727044
Z variance eval              0.009969749
total_rewards                [ 138.72068446 2525.96213849 3310.92073836  106.91153012 3268.39834979
  177.36413627 3357.8825876   439.71687803 1210.86382556 3057.23991662]
total_rewards_mean           1759.3980785305826
total_rewards_std            1393.343378479022
total_rewards_max            3357.88258760315
total_rewards_min            106.91153012259949
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               34.32581011811271
(Previous) Eval Time (s)     31.505691785831004
Sample Time (s)              25.13586109317839
Epoch Time (s)               90.96736299712211
Total Train Time (s)         31645.31541487295
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:33:46.790161 UTC | [2020_01_10_11_46_20] Iteration #356 | Epoch Duration: 78.4317398071289
2020-01-10 20:33:46.790345 UTC | [2020_01_10_11_46_20] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0713267
Z variance train             0.009999717
KL Divergence                24.615911
KL Loss                      2.4615912
QF Loss                      825.01294
VF Loss                      383.14304
Policy Loss                  -1167.4429
Q Predictions Mean           1166.2251
Q Predictions Std            233.97636
Q Predictions Max            1372.2347
Q Predictions Min            -13.412947
V Predictions Mean           1171.868
V Predictions Std            226.6816
V Predictions Max            1379.5804
V Predictions Min            4.670528
Log Pis Mean                 -0.29788053
Log Pis Std                  2.914246
Log Pis Max                  16.888145
Log Pis Min                  -8.403241
Policy mu Mean               0.0018046293
Policy mu Std                0.61479807
Policy mu Max                3.1224463
Policy mu Min                -2.0815864
Policy log std Mean          -0.9507061
Policy log std Std           0.25385705
Policy log std Max           -0.09259713
Policy log std Min           -2.302436
Z mean eval                  1.0771583
Z variance eval              0.008579219
total_rewards                [3254.62086704  836.09645688 3202.49741575 3202.25378974 3333.15103162
  808.09009861 3443.04607616 3503.56942043 2687.17337472  984.515091  ]
total_rewards_mean           2525.5013621954436
total_rewards_std            1100.1410402438105
total_rewards_max            3503.5694204277606
total_rewards_min            808.0900986130291
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               33.83956183120608
(Previous) Eval Time (s)     18.969728847034276
Sample Time (s)              25.52417948283255
Epoch Time (s)               78.33347016107291
Total Train Time (s)         31731.59448799072
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:35:13.073157 UTC | [2020_01_10_11_46_20] Iteration #357 | Epoch Duration: 86.28267478942871
2020-01-10 20:35:13.073340 UTC | [2020_01_10_11_46_20] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0775093
Z variance train             0.008582714
KL Divergence                25.067543
KL Loss                      2.5067544
QF Loss                      1820.0234
VF Loss                      144.15761
Policy Loss                  -1190.3193
Q Predictions Mean           1192.1516
Q Predictions Std            198.51105
Q Predictions Max            1346.4515
Q Predictions Min            1.5673714
V Predictions Mean           1194.1201
V Predictions Std            200.73967
V Predictions Max            1345.211
V Predictions Min            0.055541158
Log Pis Mean                 -0.14566484
Log Pis Std                  2.7505424
Log Pis Max                  9.592585
Log Pis Min                  -8.546359
Policy mu Mean               0.07123271
Policy mu Std                0.59466356
Policy mu Max                2.5191042
Policy mu Min                -1.8399441
Policy log std Mean          -1.0045536
Policy log std Std           0.2519548
Policy log std Max           -0.12260324
Policy log std Min           -1.9156078
Z mean eval                  1.0555952
Z variance eval              0.010077127
total_rewards                [2389.31395918 3084.47822292 2738.13250782 2869.10350672 3175.24349117
 3140.55911718 3096.24581309 2505.94316783 3127.97223205 3222.46895115]
total_rewards_mean           2934.9460969109255
total_rewards_std            281.62994619070787
total_rewards_max            3222.4689511519646
total_rewards_min            2389.313959183387
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               33.711143067106605
(Previous) Eval Time (s)     26.91854569129646
Sample Time (s)              25.466258877888322
Epoch Time (s)               86.09594763629138
Total Train Time (s)         31823.24225567002
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:36:44.728182 UTC | [2020_01_10_11_46_20] Iteration #358 | Epoch Duration: 91.65471029281616
2020-01-10 20:36:44.728361 UTC | [2020_01_10_11_46_20] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0552784
Z variance train             0.01007504
KL Divergence                24.109524
KL Loss                      2.4109523
QF Loss                      590.4297
VF Loss                      140.95663
Policy Loss                  -1164.4434
Q Predictions Mean           1166.0192
Q Predictions Std            239.58641
Q Predictions Max            1372.2808
Q Predictions Min            -27.438097
V Predictions Mean           1169.934
V Predictions Std            242.33508
V Predictions Max            1392.3923
V Predictions Min            -31.319149
Log Pis Mean                 -0.07580353
Log Pis Std                  2.7944877
Log Pis Max                  6.577032
Log Pis Min                  -9.520771
Policy mu Mean               -0.0081775
Policy mu Std                0.59826607
Policy mu Max                2.3044336
Policy mu Min                -2.3409088
Policy log std Mean          -0.9783462
Policy log std Std           0.2817384
Policy log std Max           -0.1894322
Policy log std Min           -1.8954576
Z mean eval                  1.0677373
Z variance eval              0.010950791
total_rewards                [2653.14131657  261.56504707 3311.7346747   104.14579429 3279.71459429
 3355.96089063 1787.64538012   19.50277098 3240.76107681 1336.91833371]
total_rewards_mean           1935.108987917624
total_rewards_std            1347.0145040436648
total_rewards_max            3355.960890628896
total_rewards_min            19.502770980602143
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               34.19815100124106
(Previous) Eval Time (s)     32.47694310173392
Sample Time (s)              24.943572758231312
Epoch Time (s)               91.6186668612063
Total Train Time (s)         31903.648403417785
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:38:05.134723 UTC | [2020_01_10_11_46_20] Iteration #359 | Epoch Duration: 80.40622735023499
2020-01-10 20:38:05.134899 UTC | [2020_01_10_11_46_20] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0681416
Z variance train             0.01094619
KL Divergence                24.40926
KL Loss                      2.440926
QF Loss                      1675.6599
VF Loss                      154.13763
Policy Loss                  -1200.2856
Q Predictions Mean           1202.6165
Q Predictions Std            196.40508
Q Predictions Max            1389.232
Q Predictions Min            34.301987
V Predictions Mean           1205.6285
V Predictions Std            193.98305
V Predictions Max            1375.8938
V Predictions Min            31.984688
Log Pis Mean                 -0.17564279
Log Pis Std                  2.5996747
Log Pis Max                  8.834729
Log Pis Min                  -9.74289
Policy mu Mean               0.0382455
Policy mu Std                0.6395446
Policy mu Max                2.5221262
Policy mu Min                -1.9637259
Policy log std Mean          -0.94034576
Policy log std Std           0.26789042
Policy log std Max           0.20451295
Policy log std Min           -2.409893
Z mean eval                  1.103471
Z variance eval              0.0111664105
total_rewards                [3079.66454225  472.57308551 3109.27473555  363.8895361    91.63749577
 1559.16391175  367.56092403 2977.62274611  884.28754236  759.45592973]
total_rewards_mean           1366.5130449175044
total_rewards_std            1167.627959686239
total_rewards_max            3109.274735550906
total_rewards_min            91.63749576910091
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               33.956681571900845
(Previous) Eval Time (s)     21.26413101097569
Sample Time (s)              25.278398387134075
Epoch Time (s)               80.49921097001061
Total Train Time (s)         31981.104935958516
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:39:22.594901 UTC | [2020_01_10_11_46_20] Iteration #360 | Epoch Duration: 77.45987486839294
2020-01-10 20:39:22.595085 UTC | [2020_01_10_11_46_20] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1035079
Z variance train             0.011142995
KL Divergence                24.698063
KL Loss                      2.4698064
QF Loss                      1185.6744
VF Loss                      254.82288
Policy Loss                  -1203.29
Q Predictions Mean           1202.4481
Q Predictions Std            193.85379
Q Predictions Max            1408.0785
Q Predictions Min            -18.584631
V Predictions Mean           1200.5454
V Predictions Std            189.86412
V Predictions Max            1403.0835
V Predictions Min            -31.293184
Log Pis Mean                 0.0008413866
Log Pis Std                  2.6651382
Log Pis Max                  14.393717
Log Pis Min                  -8.322224
Policy mu Mean               0.10352841
Policy mu Std                0.6028303
Policy mu Max                2.4327528
Policy mu Min                -2.0823298
Policy log std Mean          -0.9790507
Policy log std Std           0.29284006
Policy log std Max           -0.17713583
Policy log std Min           -3.1226635
Z mean eval                  1.0421642
Z variance eval              0.010048421
total_rewards                [ 635.03843817 3404.83664198 3464.21145891 1028.39475382 3514.87800607
 3496.96142141 3181.52920029 3412.04032574 1391.69881525 1173.07110906]
total_rewards_mean           2470.266017070114
total_rewards_std            1170.1528303504913
total_rewards_max            3514.878006069157
total_rewards_min            635.0384381722962
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               34.3432581149973
(Previous) Eval Time (s)     18.224434503819793
Sample Time (s)              25.244013984221965
Epoch Time (s)               77.81170660303906
Total Train Time (s)         32068.720285685733
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:40:50.214083 UTC | [2020_01_10_11_46_20] Iteration #361 | Epoch Duration: 87.6188633441925
2020-01-10 20:40:50.214268 UTC | [2020_01_10_11_46_20] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.041251
Z variance train             0.010037145
KL Divergence                24.422009
KL Loss                      2.442201
QF Loss                      2669.5532
VF Loss                      324.69485
Policy Loss                  -1177.9735
Q Predictions Mean           1178.888
Q Predictions Std            236.59361
Q Predictions Max            1368.3671
Q Predictions Min            -9.064196
V Predictions Mean           1178.6182
V Predictions Std            233.24042
V Predictions Max            1359.578
V Predictions Min            0.14974111
Log Pis Mean                 0.2032915
Log Pis Std                  2.6380944
Log Pis Max                  9.752656
Log Pis Min                  -6.367697
Policy mu Mean               0.06623696
Policy mu Std                0.63134336
Policy mu Max                2.2990139
Policy mu Min                -2.3845246
Policy log std Mean          -0.9845611
Policy log std Std           0.28851104
Policy log std Max           -0.14085019
Policy log std Min           -2.9951
Z mean eval                  1.0579214
Z variance eval              0.011564888
total_rewards                [ 828.9394817  3436.50870258  596.83017973 2735.10008777 1946.7997194
 1796.02132945 3246.07279638 3468.29210146 3162.60534959  747.9028669 ]
total_rewards_mean           2196.5072614964383
total_rewards_std            1105.9141803086673
total_rewards_max            3468.292101460019
total_rewards_min            596.8301797293238
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               33.839925630018115
(Previous) Eval Time (s)     28.03125900728628
Sample Time (s)              25.659239646978676
Epoch Time (s)               87.53042428428307
Total Train Time (s)         32151.1783768218
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:42:12.676381 UTC | [2020_01_10_11_46_20] Iteration #362 | Epoch Duration: 82.4619767665863
2020-01-10 20:42:12.676563 UTC | [2020_01_10_11_46_20] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0602906
Z variance train             0.011632894
KL Divergence                24.083782
KL Loss                      2.4083784
QF Loss                      971.2603
VF Loss                      275.6079
Policy Loss                  -1170.1116
Q Predictions Mean           1167.8337
Q Predictions Std            264.81653
Q Predictions Max            1395.7358
Q Predictions Min            -64.12928
V Predictions Mean           1167.7622
V Predictions Std            258.51245
V Predictions Max            1372.2034
V Predictions Min            -2.5834246
Log Pis Mean                 -0.10773559
Log Pis Std                  2.5163417
Log Pis Max                  10.250757
Log Pis Min                  -7.85316
Policy mu Mean               0.05696127
Policy mu Std                0.6056032
Policy mu Max                2.269107
Policy mu Min                -2.1004696
Policy log std Mean          -0.99046737
Policy log std Std           0.26385108
Policy log std Max           -0.15959787
Policy log std Min           -2.0052028
Z mean eval                  1.0752395
Z variance eval              0.016413061
total_rewards                [1035.03229644 3295.26873368  879.7481383   877.94008821 1238.10612543
 3059.34194739 1932.6866191  3189.07102548 3126.0294192   672.89145165]
total_rewards_mean           1930.6115844881629
total_rewards_std            1059.480386939455
total_rewards_max            3295.26873368003
total_rewards_min            672.8914516496523
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               33.49332444090396
(Previous) Eval Time (s)     22.962469174992293
Sample Time (s)              25.6991633111611
Epoch Time (s)               82.15495692705736
Total Train Time (s)         32237.312373147346
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:43:38.814106 UTC | [2020_01_10_11_46_20] Iteration #363 | Epoch Duration: 86.13741612434387
2020-01-10 20:43:38.814287 UTC | [2020_01_10_11_46_20] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0767854
Z variance train             0.016455429
KL Divergence                23.766876
KL Loss                      2.3766878
QF Loss                      1454.7593
VF Loss                      248.88516
Policy Loss                  -1194.824
Q Predictions Mean           1193.0566
Q Predictions Std            231.4896
Q Predictions Max            1412.2173
Q Predictions Min            -2.7242603
V Predictions Mean           1198.3984
V Predictions Std            221.97905
V Predictions Max            1403.7336
V Predictions Min            -8.249744
Log Pis Mean                 0.1568453
Log Pis Std                  3.0285413
Log Pis Max                  14.159025
Log Pis Min                  -7.6909013
Policy mu Mean               0.009960089
Policy mu Std                0.6198531
Policy mu Max                2.4907053
Policy mu Min                -2.0015244
Policy log std Mean          -1.0142765
Policy log std Std           0.31423324
Policy log std Max           0.058003783
Policy log std Min           -3.0677395
Z mean eval                  1.0873746
Z variance eval              0.013720119
total_rewards                [3126.18403053   45.79237118 3216.94563098 3028.05947595 2996.81062791
 3367.30882679 3171.64302741 1017.86303423 3137.88614671 3359.01825134]
total_rewards_mean           2646.751142304708
total_rewards_std            1085.5612018947056
total_rewards_max            3367.308826791742
total_rewards_min            45.792371184093625
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               33.800779497250915
(Previous) Eval Time (s)     26.944588479120284
Sample Time (s)              25.009146181866527
Epoch Time (s)               85.75451415823773
Total Train Time (s)         32325.323545735795
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:45:06.829133 UTC | [2020_01_10_11_46_20] Iteration #364 | Epoch Duration: 88.01471829414368
2020-01-10 20:45:06.829304 UTC | [2020_01_10_11_46_20] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0889605
Z variance train             0.01374646
KL Divergence                24.077507
KL Loss                      2.4077508
QF Loss                      764.53546
VF Loss                      794.3975
Policy Loss                  -1184.3584
Q Predictions Mean           1177.6925
Q Predictions Std            260.94547
Q Predictions Max            1417.682
Q Predictions Min            3.3745303
V Predictions Mean           1178.7695
V Predictions Std            257.6207
V Predictions Max            1407.076
V Predictions Min            -2.350503
Log Pis Mean                 0.03749051
Log Pis Std                  2.9086947
Log Pis Max                  12.873372
Log Pis Min                  -8.580067
Policy mu Mean               0.05308054
Policy mu Std                0.6377809
Policy mu Max                3.2033703
Policy mu Min                -2.0839176
Policy log std Mean          -0.9761343
Policy log std Std           0.2853435
Policy log std Max           0.024749696
Policy log std Min           -2.3661098
Z mean eval                  1.0692441
Z variance eval              0.017694982
total_rewards                [3094.86507476 1697.61732911  508.72827317  995.228282   3253.65589966
 3172.77749553 2415.50556967 3157.26285397 3265.74388559 3010.47950162]
total_rewards_mean           2457.1864165087527
total_rewards_std            975.4776754586474
total_rewards_max            3265.743885587582
total_rewards_min            508.7282731747332
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               34.184416479896754
(Previous) Eval Time (s)     29.2045012624003
Sample Time (s)              26.09909418411553
Epoch Time (s)               89.48801192641258
Total Train Time (s)         32414.988297157455
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:46:36.497912 UTC | [2020_01_10_11_46_20] Iteration #365 | Epoch Duration: 89.66847658157349
2020-01-10 20:46:36.498093 UTC | [2020_01_10_11_46_20] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0692945
Z variance train             0.017637942
KL Divergence                23.795511
KL Loss                      2.3795512
QF Loss                      725.9066
VF Loss                      664.2091
Policy Loss                  -1193.1046
Q Predictions Mean           1190.5396
Q Predictions Std            222.36609
Q Predictions Max            1387.8356
Q Predictions Min            -38.182987
V Predictions Mean           1173.2649
V Predictions Std            220.84523
V Predictions Max            1368.5118
V Predictions Min            -30.211798
Log Pis Mean                 0.06624396
Log Pis Std                  2.6799295
Log Pis Max                  7.0972614
Log Pis Min                  -8.791626
Policy mu Mean               -0.0036477093
Policy mu Std                0.63054967
Policy mu Max                2.3413277
Policy mu Min                -2.149611
Policy log std Mean          -0.9651965
Policy log std Std           0.26659912
Policy log std Max           -0.14390165
Policy log std Min           -2.4339023
Z mean eval                  1.0767143
Z variance eval              0.016514037
total_rewards                [3241.19138999 1814.38333343 1583.35162108  339.43821887 1247.18844063
  777.05497189 3268.34967638 3426.90337589  289.8017032  1232.66164857]
total_rewards_mean           1722.03243799461
total_rewards_std            1138.1599865640503
total_rewards_max            3426.9033758940473
total_rewards_min            289.8017032038121
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               33.27602904802188
(Previous) Eval Time (s)     29.384590811096132
Sample Time (s)              25.218985203653574
Epoch Time (s)               87.87960506277159
Total Train Time (s)         32493.34118829202
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:47:54.854476 UTC | [2020_01_10_11_46_20] Iteration #366 | Epoch Duration: 78.35625386238098
2020-01-10 20:47:54.854648 UTC | [2020_01_10_11_46_20] Iteration #366 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0754904
Z variance train             0.016523007
KL Divergence                24.010921
KL Loss                      2.4010923
QF Loss                      1470.3115
VF Loss                      119.65347
Policy Loss                  -1183.7338
Q Predictions Mean           1183.5579
Q Predictions Std            259.61255
Q Predictions Max            1371.6624
Q Predictions Min            18.031536
V Predictions Mean           1182.177
V Predictions Std            260.1114
V Predictions Max            1370.1134
V Predictions Min            16.873472
Log Pis Mean                 -0.24695066
Log Pis Std                  2.7795432
Log Pis Max                  12.368663
Log Pis Min                  -8.831444
Policy mu Mean               0.0019251304
Policy mu Std                0.599017
Policy mu Max                2.2729385
Policy mu Min                -2.0370612
Policy log std Mean          -0.9717144
Policy log std Std           0.28184974
Policy log std Max           0.007202208
Policy log std Min           -2.3113215
Z mean eval                  1.0746744
Z variance eval              0.01584408
total_rewards                [3497.93095861 3566.77118092 3468.99737333 3407.51944938 3283.328676
 3617.84167549  432.98261095 3427.03180675  455.83478008 3601.73226074]
total_rewards_mean           2875.9970772263055
total_rewards_std            1219.4352994092546
total_rewards_max            3617.8416754861637
total_rewards_min            432.98261095007535
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               33.94684510678053
(Previous) Eval Time (s)     19.86089278291911
Sample Time (s)              26.2447924958542
Epoch Time (s)               80.05253038555384
Total Train Time (s)         32582.967940000817
Epoch                        367
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:49:24.486007 UTC | [2020_01_10_11_46_20] Iteration #367 | Epoch Duration: 89.63121175765991
2020-01-10 20:49:24.486230 UTC | [2020_01_10_11_46_20] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0749018
Z variance train             0.01586
KL Divergence                24.247345
KL Loss                      2.4247346
QF Loss                      5424.221
VF Loss                      836.1682
Policy Loss                  -1223.167
Q Predictions Mean           1223.8074
Q Predictions Std            171.2854
Q Predictions Max            1386.9119
Q Predictions Min            90.67329
V Predictions Mean           1209.3098
V Predictions Std            172.9004
V Predictions Max            1406.5182
V Predictions Min            98.96983
Log Pis Mean                 0.2729344
Log Pis Std                  3.0212007
Log Pis Max                  16.17692
Log Pis Min                  -7.683924
Policy mu Mean               0.037903912
Policy mu Std                0.62266827
Policy mu Max                2.8434393
Policy mu Min                -2.3445427
Policy log std Mean          -1.0096436
Policy log std Std           0.27701992
Policy log std Max           -0.15196997
Policy log std Min           -2.4233587
Z mean eval                  1.0488403
Z variance eval              0.0106556155
total_rewards                [ -46.50238234  245.87215874 2527.8200501    46.87417191 2380.82050619
 2486.127115   3163.61708889 3432.7535429  1969.23542774 3333.66317842]
total_rewards_mean           1954.0280857550474
total_rewards_std            1300.1935251174443
total_rewards_max            3432.753542903762
total_rewards_min            -46.50238234381018
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               33.84789021778852
(Previous) Eval Time (s)     29.43917880114168
Sample Time (s)              25.90925132110715
Epoch Time (s)               89.19632034003735
Total Train Time (s)         32666.78623291431
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:50:48.307975 UTC | [2020_01_10_11_46_20] Iteration #368 | Epoch Duration: 83.82158374786377
2020-01-10 20:50:48.308178 UTC | [2020_01_10_11_46_20] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0479227
Z variance train             0.01070777
KL Divergence                23.70014
KL Loss                      2.370014
QF Loss                      3573.8818
VF Loss                      557.031
Policy Loss                  -1206.2245
Q Predictions Mean           1208.3555
Q Predictions Std            192.93301
Q Predictions Max            1385.1632
Q Predictions Min            5.499115
V Predictions Mean           1217.0167
V Predictions Std            193.66664
V Predictions Max            1388.1359
V Predictions Min            -13.836664
Log Pis Mean                 -0.15274861
Log Pis Std                  2.546008
Log Pis Max                  14.189524
Log Pis Min                  -8.21179
Policy mu Mean               0.016020674
Policy mu Std                0.59134203
Policy mu Max                2.2247167
Policy mu Min                -2.4658623
Policy log std Mean          -0.9665699
Policy log std Std           0.2642579
Policy log std Max           -0.05264318
Policy log std Min           -3.0255947
Z mean eval                  1.1004441
Z variance eval              0.008822845
total_rewards                [2828.43255645 3266.44975412 1357.65072392 3234.53762719 2867.66653958
 3203.34979894   50.54992558 3441.88542806  444.14440491 2543.03272594]
total_rewards_mean           2323.7699484694895
total_rewards_std            1182.136952618806
total_rewards_max            3441.8854280587952
total_rewards_min            50.54992558281801
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               33.89128507627174
(Previous) Eval Time (s)     24.064092400018126
Sample Time (s)              25.805392703041434
Epoch Time (s)               83.7607701793313
Total Train Time (s)         32752.199146814644
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:52:13.724944 UTC | [2020_01_10_11_46_20] Iteration #369 | Epoch Duration: 85.41662406921387
2020-01-10 20:52:13.725127 UTC | [2020_01_10_11_46_20] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1016198
Z variance train             0.008803589
KL Divergence                24.651157
KL Loss                      2.4651158
QF Loss                      1011.65924
VF Loss                      584.59625
Policy Loss                  -1212.8774
Q Predictions Mean           1214.3657
Q Predictions Std            222.49208
Q Predictions Max            1422.5336
Q Predictions Min            -45.61225
V Predictions Mean           1227.2678
V Predictions Std            226.99689
V Predictions Max            1434.2042
V Predictions Min            8.513428
Log Pis Mean                 -0.011854269
Log Pis Std                  2.7909386
Log Pis Max                  10.737009
Log Pis Min                  -6.992815
Policy mu Mean               0.022790182
Policy mu Std                0.61213124
Policy mu Max                2.3222444
Policy mu Min                -2.7270908
Policy log std Mean          -0.98382413
Policy log std Std           0.25823528
Policy log std Max           -0.094020665
Policy log std Min           -2.6824696
Z mean eval                  1.099443
Z variance eval              0.009147948
total_rewards                [2062.56185944 3058.0335204   167.0013896  3009.27306136 2418.36227831
  783.90045363 2943.99437002 3207.41680795 3094.96870659 3144.43144104]
total_rewards_mean           2388.994388834927
total_rewards_std            1024.7089441500827
total_rewards_max            3207.416807954385
total_rewards_min            167.00138960168866
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               34.11100819287822
(Previous) Eval Time (s)     25.71962872426957
Sample Time (s)              25.946695261634886
Epoch Time (s)               85.77733217878267
Total Train Time (s)         32838.49653380364
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:53:40.026259 UTC | [2020_01_10_11_46_20] Iteration #370 | Epoch Duration: 86.30099964141846
2020-01-10 20:53:40.026443 UTC | [2020_01_10_11_46_20] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.098933
Z variance train             0.00916096
KL Divergence                24.826633
KL Loss                      2.4826634
QF Loss                      971.12164
VF Loss                      179.22745
Policy Loss                  -1220.177
Q Predictions Mean           1221.5765
Q Predictions Std            231.5698
Q Predictions Max            1422.2864
Q Predictions Min            -1.5988042
V Predictions Mean           1227.0923
V Predictions Std            229.24028
V Predictions Max            1419.6526
V Predictions Min            4.124268
Log Pis Mean                 0.21322767
Log Pis Std                  3.2998857
Log Pis Max                  14.149122
Log Pis Min                  -11.068444
Policy mu Mean               0.04993671
Policy mu Std                0.64860755
Policy mu Max                2.4140146
Policy mu Min                -2.2925751
Policy log std Mean          -0.9719476
Policy log std Std           0.30579028
Policy log std Max           0.068724215
Policy log std Min           -3.3783672
Z mean eval                  1.1211113
Z variance eval              0.010914968
total_rewards                [  57.15532996 3283.89071798 3239.82508798 3227.5569541  3420.31603171
  341.42709454  510.97889215 3272.47046442 3506.71287103 3377.27588344]
total_rewards_mean           2423.7609327308687
total_rewards_std            1394.3797553330837
total_rewards_max            3506.712871034342
total_rewards_min            57.155329963829594
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               33.72509852424264
(Previous) Eval Time (s)     26.242880881298333
Sample Time (s)              25.934298334177583
Epoch Time (s)               85.90227773971856
Total Train Time (s)         32927.208916313015
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:55:08.742934 UTC | [2020_01_10_11_46_20] Iteration #371 | Epoch Duration: 88.71633863449097
2020-01-10 20:55:08.743163 UTC | [2020_01_10_11_46_20] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1226618
Z variance train             0.0108643845
KL Divergence                24.91446
KL Loss                      2.491446
QF Loss                      682.4519
VF Loss                      361.20078
Policy Loss                  -1224.1023
Q Predictions Mean           1226.6047
Q Predictions Std            240.43831
Q Predictions Max            1434.5261
Q Predictions Min            -26.117546
V Predictions Mean           1214.1233
V Predictions Std            233.47403
V Predictions Max            1441.9504
V Predictions Min            -13.930614
Log Pis Mean                 0.19868207
Log Pis Std                  2.8261986
Log Pis Max                  9.183964
Log Pis Min                  -7.315098
Policy mu Mean               0.079447806
Policy mu Std                0.6370088
Policy mu Max                2.4356961
Policy mu Min                -2.3044043
Policy log std Mean          -0.9760896
Policy log std Std           0.27355585
Policy log std Max           -0.180893
Policy log std Min           -1.914227
Z mean eval                  1.0667131
Z variance eval              0.012443272
total_rewards                [1081.48720721  724.34955646 1141.44801828  252.15849328 1832.85226241
 2915.01179624  255.13648006   80.64255836  341.09815515  546.05195429]
total_rewards_mean           917.0236481744212
total_rewards_std            836.3145551938123
total_rewards_max            2915.0117962364047
total_rewards_min            80.64255836382485
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               33.368511729408056
(Previous) Eval Time (s)     29.056568404193968
Sample Time (s)              24.926346885506064
Epoch Time (s)               87.35142701910809
Total Train Time (s)         32996.33630407648
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:56:17.874532 UTC | [2020_01_10_11_46_20] Iteration #372 | Epoch Duration: 69.1311502456665
2020-01-10 20:56:17.874726 UTC | [2020_01_10_11_46_20] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0698746
Z variance train             0.012427834
KL Divergence                24.454311
KL Loss                      2.4454312
QF Loss                      1216.9446
VF Loss                      1291.6555
Policy Loss                  -1215.3622
Q Predictions Mean           1216.8309
Q Predictions Std            172.21324
Q Predictions Max            1385.4869
Q Predictions Min            -11.7489395
V Predictions Mean           1226.2896
V Predictions Std            169.2315
V Predictions Max            1389.8862
V Predictions Min            -11.483904
Log Pis Mean                 0.43328166
Log Pis Std                  3.2857194
Log Pis Max                  19.189272
Log Pis Min                  -7.1052475
Policy mu Mean               0.006829902
Policy mu Std                0.65127033
Policy mu Max                2.3992271
Policy mu Min                -3.1878183
Policy log std Mean          -1.003813
Policy log std Std           0.30083954
Policy log std Max           -0.09676683
Policy log std Min           -3.2515192
Z mean eval                  1.095618
Z variance eval              0.013453277
total_rewards                [2979.57584027 1327.2147202  3155.94910876 3258.86243879 3359.68499592
 3408.37744075 3292.51029294  541.6174265  3183.33544935 3097.62677502]
total_rewards_mean           2760.4754488495964
total_rewards_std            937.2690634545512
total_rewards_max            3408.3774407457786
total_rewards_min            541.6174264985073
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               33.803239868953824
(Previous) Eval Time (s)     10.835934994742274
Sample Time (s)              23.094733480364084
Epoch Time (s)               67.73390834406018
Total Train Time (s)         33083.921716474
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:57:45.464240 UTC | [2020_01_10_11_46_20] Iteration #373 | Epoch Duration: 87.58937788009644
2020-01-10 20:57:45.464430 UTC | [2020_01_10_11_46_20] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0940751
Z variance train             0.0134680625
KL Divergence                25.508436
KL Loss                      2.5508437
QF Loss                      529.5204
VF Loss                      135.2839
Policy Loss                  -1229.9985
Q Predictions Mean           1230.7551
Q Predictions Std            207.07681
Q Predictions Max            1394.5432
Q Predictions Min            -4.3725076
V Predictions Mean           1231.5815
V Predictions Std            205.13239
V Predictions Max            1407.8344
V Predictions Min            -20.984835
Log Pis Mean                 -0.16464356
Log Pis Std                  2.5530465
Log Pis Max                  7.1087112
Log Pis Min                  -6.777953
Policy mu Mean               0.10010122
Policy mu Std                0.59222496
Policy mu Max                2.461594
Policy mu Min                -1.9235494
Policy log std Mean          -0.9649364
Policy log std Std           0.26214138
Policy log std Max           -0.10218215
Policy log std Min           -2.010282
Z mean eval                  1.0781838
Z variance eval              0.014243613
total_rewards                [3200.94434752 2269.55416896 2135.38994417 1610.36651402 1047.61028952
  698.59420275 2537.21175355  428.94431791  519.1815875   603.60920431]
total_rewards_mean           1505.1406330203297
total_rewards_std            934.6903013592394
total_rewards_max            3200.94434751697
total_rewards_min            428.94431790682466
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               34.20570793002844
(Previous) Eval Time (s)     30.691089797299355
Sample Time (s)              25.8611066788435
Epoch Time (s)               90.75790440617129
Total Train Time (s)         33162.925146380905
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:59:04.471925 UTC | [2020_01_10_11_46_20] Iteration #374 | Epoch Duration: 79.00735712051392
2020-01-10 20:59:04.472120 UTC | [2020_01_10_11_46_20] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0739653
Z variance train             0.014230007
KL Divergence                25.542654
KL Loss                      2.5542655
QF Loss                      1099.0259
VF Loss                      123.45741
Policy Loss                  -1202.4824
Q Predictions Mean           1201.7568
Q Predictions Std            265.20273
Q Predictions Max            1404.8142
Q Predictions Min            -2.5236208
V Predictions Mean           1203.9056
V Predictions Std            263.15735
V Predictions Max            1431.7446
V Predictions Min            2.3715599
Log Pis Mean                 0.31206134
Log Pis Std                  2.7808034
Log Pis Max                  10.571392
Log Pis Min                  -7.39868
Policy mu Mean               0.04114802
Policy mu Std                0.6324371
Policy mu Max                2.7943537
Policy mu Min                -1.9195122
Policy log std Mean          -0.9862144
Policy log std Std           0.29847208
Policy log std Max           -0.15925586
Policy log std Min           -2.7400367
Z mean eval                  1.0704136
Z variance eval              0.010362578
total_rewards                [2224.23809128 3035.24152717 3464.33625459 3416.21761264   11.74183917
 3369.08132336 1002.42720472 3298.84323957 3218.81288022 3235.95957504]
total_rewards_mean           2627.68995477548
total_rewards_std            1133.7907335929933
total_rewards_max            3464.3362545878636
total_rewards_min            11.741839170876808
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               34.312576508615166
(Previous) Eval Time (s)     18.940188240259886
Sample Time (s)              24.57963459426537
Epoch Time (s)               77.83239934314042
Total Train Time (s)         33249.312418196816
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:00:30.862956 UTC | [2020_01_10_11_46_20] Iteration #375 | Epoch Duration: 86.39070343971252
2020-01-10 21:00:30.863137 UTC | [2020_01_10_11_46_20] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0699105
Z variance train             0.01037248
KL Divergence                25.848427
KL Loss                      2.5848427
QF Loss                      1473.2108
VF Loss                      497.95764
Policy Loss                  -1212.8501
Q Predictions Mean           1211.9629
Q Predictions Std            248.52304
Q Predictions Max            1421.522
Q Predictions Min            2.8636765
V Predictions Mean           1221.4414
V Predictions Std            251.08691
V Predictions Max            1423.9268
V Predictions Min            -9.551109
Log Pis Mean                 0.35038453
Log Pis Std                  2.7319293
Log Pis Max                  8.6795435
Log Pis Min                  -6.122011
Policy mu Mean               0.08489269
Policy mu Std                0.6154244
Policy mu Max                2.7354743
Policy mu Min                -2.012883
Policy log std Mean          -1.0039592
Policy log std Std           0.31050378
Policy log std Max           -0.12279147
Policy log std Min           -2.7787037
Z mean eval                  1.09666
Z variance eval              0.00926254
total_rewards                [2807.17395108 3434.47821151 3008.34787619 3184.74795025 3172.33811111
 2440.87210047 2826.07967846  801.83682376 3295.98331823 3167.69874984]
total_rewards_mean           2813.9556770900863
total_rewards_std            723.4813645353697
total_rewards_max            3434.478211508593
total_rewards_min            801.8368237551147
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               35.78813554299995
(Previous) Eval Time (s)     27.4982055448927
Sample Time (s)              26.991081615444273
Epoch Time (s)               90.27742270333692
Total Train Time (s)         33345.41210144851
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:02:06.967134 UTC | [2020_01_10_11_46_20] Iteration #376 | Epoch Duration: 96.10380911827087
2020-01-10 21:02:06.967444 UTC | [2020_01_10_11_46_20] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0973847
Z variance train             0.009270305
KL Divergence                25.277191
KL Loss                      2.5277193
QF Loss                      1690.2869
VF Loss                      142.49243
Policy Loss                  -1219.7258
Q Predictions Mean           1218.6487
Q Predictions Std            246.22809
Q Predictions Max            1415.7882
Q Predictions Min            1.541824
V Predictions Mean           1224.5576
V Predictions Std            246.1237
V Predictions Max            1416.1406
V Predictions Min            2.707204
Log Pis Mean                 0.2027646
Log Pis Std                  2.8019423
Log Pis Max                  9.273609
Log Pis Min                  -6.871519
Policy mu Mean               -0.019286212
Policy mu Std                0.634681
Policy mu Max                2.2405808
Policy mu Min                -2.3608687
Policy log std Mean          -1.0093403
Policy log std Std           0.29789752
Policy log std Max           -0.16686869
Policy log std Min           -2.5073247
Z mean eval                  1.0959255
Z variance eval              0.010053543
total_rewards                [2588.67428233 3145.65987987 3275.1692188  3364.6359423  3333.22162624
 3343.60095728 2341.68283073 3270.95300746 3233.21702798 3298.75531614]
total_rewards_mean           3119.557008915126
total_rewards_std            336.99919153029316
total_rewards_max            3364.6359423039125
total_rewards_min            2341.6828307278747
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               37.183778706006706
(Previous) Eval Time (s)     33.32421572925523
Sample Time (s)              26.278883069287986
Epoch Time (s)               96.78687750454992
Total Train Time (s)         33444.393791097216
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:03:45.952992 UTC | [2020_01_10_11_46_20] Iteration #377 | Epoch Duration: 98.9853847026825
2020-01-10 21:03:45.953184 UTC | [2020_01_10_11_46_20] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0941632
Z variance train             0.010055779
KL Divergence                25.551922
KL Loss                      2.5551922
QF Loss                      764.3425
VF Loss                      143.83492
Policy Loss                  -1159.1356
Q Predictions Mean           1159.9541
Q Predictions Std            342.12885
Q Predictions Max            1417.5419
Q Predictions Min            -91.07744
V Predictions Mean           1162.9509
V Predictions Std            342.23563
V Predictions Max            1433.0844
V Predictions Min            -75.317665
Log Pis Mean                 -0.28772995
Log Pis Std                  2.8283694
Log Pis Max                  10.21377
Log Pis Min                  -8.54236
Policy mu Mean               0.03594955
Policy mu Std                0.57972896
Policy mu Max                2.2447236
Policy mu Min                -2.6745825
Policy log std Mean          -0.97133493
Policy log std Std           0.29516542
Policy log std Max           -0.1600169
Policy log std Min           -2.326205
Z mean eval                  1.1021729
Z variance eval              0.009925353
total_rewards                [ 407.6621041  3094.85299355 3415.55716408 3194.81672117 3508.4514284
  995.16446229  291.06213371 3325.75668312  225.75867383 3418.67214731]
total_rewards_mean           2187.7754511554494
total_rewards_std            1411.9779906914603
total_rewards_max            3508.451428395377
total_rewards_min            225.75867383460434
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               36.08660265710205
(Previous) Eval Time (s)     35.52241321094334
Sample Time (s)              26.36629903363064
Epoch Time (s)               97.97531490167603
Total Train Time (s)         33530.47600735957
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:05:12.047019 UTC | [2020_01_10_11_46_20] Iteration #378 | Epoch Duration: 86.09367060661316
2020-01-10 21:05:12.047474 UTC | [2020_01_10_11_46_20] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1009054
Z variance train             0.0099348705
KL Divergence                25.608366
KL Loss                      2.5608366
QF Loss                      786.1459
VF Loss                      318.70883
Policy Loss                  -1213.3965
Q Predictions Mean           1210.9651
Q Predictions Std            264.4146
Q Predictions Max            1421.3243
Q Predictions Min            -14.739604
V Predictions Mean           1204.4163
V Predictions Std            261.06894
V Predictions Max            1412.5198
V Predictions Min            -13.289958
Log Pis Mean                 -0.08887965
Log Pis Std                  2.6433702
Log Pis Max                  9.054764
Log Pis Min                  -8.415541
Policy mu Mean               0.057951786
Policy mu Std                0.60738325
Policy mu Max                2.4164867
Policy mu Min                -2.6704159
Policy log std Mean          -0.9852319
Policy log std Std           0.2729258
Policy log std Max           -0.013307512
Policy log std Min           -2.4636703
Z mean eval                  1.0717218
Z variance eval              0.013045387
total_rewards                [3269.80049762 1557.18659357 3209.09568062 1861.44092162  -91.76504793
  315.12878362 1675.47694741 3159.36756118 3221.10625257 3273.38456179]
total_rewards_mean           2145.022275206767
total_rewards_std            1218.8356125465018
total_rewards_max            3273.384561790354
total_rewards_min            -91.76504793246038
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               36.79236521292478
(Previous) Eval Time (s)     23.640242459252477
Sample Time (s)              27.210002657957375
Epoch Time (s)               87.64261033013463
Total Train Time (s)         33623.56060621282
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:06:45.135755 UTC | [2020_01_10_11_46_20] Iteration #379 | Epoch Duration: 93.08797264099121
2020-01-10 21:06:45.135979 UTC | [2020_01_10_11_46_20] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0744869
Z variance train             0.012994349
KL Divergence                24.737495
KL Loss                      2.4737496
QF Loss                      1794.9993
VF Loss                      614.5983
Policy Loss                  -1247.0375
Q Predictions Mean           1246.4303
Q Predictions Std            209.90456
Q Predictions Max            1413.0839
Q Predictions Min            19.00218
V Predictions Mean           1233.9556
V Predictions Std            207.79582
V Predictions Max            1386.8573
V Predictions Min            13.629156
Log Pis Mean                 0.14035815
Log Pis Std                  2.5663695
Log Pis Max                  11.817257
Log Pis Min                  -5.655823
Policy mu Mean               -0.030368665
Policy mu Std                0.6015026
Policy mu Max                3.6762795
Policy mu Min                -2.0069811
Policy log std Mean          -0.9974764
Policy log std Std           0.28570202
Policy log std Max           0.042100072
Policy log std Min           -2.9787645
Z mean eval                  1.0908096
Z variance eval              0.015894651
total_rewards                [ 480.49576461 1545.12978001 3223.92749282 3246.36996743  847.78452066
  691.69875598 1983.87408689 3468.40844769 2118.9674183  2690.70382942]
total_rewards_mean           2029.7360063827662
total_rewards_std            1060.4412024202702
total_rewards_max            3468.408447694962
total_rewards_min            480.49576461037776
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               35.71854650834575
(Previous) Eval Time (s)     29.085209399927408
Sample Time (s)              26.393540089949965
Epoch Time (s)               91.19729599822313
Total Train Time (s)         33707.19061684515
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:08:08.769576 UTC | [2020_01_10_11_46_20] Iteration #380 | Epoch Duration: 83.63345694541931
2020-01-10 21:08:08.769798 UTC | [2020_01_10_11_46_20] Iteration #380 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0900234
Z variance train             0.015904775
KL Divergence                24.71136
KL Loss                      2.471136
QF Loss                      1296.9883
VF Loss                      179.67888
Policy Loss                  -1235.0488
Q Predictions Mean           1234.3029
Q Predictions Std            237.75273
Q Predictions Max            1471.7386
Q Predictions Min            -13.193848
V Predictions Mean           1227.3352
V Predictions Std            236.55038
V Predictions Max            1462.3785
V Predictions Min            -3.2395186
Log Pis Mean                 0.016514987
Log Pis Std                  2.665928
Log Pis Max                  10.646655
Log Pis Min                  -7.0992384
Policy mu Mean               0.033543482
Policy mu Std                0.6150883
Policy mu Max                2.3833392
Policy mu Min                -2.294689
Policy log std Mean          -0.98498386
Policy log std Std           0.2802704
Policy log std Max           -0.04265392
Policy log std Min           -2.2096891
Z mean eval                  1.0973393
Z variance eval              0.0136971725
total_rewards                [-1.47659970e+01  2.30979852e+00  3.40341518e+03  1.53606276e+03
  5.74816827e+01  1.41073349e+03  9.14602651e+02  6.37452944e+01
  8.43459442e+02  2.25140580e+02]
total_rewards_mean           844.2184882136222
total_rewards_std            1020.3942968149056
total_rewards_max            3403.415180182851
total_rewards_min            -14.765996959367857
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               36.38157184794545
(Previous) Eval Time (s)     21.521044451277703
Sample Time (s)              26.31099603464827
Epoch Time (s)               84.21361233387142
Total Train Time (s)         33781.9972214601
Epoch                        381
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:09:23.582261 UTC | [2020_01_10_11_46_20] Iteration #381 | Epoch Duration: 74.81231141090393
2020-01-10 21:09:23.582472 UTC | [2020_01_10_11_46_20] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0951817
Z variance train             0.013681816
KL Divergence                25.138172
KL Loss                      2.5138173
QF Loss                      3478.5068
VF Loss                      848.97424
Policy Loss                  -1209.7333
Q Predictions Mean           1210.562
Q Predictions Std            250.4547
Q Predictions Max            1378.6945
Q Predictions Min            -24.798973
V Predictions Mean           1212.3936
V Predictions Std            240.3162
V Predictions Max            1379.1116
V Predictions Min            -7.5197325
Log Pis Mean                 -0.3522893
Log Pis Std                  2.6942017
Log Pis Max                  8.757178
Log Pis Min                  -7.5928383
Policy mu Mean               0.06437318
Policy mu Std                0.6041929
Policy mu Max                2.8847144
Policy mu Min                -2.3509865
Policy log std Mean          -0.9519838
Policy log std Std           0.28354397
Policy log std Max           -0.010304809
Policy log std Min           -2.7659898
Z mean eval                  1.0827631
Z variance eval              0.012007024
total_rewards                [ 930.06755472 3699.77685209 3549.20733721 1281.13493469 2672.40261189
 3220.78564332 3281.36517788 2228.38836304 3742.17916854  568.19966243]
total_rewards_mean           2517.350730581482
total_rewards_std            1140.0013438885505
total_rewards_max            3742.179168542657
total_rewards_min            568.1996624281142
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               37.71460898220539
(Previous) Eval Time (s)     12.119369054213166
Sample Time (s)              25.999887557700276
Epoch Time (s)               75.83386559411883
Total Train Time (s)         33872.02806596365
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:10:53.616120 UTC | [2020_01_10_11_46_20] Iteration #382 | Epoch Duration: 90.03350234031677
2020-01-10 21:10:53.616297 UTC | [2020_01_10_11_46_20] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084456
Z variance train             0.012032263
KL Divergence                25.494629
KL Loss                      2.549463
QF Loss                      1147.9758
VF Loss                      189.5522
Policy Loss                  -1207.0762
Q Predictions Mean           1206.8834
Q Predictions Std            291.42334
Q Predictions Max            1432.5366
Q Predictions Min            18.326391
V Predictions Mean           1201.3708
V Predictions Std            287.4397
V Predictions Max            1428.1665
V Predictions Min            -6.374338
Log Pis Mean                 0.16394657
Log Pis Std                  2.721416
Log Pis Max                  10.3684025
Log Pis Min                  -7.621476
Policy mu Mean               0.028177254
Policy mu Std                0.62401396
Policy mu Max                2.2650905
Policy mu Min                -2.0485756
Policy log std Mean          -0.9843801
Policy log std Std           0.3012606
Policy log std Max           -0.08983725
Policy log std Min           -2.511403
Z mean eval                  1.0866597
Z variance eval              0.014347379
total_rewards                [3276.83792013 1116.43671731 3339.21346742 3231.59484265 3508.19524711
 3341.1171107  3112.25562759 1686.5566187  2929.50750785 2690.14331362]
total_rewards_mean           2823.1858373069995
total_rewards_std            754.5765588731986
total_rewards_max            3508.195247112462
total_rewards_min            1116.4367173068372
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               36.208588276058435
(Previous) Eval Time (s)     26.318603729829192
Sample Time (s)              27.139344098977745
Epoch Time (s)               89.66653610486537
Total Train Time (s)         33964.97591420449
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:12:26.568859 UTC | [2020_01_10_11_46_20] Iteration #383 | Epoch Duration: 92.95243406295776
2020-01-10 21:12:26.569055 UTC | [2020_01_10_11_46_20] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0882258
Z variance train             0.014344196
KL Divergence                24.932528
KL Loss                      2.4932528
QF Loss                      1987.4121
VF Loss                      950.7721
Policy Loss                  -1246.7039
Q Predictions Mean           1244.927
Q Predictions Std            187.28058
Q Predictions Max            1424.755
Q Predictions Min            -53.301983
V Predictions Mean           1251.6523
V Predictions Std            181.62585
V Predictions Max            1426.8406
V Predictions Min            -50.660366
Log Pis Mean                 0.34219763
Log Pis Std                  2.8883808
Log Pis Max                  16.636385
Log Pis Min                  -5.881268
Policy mu Mean               0.09360787
Policy mu Std                0.6356713
Policy mu Max                2.7662797
Policy mu Min                -1.880291
Policy log std Mean          -1.0080603
Policy log std Std           0.30188054
Policy log std Max           -0.21753213
Policy log std Min           -2.973526
Z mean eval                  1.0845487
Z variance eval              0.009559105
total_rewards                [ 509.24702986  458.07109197 3363.9742979  3272.57941649  541.17597146
 3557.09042062 3407.038363   3254.88105435 3314.14119416 3732.63339044]
total_rewards_mean           2541.08322302356
total_rewards_std            1341.202071770044
total_rewards_max            3732.6333904402936
total_rewards_min            458.0710919690376
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               36.86308833118528
(Previous) Eval Time (s)     29.604041930288076
Sample Time (s)              26.944987408351153
Epoch Time (s)               93.41211766982451
Total Train Time (s)         34055.62110177381
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:13:57.219105 UTC | [2020_01_10_11_46_20] Iteration #384 | Epoch Duration: 90.64990305900574
2020-01-10 21:13:57.219329 UTC | [2020_01_10_11_46_20] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0831006
Z variance train             0.009562743
KL Divergence                26.092083
KL Loss                      2.6092083
QF Loss                      11240.709
VF Loss                      136.0391
Policy Loss                  -1247.4125
Q Predictions Mean           1247.854
Q Predictions Std            196.35956
Q Predictions Max            1430.2362
Q Predictions Min            13.637048
V Predictions Mean           1247.9657
V Predictions Std            192.6546
V Predictions Max            1420.0997
V Predictions Min            14.110182
Log Pis Mean                 -0.008405916
Log Pis Std                  2.796363
Log Pis Max                  12.473093
Log Pis Min                  -7.737052
Policy mu Mean               0.09460653
Policy mu Std                0.6204961
Policy mu Max                2.2836943
Policy mu Min                -2.3677843
Policy log std Mean          -0.97047377
Policy log std Std           0.24465796
Policy log std Max           -0.2077049
Policy log std Min           -2.251039
Z mean eval                  1.1143622
Z variance eval              0.007933286
total_rewards                [2074.54983942 2135.20925089 3580.39241055 3165.11739418 3426.67306557
 1407.21327098 1086.78633221 2621.79176892 3329.9705471  3388.95564301]
total_rewards_mean           2621.665952283586
total_rewards_std            855.5517608416778
total_rewards_max            3580.3924105539945
total_rewards_min            1086.7863322130147
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               33.84455810999498
(Previous) Eval Time (s)     26.841451465617865
Sample Time (s)              24.918530836235732
Epoch Time (s)               85.60454041184857
Total Train Time (s)         34145.63280926272
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:15:27.240548 UTC | [2020_01_10_11_46_20] Iteration #385 | Epoch Duration: 90.0210645198822
2020-01-10 21:15:27.240730 UTC | [2020_01_10_11_46_20] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1142961
Z variance train             0.007922393
KL Divergence                26.384165
KL Loss                      2.6384165
QF Loss                      2412.9895
VF Loss                      852.44965
Policy Loss                  -1252.6438
Q Predictions Mean           1254.1721
Q Predictions Std            213.90465
Q Predictions Max            1473.1473
Q Predictions Min            -22.254879
V Predictions Mean           1260.4436
V Predictions Std            204.16624
V Predictions Max            1481.6226
V Predictions Min            21.08981
Log Pis Mean                 0.43565774
Log Pis Std                  2.9165065
Log Pis Max                  13.816962
Log Pis Min                  -7.9443445
Policy mu Mean               0.074883424
Policy mu Std                0.6269414
Policy mu Max                3.3246667
Policy mu Min                -2.4864857
Policy log std Mean          -1.0416262
Policy log std Std           0.3145857
Policy log std Max           -0.20797181
Policy log std Min           -3.3721175
Z mean eval                  1.128218
Z variance eval              0.00716161
total_rewards                [3269.30294797 2569.06817424 2381.12122514 3371.56388871 3293.86383472
 2027.65553908 3098.60922509 3314.7250952  3455.02183771  326.86200723]
total_rewards_mean           2710.779377507699
total_rewards_std            918.4828938481824
total_rewards_max            3455.021837713554
total_rewards_min            326.8620072268561
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               34.08755850419402
(Previous) Eval Time (s)     31.257594352122396
Sample Time (s)              26.261492431163788
Epoch Time (s)               91.6066452874802
Total Train Time (s)         34238.579223204404
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:17:00.191098 UTC | [2020_01_10_11_46_20] Iteration #386 | Epoch Duration: 92.9502375125885
2020-01-10 21:17:00.191307 UTC | [2020_01_10_11_46_20] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1287572
Z variance train             0.0071668895
KL Divergence                26.907082
KL Loss                      2.6907082
QF Loss                      1730.9436
VF Loss                      430.04642
Policy Loss                  -1216.8027
Q Predictions Mean           1216.6938
Q Predictions Std            261.736
Q Predictions Max            1421.9419
Q Predictions Min            -23.748327
V Predictions Mean           1223.9388
V Predictions Std            262.01535
V Predictions Max            1426.2548
V Predictions Min            -25.087358
Log Pis Mean                 0.13951367
Log Pis Std                  2.7003958
Log Pis Max                  11.499437
Log Pis Min                  -6.712167
Policy mu Mean               0.050132878
Policy mu Std                0.6195474
Policy mu Max                2.4959393
Policy mu Min                -2.2794845
Policy log std Mean          -1.0128102
Policy log std Std           0.29867315
Policy log std Max           -0.17293054
Policy log std Min           -2.9318602
Z mean eval                  1.0946716
Z variance eval              0.0063594216
total_rewards                [1494.95529321 3498.21856647 1508.03704635 3180.04825992 3517.60559996
  276.58309171 1913.35225338 1620.98765801 2668.98578728 3469.80049793]
total_rewards_mean           2314.8574054202522
total_rewards_std            1057.129362294427
total_rewards_max            3517.605599957366
total_rewards_min            276.58309170948013
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               34.41416121227667
(Previous) Eval Time (s)     32.600826329085976
Sample Time (s)              25.05674957577139
Epoch Time (s)               92.07173711713403
Total Train Time (s)         34321.944561146665
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:18:23.560652 UTC | [2020_01_10_11_46_20] Iteration #387 | Epoch Duration: 83.36921238899231
2020-01-10 21:18:23.560835 UTC | [2020_01_10_11_46_20] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0935371
Z variance train             0.0063599907
KL Divergence                26.197601
KL Loss                      2.6197603
QF Loss                      758.20795
VF Loss                      182.23135
Policy Loss                  -1240.9451
Q Predictions Mean           1239.9565
Q Predictions Std            201.79584
Q Predictions Max            1424.169
Q Predictions Min            -25.14567
V Predictions Mean           1237.0674
V Predictions Std            199.53502
V Predictions Max            1401.2031
V Predictions Min            -36.617985
Log Pis Mean                 -0.0025288314
Log Pis Std                  2.830185
Log Pis Max                  10.299845
Log Pis Min                  -10.131056
Policy mu Mean               0.014046548
Policy mu Std                0.6267842
Policy mu Max                2.4967875
Policy mu Min                -2.7026358
Policy log std Mean          -1.0076991
Policy log std Std           0.26678145
Policy log std Max           -0.2639146
Policy log std Min           -2.1624875
Z mean eval                  1.0981796
Z variance eval              0.008843413
total_rewards                [ 145.33607678 3367.12615975  930.9743238  1937.01601213  502.17416742
  316.18761305  317.58440759 1370.80365726  120.71801388  208.44333501]
total_rewards_mean           921.6363766678957
total_rewards_std            993.6501774929806
total_rewards_max            3367.126159751583
total_rewards_min            120.71801388315862
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               33.7157487408258
(Previous) Eval Time (s)     23.898005655035377
Sample Time (s)              26.057923966553062
Epoch Time (s)               83.67167836241424
Total Train Time (s)         34397.65910955146
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:19:39.279502 UTC | [2020_01_10_11_46_20] Iteration #388 | Epoch Duration: 75.71853399276733
2020-01-10 21:19:39.279693 UTC | [2020_01_10_11_46_20] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0974023
Z variance train             0.008863074
KL Divergence                26.19466
KL Loss                      2.619466
QF Loss                      2030.3319
VF Loss                      4302.0986
Policy Loss                  -1206.0684
Q Predictions Mean           1205.5054
Q Predictions Std            282.1766
Q Predictions Max            1484.2386
Q Predictions Min            -44.126915
V Predictions Mean           1211.5753
V Predictions Std            269.73322
V Predictions Max            1476.7911
V Predictions Min            -69.861565
Log Pis Mean                 0.40045974
Log Pis Std                  3.062948
Log Pis Max                  11.926513
Log Pis Min                  -7.5128446
Policy mu Mean               0.06819381
Policy mu Std                0.6378589
Policy mu Max                2.7803388
Policy mu Min                -2.0924206
Policy log std Mean          -0.99281144
Policy log std Std           0.32845402
Policy log std Max           -0.11027765
Policy log std Min           -2.6428878
Z mean eval                  1.1205417
Z variance eval              0.010466291
total_rewards                [ 536.15654106 3415.88435921 3453.18244221 3442.828905   3560.07945887
  564.78760446  571.13109292 2794.4571853  2068.55544276  760.38823219]
total_rewards_mean           2116.7451263977464
total_rewards_std            1300.485090257299
total_rewards_max            3560.07945887403
total_rewards_min            536.1565410567065
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               33.726213487330824
(Previous) Eval Time (s)     15.944539989810437
Sample Time (s)              25.06571179209277
Epoch Time (s)               74.73646526923403
Total Train Time (s)         34480.66221827408
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:21:02.287882 UTC | [2020_01_10_11_46_20] Iteration #389 | Epoch Duration: 83.00802683830261
2020-01-10 21:21:02.288128 UTC | [2020_01_10_11_46_20] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.117193
Z variance train             0.0103518665
KL Divergence                25.296026
KL Loss                      2.5296028
QF Loss                      674.66956
VF Loss                      339.98352
Policy Loss                  -1274.9775
Q Predictions Mean           1277.2087
Q Predictions Std            180.75742
Q Predictions Max            1468.9178
Q Predictions Min            46.325558
V Predictions Mean           1283.8501
V Predictions Std            179.80592
V Predictions Max            1496.5685
V Predictions Min            24.413153
Log Pis Mean                 0.2354966
Log Pis Std                  3.0569355
Log Pis Max                  10.346069
Log Pis Min                  -10.0919285
Policy mu Mean               0.10586446
Policy mu Std                0.59492576
Policy mu Max                2.4655437
Policy mu Min                -2.573279
Policy log std Mean          -1.0468326
Policy log std Std           0.2783453
Policy log std Max           -0.14130801
Policy log std Min           -2.5736976
Z mean eval                  1.0888971
Z variance eval              0.01841881
total_rewards                [1172.7215411  3322.59460223  763.73607431 3415.66784426  532.35228231
 3529.44179346 3364.9110272  3351.9398119  2869.64836975 3502.6720421 ]
total_rewards_mean           2582.5685388622546
total_rewards_std            1173.4762881298072
total_rewards_max            3529.441793459174
total_rewards_min            532.3522823124612
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               33.90568688837811
(Previous) Eval Time (s)     24.215714937075973
Sample Time (s)              25.96415463835001
Epoch Time (s)               84.0855564638041
Total Train Time (s)         34566.92626848025
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:22:28.564367 UTC | [2020_01_10_11_46_20] Iteration #390 | Epoch Duration: 86.27603793144226
2020-01-10 21:22:28.564802 UTC | [2020_01_10_11_46_20] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0882807
Z variance train             0.018533614
KL Divergence                24.21109
KL Loss                      2.421109
QF Loss                      11050.986
VF Loss                      769.4235
Policy Loss                  -1214.5756
Q Predictions Mean           1217.4705
Q Predictions Std            283.38223
Q Predictions Max            1419.756
Q Predictions Min            -16.419018
V Predictions Mean           1214.5093
V Predictions Std            281.26666
V Predictions Max            1412.7345
V Predictions Min            -39.828487
Log Pis Mean                 -0.036008485
Log Pis Std                  2.8770528
Log Pis Max                  14.321135
Log Pis Min                  -8.535607
Policy mu Mean               0.047304988
Policy mu Std                0.6278049
Policy mu Max                2.6857843
Policy mu Min                -2.8613882
Policy log std Mean          -0.97024506
Policy log std Std           0.29577687
Policy log std Max           -0.07148892
Policy log std Min           -2.9107058
Z mean eval                  1.0856371
Z variance eval              0.015918318
total_rewards                [2992.44814324  248.78395561 3334.05200859 3222.24881528 1004.55006612
 1697.98066761  200.25599769  458.7060959    84.61890633 1710.3630296 ]
total_rewards_mean           1495.4007685983015
total_rewards_std            1234.0368699983385
total_rewards_max            3334.052008592798
total_rewards_min            84.61890633387807
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               33.29075692407787
(Previous) Eval Time (s)     26.40583058493212
Sample Time (s)              24.22214835882187
Epoch Time (s)               83.91873586783186
Total Train Time (s)         34642.10627142666
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:23:43.739916 UTC | [2020_01_10_11_46_20] Iteration #391 | Epoch Duration: 75.17470526695251
2020-01-10 21:23:43.740116 UTC | [2020_01_10_11_46_20] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0846484
Z variance train             0.015932577
KL Divergence                24.719482
KL Loss                      2.4719484
QF Loss                      581.55115
VF Loss                      115.98253
Policy Loss                  -1256.6926
Q Predictions Mean           1257.0007
Q Predictions Std            242.4513
Q Predictions Max            1456.2946
Q Predictions Min            -22.854088
V Predictions Mean           1256.6672
V Predictions Std            244.02528
V Predictions Max            1454.1449
V Predictions Min            -18.671013
Log Pis Mean                 -0.057413623
Log Pis Std                  2.6334689
Log Pis Max                  15.39108
Log Pis Min                  -9.205432
Policy mu Mean               0.092270315
Policy mu Std                0.6272925
Policy mu Max                2.8328273
Policy mu Min                -2.559144
Policy log std Mean          -0.9861279
Policy log std Std           0.27864292
Policy log std Max           -1.9967556e-05
Policy log std Min           -2.201539
Z mean eval                  1.0953138
Z variance eval              0.0114471195
total_rewards                [2560.81825012  772.42847445 2993.21334751 3285.29252537 1394.47524625
 3224.76300154 1686.49439344 2542.93572683  290.999334   3290.99176335]
total_rewards_mean           2204.2412062859175
total_rewards_std            1043.545231485805
total_rewards_max            3290.991763351771
total_rewards_min            290.99933400171415
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               33.82202310208231
(Previous) Eval Time (s)     17.66145824594423
Sample Time (s)              24.19733376521617
Epoch Time (s)               75.68081511324272
Total Train Time (s)         34722.69279943453
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:25:04.330254 UTC | [2020_01_10_11_46_20] Iteration #392 | Epoch Duration: 80.59000706672668
2020-01-10 21:25:04.330444 UTC | [2020_01_10_11_46_20] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0946891
Z variance train             0.011451731
KL Divergence                24.781326
KL Loss                      2.4781327
QF Loss                      661.70087
VF Loss                      125.53141
Policy Loss                  -1254.7817
Q Predictions Mean           1255.6995
Q Predictions Std            228.64485
Q Predictions Max            1457.6514
Q Predictions Min            -31.504967
V Predictions Mean           1255.0974
V Predictions Std            226.12103
V Predictions Max            1460.8313
V Predictions Min            -6.0038304
Log Pis Mean                 0.25025886
Log Pis Std                  2.820601
Log Pis Max                  9.740047
Log Pis Min                  -7.335588
Policy mu Mean               0.026127882
Policy mu Std                0.6491814
Policy mu Max                2.181541
Policy mu Min                -2.1154041
Policy log std Mean          -0.9860301
Policy log std Std           0.2854782
Policy log std Max           -0.16343021
Policy log std Min           -2.417109
Z mean eval                  1.0933497
Z variance eval              0.00952307
total_rewards                [ 431.32528269  303.48529492 3306.71362617 2934.19839666 3358.83365388
 3227.95967168 3425.98516894 3422.97541427 2979.61843827  994.22602113]
total_rewards_mean           2438.5320968620827
total_rewards_std            1240.1558702698414
total_rewards_max            3425.98516893857
total_rewards_min            303.48529492392686
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               34.189552719239146
(Previous) Eval Time (s)     22.570304607972503
Sample Time (s)              25.720774007961154
Epoch Time (s)               82.4806313351728
Total Train Time (s)         34807.71873162547
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:26:29.360391 UTC | [2020_01_10_11_46_20] Iteration #393 | Epoch Duration: 85.02981662750244
2020-01-10 21:26:29.360568 UTC | [2020_01_10_11_46_20] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0921122
Z variance train             0.00954726
KL Divergence                24.718302
KL Loss                      2.4718301
QF Loss                      484.9592
VF Loss                      141.18497
Policy Loss                  -1236.8544
Q Predictions Mean           1237.5571
Q Predictions Std            278.8206
Q Predictions Max            1465.0088
Q Predictions Min            -37.169502
V Predictions Mean           1242.584
V Predictions Std            279.77667
V Predictions Max            1452.7834
V Predictions Min            -26.408724
Log Pis Mean                 -0.18375093
Log Pis Std                  2.496876
Log Pis Max                  7.0889626
Log Pis Min                  -7.590555
Policy mu Mean               0.016493503
Policy mu Std                0.61134785
Policy mu Max                2.4179
Policy mu Min                -2.1063807
Policy log std Mean          -0.95577633
Policy log std Std           0.28441596
Policy log std Max           -0.033352077
Policy log std Min           -2.420031
Z mean eval                  1.0903037
Z variance eval              0.014854583
total_rewards                [ 808.244128   3324.56139019 3080.58529273 3149.75396206 2050.59737458
 2616.76124489 3256.46977198 1478.74120332 3381.2962569  3236.35001316]
total_rewards_mean           2638.336063780692
total_rewards_std            852.0291446088443
total_rewards_max            3381.2962568996036
total_rewards_min            808.2441280000503
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               34.142593406606466
(Previous) Eval Time (s)     25.119159270077944
Sample Time (s)              26.078361029736698
Epoch Time (s)               85.3401137064211
Total Train Time (s)         34901.356829593424
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:28:03.002520 UTC | [2020_01_10_11_46_20] Iteration #394 | Epoch Duration: 93.64180636405945
2020-01-10 21:28:03.002702 UTC | [2020_01_10_11_46_20] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0881652
Z variance train             0.014893127
KL Divergence                24.336159
KL Loss                      2.433616
QF Loss                      943.937
VF Loss                      165.28758
Policy Loss                  -1247.9741
Q Predictions Mean           1245.4714
Q Predictions Std            227.80704
Q Predictions Max            1420.3428
Q Predictions Min            67.16496
V Predictions Mean           1247.8176
V Predictions Std            227.5415
V Predictions Max            1415.6221
V Predictions Min            59.088562
Log Pis Mean                 0.15964079
Log Pis Std                  2.7099333
Log Pis Max                  9.792325
Log Pis Min                  -5.976277
Policy mu Mean               0.020572815
Policy mu Std                0.6154262
Policy mu Max                2.3809686
Policy mu Min                -2.0485992
Policy log std Mean          -0.9903343
Policy log std Std           0.28530434
Policy log std Max           -0.18238866
Policy log std Min           -2.1222196
Z mean eval                  1.0978595
Z variance eval              0.016039105
total_rewards                [ 420.8809598  3495.00900796 3344.08473763 2324.71245723 3234.01557625
 3551.82118645 2061.52925692   13.4448826  3407.4359587  3600.40427557]
total_rewards_mean           2545.3338299099287
total_rewards_std            1268.4668431831187
total_rewards_max            3600.4042755701694
total_rewards_min            13.44488259657781
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               34.16915951902047
(Previous) Eval Time (s)     33.420486447867006
Sample Time (s)              24.694050957914442
Epoch Time (s)               92.28369692480192
Total Train Time (s)         34989.2812602832
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:29:30.931270 UTC | [2020_01_10_11_46_20] Iteration #395 | Epoch Duration: 87.9284393787384
2020-01-10 21:29:30.931455 UTC | [2020_01_10_11_46_20] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0981075
Z variance train             0.016159575
KL Divergence                24.562502
KL Loss                      2.4562502
QF Loss                      3299.1323
VF Loss                      344.08752
Policy Loss                  -1259.1184
Q Predictions Mean           1254.9855
Q Predictions Std            218.02997
Q Predictions Max            1437.5408
Q Predictions Min            -27.764938
V Predictions Mean           1247.1833
V Predictions Std            212.54651
V Predictions Max            1437.3834
V Predictions Min            -31.883656
Log Pis Mean                 0.2030462
Log Pis Std                  2.917613
Log Pis Max                  11.113117
Log Pis Min                  -7.5566616
Policy mu Mean               0.04887648
Policy mu Std                0.65086955
Policy mu Max                3.5235238
Policy mu Min                -2.2123582
Policy log std Mean          -0.9756328
Policy log std Std           0.27685422
Policy log std Max           -0.17967749
Policy log std Min           -2.5284023
Z mean eval                  1.1126584
Z variance eval              0.013818135
total_rewards                [ 530.45113041 3367.37050357 3544.8438773  3451.4602957  3489.02643709
 1414.16708541 3440.98108679 3524.37344539 2663.29060855 2488.97164713]
total_rewards_mean           2791.4936117337706
total_rewards_std            994.8629416138804
total_rewards_max            3544.8438772987374
total_rewards_min            530.4511304118738
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               34.71557116787881
(Previous) Eval Time (s)     29.064822903834283
Sample Time (s)              24.71599368005991
Epoch Time (s)               88.496387751773
Total Train Time (s)         35075.12695635436
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:30:56.781149 UTC | [2020_01_10_11_46_20] Iteration #396 | Epoch Duration: 85.84956669807434
2020-01-10 21:30:56.781325 UTC | [2020_01_10_11_46_20] Iteration #396 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1116307
Z variance train             0.013816441
KL Divergence                24.699394
KL Loss                      2.4699395
QF Loss                      551.22394
VF Loss                      105.23325
Policy Loss                  -1262.8596
Q Predictions Mean           1262.5643
Q Predictions Std            222.40454
Q Predictions Max            1474.2083
Q Predictions Min            -43.3157
V Predictions Mean           1264.0619
V Predictions Std            220.7578
V Predictions Max            1475.6947
V Predictions Min            42.163475
Log Pis Mean                 0.25089204
Log Pis Std                  2.8293412
Log Pis Max                  13.707119
Log Pis Min                  -9.145335
Policy mu Mean               0.058861844
Policy mu Std                0.63664514
Policy mu Max                2.513959
Policy mu Min                -2.3113043
Policy log std Mean          -0.9794928
Policy log std Std           0.26813132
Policy log std Max           -0.2325015
Policy log std Min           -3.0489469
Z mean eval                  1.0646012
Z variance eval              0.014536381
total_rewards                [3298.75630148 3375.01435873 3397.58303405 1340.25006306 3205.4823412
 2919.92783581 3469.78915805 1496.69513079 3412.72119772 3412.17348122]
total_rewards_mean           2932.8392902102496
total_rewards_std            772.4710546148239
total_rewards_max            3469.7891580451837
total_rewards_min            1340.2500630630545
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               34.58913631271571
(Previous) Eval Time (s)     26.417695119045675
Sample Time (s)              26.520005341153592
Epoch Time (s)               87.52683677291498
Total Train Time (s)         35167.31260576332
Epoch                        397
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:32:28.971358 UTC | [2020_01_10_11_46_20] Iteration #397 | Epoch Duration: 92.18989157676697
2020-01-10 21:32:28.971564 UTC | [2020_01_10_11_46_20] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0653608
Z variance train             0.014476389
KL Divergence                24.992199
KL Loss                      2.49922
QF Loss                      4856.2354
VF Loss                      142.81969
Policy Loss                  -1265.2323
Q Predictions Mean           1266.4517
Q Predictions Std            183.42673
Q Predictions Max            1444.4406
Q Predictions Min            14.523141
V Predictions Mean           1261.6304
V Predictions Std            183.8567
V Predictions Max            1443.8828
V Predictions Min            27.029572
Log Pis Mean                 0.1505605
Log Pis Std                  2.5839574
Log Pis Max                  11.118704
Log Pis Min                  -8.504392
Policy mu Mean               -0.0083240885
Policy mu Std                0.6273681
Policy mu Max                2.3885813
Policy mu Min                -2.3047245
Policy log std Mean          -0.9940599
Policy log std Std           0.29240644
Policy log std Max           -0.085006595
Policy log std Min           -2.36163
Z mean eval                  1.1057843
Z variance eval              0.014224802
total_rewards                [ 987.30725402  861.47120381 2020.96757332  552.13302333 1388.60458478
 3332.37949835 3519.43044532 2257.27889396 1105.79684838 3219.95202626]
total_rewards_mean           1924.5321351536727
total_rewards_std            1057.042187620043
total_rewards_max            3519.4304453207374
total_rewards_min            552.13302332562
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               34.46684696897864
(Previous) Eval Time (s)     31.080419058911502
Sample Time (s)              25.913257889915258
Epoch Time (s)               91.4605239178054
Total Train Time (s)         35249.84949183883
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:33:51.512192 UTC | [2020_01_10_11_46_20] Iteration #398 | Epoch Duration: 82.54040217399597
2020-01-10 21:33:51.512757 UTC | [2020_01_10_11_46_20] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.104253
Z variance train             0.014205883
KL Divergence                24.291077
KL Loss                      2.4291077
QF Loss                      3617.8728
VF Loss                      1235.7157
Policy Loss                  -1241.816
Q Predictions Mean           1240.3953
Q Predictions Std            286.67136
Q Predictions Max            1477.7416
Q Predictions Min            -29.979673
V Predictions Mean           1242.9983
V Predictions Std            288.19278
V Predictions Max            1485.9865
V Predictions Min            -37.807976
Log Pis Mean                 0.5219686
Log Pis Std                  3.315071
Log Pis Max                  17.65418
Log Pis Min                  -6.8302155
Policy mu Mean               0.079843156
Policy mu Std                0.65739524
Policy mu Max                2.4914882
Policy mu Min                -2.4102037
Policy log std Mean          -1.0286067
Policy log std Std           0.34527102
Policy log std Max           -0.081394374
Policy log std Min           -3.3936749
Z mean eval                  1.0799326
Z variance eval              0.012693253
total_rewards                [3135.09596884 3661.39039614 3525.69408992 1018.15387494 3370.21387176
 3407.41605755 3801.32980749 3696.39861803 3743.10542708 3434.83327351]
total_rewards_mean           3279.363138527425
total_rewards_std            777.8657459150002
total_rewards_max            3801.3298074905915
total_rewards_min            1018.1538749441472
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               33.62919565103948
(Previous) Eval Time (s)     22.159889839123935
Sample Time (s)              25.816682441625744
Epoch Time (s)               81.60576793178916
Total Train Time (s)         35341.893287837505
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:35:23.559242 UTC | [2020_01_10_11_46_20] Iteration #399 | Epoch Duration: 92.04615926742554
2020-01-10 21:35:23.559422 UTC | [2020_01_10_11_46_20] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0798236
Z variance train             0.012755064
KL Divergence                24.789387
KL Loss                      2.4789388
QF Loss                      1105.0576
VF Loss                      428.2076
Policy Loss                  -1238.3943
Q Predictions Mean           1239.4089
Q Predictions Std            284.60294
Q Predictions Max            1460.2515
Q Predictions Min            -10.123538
V Predictions Mean           1228.0859
V Predictions Std            279.8742
V Predictions Max            1448.1165
V Predictions Min            -13.512671
Log Pis Mean                 0.07249568
Log Pis Std                  2.6085777
Log Pis Max                  10.192814
Log Pis Min                  -8.531792
Policy mu Mean               -0.010347793
Policy mu Std                0.6059306
Policy mu Max                2.1970077
Policy mu Min                -2.5531464
Policy log std Mean          -1.009372
Policy log std Std           0.2857188
Policy log std Max           -0.07370794
Policy log std Min           -2.309172
Z mean eval                  1.1476951
Z variance eval              0.010369355
total_rewards                [3318.36683914 2797.23734296 3403.00305015 3475.619968   3352.33689612
 3088.67397683 3271.62224287 2674.35505219 3242.02027761 3296.17053347]
total_rewards_mean           3191.940617935218
total_rewards_std            249.1590617803169
total_rewards_max            3475.619968003648
total_rewards_min            2674.3550521921015
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               34.20772580103949
(Previous) Eval Time (s)     32.599926262162626
Sample Time (s)              24.791362962219864
Epoch Time (s)               91.59901502542198
Total Train Time (s)         35434.51659814129
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:36:56.186798 UTC | [2020_01_10_11_46_20] Iteration #400 | Epoch Duration: 92.62724232673645
2020-01-10 21:36:56.186987 UTC | [2020_01_10_11_46_20] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1482111
Z variance train             0.010407159
KL Divergence                25.046574
KL Loss                      2.5046575
QF Loss                      753.631
VF Loss                      226.40912
Policy Loss                  -1244.9728
Q Predictions Mean           1244.4991
Q Predictions Std            281.96585
Q Predictions Max            1435.5391
Q Predictions Min            -56.26765
V Predictions Mean           1248.5383
V Predictions Std            278.53506
V Predictions Max            1424.5554
V Predictions Min            -9.922816
Log Pis Mean                 0.32535493
Log Pis Std                  2.7712789
Log Pis Max                  14.489977
Log Pis Min                  -9.391398
Policy mu Mean               0.043654926
Policy mu Std                0.6695889
Policy mu Max                2.5702932
Policy mu Min                -2.312271
Policy log std Mean          -0.9658928
Policy log std Std           0.2704544
Policy log std Max           -0.10229939
Policy log std Min           -2.847035
Z mean eval                  1.0929716
Z variance eval              0.010566334
total_rewards                [2221.4203736  3067.05815119 2945.96477561 3244.88824262 3329.5228316
  411.32812737 2905.08918462 3598.17942257  105.83425749 3307.29832604]
total_rewards_mean           2513.658369272526
total_rewards_std            1181.3362315951326
total_rewards_max            3598.1794225704075
total_rewards_min            105.83425748856106
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               34.263850613031536
(Previous) Eval Time (s)     33.62783363787457
Sample Time (s)              25.135801101103425
Epoch Time (s)               93.02748535200953
Total Train Time (s)         35523.01602582494
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:38:24.690219 UTC | [2020_01_10_11_46_20] Iteration #401 | Epoch Duration: 88.50309777259827
2020-01-10 21:38:24.690400 UTC | [2020_01_10_11_46_20] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0932531
Z variance train             0.01057905
KL Divergence                25.384754
KL Loss                      2.5384755
QF Loss                      507.2421
VF Loss                      1172.6766
Policy Loss                  -1241.1558
Q Predictions Mean           1242.8169
Q Predictions Std            273.6737
Q Predictions Max            1447.5354
Q Predictions Min            -51.695942
V Predictions Mean           1245.3671
V Predictions Std            262.45682
V Predictions Max            1449.6445
V Predictions Min            -31.251072
Log Pis Mean                 -0.21920982
Log Pis Std                  2.8889241
Log Pis Max                  10.371698
Log Pis Min                  -7.68886
Policy mu Mean               0.027151627
Policy mu Std                0.611594
Policy mu Max                2.6279318
Policy mu Min                -2.0977108
Policy log std Mean          -0.96913
Policy log std Std           0.30705917
Policy log std Max           -0.05681491
Policy log std Min           -2.6286395
Z mean eval                  1.0845437
Z variance eval              0.011358271
total_rewards                [ 625.48905147 3303.48690777 1877.29345934  249.02084641 3206.43895809
 2088.36498308 3267.02561518 2522.79788041 1642.15996228 2120.75305908]
total_rewards_mean           2090.283072311892
total_rewards_std            1003.6153986105895
total_rewards_max            3303.4869077694884
total_rewards_min            249.02084641253737
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               33.96653025597334
(Previous) Eval Time (s)     29.10316904494539
Sample Time (s)              25.068185346201062
Epoch Time (s)               88.13788464711979
Total Train Time (s)         35604.899262637366
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:39:46.579013 UTC | [2020_01_10_11_46_20] Iteration #402 | Epoch Duration: 81.8884813785553
2020-01-10 21:39:46.579240 UTC | [2020_01_10_11_46_20] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0843161
Z variance train             0.011351532
KL Divergence                25.225002
KL Loss                      2.5225003
QF Loss                      853.6387
VF Loss                      183.12463
Policy Loss                  -1273.6895
Q Predictions Mean           1273.5039
Q Predictions Std            221.03372
Q Predictions Max            1480.0668
Q Predictions Min            -45.611443
V Predictions Mean           1276.2156
V Predictions Std            221.52982
V Predictions Max            1489.9265
V Predictions Min            -45.174057
Log Pis Mean                 0.4074651
Log Pis Std                  2.8594885
Log Pis Max                  14.014622
Log Pis Min                  -7.620594
Policy mu Mean               0.036781795
Policy mu Std                0.61135477
Policy mu Max                2.3066368
Policy mu Min                -2.083688
Policy log std Mean          -1.0326976
Policy log std Std           0.29232958
Policy log std Max           -0.080742
Policy log std Min           -2.5346546
Z mean eval                  1.1005083
Z variance eval              0.0114199035
total_rewards                [3536.46649679  254.7276837  3462.29572377 3412.73459738 3857.0310477
 1506.85804068  461.81924681 3425.87900434  388.17232471 1587.48809782]
total_rewards_mean           2189.3472263695157
total_rewards_std            1415.6746678456705
total_rewards_max            3857.0310476955947
total_rewards_min            254.72768370005946
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               34.05999727221206
(Previous) Eval Time (s)     22.853437122888863
Sample Time (s)              23.851573172025383
Epoch Time (s)               80.7650075671263
Total Train Time (s)         35684.5412680516
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:41:06.224312 UTC | [2020_01_10_11_46_20] Iteration #403 | Epoch Duration: 79.64490723609924
2020-01-10 21:41:06.224524 UTC | [2020_01_10_11_46_20] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0982602
Z variance train             0.011436025
KL Divergence                25.523083
KL Loss                      2.5523083
QF Loss                      1069.981
VF Loss                      832.19464
Policy Loss                  -1246.5016
Q Predictions Mean           1244.5455
Q Predictions Std            270.65613
Q Predictions Max            1477.4324
Q Predictions Min            -46.793983
V Predictions Mean           1234.6854
V Predictions Std            265.2606
V Predictions Max            1456.4316
V Predictions Min            -43.48323
Log Pis Mean                 0.40960926
Log Pis Std                  3.2858543
Log Pis Max                  17.585443
Log Pis Min                  -9.734488
Policy mu Mean               0.0630403
Policy mu Std                0.61693406
Policy mu Max                2.9677193
Policy mu Min                -2.9679277
Policy log std Mean          -1.0402143
Policy log std Std           0.32729253
Policy log std Max           0.055436373
Policy log std Min           -2.8554862
Z mean eval                  1.0844398
Z variance eval              0.015565802
total_rewards                [3440.77680349 3603.29480782 3259.85622545 3568.12120472 3333.75796379
   25.84235965 3439.71673468 3525.97149095 3568.39603572 3379.94117064]
total_rewards_mean           3114.5674796931567
total_rewards_std            1034.974053465877
total_rewards_max            3603.294807820017
total_rewards_min            25.842359645671785
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               34.51767754787579
(Previous) Eval Time (s)     21.73301933472976
Sample Time (s)              26.109754006378353
Epoch Time (s)               82.3604508889839
Total Train Time (s)         35779.40759163024
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:42:41.094988 UTC | [2020_01_10_11_46_20] Iteration #404 | Epoch Duration: 94.8702826499939
2020-01-10 21:42:41.095208 UTC | [2020_01_10_11_46_20] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0851957
Z variance train             0.015625883
KL Divergence                25.279266
KL Loss                      2.5279267
QF Loss                      1707.1804
VF Loss                      152.29349
Policy Loss                  -1275.0624
Q Predictions Mean           1274.7717
Q Predictions Std            170.42264
Q Predictions Max            1441.8535
Q Predictions Min            47.218014
V Predictions Mean           1275.3425
V Predictions Std            168.40681
V Predictions Max            1427.2445
V Predictions Min            48.20466
Log Pis Mean                 0.4395644
Log Pis Std                  2.733992
Log Pis Max                  12.490415
Log Pis Min                  -8.35063
Policy mu Mean               -0.01735824
Policy mu Std                0.59413165
Policy mu Max                2.4633582
Policy mu Min                -2.0703704
Policy log std Mean          -1.0674746
Policy log std Std           0.2995677
Policy log std Max           0.0010560155
Policy log std Min           -2.4240088
Z mean eval                  1.1049752
Z variance eval              0.016656173
total_rewards                [3392.91502152 3365.59424469 1888.32841571 3384.61804991 3145.09333186
  671.50139582 1387.16764153 3676.37258368 3427.41379445  455.88813627]
total_rewards_mean           2479.4892615442523
total_rewards_std            1188.2476792752598
total_rewards_max            3676.3725836774993
total_rewards_min            455.8881362662929
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               34.44694171193987
(Previous) Eval Time (s)     34.24247696297243
Sample Time (s)              26.023092543240637
Epoch Time (s)               94.71251121815294
Total Train Time (s)         35870.010696871206
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:44:11.702090 UTC | [2020_01_10_11_46_20] Iteration #405 | Epoch Duration: 90.60673594474792
2020-01-10 21:44:11.702259 UTC | [2020_01_10_11_46_20] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1058038
Z variance train             0.0166069
KL Divergence                25.209156
KL Loss                      2.5209157
QF Loss                      664.51544
VF Loss                      163.05817
Policy Loss                  -1289.4617
Q Predictions Mean           1289.292
Q Predictions Std            225.21759
Q Predictions Max            1460.57
Q Predictions Min            -86.54713
V Predictions Mean           1285.9307
V Predictions Std            225.77034
V Predictions Max            1455.6401
V Predictions Min            -62.56807
Log Pis Mean                 0.38110125
Log Pis Std                  2.434336
Log Pis Max                  8.8315
Log Pis Min                  -7.780755
Policy mu Mean               0.0037901443
Policy mu Std                0.61329097
Policy mu Max                2.402979
Policy mu Min                -1.9195366
Policy log std Mean          -1.015738
Policy log std Std           0.26659226
Policy log std Max           -0.15626013
Policy log std Min           -2.6237116
Z mean eval                  1.0994008
Z variance eval              0.01875871
total_rewards                [1990.68514507 1789.58112112  635.78713196   58.05109168 3437.06357261
  166.83959728 3448.22905485 2370.37476295  848.43445302 2757.52212898]
total_rewards_mean           1750.256805953506
total_rewards_std            1208.8426354269168
total_rewards_max            3448.22905485113
total_rewards_min            58.05109167934359
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               34.06031585019082
(Previous) Eval Time (s)     30.136381544172764
Sample Time (s)              25.33963664760813
Epoch Time (s)               89.53633404197171
Total Train Time (s)         35950.352484449744
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:45:32.048081 UTC | [2020_01_10_11_46_20] Iteration #406 | Epoch Duration: 80.34568953514099
2020-01-10 21:45:32.048252 UTC | [2020_01_10_11_46_20] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0995443
Z variance train             0.01871666
KL Divergence                25.549688
KL Loss                      2.5549688
QF Loss                      974.5982
VF Loss                      141.54002
Policy Loss                  -1264.632
Q Predictions Mean           1266.0842
Q Predictions Std            240.19289
Q Predictions Max            1475.2994
Q Predictions Min            -51.78605
V Predictions Mean           1260.7031
V Predictions Std            240.47441
V Predictions Max            1480.4836
V Predictions Min            -46.71459
Log Pis Mean                 0.16604963
Log Pis Std                  2.6189303
Log Pis Max                  9.636695
Log Pis Min                  -6.618947
Policy mu Mean               0.04112935
Policy mu Std                0.59753215
Policy mu Max                2.1896663
Policy mu Min                -1.9760069
Policy log std Mean          -1.020648
Policy log std Std           0.2924319
Policy log std Max           -0.13568562
Policy log std Min           -2.3479118
Z mean eval                  1.100873
Z variance eval              0.022373596
total_rewards                [1680.03011217  355.81651083 2258.80262624 3171.63368658 3264.97116434
  132.0418547  1316.057238   3459.95691482  404.59919766 2683.88290628]
total_rewards_mean           1872.779221161781
total_rewards_std            1215.945896330118
total_rewards_max            3459.9569148209757
total_rewards_min            132.0418547021236
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               33.91403082292527
(Previous) Eval Time (s)     20.945442819036543
Sample Time (s)              26.277349019423127
Epoch Time (s)               81.13682266138494
Total Train Time (s)         36033.98172595026
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:46:55.681078 UTC | [2020_01_10_11_46_20] Iteration #407 | Epoch Duration: 83.63267135620117
2020-01-10 21:46:55.681509 UTC | [2020_01_10_11_46_20] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0982071
Z variance train             0.022545638
KL Divergence                25.447472
KL Loss                      2.544747
QF Loss                      3818.3762
VF Loss                      369.23828
Policy Loss                  -1283.3767
Q Predictions Mean           1282.4316
Q Predictions Std            200.30724
Q Predictions Max            1452.1713
Q Predictions Min            -9.827599
V Predictions Mean           1272.2938
V Predictions Std            199.96097
V Predictions Max            1441.1449
V Predictions Min            4.161091
Log Pis Mean                 0.17595455
Log Pis Std                  3.096001
Log Pis Max                  14.299606
Log Pis Min                  -12.88576
Policy mu Mean               0.06532092
Policy mu Std                0.6372094
Policy mu Max                3.005652
Policy mu Min                -2.5412161
Policy log std Mean          -1.0159888
Policy log std Std           0.2781164
Policy log std Max           -0.1870594
Policy log std Min           -2.846805
Z mean eval                  1.1361167
Z variance eval              0.023402527
total_rewards                [ 117.42891709 3542.01539639  358.95342646 3369.59722001 1217.59388711
 3383.36611875 3766.04531073 3452.71227739 3397.62590544 3315.89196084]
total_rewards_mean           2592.123042022303
total_rewards_std            1357.3760999140493
total_rewards_max            3766.0453107300464
total_rewards_min            117.42891709375508
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               33.93163830880076
(Previous) Eval Time (s)     23.440929416101426
Sample Time (s)              23.82231360534206
Epoch Time (s)               81.19488133024424
Total Train Time (s)         36123.067092270125
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:48:24.772068 UTC | [2020_01_10_11_46_20] Iteration #408 | Epoch Duration: 89.09038805961609
2020-01-10 21:48:24.772285 UTC | [2020_01_10_11_46_20] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1396229
Z variance train             0.02342635
KL Divergence                25.264454
KL Loss                      2.5264454
QF Loss                      734.8014
VF Loss                      149.82698
Policy Loss                  -1260.4598
Q Predictions Mean           1262.6309
Q Predictions Std            268.28864
Q Predictions Max            1508.2863
Q Predictions Min            5.572038
V Predictions Mean           1267.287
V Predictions Std            266.11246
V Predictions Max            1520.6736
V Predictions Min            4.9591208
Log Pis Mean                 0.13157842
Log Pis Std                  2.6460252
Log Pis Max                  7.7879114
Log Pis Min                  -6.827581
Policy mu Mean               -0.024937931
Policy mu Std                0.6265157
Policy mu Max                3.1551254
Policy mu Min                -2.3416839
Policy log std Mean          -1.0125992
Policy log std Std           0.30039582
Policy log std Max           -0.13974768
Policy log std Min           -2.5640235
Z mean eval                  1.0793844
Z variance eval              0.032076623
total_rewards                [1043.0096055  3119.40225018 3803.6052819  1776.71021006 2083.32022707
 3691.98816236 1615.79336585 2022.22255525 1063.3659879  3761.2072224 ]
total_rewards_mean           2398.0624868460595
total_rewards_std            1043.274357782374
total_rewards_max            3803.6052819032357
total_rewards_min            1043.0096055010426
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               33.903217901010066
(Previous) Eval Time (s)     31.336064983159304
Sample Time (s)              25.877953103743494
Epoch Time (s)               91.11723598791286
Total Train Time (s)         36208.34836170403
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:49:50.057569 UTC | [2020_01_10_11_46_20] Iteration #409 | Epoch Duration: 85.28510642051697
2020-01-10 21:49:50.057765 UTC | [2020_01_10_11_46_20] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0777352
Z variance train             0.032135732
KL Divergence                25.031303
KL Loss                      2.5031304
QF Loss                      1540.1016
VF Loss                      325.7401
Policy Loss                  -1281.848
Q Predictions Mean           1281.3418
Q Predictions Std            243.92203
Q Predictions Max            1489.7361
Q Predictions Min            -52.917038
V Predictions Mean           1270.6592
V Predictions Std            245.62091
V Predictions Max            1475.5997
V Predictions Min            -58.05798
Log Pis Mean                 0.36582583
Log Pis Std                  3.1329105
Log Pis Max                  14.290715
Log Pis Min                  -6.800467
Policy mu Mean               0.06521995
Policy mu Std                0.63187057
Policy mu Max                3.552794
Policy mu Min                -2.5278475
Policy log std Mean          -1.0270674
Policy log std Std           0.31715316
Policy log std Max           -0.09556377
Policy log std Min           -2.8854449
Z mean eval                  1.0781515
Z variance eval              0.025312554
total_rewards                [ 125.55184531 3518.80521971 3185.96988485 3695.42137211 1754.26996416
 1849.68310687  869.81786421 1522.61433167  490.30777941  902.29071251]
total_rewards_mean           1791.4732080814192
total_rewards_std            1214.0342904288684
total_rewards_max            3695.4213721063566
total_rewards_min            125.55184530510435
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               33.68564436677843
(Previous) Eval Time (s)     25.503663264680654
Sample Time (s)              26.138953674118966
Epoch Time (s)               85.32826130557805
Total Train Time (s)         36291.08295182418
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:51:12.796812 UTC | [2020_01_10_11_46_20] Iteration #410 | Epoch Duration: 82.7389121055603
2020-01-10 21:51:12.796999 UTC | [2020_01_10_11_46_20] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0773698
Z variance train             0.025333304
KL Divergence                25.141888
KL Loss                      2.5141888
QF Loss                      566.40894
VF Loss                      489.10773
Policy Loss                  -1275.3906
Q Predictions Mean           1272.5166
Q Predictions Std            277.15942
Q Predictions Max            1496.9652
Q Predictions Min            -49.966213
V Predictions Mean           1267.2998
V Predictions Std            269.72403
V Predictions Max            1475.9116
V Predictions Min            -60.713474
Log Pis Mean                 0.13119675
Log Pis Std                  2.738266
Log Pis Max                  12.381573
Log Pis Min                  -7.681198
Policy mu Mean               0.020970356
Policy mu Std                0.6005226
Policy mu Max                2.6390598
Policy mu Min                -2.245983
Policy log std Mean          -1.0225223
Policy log std Std           0.27141932
Policy log std Max           -0.1342786
Policy log std Min           -2.1761847
Z mean eval                  1.0855925
Z variance eval              0.022185499
total_rewards                [3689.45435693 1117.52703643 1375.89007972 3467.52711398 3519.00202452
 3427.82286505 3463.0198725  1014.33817353 3674.91648266 3648.57347108]
total_rewards_mean           2839.8071476401096
total_rewards_std            1100.2065491332992
total_rewards_max            3689.454356926614
total_rewards_min            1014.3381735347908
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               34.25666774995625
(Previous) Eval Time (s)     22.913985279388726
Sample Time (s)              25.36922076018527
Epoch Time (s)               82.53987378953025
Total Train Time (s)         36378.28988374164
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:52:40.007073 UTC | [2020_01_10_11_46_20] Iteration #411 | Epoch Duration: 87.20993971824646
2020-01-10 21:52:40.007274 UTC | [2020_01_10_11_46_20] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0828017
Z variance train             0.022235662
KL Divergence                25.219868
KL Loss                      2.5219867
QF Loss                      824.9491
VF Loss                      427.35553
Policy Loss                  -1249.9576
Q Predictions Mean           1247.0665
Q Predictions Std            263.21167
Q Predictions Max            1443.6895
Q Predictions Min            -76.301895
V Predictions Mean           1238.8379
V Predictions Std            256.0687
V Predictions Max            1431.3665
V Predictions Min            -30.660675
Log Pis Mean                 0.26640657
Log Pis Std                  3.442742
Log Pis Max                  32.242447
Log Pis Min                  -7.9963202
Policy mu Mean               0.029733267
Policy mu Std                0.6664308
Policy mu Max                3.8461137
Policy mu Min                -4.3532863
Policy log std Mean          -0.9767051
Policy log std Std           0.28031942
Policy log std Max           1.5181643
Policy log std Min           -2.4776442
Z mean eval                  1.10765
Z variance eval              0.020600775
total_rewards                [3702.15204268 3558.39843495 3375.78110686  228.47711663 3378.9554471
 3562.8737607  3592.26410634 3584.35286579 3769.69958761 3432.37577495]
total_rewards_mean           3218.5330243605445
total_rewards_std            1004.0854256431668
total_rewards_max            3769.699587612454
total_rewards_min            228.47711662597632
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               34.31019952800125
(Previous) Eval Time (s)     27.583753334823996
Sample Time (s)              24.701413112226874
Epoch Time (s)               86.59536597505212
Total Train Time (s)         36468.98121742299
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:54:10.703089 UTC | [2020_01_10_11_46_20] Iteration #412 | Epoch Duration: 90.69567441940308
2020-01-10 21:54:10.703402 UTC | [2020_01_10_11_46_20] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1081069
Z variance train             0.020628769
KL Divergence                25.650644
KL Loss                      2.5650644
QF Loss                      754.6961
VF Loss                      180.88211
Policy Loss                  -1294.8611
Q Predictions Mean           1294.1274
Q Predictions Std            212.77007
Q Predictions Max            1476.4736
Q Predictions Min            -38.221737
V Predictions Mean           1298.7922
V Predictions Std            207.4283
V Predictions Max            1490.3706
V Predictions Min            -32.34046
Log Pis Mean                 0.3335133
Log Pis Std                  2.7584102
Log Pis Max                  10.67371
Log Pis Min                  -6.658517
Policy mu Mean               0.09447921
Policy mu Std                0.61954045
Policy mu Max                2.2797291
Policy mu Min                -1.867624
Policy log std Mean          -1.0019052
Policy log std Std           0.27924845
Policy log std Max           -0.11556852
Policy log std Min           -2.9039538
Z mean eval                  1.1012003
Z variance eval              0.028713271
total_rewards                [3468.07644246 3710.18179012 1610.31814579 3745.64255634 1803.32117032
 2546.3854929  2003.68511294 3598.92717464  255.74974624 3780.99694549]
total_rewards_mean           2652.3284577222053
total_rewards_std            1145.9461739961341
total_rewards_max            3780.996945490866
total_rewards_min            255.7497462360989
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               34.370256814174354
(Previous) Eval Time (s)     31.683652179315686
Sample Time (s)              24.642462647054344
Epoch Time (s)               90.69637164054438
Total Train Time (s)         36552.80025831424
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:55:34.525833 UTC | [2020_01_10_11_46_20] Iteration #413 | Epoch Duration: 83.82229590415955
2020-01-10 21:55:34.526002 UTC | [2020_01_10_11_46_20] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.099699
Z variance train             0.028616423
KL Divergence                25.264435
KL Loss                      2.5264435
QF Loss                      2456.8335
VF Loss                      486.76385
Policy Loss                  -1287.9375
Q Predictions Mean           1289.2517
Q Predictions Std            228.16653
Q Predictions Max            1511.4945
Q Predictions Min            -55.41325
V Predictions Mean           1295.4802
V Predictions Std            227.92172
V Predictions Max            1506.9146
V Predictions Min            -35.9835
Log Pis Mean                 0.11159788
Log Pis Std                  2.8322418
Log Pis Max                  12.241859
Log Pis Min                  -7.15649
Policy mu Mean               -0.01969003
Policy mu Std                0.6225647
Policy mu Max                2.4080205
Policy mu Min                -3.7305734
Policy log std Mean          -1.0091956
Policy log std Std           0.29367056
Policy log std Max           -0.18600166
Policy log std Min           -2.7089405
Z mean eval                  1.1052976
Z variance eval              0.020434614
total_rewards                [ -38.42975423 1103.92054205 3649.17132325 3565.93869188 3544.81673874
 1660.67748085  865.24078547  824.21775172 1735.80886173 3465.93195998]
total_rewards_mean           2037.729438143752
total_rewards_std            1323.1153978556715
total_rewards_max            3649.1713232497177
total_rewards_min            -38.42975422676549
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               36.09936165018007
(Previous) Eval Time (s)     24.809316533152014
Sample Time (s)              26.864576656837016
Epoch Time (s)               87.7732548401691
Total Train Time (s)         36637.82252593944
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:56:59.552341 UTC | [2020_01_10_11_46_20] Iteration #414 | Epoch Duration: 85.0262143611908
2020-01-10 21:56:59.552521 UTC | [2020_01_10_11_46_20] Iteration #414 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1053598
Z variance train             0.020456996
KL Divergence                26.255836
KL Loss                      2.6255836
QF Loss                      1580.4321
VF Loss                      727.8415
Policy Loss                  -1256.7908
Q Predictions Mean           1258.5544
Q Predictions Std            284.44943
Q Predictions Max            1460.3735
Q Predictions Min            -65.25161
V Predictions Mean           1261.7249
V Predictions Std            278.56223
V Predictions Max            1464.7122
V Predictions Min            -55.500774
Log Pis Mean                 0.38252676
Log Pis Std                  3.0120506
Log Pis Max                  14.3191185
Log Pis Min                  -6.6200166
Policy mu Mean               0.072721176
Policy mu Std                0.6195436
Policy mu Max                2.884633
Policy mu Min                -2.1925988
Policy log std Mean          -1.0064341
Policy log std Std           0.31048343
Policy log std Max           0.13515776
Policy log std Min           -2.9102633
Z mean eval                  1.095457
Z variance eval              0.015646348
total_rewards                [1628.32095286 3552.57021647 3672.96481463 2271.46174479 1326.142051
 1913.89932217 3742.73614345 3810.71205117 2335.24258011 3655.69950237]
total_rewards_mean           2790.974937901185
total_rewards_std            937.8561993666033
total_rewards_max            3810.7120511710814
total_rewards_min            1326.1420509958434
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               37.17193580418825
(Previous) Eval Time (s)     22.06191753828898
Sample Time (s)              26.121402627788484
Epoch Time (s)               85.35525597026572
Total Train Time (s)         36730.838366840966
Epoch                        415
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:58:32.573990 UTC | [2020_01_10_11_46_20] Iteration #415 | Epoch Duration: 93.02127432823181
2020-01-10 21:58:32.574360 UTC | [2020_01_10_11_46_20] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0947831
Z variance train             0.01566382
KL Divergence                26.620655
KL Loss                      2.6620655
QF Loss                      800.5831
VF Loss                      162.23027
Policy Loss                  -1289.0635
Q Predictions Mean           1288.5753
Q Predictions Std            179.81848
Q Predictions Max            1489.4321
Q Predictions Min            -181.3746
V Predictions Mean           1294.6669
V Predictions Std            178.92966
V Predictions Max            1490.9313
V Predictions Min            -155.77014
Log Pis Mean                 0.30392945
Log Pis Std                  2.6728518
Log Pis Max                  9.345003
Log Pis Min                  -8.173172
Policy mu Mean               0.03388629
Policy mu Std                0.6149137
Policy mu Max                2.5467808
Policy mu Min                -2.3661597
Policy log std Mean          -1.0221431
Policy log std Std           0.249809
Policy log std Max           -0.26686788
Policy log std Min           -2.0729728
Z mean eval                  1.0897945
Z variance eval              0.014512124
total_rewards                [2110.68413379 1693.43891544 1141.72886416 3741.75745757 3598.69450559
 3185.43367546 1714.50137461  398.92671565  770.64405515 2239.68565748]
total_rewards_mean           2059.5495354892473
total_rewards_std            1096.1708393100787
total_rewards_max            3741.757457574994
total_rewards_min            398.9267156450063
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               35.95968525996432
(Previous) Eval Time (s)     29.727570700924844
Sample Time (s)              27.472015652339906
Epoch Time (s)               93.15927161322907
Total Train Time (s)         36817.10377093777
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:59:58.844669 UTC | [2020_01_10_11_46_20] Iteration #416 | Epoch Duration: 86.27009630203247
2020-01-10 21:59:58.844951 UTC | [2020_01_10_11_46_20] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0898577
Z variance train             0.0145169245
KL Divergence                26.340855
KL Loss                      2.6340854
QF Loss                      831.4657
VF Loss                      335.96674
Policy Loss                  -1242.863
Q Predictions Mean           1242.0432
Q Predictions Std            319.87387
Q Predictions Max            1489.5753
Q Predictions Min            -58.65129
V Predictions Mean           1248.3647
V Predictions Std            317.37604
V Predictions Max            1481.7805
V Predictions Min            -46.25618
Log Pis Mean                 -0.20257653
Log Pis Std                  3.1039672
Log Pis Max                  11.417453
Log Pis Min                  -8.025208
Policy mu Mean               0.07783887
Policy mu Std                0.60024416
Policy mu Max                2.3768764
Policy mu Min                -2.170204
Policy log std Mean          -0.97114015
Policy log std Std           0.29331052
Policy log std Max           -0.08885735
Policy log std Min           -2.3561337
Z mean eval                  1.0703914
Z variance eval              0.016178051
total_rewards                [3180.28518719 3595.11044805 3630.93881042  983.30122698 3565.53237123
 1991.36239324 1239.79595184 1113.87066515 3108.53435515 1125.36315811]
total_rewards_mean           2353.409456735045
total_rewards_std            1104.0853884627957
total_rewards_max            3630.938810422179
total_rewards_min            983.3012269798461
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               36.83688089204952
(Previous) Eval Time (s)     22.83801190368831
Sample Time (s)              25.87054974772036
Epoch Time (s)               85.5454425434582
Total Train Time (s)         36905.775374160614
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:01:27.520719 UTC | [2020_01_10_11_46_20] Iteration #417 | Epoch Duration: 88.67558813095093
2020-01-10 22:01:27.521074 UTC | [2020_01_10_11_46_20] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0704453
Z variance train             0.016199239
KL Divergence                26.351841
KL Loss                      2.635184
QF Loss                      936.321
VF Loss                      130.37456
Policy Loss                  -1274.6674
Q Predictions Mean           1273.1497
Q Predictions Std            282.04605
Q Predictions Max            1477.4093
Q Predictions Min            -38.246704
V Predictions Mean           1272.2726
V Predictions Std            281.95447
V Predictions Max            1478.0929
V Predictions Min            -55.072266
Log Pis Mean                 0.41943574
Log Pis Std                  3.1879451
Log Pis Max                  10.945116
Log Pis Min                  -8.927776
Policy mu Mean               0.01798521
Policy mu Std                0.63609976
Policy mu Max                2.4170353
Policy mu Min                -2.7427351
Policy log std Mean          -1.0293679
Policy log std Std           0.33418116
Policy log std Max           0.1165086
Policy log std Min           -2.7615557
Z mean eval                  1.0952933
Z variance eval              0.018661203
total_rewards                [1461.57902467 3591.34326006  977.42551856 1254.60037774 3587.27656942
  760.24822029 1254.4449245   888.58891988 2671.29520906  236.05022007]
total_rewards_mean           1668.2852244247842
total_rewards_std            1128.4005134778192
total_rewards_max            3591.343260055318
total_rewards_min            236.050220068761
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               36.81031858827919
(Previous) Eval Time (s)     25.96777278603986
Sample Time (s)              27.223763276822865
Epoch Time (s)               90.00185465114191
Total Train Time (s)         36985.75098490296
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:02:47.500896 UTC | [2020_01_10_11_46_20] Iteration #418 | Epoch Duration: 79.97957968711853
2020-01-10 22:02:47.501107 UTC | [2020_01_10_11_46_20] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0972774
Z variance train             0.01873378
KL Divergence                26.408707
KL Loss                      2.6408708
QF Loss                      559.4147
VF Loss                      239.66963
Policy Loss                  -1298.1799
Q Predictions Mean           1300.8667
Q Predictions Std            211.48578
Q Predictions Max            1491.5653
Q Predictions Min            -3.4211812
V Predictions Mean           1294.0417
V Predictions Std            211.33536
V Predictions Max            1480.5549
V Predictions Min            -6.4938517
Log Pis Mean                 0.13794649
Log Pis Std                  2.5841448
Log Pis Max                  13.035922
Log Pis Min                  -6.478752
Policy mu Mean               0.042083375
Policy mu Std                0.60387176
Policy mu Max                2.926789
Policy mu Min                -2.4318676
Policy log std Mean          -1.018975
Policy log std Std           0.26721656
Policy log std Max           -0.1906395
Policy log std Min           -2.2900429
Z mean eval                  1.0863262
Z variance eval              0.021874543
total_rewards                [2599.13245159 3657.89654584 2836.75267357 3648.92576208 3649.04247982
 3834.9381181  3221.62986158 3782.73482614 1151.29767611 3456.30795055]
total_rewards_mean           3183.8658345379536
total_rewards_std            781.6200594234399
total_rewards_max            3834.938118098922
total_rewards_min            1151.297676107723
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               36.473608857020736
(Previous) Eval Time (s)     15.945040001068264
Sample Time (s)              26.750151024200022
Epoch Time (s)               79.16879988228902
Total Train Time (s)         37079.53310251003
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:04:21.287278 UTC | [2020_01_10_11_46_20] Iteration #419 | Epoch Duration: 93.78603005409241
2020-01-10 22:04:21.287465 UTC | [2020_01_10_11_46_20] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0875661
Z variance train             0.021782951
KL Divergence                25.476381
KL Loss                      2.5476382
QF Loss                      687.124
VF Loss                      164.87383
Policy Loss                  -1291.677
Q Predictions Mean           1291.2434
Q Predictions Std            228.75874
Q Predictions Max            1457.2308
Q Predictions Min            -37.00019
V Predictions Mean           1298.8289
V Predictions Std            230.57288
V Predictions Max            1461.4136
V Predictions Min            -32.873962
Log Pis Mean                 0.30384988
Log Pis Std                  2.799502
Log Pis Max                  10.127073
Log Pis Min                  -8.035376
Policy mu Mean               0.07899788
Policy mu Std                0.65239066
Policy mu Max                2.4819884
Policy mu Min                -2.1390238
Policy log std Mean          -0.9920268
Policy log std Std           0.25299093
Policy log std Max           -0.14582139
Policy log std Min           -1.9053822
Z mean eval                  1.0932724
Z variance eval              0.021784147
total_rewards                [3650.81196967  913.17565977 3571.5643317   413.59365455 3658.85338158
  946.47480624 3723.93510617 3800.4543044  3864.07195455 3694.86851952]
total_rewards_mean           2823.7803688139115
total_rewards_std            1361.2261849171505
total_rewards_max            3864.0719545479906
total_rewards_min            413.5936545485706
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               37.09090961469337
(Previous) Eval Time (s)     30.561870240140706
Sample Time (s)              25.339618928730488
Epoch Time (s)               92.99239878356457
Total Train Time (s)         37168.801420087926
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:05:50.560270 UTC | [2020_01_10_11_46_20] Iteration #420 | Epoch Duration: 89.27266836166382
2020-01-10 22:05:50.560469 UTC | [2020_01_10_11_46_20] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.092846
Z variance train             0.02179224
KL Divergence                25.307852
KL Loss                      2.5307853
QF Loss                      1463.1794
VF Loss                      826.4872
Policy Loss                  -1248.8987
Q Predictions Mean           1252.8319
Q Predictions Std            295.6584
Q Predictions Max            1482.8568
Q Predictions Min            -52.839176
V Predictions Mean           1253.5437
V Predictions Std            295.23196
V Predictions Max            1488.8047
V Predictions Min            -62.875004
Log Pis Mean                 0.1641117
Log Pis Std                  2.723254
Log Pis Max                  9.521825
Log Pis Min                  -7.9527025
Policy mu Mean               0.064809285
Policy mu Std                0.5955877
Policy mu Max                2.3940005
Policy mu Min                -2.3118112
Policy log std Mean          -1.0223749
Policy log std Std           0.30159009
Policy log std Max           0.05975908
Policy log std Min           -2.548748
Z mean eval                  1.0931698
Z variance eval              0.014663431
total_rewards                [3418.65063257 3557.54126148 3456.89981938 3607.90210132 3528.67242885
 1576.17213545 3467.79731882 3620.49792403 1141.49572543   37.11516424]
total_rewards_mean           2741.274451157697
total_rewards_std            1246.5308236325518
total_rewards_max            3620.497924034876
total_rewards_min            37.11516423500703
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               36.31414292566478
(Previous) Eval Time (s)     26.841703879646957
Sample Time (s)              26.119535055942833
Epoch Time (s)               89.27538186125457
Total Train Time (s)         37261.58536327677
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:07:23.349749 UTC | [2020_01_10_11_46_20] Iteration #421 | Epoch Duration: 92.78911685943604
2020-01-10 22:07:23.350148 UTC | [2020_01_10_11_46_20] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.092958
Z variance train             0.014679546
KL Divergence                26.217903
KL Loss                      2.6217904
QF Loss                      2181.6008
VF Loss                      414.17233
Policy Loss                  -1273.855
Q Predictions Mean           1276.8635
Q Predictions Std            277.10104
Q Predictions Max            1487.8353
Q Predictions Min            -95.54743
V Predictions Mean           1267.9138
V Predictions Std            271.58926
V Predictions Max            1475.8916
V Predictions Min            -98.321495
Log Pis Mean                 0.50502884
Log Pis Std                  2.6278305
Log Pis Max                  9.1977215
Log Pis Min                  -7.2726784
Policy mu Mean               -0.032052547
Policy mu Std                0.68165535
Policy mu Max                2.313085
Policy mu Min                -2.9465723
Policy log std Mean          -0.97743094
Policy log std Std           0.2717539
Policy log std Max           0.068974614
Policy log std Min           -2.429037
Z mean eval                  1.1346774
Z variance eval              0.011715735
total_rewards                [3489.1344057  3574.40905089 3752.71622016  153.61226091 3674.17259993
 3348.26387599 3116.13734464 3368.2971309  1445.5043343  3486.48913231]
total_rewards_mean           2940.873635571107
total_rewards_std            1121.6416252972078
total_rewards_max            3752.7162201577744
total_rewards_min            153.61226091142493
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               36.73494408512488
(Previous) Eval Time (s)     30.3550608237274
Sample Time (s)              26.77160745440051
Epoch Time (s)               93.86161236325279
Total Train Time (s)         37361.21659029648
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:09:02.985757 UTC | [2020_01_10_11_46_20] Iteration #422 | Epoch Duration: 99.63531827926636
2020-01-10 22:09:02.986092 UTC | [2020_01_10_11_46_20] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1363062
Z variance train             0.0117313685
KL Divergence                27.058834
KL Loss                      2.7058835
QF Loss                      2599.3062
VF Loss                      414.603
Policy Loss                  -1330.2432
Q Predictions Mean           1328.2903
Q Predictions Std            179.52965
Q Predictions Max            1524.4674
Q Predictions Min            -82.10771
V Predictions Mean           1331.0237
V Predictions Std            176.70488
V Predictions Max            1504.6924
V Predictions Min            -24.725718
Log Pis Mean                 0.76230377
Log Pis Std                  2.7064931
Log Pis Max                  11.333573
Log Pis Min                  -6.073159
Policy mu Mean               -0.005683571
Policy mu Std                0.6345995
Policy mu Max                2.6229641
Policy mu Min                -3.155129
Policy log std Mean          -1.0636989
Policy log std Std           0.25883847
Policy log std Max           -0.14234322
Policy log std Min           -2.3093135
Z mean eval                  1.1084828
Z variance eval              0.011950278
total_rewards                [ 250.51372526  919.96843501 3778.63149076 3563.55503343 3225.67514723
  341.3047458  3584.98569508 1882.49947389 3431.01580144 2014.9257563 ]
total_rewards_mean           2299.3075304192516
total_rewards_std            1332.9335802627977
total_rewards_max            3778.6314907609335
total_rewards_min            250.51372526425385
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               34.34695114195347
(Previous) Eval Time (s)     36.12836701609194
Sample Time (s)              27.041099620517343
Epoch Time (s)               97.51641777856275
Total Train Time (s)         37447.23568874458
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:10:29.008690 UTC | [2020_01_10_11_46_20] Iteration #423 | Epoch Duration: 86.02243614196777
2020-01-10 22:10:29.008897 UTC | [2020_01_10_11_46_20] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1097722
Z variance train             0.011990466
KL Divergence                27.019577
KL Loss                      2.7019577
QF Loss                      1067.9609
VF Loss                      512.09326
Policy Loss                  -1297.2938
Q Predictions Mean           1292.9818
Q Predictions Std            247.50372
Q Predictions Max            1494.5735
Q Predictions Min            11.033321
V Predictions Mean           1280.6084
V Predictions Std            243.19583
V Predictions Max            1458.3195
V Predictions Min            -13.076903
Log Pis Mean                 0.5936457
Log Pis Std                  3.0109534
Log Pis Max                  13.156607
Log Pis Min                  -6.932783
Policy mu Mean               0.07613386
Policy mu Std                0.6706255
Policy mu Max                2.8051984
Policy mu Min                -2.5668964
Policy log std Mean          -1.0451679
Policy log std Std           0.30106184
Policy log std Max           0.033503354
Policy log std Min           -3.015153
Z mean eval                  1.0911487
Z variance eval              0.01847513
total_rewards                [3507.11514806 3545.23869234 2812.05894664 3687.54430946 3895.2308634
 3741.60130691  642.38044457 3801.0086818  3629.15018186 3508.85917317]
total_rewards_mean           3277.0187748215926
total_rewards_std            922.0227377391847
total_rewards_max            3895.2308634032433
total_rewards_min            642.380444574413
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               34.0444733039476
(Previous) Eval Time (s)     24.634006632026285
Sample Time (s)              26.41371825709939
Epoch Time (s)               85.09219819307327
Total Train Time (s)         37541.426561492495
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:12:03.205679 UTC | [2020_01_10_11_46_20] Iteration #424 | Epoch Duration: 94.19664907455444
2020-01-10 22:12:03.205816 UTC | [2020_01_10_11_46_20] Iteration #424 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0910109
Z variance train             0.018440953
KL Divergence                26.582985
KL Loss                      2.6582985
QF Loss                      876.8135
VF Loss                      347.68817
Policy Loss                  -1317.5754
Q Predictions Mean           1313.0576
Q Predictions Std            201.80835
Q Predictions Max            1496.9258
Q Predictions Min            24.253532
V Predictions Mean           1319.6611
V Predictions Std            176.9756
V Predictions Max            1506.8927
V Predictions Min            10.040887
Log Pis Mean                 0.74938715
Log Pis Std                  3.209317
Log Pis Max                  19.46623
Log Pis Min                  -6.1181293
Policy mu Mean               0.059406675
Policy mu Std                0.6898278
Policy mu Max                2.6407957
Policy mu Min                -3.2019846
Policy log std Mean          -1.0284004
Policy log std Std           0.28360355
Policy log std Max           -0.15700018
Policy log std Min           -2.8966644
Z mean eval                  1.1079727
Z variance eval              0.014570022
total_rewards                [1650.05907297  894.66795619 3131.73051022 1228.04059997 2395.3215136
  141.15362145 2884.64873126  106.82116474 2785.69155436 1746.31550362]
total_rewards_mean           1696.4450228384176
total_rewards_std            1046.875450155265
total_rewards_max            3131.730510222294
total_rewards_min            106.82116474013966
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               33.91532103996724
(Previous) Eval Time (s)     33.73809184413403
Sample Time (s)              25.33103456022218
Epoch Time (s)               92.98444744432345
Total Train Time (s)         37620.7602356025
Epoch                        425
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:13:22.545968 UTC | [2020_01_10_11_46_20] Iteration #425 | Epoch Duration: 79.3400297164917
2020-01-10 22:13:22.546168 UTC | [2020_01_10_11_46_20] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1083535
Z variance train             0.014602663
KL Divergence                26.561655
KL Loss                      2.6561656
QF Loss                      713.8033
VF Loss                      243.61594
Policy Loss                  -1272.232
Q Predictions Mean           1271.5879
Q Predictions Std            289.41693
Q Predictions Max            1478.0188
Q Predictions Min            -75.916855
V Predictions Mean           1280.887
V Predictions Std            289.11734
V Predictions Max            1487.5972
V Predictions Min            -66.46608
Log Pis Mean                 0.21551444
Log Pis Std                  2.8771188
Log Pis Max                  11.7954235
Log Pis Min                  -7.7684946
Policy mu Mean               0.010568225
Policy mu Std                0.63736296
Policy mu Max                2.4707134
Policy mu Min                -2.6603103
Policy log std Mean          -0.99649394
Policy log std Std           0.28550023
Policy log std Max           -0.083527386
Policy log std Min           -2.2468777
Z mean eval                  1.0940878
Z variance eval              0.014534963
total_rewards                [3316.5064275  3178.60744021 3676.08496844 3739.51252114 3831.85734199
 3536.89559516 3777.2017117  1745.63743354 3723.25870002  107.88887431]
total_rewards_mean           3063.3451014004736
total_rewards_std            1146.3438379428053
total_rewards_max            3831.857341986425
total_rewards_min            107.88887431194051
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               34.636861882172525
(Previous) Eval Time (s)     20.093302574940026
Sample Time (s)              25.886809000279754
Epoch Time (s)               80.6169734573923
Total Train Time (s)         37710.045539174695
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:14:51.836060 UTC | [2020_01_10_11_46_20] Iteration #426 | Epoch Duration: 89.28969430923462
2020-01-10 22:14:51.836322 UTC | [2020_01_10_11_46_20] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0965486
Z variance train             0.014459874
KL Divergence                26.470669
KL Loss                      2.6470668
QF Loss                      1055.1968
VF Loss                      356.70886
Policy Loss                  -1258.2476
Q Predictions Mean           1261.5469
Q Predictions Std            332.12375
Q Predictions Max            1520.1545
Q Predictions Min            -56.123882
V Predictions Mean           1261.1151
V Predictions Std            332.36633
V Predictions Max            1508.4271
V Predictions Min            -65.48212
Log Pis Mean                 0.17653546
Log Pis Std                  3.0822315
Log Pis Max                  13.899168
Log Pis Min                  -7.1777053
Policy mu Mean               0.0015549343
Policy mu Std                0.60588026
Policy mu Max                2.632892
Policy mu Min                -2.4931514
Policy log std Mean          -1.0435799
Policy log std Std           0.31980717
Policy log std Max           -0.12524027
Policy log std Min           -2.8004515
Z mean eval                  1.0808699
Z variance eval              0.014326441
total_rewards                [1536.0834753  3494.59299122 3407.75617618  427.16865511 2478.5910256
 3730.28355921  775.05324098 3594.82794077 3743.8068954  3787.09834628]
total_rewards_mean           2697.526230603873
total_rewards_std            1246.621774813961
total_rewards_max            3787.098346275171
total_rewards_min            427.1686551056838
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               34.24996233638376
(Previous) Eval Time (s)     28.76571902818978
Sample Time (s)              26.129968945402652
Epoch Time (s)               89.14565030997619
Total Train Time (s)         37800.14828923484
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:16:21.942998 UTC | [2020_01_10_11_46_20] Iteration #427 | Epoch Duration: 90.10653376579285
2020-01-10 22:16:21.943340 UTC | [2020_01_10_11_46_20] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0808249
Z variance train             0.01434131
KL Divergence                26.107374
KL Loss                      2.6107376
QF Loss                      588.8645
VF Loss                      374.65454
Policy Loss                  -1268.4895
Q Predictions Mean           1270.3684
Q Predictions Std            308.94138
Q Predictions Max            1505.081
Q Predictions Min            -69.53828
V Predictions Mean           1268.2631
V Predictions Std            303.41507
V Predictions Max            1503.9094
V Predictions Min            -50.900265
Log Pis Mean                 -0.15230817
Log Pis Std                  2.6655805
Log Pis Max                  7.3592305
Log Pis Min                  -7.120166
Policy mu Mean               0.039189257
Policy mu Std                0.60815924
Policy mu Max                2.7759469
Policy mu Min                -2.2976367
Policy log std Mean          -1.0054109
Policy log std Std           0.2947953
Policy log std Max           -0.05619669
Policy log std Min           -2.5871513
Z mean eval                  1.1341413
Z variance eval              0.018668866
total_rewards                [1175.07986922 3735.27907713 3718.3164702  3666.60714534  325.08585891
 3469.61799665  147.7922833   492.30919285 1442.52923603 3433.85544916]
total_rewards_mean           2160.6472578785174
total_rewards_std            1489.9475388529115
total_rewards_max            3735.2790771289397
total_rewards_min            147.79228329648652
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               34.061828943900764
(Previous) Eval Time (s)     29.726301179267466
Sample Time (s)              25.655933503527194
Epoch Time (s)               89.44406362669542
Total Train Time (s)         37886.69310177071
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:17:48.491475 UTC | [2020_01_10_11_46_20] Iteration #428 | Epoch Duration: 86.54800462722778
2020-01-10 22:17:48.491639 UTC | [2020_01_10_11_46_20] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1358343
Z variance train             0.018593773
KL Divergence                25.818842
KL Loss                      2.5818841
QF Loss                      1150.5815
VF Loss                      135.6894
Policy Loss                  -1316.7334
Q Predictions Mean           1316.0402
Q Predictions Std            255.14624
Q Predictions Max            1541.4017
Q Predictions Min            -45.61282
V Predictions Mean           1318.5542
V Predictions Std            253.32559
V Predictions Max            1552.1365
V Predictions Min            -40.504364
Log Pis Mean                 0.3124408
Log Pis Std                  2.6049802
Log Pis Max                  7.373541
Log Pis Min                  -7.382657
Policy mu Mean               -0.0062817093
Policy mu Std                0.63329774
Policy mu Max                2.6052725
Policy mu Min                -2.1007257
Policy log std Mean          -1.0124131
Policy log std Std           0.2817086
Policy log std Max           -0.20162266
Policy log std Min           -2.1743596
Z mean eval                  1.1261953
Z variance eval              0.015288038
total_rewards                [3593.97243899 2289.40147723 3044.6541319  3718.74261087  603.34538893
 2141.22530494 3904.20944428 3724.07342411 4006.36316283 3629.35404877]
total_rewards_mean           3065.5341432850832
total_rewards_std            1027.8895315223526
total_rewards_max            4006.3631628307335
total_rewards_min            603.3453889276725
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               34.710982026997954
(Previous) Eval Time (s)     26.82995804818347
Sample Time (s)              24.827649070881307
Epoch Time (s)               86.36858914606273
Total Train Time (s)         37974.2446106975
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:19:16.051149 UTC | [2020_01_10_11_46_20] Iteration #429 | Epoch Duration: 87.55937695503235
2020-01-10 22:19:16.051372 UTC | [2020_01_10_11_46_20] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.126962
Z variance train             0.015296523
KL Divergence                26.067596
KL Loss                      2.6067598
QF Loss                      665.39844
VF Loss                      235.16368
Policy Loss                  -1302.4484
Q Predictions Mean           1301.78
Q Predictions Std            286.44424
Q Predictions Max            1534.7759
Q Predictions Min            -38.746494
V Predictions Mean           1305.0916
V Predictions Std            288.40982
V Predictions Max            1529.796
V Predictions Min            -39.9784
Log Pis Mean                 0.28859502
Log Pis Std                  2.6404624
Log Pis Max                  9.905594
Log Pis Min                  -10.595399
Policy mu Mean               0.014128288
Policy mu Std                0.6239705
Policy mu Max                2.3812246
Policy mu Min                -2.2970614
Policy log std Mean          -1.0170077
Policy log std Std           0.26251057
Policy log std Max           -0.04829693
Policy log std Min           -2.3040752
Z mean eval                  1.1189083
Z variance eval              0.014502118
total_rewards                [3364.2621885  3245.69711505 2861.02987057 3772.57222726 3433.92996088
 3465.86908818 2247.56167284 3507.51328906 3267.64471722 3514.15716792]
total_rewards_mean           3268.0237297485737
total_rewards_std            406.93009736755135
total_rewards_max            3772.572227255909
total_rewards_min            2247.561672844271
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               34.22424239292741
(Previous) Eval Time (s)     28.020406822673976
Sample Time (s)              23.64795800577849
Epoch Time (s)               85.89260722137988
Total Train Time (s)         38064.8089161329
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:20:46.620133 UTC | [2020_01_10_11_46_20] Iteration #430 | Epoch Duration: 90.56861591339111
2020-01-10 22:20:46.620324 UTC | [2020_01_10_11_46_20] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1175212
Z variance train             0.014506688
KL Divergence                26.169815
KL Loss                      2.6169815
QF Loss                      8992.632
VF Loss                      121.32782
Policy Loss                  -1342.9452
Q Predictions Mean           1345.8682
Q Predictions Std            196.58008
Q Predictions Max            1518.6017
Q Predictions Min            -16.143095
V Predictions Mean           1342.0325
V Predictions Std            197.15652
V Predictions Max            1511.622
V Predictions Min            -23.728952
Log Pis Mean                 0.60284775
Log Pis Std                  2.8320057
Log Pis Max                  11.007546
Log Pis Min                  -7.664484
Policy mu Mean               0.026770331
Policy mu Std                0.6424083
Policy mu Max                3.3675394
Policy mu Min                -2.893271
Policy log std Mean          -1.0546412
Policy log std Std           0.2712923
Policy log std Max           0.005148649
Policy log std Min           -2.2996287
Z mean eval                  1.1570729
Z variance eval              0.013977434
total_rewards                [3567.24831152 3762.04023337  223.11437683 3452.74247222 3524.49479618
  223.15197437 3528.09477598 3560.1640023  3564.08352379 3290.26772406]
total_rewards_mean           2869.540219063041
total_rewards_std            1327.7590539729
total_rewards_max            3762.0402333658426
total_rewards_min            223.11437683272112
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               33.33549639116973
(Previous) Eval Time (s)     32.696023468859494
Sample Time (s)              26.103723450563848
Epoch Time (s)               92.13524331059307
Total Train Time (s)         38151.78333859751
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:22:13.599632 UTC | [2020_01_10_11_46_20] Iteration #431 | Epoch Duration: 86.97917675971985
2020-01-10 22:22:13.599813 UTC | [2020_01_10_11_46_20] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1586014
Z variance train             0.013992879
KL Divergence                26.088581
KL Loss                      2.608858
QF Loss                      683.73376
VF Loss                      125.726234
Policy Loss                  -1336.3121
Q Predictions Mean           1338.241
Q Predictions Std            247.83224
Q Predictions Max            1550.9176
Q Predictions Min            -35.99596
V Predictions Mean           1337.5309
V Predictions Std            248.30121
V Predictions Max            1531.5231
V Predictions Min            -44.14446
Log Pis Mean                 0.46855363
Log Pis Std                  2.5572073
Log Pis Max                  10.897539
Log Pis Min                  -6.9170704
Policy mu Mean               0.027741207
Policy mu Std                0.626836
Policy mu Max                2.4958293
Policy mu Min                -2.6965542
Policy log std Mean          -1.0458388
Policy log std Std           0.27454656
Policy log std Max           -0.16648895
Policy log std Min           -2.6246614
Z mean eval                  1.1190145
Z variance eval              0.012639101
total_rewards                [1095.16408718 3477.71222749 3497.89916731 3681.22336427 3847.68960502
 3670.34210114 2520.56718178 3736.15708463 3802.67512461 3690.15361075]
total_rewards_mean           3301.9583554175015
total_rewards_std            819.5796384369041
total_rewards_max            3847.6896050163673
total_rewards_min            1095.1640871768368
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               34.439158590044826
(Previous) Eval Time (s)     27.539640897884965
Sample Time (s)              25.14328349707648
Epoch Time (s)               87.12208298500627
Total Train Time (s)         38243.21130648721
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:23:45.031682 UTC | [2020_01_10_11_46_20] Iteration #432 | Epoch Duration: 91.43172883987427
2020-01-10 22:23:45.031891 UTC | [2020_01_10_11_46_20] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1182963
Z variance train             0.012663369
KL Divergence                26.505177
KL Loss                      2.6505177
QF Loss                      1430.4899
VF Loss                      354.40186
Policy Loss                  -1328.5475
Q Predictions Mean           1328.7458
Q Predictions Std            199.7465
Q Predictions Max            1503.7457
Q Predictions Min            60.435238
V Predictions Mean           1319.4004
V Predictions Std            201.89288
V Predictions Max            1496.0967
V Predictions Min            48.820316
Log Pis Mean                 0.8154408
Log Pis Std                  2.792256
Log Pis Max                  10.421867
Log Pis Min                  -6.948784
Policy mu Mean               -0.010330591
Policy mu Std                0.665605
Policy mu Max                2.37467
Policy mu Min                -2.3837962
Policy log std Mean          -1.0562756
Policy log std Std           0.28715843
Policy log std Max           -0.20673347
Policy log std Min           -2.0409832
Z mean eval                  1.1306095
Z variance eval              0.0065309345
total_rewards                [3358.12377824 3606.36442075 3757.53514879 3671.82455304 3752.73089591
 3373.23430213 3707.13804188 1893.43988127 3471.48135371 4037.9890129 ]
total_rewards_mean           3462.986138861954
total_rewards_std            557.4692409116071
total_rewards_max            4037.989012903564
total_rewards_min            1893.4398812652562
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               34.02201649406925
(Previous) Eval Time (s)     31.848994039930403
Sample Time (s)              25.331957079470158
Epoch Time (s)               91.20296761346981
Total Train Time (s)         38336.117784937844
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:25:17.943051 UTC | [2020_01_10_11_46_20] Iteration #433 | Epoch Duration: 92.91100692749023
2020-01-10 22:25:17.943357 UTC | [2020_01_10_11_46_20] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1292856
Z variance train             0.0065410077
KL Divergence                28.121284
KL Loss                      2.8121285
QF Loss                      792.4236
VF Loss                      137.26587
Policy Loss                  -1309.302
Q Predictions Mean           1309.0355
Q Predictions Std            257.79626
Q Predictions Max            1525.6437
Q Predictions Min            -7.053384
V Predictions Mean           1314.4867
V Predictions Std            256.2113
V Predictions Max            1529.9585
V Predictions Min            -19.191982
Log Pis Mean                 0.79498816
Log Pis Std                  2.7920969
Log Pis Max                  12.359383
Log Pis Min                  -7.2157707
Policy mu Mean               0.08212874
Policy mu Std                0.6636712
Policy mu Max                2.9592223
Policy mu Min                -2.7263258
Policy log std Mean          -1.0781608
Policy log std Std           0.2996676
Policy log std Max           -0.018990636
Policy log std Min           -3.0978448
Z mean eval                  1.1086614
Z variance eval              0.0070609087
total_rewards                [3036.67358309 3365.1701647  3091.44166201 1571.29535442 3159.39556602
 3333.59442138 3479.87195603 3442.99494241 3359.17349637 3191.57351294]
total_rewards_mean           3103.118465936631
total_rewards_std            529.796033538405
total_rewards_max            3479.87195603443
total_rewards_min            1571.2953544244212
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               33.76520561799407
(Previous) Eval Time (s)     33.55670217098668
Sample Time (s)              24.672254523728043
Epoch Time (s)               91.9941623127088
Total Train Time (s)         38426.54444392305
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:26:48.373963 UTC | [2020_01_10_11_46_20] Iteration #434 | Epoch Duration: 90.43046283721924
2020-01-10 22:26:48.374120 UTC | [2020_01_10_11_46_20] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.110229
Z variance train             0.0070348806
KL Divergence                28.081686
KL Loss                      2.8081686
QF Loss                      811.1676
VF Loss                      520.0784
Policy Loss                  -1324.0485
Q Predictions Mean           1326.2598
Q Predictions Std            240.90553
Q Predictions Max            1532.8914
Q Predictions Min            -51.534836
V Predictions Mean           1340.5413
V Predictions Std            244.40063
V Predictions Max            1534.5923
V Predictions Min            -50.472805
Log Pis Mean                 0.50147957
Log Pis Std                  2.6470351
Log Pis Max                  10.692842
Log Pis Min                  -6.3298626
Policy mu Mean               0.02514582
Policy mu Std                0.64018345
Policy mu Max                2.8433917
Policy mu Min                -2.9737115
Policy log std Mean          -1.0316771
Policy log std Std           0.27677444
Policy log std Max           -0.056143165
Policy log std Min           -2.1310623
Z mean eval                  1.1416758
Z variance eval              0.013440509
total_rewards                [3766.38519019 1756.50829545 3496.89866227 3928.72561909 1435.63535899
 3775.14128682 1054.69244877 3633.90015115 3609.4803599  3559.70962908]
total_rewards_mean           3001.7077001699517
total_rewards_std            1056.4989856032923
total_rewards_max            3928.7256190933067
total_rewards_min            1054.6924487670124
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               34.1754562901333
(Previous) Eval Time (s)     31.992659754119813
Sample Time (s)              25.25246028928086
Epoch Time (s)               91.42057633353397
Total Train Time (s)         38514.78143009916
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:28:16.615545 UTC | [2020_01_10_11_46_20] Iteration #435 | Epoch Duration: 88.24130439758301
2020-01-10 22:28:16.615722 UTC | [2020_01_10_11_46_20] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1408864
Z variance train             0.013400881
KL Divergence                27.302746
KL Loss                      2.7302747
QF Loss                      1243.9158
VF Loss                      276.4764
Policy Loss                  -1300.6786
Q Predictions Mean           1301.2498
Q Predictions Std            312.7198
Q Predictions Max            1566.4032
Q Predictions Min            -15.299669
V Predictions Mean           1296.9269
V Predictions Std            312.06104
V Predictions Max            1559.4819
V Predictions Min            -29.134724
Log Pis Mean                 0.47852036
Log Pis Std                  3.0516505
Log Pis Max                  10.619202
Log Pis Min                  -7.3555455
Policy mu Mean               0.026182234
Policy mu Std                0.6348401
Policy mu Max                2.7277088
Policy mu Min                -2.2375166
Policy log std Mean          -1.0319016
Policy log std Std           0.30296612
Policy log std Max           -0.06561214
Policy log std Min           -2.1870806
Z mean eval                  1.1439698
Z variance eval              0.009780054
total_rewards                [3432.27051705 1269.67730656 3586.65761455 3788.29989509 3785.15412195
 3570.72404783 2384.77397182 1200.24763187 3582.38374293 3545.87488568]
total_rewards_mean           3014.606373532717
total_rewards_std            966.5029562471088
total_rewards_max            3788.2998950870574
total_rewards_min            1200.2476318725876
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               33.50344925979152
(Previous) Eval Time (s)     28.81305865291506
Sample Time (s)              25.006437965203077
Epoch Time (s)               87.32294587790966
Total Train Time (s)         38602.44839829719
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:29:44.287703 UTC | [2020_01_10_11_46_20] Iteration #436 | Epoch Duration: 87.67184162139893
2020-01-10 22:29:44.287903 UTC | [2020_01_10_11_46_20] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1449455
Z variance train             0.009794744
KL Divergence                27.95816
KL Loss                      2.7958162
QF Loss                      657.46497
VF Loss                      131.43904
Policy Loss                  -1336.0173
Q Predictions Mean           1336.2113
Q Predictions Std            197.75256
Q Predictions Max            1538.2656
Q Predictions Min            -16.33992
V Predictions Mean           1336.6827
V Predictions Std            196.96481
V Predictions Max            1535.3306
V Predictions Min            -14.874743
Log Pis Mean                 0.5089469
Log Pis Std                  2.8703105
Log Pis Max                  16.605019
Log Pis Min                  -7.03664
Policy mu Mean               0.04303242
Policy mu Std                0.6389403
Policy mu Max                2.2338905
Policy mu Min                -2.8401365
Policy log std Mean          -1.0572603
Policy log std Std           0.28076842
Policy log std Max           0.066108525
Policy log std Min           -2.3275018
Z mean eval                  1.1803021
Z variance eval              0.015126795
total_rewards                [3825.61992706 3834.16614485 3945.12693434 3728.60428802 3890.03951548
  332.83707971  245.25837816 4212.94290148 3847.05689244 4008.50636617]
total_rewards_mean           3187.0158427704782
total_rewards_std            1454.3800065566272
total_rewards_max            4212.942901475936
total_rewards_min            245.25837815902415
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               34.028584411833435
(Previous) Eval Time (s)     29.161638613324612
Sample Time (s)              25.787802960257977
Epoch Time (s)               88.97802598541602
Total Train Time (s)         38691.37044793554
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:31:13.213534 UTC | [2020_01_10_11_46_20] Iteration #437 | Epoch Duration: 88.92547392845154
2020-01-10 22:31:13.213801 UTC | [2020_01_10_11_46_20] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1828941
Z variance train             0.015078723
KL Divergence                27.709871
KL Loss                      2.7709873
QF Loss                      580.2433
VF Loss                      311.02713
Policy Loss                  -1349.3994
Q Predictions Mean           1350.2244
Q Predictions Std            198.72243
Q Predictions Max            1528.2184
Q Predictions Min            -9.076072
V Predictions Mean           1363.551
V Predictions Std            198.17517
V Predictions Max            1542.38
V Predictions Min            -1.6294085
Log Pis Mean                 0.6483271
Log Pis Std                  2.853475
Log Pis Max                  12.457685
Log Pis Min                  -7.720195
Policy mu Mean               0.019539665
Policy mu Std                0.616326
Policy mu Max                2.118491
Policy mu Min                -2.3862507
Policy log std Mean          -1.0920031
Policy log std Std           0.29480848
Policy log std Max           -0.10995078
Policy log std Min           -2.668446
Z mean eval                  1.1240261
Z variance eval              0.016852306
total_rewards                [3838.34765477 3690.25929382 3679.29151036 3907.22917588 3374.3649686
 3602.90801812 3638.14067132 3726.23445783 3844.88562531 2135.59993444]
total_rewards_mean           3543.7261310445915
total_rewards_std            490.5824870614453
total_rewards_max            3907.2291758842607
total_rewards_min            2135.5999344427046
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               33.828790799248964
(Previous) Eval Time (s)     29.108752724248916
Sample Time (s)              25.612334745936096
Epoch Time (s)               88.54987826943398
Total Train Time (s)         38783.83861107379
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:32:45.685625 UTC | [2020_01_10_11_46_20] Iteration #438 | Epoch Duration: 92.47165751457214
2020-01-10 22:32:45.685804 UTC | [2020_01_10_11_46_20] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1257136
Z variance train             0.016815197
KL Divergence                26.175781
KL Loss                      2.6175783
QF Loss                      897.3822
VF Loss                      194.34494
Policy Loss                  -1328.6876
Q Predictions Mean           1325.4457
Q Predictions Std            234.97607
Q Predictions Max            1515.2913
Q Predictions Min            -66.38151
V Predictions Mean           1328.9337
V Predictions Std            231.27263
V Predictions Max            1516.22
V Predictions Min            -27.897562
Log Pis Mean                 0.386128
Log Pis Std                  2.6523082
Log Pis Max                  12.693693
Log Pis Min                  -6.668994
Policy mu Mean               -0.012536083
Policy mu Std                0.60062873
Policy mu Max                2.068185
Policy mu Min                -1.9781317
Policy log std Mean          -1.055289
Policy log std Std           0.28895524
Policy log std Max           -0.050878227
Policy log std Min           -2.6488876
Z mean eval                  1.1202452
Z variance eval              0.012059585
total_rewards                [2293.32564849 3718.33552435 3754.12498301 2307.6943031  3521.63344141
 3667.93149438 3619.13434148 3467.9084568  3359.4350415  3514.9986012 ]
total_rewards_mean           3322.4521835713954
total_rewards_std            523.3114578434372
total_rewards_max            3754.124983006348
total_rewards_min            2293.3256484856443
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               33.90944812214002
(Previous) Eval Time (s)     33.03016836801544
Sample Time (s)              25.951761355623603
Epoch Time (s)               92.89137784577906
Total Train Time (s)         38877.78818239411
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:34:19.637729 UTC | [2020_01_10_11_46_20] Iteration #439 | Epoch Duration: 93.95175957679749
2020-01-10 22:34:19.638031 UTC | [2020_01_10_11_46_20] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1181175
Z variance train             0.012070162
KL Divergence                26.882832
KL Loss                      2.6882832
QF Loss                      642.999
VF Loss                      336.97473
Policy Loss                  -1339.0708
Q Predictions Mean           1343.6759
Q Predictions Std            216.76833
Q Predictions Max            1567.2645
Q Predictions Min            -79.87745
V Predictions Mean           1351.4395
V Predictions Std            216.58823
V Predictions Max            1553.7822
V Predictions Min            -50.693867
Log Pis Mean                 0.7223687
Log Pis Std                  2.9586957
Log Pis Max                  13.137192
Log Pis Min                  -9.499025
Policy mu Mean               0.023651745
Policy mu Std                0.6995906
Policy mu Max                2.82651
Policy mu Min                -2.805249
Policy log std Mean          -0.9932051
Policy log std Std           0.26811934
Policy log std Max           -0.08825266
Policy log std Min           -2.2490606
Z mean eval                  1.1328152
Z variance eval              0.0073476583
total_rewards                [3480.20125362 3396.82988982 3379.50172506 3515.78272834 3502.3159121
 3588.93002049 3515.13481773 3625.1619398  3367.08443591 3168.45030425]
total_rewards_mean           3453.93930271224
total_rewards_std            124.89569497457089
total_rewards_max            3625.1619398045864
total_rewards_min            3168.4503042491006
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               34.14750223886222
(Previous) Eval Time (s)     34.090179850813
Sample Time (s)              25.260053427424282
Epoch Time (s)               93.4977355170995
Total Train Time (s)         38970.32415452786
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:35:52.178480 UTC | [2020_01_10_11_46_20] Iteration #440 | Epoch Duration: 92.54023909568787
2020-01-10 22:35:52.178678 UTC | [2020_01_10_11_46_20] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1296184
Z variance train             0.0073442943
KL Divergence                28.44625
KL Loss                      2.8446252
QF Loss                      923.00586
VF Loss                      180.78334
Policy Loss                  -1358.9559
Q Predictions Mean           1361.4154
Q Predictions Std            162.62383
Q Predictions Max            1560.2181
Q Predictions Min            -22.188189
V Predictions Mean           1366.2812
V Predictions Std            159.07242
V Predictions Max            1545.2623
V Predictions Min            -12.616755
Log Pis Mean                 0.5398316
Log Pis Std                  2.8582723
Log Pis Max                  12.70261
Log Pis Min                  -5.993978
Policy mu Mean               0.014147523
Policy mu Std                0.5992558
Policy mu Max                2.404881
Policy mu Min                -2.3035562
Policy log std Mean          -1.0867544
Policy log std Std           0.28482836
Policy log std Max           -0.18693316
Policy log std Min           -2.8746781
Z mean eval                  1.1156728
Z variance eval              0.009001455
total_rewards                [3428.86205663 2332.28192402 1898.72870095  426.19315494 3055.76937065
 3608.38801041 3890.57822756  911.52658624 2392.90908537 1272.3426328 ]
total_rewards_mean           2321.7579749579045
total_rewards_std            1129.0874247550446
total_rewards_max            3890.578227560475
total_rewards_min            426.1931549443276
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               34.76098795467988
(Previous) Eval Time (s)     33.13238026201725
Sample Time (s)              25.854215857572854
Epoch Time (s)               93.74758407426998
Total Train Time (s)         39059.91199528286
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:37:21.770541 UTC | [2020_01_10_11_46_20] Iteration #441 | Epoch Duration: 89.591726064682
2020-01-10 22:37:21.770733 UTC | [2020_01_10_11_46_20] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1140838
Z variance train             0.009003526
KL Divergence                28.145973
KL Loss                      2.8145974
QF Loss                      588.542
VF Loss                      222.62755
Policy Loss                  -1330.2954
Q Predictions Mean           1328.741
Q Predictions Std            270.32047
Q Predictions Max            1511.5459
Q Predictions Min            -67.7186
V Predictions Mean           1321.3776
V Predictions Std            271.078
V Predictions Max            1507.1475
V Predictions Min            -128.49173
Log Pis Mean                 0.29340172
Log Pis Std                  2.5815516
Log Pis Max                  8.75819
Log Pis Min                  -7.5735025
Policy mu Mean               0.02400795
Policy mu Std                0.6385787
Policy mu Max                2.4579177
Policy mu Min                -3.0282378
Policy log std Mean          -1.0021834
Policy log std Std           0.27782422
Policy log std Max           0.03258753
Policy log std Min           -2.0023806
Z mean eval                  1.127007
Z variance eval              0.010971834
total_rewards                [3760.91515293 3924.52899554 1175.12378449 4062.12417079 3963.25639777
 3922.5556642  1190.85488873 2032.76855847 2270.04600644 3953.42788989]
total_rewards_mean           3025.5601509247476
total_rewards_std            1153.9005844061498
total_rewards_max            4062.124170793056
total_rewards_min            1175.1237844891123
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               33.91811065003276
(Previous) Eval Time (s)     28.97622245363891
Sample Time (s)              23.833203534130007
Epoch Time (s)               86.72753663780168
Total Train Time (s)         39147.88604554348
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:38:49.748962 UTC | [2020_01_10_11_46_20] Iteration #442 | Epoch Duration: 87.97809600830078
2020-01-10 22:38:49.749137 UTC | [2020_01_10_11_46_20] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1256406
Z variance train             0.011003273
KL Divergence                27.694859
KL Loss                      2.769486
QF Loss                      1039.8063
VF Loss                      301.8722
Policy Loss                  -1339.7861
Q Predictions Mean           1341.6229
Q Predictions Std            272.31805
Q Predictions Max            1639.7484
Q Predictions Min            -51.468857
V Predictions Mean           1335.722
V Predictions Std            263.95358
V Predictions Max            1591.5775
V Predictions Min            -52.7381
Log Pis Mean                 0.60815173
Log Pis Std                  2.681768
Log Pis Max                  14.101858
Log Pis Min                  -6.2597456
Policy mu Mean               0.016507873
Policy mu Std                0.6378659
Policy mu Max                3.533502
Policy mu Min                -3.8917148
Policy log std Mean          -1.0479271
Policy log std Std           0.28340897
Policy log std Max           -0.15689945
Policy log std Min           -2.294344
Z mean eval                  1.1151863
Z variance eval              0.008534802
total_rewards                [ 362.59602569 3700.50804973 3957.61702363 1627.90125829 3970.28556101
 3827.39421297 4108.92119908 3960.97520857 3861.67070526 1047.84277777]
total_rewards_mean           3042.5712021990735
total_rewards_std            1362.3796297378847
total_rewards_max            4108.9211990849335
total_rewards_min            362.5960256904601
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               34.11737729795277
(Previous) Eval Time (s)     30.22645655972883
Sample Time (s)              25.63300617178902
Epoch Time (s)               89.97684002947062
Total Train Time (s)         39236.72590364609
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:40:18.591395 UTC | [2020_01_10_11_46_20] Iteration #443 | Epoch Duration: 88.84211659431458
2020-01-10 22:40:18.591632 UTC | [2020_01_10_11_46_20] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1189969
Z variance train             0.008510021
KL Divergence                28.408403
KL Loss                      2.8408403
QF Loss                      2165.4194
VF Loss                      180.59148
Policy Loss                  -1320.3501
Q Predictions Mean           1319.4226
Q Predictions Std            285.4627
Q Predictions Max            1556.0223
Q Predictions Min            -41.628036
V Predictions Mean           1327.1787
V Predictions Std            285.98868
V Predictions Max            1549.6721
V Predictions Min            -39.896404
Log Pis Mean                 0.5770159
Log Pis Std                  2.758921
Log Pis Max                  12.644736
Log Pis Min                  -8.321302
Policy mu Mean               0.023375675
Policy mu Std                0.6000305
Policy mu Max                2.3132846
Policy mu Min                -2.0519032
Policy log std Mean          -1.0857229
Policy log std Std           0.28641182
Policy log std Max           -0.035117567
Policy log std Min           -2.537993
Z mean eval                  1.1138858
Z variance eval              0.010178643
total_rewards                [3577.7307567   887.03139535 3748.70225503  208.62774777 3665.66167314
 2225.93058747 3666.24665324 2580.58348928  791.65741764 3717.49275149]
total_rewards_mean           2506.966472711414
total_rewards_std            1333.1751279857808
total_rewards_max            3748.7022550269703
total_rewards_min            208.62774776911095
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               33.915264253970236
(Previous) Eval Time (s)     29.09143182868138
Sample Time (s)              26.20052178669721
Epoch Time (s)               89.20721786934882
Total Train Time (s)         39323.500319927
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:41:45.371495 UTC | [2020_01_10_11_46_20] Iteration #444 | Epoch Duration: 86.77966070175171
2020-01-10 22:41:45.371755 UTC | [2020_01_10_11_46_20] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1166888
Z variance train             0.010205171
KL Divergence                28.42962
KL Loss                      2.842962
QF Loss                      1450.291
VF Loss                      1087.1741
Policy Loss                  -1343.2667
Q Predictions Mean           1345.2097
Q Predictions Std            243.36923
Q Predictions Max            1597.4362
Q Predictions Min            35.463737
V Predictions Mean           1320.6625
V Predictions Std            243.96294
V Predictions Max            1556.1705
V Predictions Min            18.945078
Log Pis Mean                 0.8527463
Log Pis Std                  2.9194524
Log Pis Max                  8.398209
Log Pis Min                  -7.035328
Policy mu Mean               0.0102508385
Policy mu Std                0.65477175
Policy mu Max                2.734339
Policy mu Min                -2.3827164
Policy log std Mean          -1.0459726
Policy log std Std           0.3039012
Policy log std Max           0.002211988
Policy log std Min           -2.6988776
Z mean eval                  1.1222908
Z variance eval              0.012531184
total_rewards                [3412.05308635 3692.25588562 3674.23379741 3743.34599649 3960.50309923
 3649.54548111  939.78485143 3758.06145997 3500.61843147 3841.09970285]
total_rewards_mean           3417.1501791911346
total_rewards_std            838.9102703168613
total_rewards_max            3960.5030992265824
total_rewards_min            939.7848514260398
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               33.710953722242266
(Previous) Eval Time (s)     26.66350265685469
Sample Time (s)              25.78266335465014
Epoch Time (s)               86.1571197337471
Total Train Time (s)         39414.2894439986
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:43:16.166467 UTC | [2020_01_10_11_46_20] Iteration #445 | Epoch Duration: 90.7944757938385
2020-01-10 22:43:16.166795 UTC | [2020_01_10_11_46_20] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.12307
Z variance train             0.012520144
KL Divergence                27.711834
KL Loss                      2.7711835
QF Loss                      1845.1191
VF Loss                      325.331
Policy Loss                  -1329.774
Q Predictions Mean           1327.282
Q Predictions Std            265.37073
Q Predictions Max            1525.9747
Q Predictions Min            -52.794815
V Predictions Mean           1335.2925
V Predictions Std            268.46848
V Predictions Max            1534.021
V Predictions Min            -68.22935
Log Pis Mean                 0.8122902
Log Pis Std                  2.880322
Log Pis Max                  10.622201
Log Pis Min                  -7.194813
Policy mu Mean               0.022739708
Policy mu Std                0.63381284
Policy mu Max                2.9014902
Policy mu Min                -2.5396461
Policy log std Mean          -1.0756797
Policy log std Std           0.3154636
Policy log std Max           -0.042674363
Policy log std Min           -2.5544753
Z mean eval                  1.1031153
Z variance eval              0.011976932
total_rewards                [2262.6615165   879.56474415 2756.44261175 1447.45461794 3589.80553768
 3546.94293599  722.38453181 3631.2676471  3655.87867719 3443.57901663]
total_rewards_mean           2593.5981836742817
total_rewards_std            1127.7408438565622
total_rewards_max            3655.878677189818
total_rewards_min            722.3845318059634
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               33.48312749573961
(Previous) Eval Time (s)     31.300498075783253
Sample Time (s)              25.8703637951985
Epoch Time (s)               90.65398936672136
Total Train Time (s)         39497.24034827622
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:44:39.121097 UTC | [2020_01_10_11_46_20] Iteration #446 | Epoch Duration: 82.95413875579834
2020-01-10 22:44:39.121281 UTC | [2020_01_10_11_46_20] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1027367
Z variance train             0.011984544
KL Divergence                27.994917
KL Loss                      2.7994916
QF Loss                      1302.1912
VF Loss                      314.15433
Policy Loss                  -1347.5217
Q Predictions Mean           1349.1797
Q Predictions Std            246.35577
Q Predictions Max            1565.0256
Q Predictions Min            -69.18377
V Predictions Mean           1356.5413
V Predictions Std            241.60886
V Predictions Max            1570.0232
V Predictions Min            -73.0167
Log Pis Mean                 0.66401446
Log Pis Std                  2.958845
Log Pis Max                  9.974678
Log Pis Min                  -8.483887
Policy mu Mean               0.028656332
Policy mu Std                0.607654
Policy mu Max                2.225481
Policy mu Min                -1.9785646
Policy log std Mean          -1.0997602
Policy log std Std           0.31574196
Policy log std Max           -0.16748655
Policy log std Min           -2.7280507
Z mean eval                  1.1333747
Z variance eval              0.013173416
total_rewards                [3754.14267606 3743.66258935 1284.19224141 3839.29464069 3816.60954476
 3746.63698107 1799.55968682 1321.22576786 3823.56152032  525.18733411]
total_rewards_mean           2765.407298245854
total_rewards_std            1284.7742498562773
total_rewards_max            3839.2946406871724
total_rewards_min            525.1873341098036
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               33.889126339927316
(Previous) Eval Time (s)     23.600298484787345
Sample Time (s)              26.004772548098117
Epoch Time (s)               83.49419737281278
Total Train Time (s)         39584.4948853571
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:46:06.380738 UTC | [2020_01_10_11_46_20] Iteration #447 | Epoch Duration: 87.25925779342651
2020-01-10 22:46:06.381011 UTC | [2020_01_10_11_46_20] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1338375
Z variance train             0.01318004
KL Divergence                27.666637
KL Loss                      2.7666638
QF Loss                      1019.2601
VF Loss                      417.94113
Policy Loss                  -1337.1198
Q Predictions Mean           1337.7365
Q Predictions Std            235.2587
Q Predictions Max            1548.3239
Q Predictions Min            -48.395542
V Predictions Mean           1326.4854
V Predictions Std            235.89357
V Predictions Max            1544.3419
V Predictions Min            -50.948254
Log Pis Mean                 0.30543897
Log Pis Std                  2.8708677
Log Pis Max                  9.1714735
Log Pis Min                  -7.8478317
Policy mu Mean               0.015373658
Policy mu Std                0.6164814
Policy mu Max                2.6747937
Policy mu Min                -2.1799831
Policy log std Mean          -1.0611899
Policy log std Std           0.2824136
Policy log std Max           -0.027550876
Policy log std Min           -2.6126833
Z mean eval                  1.1225685
Z variance eval              0.012638253
total_rewards                [2737.57140438 3835.13998396 3324.99934969 2180.75329661 2162.10428796
 3506.61318946 4055.40718946 3771.57223112  154.01619127 3252.35921369]
total_rewards_mean           2898.0536337609824
total_rewards_std            1107.7197247809447
total_rewards_max            4055.4071894635945
total_rewards_min            154.01619127491247
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               34.3167904173024
(Previous) Eval Time (s)     27.364968368783593
Sample Time (s)              25.39658410428092
Epoch Time (s)               87.07834289036691
Total Train Time (s)         39672.535321790725
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:47:34.424994 UTC | [2020_01_10_11_46_20] Iteration #448 | Epoch Duration: 88.04384398460388
2020-01-10 22:47:34.425159 UTC | [2020_01_10_11_46_20] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1230997
Z variance train             0.012637889
KL Divergence                27.794565
KL Loss                      2.7794566
QF Loss                      1989.6741
VF Loss                      399.89648
Policy Loss                  -1358.3285
Q Predictions Mean           1359.415
Q Predictions Std            225.9834
Q Predictions Max            1563.5883
Q Predictions Min            -72.41521
V Predictions Mean           1354.4893
V Predictions Std            219.36462
V Predictions Max            1529.1644
V Predictions Min            -64.22819
Log Pis Mean                 0.48591927
Log Pis Std                  3.0355563
Log Pis Max                  10.186046
Log Pis Min                  -8.952984
Policy mu Mean               0.050021853
Policy mu Std                0.6265446
Policy mu Max                2.6068575
Policy mu Min                -2.0078025
Policy log std Mean          -1.0559263
Policy log std Std           0.29443341
Policy log std Max           -0.023170292
Policy log std Min           -2.6195478
Z mean eval                  1.1570708
Z variance eval              0.012888433
total_rewards                [3764.04779223 3918.10049541 3769.59388179 3290.58240667  654.09501916
 1555.84772715 4022.588601   3804.8875774   910.81376762 3900.35940356]
total_rewards_mean           2959.0916671986893
total_rewards_std            1286.2495521534925
total_rewards_max            4022.5886009982055
total_rewards_min            654.0950191556094
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               33.835138894151896
(Previous) Eval Time (s)     28.330121390055865
Sample Time (s)              25.64164034789428
Epoch Time (s)               87.80690063210204
Total Train Time (s)         39761.8863136936
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:49:03.781473 UTC | [2020_01_10_11_46_20] Iteration #449 | Epoch Duration: 89.35617446899414
2020-01-10 22:49:03.781714 UTC | [2020_01_10_11_46_20] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1606491
Z variance train             0.012862387
KL Divergence                27.986137
KL Loss                      2.7986138
QF Loss                      791.44366
VF Loss                      841.1651
Policy Loss                  -1362.1011
Q Predictions Mean           1361.7688
Q Predictions Std            234.71184
Q Predictions Max            1584.7799
Q Predictions Min            -45.156258
V Predictions Mean           1357.0459
V Predictions Std            222.39528
V Predictions Max            1576.8453
V Predictions Min            -47.145096
Log Pis Mean                 0.3921802
Log Pis Std                  2.740855
Log Pis Max                  14.932358
Log Pis Min                  -7.031573
Policy mu Mean               0.030436635
Policy mu Std                0.60504186
Policy mu Max                2.3364167
Policy mu Min                -2.685579
Policy log std Mean          -1.0648077
Policy log std Std           0.28297913
Policy log std Max           -0.14883798
Policy log std Min           -3.2412534
Z mean eval                  1.1565287
Z variance eval              0.015227218
total_rewards                [3755.61975142 3878.78996069 4027.62932607 3649.6249716  3898.27686489
 3968.05651272 3875.27609431 3733.94248503   99.41060863 3848.0247182 ]
total_rewards_mean           3473.4651293548623
total_rewards_std            1129.6439546408176
total_rewards_max            4027.629326074093
total_rewards_min            99.41060862520806
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               34.00368659803644
(Previous) Eval Time (s)     29.87902235193178
Sample Time (s)              24.936878133565187
Epoch Time (s)               88.8195870835334
Total Train Time (s)         39851.39202901162
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:50:33.291469 UTC | [2020_01_10_11_46_20] Iteration #450 | Epoch Duration: 89.50960969924927
2020-01-10 22:50:33.291655 UTC | [2020_01_10_11_46_20] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1547201
Z variance train             0.015193015
KL Divergence                28.032757
KL Loss                      2.8032758
QF Loss                      4129.4365
VF Loss                      386.9128
Policy Loss                  -1352.4419
Q Predictions Mean           1350.9001
Q Predictions Std            235.22221
Q Predictions Max            1563.6765
Q Predictions Min            -65.922195
V Predictions Mean           1346.2081
V Predictions Std            222.30893
V Predictions Max            1562.8864
V Predictions Min            -61.670334
Log Pis Mean                 0.7154384
Log Pis Std                  2.9542491
Log Pis Max                  15.001422
Log Pis Min                  -6.369071
Policy mu Mean               -0.0050856746
Policy mu Std                0.649895
Policy mu Max                2.459071
Policy mu Min                -2.2481909
Policy log std Mean          -1.0788264
Policy log std Std           0.31012994
Policy log std Max           0.24097353
Policy log std Min           -3.2258477
Z mean eval                  1.1518911
Z variance eval              0.012019833
total_rewards                [3677.83342829 3740.14958191  741.69484202 1340.86996714 3840.94251113
 3417.60909161 3642.73258484 3650.35268085 3929.32149809 3752.74641861]
total_rewards_mean           3173.4252604486237
total_rewards_std            1081.9927017345644
total_rewards_max            3929.321498090347
total_rewards_min            741.6948420154486
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               35.8543601622805
(Previous) Eval Time (s)     30.56872000405565
Sample Time (s)              26.691601417027414
Epoch Time (s)               93.11468158336356
Total Train Time (s)         39944.4177235649
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:52:06.321651 UTC | [2020_01_10_11_46_20] Iteration #451 | Epoch Duration: 93.02986407279968
2020-01-10 22:52:06.321845 UTC | [2020_01_10_11_46_20] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1524084
Z variance train             0.012035404
KL Divergence                27.764532
KL Loss                      2.7764533
QF Loss                      1182.1465
VF Loss                      156.49693
Policy Loss                  -1368.7765
Q Predictions Mean           1369.6002
Q Predictions Std            223.3651
Q Predictions Max            1585.1746
Q Predictions Min            -25.64887
V Predictions Mean           1366.2607
V Predictions Std            219.28568
V Predictions Max            1574.1001
V Predictions Min            -19.59075
Log Pis Mean                 0.41035044
Log Pis Std                  3.0966566
Log Pis Max                  9.849043
Log Pis Min                  -8.500242
Policy mu Mean               0.010641573
Policy mu Std                0.6038351
Policy mu Max                2.9150882
Policy mu Min                -2.0715816
Policy log std Mean          -1.0710704
Policy log std Std           0.2914311
Policy log std Max           -0.20198697
Policy log std Min           -2.5447369
Z mean eval                  1.1356164
Z variance eval              0.009517196
total_rewards                [3502.51591875 4163.91096346 3604.96242977 2870.82083549 3689.65257256
 3783.35633767 3529.76841985 3759.39442259 4108.30262208 3998.77948125]
total_rewards_mean           3701.1464003465126
total_rewards_std            353.03151061252123
total_rewards_max            4163.910963456258
total_rewards_min            2870.8208354861813
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               36.64062773576006
(Previous) Eval Time (s)     30.483507049269974
Sample Time (s)              27.39325155224651
Epoch Time (s)               94.51738633727655
Total Train Time (s)         40042.21707062377
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:53:44.125614 UTC | [2020_01_10_11_46_20] Iteration #452 | Epoch Duration: 97.80362558364868
2020-01-10 22:53:44.125830 UTC | [2020_01_10_11_46_20] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1357983
Z variance train             0.009509975
KL Divergence                27.238293
KL Loss                      2.7238293
QF Loss                      1787.6965
VF Loss                      1400.538
Policy Loss                  -1336.9038
Q Predictions Mean           1335.9817
Q Predictions Std            284.57153
Q Predictions Max            1577.5795
Q Predictions Min            -80.044716
V Predictions Mean           1332.3613
V Predictions Std            268.9242
V Predictions Max            1565.1235
V Predictions Min            -69.685555
Log Pis Mean                 0.8407788
Log Pis Std                  2.6350524
Log Pis Max                  9.213137
Log Pis Min                  -5.561647
Policy mu Mean               0.054294165
Policy mu Std                0.65189457
Policy mu Max                2.7233386
Policy mu Min                -2.0608075
Policy log std Mean          -1.0540371
Policy log std Std           0.27953365
Policy log std Max           -0.057179928
Policy log std Min           -2.283999
Z mean eval                  1.1192437
Z variance eval              0.00917152
total_rewards                [1236.78124943   88.79386281 3698.85113104 3770.0624335  1311.84708999
 3768.66282351 1298.19418183 3704.55737734 3216.92624294 3708.56618144]
total_rewards_mean           2580.324257383391
total_rewards_std            1352.2774587287654
total_rewards_max            3770.0624335035263
total_rewards_min            88.79386281212913
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               37.75980914197862
(Previous) Eval Time (s)     33.769310038071126
Sample Time (s)              28.37359920097515
Epoch Time (s)               99.9027183810249
Total Train Time (s)         40135.76182096964
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:55:17.674998 UTC | [2020_01_10_11_46_20] Iteration #453 | Epoch Duration: 93.54899787902832
2020-01-10 22:55:17.675272 UTC | [2020_01_10_11_46_20] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.120993
Z variance train             0.009144461
KL Divergence                27.705923
KL Loss                      2.7705925
QF Loss                      756.593
VF Loss                      158.2141
Policy Loss                  -1351.2516
Q Predictions Mean           1353.3291
Q Predictions Std            228.2966
Q Predictions Max            1556.508
Q Predictions Min            -36.321342
V Predictions Mean           1353.9253
V Predictions Std            229.10977
V Predictions Max            1538.6498
V Predictions Min            -53.103104
Log Pis Mean                 0.95118743
Log Pis Std                  3.0158596
Log Pis Max                  12.075044
Log Pis Min                  -6.435302
Policy mu Mean               0.03793584
Policy mu Std                0.66070217
Policy mu Max                2.6798058
Policy mu Min                -3.2486236
Policy log std Mean          -1.0608094
Policy log std Std           0.31209564
Policy log std Max           -0.068897426
Policy log std Min           -2.7361548
Z mean eval                  1.1114478
Z variance eval              0.0068349717
total_rewards                [ 911.24610369 3598.67276977  197.33313819  504.68487732 3587.3579643
 3724.88057878 2933.14786433 1493.18131717 3538.75419927 3501.5448717 ]
total_rewards_mean           2399.08036845179
total_rewards_std            1374.0092181938314
total_rewards_max            3724.8805787774704
total_rewards_min            197.3331381911122
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               36.58594546513632
(Previous) Eval Time (s)     27.415149787906557
Sample Time (s)              25.566348547115922
Epoch Time (s)               89.5674438001588
Total Train Time (s)         40224.367504560854
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:56:46.286503 UTC | [2020_01_10_11_46_20] Iteration #454 | Epoch Duration: 88.61104893684387
2020-01-10 22:56:46.286790 UTC | [2020_01_10_11_46_20] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1130579
Z variance train             0.0068370863
KL Divergence                27.85304
KL Loss                      2.785304
QF Loss                      1322.9425
VF Loss                      141.03406
Policy Loss                  -1344.3698
Q Predictions Mean           1347.4087
Q Predictions Std            288.6616
Q Predictions Max            1595.3027
Q Predictions Min            -13.072619
V Predictions Mean           1346.2162
V Predictions Std            289.24612
V Predictions Max            1578.5795
V Predictions Min            -2.0619354
Log Pis Mean                 0.5845263
Log Pis Std                  3.0019138
Log Pis Max                  13.249034
Log Pis Min                  -7.116024
Policy mu Mean               -0.008391969
Policy mu Std                0.6622203
Policy mu Max                2.6569157
Policy mu Min                -3.2710588
Policy log std Mean          -1.0299263
Policy log std Std           0.28494486
Policy log std Max           -0.0933851
Policy log std Min           -2.429646
Z mean eval                  1.1437287
Z variance eval              0.008486821
total_rewards                [ -24.50505933  -28.56596866 3570.42588538 3851.71690898 3734.28171655
 1129.01077113 3799.16626807 3717.73490246 3832.39354582 3664.37432799]
total_rewards_mean           2724.6033298380735
total_rewards_std            1579.2425246189143
total_rewards_max            3851.716908980351
total_rewards_min            -28.565968661269945
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               37.06205465039238
(Previous) Eval Time (s)     26.458379092160612
Sample Time (s)              27.783066240604967
Epoch Time (s)               91.30349998315796
Total Train Time (s)         40314.71474818839
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:58:16.644788 UTC | [2020_01_10_11_46_20] Iteration #455 | Epoch Duration: 90.35780835151672
2020-01-10 22:58:16.645068 UTC | [2020_01_10_11_46_20] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1440794
Z variance train             0.008462168
KL Divergence                27.630913
KL Loss                      2.7630913
QF Loss                      1201.2041
VF Loss                      255.27344
Policy Loss                  -1358.0344
Q Predictions Mean           1363.7412
Q Predictions Std            217.53691
Q Predictions Max            1561.5312
Q Predictions Min            -56.013535
V Predictions Mean           1357.6343
V Predictions Std            214.1413
V Predictions Max            1581.5665
V Predictions Min            -52.734154
Log Pis Mean                 0.56952244
Log Pis Std                  3.0064106
Log Pis Max                  14.542348
Log Pis Min                  -8.915659
Policy mu Mean               0.031611033
Policy mu Std                0.64694536
Policy mu Max                2.283246
Policy mu Min                -2.7674706
Policy log std Mean          -1.0634193
Policy log std Std           0.28125522
Policy log std Max           -0.08074367
Policy log std Min           -2.8904464
Z mean eval                  1.1634376
Z variance eval              0.0075227628
total_rewards                [3599.51934574   93.96862906 3550.9850646  3576.70742204 3168.4035216
 1746.39083425 3475.27806074 2861.44472046 1212.8344383  3529.05604463]
total_rewards_mean           2681.4588081419606
total_rewards_std            1172.381183237035
total_rewards_max            3599.519345743298
total_rewards_min            93.96862906208656
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               36.08196464786306
(Previous) Eval Time (s)     25.512181180063635
Sample Time (s)              25.60696476371959
Epoch Time (s)               87.20111059164628
Total Train Time (s)         40406.96974394284
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:59:48.904745 UTC | [2020_01_10_11_46_20] Iteration #456 | Epoch Duration: 92.25944828987122
2020-01-10 22:59:48.905041 UTC | [2020_01_10_11_46_20] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.162236
Z variance train             0.0075428784
KL Divergence                28.213842
KL Loss                      2.8213842
QF Loss                      1047.0588
VF Loss                      267.84424
Policy Loss                  -1376.3649
Q Predictions Mean           1375.2223
Q Predictions Std            211.65245
Q Predictions Max            1575.1749
Q Predictions Min            -44.725388
V Predictions Mean           1365.0507
V Predictions Std            211.18655
V Predictions Max            1554.9924
V Predictions Min            -40.67225
Log Pis Mean                 0.77525604
Log Pis Std                  2.5276325
Log Pis Max                  7.4447255
Log Pis Min                  -7.0295224
Policy mu Mean               -0.009722304
Policy mu Std                0.66870195
Policy mu Max                2.7444484
Policy mu Min                -2.5069532
Policy log std Mean          -1.0493588
Policy log std Std           0.28533605
Policy log std Max           -0.035615265
Policy log std Min           -2.1620252
Z mean eval                  1.1267574
Z variance eval              0.005800284
total_rewards                [3677.43067554 1288.07491518 3595.04228348 3718.28121309  408.08889011
  942.64344117 3646.4687574  3665.83539484 1574.49020067 2291.46899399]
total_rewards_mean           2480.782476546503
total_rewards_std            1261.3408295665813
total_rewards_max            3718.2812130916736
total_rewards_min            408.08889010642145
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               37.26877977512777
(Previous) Eval Time (s)     30.570109449792653
Sample Time (s)              26.11697461316362
Epoch Time (s)               93.95586383808404
Total Train Time (s)         40495.196834892035
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:01:17.135597 UTC | [2020_01_10_11_46_20] Iteration #457 | Epoch Duration: 88.23038077354431
2020-01-10 23:01:17.135784 UTC | [2020_01_10_11_46_20] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1267402
Z variance train             0.0058018826
KL Divergence                28.699732
KL Loss                      2.8699732
QF Loss                      1484.7129
VF Loss                      275.4874
Policy Loss                  -1327.5413
Q Predictions Mean           1332.236
Q Predictions Std            343.87286
Q Predictions Max            1638.6377
Q Predictions Min            -35.583584
V Predictions Mean           1318.2552
V Predictions Std            338.35858
V Predictions Max            1608.1965
V Predictions Min            -44.000286
Log Pis Mean                 0.74252415
Log Pis Std                  2.9043372
Log Pis Max                  14.375074
Log Pis Min                  -6.2665815
Policy mu Mean               0.00293564
Policy mu Std                0.6469004
Policy mu Max                2.9108984
Policy mu Min                -2.2490797
Policy log std Mean          -1.0364914
Policy log std Std           0.31130093
Policy log std Max           0.19550931
Policy log std Min           -3.1159115
Z mean eval                  1.1294436
Z variance eval              0.006480907
total_rewards                [2518.45306313 3472.0729192  3503.11700396 3307.44273582 3828.48331314
 1831.84188477 3307.17371405 3539.47250274 3534.28016891 3690.97759288]
total_rewards_mean           3253.3314898588533
total_rewards_std            579.6455122127787
total_rewards_max            3828.48331313669
total_rewards_min            1831.8418847674689
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               36.50300904503092
(Previous) Eval Time (s)     24.844279490876943
Sample Time (s)              28.265495744068176
Epoch Time (s)               89.61278427997604
Total Train Time (s)         40594.75070685288
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:02:56.694383 UTC | [2020_01_10_11_46_20] Iteration #458 | Epoch Duration: 99.55845856666565
2020-01-10 23:02:56.694575 UTC | [2020_01_10_11_46_20] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.130616
Z variance train             0.0064821197
KL Divergence                28.634794
KL Loss                      2.8634794
QF Loss                      942.0735
VF Loss                      256.97797
Policy Loss                  -1347.1765
Q Predictions Mean           1348.4594
Q Predictions Std            267.92007
Q Predictions Max            1571.0494
Q Predictions Min            -75.05279
V Predictions Mean           1339.4894
V Predictions Std            266.45868
V Predictions Max            1548.3817
V Predictions Min            -78.44211
Log Pis Mean                 1.0604807
Log Pis Std                  3.2893834
Log Pis Max                  13.449305
Log Pis Min                  -8.018448
Policy mu Mean               0.042721678
Policy mu Std                0.6771315
Policy mu Max                2.5281758
Policy mu Min                -2.4514825
Policy log std Mean          -1.0563288
Policy log std Std           0.30939552
Policy log std Max           -0.09763175
Policy log std Min           -2.2684
Z mean eval                  1.1331853
Z variance eval              0.0061939415
total_rewards                [3404.76709487 3522.71381317 3733.65805158 3329.89467417  787.65190621
 3544.68162258 3587.18330653 3778.59414879  227.48038369 3567.87764049]
total_rewards_mean           2948.4502642068337
total_rewards_std            1233.2510811315838
total_rewards_max            3778.5941487891673
total_rewards_min            227.48038369121969
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               37.0826200991869
(Previous) Eval Time (s)     34.789543605875224
Sample Time (s)              27.48393276007846
Epoch Time (s)               99.35609646514058
Total Train Time (s)         40688.61670982838
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:04:30.565174 UTC | [2020_01_10_11_46_20] Iteration #459 | Epoch Duration: 93.87046432495117
2020-01-10 23:04:30.565359 UTC | [2020_01_10_11_46_20] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1336465
Z variance train             0.0062084584
KL Divergence                29.353172
KL Loss                      2.9353173
QF Loss                      603.2622
VF Loss                      166.38321
Policy Loss                  -1321.2069
Q Predictions Mean           1318.9214
Q Predictions Std            353.68723
Q Predictions Max            1577.294
Q Predictions Min            -76.52171
V Predictions Mean           1313.5583
V Predictions Std            348.1385
V Predictions Max            1566.8298
V Predictions Min            -70.863144
Log Pis Mean                 0.40531588
Log Pis Std                  2.9603858
Log Pis Max                  11.833771
Log Pis Min                  -8.360325
Policy mu Mean               -0.013172183
Policy mu Std                0.64058274
Policy mu Max                2.9410655
Policy mu Min                -2.4773762
Policy log std Mean          -1.0305426
Policy log std Std           0.29395643
Policy log std Max           -0.055507183
Policy log std Min           -2.2252402
Z mean eval                  1.1316985
Z variance eval              0.0070550134
total_rewards                [3747.7059596  -169.42665964 3850.46956122 3941.14145733 3713.00113582
 3569.62247465 3205.91087431 4007.4846881  2656.90653407 4082.83972059]
total_rewards_mean           3260.5655746055954
total_rewards_std            1213.051983159749
total_rewards_max            4082.839720591942
total_rewards_min            -169.42665963533005
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               34.24020553799346
(Previous) Eval Time (s)     29.303493484854698
Sample Time (s)              28.062541409861296
Epoch Time (s)               91.60624043270946
Total Train Time (s)         40782.970280426554
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:06:04.923087 UTC | [2020_01_10_11_46_20] Iteration #460 | Epoch Duration: 94.3576021194458
2020-01-10 23:06:04.923273 UTC | [2020_01_10_11_46_20] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.129216
Z variance train             0.007055746
KL Divergence                28.062445
KL Loss                      2.8062446
QF Loss                      997.4341
VF Loss                      289.69278
Policy Loss                  -1354.9851
Q Predictions Mean           1354.8491
Q Predictions Std            268.75046
Q Predictions Max            1563.7048
Q Predictions Min            -79.14295
V Predictions Mean           1354.6572
V Predictions Std            268.9056
V Predictions Max            1545.605
V Predictions Min            -73.45493
Log Pis Mean                 0.95635843
Log Pis Std                  3.3081648
Log Pis Max                  15.9921055
Log Pis Min                  -6.339772
Policy mu Mean               0.056228526
Policy mu Std                0.6731777
Policy mu Max                2.7991974
Policy mu Min                -2.946333
Policy log std Mean          -1.0501703
Policy log std Std           0.29294452
Policy log std Max           -0.06561047
Policy log std Min           -2.7038846
Z mean eval                  1.1249188
Z variance eval              0.007569504
total_rewards                [3194.67013969 3410.8426224  3243.21571244 3246.90594461 3136.32745625
 3667.76300905 3375.55477537 3132.56301956 3242.20569505 3214.10503686]
total_rewards_mean           3286.4153411280627
total_rewards_std            152.99627320826386
total_rewards_max            3667.7630090452008
total_rewards_min            3132.5630195581107
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               33.51282626809552
(Previous) Eval Time (s)     32.05444213701412
Sample Time (s)              26.761812722310424
Epoch Time (s)               92.32908112742007
Total Train Time (s)         40877.33926403336
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:07:39.297573 UTC | [2020_01_10_11_46_20] Iteration #461 | Epoch Duration: 94.37417268753052
2020-01-10 23:07:39.297756 UTC | [2020_01_10_11_46_20] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1251204
Z variance train             0.00758545
KL Divergence                27.572796
KL Loss                      2.7572796
QF Loss                      760.0826
VF Loss                      1263.6925
Policy Loss                  -1325.5146
Q Predictions Mean           1327.6665
Q Predictions Std            325.65234
Q Predictions Max            1564.3083
Q Predictions Min            -73.60758
V Predictions Mean           1329.9642
V Predictions Std            314.53333
V Predictions Max            1556.8704
V Predictions Min            -79.18824
Log Pis Mean                 1.014724
Log Pis Std                  3.214697
Log Pis Max                  12.279076
Log Pis Min                  -8.347794
Policy mu Mean               0.09423746
Policy mu Std                0.72233456
Policy mu Max                3.1282225
Policy mu Min                -2.8223898
Policy log std Mean          -1.0192071
Policy log std Std           0.3048621
Policy log std Max           -0.092105746
Policy log std Min           -2.390539
Z mean eval                  1.1326046
Z variance eval              0.013140259
total_rewards                [3717.95436308  372.82600076 3735.68157835 3567.79562351 1542.68034773
  307.1542382  3605.86500704 -271.15381855 3871.92399859 3779.9940425 ]
total_rewards_mean           2423.072138123563
total_rewards_std            1635.9713967309613
total_rewards_max            3871.9239985942595
total_rewards_min            -271.1538185493123
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               34.43125284835696
(Previous) Eval Time (s)     34.099180270917714
Sample Time (s)              26.323055386543274
Epoch Time (s)               94.85348850581795
Total Train Time (s)         40964.755372758955
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:09:06.715793 UTC | [2020_01_10_11_46_20] Iteration #462 | Epoch Duration: 87.41792130470276
2020-01-10 23:09:06.715931 UTC | [2020_01_10_11_46_20] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1312945
Z variance train             0.013210428
KL Divergence                27.534616
KL Loss                      2.7534616
QF Loss                      922.16583
VF Loss                      193.21532
Policy Loss                  -1353.9839
Q Predictions Mean           1355.0079
Q Predictions Std            294.6545
Q Predictions Max            1594.4038
Q Predictions Min            -120.42741
V Predictions Mean           1351.6437
V Predictions Std            292.99936
V Predictions Max            1584.9641
V Predictions Min            -91.25473
Log Pis Mean                 0.6954708
Log Pis Std                  2.9916725
Log Pis Max                  15.868412
Log Pis Min                  -8.54954
Policy mu Mean               0.058995068
Policy mu Std                0.6415065
Policy mu Max                2.7166889
Policy mu Min                -2.509769
Policy log std Mean          -1.0379299
Policy log std Std           0.31063464
Policy log std Max           0.13986152
Policy log std Min           -3.3555439
Z mean eval                  1.169141
Z variance eval              0.008655085
total_rewards                [ 685.17813019 1626.63759234 1247.32094311 1012.35991364 3620.58633158
 1206.33912887  197.50318327 3381.35538733 1226.31185719 1061.96513149]
total_rewards_mean           1526.5557599009476
total_rewards_std            1051.687126885716
total_rewards_max            3620.5863315805964
total_rewards_min            197.50318327216547
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               33.81633674679324
(Previous) Eval Time (s)     26.663331454154104
Sample Time (s)              26.123836473096162
Epoch Time (s)               86.6035046740435
Total Train Time (s)         41047.47025743313
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:10:29.436451 UTC | [2020_01_10_11_46_20] Iteration #463 | Epoch Duration: 82.72039341926575
2020-01-10 23:10:29.436667 UTC | [2020_01_10_11_46_20] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1674931
Z variance train             0.008677585
KL Divergence                28.098604
KL Loss                      2.8098605
QF Loss                      1984.219
VF Loss                      358.72256
Policy Loss                  -1378.095
Q Predictions Mean           1380.9976
Q Predictions Std            267.8472
Q Predictions Max            1587.9403
Q Predictions Min            -73.03219
V Predictions Mean           1378.8514
V Predictions Std            265.0162
V Predictions Max            1580.0375
V Predictions Min            -49.694122
Log Pis Mean                 0.97991645
Log Pis Std                  3.0136495
Log Pis Max                  11.076838
Log Pis Min                  -7.6576486
Policy mu Mean               0.009453448
Policy mu Std                0.7243891
Policy mu Max                3.3166978
Policy mu Min                -2.4587376
Policy log std Mean          -1.0318158
Policy log std Std           0.29826698
Policy log std Max           0.010219216
Policy log std Min           -2.7661731
Z mean eval                  1.1455653
Z variance eval              0.01342074
total_rewards                [1046.2604843  1142.15764875  872.24381307 4111.48912702 1759.70930431
 1593.58085375 3052.74909455 1340.11692228 2704.38152791 3895.05892947]
total_rewards_mean           2151.7747705397805
total_rewards_std            1140.1500454154334
total_rewards_max            4111.489127022083
total_rewards_min            872.2438130663245
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               34.18934405222535
(Previous) Eval Time (s)     22.779919921886176
Sample Time (s)              25.924483965151012
Epoch Time (s)               82.89374793926254
Total Train Time (s)         41132.01514814282
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:11:53.986430 UTC | [2020_01_10_11_46_20] Iteration #464 | Epoch Duration: 84.54956197738647
2020-01-10 23:11:53.986733 UTC | [2020_01_10_11_46_20] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1450095
Z variance train             0.013491007
KL Divergence                27.41929
KL Loss                      2.741929
QF Loss                      1163.4089
VF Loss                      255.52429
Policy Loss                  -1344.483
Q Predictions Mean           1344.6785
Q Predictions Std            309.8334
Q Predictions Max            1636.3689
Q Predictions Min            -119.937454
V Predictions Mean           1347.2264
V Predictions Std            309.32266
V Predictions Max            1626.7024
V Predictions Min            -106.29499
Log Pis Mean                 0.56576604
Log Pis Std                  3.3194482
Log Pis Max                  20.491
Log Pis Min                  -8.280166
Policy mu Mean               0.022692047
Policy mu Std                0.67792
Policy mu Max                3.2860339
Policy mu Min                -2.9157684
Policy log std Mean          -1.0217327
Policy log std Std           0.30227846
Policy log std Max           0.12961072
Policy log std Min           -2.7572312
Z mean eval                  1.1420996
Z variance eval              0.012034776
total_rewards                [2356.00788645 1930.5250357  2529.82759584 3268.54530958 3889.33053693
 3793.4545546  3666.84593346 3828.54698822 3874.32102778 3639.13438524]
total_rewards_mean           3277.653925379799
total_rewards_std            693.206084691852
total_rewards_max            3889.330536933095
total_rewards_min            1930.5250356954764
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               34.592448838986456
(Previous) Eval Time (s)     24.43536664871499
Sample Time (s)              25.43713539838791
Epoch Time (s)               84.46495088608935
Total Train Time (s)         41222.36860536458
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:13:24.344157 UTC | [2020_01_10_11_46_20] Iteration #465 | Epoch Duration: 90.35725617408752
2020-01-10 23:13:24.344365 UTC | [2020_01_10_11_46_20] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1415862
Z variance train             0.012079507
KL Divergence                27.065323
KL Loss                      2.7065322
QF Loss                      760.08374
VF Loss                      136.69653
Policy Loss                  -1350.0199
Q Predictions Mean           1353.7683
Q Predictions Std            294.9757
Q Predictions Max            1572.9066
Q Predictions Min            -49.719128
V Predictions Mean           1349.666
V Predictions Std            291.39075
V Predictions Max            1566.3429
V Predictions Min            -52.249813
Log Pis Mean                 0.54272705
Log Pis Std                  2.825734
Log Pis Max                  10.707184
Log Pis Min                  -7.249789
Policy mu Mean               0.08235967
Policy mu Std                0.6442917
Policy mu Max                3.0439
Policy mu Min                -2.1950855
Policy log std Mean          -1.0290821
Policy log std Std           0.27450743
Policy log std Max           -0.09066498
Policy log std Min           -2.054089
Z mean eval                  1.1338451
Z variance eval              0.0130001325
total_rewards                [ -13.93994508  -26.69051283 3478.39341219 3971.95117229 3635.04290136
 3706.55910032 4102.70095619 1164.84598723 4057.71280525 3671.69011774]
total_rewards_mean           2774.8265994663843
total_rewards_std            1611.4396383025742
total_rewards_max            4102.7009561916675
total_rewards_min            -26.690512831820946
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               33.77468025684357
(Previous) Eval Time (s)     30.32723800605163
Sample Time (s)              24.683361511211842
Epoch Time (s)               88.78527977410704
Total Train Time (s)         41306.31749904575
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:14:48.297985 UTC | [2020_01_10_11_46_20] Iteration #466 | Epoch Duration: 83.95341229438782
2020-01-10 23:14:48.298261 UTC | [2020_01_10_11_46_20] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1332583
Z variance train             0.013037628
KL Divergence                26.659977
KL Loss                      2.6659977
QF Loss                      1142.2357
VF Loss                      313.7887
Policy Loss                  -1362.8531
Q Predictions Mean           1366.3647
Q Predictions Std            243.27269
Q Predictions Max            1583.8153
Q Predictions Min            -117.323746
V Predictions Mean           1364.4097
V Predictions Std            241.63109
V Predictions Max            1572.1802
V Predictions Min            -85.082375
Log Pis Mean                 0.6805898
Log Pis Std                  3.088291
Log Pis Max                  13.035748
Log Pis Min                  -8.303544
Policy mu Mean               0.02604998
Policy mu Std                0.6441691
Policy mu Max                2.825355
Policy mu Min                -3.0124688
Policy log std Mean          -1.0656601
Policy log std Std           0.28035557
Policy log std Max           -0.115596235
Policy log std Min           -2.5074449
Z mean eval                  1.1501154
Z variance eval              0.011433772
total_rewards                [3953.64342528 3202.71985737 3886.0113839  3717.2251082  3945.9641109
 2049.38846249 4100.29886853 3879.23831704 3772.43675305 3817.05456812]
total_rewards_mean           3632.3980854884408
total_rewards_std            574.2081925085771
total_rewards_max            4100.298868534199
total_rewards_min            2049.3884624927196
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               34.41406324505806
(Previous) Eval Time (s)     25.49506220780313
Sample Time (s)              24.56840948574245
Epoch Time (s)               84.47753493860364
Total Train Time (s)         41397.7829398294
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:16:19.774278 UTC | [2020_01_10_11_46_20] Iteration #467 | Epoch Duration: 91.47588062286377
2020-01-10 23:16:19.774447 UTC | [2020_01_10_11_46_20] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1496133
Z variance train             0.011441404
KL Divergence                27.42566
KL Loss                      2.7425659
QF Loss                      688.50665
VF Loss                      133.79492
Policy Loss                  -1392.927
Q Predictions Mean           1394.2653
Q Predictions Std            226.09561
Q Predictions Max            1577.1555
Q Predictions Min            -15.786991
V Predictions Mean           1395.344
V Predictions Std            226.08276
V Predictions Max            1586.7129
V Predictions Min            -18.306776
Log Pis Mean                 0.5194831
Log Pis Std                  2.703912
Log Pis Max                  9.181191
Log Pis Min                  -7.8996186
Policy mu Mean               -0.0031408048
Policy mu Std                0.620454
Policy mu Max                2.5959513
Policy mu Min                -2.5633223
Policy log std Mean          -1.090029
Policy log std Std           0.2997602
Policy log std Max           -0.054817915
Policy log std Min           -2.5037491
Z mean eval                  1.1440136
Z variance eval              0.0139161395
total_rewards                [ -31.43557483  559.3262245  2877.55664783 4131.03093596 2839.39019506
 1078.0490371  1049.23195856 3727.06503046  901.32600145  416.8266076 ]
total_rewards_mean           1754.8367063701257
total_rewards_std            1416.5953920569511
total_rewards_max            4131.030935962371
total_rewards_min            -31.43557482706189
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               34.56902058934793
(Previous) Eval Time (s)     32.493080482352525
Sample Time (s)              26.517638572026044
Epoch Time (s)               93.5797396437265
Total Train Time (s)         41476.95978360344
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:17:38.949052 UTC | [2020_01_10_11_46_20] Iteration #468 | Epoch Duration: 79.17447519302368
2020-01-10 23:17:38.949246 UTC | [2020_01_10_11_46_20] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.142753
Z variance train             0.013895815
KL Divergence                27.347523
KL Loss                      2.7347524
QF Loss                      882.55884
VF Loss                      203.34624
Policy Loss                  -1375.31
Q Predictions Mean           1374.169
Q Predictions Std            271.9989
Q Predictions Max            1608.3523
Q Predictions Min            -66.604996
V Predictions Mean           1367.6802
V Predictions Std            259.78876
V Predictions Max            1565.2393
V Predictions Min            -66.84996
Log Pis Mean                 0.37445787
Log Pis Std                  3.067563
Log Pis Max                  11.826826
Log Pis Min                  -9.132029
Policy mu Mean               -0.004431977
Policy mu Std                0.6535544
Policy mu Max                2.865865
Policy mu Min                -2.3898468
Policy log std Mean          -1.0536757
Policy log std Std           0.30877253
Policy log std Max           -0.0156235695
Policy log std Min           -2.9398286
Z mean eval                  1.1304538
Z variance eval              0.0089107305
total_rewards                [1552.97801946 4034.96779366 4146.1657867  3955.60020817 4033.4491073
 1069.10423283   10.31059334 1675.49271396 4168.62113074 4209.51123727]
total_rewards_mean           2885.6200823438285
total_rewards_std            1535.532534963481
total_rewards_max            4209.5112372736585
total_rewards_min            10.310593343845436
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               34.319429436698556
(Previous) Eval Time (s)     18.087458869908005
Sample Time (s)              25.64277950208634
Epoch Time (s)               78.0496678086929
Total Train Time (s)         41562.501969518606
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:19:04.496688 UTC | [2020_01_10_11_46_20] Iteration #469 | Epoch Duration: 85.54730081558228
2020-01-10 23:19:04.496932 UTC | [2020_01_10_11_46_20] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.130577
Z variance train             0.0089354655
KL Divergence                28.080269
KL Loss                      2.808027
QF Loss                      688.91504
VF Loss                      144.42009
Policy Loss                  -1382.878
Q Predictions Mean           1385.178
Q Predictions Std            217.67043
Q Predictions Max            1584.8978
Q Predictions Min            -50.141853
V Predictions Mean           1389.9307
V Predictions Std            220.13716
V Predictions Max            1582.5958
V Predictions Min            -58.329323
Log Pis Mean                 1.1137052
Log Pis Std                  2.8882747
Log Pis Max                  9.406406
Log Pis Min                  -6.9441605
Policy mu Mean               0.009155236
Policy mu Std                0.6558241
Policy mu Max                2.8542812
Policy mu Min                -2.0984766
Policy log std Mean          -1.0999209
Policy log std Std           0.29152715
Policy log std Max           -0.24721342
Policy log std Min           -2.3203237
Z mean eval                  1.1613901
Z variance eval              0.0076200804
total_rewards                [ 833.43970339 1841.69805664  313.17429208 4019.69029885  952.62356353
 1026.12969892 1923.83248393 1400.86616912  893.03446944  829.34507302]
total_rewards_mean           1403.3833808936881
total_rewards_std            987.7716155984201
total_rewards_max            4019.6902988524234
total_rewards_min            313.1742920835079
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               33.94925415702164
(Previous) Eval Time (s)     25.58478158991784
Sample Time (s)              25.566751699894667
Epoch Time (s)               85.10078744683415
Total Train Time (s)         41635.536940087564
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:20:17.535369 UTC | [2020_01_10_11_46_20] Iteration #470 | Epoch Duration: 73.03829383850098
2020-01-10 23:20:17.535549 UTC | [2020_01_10_11_46_20] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.159759
Z variance train             0.007629948
KL Divergence                28.524544
KL Loss                      2.8524544
QF Loss                      1403.6074
VF Loss                      604.48157
Policy Loss                  -1379.9618
Q Predictions Mean           1379.5627
Q Predictions Std            241.43039
Q Predictions Max            1562.4989
Q Predictions Min            -10.614176
V Predictions Mean           1372.8821
V Predictions Std            240.01274
V Predictions Max            1555.7042
V Predictions Min            -30.002607
Log Pis Mean                 0.81955814
Log Pis Std                  3.190495
Log Pis Max                  20.260857
Log Pis Min                  -6.4533997
Policy mu Mean               0.06056705
Policy mu Std                0.66136307
Policy mu Max                3.1855755
Policy mu Min                -2.8501883
Policy log std Mean          -1.0618417
Policy log std Std           0.2943395
Policy log std Max           -0.22304922
Policy log std Min           -2.4183152
Z mean eval                  1.1734635
Z variance eval              0.0038423974
total_rewards                [-428.67110299 1108.86430868 3795.48866417 4030.45496036 1489.39098089
 3636.90220775 2030.92241869  825.30156525 3421.72723408 2107.98124052]
total_rewards_mean           2201.8362477401542
total_rewards_std            1413.7087967548016
total_rewards_max            4030.4549603610194
total_rewards_min            -428.6711029935214
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               34.15891260327771
(Previous) Eval Time (s)     13.521945657208562
Sample Time (s)              24.978482525795698
Epoch Time (s)               72.65934078628197
Total Train Time (s)         41720.32336469833
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:21:42.326643 UTC | [2020_01_10_11_46_20] Iteration #471 | Epoch Duration: 84.79096341133118
2020-01-10 23:21:42.326827 UTC | [2020_01_10_11_46_20] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1743776
Z variance train             0.0038411103
KL Divergence                29.486423
KL Loss                      2.9486425
QF Loss                      749.09863
VF Loss                      244.11044
Policy Loss                  -1380.5092
Q Predictions Mean           1383.0829
Q Predictions Std            271.57065
Q Predictions Max            1612.6349
Q Predictions Min            -72.80713
V Predictions Mean           1375.8666
V Predictions Std            269.12903
V Predictions Max            1601.365
V Predictions Min            -89.140724
Log Pis Mean                 0.3097888
Log Pis Std                  2.755943
Log Pis Max                  9.514882
Log Pis Min                  -6.886478
Policy mu Mean               0.086297244
Policy mu Std                0.6399273
Policy mu Max                2.831787
Policy mu Min                -2.7586613
Policy log std Mean          -1.0223317
Policy log std Std           0.2800619
Policy log std Max           -0.024989903
Policy log std Min           -2.4303646
Z mean eval                  1.1746308
Z variance eval              0.005587685
total_rewards                [3433.46251503 3854.9768605  3638.6217558  3775.89511159 3900.59423068
 3631.43395042   19.94552092 3727.12873622 3829.65239638 3930.22113541]
total_rewards_mean           3374.193221294024
total_rewards_std            1127.0037553363118
total_rewards_max            3930.221135406772
total_rewards_min            19.94552092272159
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               34.002309433184564
(Previous) Eval Time (s)     25.653253267053515
Sample Time (s)              25.544751415029168
Epoch Time (s)               85.20031411526725
Total Train Time (s)         41810.463007438
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:23:12.470847 UTC | [2020_01_10_11_46_20] Iteration #472 | Epoch Duration: 90.14388728141785
2020-01-10 23:23:12.471027 UTC | [2020_01_10_11_46_20] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1742266
Z variance train             0.0055800388
KL Divergence                28.034771
KL Loss                      2.803477
QF Loss                      1871.9264
VF Loss                      485.22345
Policy Loss                  -1392.9536
Q Predictions Mean           1393.2031
Q Predictions Std            214.86877
Q Predictions Max            1585.8469
Q Predictions Min            -32.505836
V Predictions Mean           1382.2509
V Predictions Std            204.54027
V Predictions Max            1569.4208
V Predictions Min            -12.865887
Log Pis Mean                 0.7391742
Log Pis Std                  3.1466217
Log Pis Max                  17.984552
Log Pis Min                  -6.0358415
Policy mu Mean               0.040872723
Policy mu Std                0.6862326
Policy mu Max                3.441888
Policy mu Min                -2.9380205
Policy log std Mean          -1.0482231
Policy log std Std           0.2836004
Policy log std Max           0.51342046
Policy log std Min           -2.5208976
Z mean eval                  1.1510522
Z variance eval              0.0056870747
total_rewards                [2680.55829636  441.2182259  2719.20574833 3517.17726935 3229.02435126
 3527.10563178 3712.35037023 3640.90885759 3605.93761232 3567.17631386]
total_rewards_mean           3064.0662676967045
total_rewards_std            942.9755626664461
total_rewards_max            3712.3503702299986
total_rewards_min            441.218225901469
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               34.267007547896355
(Previous) Eval Time (s)     30.596468328032643
Sample Time (s)              26.19056859286502
Epoch Time (s)               91.05404446879402
Total Train Time (s)         41904.39194906736
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:24:46.404927 UTC | [2020_01_10_11_46_20] Iteration #473 | Epoch Duration: 93.93376302719116
2020-01-10 23:24:46.405145 UTC | [2020_01_10_11_46_20] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1509471
Z variance train             0.0056912755
KL Divergence                27.999474
KL Loss                      2.7999475
QF Loss                      884.1884
VF Loss                      390.5036
Policy Loss                  -1384.7104
Q Predictions Mean           1387.5288
Q Predictions Std            256.27087
Q Predictions Max            1611.9852
Q Predictions Min            -10.751008
V Predictions Mean           1393.8964
V Predictions Std            248.8087
V Predictions Max            1592.5314
V Predictions Min            -8.898647
Log Pis Mean                 0.82704127
Log Pis Std                  2.811453
Log Pis Max                  10.19562
Log Pis Min                  -6.9131317
Policy mu Mean               -0.02197083
Policy mu Std                0.652233
Policy mu Max                2.5818114
Policy mu Min                -2.6863534
Policy log std Mean          -1.0774992
Policy log std Std           0.2898104
Policy log std Max           -0.087595105
Policy log std Min           -2.2773416
Z mean eval                  1.1628604
Z variance eval              0.0061236294
total_rewards                [ -66.97759318 3687.32351662 1990.04800903 2326.51594935 -154.18881931
 3613.45196133 2691.46666757 3772.29565305 3748.1639665  2223.52906755]
total_rewards_mean           2383.1628378520136
total_rewards_std            1404.527976133338
total_rewards_max            3772.2956530497886
total_rewards_min            -154.1888193067867
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               33.81486739823595
(Previous) Eval Time (s)     33.47585898125544
Sample Time (s)              26.711808391381055
Epoch Time (s)               94.00253477087244
Total Train Time (s)         41994.072312560864
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:26:16.090368 UTC | [2020_01_10_11_46_20] Iteration #474 | Epoch Duration: 89.68505048751831
2020-01-10 23:26:16.090555 UTC | [2020_01_10_11_46_20] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1623461
Z variance train             0.006143039
KL Divergence                27.886227
KL Loss                      2.7886226
QF Loss                      645.14294
VF Loss                      181.26447
Policy Loss                  -1397.833
Q Predictions Mean           1396.9856
Q Predictions Std            230.066
Q Predictions Max            1596.2
Q Predictions Min            -19.366726
V Predictions Mean           1392.7651
V Predictions Std            228.96182
V Predictions Max            1596.2161
V Predictions Min            -13.512445
Log Pis Mean                 0.4451196
Log Pis Std                  2.893538
Log Pis Max                  9.160442
Log Pis Min                  -10.2563
Policy mu Mean               0.010251779
Policy mu Std                0.643314
Policy mu Max                2.492095
Policy mu Min                -2.4729512
Policy log std Mean          -1.0544022
Policy log std Std           0.27723014
Policy log std Max           -0.16214216
Policy log std Min           -2.673323
Z mean eval                  1.1483933
Z variance eval              0.007145848
total_rewards                [3774.12657345 4183.03294703  887.91030899 3960.73885944 3817.13434396
 3847.62568234 4139.8318948  2527.34226743 3175.92784866 3801.23029571]
total_rewards_mean           3411.4901021807977
total_rewards_std            962.8738438210213
total_rewards_max            4183.032947029346
total_rewards_min            887.9103089896595
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               34.16719905100763
(Previous) Eval Time (s)     29.15803591813892
Sample Time (s)              25.85020765522495
Epoch Time (s)               89.1754426243715
Total Train Time (s)         42086.955587010365
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:27:48.978465 UTC | [2020_01_10_11_46_20] Iteration #475 | Epoch Duration: 92.88777089118958
2020-01-10 23:27:48.978671 UTC | [2020_01_10_11_46_20] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1478212
Z variance train             0.0071269376
KL Divergence                28.287868
KL Loss                      2.8287868
QF Loss                      603.3579
VF Loss                      200.62381
Policy Loss                  -1413.5071
Q Predictions Mean           1411.5569
Q Predictions Std            216.7534
Q Predictions Max            1603.9767
Q Predictions Min            -97.83536
V Predictions Mean           1413.7913
V Predictions Std            215.84428
V Predictions Max            1609.2408
V Predictions Min            -82.711235
Log Pis Mean                 1.1536055
Log Pis Std                  2.713109
Log Pis Max                  12.759544
Log Pis Min                  -7.0416565
Policy mu Mean               0.04947737
Policy mu Std                0.69145507
Policy mu Max                2.7766132
Policy mu Min                -2.5966785
Policy log std Mean          -1.0562508
Policy log std Std           0.2982936
Policy log std Max           -0.15193683
Policy log std Min           -2.714424
Z mean eval                  1.1432062
Z variance eval              0.011898607
total_rewards                [3538.2773053  3912.56499933 3440.63312256  336.24184829  588.38940242
 2120.34615661   13.07699389 2923.26703158 3146.9108035   382.65678588]
total_rewards_mean           2040.2364449361048
total_rewards_std            1469.3584788866142
total_rewards_max            3912.5649993277
total_rewards_min            13.076993886640702
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               34.707248270045966
(Previous) Eval Time (s)     32.87009550118819
Sample Time (s)              25.975984473712742
Epoch Time (s)               93.5533282449469
Total Train Time (s)         42168.588238261174
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:29:10.615542 UTC | [2020_01_10_11_46_20] Iteration #476 | Epoch Duration: 81.63673377037048
2020-01-10 23:29:10.615727 UTC | [2020_01_10_11_46_20] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1440243
Z variance train             0.011931759
KL Divergence                28.847507
KL Loss                      2.8847508
QF Loss                      2363.9421
VF Loss                      1151.1952
Policy Loss                  -1394.865
Q Predictions Mean           1394.6323
Q Predictions Std            219.42776
Q Predictions Max            1580.5927
Q Predictions Min            8.960054
V Predictions Mean           1385.5133
V Predictions Std            220.35135
V Predictions Max            1562.8503
V Predictions Min            17.41783
Log Pis Mean                 0.89152884
Log Pis Std                  3.1000159
Log Pis Max                  15.730899
Log Pis Min                  -6.6871247
Policy mu Mean               0.068935215
Policy mu Std                0.7068134
Policy mu Max                2.7917678
Policy mu Min                -3.1753228
Policy log std Mean          -1.051022
Policy log std Std           0.29459736
Policy log std Max           -0.09805894
Policy log std Min           -2.4190145
Z mean eval                  1.127388
Z variance eval              0.0074699433
total_rewards                [1997.578235   3763.23018569 4065.64114461 3994.17372203 1418.9488809
 4051.70633826 4004.95521155 3789.35187937  617.44218331 1918.59098112]
total_rewards_mean           2962.1618761849086
total_rewards_std            1256.2592232350776
total_rewards_max            4065.6411446130455
total_rewards_min            617.4421833121764
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               34.429477700032294
(Previous) Eval Time (s)     20.953128234948963
Sample Time (s)              24.777353543788195
Epoch Time (s)               80.15995947876945
Total Train Time (s)         42258.07686277898
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:30:40.106891 UTC | [2020_01_10_11_46_20] Iteration #477 | Epoch Duration: 89.4910478591919
2020-01-10 23:30:40.107014 UTC | [2020_01_10_11_46_20] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.127792
Z variance train             0.0074703605
KL Divergence                29.02548
KL Loss                      2.902548
QF Loss                      13208.141
VF Loss                      174.81111
Policy Loss                  -1420.4631
Q Predictions Mean           1422.5272
Q Predictions Std            180.39964
Q Predictions Max            1586.6763
Q Predictions Min            -50.23578
V Predictions Mean           1417.6775
V Predictions Std            176.41606
V Predictions Max            1582.8075
V Predictions Min            -15.3279295
Log Pis Mean                 0.95142543
Log Pis Std                  2.7579176
Log Pis Max                  10.985209
Log Pis Min                  -6.846743
Policy mu Mean               0.069683485
Policy mu Std                0.67960477
Policy mu Max                2.668367
Policy mu Min                -2.7322147
Policy log std Mean          -1.075475
Policy log std Std           0.2917747
Policy log std Max           -0.21979636
Policy log std Min           -2.5604172
Z mean eval                  1.176904
Z variance eval              0.006348517
total_rewards                [  48.97130371 1376.35743974 4031.81162449 4072.44404481 4005.18070798
 2325.89097064  825.89911816 4083.03463424 3894.98293414 3987.22180473]
total_rewards_mean           2865.179458261974
total_rewards_std            1500.595963257252
total_rewards_max            4083.034634235394
total_rewards_min            48.97130370782584
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               34.28510848712176
(Previous) Eval Time (s)     30.283898756839335
Sample Time (s)              23.5161808161065
Epoch Time (s)               88.0851880600676
Total Train Time (s)         42342.563862957526
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:32:04.597661 UTC | [2020_01_10_11_46_20] Iteration #478 | Epoch Duration: 84.49056363105774
2020-01-10 23:32:04.597782 UTC | [2020_01_10_11_46_20] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1769149
Z variance train             0.006343603
KL Divergence                28.696209
KL Loss                      2.869621
QF Loss                      910.10876
VF Loss                      474.09967
Policy Loss                  -1408.8658
Q Predictions Mean           1407.084
Q Predictions Std            236.38103
Q Predictions Max            1592.0116
Q Predictions Min            -75.32848
V Predictions Mean           1393.2661
V Predictions Std            234.60257
V Predictions Max            1580.4053
V Predictions Min            -104.50127
Log Pis Mean                 0.88519204
Log Pis Std                  2.9029121
Log Pis Max                  13.730463
Log Pis Min                  -7.592508
Policy mu Mean               -0.006738902
Policy mu Std                0.63555765
Policy mu Max                3.0084412
Policy mu Min                -1.8766086
Policy log std Mean          -1.1173323
Policy log std Std           0.31758416
Policy log std Max           -0.10806024
Policy log std Min           -2.8230958
Z mean eval                  1.1433775
Z variance eval              0.0054711276
total_rewards                [3740.94904969 4028.49975383 3737.94139961 3909.81562368 3913.32482539
  564.09037875 3671.11110902 3667.61686433 1274.42554847 4101.0177684 ]
total_rewards_mean           3260.879232116175
total_rewards_std            1189.635537069076
total_rewards_max            4101.017768395274
total_rewards_min            564.0903787504552
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               34.07085510715842
(Previous) Eval Time (s)     26.688937635160983
Sample Time (s)              26.68655584938824
Epoch Time (s)               87.44634859170765
Total Train Time (s)         42431.52660597209
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:33:33.565989 UTC | [2020_01_10_11_46_20] Iteration #479 | Epoch Duration: 88.96808052062988
2020-01-10 23:33:33.566269 UTC | [2020_01_10_11_46_20] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.142435
Z variance train             0.00545966
KL Divergence                28.881283
KL Loss                      2.8881283
QF Loss                      2105.2344
VF Loss                      442.0923
Policy Loss                  -1390.4275
Q Predictions Mean           1391.6399
Q Predictions Std            263.5142
Q Predictions Max            1612.91
Q Predictions Min            -62.78434
V Predictions Mean           1399.5044
V Predictions Std            266.6356
V Predictions Max            1604.203
V Predictions Min            -79.050186
Log Pis Mean                 0.96266913
Log Pis Std                  3.1534348
Log Pis Max                  13.4405155
Log Pis Min                  -8.809004
Policy mu Mean               0.034141317
Policy mu Std                0.6689018
Policy mu Max                2.8095796
Policy mu Min                -2.659858
Policy log std Mean          -1.0768358
Policy log std Std           0.3126201
Policy log std Max           -0.19611442
Policy log std Min           -3.5022502
Z mean eval                  1.1670848
Z variance eval              0.0053854184
total_rewards                [3936.97435023 3874.03221291 3955.9888174  4065.61066054 4038.22466329
 3897.85270544 4046.98352667   14.06858449 3906.57317978 2861.22485637]
total_rewards_mean           3459.7533557120623
total_rewards_std            1196.4408379159754
total_rewards_max            4065.6106605413443
total_rewards_min            14.068584488838404
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               33.92778707575053
(Previous) Eval Time (s)     28.210323793813586
Sample Time (s)              25.62664543092251
Epoch Time (s)               87.76475630048662
Total Train Time (s)         42522.89449457405
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:35:04.938934 UTC | [2020_01_10_11_46_20] Iteration #480 | Epoch Duration: 91.37245559692383
2020-01-10 23:35:04.939144 UTC | [2020_01_10_11_46_20] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1679738
Z variance train             0.0053845895
KL Divergence                29.22102
KL Loss                      2.922102
QF Loss                      991.8003
VF Loss                      577.57556
Policy Loss                  -1375.7178
Q Predictions Mean           1379.511
Q Predictions Std            311.98074
Q Predictions Max            1611.6444
Q Predictions Min            -27.895676
V Predictions Mean           1381.6863
V Predictions Std            313.17505
V Predictions Max            1609.1732
V Predictions Min            -26.784527
Log Pis Mean                 0.61379004
Log Pis Std                  3.0683844
Log Pis Max                  9.981004
Log Pis Min                  -7.1423097
Policy mu Mean               0.04686461
Policy mu Std                0.6552728
Policy mu Max                2.8436103
Policy mu Min                -2.6424007
Policy log std Mean          -1.0579147
Policy log std Std           0.31158748
Policy log std Max           -0.07560837
Policy log std Min           -2.6399813
Z mean eval                  1.1626201
Z variance eval              0.0042396546
total_rewards                [3746.49681264 3953.94252838 -138.30054868 1390.73171118 3668.16623293
  128.32724043 3970.49246635 1715.47435444 4093.74777019  263.25662053]
total_rewards_mean           2279.233518840703
total_rewards_std            1693.5689008246047
total_rewards_max            4093.74777019291
total_rewards_min            -138.30054867818495
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               34.276233912911266
(Previous) Eval Time (s)     31.81766881700605
Sample Time (s)              24.883658034261316
Epoch Time (s)               90.97756076417863
Total Train Time (s)         42609.042556435335
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:36:31.093199 UTC | [2020_01_10_11_46_20] Iteration #481 | Epoch Duration: 86.15382432937622
2020-01-10 23:36:31.093409 UTC | [2020_01_10_11_46_20] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1629632
Z variance train             0.004238724
KL Divergence                30.327076
KL Loss                      3.0327077
QF Loss                      1874.1808
VF Loss                      1264.6915
Policy Loss                  -1418.1682
Q Predictions Mean           1416.1599
Q Predictions Std            217.02144
Q Predictions Max            1595.413
Q Predictions Min            -46.835625
V Predictions Mean           1395.9568
V Predictions Std            216.9402
V Predictions Max            1570.0367
V Predictions Min            -25.730005
Log Pis Mean                 0.8730876
Log Pis Std                  2.942217
Log Pis Max                  10.873317
Log Pis Min                  -6.138205
Policy mu Mean               0.011367279
Policy mu Std                0.6690312
Policy mu Max                4.6254864
Policy mu Min                -2.5592663
Policy log std Mean          -1.0975251
Policy log std Std           0.29932517
Policy log std Max           0.1424554
Policy log std Min           -2.55014
Z mean eval                  1.1580371
Z variance eval              0.004289241
total_rewards                [3701.61784459 3732.66122563 1929.44026921 3720.36842705 2549.21920508
 4012.87083289 3977.69271869 3805.92867325 4029.08517168 3849.39904484]
total_rewards_mean           3530.828341289569
total_rewards_std            670.1724670391809
total_rewards_max            4029.0851716830057
total_rewards_min            1929.440269210974
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               34.099209140986204
(Previous) Eval Time (s)     26.993559314869344
Sample Time (s)              25.84123992640525
Epoch Time (s)               86.9340083822608
Total Train Time (s)         42700.863196291495
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:38:02.918112 UTC | [2020_01_10_11_46_20] Iteration #482 | Epoch Duration: 91.82455801963806
2020-01-10 23:38:02.918291 UTC | [2020_01_10_11_46_20] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1588621
Z variance train             0.004284299
KL Divergence                30.405045
KL Loss                      3.0405045
QF Loss                      490.03894
VF Loss                      87.53263
Policy Loss                  -1411.978
Q Predictions Mean           1413.0121
Q Predictions Std            266.70044
Q Predictions Max            1594.7133
Q Predictions Min            -93.67955
V Predictions Mean           1412.3896
V Predictions Std            267.63666
V Predictions Max            1594.219
V Predictions Min            -74.66407
Log Pis Mean                 0.9474149
Log Pis Std                  3.1611075
Log Pis Max                  9.593288
Log Pis Min                  -11.641634
Policy mu Mean               0.017058343
Policy mu Std                0.65145737
Policy mu Max                2.9521723
Policy mu Min                -2.8428507
Policy log std Mean          -1.0834142
Policy log std Std           0.30036002
Policy log std Max           -0.02028197
Policy log std Min           -2.2446117
Z mean eval                  1.1857421
Z variance eval              0.0058936244
total_rewards                [2339.2655846   457.53760592 2545.24561656  951.64263137 3602.82629033
 3034.09140575 3949.21461615 1697.37891223 3885.30817077 3693.32185581]
total_rewards_mean           2615.583268950595
total_rewards_std            1185.426076135308
total_rewards_max            3949.2146161537207
total_rewards_min            457.5376059212298
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               34.15230396995321
(Previous) Eval Time (s)     31.88375276979059
Sample Time (s)              25.873289555776864
Epoch Time (s)               91.90934629552066
Total Train Time (s)         42786.094939834904
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:39:28.156513 UTC | [2020_01_10_11_46_20] Iteration #483 | Epoch Duration: 85.23808312416077
2020-01-10 23:39:28.156701 UTC | [2020_01_10_11_46_20] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1877573
Z variance train             0.0058796266
KL Divergence                30.168743
KL Loss                      3.0168743
QF Loss                      1898.9534
VF Loss                      186.46533
Policy Loss                  -1402.3881
Q Predictions Mean           1399.2021
Q Predictions Std            272.48068
Q Predictions Max            1625.3544
Q Predictions Min            -94.17847
V Predictions Mean           1398.3699
V Predictions Std            268.80035
V Predictions Max            1620.4834
V Predictions Min            -84.6253
Log Pis Mean                 0.6935249
Log Pis Std                  2.6917946
Log Pis Max                  12.818327
Log Pis Min                  -6.2307253
Policy mu Mean               0.08034195
Policy mu Std                0.65475684
Policy mu Max                3.0114713
Policy mu Min                -2.1550515
Policy log std Mean          -1.0552117
Policy log std Std           0.30606237
Policy log std Max           -0.04682076
Policy log std Min           -3.017897
Z mean eval                  1.1597965
Z variance eval              0.0040318873
total_rewards                [3684.5153657   608.0056395   588.62480174 3778.94235125 2176.88290024
 2218.14903884 2309.33332963 4011.62164388 3909.07652155  831.25235577]
total_rewards_mean           2411.6403948102734
total_rewards_std            1321.707514595212
total_rewards_max            4011.621643879878
total_rewards_min            588.6248017407152
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               33.79097761726007
(Previous) Eval Time (s)     25.212151578627527
Sample Time (s)              25.216503478121012
Epoch Time (s)               84.21963267400861
Total Train Time (s)         42868.704396083485
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:40:50.770991 UTC | [2020_01_10_11_46_20] Iteration #484 | Epoch Duration: 82.61415386199951
2020-01-10 23:40:50.771211 UTC | [2020_01_10_11_46_20] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158881
Z variance train             0.0040285266
KL Divergence                30.241566
KL Loss                      3.0241566
QF Loss                      1364.8611
VF Loss                      1550.7908
Policy Loss                  -1419.6279
Q Predictions Mean           1423.2712
Q Predictions Std            221.77187
Q Predictions Max            1593.4651
Q Predictions Min            -47.16663
V Predictions Mean           1428.8057
V Predictions Std            207.5429
V Predictions Max            1594.0187
V Predictions Min            -36.218254
Log Pis Mean                 1.0715925
Log Pis Std                  2.994887
Log Pis Max                  12.007008
Log Pis Min                  -8.051075
Policy mu Mean               0.011827957
Policy mu Std                0.6914464
Policy mu Max                2.7218173
Policy mu Min                -2.5696986
Policy log std Mean          -1.0672904
Policy log std Std           0.30754283
Policy log std Max           -0.095339954
Policy log std Min           -2.9744718
Z mean eval                  1.1665504
Z variance eval              0.007058351
total_rewards                [ 776.15974115 3875.07365921 3826.81107014 4015.51279364 3877.99903335
 4000.88546035  673.76221893 3839.66933932 1514.41731128 3902.02189216]
total_rewards_mean           3030.23125195397
total_rewards_std            1353.7593264482975
total_rewards_max            4015.5127936435606
total_rewards_min            673.7622189317213
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               34.18354462180287
(Previous) Eval Time (s)     23.60634200507775
Sample Time (s)              25.737046835012734
Epoch Time (s)               83.52693346189335
Total Train Time (s)         42959.36879073223
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:42:21.440770 UTC | [2020_01_10_11_46_20] Iteration #485 | Epoch Duration: 90.66941237449646
2020-01-10 23:42:21.440949 UTC | [2020_01_10_11_46_20] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1654851
Z variance train             0.0070594884
KL Divergence                29.283611
KL Loss                      2.9283612
QF Loss                      1489.6348
VF Loss                      374.85895
Policy Loss                  -1426.3175
Q Predictions Mean           1429.5312
Q Predictions Std            192.23065
Q Predictions Max            1594.5992
Q Predictions Min            -92.53631
V Predictions Mean           1433.1205
V Predictions Std            193.26111
V Predictions Max            1612.179
V Predictions Min            -76.619644
Log Pis Mean                 1.2273023
Log Pis Std                  3.2684321
Log Pis Max                  13.883072
Log Pis Min                  -6.0072155
Policy mu Mean               0.044248156
Policy mu Std                0.66772735
Policy mu Max                2.8929067
Policy mu Min                -2.4800012
Policy log std Mean          -1.1096635
Policy log std Std           0.31753114
Policy log std Max           0.085205615
Policy log std Min           -2.7658763
Z mean eval                  1.1536617
Z variance eval              0.0042146873
total_rewards                [ 596.55027528 1623.40534741 1827.91488188 3891.95824961 3967.48367379
 3898.98789296 4095.50817316 4302.83722349  761.43924738 1026.81807362]
total_rewards_mean           2599.290303857614
total_rewards_std            1475.8591359267982
total_rewards_max            4302.837223486762
total_rewards_min            596.5502752792876
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               34.08481888612732
(Previous) Eval Time (s)     30.74846458528191
Sample Time (s)              25.128715629223734
Epoch Time (s)               89.96199910063297
Total Train Time (s)         43043.3526754803
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:43:45.429731 UTC | [2020_01_10_11_46_20] Iteration #486 | Epoch Duration: 83.98863577842712
2020-01-10 23:43:45.429948 UTC | [2020_01_10_11_46_20] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1558157
Z variance train             0.0042160777
KL Divergence                30.16577
KL Loss                      3.016577
QF Loss                      933.03357
VF Loss                      149.90086
Policy Loss                  -1415.811
Q Predictions Mean           1416.0713
Q Predictions Std            244.72987
Q Predictions Max            1630.0997
Q Predictions Min            -130.65819
V Predictions Mean           1418.0045
V Predictions Std            243.43643
V Predictions Max            1629.3225
V Predictions Min            -85.935936
Log Pis Mean                 0.9814079
Log Pis Std                  2.90277
Log Pis Max                  8.6174755
Log Pis Min                  -10.607697
Policy mu Mean               0.058879796
Policy mu Std                0.638954
Policy mu Max                2.6244247
Policy mu Min                -1.8989643
Policy log std Mean          -1.1120894
Policy log std Std           0.31184682
Policy log std Max           0.16525435
Policy log std Min           -2.8235338
Z mean eval                  1.1882107
Z variance eval              0.007687433
total_rewards                [1664.71248064 3397.37443199 4103.37897908 3441.40305694 3818.97520258
 4066.61169927 2619.44467295 1347.08783222  413.66135534 2894.70772974]
total_rewards_mean           2776.735744075104
total_rewards_std            1193.325927264312
total_rewards_max            4103.378979083315
total_rewards_min            413.6613553399703
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               33.791547175031155
(Previous) Eval Time (s)     24.77470993436873
Sample Time (s)              24.558521472848952
Epoch Time (s)               83.12477858224884
Total Train Time (s)         43127.54695507698
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:45:09.630101 UTC | [2020_01_10_11_46_20] Iteration #487 | Epoch Duration: 84.19999647140503
2020-01-10 23:45:09.630310 UTC | [2020_01_10_11_46_20] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1896461
Z variance train             0.0076922686
KL Divergence                28.719711
KL Loss                      2.8719711
QF Loss                      1729.1758
VF Loss                      315.59985
Policy Loss                  -1410.305
Q Predictions Mean           1412.2129
Q Predictions Std            274.816
Q Predictions Max            1669.8955
Q Predictions Min            -34.74021
V Predictions Mean           1407.004
V Predictions Std            269.534
V Predictions Max            1645.939
V Predictions Min            -31.167826
Log Pis Mean                 1.2120792
Log Pis Std                  3.6016183
Log Pis Max                  15.313177
Log Pis Min                  -7.2360163
Policy mu Mean               0.045058094
Policy mu Std                0.6833045
Policy mu Max                2.9969535
Policy mu Min                -4.044195
Policy log std Mean          -1.1134233
Policy log std Std           0.341438
Policy log std Max           -0.08493674
Policy log std Min           -2.9487638
Z mean eval                  1.2216629
Z variance eval              0.0062785884
total_rewards                [  29.52634201 4047.30351657 3986.98360998 3807.11006363 3877.76159261
 3633.75773025 3714.14013902 3957.53698831 3774.18048476 4019.37470867]
total_rewards_mean           3484.7675175795075
total_rewards_std            1159.0338202455973
total_rewards_max            4047.3035165675396
total_rewards_min            29.526342005280007
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               35.5636948319152
(Previous) Eval Time (s)     25.849613555241376
Sample Time (s)              25.216197807341814
Epoch Time (s)               86.62950619449839
Total Train Time (s)         43221.223690353334
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:46:43.310861 UTC | [2020_01_10_11_46_20] Iteration #488 | Epoch Duration: 93.68040704727173
2020-01-10 23:46:43.311045 UTC | [2020_01_10_11_46_20] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2222332
Z variance train             0.0062830187
KL Divergence                28.96407
KL Loss                      2.896407
QF Loss                      1519.2823
VF Loss                      533.67175
Policy Loss                  -1381.329
Q Predictions Mean           1381.4224
Q Predictions Std            316.3222
Q Predictions Max            1633.6729
Q Predictions Min            -95.73735
V Predictions Mean           1391.6123
V Predictions Std            315.01456
V Predictions Max            1605.9191
V Predictions Min            -98.151665
Log Pis Mean                 1.363658
Log Pis Std                  3.589349
Log Pis Max                  17.159191
Log Pis Min                  -5.6962233
Policy mu Mean               0.03613843
Policy mu Std                0.6803238
Policy mu Max                2.7602193
Policy mu Min                -3.3121533
Policy log std Mean          -1.0681123
Policy log std Std           0.31889817
Policy log std Max           0.0010630488
Policy log std Min           -3.4046278
Z mean eval                  1.133013
Z variance eval              0.0058357827
total_rewards                [3895.96667377 4044.80415985 3754.73645454 1315.3295548  2064.90068323
 3896.25273329 4003.28582393 2935.38226017 3867.79056094 3733.4713044 ]
total_rewards_mean           3351.192020892862
total_rewards_std            897.119472831142
total_rewards_max            4044.8041598521468
total_rewards_min            1315.3295547966377
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               36.475267217028886
(Previous) Eval Time (s)     32.90009085694328
Sample Time (s)              26.49737073108554
Epoch Time (s)               95.8727288050577
Total Train Time (s)         43314.536704288796
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:48:16.629240 UTC | [2020_01_10_11_46_20] Iteration #489 | Epoch Duration: 93.31805467605591
2020-01-10 23:48:16.629448 UTC | [2020_01_10_11_46_20] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1329652
Z variance train             0.0058396305
KL Divergence                29.062784
KL Loss                      2.9062784
QF Loss                      2069.9666
VF Loss                      571.33704
Policy Loss                  -1417.6615
Q Predictions Mean           1421.6199
Q Predictions Std            239.01859
Q Predictions Max            1638.6016
Q Predictions Min            5.8689346
V Predictions Mean           1420.9712
V Predictions Std            235.30034
V Predictions Max            1634.4901
V Predictions Min            8.649179
Log Pis Mean                 0.90444416
Log Pis Std                  3.032442
Log Pis Max                  14.150132
Log Pis Min                  -6.049367
Policy mu Mean               0.05173219
Policy mu Std                0.6672013
Policy mu Max                2.7025597
Policy mu Min                -3.1461115
Policy log std Mean          -1.0729655
Policy log std Std           0.28128123
Policy log std Max           -0.047935843
Policy log std Min           -2.9031491
Z mean eval                  1.129565
Z variance eval              0.005190526
total_rewards                [3741.96982181 4007.7704544  4069.86110523  486.31653919 4080.96657912
  212.19184851  927.60856625 3839.53472199  945.58477379   13.45927463]
total_rewards_mean           2232.526368493427
total_rewards_std            1738.3672035845009
total_rewards_max            4080.966579118164
total_rewards_min            13.459274631677644
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               37.42154219793156
(Previous) Eval Time (s)     30.344970664009452
Sample Time (s)              26.648711238522083
Epoch Time (s)               94.41522410046309
Total Train Time (s)         43400.19704942452
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:49:42.301932 UTC | [2020_01_10_11_46_20] Iteration #490 | Epoch Duration: 85.67229437828064
2020-01-10 23:49:42.302298 UTC | [2020_01_10_11_46_20] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1312157
Z variance train             0.0051950505
KL Divergence                29.01469
KL Loss                      2.901469
QF Loss                      1050.2769
VF Loss                      871.6485
Policy Loss                  -1411.6777
Q Predictions Mean           1412.6235
Q Predictions Std            252.16263
Q Predictions Max            1628.006
Q Predictions Min            -91.555695
V Predictions Mean           1403.2844
V Predictions Std            253.62234
V Predictions Max            1614.6843
V Predictions Min            -87.77468
Log Pis Mean                 0.65800416
Log Pis Std                  3.1957495
Log Pis Max                  13.50045
Log Pis Min                  -8.312363
Policy mu Mean               0.049816944
Policy mu Std                0.63251966
Policy mu Max                3.9584837
Policy mu Min                -3.2915998
Policy log std Mean          -1.1087656
Policy log std Std           0.298623
Policy log std Max           0.01475656
Policy log std Min           -2.5043483
Z mean eval                  1.1697233
Z variance eval              0.00491542
total_rewards                [-322.41038887 1934.39362114  212.34950505 4138.66936256 3998.5073237
 1896.65978059 4188.95265947 3599.31044024 4084.55410071 3988.34559226]
total_rewards_mean           2771.9331996857463
total_rewards_std            1638.950543625673
total_rewards_max            4188.952659471289
total_rewards_min            -322.4103888682728
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               36.9535417011939
(Previous) Eval Time (s)     21.601546900346875
Sample Time (s)              26.98751685442403
Epoch Time (s)               85.5426054559648
Total Train Time (s)         43492.04069793923
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:51:14.143942 UTC | [2020_01_10_11_46_20] Iteration #491 | Epoch Duration: 91.84140133857727
2020-01-10 23:51:14.144159 UTC | [2020_01_10_11_46_20] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700858
Z variance train             0.0049377386
KL Divergence                29.107822
KL Loss                      2.9107823
QF Loss                      1187.7666
VF Loss                      1563.0729
Policy Loss                  -1444.6567
Q Predictions Mean           1444.0171
Q Predictions Std            221.33789
Q Predictions Max            1645.1669
Q Predictions Min            -57.182167
V Predictions Mean           1447.5869
V Predictions Std            205.6541
V Predictions Max            1636.2977
V Predictions Min            -51.73439
Log Pis Mean                 1.0300925
Log Pis Std                  3.0419526
Log Pis Max                  16.03489
Log Pis Min                  -12.763541
Policy mu Mean               0.06369636
Policy mu Std                0.65215343
Policy mu Max                2.6691425
Policy mu Min                -2.4106703
Policy log std Mean          -1.1071125
Policy log std Std           0.31174174
Policy log std Max           -0.18893135
Policy log std Min           -3.390699
Z mean eval                  1.162757
Z variance eval              0.0051875496
total_rewards                [  51.11044846 3826.13742004 3945.14566573 3564.40745643 3596.8941647
 3849.59035247 1851.2633025  3758.45803032  979.72416454 2817.22901002]
total_rewards_mean           2823.9960015222396
total_rewards_std            1317.892079663307
total_rewards_max            3945.1456657348967
total_rewards_min            51.11044846432701
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               36.99317747494206
(Previous) Eval Time (s)     27.899948555976152
Sample Time (s)              26.94621008867398
Epoch Time (s)               91.83933611959219
Total Train Time (s)         43584.149509422015
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:52:46.259281 UTC | [2020_01_10_11_46_20] Iteration #492 | Epoch Duration: 92.11488080024719
2020-01-10 23:52:46.259573 UTC | [2020_01_10_11_46_20] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.164448
Z variance train             0.0051751332
KL Divergence                29.0132
KL Loss                      2.9013202
QF Loss                      1948.7156
VF Loss                      702.44684
Policy Loss                  -1437.3203
Q Predictions Mean           1437.4314
Q Predictions Std            284.50705
Q Predictions Max            1669.5453
Q Predictions Min            -166.60056
V Predictions Mean           1439.0703
V Predictions Std            284.4364
V Predictions Max            1654.414
V Predictions Min            -126.28964
Log Pis Mean                 0.8303411
Log Pis Std                  2.8760338
Log Pis Max                  11.991389
Log Pis Min                  -5.1920347
Policy mu Mean               0.012185033
Policy mu Std                0.6607435
Policy mu Max                2.5910661
Policy mu Min                -2.535674
Policy log std Mean          -1.0801852
Policy log std Std           0.32509196
Policy log std Max           0.07191157
Policy log std Min           -2.728423
Z mean eval                  1.1691064
Z variance eval              0.005607224
total_rewards                [3208.28605864 4201.65638476  213.28269045 4088.1341097  3568.4853097
 1954.01877993 4133.15308208 3946.84420254   47.9768617  1469.57334815]
total_rewards_mean           2683.1410827633163
total_rewards_std            1552.019428878607
total_rewards_max            4201.656384761589
total_rewards_min            47.97686169501803
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               36.09981413092464
(Previous) Eval Time (s)     28.175091880839318
Sample Time (s)              27.488454166799784
Epoch Time (s)               91.76336017856374
Total Train Time (s)         43672.354648312554
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:54:14.468687 UTC | [2020_01_10_11_46_20] Iteration #493 | Epoch Duration: 88.20887613296509
2020-01-10 23:54:14.468899 UTC | [2020_01_10_11_46_20] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1696188
Z variance train             0.0055885846
KL Divergence                29.029047
KL Loss                      2.9029047
QF Loss                      1200.011
VF Loss                      108.61362
Policy Loss                  -1449.8239
Q Predictions Mean           1446.8977
Q Predictions Std            237.76324
Q Predictions Max            1645.3516
Q Predictions Min            -122.99669
V Predictions Mean           1450.3231
V Predictions Std            232.89186
V Predictions Max            1639.2748
V Predictions Min            -114.16681
Log Pis Mean                 1.0929794
Log Pis Std                  3.030668
Log Pis Max                  13.771454
Log Pis Min                  -8.199905
Policy mu Mean               0.0697511
Policy mu Std                0.69549406
Policy mu Max                2.5494199
Policy mu Min                -2.1708906
Policy log std Mean          -1.0657291
Policy log std Std           0.302231
Policy log std Max           -0.109921694
Policy log std Min           -2.8366604
Z mean eval                  1.1673195
Z variance eval              0.0067721503
total_rewards                [2845.23336044 3640.22642872 3529.89521003 3986.21356857 3543.2280674
 1058.17749998  193.70104441  395.85495414 4060.87779425 4162.1003315 ]
total_rewards_mean           2741.5508259435023
total_rewards_std            1490.5664846335333
total_rewards_max            4162.100331500538
total_rewards_min            193.7010444082397
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               36.51085079088807
(Previous) Eval Time (s)     24.620210715103894
Sample Time (s)              26.489422727376223
Epoch Time (s)               87.62048423336819
Total Train Time (s)         43761.2851211722
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:55:43.403956 UTC | [2020_01_10_11_46_20] Iteration #494 | Epoch Duration: 88.93492102622986
2020-01-10 23:55:43.404135 UTC | [2020_01_10_11_46_20] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1667107
Z variance train             0.0067794668
KL Divergence                28.399368
KL Loss                      2.839937
QF Loss                      645.5412
VF Loss                      213.80867
Policy Loss                  -1432.2987
Q Predictions Mean           1433.9503
Q Predictions Std            249.70781
Q Predictions Max            1623.2947
Q Predictions Min            -85.61504
V Predictions Mean           1443.7498
V Predictions Std            249.74202
V Predictions Max            1631.4227
V Predictions Min            -80.04531
Log Pis Mean                 1.1026376
Log Pis Std                  2.7223425
Log Pis Max                  8.251236
Log Pis Min                  -7.433799
Policy mu Mean               0.078685015
Policy mu Std                0.6878857
Policy mu Max                2.627516
Policy mu Min                -2.457116
Policy log std Mean          -1.0484364
Policy log std Std           0.26948923
Policy log std Max           0.41106248
Policy log std Min           -2.6248598
Z mean eval                  1.1578294
Z variance eval              0.0053065345
total_rewards                [3815.79662434  401.52880398 3912.34068174 4078.58631079 4066.16191153
   47.86670388   14.42592221 2766.74062518   43.28608945 4046.58209612]
total_rewards_mean           2319.3315769234414
total_rewards_std            1828.593491698059
total_rewards_max            4078.586310794334
total_rewards_min            14.425922213928672
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               37.81901784520596
(Previous) Eval Time (s)     25.934301356319338
Sample Time (s)              27.235428082756698
Epoch Time (s)               90.988747284282
Total Train Time (s)         43847.11107521085
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:57:09.235491 UTC | [2020_01_10_11_46_20] Iteration #495 | Epoch Duration: 85.83120012283325
2020-01-10 23:57:09.235792 UTC | [2020_01_10_11_46_20] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1563355
Z variance train             0.0053052427
KL Divergence                28.87181
KL Loss                      2.887181
QF Loss                      816.8124
VF Loss                      274.82825
Policy Loss                  -1431.447
Q Predictions Mean           1429.0076
Q Predictions Std            268.80563
Q Predictions Max            1653.8495
Q Predictions Min            -105.442245
V Predictions Mean           1421.8307
V Predictions Std            266.37747
V Predictions Max            1638.4777
V Predictions Min            -103.552704
Log Pis Mean                 0.7014241
Log Pis Std                  3.189477
Log Pis Max                  10.678812
Log Pis Min                  -7.8590016
Policy mu Mean               0.03753474
Policy mu Std                0.6480411
Policy mu Max                3.3338053
Policy mu Min                -2.3529491
Policy log std Mean          -1.0998034
Policy log std Std           0.30887645
Policy log std Max           0.1323306
Policy log std Min           -2.2501807
Z mean eval                  1.1669115
Z variance eval              0.020144034
total_rewards                [3582.21331866 4138.41625451 4055.25831448 1375.59870686  377.54916945
 2486.32923287 3974.24715128 3819.89008664  612.51878708 1747.45644403]
total_rewards_mean           2616.947746586785
total_rewards_std            1412.4920701792803
total_rewards_max            4138.416254511242
total_rewards_min            377.54916944833286
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               36.091577962972224
(Previous) Eval Time (s)     20.77632154058665
Sample Time (s)              26.17816783580929
Epoch Time (s)               83.04606733936816
Total Train Time (s)         43932.70902352827
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:58:34.838558 UTC | [2020_01_10_11_46_20] Iteration #496 | Epoch Duration: 85.60259652137756
2020-01-10 23:58:34.838768 UTC | [2020_01_10_11_46_20] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1679579
Z variance train             0.020126838
KL Divergence                27.412676
KL Loss                      2.7412677
QF Loss                      2541.9966
VF Loss                      475.43304
Policy Loss                  -1435.3094
Q Predictions Mean           1434.6721
Q Predictions Std            247.52219
Q Predictions Max            1673.9316
Q Predictions Min            -62.66294
V Predictions Mean           1430.6511
V Predictions Std            246.3776
V Predictions Max            1651.7839
V Predictions Min            -64.41494
Log Pis Mean                 1.225036
Log Pis Std                  3.3596985
Log Pis Max                  14.824869
Log Pis Min                  -6.658285
Policy mu Mean               0.011430912
Policy mu Std                0.7004344
Policy mu Max                2.9170778
Policy mu Min                -2.7992616
Policy log std Mean          -1.0911473
Policy log std Std           0.32479963
Policy log std Max           0.110292315
Policy log std Min           -2.741306
Z mean eval                  1.1523888
Z variance eval              0.011962188
total_rewards                [ 700.81903033 4007.73411964 1944.33206278 3947.47307375 1121.67087422
 1806.64167793 2731.05985528 3783.30154054  112.75078884 3540.10145234]
total_rewards_mean           2369.58844756544
total_rewards_std            1364.0288132040241
total_rewards_max            4007.7341196382968
total_rewards_min            112.75078884439493
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               37.10423734365031
(Previous) Eval Time (s)     23.33251617802307
Sample Time (s)              26.725799183361232
Epoch Time (s)               87.16255270503461
Total Train Time (s)         44018.51143162325
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:00:00.646126 UTC | [2020_01_10_11_46_20] Iteration #497 | Epoch Duration: 85.8072018623352
2020-01-11 00:00:00.646330 UTC | [2020_01_10_11_46_20] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1515312
Z variance train             0.011931276
KL Divergence                27.637108
KL Loss                      2.7637107
QF Loss                      1399.3452
VF Loss                      919.05304
Policy Loss                  -1403.7592
Q Predictions Mean           1408.505
Q Predictions Std            346.53397
Q Predictions Max            1678.5968
Q Predictions Min            -109.605125
V Predictions Mean           1416.0468
V Predictions Std            356.96298
V Predictions Max            1676.3302
V Predictions Min            -112.68642
Log Pis Mean                 0.89878047
Log Pis Std                  3.313557
Log Pis Max                  15.336579
Log Pis Min                  -7.749344
Policy mu Mean               0.024565445
Policy mu Std                0.6476198
Policy mu Max                2.8644497
Policy mu Min                -2.2895262
Policy log std Mean          -1.1157509
Policy log std Std           0.32103115
Policy log std Max           -0.15002817
Policy log std Min           -3.157317
Z mean eval                  1.1368945
Z variance eval              0.0074221618
total_rewards                [ 159.1259926  4184.60625501 3931.06473516 4022.08829941 4076.45408838
 2686.37996597 3971.80543358 1043.96634853 4019.51049466 4129.55165752]
total_rewards_mean           3222.4553270811966
total_rewards_std            1386.8457875705321
total_rewards_max            4184.606255013084
total_rewards_min            159.12599259733318
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               34.02857248997316
(Previous) Eval Time (s)     21.976741109974682
Sample Time (s)              25.071819680277258
Epoch Time (s)               81.0771332802251
Total Train Time (s)         44104.25978623796
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:01:26.399404 UTC | [2020_01_10_11_46_20] Iteration #498 | Epoch Duration: 85.7529399394989
2020-01-11 00:01:26.399583 UTC | [2020_01_10_11_46_20] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1368732
Z variance train             0.0074294023
KL Divergence                28.376595
KL Loss                      2.8376596
QF Loss                      16805.02
VF Loss                      505.60175
Policy Loss                  -1401.6882
Q Predictions Mean           1407.5568
Q Predictions Std            313.0585
Q Predictions Max            1630.5078
Q Predictions Min            -72.41621
V Predictions Mean           1406.581
V Predictions Std            311.8815
V Predictions Max            1631.5197
V Predictions Min            -69.83469
Log Pis Mean                 1.141391
Log Pis Std                  2.975078
Log Pis Max                  10.126805
Log Pis Min                  -7.3074307
Policy mu Mean               0.016947122
Policy mu Std                0.66739726
Policy mu Max                2.6928215
Policy mu Min                -2.355742
Policy log std Mean          -1.0671694
Policy log std Std           0.327022
Policy log std Max           -0.09582275
Policy log std Min           -2.7348614
Z mean eval                  1.1603923
Z variance eval              0.0058647953
total_rewards                [ 749.51440327 2649.71132002  359.00302882 3979.46300177 1381.18761938
  242.95974076  751.53578828 3805.73549918 1858.29404315  109.42799535]
total_rewards_mean           1588.6832439989892
total_rewards_std            1370.7288215773365
total_rewards_max            3979.463001770592
total_rewards_min            109.42799535072217
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               33.92146273795515
(Previous) Eval Time (s)     26.652208493091166
Sample Time (s)              25.058201727923006
Epoch Time (s)               85.63187295896932
Total Train Time (s)         44180.35343930172
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:02:42.500142 UTC | [2020_01_10_11_46_20] Iteration #499 | Epoch Duration: 76.10041832923889
2020-01-11 00:02:42.500412 UTC | [2020_01_10_11_46_20] Iteration #499 | Started Training: True
2020-01-11 00:02:43.428174 UTC | [2020_01_10_11_46_20] Variant:
2020-01-11 00:02:43.428830 UTC | [2020_01_10_11_46_20] {
  "env_name": "Hopper-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_seed567",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00067216775
Z variance train             0.69231623
KL Divergence                0.15007588
KL Loss                      0.015007588
QF Loss                      72.00627
VF Loss                      4.348541
Policy Loss                  -2.0539703
Q Predictions Mean           0.0046742754
Q Predictions Std            0.00078647234
Q Predictions Max            0.0068198126
Q Predictions Min            0.0025699805
V Predictions Mean           0.00083554036
V Predictions Std            0.0008371301
V Predictions Max            0.0042383783
V Predictions Min            -0.0017800751
Log Pis Mean                 -2.0363827
Log Pis Std                  0.3649491
Log Pis Max                  -0.8460885
Log Pis Min                  -3.0406342
Policy mu Mean               0.0006062304
Policy mu Std                0.00081670156
Policy mu Max                0.002711602
Policy mu Min                -0.0007597279
Policy log std Mean          -0.00023992085
Policy log std Std           0.0010433691
Policy log std Max           0.0016407097
Policy log std Min           -0.0020184107
Z mean eval                  0.026589826
Z variance eval              0.58883274
total_rewards                [ 10.72945366  68.61138194  25.47627802  78.48916957 111.0681504
  68.71519553  71.02865102  53.91281892  76.12110143  86.24953234]
total_rewards_mean           65.0401732832683
total_rewards_std            27.519028569256268
total_rewards_max            111.06815040000205
total_rewards_min            10.729453660002095
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               30.266317098401487
(Previous) Eval Time (s)     0
Sample Time (s)              18.66422809381038
Epoch Time (s)               48.930545192211866
Total Train Time (s)         50.147329138591886
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:03:33.660380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #0 | Epoch Duration: 50.15370488166809
2020-01-11 00:03:33.660588 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026486132
Z variance train             0.5903282
KL Divergence                0.29706055
KL Loss                      0.029706055
QF Loss                      34.711502
VF Loss                      2.4369445
Policy Loss                  -11.049603
Q Predictions Mean           9.537714
Q Predictions Std            7.677554
Q Predictions Max            27.861734
Q Predictions Min            -4.0885653
V Predictions Mean           12.102646
V Predictions Std            7.694116
V Predictions Max            29.96802
V Predictions Min            -2.249002
Log Pis Mean                 -1.9468197
Log Pis Std                  0.43420827
Log Pis Max                  -0.6750458
Log Pis Min                  -4.080131
Policy mu Mean               0.118608646
Policy mu Std                0.18478025
Policy mu Max                0.51896757
Policy mu Min                -0.20461713
Policy log std Mean          -0.1465586
Policy log std Std           0.018457707
Policy log std Max           -0.10941944
Policy log std Min           -0.19813466
Z mean eval                  0.024042394
Z variance eval              0.25257763
total_rewards                [ 50.7037914   62.81042554  43.96765189 145.87490541  52.51174958
  52.85819597  44.93183341  51.03613993  67.12139962  49.80038516]
total_rewards_mean           62.16164779134645
total_rewards_std            28.719945170134505
total_rewards_max            145.87490541039116
total_rewards_min            43.96765188847565
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               30.551251977682114
(Previous) Eval Time (s)     1.2226963778957725
Sample Time (s)              14.15927161090076
Epoch Time (s)               45.933219966478646
Total Train Time (s)         95.68928926018998
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:04:19.200332 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #1 | Epoch Duration: 45.539597272872925
2020-01-11 00:04:19.200482 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020069977
Z variance train             0.25330886
KL Divergence                1.5675302
KL Loss                      0.15675302
QF Loss                      23.363625
VF Loss                      4.00715
Policy Loss                  -15.868343
Q Predictions Mean           14.25014
Q Predictions Std            16.985588
Q Predictions Max            87.621544
Q Predictions Min            -2.1960828
V Predictions Mean           16.331642
V Predictions Std            17.15512
V Predictions Max            90.395966
V Predictions Min            -1.2345359
Log Pis Mean                 -1.8471296
Log Pis Std                  0.7442659
Log Pis Max                  2.1220274
Log Pis Min                  -3.5090992
Policy mu Mean               0.119315974
Policy mu Std                0.29050696
Policy mu Max                1.1860263
Policy mu Min                -0.20023996
Policy log std Mean          -0.16520812
Policy log std Std           0.08339335
Policy log std Max           -0.0895555
Policy log std Min           -0.47853282
Z mean eval                  0.067188725
Z variance eval              0.114167534
total_rewards                [157.1765336  140.54934948  55.03791369 116.81095278 127.07140418
 160.73595885  80.92397529 120.53764774 218.41199314 127.72134702]
total_rewards_mean           130.49770757649475
total_rewards_std            42.324675918123624
total_rewards_max            218.41199313507593
total_rewards_min            55.037913693286356
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               30.81093100924045
(Previous) Eval Time (s)     0.8287718379870057
Sample Time (s)              12.930747710168362
Epoch Time (s)               44.570450557395816
Total Train Time (s)         141.64522658567876
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:05.157376 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #2 | Epoch Duration: 45.95677852630615
2020-01-11 00:05:05.157564 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067518875
Z variance train             0.116938636
KL Divergence                3.1876185
KL Loss                      0.31876186
QF Loss                      57.723198
VF Loss                      4.614026
Policy Loss                  -23.647322
Q Predictions Mean           22.086952
Q Predictions Std            28.976866
Q Predictions Max            124.38506
Q Predictions Min            -3.9004679
V Predictions Mean           23.687431
V Predictions Std            28.803547
V Predictions Max            119.30259
V Predictions Min            -2.4792495
Log Pis Mean                 -1.6242768
Log Pis Std                  1.145045
Log Pis Max                  3.7015705
Log Pis Min                  -4.026188
Policy mu Mean               0.15994398
Policy mu Std                0.39753592
Policy mu Max                1.9366829
Policy mu Min                -1.0006168
Policy log std Mean          -0.20459491
Policy log std Std           0.11222951
Policy log std Max           -0.09863344
Policy log std Min           -0.6472589
Z mean eval                  0.05569253
Z variance eval              0.0396292
total_rewards                [181.73167884 325.76735876 332.79807604 312.17847332 265.86070045
 320.97785562 333.30114132 337.98443743 343.26532291 314.59269965]
total_rewards_mean           306.84577443346905
total_rewards_std            46.52839567899935
total_rewards_max            343.2653229060602
total_rewards_min            181.7316788399396
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               30.97315056808293
(Previous) Eval Time (s)     2.2147550024092197
Sample Time (s)              14.7225031577982
Epoch Time (s)               47.91040872829035
Total Train Time (s)         191.48868996463716
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:55.000414 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #3 | Epoch Duration: 49.84272599220276
2020-01-11 00:05:55.000527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052979954
Z variance train             0.04750199
KL Divergence                5.2634926
KL Loss                      0.52634925
QF Loss                      30.629953
VF Loss                      10.056182
Policy Loss                  -37.728107
Q Predictions Mean           35.263237
Q Predictions Std            45.10834
Q Predictions Max            158.05803
Q Predictions Min            -6.647296
V Predictions Mean           37.235188
V Predictions Std            45.25705
V Predictions Max            162.9658
V Predictions Min            -4.6033573
Log Pis Mean                 -1.6713634
Log Pis Std                  1.0045797
Log Pis Max                  3.518489
Log Pis Min                  -4.572224
Policy mu Mean               0.07883921
Policy mu Std                0.41208878
Policy mu Max                1.7045779
Policy mu Min                -1.3869996
Policy log std Mean          -0.23548935
Policy log std Std           0.15103857
Policy log std Max           -0.10515492
Policy log std Min           -0.7930541
Z mean eval                  0.039729945
Z variance eval              0.02122881
total_rewards                [338.01553251 345.99971842 363.97199003 326.61074589 329.82174669
 352.46384769 348.38026709 364.8159058  346.53015006 348.87465184]
total_rewards_mean           346.54845560236
total_rewards_std            11.964301726644019
total_rewards_max            364.81590580369647
total_rewards_min            326.61074589305395
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.91683672880754
(Previous) Eval Time (s)     4.146769751794636
Sample Time (s)              17.83284359658137
Epoch Time (s)               52.896450077183545
Total Train Time (s)         244.40614677919075
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:06:47.922804 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #4 | Epoch Duration: 52.9221773147583
2020-01-11 00:06:47.922973 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040154435
Z variance train             0.020558018
KL Divergence                7.2814655
KL Loss                      0.72814655
QF Loss                      71.89789
VF Loss                      15.360215
Policy Loss                  -59.465797
Q Predictions Mean           54.87498
Q Predictions Std            64.03212
Q Predictions Max            195.68477
Q Predictions Min            -3.9964855
V Predictions Mean           59.548306
V Predictions Std            65.7031
V Predictions Max            201.1116
V Predictions Min            -1.8115464
Log Pis Mean                 -1.2948047
Log Pis Std                  1.6206936
Log Pis Max                  5.790661
Log Pis Min                  -5.0501575
Policy mu Mean               0.042854417
Policy mu Std                0.5730834
Policy mu Max                1.8084648
Policy mu Min                -1.7233307
Policy log std Mean          -0.31780607
Policy log std Std           0.2326935
Policy log std Max           -0.09871339
Policy log std Min           -0.959804
Z mean eval                  0.033475537
Z variance eval              0.007966122
total_rewards                [326.95803816 302.95757156 309.42459662 339.50769619 354.11402378
 346.3899378  338.31319332 228.27500099 332.15318015 319.38044389]
total_rewards_mean           319.7473682454518
total_rewards_std            34.04076580788102
total_rewards_max            354.114023780601
total_rewards_min            228.27500098795974
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               31.05026436271146
(Previous) Eval Time (s)     4.172175330109894
Sample Time (s)              20.12335371831432
Epoch Time (s)               55.34579341113567
Total Train Time (s)         299.7451312430203
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:07:43.260634 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #5 | Epoch Duration: 55.337509632110596
2020-01-11 00:07:43.260874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033154573
Z variance train             0.007984597
KL Divergence                9.672311
KL Loss                      0.9672311
QF Loss                      57.98923
VF Loss                      22.852116
Policy Loss                  -85.0979
Q Predictions Mean           82.79522
Q Predictions Std            90.0113
Q Predictions Max            246.27472
Q Predictions Min            -4.9879575
V Predictions Mean           87.58327
V Predictions Std            91.92745
V Predictions Max            251.69647
V Predictions Min            -1.396944
Log Pis Mean                 -1.255902
Log Pis Std                  1.4037503
Log Pis Max                  5.1215224
Log Pis Min                  -4.230089
Policy mu Mean               -0.013409392
Policy mu Std                0.55258393
Policy mu Max                1.9710511
Policy mu Min                -2.262724
Policy log std Mean          -0.33995116
Policy log std Std           0.2647097
Policy log std Max           -0.08971545
Policy log std Min           -1.063372
Z mean eval                  0.013656305
Z variance eval              0.0034099296
total_rewards                [139.68282841 213.88376781 125.13856606 380.82961259 215.06469718
 178.93932176 202.34113442 121.94905037 253.19269069 147.6645665 ]
total_rewards_mean           197.86862357821948
total_rewards_std            73.77361620873354
total_rewards_max            380.8296125941042
total_rewards_min            121.94905037228276
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               31.12620525388047
(Previous) Eval Time (s)     4.16357495682314
Sample Time (s)              19.13850288465619
Epoch Time (s)               54.4282830953598
Total Train Time (s)         352.9875934673473
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:36.504483 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #6 | Epoch Duration: 53.243449449539185
2020-01-11 00:08:36.504692 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013534734
Z variance train             0.0038681298
KL Divergence                11.413842
KL Loss                      1.1413842
QF Loss                      1104.6996
VF Loss                      52.092834
Policy Loss                  -122.09263
Q Predictions Mean           121.43369
Q Predictions Std            111.34866
Q Predictions Max            294.0912
Q Predictions Min            -5.482259
V Predictions Mean           123.18318
V Predictions Std            110.830734
V Predictions Max            305.21786
V Predictions Min            -3.3779616
Log Pis Mean                 -1.0154151
Log Pis Std                  1.5755054
Log Pis Max                  5.391894
Log Pis Min                  -4.6098323
Policy mu Mean               0.098006405
Policy mu Std                0.59597176
Policy mu Max                2.2863178
Policy mu Min                -2.0584974
Policy log std Mean          -0.37136593
Policy log std Std           0.25527292
Policy log std Max           -0.09182305
Policy log std Min           -1.1069276
Z mean eval                  0.020454485
Z variance eval              0.0047339336
total_rewards                [344.20516794 380.87847963 337.12361165 345.46694721 374.4848553
 358.04673378 359.10480144 373.01338427 351.71799566 367.03334781]
total_rewards_mean           359.1075324688133
total_rewards_std            13.834004577359156
total_rewards_max            380.8784796343999
total_rewards_min            337.1236116452436
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               30.957914346829057
(Previous) Eval Time (s)     2.9783410849049687
Sample Time (s)              18.39092287234962
Epoch Time (s)               52.327178304083645
Total Train Time (s)         406.9947889158502
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:09:30.513431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #7 | Epoch Duration: 54.008514404296875
2020-01-11 00:09:30.513720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021985117
Z variance train             0.00496152
KL Divergence                10.943558
KL Loss                      1.0943558
QF Loss                      193.29425
VF Loss                      31.89183
Policy Loss                  -143.3478
Q Predictions Mean           134.57956
Q Predictions Std            132.83595
Q Predictions Max            418.5353
Q Predictions Min            -6.3230085
V Predictions Mean           144.8086
V Predictions Std            136.53387
V Predictions Max            429.95297
V Predictions Min            -3.0050507
Log Pis Mean                 -0.6575785
Log Pis Std                  1.9374475
Log Pis Max                  5.7303543
Log Pis Min                  -3.5885582
Policy mu Mean               0.041861888
Policy mu Std                0.7744956
Policy mu Max                2.6696968
Policy mu Min                -2.9084284
Policy log std Mean          -0.38086614
Policy log std Std           0.26366436
Policy log std Max           -0.08355616
Policy log std Min           -1.3645941
Z mean eval                  0.018341873
Z variance eval              0.0027775117
total_rewards                [377.77724731 358.97863555 371.47248713 322.25011534 342.03450296
 332.31847284 354.02584965 380.10411668 333.01174874 413.86803544]
total_rewards_mean           358.5841211647861
total_rewards_std            26.481543174570014
total_rewards_max            413.868035441015
total_rewards_min            322.25011533865904
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               30.491495749913156
(Previous) Eval Time (s)     4.659355406183749
Sample Time (s)              18.995000021532178
Epoch Time (s)               54.14585117762908
Total Train Time (s)         461.4029626818374
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:10:24.921783 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #8 | Epoch Duration: 54.407862186431885
2020-01-11 00:10:24.921963 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01693942
Z variance train             0.0029205817
KL Divergence                12.177782
KL Loss                      1.2177782
QF Loss                      116.348404
VF Loss                      39.78348
Policy Loss                  -152.65735
Q Predictions Mean           151.03244
Q Predictions Std            159.28876
Q Predictions Max            431.54877
Q Predictions Min            -6.5703034
V Predictions Mean           153.2069
V Predictions Std            158.33836
V Predictions Max            435.04224
V Predictions Min            -4.950321
Log Pis Mean                 -0.96140635
Log Pis Std                  1.577533
Log Pis Max                  6.8227468
Log Pis Min                  -3.0115077
Policy mu Mean               0.035351045
Policy mu Std                0.6464163
Policy mu Max                2.3996582
Policy mu Min                -2.2788572
Policy log std Mean          -0.38710818
Policy log std Std           0.29957744
Policy log std Max           -0.05154278
Policy log std Min           -1.3839762
Z mean eval                  0.021627951
Z variance eval              0.0039802454
total_rewards                [404.32071664 378.75462928 372.70872742 356.84093448 382.65578642
 393.97171139 405.00449185 369.80228273 374.78216231 353.563065  ]
total_rewards_mean           379.2404507526183
total_rewards_std            16.835680445660536
total_rewards_max            405.0044918503393
total_rewards_min            353.5630649982128
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               31.25347454380244
(Previous) Eval Time (s)     4.921055952087045
Sample Time (s)              20.65163559280336
Epoch Time (s)               56.826166088692844
Total Train Time (s)         517.4146692045033
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:20.935502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #9 | Epoch Duration: 56.0134003162384
2020-01-11 00:11:20.935700 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023848275
Z variance train             0.003224215
KL Divergence                11.9057045
KL Loss                      1.1905705
QF Loss                      200.73874
VF Loss                      24.301039
Policy Loss                  -213.94704
Q Predictions Mean           210.72092
Q Predictions Std            179.49612
Q Predictions Max            540.6157
Q Predictions Min            -5.509858
V Predictions Mean           214.39047
V Predictions Std            178.84833
V Predictions Max            534.1483
V Predictions Min            -3.0511007
Log Pis Mean                 -0.625914
Log Pis Std                  1.8416772
Log Pis Max                  5.750698
Log Pis Min                  -7.0729184
Policy mu Mean               0.014301524
Policy mu Std                0.7495782
Policy mu Max                1.9598318
Policy mu Min                -2.6007967
Policy log std Mean          -0.4461236
Policy log std Std           0.31856567
Policy log std Max           -0.040748
Policy log std Min           -1.4069445
Z mean eval                  0.027410949
Z variance eval              0.0015943951
total_rewards                [360.80448484 372.87660524 358.18630051 371.11752373 372.84796566
 360.94159398 346.92487913 363.78807955 366.10463379 371.9387199 ]
total_rewards_mean           364.55307863324555
total_rewards_std            7.855587102892538
total_rewards_max            372.8766052368387
total_rewards_min            346.92487913339187
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               30.695216118358076
(Previous) Eval Time (s)     4.107905561104417
Sample Time (s)              18.682986243627965
Epoch Time (s)               53.48610792309046
Total Train Time (s)         569.8724958491512
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:12:13.394578 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #10 | Epoch Duration: 52.45866513252258
2020-01-11 00:12:13.394839 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #10 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026634583
Z variance train             0.0014713766
KL Divergence                13.8498535
KL Loss                      1.3849853
QF Loss                      486.24908
VF Loss                      93.144264
Policy Loss                  -213.89627
Q Predictions Mean           211.7992
Q Predictions Std            192.93625
Q Predictions Max            562.59845
Q Predictions Min            -5.109295
V Predictions Mean           220.07202
V Predictions Std            196.04474
V Predictions Max            542.54553
V Predictions Min            -1.6983359
Log Pis Mean                 -0.33868498
Log Pis Std                  1.9856404
Log Pis Max                  9.49097
Log Pis Min                  -3.5368352
Policy mu Mean               0.19926171
Policy mu Std                0.7811649
Policy mu Max                2.782279
Policy mu Min                -2.6969247
Policy log std Mean          -0.46474442
Policy log std Std           0.31855854
Policy log std Max           -0.10308256
Policy log std Min           -1.4426233
Z mean eval                  0.009853052
Z variance eval              0.0024030185
total_rewards                [347.90114548 321.07522934 324.59316686 333.77624525 319.9000828
 346.11374596 328.55125689 382.26344863 351.83004561 369.66564323]
total_rewards_mean           342.56700100503105
total_rewards_std            20.023594760905723
total_rewards_max            382.2634486315861
total_rewards_min            319.9000827981535
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               30.889728923793882
(Previous) Eval Time (s)     3.0801622890867293
Sample Time (s)              18.702479977160692
Epoch Time (s)               52.672371190041304
Total Train Time (s)         623.436172563117
Epoch                        11
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:06.959266 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #11 | Epoch Duration: 53.56427836418152
2020-01-11 00:13:06.959445 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011617202
Z variance train             0.0017070044
KL Divergence                13.702921
KL Loss                      1.3702921
QF Loss                      331.64233
VF Loss                      86.62389
Policy Loss                  -240.39279
Q Predictions Mean           230.20569
Q Predictions Std            224.72351
Q Predictions Max            632.6059
Q Predictions Min            -8.41765
V Predictions Mean           235.70386
V Predictions Std            222.91397
V Predictions Max            616.6725
V Predictions Min            -3.247944
Log Pis Mean                 -0.40799206
Log Pis Std                  2.2126088
Log Pis Max                  9.70751
Log Pis Min                  -4.987379
Policy mu Mean               0.014830362
Policy mu Std                0.7760613
Policy mu Max                2.4482808
Policy mu Min                -3.6118011
Policy log std Mean          -0.43816814
Policy log std Std           0.33740208
Policy log std Max           -0.073311076
Policy log std Min           -1.4838591
Z mean eval                  0.012093007
Z variance eval              0.00241483
total_rewards                [329.31339862 307.6705747  258.17676928 388.66256502 303.91139806
 858.18741403 313.42714045 340.08871053 164.59515893 321.81057413]
total_rewards_mean           358.5843703741329
total_rewards_std            175.6112509928135
total_rewards_max            858.1874140260925
total_rewards_min            164.59515892627547
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.82227645115927
(Previous) Eval Time (s)     3.9716894887387753
Sample Time (s)              18.040620107203722
Epoch Time (s)               52.834586047101766
Total Train Time (s)         679.1444779089652
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:02.668968 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #12 | Epoch Duration: 55.709367752075195
2020-01-11 00:14:02.669217 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01216197
Z variance train             0.0022220968
KL Divergence                12.97816
KL Loss                      1.297816
QF Loss                      237.79529
VF Loss                      67.9396
Policy Loss                  -274.54974
Q Predictions Mean           268.87433
Q Predictions Std            234.93434
Q Predictions Max            686.9146
Q Predictions Min            -6.858407
V Predictions Mean           269.71362
V Predictions Std            233.67123
V Predictions Max            671.1424
V Predictions Min            -4.802189
Log Pis Mean                 -0.13226542
Log Pis Std                  2.3266609
Log Pis Max                  8.310453
Log Pis Min                  -4.6699295
Policy mu Mean               0.25396398
Policy mu Std                0.85059184
Policy mu Max                2.669519
Policy mu Min                -2.936451
Policy log std Mean          -0.46895972
Policy log std Std           0.31780523
Policy log std Max           -0.09384453
Policy log std Min           -1.5005872
Z mean eval                  0.009370426
Z variance eval              0.004009909
total_rewards                [320.09688443 310.54622509 323.99171879 333.11759977 325.88755476
 311.96005009 313.12404346 324.99188998 331.31369554 325.71140049]
total_rewards_mean           322.0741062383587
total_rewards_std            7.526559401492273
total_rewards_max            333.1175997685075
total_rewards_min            310.5462250855529
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               31.032932445872575
(Previous) Eval Time (s)     6.846145196817815
Sample Time (s)              20.473794294521213
Epoch Time (s)               58.3528719372116
Total Train Time (s)         733.8671323363669
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:57.392756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #13 | Epoch Duration: 54.72339606285095
2020-01-11 00:14:57.392894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00987216
Z variance train             0.004145436
KL Divergence                11.850637
KL Loss                      1.1850637
QF Loss                      273.58286
VF Loss                      31.767653
Policy Loss                  -262.30438
Q Predictions Mean           260.6338
Q Predictions Std            259.68176
Q Predictions Max            746.6887
Q Predictions Min            -8.814343
V Predictions Mean           261.87476
V Predictions Std            259.30945
V Predictions Max            734.0703
V Predictions Min            -5.2544
Log Pis Mean                 -0.5694754
Log Pis Std                  1.9385861
Log Pis Max                  8.500201
Log Pis Min                  -4.473015
Policy mu Mean               0.16300912
Policy mu Std                0.7197198
Policy mu Max                2.021441
Policy mu Min                -2.5900042
Policy log std Mean          -0.4503893
Policy log std Std           0.3501393
Policy log std Max           -0.014051929
Policy log std Min           -1.5211142
Z mean eval                  0.008957582
Z variance eval              0.0026167887
total_rewards                [296.91738307 314.30222688 289.49394308 292.90863362 296.22182023
 317.00214317 314.79808835 305.45517955 297.52770185 321.11458037]
total_rewards_mean           304.57417001725497
total_rewards_std            10.814426922108469
total_rewards_max            321.1145803715063
total_rewards_min            289.4939430785715
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               30.919219001196325
(Previous) Eval Time (s)     3.2163559240289032
Sample Time (s)              17.73497967561707
Epoch Time (s)               51.8705546008423
Total Train Time (s)         785.1884572324343
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:15:48.714253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #14 | Epoch Duration: 51.321258783340454
2020-01-11 00:15:48.714413 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011045639
Z variance train             0.002568997
KL Divergence                13.183407
KL Loss                      1.3183407
QF Loss                      710.43945
VF Loss                      88.49152
Policy Loss                  -302.43417
Q Predictions Mean           300.3154
Q Predictions Std            270.27765
Q Predictions Max            788.7538
Q Predictions Min            -5.03804
V Predictions Mean           307.61316
V Predictions Std            271.19217
V Predictions Max            791.2388
V Predictions Min            0.5292738
Log Pis Mean                 -0.11441173
Log Pis Std                  2.182102
Log Pis Max                  7.792965
Log Pis Min                  -3.5240893
Policy mu Mean               0.21568088
Policy mu Std                0.83071893
Policy mu Max                2.2832828
Policy mu Min                -3.0028055
Policy log std Mean          -0.4752915
Policy log std Std           0.3297881
Policy log std Max           -0.07329056
Policy log std Min           -1.6337264
Z mean eval                  0.020112883
Z variance eval              0.0032170124
total_rewards                [298.87539425 296.10532066 307.39683515 297.72013823 322.86649825
 305.62741715 297.28366395 296.19472967 288.38802339 305.03156234]
total_rewards_mean           301.54895830380593
total_rewards_std            8.882056277781558
total_rewards_max            322.86649825278516
total_rewards_min            288.38802338803987
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.105909927282482
(Previous) Eval Time (s)     2.6667452650144696
Sample Time (s)              17.706172281876206
Epoch Time (s)               51.47882747417316
Total Train Time (s)         837.6405712449923
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:41.168102 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #15 | Epoch Duration: 52.453561782836914
2020-01-11 00:16:41.168276 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020393986
Z variance train             0.0039881403
KL Divergence                12.226855
KL Loss                      1.2226856
QF Loss                      1019.88434
VF Loss                      76.470985
Policy Loss                  -332.90912
Q Predictions Mean           329.082
Q Predictions Std            296.29337
Q Predictions Max            826.2245
Q Predictions Min            -2.6181242
V Predictions Mean           335.94678
V Predictions Std            299.85123
V Predictions Max            822.94
V Predictions Min            -2.355661
Log Pis Mean                 -0.32781228
Log Pis Std                  2.0666573
Log Pis Max                  5.631875
Log Pis Min                  -4.20846
Policy mu Mean               0.2374204
Policy mu Std                0.78249353
Policy mu Max                2.4577897
Policy mu Min                -2.6808796
Policy log std Mean          -0.48388842
Policy log std Std           0.3615335
Policy log std Max           -0.0657296
Policy log std Min           -1.7053568
Z mean eval                  0.014547816
Z variance eval              0.0021805756
total_rewards                [296.86172311 295.55370847 307.19775922 286.47594017 281.50244621
 283.36911875 295.23838427 302.96918246 302.96359234 292.28624814]
total_rewards_mean           294.44181031419777
total_rewards_std            8.20920873059584
total_rewards_max            307.1977592196281
total_rewards_min            281.50244620992373
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               30.757525188848376
(Previous) Eval Time (s)     3.6411369792185724
Sample Time (s)              17.02162070851773
Epoch Time (s)               51.42028287658468
Total Train Time (s)         888.4438684671186
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:17:31.971710 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #16 | Epoch Duration: 50.80330777168274
2020-01-11 00:17:31.971861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012177665
Z variance train             0.0027766451
KL Divergence                13.109672
KL Loss                      1.3109672
QF Loss                      299.53464
VF Loss                      100.70416
Policy Loss                  -328.2709
Q Predictions Mean           327.2192
Q Predictions Std            307.13824
Q Predictions Max            844.59717
Q Predictions Min            -6.0918818
V Predictions Mean           332.48755
V Predictions Std            309.48193
V Predictions Max            859.48065
V Predictions Min            -2.4687605
Log Pis Mean                 -0.5109077
Log Pis Std                  1.9726111
Log Pis Max                  8.835842
Log Pis Min                  -6.2381363
Policy mu Mean               0.12479818
Policy mu Std                0.76115525
Policy mu Max                2.7282813
Policy mu Min                -2.9532928
Policy log std Mean          -0.48569503
Policy log std Std           0.36504662
Policy log std Max           -0.09506688
Policy log std Min           -1.7687562
Z mean eval                  0.0071532503
Z variance eval              0.0036396317
total_rewards                [289.46333751 308.11481542 355.32121829 311.50004946 310.99786085
 303.71427859 310.03478528 316.68873113 311.45315321 311.73800788]
total_rewards_mean           312.90262376417246
total_rewards_std            15.772437464790753
total_rewards_max            355.32121829468434
total_rewards_min            289.46333751036445
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.184879643376917
(Previous) Eval Time (s)     3.0238808933645487
Sample Time (s)              16.66138250147924
Epoch Time (s)               50.870143038220704
Total Train Time (s)         939.3826386556029
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:18:22.912475 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #17 | Epoch Duration: 50.94048094749451
2020-01-11 00:18:22.912675 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010559486
Z variance train             0.003698045
KL Divergence                12.478775
KL Loss                      1.2478775
QF Loss                      300.9643
VF Loss                      165.81744
Policy Loss                  -365.95535
Q Predictions Mean           358.04352
Q Predictions Std            325.9021
Q Predictions Max            937.0292
Q Predictions Min            -9.404067
V Predictions Mean           358.90765
V Predictions Std            326.0642
V Predictions Max            927.39905
V Predictions Min            -10.252751
Log Pis Mean                 -0.1470456
Log Pis Std                  2.2275198
Log Pis Max                  9.399709
Log Pis Min                  -4.1196647
Policy mu Mean               0.17056869
Policy mu Std                0.845202
Policy mu Max                2.5610836
Policy mu Min                -3.0525258
Policy log std Mean          -0.46375498
Policy log std Std           0.33094493
Policy log std Max           -0.068964496
Policy log std Min           -1.5260706
Z mean eval                  0.014631769
Z variance eval              0.0019942634
total_rewards                [284.04596725 298.42559837 440.33578543 270.77011832 272.92225598
 376.01755906 353.03710581 328.53108797 275.23618489 266.94121972]
total_rewards_mean           316.62628828128135
total_rewards_std            54.668230727328435
total_rewards_max            440.33578542988806
total_rewards_min            266.94121972235786
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.573476111050695
(Previous) Eval Time (s)     3.093845194671303
Sample Time (s)              17.56938245985657
Epoch Time (s)               51.23670376557857
Total Train Time (s)         993.0627624737099
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:16.594213 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #18 | Epoch Duration: 53.68135690689087
2020-01-11 00:19:16.594484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0129647525
Z variance train             0.0025176604
KL Divergence                13.898653
KL Loss                      1.3898653
QF Loss                      208.8899
VF Loss                      57.608032
Policy Loss                  -423.43253
Q Predictions Mean           414.90433
Q Predictions Std            330.8148
Q Predictions Max            941.99615
Q Predictions Min            -4.6779146
V Predictions Mean           424.94147
V Predictions Std            332.65216
V Predictions Max            963.4605
V Predictions Min            -4.3648553
Log Pis Mean                 0.0703865
Log Pis Std                  2.3725986
Log Pis Max                  8.446959
Log Pis Min                  -5.9490557
Policy mu Mean               0.20994897
Policy mu Std                0.8837473
Policy mu Max                2.8246577
Policy mu Min                -3.2157826
Policy log std Mean          -0.5307341
Policy log std Std           0.36750728
Policy log std Max           0.10250901
Policy log std Min           -1.7375216
Z mean eval                  0.01508114
Z variance eval              0.0026094366
total_rewards                [243.39952962 234.19541811 331.96893247 238.82075159 237.43219321
 236.26713037 246.30153782 244.95204013 322.02579252 244.52382418]
total_rewards_mean           257.9887150017973
total_rewards_std            34.78856438072496
total_rewards_max            331.96893247493534
total_rewards_min            234.1954181067187
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               30.901774981059134
(Previous) Eval Time (s)     5.538151722867042
Sample Time (s)              20.261274322867393
Epoch Time (s)               56.70120102679357
Total Train Time (s)         1047.4024943951517
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:20:10.935065 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #19 | Epoch Duration: 54.34042048454285
2020-01-11 00:20:10.935258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015555275
Z variance train             0.0021721101
KL Divergence                14.480497
KL Loss                      1.4480498
QF Loss                      894.19855
VF Loss                      134.1813
Policy Loss                  -427.25894
Q Predictions Mean           428.62836
Q Predictions Std            348.7698
Q Predictions Max            989.5991
Q Predictions Min            -9.522605
V Predictions Mean           429.63947
V Predictions Std            347.27405
V Predictions Max            1002.62195
V Predictions Min            -6.913979
Log Pis Mean                 0.012089705
Log Pis Std                  2.3262792
Log Pis Max                  7.5767083
Log Pis Min                  -6.1201057
Policy mu Mean               0.21219264
Policy mu Std                0.8794355
Policy mu Max                2.5567722
Policy mu Min                -3.0479074
Policy log std Mean          -0.49228302
Policy log std Std           0.34452847
Policy log std Max           0.13123608
Policy log std Min           -1.6048397
Z mean eval                  0.009666761
Z variance eval              0.0024845689
total_rewards                [227.93519846 356.95627711 344.58142553 371.61312361 326.15694766
 372.80015516 372.49034629 355.09167259 324.2188262  338.52905625]
total_rewards_mean           339.03730288588224
total_rewards_std            40.81570389936506
total_rewards_max            372.8001551642663
total_rewards_min            227.93519845584262
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               31.286493041086942
(Previous) Eval Time (s)     3.1770517085678875
Sample Time (s)              16.561402721796185
Epoch Time (s)               51.024947471451014
Total Train Time (s)         1099.4036838538013
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:02.937180 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #20 | Epoch Duration: 52.001784563064575
2020-01-11 00:21:02.937359 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008960179
Z variance train             0.0039261905
KL Divergence                13.105944
KL Loss                      1.3105944
QF Loss                      346.94208
VF Loss                      137.21852
Policy Loss                  -402.1077
Q Predictions Mean           398.00882
Q Predictions Std            362.66177
Q Predictions Max            1014.78436
Q Predictions Min            -2.616018
V Predictions Mean           396.22913
V Predictions Std            359.8111
V Predictions Max            1010.8875
V Predictions Min            -1.22385
Log Pis Mean                 0.30960923
Log Pis Std                  2.7117162
Log Pis Max                  12.7488365
Log Pis Min                  -3.7034965
Policy mu Mean               0.31459486
Policy mu Std                0.97446966
Policy mu Max                3.7505453
Policy mu Min                -3.3939703
Policy log std Mean          -0.46885923
Policy log std Std           0.32442164
Policy log std Max           -0.04180853
Policy log std Min           -1.6075326
Z mean eval                  0.0151794795
Z variance eval              0.0031596601
total_rewards                [330.45300851 280.8643118  330.64202765 305.12590478 336.80860899
 332.80863505 334.09407252 338.16004174 320.849776   334.85367164]
total_rewards_mean           324.46600586744455
total_rewards_std            17.240304519563438
total_rewards_max            338.1600417396629
total_rewards_min            280.8643118024641
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               30.853313592262566
(Previous) Eval Time (s)     4.153577511198819
Sample Time (s)              18.551423602737486
Epoch Time (s)               53.55831470619887
Total Train Time (s)         1152.6337358844467
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:56.168437 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #21 | Epoch Duration: 53.230939865112305
2020-01-11 00:21:56.168617 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #21 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015542218
Z variance train             0.0032668188
KL Divergence                13.710399
KL Loss                      1.3710399
QF Loss                      246.49614
VF Loss                      105.714134
Policy Loss                  -440.88672
Q Predictions Mean           436.8363
Q Predictions Std            372.6268
Q Predictions Max            1014.665
Q Predictions Min            -3.812631
V Predictions Mean           438.2798
V Predictions Std            373.71277
V Predictions Max            1014.98627
V Predictions Min            -4.843983
Log Pis Mean                 0.14721015
Log Pis Std                  2.2868228
Log Pis Max                  6.839848
Log Pis Min                  -5.4935284
Policy mu Mean               0.14677991
Policy mu Std                0.9222208
Policy mu Max                2.3691926
Policy mu Min                -2.8837905
Policy log std Mean          -0.49256492
Policy log std Std           0.3352093
Policy log std Max           -0.033198237
Policy log std Min           -1.643299
Z mean eval                  0.022784347
Z variance eval              0.004148795
total_rewards                [311.53478051 336.79998274 331.68960599 248.00751376 309.6545871
 349.7501717  327.42237195 332.25349668 321.2331816  320.83928573]
total_rewards_mean           318.9184977772358
total_rewards_std            26.194146409432722
total_rewards_max            349.75017170080764
total_rewards_min            248.0075137644055
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               30.97728577395901
(Previous) Eval Time (s)     3.8258934770710766
Sample Time (s)              17.87233171192929
Epoch Time (s)               52.67551096295938
Total Train Time (s)         1205.0869304388762
Epoch                        22
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:48.623110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #22 | Epoch Duration: 52.454357862472534
2020-01-11 00:22:48.623330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022985097
Z variance train             0.004145743
KL Divergence                12.443979
KL Loss                      1.244398
QF Loss                      577.3473
VF Loss                      167.72879
Policy Loss                  -422.85773
Q Predictions Mean           416.10983
Q Predictions Std            376.9387
Q Predictions Max            1081.5902
Q Predictions Min            -4.5096207
V Predictions Mean           418.60245
V Predictions Std            376.23605
V Predictions Max            1081.7595
V Predictions Min            -0.7020532
Log Pis Mean                 -0.015296986
Log Pis Std                  2.3421314
Log Pis Max                  7.9732947
Log Pis Min                  -3.977352
Policy mu Mean               0.17545652
Policy mu Std                0.90752953
Policy mu Max                2.6652794
Policy mu Min                -3.617496
Policy log std Mean          -0.513906
Policy log std Std           0.33978063
Policy log std Max           -0.1029358
Policy log std Min           -1.5609468
Z mean eval                  0.022446882
Z variance eval              0.003707102
total_rewards                [386.79962206 338.44555982 338.37311127 343.51040917 355.47925189
 362.33935406 325.46187248 323.58898439 353.47517324 382.69684378]
total_rewards_mean           351.01701821518157
total_rewards_std            20.53722734889764
total_rewards_max            386.7996220571438
total_rewards_min            323.5889843857965
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               31.02459511719644
(Previous) Eval Time (s)     3.604439546354115
Sample Time (s)              17.32811971893534
Epoch Time (s)               51.957154382485896
Total Train Time (s)         1257.4713065158576
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:23:41.008353 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #23 | Epoch Duration: 52.38488793373108
2020-01-11 00:23:41.008531 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016045231
Z variance train             0.0026514053
KL Divergence                13.616076
KL Loss                      1.3616077
QF Loss                      542.9874
VF Loss                      356.55014
Policy Loss                  -423.34283
Q Predictions Mean           418.0861
Q Predictions Std            383.36072
Q Predictions Max            1135.8944
Q Predictions Min            -1.8445054
V Predictions Mean           432.5445
V Predictions Std            387.68396
V Predictions Max            1153.549
V Predictions Min            0.40957195
Log Pis Mean                 0.18792313
Log Pis Std                  2.5318983
Log Pis Max                  9.260107
Log Pis Min                  -4.720354
Policy mu Mean               0.17178535
Policy mu Std                0.93149287
Policy mu Max                3.4388082
Policy mu Min                -3.137384
Policy log std Mean          -0.49718508
Policy log std Std           0.330777
Policy log std Max           -0.09326147
Policy log std Min           -1.8451307
Z mean eval                  0.009941803
Z variance eval              0.0027275742
total_rewards                [283.40634447 338.83637271 371.19306609 360.61961376 371.38001066
 347.35798206 365.74363707 340.12423022 279.67597756 354.11827315]
total_rewards_mean           341.2455507748794
total_rewards_std            31.822580542432412
total_rewards_max            371.3800106645187
total_rewards_min            279.67597755713575
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               31.02185179013759
(Previous) Eval Time (s)     4.03179980115965
Sample Time (s)              18.44332126248628
Epoch Time (s)               53.49697285378352
Total Train Time (s)         1311.2012164588086
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:24:34.739831 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #24 | Epoch Duration: 53.73115611076355
2020-01-11 00:24:34.740002 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009273192
Z variance train             0.0028040374
KL Divergence                13.248844
KL Loss                      1.3248844
QF Loss                      348.94165
VF Loss                      143.83151
Policy Loss                  -472.5628
Q Predictions Mean           460.8576
Q Predictions Std            383.32645
Q Predictions Max            1114.8417
Q Predictions Min            -10.486504
V Predictions Mean           466.5805
V Predictions Std            386.381
V Predictions Max            1121.8552
V Predictions Min            -5.369672
Log Pis Mean                 -0.06873852
Log Pis Std                  2.2335446
Log Pis Max                  8.1433325
Log Pis Min                  -3.9616342
Policy mu Mean               0.105436295
Policy mu Std                0.8971972
Policy mu Max                2.3771963
Policy mu Min                -3.0812485
Policy log std Mean          -0.51075214
Policy log std Std           0.3358122
Policy log std Max           -0.029186666
Policy log std Min           -1.7052565
Z mean eval                  0.0146221295
Z variance eval              0.0028928132
total_rewards                [407.03259064 398.02624186 401.22884443 398.77142189 399.36008113
 400.27949352 405.85246585 400.2925652  398.40553655 407.50552928]
total_rewards_mean           401.6754770346157
total_rewards_std            3.492851692112797
total_rewards_max            407.5055292794449
total_rewards_min            398.02624185876857
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               31.00897043943405
(Previous) Eval Time (s)     4.26568323886022
Sample Time (s)              18.039444601163268
Epoch Time (s)               53.31409827945754
Total Train Time (s)         1364.1599161326885
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:25:27.699231 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #25 | Epoch Duration: 52.95906662940979
2020-01-11 00:25:27.699407 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017328728
Z variance train             0.003023696
KL Divergence                12.75169
KL Loss                      1.275169
QF Loss                      1207.0298
VF Loss                      133.29762
Policy Loss                  -457.49478
Q Predictions Mean           451.3156
Q Predictions Std            387.4695
Q Predictions Max            1085.8154
Q Predictions Min            -8.135998
V Predictions Mean           456.21704
V Predictions Std            387.04977
V Predictions Max            1085.2192
V Predictions Min            -4.171123
Log Pis Mean                 0.089330465
Log Pis Std                  2.2598414
Log Pis Max                  8.83801
Log Pis Min                  -3.9074874
Policy mu Mean               0.06965207
Policy mu Std                0.93398863
Policy mu Max                2.7268634
Policy mu Min                -3.3424194
Policy log std Mean          -0.46498737
Policy log std Std           0.30979747
Policy log std Max           -0.013594255
Policy log std Min           -1.8511921
Z mean eval                  0.047910657
Z variance eval              0.0012366495
total_rewards                [378.58134022 388.1397153  401.16132886 391.66099001 383.58280656
 394.20939749 389.02938785 401.70548244 395.99991579 409.25337324]
total_rewards_mean           393.33237377542827
total_rewards_std            8.681501176436667
total_rewards_max            409.2533732405475
total_rewards_min            378.5813402233587
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               31.186848196201026
(Previous) Eval Time (s)     3.9103721026331186
Sample Time (s)              18.610969222150743
Epoch Time (s)               53.70818952098489
Total Train Time (s)         1417.945911932271
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:26:21.487637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #26 | Epoch Duration: 53.788097858428955
2020-01-11 00:26:21.487845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22125919
Z variance train             0.00016094383
KL Divergence                20.31233
KL Loss                      2.031233
QF Loss                      244.09926
VF Loss                      75.47821
Policy Loss                  -380.62308
Q Predictions Mean           380.42505
Q Predictions Std            362.9953
Q Predictions Max            992.5324
Q Predictions Min            -5.656588
V Predictions Mean           381.657
V Predictions Std            363.17572
V Predictions Max            1002.5655
V Predictions Min            -4.9657516
Log Pis Mean                 -0.19717792
Log Pis Std                  2.3961902
Log Pis Max                  9.900117
Log Pis Min                  -4.00106
Policy mu Mean               0.10513414
Policy mu Std                0.8852379
Policy mu Max                2.96289
Policy mu Min                -3.341849
Policy log std Mean          -0.44189084
Policy log std Std           0.3247873
Policy log std Max           -0.06652616
Policy log std Min           -1.7844372
Z mean eval                  0.016944692
Z variance eval              0.0018227197
total_rewards                [401.68419374 403.76670443 408.09857808 391.87865125 420.03976996
 380.57382544 387.35103597 372.27948544 388.14012974 479.24198655]
total_rewards_mean           403.30543605926937
total_rewards_std            28.577350434019316
total_rewards_max            479.24198654529056
total_rewards_min            372.27948544358304
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               31.10644420888275
(Previous) Eval Time (s)     3.989936748985201
Sample Time (s)              17.00082544889301
Epoch Time (s)               52.09720640676096
Total Train Time (s)         1470.250926275272
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:27:13.794560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #27 | Epoch Duration: 52.30648064613342
2020-01-11 00:27:13.794903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018125767
Z variance train             0.0018507794
KL Divergence                13.46458
KL Loss                      1.346458
QF Loss                      237.5816
VF Loss                      83.322525
Policy Loss                  -475.32327
Q Predictions Mean           469.2472
Q Predictions Std            400.64688
Q Predictions Max            1054.2881
Q Predictions Min            -17.620562
V Predictions Mean           478.0259
V Predictions Std            402.2712
V Predictions Max            1084.8195
V Predictions Min            0.61724925
Log Pis Mean                 -0.14952382
Log Pis Std                  2.2319546
Log Pis Max                  7.5013647
Log Pis Min                  -3.822588
Policy mu Mean               0.05035368
Policy mu Std                0.84610504
Policy mu Max                2.1938477
Policy mu Min                -2.597177
Policy log std Mean          -0.475908
Policy log std Std           0.33406273
Policy log std Max           0.031357393
Policy log std Min           -1.7646899
Z mean eval                  0.010996924
Z variance eval              0.0014375532
total_rewards                [381.15588588 380.85046119 385.97907279 377.61675352 388.41769277
 368.32102885 402.48043836 410.39366142 378.04350957 390.85708912]
total_rewards_mean           386.41155934738333
total_rewards_std            11.791999491995277
total_rewards_max            410.39366142122265
total_rewards_min            368.3210288514177
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               30.887153584044427
(Previous) Eval Time (s)     4.198899383656681
Sample Time (s)              19.49817061703652
Epoch Time (s)               54.58422358473763
Total Train Time (s)         1524.958276316058
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:28:08.506264 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #28 | Epoch Duration: 54.71116304397583
2020-01-11 00:28:08.506478 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010844424
Z variance train             0.0014420912
KL Divergence                14.085743
KL Loss                      1.4085743
QF Loss                      201.99173
VF Loss                      65.17075
Policy Loss                  -468.16547
Q Predictions Mean           463.59207
Q Predictions Std            404.93518
Q Predictions Max            1061.2974
Q Predictions Min            -15.182414
V Predictions Mean           470.49115
V Predictions Std            408.73892
V Predictions Max            1072.9232
V Predictions Min            -4.245168
Log Pis Mean                 -0.27152377
Log Pis Std                  2.1742623
Log Pis Max                  7.6923637
Log Pis Min                  -5.8435726
Policy mu Mean               0.076188
Policy mu Std                0.8643588
Policy mu Max                2.211442
Policy mu Min                -3.033147
Policy log std Mean          -0.49033418
Policy log std Std           0.33260688
Policy log std Max           -0.07119796
Policy log std Min           -1.8961402
Z mean eval                  0.016529249
Z variance eval              0.0014575211
total_rewards                [342.68721043 373.07869796 397.52843262 369.65815473 383.71260404
 377.51832663 375.05137665 373.67720208 369.74045667 384.7994992 ]
total_rewards_mean           374.74519610135894
total_rewards_std            13.382529510117278
total_rewards_max            397.52843261926756
total_rewards_min            342.6872104295711
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               31.69575296714902
(Previous) Eval Time (s)     4.325495254248381
Sample Time (s)              17.908303215168417
Epoch Time (s)               53.929551436565816
Total Train Time (s)         1578.5166424275376
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:02.062825 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #29 | Epoch Duration: 53.55612301826477
2020-01-11 00:29:02.063123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017448004
Z variance train             0.0014601656
KL Divergence                13.951802
KL Loss                      1.3951802
QF Loss                      690.0321
VF Loss                      186.52634
Policy Loss                  -451.66937
Q Predictions Mean           447.06146
Q Predictions Std            389.26968
Q Predictions Max            1057.7792
Q Predictions Min            -7.164452
V Predictions Mean           460.8907
V Predictions Std            398.29785
V Predictions Max            1078.3116
V Predictions Min            -3.0483637
Log Pis Mean                 -0.11743279
Log Pis Std                  2.2592676
Log Pis Max                  8.103357
Log Pis Min                  -4.3840346
Policy mu Mean               0.24293499
Policy mu Std                0.9047879
Policy mu Max                2.8818517
Policy mu Min                -2.6595993
Policy log std Mean          -0.4827005
Policy log std Std           0.33470267
Policy log std Max           0.05555238
Policy log std Min           -2.5311236
Z mean eval                  0.030848708
Z variance eval              0.0025139495
total_rewards                [398.7558299  386.14131948 396.0303838  391.58068769 392.44318667
 395.91665581 382.61142915 383.16443361 391.4140338  401.58473886]
total_rewards_mean           391.96426987680604
total_rewards_std            6.085491791408053
total_rewards_max            401.58473885593236
total_rewards_min            382.61142915487835
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.327548041008413
(Previous) Eval Time (s)     3.951726029161364
Sample Time (s)              17.470294954720885
Epoch Time (s)               52.74956902489066
Total Train Time (s)         1631.544985102024
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:55.092431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #30 | Epoch Duration: 53.02912616729736
2020-01-11 00:29:55.092602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029291237
Z variance train             0.0024534704
KL Divergence                12.741919
KL Loss                      1.2741919
QF Loss                      260.21075
VF Loss                      63.85291
Policy Loss                  -432.16946
Q Predictions Mean           435.13214
Q Predictions Std            407.561
Q Predictions Max            1053.7372
Q Predictions Min            -5.670738
V Predictions Mean           433.34375
V Predictions Std            405.1307
V Predictions Max            1047.5709
V Predictions Min            -8.252671
Log Pis Mean                 -0.57693756
Log Pis Std                  1.9213294
Log Pis Max                  4.957113
Log Pis Min                  -4.762366
Policy mu Mean               0.15816686
Policy mu Std                0.7476674
Policy mu Max                2.3937945
Policy mu Min                -2.2305768
Policy log std Mean          -0.43399644
Policy log std Std           0.3058613
Policy log std Max           -0.08917895
Policy log std Min           -1.6437988
Z mean eval                  0.012098837
Z variance eval              0.0019430649
total_rewards                [424.45760595 397.77952394 408.29719855 360.15720122 385.09376056
 330.43881249 389.80660436 392.07207997 383.08035313 369.27459462]
total_rewards_mean           384.04577347887823
total_rewards_std            24.84363234664852
total_rewards_max            424.45760595148903
total_rewards_min            330.4388124875426
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.0230303988792
(Previous) Eval Time (s)     4.231009128969163
Sample Time (s)              18.371494887862355
Epoch Time (s)               53.62553441571072
Total Train Time (s)         1685.23361052759
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:30:48.781868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #31 | Epoch Duration: 53.68913435935974
2020-01-11 00:30:48.782067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011560408
Z variance train             0.0019746523
KL Divergence                13.178093
KL Loss                      1.3178093
QF Loss                      299.78064
VF Loss                      104.576195
Policy Loss                  -494.9163
Q Predictions Mean           498.15765
Q Predictions Std            405.72614
Q Predictions Max            1077.7842
Q Predictions Min            -5.1254687
V Predictions Mean           499.48257
V Predictions Std            405.71738
V Predictions Max            1073.1155
V Predictions Min            -10.097398
Log Pis Mean                 -0.17616086
Log Pis Std                  2.0161285
Log Pis Max                  8.735632
Log Pis Min                  -3.67942
Policy mu Mean               0.030925259
Policy mu Std                0.8472323
Policy mu Max                2.2830265
Policy mu Min                -2.72207
Policy log std Mean          -0.49123994
Policy log std Std           0.33355504
Policy log std Max           0.021430135
Policy log std Min           -1.8553516
Z mean eval                  0.006766683
Z variance eval              0.0017754879
total_rewards                [370.91701639 323.54556988 367.46054567 366.03237054 357.38404205
 377.87433839 364.07105235 349.70485652 369.61723375 385.24501862]
total_rewards_mean           363.18520441728054
total_rewards_std            16.178385247094198
total_rewards_max            385.24501861635423
total_rewards_min            323.5455698768926
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.29992320621386
(Previous) Eval Time (s)     4.29428030597046
Sample Time (s)              17.672971955500543
Epoch Time (s)               53.267175467684865
Total Train Time (s)         1737.917074399069
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:31:41.475970 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #32 | Epoch Duration: 52.69376492500305
2020-01-11 00:31:41.476157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007030219
Z variance train             0.0017351804
KL Divergence                13.453959
KL Loss                      1.3453959
QF Loss                      193.27481
VF Loss                      100.514534
Policy Loss                  -473.23947
Q Predictions Mean           475.5237
Q Predictions Std            407.65143
Q Predictions Max            1087.1815
Q Predictions Min            -4.9669657
V Predictions Mean           467.7988
V Predictions Std            402.5984
V Predictions Max            1075.9922
V Predictions Min            -12.469202
Log Pis Mean                 -0.40412444
Log Pis Std                  2.0529194
Log Pis Max                  7.623161
Log Pis Min                  -4.8923135
Policy mu Mean               0.09295226
Policy mu Std                0.81244206
Policy mu Max                2.9223483
Policy mu Min                -2.3183165
Policy log std Mean          -0.436674
Policy log std Std           0.3080034
Policy log std Max           0.108532324
Policy log std Min           -1.5913409
Z mean eval                  0.022178914
Z variance eval              0.0016632213
total_rewards                [ 367.61914884  383.98969068 1031.30462595  384.59845556 1030.00447603
  390.02316767  373.77140012  384.03320811  400.34487946  397.21162308]
total_rewards_mean           514.290067550088
total_rewards_std            258.34499053017214
total_rewards_max            1031.3046259543573
total_rewards_min            367.61914883886413
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.158570700790733
(Previous) Eval Time (s)     3.7205462949350476
Sample Time (s)              18.066939444746822
Epoch Time (s)               52.9460564404726
Total Train Time (s)         1796.5140845365822
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:32:40.064110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #33 | Epoch Duration: 58.58783197402954
2020-01-11 00:32:40.064233 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023352532
Z variance train             0.0016894769
KL Divergence                13.547924
KL Loss                      1.3547925
QF Loss                      1063.1152
VF Loss                      212.7399
Policy Loss                  -521.093
Q Predictions Mean           513.17816
Q Predictions Std            408.20746
Q Predictions Max            1098.158
Q Predictions Min            -5.657163
V Predictions Mean           512.9009
V Predictions Std            408.553
V Predictions Max            1087.5999
V Predictions Min            -3.3401923
Log Pis Mean                 -0.25499922
Log Pis Std                  2.1099625
Log Pis Max                  6.026663
Log Pis Min                  -4.267336
Policy mu Mean               0.02464638
Policy mu Std                0.8750543
Policy mu Max                3.5597358
Policy mu Min                -2.945334
Policy log std Mean          -0.46388555
Policy log std Std           0.30169913
Policy log std Max           0.118610725
Policy log std Min           -1.6547372
Z mean eval                  0.0069880695
Z variance eval              0.0015144234
total_rewards                [445.95064128 415.0899617  401.32389561 392.69706621 398.20925704
 417.74717045 412.36068641 473.78800932 408.35730532 433.02288491]
total_rewards_mean           419.85468782725076
total_rewards_std            23.51201569505809
total_rewards_max            473.78800932061966
total_rewards_min            392.6970662134078
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               30.9265018212609
(Previous) Eval Time (s)     9.36198962200433
Sample Time (s)              21.01395480101928
Epoch Time (s)               61.30244624428451
Total Train Time (s)         1852.712184804026
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:33:36.264319 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #34 | Epoch Duration: 56.19997549057007
2020-01-11 00:33:36.264516 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0070521696
Z variance train             0.0015261436
KL Divergence                13.808952
KL Loss                      1.3808953
QF Loss                      369.03384
VF Loss                      51.51282
Policy Loss                  -425.5688
Q Predictions Mean           421.4417
Q Predictions Std            403.76562
Q Predictions Max            1078.8711
Q Predictions Min            -3.7709444
V Predictions Mean           423.97388
V Predictions Std            405.94424
V Predictions Max            1073.2999
V Predictions Min            -13.785236
Log Pis Mean                 -0.17924759
Log Pis Std                  2.2517152
Log Pis Max                  7.2949705
Log Pis Min                  -5.314374
Policy mu Mean               -0.14083456
Policy mu Std                0.86631554
Policy mu Max                2.292055
Policy mu Min                -3.49895
Policy log std Mean          -0.4461278
Policy log std Std           0.309995
Policy log std Max           0.016562998
Policy log std Min           -1.7955793
Z mean eval                  0.008979342
Z variance eval              0.00090930436
total_rewards                [390.79937064 388.33469363 363.29192037 314.31594985 376.40772244
 382.43017235 379.59792721 383.83741095 357.65297513 337.44662211]
total_rewards_mean           367.41147646725585
total_rewards_std            23.53468868916618
total_rewards_max            390.7993706390932
total_rewards_min            314.3159498528787
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.871914794202894
(Previous) Eval Time (s)     4.259186799172312
Sample Time (s)              17.58856489835307
Epoch Time (s)               52.719666491728276
Total Train Time (s)         1905.0024074614048
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:34:28.557995 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #35 | Epoch Duration: 52.29330658912659
2020-01-11 00:34:28.558255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029964263
Z variance train             0.0012361059
KL Divergence                14.314242
KL Loss                      1.4314243
QF Loss                      641.86646
VF Loss                      207.13226
Policy Loss                  -479.62827
Q Predictions Mean           479.6767
Q Predictions Std            411.0401
Q Predictions Max            1096.494
Q Predictions Min            -6.404221
V Predictions Mean           474.47363
V Predictions Std            405.21463
V Predictions Max            1069.7542
V Predictions Min            -0.67681706
Log Pis Mean                 -0.117517665
Log Pis Std                  2.3384883
Log Pis Max                  9.951172
Log Pis Min                  -5.635852
Policy mu Mean               0.08653506
Policy mu Std                0.9073831
Policy mu Max                3.688937
Policy mu Min                -3.231535
Policy log std Mean          -0.45366713
Policy log std Std           0.30097392
Policy log std Max           0.063622564
Policy log std Min           -2.1565058
Z mean eval                  0.020007525
Z variance eval              0.0009673002
total_rewards                [401.19699937 340.33953622 409.84967596 406.01354288 480.85460359
 407.69393005 423.45379632 351.36598708 383.6607996  423.34063104]
total_rewards_mean           402.77695021010777
total_rewards_std            37.337158190547484
total_rewards_max            480.85460358802334
total_rewards_min            340.33953622395313
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.207388519775122
(Previous) Eval Time (s)     3.832511610817164
Sample Time (s)              17.808892035856843
Epoch Time (s)               52.84879216644913
Total Train Time (s)         1958.303358425852
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:35:21.857923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #36 | Epoch Duration: 53.29951333999634
2020-01-11 00:35:21.858096 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017121172
Z variance train             0.0006081685
KL Divergence                16.076267
KL Loss                      1.6076268
QF Loss                      1124.7457
VF Loss                      200.35693
Policy Loss                  -474.28107
Q Predictions Mean           470.62152
Q Predictions Std            412.7868
Q Predictions Max            1059.7347
Q Predictions Min            -7.943347
V Predictions Mean           469.79935
V Predictions Std            409.39758
V Predictions Max            1051.4642
V Predictions Min            -0.86224335
Log Pis Mean                 -0.5484702
Log Pis Std                  2.080963
Log Pis Max                  11.329817
Log Pis Min                  -4.793499
Policy mu Mean               0.011908243
Policy mu Std                0.8168767
Policy mu Max                2.6322987
Policy mu Min                -3.5442636
Policy log std Mean          -0.44588318
Policy log std Std           0.31711233
Policy log std Max           0.16566156
Policy log std Min           -1.6008172
Z mean eval                  0.007786234
Z variance eval              0.0008306196
total_rewards                [ 564.30470749  653.36045072 1054.61836003  650.87140617  633.41647028
  395.21083768  517.14865557  412.02040222  401.12689183  355.73651915]
total_rewards_mean           563.7814701154392
total_rewards_std            196.14803668483768
total_rewards_max            1054.6183600294182
total_rewards_min            355.7365191493991
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               30.90919113298878
(Previous) Eval Time (s)     4.282910958863795
Sample Time (s)              18.436517019290477
Epoch Time (s)               53.62861911114305
Total Train Time (s)         2014.8635015101172
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:36:18.419911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #37 | Epoch Duration: 56.56166958808899
2020-01-11 00:36:18.420111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #37 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075560203
Z variance train             0.00086189306
KL Divergence                15.234495
KL Loss                      1.5234495
QF Loss                      964.2453
VF Loss                      106.9009
Policy Loss                  -453.74847
Q Predictions Mean           452.7658
Q Predictions Std            410.25003
Q Predictions Max            1056.5842
Q Predictions Min            -7.004784
V Predictions Mean           454.98224
V Predictions Std            412.41254
V Predictions Max            1055.306
V Predictions Min            -0.78340864
Log Pis Mean                 -0.4653784
Log Pis Std                  2.0328126
Log Pis Max                  5.790124
Log Pis Min                  -5.7127986
Policy mu Mean               -0.0040944167
Policy mu Std                0.77909476
Policy mu Max                2.472923
Policy mu Min                -2.2655997
Policy log std Mean          -0.43484864
Policy log std Std           0.31429806
Policy log std Max           0.10429676
Policy log std Min           -2.0083482
Z mean eval                  0.020848796
Z variance eval              0.00066763035
total_rewards                [535.57006911 414.55379852 499.42033372 414.35594904 655.5557805
 421.90432588 419.11385817 417.61133081 422.36402331 417.90602196]
total_rewards_mean           461.8355491022188
total_rewards_std            75.98028134948346
total_rewards_max            655.5557804992662
total_rewards_min            414.355949040707
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               31.077694503124803
(Previous) Eval Time (s)     7.215649134013802
Sample Time (s)              21.754135325551033
Epoch Time (s)               60.04747896268964
Total Train Time (s)         2072.745675492566
Epoch                        38
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:37:16.305444 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #38 | Epoch Duration: 57.88518810272217
2020-01-11 00:37:16.305636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020610657
Z variance train             0.0006733915
KL Divergence                15.842235
KL Loss                      1.5842235
QF Loss                      1425.5134
VF Loss                      160.53195
Policy Loss                  -495.13776
Q Predictions Mean           491.81583
Q Predictions Std            414.222
Q Predictions Max            1062.3888
Q Predictions Min            -8.099921
V Predictions Mean           494.2477
V Predictions Std            416.52313
V Predictions Max            1059.8345
V Predictions Min            -5.3694835
Log Pis Mean                 -0.57324165
Log Pis Std                  2.056398
Log Pis Max                  10.087476
Log Pis Min                  -5.0865293
Policy mu Mean               -0.017907029
Policy mu Std                0.7702984
Policy mu Max                2.6786902
Policy mu Min                -2.7915816
Policy log std Mean          -0.43336746
Policy log std Std           0.2915368
Policy log std Max           0.15718539
Policy log std Min           -2.2248154
Z mean eval                  0.02179817
Z variance eval              0.0006813138
total_rewards                [843.39061139 613.29343393 415.4787592  712.42776912 525.40095502
 713.66253454 774.36432175 420.24477904 408.44984509 438.48998491]
total_rewards_mean           586.5202993992315
total_rewards_std            157.56356356795507
total_rewards_max            843.3906113912093
total_rewards_min            408.44984509418373
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               31.537933100946248
(Previous) Eval Time (s)     5.053042381070554
Sample Time (s)              19.421061523724347
Epoch Time (s)               56.01203700574115
Total Train Time (s)         2133.399352164939
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:38:16.958556 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #39 | Epoch Duration: 60.652743339538574
2020-01-11 00:38:16.958917 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021872466
Z variance train             0.00066442916
KL Divergence                15.898125
KL Loss                      1.5898125
QF Loss                      323.1114
VF Loss                      110.516685
Policy Loss                  -468.1059
Q Predictions Mean           468.68286
Q Predictions Std            411.92856
Q Predictions Max            1234.6155
Q Predictions Min            -0.83733016
V Predictions Mean           471.5882
V Predictions Std            411.42987
V Predictions Max            1286.0983
V Predictions Min            -5.0889735
Log Pis Mean                 -0.49027914
Log Pis Std                  2.2796288
Log Pis Max                  10.884975
Log Pis Min                  -4.459349
Policy mu Mean               0.01112398
Policy mu Std                0.8158896
Policy mu Max                3.0041153
Policy mu Min                -3.0258389
Policy log std Mean          -0.42656478
Policy log std Std           0.2873702
Policy log std Max           0.17487758
Policy log std Min           -2.5704658
Z mean eval                  0.01758308
Z variance eval              0.00066005206
total_rewards                [470.00641547 776.49141052 570.14110216 413.29288806 585.56722622
 622.65172514 411.01809512 569.67478476 571.55472746 621.55691875]
total_rewards_mean           561.1955293680086
total_rewards_std            103.61939922653295
total_rewards_max            776.4914105201648
total_rewards_min            411.0180951240786
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               30.719848528970033
(Previous) Eval Time (s)     9.693436589092016
Sample Time (s)              21.99465480586514
Epoch Time (s)               62.40793992392719
Total Train Time (s)         2191.3512603654526
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:39:14.913270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #40 | Epoch Duration: 57.95413088798523
2020-01-11 00:39:14.913521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018203741
Z variance train             0.0006466334
KL Divergence                15.985527
KL Loss                      1.5985527
QF Loss                      3241.0405
VF Loss                      132.72
Policy Loss                  -528.8356
Q Predictions Mean           527.2318
Q Predictions Std            396.6688
Q Predictions Max            1165.5415
Q Predictions Min            -1.0638237
V Predictions Mean           534.54535
V Predictions Std            397.65018
V Predictions Max            1194.7821
V Predictions Min            -4.619233
Log Pis Mean                 -0.2525292
Log Pis Std                  2.1947477
Log Pis Max                  8.757261
Log Pis Min                  -6.8027697
Policy mu Mean               -0.117398314
Policy mu Std                0.88014066
Policy mu Max                3.047647
Policy mu Min                -3.2479868
Policy log std Mean          -0.45345142
Policy log std Std           0.29834956
Policy log std Max           0.25619477
Policy log std Min           -1.4831046
Z mean eval                  0.018949335
Z variance eval              0.000684743
total_rewards                [ 660.68620319  626.55138262  671.25562949  615.27433683 1092.78802415
  676.01894419  659.71533925 1086.20783201 1076.8561033   698.3014795 ]
total_rewards_mean           786.3655274538702
total_rewards_std            196.98100960441434
total_rewards_max            1092.7880241511536
total_rewards_min            615.2743368328912
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               31.30603581527248
(Previous) Eval Time (s)     5.239308009855449
Sample Time (s)              21.566738773602992
Epoch Time (s)               58.11208259873092
Total Train Time (s)         2256.9853255809285
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:40:20.548635 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #41 | Epoch Duration: 65.63492178916931
2020-01-11 00:40:20.548874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #41 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019158658
Z variance train             0.00067935826
KL Divergence                15.9186
KL Loss                      1.59186
QF Loss                      623.31995
VF Loss                      117.309296
Policy Loss                  -484.2644
Q Predictions Mean           482.95874
Q Predictions Std            411.17657
Q Predictions Max            1049.473
Q Predictions Min            -6.303493
V Predictions Mean           486.0427
V Predictions Std            411.0929
V Predictions Max            1040.2462
V Predictions Min            -2.926685
Log Pis Mean                 -0.41600257
Log Pis Std                  2.1641994
Log Pis Max                  10.733356
Log Pis Min                  -5.236029
Policy mu Mean               -0.031235255
Policy mu Std                0.8462809
Policy mu Max                2.7721674
Policy mu Min                -2.8721342
Policy log std Mean          -0.43709424
Policy log std Std           0.30152828
Policy log std Max           0.060325623
Policy log std Min           -2.1021278
Z mean eval                  0.017079968
Z variance eval              0.0007377393
total_rewards                [1054.33445903 1052.8752632  1051.23145683 1055.05017216 1051.1728552
 1054.91453856 1050.11700652 1047.93866835 1048.83112699 1058.2891832 ]
total_rewards_mean           1052.4754730043787
total_rewards_std            3.0440698407784037
total_rewards_max            1058.2891832043927
total_rewards_min            1047.9386683484015
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               31.295208150986582
(Previous) Eval Time (s)     12.76176326815039
Sample Time (s)              22.374186872970313
Epoch Time (s)               66.43115829210728
Total Train Time (s)         2341.1746093872935
Epoch                        42
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:41:44.738408 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #42 | Epoch Duration: 84.18936824798584
2020-01-11 00:41:44.738588 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016680008
Z variance train             0.0007373608
KL Divergence                15.748104
KL Loss                      1.5748104
QF Loss                      242.34439
VF Loss                      182.83475
Policy Loss                  -485.6198
Q Predictions Mean           481.70593
Q Predictions Std            418.10025
Q Predictions Max            1215.1146
Q Predictions Min            -1.9283656
V Predictions Mean           479.20035
V Predictions Std            412.0178
V Predictions Max            1110.9779
V Predictions Min            -0.6758576
Log Pis Mean                 -0.2430895
Log Pis Std                  2.108046
Log Pis Max                  8.054844
Log Pis Min                  -3.7438548
Policy mu Mean               -0.0072797164
Policy mu Std                0.86089426
Policy mu Max                2.7516472
Policy mu Min                -2.9370792
Policy log std Mean          -0.4375131
Policy log std Std           0.29798275
Policy log std Max           0.27783918
Policy log std Min           -1.6102867
Z mean eval                  0.019031167
Z variance eval              0.00075017323
total_rewards                [1074.82963779 1075.06801428  913.3949596  1067.55422886 1070.16636029
 1058.16714547 1074.10204995  688.13912913 1066.30910335 1078.50964286]
total_rewards_mean           1016.6240271597329
total_rewards_std            119.22701801662213
total_rewards_max            1078.5096428623133
total_rewards_min            688.1391291342089
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               32.92713957140222
(Previous) Eval Time (s)     30.519660626072437
Sample Time (s)              24.032133617904037
Epoch Time (s)               87.4789338153787
Total Train Time (s)         2425.7082920060493
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:43:09.274474 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #43 | Epoch Duration: 84.5357449054718
2020-01-11 00:43:09.274708 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019179525
Z variance train             0.0007500694
KL Divergence                15.75379
KL Loss                      1.575379
QF Loss                      332.28223
VF Loss                      152.20834
Policy Loss                  -541.8977
Q Predictions Mean           538.0144
Q Predictions Std            395.9982
Q Predictions Max            1016.6448
Q Predictions Min            -12.593231
V Predictions Mean           546.4218
V Predictions Std            393.4602
V Predictions Max            1010.9325
V Predictions Min            -5.5291924
Log Pis Mean                 -0.22432706
Log Pis Std                  2.1876755
Log Pis Max                  14.870672
Log Pis Min                  -3.7674565
Policy mu Mean               -0.029364645
Policy mu Std                0.877241
Policy mu Max                2.665508
Policy mu Min                -3.7733722
Policy log std Mean          -0.45900163
Policy log std Std           0.29182893
Policy log std Max           0.13694386
Policy log std Min           -1.694942
Z mean eval                  0.0078042373
Z variance eval              0.00095414306
total_rewards                [645.04365375 586.88154676 704.44750447 647.5892187  949.53832423
 596.64436558 644.22877983 786.32716622 550.43223234 697.04635305]
total_rewards_mean           680.8179144940412
total_rewards_std            109.90766256771127
total_rewards_max            949.5383242323137
total_rewards_min            550.4322323405836
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               33.801489882636815
(Previous) Eval Time (s)     27.576133941765875
Sample Time (s)              24.786661015357822
Epoch Time (s)               86.16428483976051
Total Train Time (s)         2494.4098094897345
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:44:17.977906 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #44 | Epoch Duration: 68.70304012298584
2020-01-11 00:44:17.978157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0073753423
Z variance train             0.0009522155
KL Divergence                15.46591
KL Loss                      1.546591
QF Loss                      267.87628
VF Loss                      68.755035
Policy Loss                  -575.6378
Q Predictions Mean           573.1882
Q Predictions Std            392.95847
Q Predictions Max            1185.2496
Q Predictions Min            -1.4287397
V Predictions Mean           574.2631
V Predictions Std            392.01904
V Predictions Max            1200.8546
V Predictions Min            -2.5196507
Log Pis Mean                 -0.010231668
Log Pis Std                  2.2763343
Log Pis Max                  7.909764
Log Pis Min                  -5.4604015
Policy mu Mean               0.09048071
Policy mu Std                0.8824534
Policy mu Max                3.053651
Policy mu Min                -2.7378118
Policy log std Mean          -0.46679756
Policy log std Std           0.2824738
Policy log std Max           0.25043386
Policy log std Min           -1.4571798
Z mean eval                  0.008174429
Z variance eval              0.00091927825
total_rewards                [ 996.15973468 1093.03802594  511.8757438  1200.83760637  859.61204713
 1103.86313684  715.30971189  660.21954443  762.13410018  660.23442467]
total_rewards_mean           856.3284075925136
total_rewards_std            219.0600534100779
total_rewards_max            1200.837606366654
total_rewards_min            511.87574380070663
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               34.11998029705137
(Previous) Eval Time (s)     10.114527266006917
Sample Time (s)              23.87363829324022
Epoch Time (s)               68.1081458562985
Total Train Time (s)         2567.655966144521
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:31.232063 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #45 | Epoch Duration: 73.253746509552
2020-01-11 00:45:31.232255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008301256
Z variance train             0.0009158294
KL Divergence                15.281789
KL Loss                      1.5281789
QF Loss                      552.4818
VF Loss                      425.96454
Policy Loss                  -579.8713
Q Predictions Mean           570.13934
Q Predictions Std            387.0546
Q Predictions Max            1147.84
Q Predictions Min            -2.32923
V Predictions Mean           578.5204
V Predictions Std            387.77664
V Predictions Max            1180.6787
V Predictions Min            -3.2872303
Log Pis Mean                 0.1930779
Log Pis Std                  2.574314
Log Pis Max                  11.5966015
Log Pis Min                  -5.455398
Policy mu Mean               -0.04128931
Policy mu Std                0.9902593
Policy mu Max                2.9325473
Policy mu Min                -3.3533397
Policy log std Mean          -0.4717238
Policy log std Std           0.30777153
Policy log std Max           0.2965299
Policy log std Min           -1.6283073
Z mean eval                  0.0069436273
Z variance eval              0.0011693143
total_rewards                [1310.98814645 1032.19998098 1128.35741372 1328.56683541 1091.10101406
 1117.62065712  831.52224428 1253.89426432 1635.79111759 1218.03901127]
total_rewards_mean           1194.8080685197042
total_rewards_std            202.3444692594237
total_rewards_max            1635.7911175869267
total_rewards_min            831.5222442844729
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               32.72781116422266
(Previous) Eval Time (s)     15.259648301638663
Sample Time (s)              23.967951292637736
Epoch Time (s)               71.95541075849906
Total Train Time (s)         2642.7857887758873
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:46:46.356776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #46 | Epoch Duration: 75.12437844276428
2020-01-11 00:46:46.356967 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007941226
Z variance train             0.0011719877
KL Divergence                14.735023
KL Loss                      1.4735023
QF Loss                      947.97314
VF Loss                      128.91722
Policy Loss                  -613.21234
Q Predictions Mean           613.4119
Q Predictions Std            404.87003
Q Predictions Max            1213.9735
Q Predictions Min            -4.429108
V Predictions Mean           619.4674
V Predictions Std            406.2687
V Predictions Max            1193.6292
V Predictions Min            -4.4499235
Log Pis Mean                 0.25282156
Log Pis Std                  2.4550974
Log Pis Max                  9.909151
Log Pis Min                  -4.8970695
Policy mu Mean               0.060189266
Policy mu Std                1.0104872
Policy mu Max                2.4632356
Policy mu Min                -2.8978374
Policy log std Mean          -0.5050967
Policy log std Std           0.31053454
Policy log std Max           0.022112176
Policy log std Min           -2.0864747
Z mean eval                  0.005602873
Z variance eval              0.001209155
total_rewards                [ 580.31357605 1153.98010152 1555.71463485  292.72457667 1623.39220122
  961.51826331 1581.05094549  678.19131078 1284.05120109 1379.85793752]
total_rewards_mean           1109.0794748503229
total_rewards_std            441.1550044432718
total_rewards_max            1623.3922012217843
total_rewards_min            292.72457667420116
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               33.301151604857296
(Previous) Eval Time (s)     18.428226646967232
Sample Time (s)              24.991101620718837
Epoch Time (s)               76.72047987254336
Total Train Time (s)         2718.7449759445153
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:48:02.319258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #47 | Epoch Duration: 75.96210145950317
2020-01-11 00:48:02.319607 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006282703
Z variance train             0.0012061064
KL Divergence                14.788509
KL Loss                      1.478851
QF Loss                      5816.2354
VF Loss                      108.34141
Policy Loss                  -584.6928
Q Predictions Mean           586.3573
Q Predictions Std            416.3191
Q Predictions Max            1303.1548
Q Predictions Min            -7.0387964
V Predictions Mean           584.79785
V Predictions Std            412.7734
V Predictions Max            1271.1204
V Predictions Min            -0.3827562
Log Pis Mean                 0.28346968
Log Pis Std                  2.5638516
Log Pis Max                  10.916031
Log Pis Min                  -4.2849827
Policy mu Mean               -0.1604052
Policy mu Std                1.0147368
Policy mu Max                2.7928748
Policy mu Min                -3.716891
Policy log std Mean          -0.47765175
Policy log std Std           0.301177
Policy log std Max           0.17214274
Policy log std Min           -1.7009182
Z mean eval                  0.0055786027
Z variance eval              0.0014024947
total_rewards                [ 735.48810309 1106.69341787  833.66605504  693.41853936  761.60789308
  517.6872695   810.82544254  625.8120457  1118.20507229 1107.31201098]
total_rewards_mean           831.0715849450435
total_rewards_std            202.0864715758059
total_rewards_max            1118.20507228694
total_rewards_min            517.6872694985158
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               32.598390767816454
(Previous) Eval Time (s)     17.669457965996116
Sample Time (s)              24.691927782725543
Epoch Time (s)               74.95977651653811
Total Train Time (s)         2787.7608395460993
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:11.337332 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #48 | Epoch Duration: 69.01746416091919
2020-01-11 00:49:11.337606 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.005394737
Z variance train             0.001402125
KL Divergence                14.333792
KL Loss                      1.4333792
QF Loss                      276.29785
VF Loss                      143.21072
Policy Loss                  -638.7753
Q Predictions Mean           632.7413
Q Predictions Std            432.81982
Q Predictions Max            1325.95
Q Predictions Min            -4.162385
V Predictions Mean           640.4403
V Predictions Std            434.44534
V Predictions Max            1348.7319
V Predictions Min            -5.3792424
Log Pis Mean                 0.47173536
Log Pis Std                  2.642879
Log Pis Max                  8.5369005
Log Pis Min                  -5.814853
Policy mu Mean               -0.096892975
Policy mu Std                1.0832471
Policy mu Max                3.4365265
Policy mu Min                -2.82996
Policy log std Mean          -0.48599792
Policy log std Std           0.31187856
Policy log std Max           0.074042544
Policy log std Min           -1.5003042
Z mean eval                  0.0119470535
Z variance eval              0.001322934
total_rewards                [391.62338484 391.50720967 351.09360195 375.92286555 462.83505004
 557.25628267 430.51835859 395.11148966 454.34522557 660.94599154]
total_rewards_mean           447.11594600803016
total_rewards_std            90.32938580660627
total_rewards_max            660.945991540686
total_rewards_min            351.09360194739065
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               33.18805130710825
(Previous) Eval Time (s)     11.726714645978063
Sample Time (s)              23.2647539624013
Epoch Time (s)               68.17951991548762
Total Train Time (s)         2852.3666979600675
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:15.945462 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #49 | Epoch Duration: 64.60751056671143
2020-01-11 00:50:15.945921 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012904605
Z variance train             0.0013254599
KL Divergence                14.498644
KL Loss                      1.4498644
QF Loss                      545.1288
VF Loss                      196.80708
Policy Loss                  -645.65564
Q Predictions Mean           639.5864
Q Predictions Std            449.34573
Q Predictions Max            1478.3423
Q Predictions Min            -6.9395013
V Predictions Mean           641.95166
V Predictions Std            444.974
V Predictions Max            1465.4551
V Predictions Min            -2.543223
Log Pis Mean                 0.49532342
Log Pis Std                  2.67569
Log Pis Max                  9.79902
Log Pis Min                  -6.5837326
Policy mu Mean               0.030898482
Policy mu Std                1.0957218
Policy mu Max                3.047399
Policy mu Min                -3.4774177
Policy log std Mean          -0.49561754
Policy log std Std           0.29420212
Policy log std Max           0.25143173
Policy log std Min           -1.6433544
Z mean eval                  0.013208436
Z variance eval              0.0012859309
total_rewards                [318.79312377 317.28542801 351.61487082 320.3093022  314.59228275
 300.09209434 321.68331285 350.3133796  272.86412186 324.54883815]
total_rewards_mean           319.2096754342229
total_rewards_std            21.428860498646348
total_rewards_max            351.6148708215449
total_rewards_min            272.8641218575868
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               33.83064079191536
(Previous) Eval Time (s)     8.154267358127981
Sample Time (s)              23.498113424051553
Epoch Time (s)               65.48302157409489
Total Train Time (s)         2914.5417062356137
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:18.121245 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #50 | Epoch Duration: 62.175065994262695
2020-01-11 00:51:18.121450 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0132830115
Z variance train             0.0012857384
KL Divergence                14.4138155
KL Loss                      1.4413816
QF Loss                      1751.9941
VF Loss                      223.28635
Policy Loss                  -648.7714
Q Predictions Mean           640.9083
Q Predictions Std            475.3338
Q Predictions Max            1611.3523
Q Predictions Min            -6.811528
V Predictions Mean           648.7905
V Predictions Std            478.04095
V Predictions Max            1591.861
V Predictions Min            -6.345121
Log Pis Mean                 0.5379626
Log Pis Std                  2.384349
Log Pis Max                  6.3802614
Log Pis Min                  -4.538206
Policy mu Mean               0.16607715
Policy mu Std                1.0668693
Policy mu Max                3.1375542
Policy mu Min                -2.7205148
Policy log std Mean          -0.5249744
Policy log std Std           0.31355926
Policy log std Max           -0.05270475
Policy log std Min           -1.835839
Z mean eval                  0.0060366825
Z variance eval              0.0011030554
total_rewards                [291.20396181 307.61285352 293.39690871 278.47620891 294.53536989
 296.7779132  304.79750308 435.9076425  272.99948262 322.84988784]
total_rewards_mean           309.8557732063801
total_rewards_std            44.10910363476431
total_rewards_max            435.907642502588
total_rewards_min            272.9994826156554
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               34.37928920472041
(Previous) Eval Time (s)     4.84591996204108
Sample Time (s)              19.43523713806644
Epoch Time (s)               58.66044630482793
Total Train Time (s)         2972.8144738203846
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:16.401582 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #51 | Epoch Duration: 58.27991271018982
2020-01-11 00:52:16.402101 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0066265045
Z variance train             0.0011258225
KL Divergence                14.605666
KL Loss                      1.4605666
QF Loss                      1805.7914
VF Loss                      181.16667
Policy Loss                  -661.84216
Q Predictions Mean           665.8543
Q Predictions Std            466.6607
Q Predictions Max            1412.9454
Q Predictions Min            -0.44355023
V Predictions Mean           655.17334
V Predictions Std            460.11954
V Predictions Max            1390.5885
V Predictions Min            -1.3376765
Log Pis Mean                 0.8076565
Log Pis Std                  2.6567628
Log Pis Max                  9.812515
Log Pis Min                  -4.2483068
Policy mu Mean               0.1768055
Policy mu Std                1.0767741
Policy mu Max                2.6586916
Policy mu Min                -3.1082494
Policy log std Mean          -0.56149274
Policy log std Std           0.32043388
Policy log std Max           -0.077040836
Policy log std Min           -1.8337822
Z mean eval                  0.013157794
Z variance eval              0.0010150315
total_rewards                [593.41418518 656.91146394 572.69258633 448.41094714 699.09083144
 585.157675   458.29474793 459.20240334 504.61654547 503.13768855]
total_rewards_mean           548.0929074318894
total_rewards_std            82.75729625424579
total_rewards_max            699.090831436869
total_rewards_min            448.41094714436144
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               32.818832895252854
(Previous) Eval Time (s)     4.465014923829585
Sample Time (s)              18.67249727481976
Epoch Time (s)               55.9563450939022
Total Train Time (s)         3030.2132916981354
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:13.795455 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #52 | Epoch Duration: 57.39301538467407
2020-01-11 00:53:13.795648 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1276865
Z variance train             0.0004786143
KL Divergence                16.791937
KL Loss                      1.6791937
QF Loss                      480.37363
VF Loss                      284.3929
Policy Loss                  -669.827
Q Predictions Mean           659.57074
Q Predictions Std            490.9723
Q Predictions Max            1376.0245
Q Predictions Min            -3.2806551
V Predictions Mean           661.5211
V Predictions Std            485.32953
V Predictions Max            1375.9788
V Predictions Min            -1.1344771
Log Pis Mean                 0.54245156
Log Pis Std                  2.4828062
Log Pis Max                  9.578029
Log Pis Min                  -3.8570852
Policy mu Mean               0.14885168
Policy mu Std                1.0584339
Policy mu Max                2.3618767
Policy mu Min                -3.5092347
Policy log std Mean          -0.5616519
Policy log std Std           0.3214532
Policy log std Max           -0.06280181
Policy log std Min           -2.0784798
Z mean eval                  0.016386785
Z variance eval              0.001259702
total_rewards                [660.61537384 504.00046391 363.70537812 380.49937549 715.50257336
 361.80281444 511.6830289  489.6228843  426.61024931 384.41316166]
total_rewards_mean           479.8455303345562
total_rewards_std            117.95688635365326
total_rewards_max            715.5025733643446
total_rewards_min            361.8028144404594
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               33.18364604283124
(Previous) Eval Time (s)     5.901396485976875
Sample Time (s)              20.50651355087757
Epoch Time (s)               59.59155607968569
Total Train Time (s)         3089.4101512669586
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:54:12.993722 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #53 | Epoch Duration: 59.19793128967285
2020-01-11 00:54:12.993903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07126595
Z variance train             0.0010168867
KL Divergence                15.156977
KL Loss                      1.5156977
QF Loss                      424.6672
VF Loss                      189.93784
Policy Loss                  -654.21216
Q Predictions Mean           650.92487
Q Predictions Std            497.1149
Q Predictions Max            1423.8806
Q Predictions Min            -4.95456
V Predictions Mean           649.88776
V Predictions Std            493.21542
V Predictions Max            1425.8726
V Predictions Min            -2.4624543
Log Pis Mean                 0.24259791
Log Pis Std                  2.4275596
Log Pis Max                  10.665002
Log Pis Min                  -8.202391
Policy mu Mean               0.2519474
Policy mu Std                0.96048546
Policy mu Max                3.038214
Policy mu Min                -3.1175933
Policy log std Mean          -0.5099802
Policy log std Std           0.3269542
Policy log std Max           0.1835213
Policy log std Min           -2.6549017
Z mean eval                  0.1409862
Z variance eval              0.00067488453
total_rewards                [469.5452364  366.24507826 447.61912834 477.74687874 523.64530147
 485.73890238 527.59507793 496.90858629 476.85744636 457.71563558]
total_rewards_mean           472.96172717356575
total_rewards_std            43.131446161648725
total_rewards_max            527.5950779335527
total_rewards_min            366.24507825714556
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               33.47103785723448
(Previous) Eval Time (s)     5.507436879910529
Sample Time (s)              22.52935842005536
Epoch Time (s)               61.507833157200366
Total Train Time (s)         3151.0380693543702
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:14.625540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #54 | Epoch Duration: 61.631460189819336
2020-01-11 00:55:14.625875 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04286558
Z variance train             0.0010204457
KL Divergence                15.035196
KL Loss                      1.5035197
QF Loss                      729.645
VF Loss                      225.7493
Policy Loss                  -705.087
Q Predictions Mean           704.38245
Q Predictions Std            479.7529
Q Predictions Max            1355.7588
Q Predictions Min            -6.881857
V Predictions Mean           713.5945
V Predictions Std            484.17838
V Predictions Max            1369.0981
V Predictions Min            -5.9819636
Log Pis Mean                 0.4419515
Log Pis Std                  2.4332654
Log Pis Max                  7.8446317
Log Pis Min                  -3.5479252
Policy mu Mean               -0.09107516
Policy mu Std                1.0652219
Policy mu Max                2.669562
Policy mu Min                -3.3137586
Policy log std Mean          -0.50889224
Policy log std Std           0.30510864
Policy log std Max           -0.031163603
Policy log std Min           -1.5492303
Z mean eval                  0.020236496
Z variance eval              0.0010760453
total_rewards                [679.50706077 686.78089241 502.20459552 638.20037763 718.58623234
 763.65045206 657.80831914 800.21992654 505.18960184 497.58267756]
total_rewards_mean           644.9730135799939
total_rewards_std            104.11632519647137
total_rewards_max            800.2199265393165
total_rewards_min            497.5826775571885
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.39984830794856
(Previous) Eval Time (s)     5.630359496921301
Sample Time (s)              22.10134366294369
Epoch Time (s)               59.13155146781355
Total Train Time (s)         3211.227071161382
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:14.815670 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #55 | Epoch Duration: 60.1895854473114
2020-01-11 00:56:14.815906 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0148523105
Z variance train             0.0010121533
KL Divergence                14.944286
KL Loss                      1.4944286
QF Loss                      296.6045
VF Loss                      76.971794
Policy Loss                  -672.623
Q Predictions Mean           669.0842
Q Predictions Std            485.0215
Q Predictions Max            1431.5719
Q Predictions Min            -2.583983
V Predictions Mean           672.5532
V Predictions Std            484.68567
V Predictions Max            1418.733
V Predictions Min            -5.2903886
Log Pis Mean                 0.3695451
Log Pis Std                  2.7224383
Log Pis Max                  17.155062
Log Pis Min                  -5.6903095
Policy mu Mean               0.008962276
Policy mu Std                1.07047
Policy mu Max                2.9923506
Policy mu Min                -4.203392
Policy log std Mean          -0.4677404
Policy log std Std           0.28586742
Policy log std Max           -0.00920555
Policy log std Min           -1.6902573
Z mean eval                  0.007909606
Z variance eval              0.0012720788
total_rewards                [435.45105208 780.89294386 421.45290605 723.52902873 723.14544782
 663.34583438 648.50452245 760.9684184  414.75268696 741.10566097]
total_rewards_mean           631.3148501689951
total_rewards_std            140.9962026803928
total_rewards_max            780.8929438566071
total_rewards_min            414.7526869553621
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.16271449998021
(Previous) Eval Time (s)     6.688016295898706
Sample Time (s)              23.17025839071721
Epoch Time (s)               61.020989186596125
Total Train Time (s)         3272.2608599532396
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:15.851649 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #56 | Epoch Duration: 61.03556275367737
2020-01-11 00:57:15.851901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0066080675
Z variance train             0.0012507694
KL Divergence                14.423075
KL Loss                      1.4423075
QF Loss                      438.5935
VF Loss                      189.257
Policy Loss                  -681.401
Q Predictions Mean           676.38605
Q Predictions Std            498.82266
Q Predictions Max            1416.183
Q Predictions Min            -1.9917153
V Predictions Mean           683.68823
V Predictions Std            500.54385
V Predictions Max            1430.9712
V Predictions Min            -3.4151459
Log Pis Mean                 0.54228616
Log Pis Std                  2.86828
Log Pis Max                  9.891985
Log Pis Min                  -5.294687
Policy mu Mean               -0.0076140915
Policy mu Std                1.1154399
Policy mu Max                2.6287086
Policy mu Min                -3.9637392
Policy log std Mean          -0.4764351
Policy log std Std           0.31648323
Policy log std Max           0.16076206
Policy log std Min           -3.1579227
Z mean eval                  0.018042907
Z variance eval              0.00080229586
total_rewards                [614.07984859 442.92788532 732.72423192 686.38969465 648.54174602
 878.21941881 732.61259642 442.6276061  652.57042237 436.13640362]
total_rewards_mean           626.6829853827574
total_rewards_std            139.4841998459565
total_rewards_max            878.2194188118642
total_rewards_min            436.1364036234581
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               31.081735833082348
(Previous) Eval Time (s)     6.702255124691874
Sample Time (s)              22.698567289859056
Epoch Time (s)               60.48255824763328
Total Train Time (s)         3332.210783584509
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:15.801769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #57 | Epoch Duration: 59.949700355529785
2020-01-11 00:58:15.801952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021378515
Z variance train             0.0008604334
KL Divergence                15.326987
KL Loss                      1.5326988
QF Loss                      371.67554
VF Loss                      351.7643
Policy Loss                  -752.0422
Q Predictions Mean           746.744
Q Predictions Std            487.4466
Q Predictions Max            1396.6703
Q Predictions Min            -5.773396
V Predictions Mean           749.3158
V Predictions Std            484.67743
V Predictions Max            1377.5337
V Predictions Min            0.9760708
Log Pis Mean                 0.7722759
Log Pis Std                  2.771618
Log Pis Max                  10.373615
Log Pis Min                  -4.3057055
Policy mu Mean               0.061329428
Policy mu Std                1.0974007
Policy mu Max                2.9691856
Policy mu Min                -2.7985532
Policy log std Mean          -0.51926893
Policy log std Std           0.3171377
Policy log std Max           -0.027607322
Policy log std Min           -2.3021908
Z mean eval                  0.031505097
Z variance eval              0.0011870381
total_rewards                [454.06293839 550.11946803 437.32088559 697.18243685 493.76738756
 724.66251644 539.29537323 383.21431402 731.3943596  667.17533045]
total_rewards_mean           567.8195010166162
total_rewards_std            121.91101985977967
total_rewards_max            731.3943596009668
total_rewards_min            383.21431402390726
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               31.481764622032642
(Previous) Eval Time (s)     6.169091887772083
Sample Time (s)              22.631619510706514
Epoch Time (s)               60.28247602051124
Total Train Time (s)         3392.015953788534
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:15.608961 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #58 | Epoch Duration: 59.806862592697144
2020-01-11 00:59:15.609139 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06421672
Z variance train             0.0007530224
KL Divergence                15.942972
KL Loss                      1.5942973
QF Loss                      377.9356
VF Loss                      258.76105
Policy Loss                  -751.81824
Q Predictions Mean           747.7313
Q Predictions Std            501.3705
Q Predictions Max            1453.651
Q Predictions Min            -15.332188
V Predictions Mean           760.06335
V Predictions Std            506.0627
V Predictions Max            1437.9054
V Predictions Min            -15.200192
Log Pis Mean                 0.8086957
Log Pis Std                  2.6529286
Log Pis Max                  8.904385
Log Pis Min                  -5.7753634
Policy mu Mean               0.26067734
Policy mu Std                1.0740137
Policy mu Max                3.0164099
Policy mu Min                -3.6079044
Policy log std Mean          -0.5255332
Policy log std Std           0.29860818
Policy log std Max           -0.06463641
Policy log std Min           -1.9814183
Z mean eval                  0.027769078
Z variance eval              0.0016517384
total_rewards                [ 950.33452046  937.94732959  566.39188211  851.83828331  810.56763261
  778.16128706  767.92416703  914.10800196 1061.1149288   466.36504466]
total_rewards_mean           810.4753077596588
total_rewards_std            170.85782460888973
total_rewards_max            1061.11492879951
total_rewards_min            466.3650446617518
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               31.36582115571946
(Previous) Eval Time (s)     5.693167405202985
Sample Time (s)              20.76628078846261
Epoch Time (s)               57.82526934938505
Total Train Time (s)         3451.526709727943
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:15.120487 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #59 | Epoch Duration: 59.511213541030884
2020-01-11 01:00:15.120656 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02212281
Z variance train             0.0015556604
KL Divergence                13.894184
KL Loss                      1.3894185
QF Loss                      611.13806
VF Loss                      180.83426
Policy Loss                  -674.2611
Q Predictions Mean           670.40845
Q Predictions Std            504.92108
Q Predictions Max            1404.4917
Q Predictions Min            -1.3641644
V Predictions Mean           680.6055
V Predictions Std            510.5884
V Predictions Max            1401.9547
V Predictions Min            -3.9198847
Log Pis Mean                 0.14569211
Log Pis Std                  2.4161055
Log Pis Max                  7.5019436
Log Pis Min                  -5.56964
Policy mu Mean               0.062931456
Policy mu Std                0.9681023
Policy mu Max                2.5022619
Policy mu Min                -2.8600776
Policy log std Mean          -0.5280597
Policy log std Std           0.31950954
Policy log std Max           -0.06287205
Policy log std Min           -2.3251002
Z mean eval                  0.08285327
Z variance eval              0.0010647115
total_rewards                [1253.52426335  657.63538207  797.25881463  985.80231653 1004.10038672
  878.95558252  749.40003321  661.26637561  709.22896587  654.93975252]
total_rewards_mean           835.2111873021637
total_rewards_std            186.29650098120783
total_rewards_max            1253.5242633484118
total_rewards_min            654.9397525236384
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               31.231100158765912
(Previous) Eval Time (s)     7.378777622710913
Sample Time (s)              23.24499191250652
Epoch Time (s)               61.854869693983346
Total Train Time (s)         3514.4721240792423
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:01:18.067844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #60 | Epoch Duration: 62.94703555107117
2020-01-11 01:01:18.068029 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011694898
Z variance train             0.0016812154
KL Divergence                13.712099
KL Loss                      1.37121
QF Loss                      667.14197
VF Loss                      375.0576
Policy Loss                  -790.885
Q Predictions Mean           790.5891
Q Predictions Std            486.84058
Q Predictions Max            1414.5477
Q Predictions Min            -9.064528
V Predictions Mean           792.8632
V Predictions Std            484.60083
V Predictions Max            1412.042
V Predictions Min            -5.126882
Log Pis Mean                 0.36773175
Log Pis Std                  2.57514
Log Pis Max                  10.198542
Log Pis Min                  -5.0026627
Policy mu Mean               0.09008274
Policy mu Std                1.0207013
Policy mu Max                2.7796292
Policy mu Min                -3.0476563
Policy log std Mean          -0.5610225
Policy log std Std           0.30612394
Policy log std Max           -0.057932943
Policy log std Min           -1.6662318
Z mean eval                  0.020314928
Z variance eval              0.0018041827
total_rewards                [646.84803829 582.06909012 571.71685189 591.58602469 486.65407805
 473.7212713  423.66624893 557.87696721 762.91155784 483.24134119]
total_rewards_mean           558.029146951453
total_rewards_std            93.59795921966152
total_rewards_max            762.9115578445447
total_rewards_min            423.66624893004507
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               31.493689644150436
(Previous) Eval Time (s)     8.470638540107757
Sample Time (s)              21.462174843531102
Epoch Time (s)               61.426503027789295
Total Train Time (s)         3572.9928049426526
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:16.590538 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #61 | Epoch Duration: 58.52234888076782
2020-01-11 01:02:16.590755 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022499418
Z variance train             0.0017833102
KL Divergence                13.641309
KL Loss                      1.3641309
QF Loss                      352.55225
VF Loss                      127.82372
Policy Loss                  -730.04865
Q Predictions Mean           729.4281
Q Predictions Std            519.75323
Q Predictions Max            1384.0275
Q Predictions Min            0.46840376
V Predictions Mean           731.3386
V Predictions Std            520.4699
V Predictions Max            1376.179
V Predictions Min            -5.4875693
Log Pis Mean                 0.25048006
Log Pis Std                  2.4994845
Log Pis Max                  7.157368
Log Pis Min                  -5.2465096
Policy mu Mean               -0.06617579
Policy mu Std                0.9900397
Policy mu Max                2.5575252
Policy mu Min                -2.9018793
Policy log std Mean          -0.4839824
Policy log std Std           0.2986476
Policy log std Max           0.025300324
Policy log std Min           -1.7874955
Z mean eval                  0.00857982
Z variance eval              0.0029986857
total_rewards                [524.72998563 923.82513717 654.05987368 605.07779474 656.80721144
 398.44049016 439.84735365 425.11363116 616.0441963  917.12671146]
total_rewards_mean           616.1072385392551
total_rewards_std            176.57754441263793
total_rewards_max            923.825137169239
total_rewards_min            398.4404901562977
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               30.941952290013433
(Previous) Eval Time (s)     5.566187494900078
Sample Time (s)              21.24373529618606
Epoch Time (s)               57.75187508109957
Total Train Time (s)         3632.025810590945
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:15.624583 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #62 | Epoch Duration: 59.03367853164673
2020-01-11 01:03:15.624755 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #62 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009281611
Z variance train             0.003185695
KL Divergence                12.027058
KL Loss                      1.2027057
QF Loss                      286.81186
VF Loss                      487.53668
Policy Loss                  -788.0916
Q Predictions Mean           784.1164
Q Predictions Std            477.4464
Q Predictions Max            1362.6965
Q Predictions Min            -3.4443202
V Predictions Mean           789.6776
V Predictions Std            476.95728
V Predictions Max            1358.4011
V Predictions Min            0.6655785
Log Pis Mean                 0.49855292
Log Pis Std                  2.5079625
Log Pis Max                  9.58994
Log Pis Min                  -5.724534
Policy mu Mean               -0.057365905
Policy mu Std                1.047396
Policy mu Max                3.025392
Policy mu Min                -2.7296438
Policy log std Mean          -0.527575
Policy log std Std           0.27934143
Policy log std Max           -0.087637976
Policy log std Min           -1.5525432
Z mean eval                  0.010754364
Z variance eval              0.00244996
total_rewards                [1208.84973794 1077.02060377  758.31297947 1036.50992113 1054.520992
 1066.96576639  805.15209483  704.21553164 1095.87406445 1011.35599826]
total_rewards_mean           981.8777689875387
total_rewards_std            157.5575226207541
total_rewards_max            1208.8497379402334
total_rewards_min            704.2155316383561
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               32.018822450656444
(Previous) Eval Time (s)     6.847640388645232
Sample Time (s)              21.68060906464234
Epoch Time (s)               60.547071903944016
Total Train Time (s)         3695.564263682347
Epoch                        63
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:19.164567 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #63 | Epoch Duration: 63.539676666259766
2020-01-11 01:04:19.164731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010669112
Z variance train             0.0026476898
KL Divergence                12.502518
KL Loss                      1.2502518
QF Loss                      363.98004
VF Loss                      166.1805
Policy Loss                  -758.2341
Q Predictions Mean           753.5973
Q Predictions Std            511.67157
Q Predictions Max            1466.68
Q Predictions Min            -11.006378
V Predictions Mean           752.56946
V Predictions Std            508.83813
V Predictions Max            1438.9419
V Predictions Min            -7.612322
Log Pis Mean                 0.27790082
Log Pis Std                  2.4819834
Log Pis Max                  7.969019
Log Pis Min                  -6.4028616
Policy mu Mean               0.039999295
Policy mu Std                1.030988
Policy mu Max                2.8776696
Policy mu Min                -3.8426816
Policy log std Mean          -0.4937675
Policy log std Std           0.2888306
Policy log std Max           0.12938601
Policy log std Min           -1.6174095
Z mean eval                  0.01274925
Z variance eval              0.0019846843
total_rewards                [992.8245172  772.90290406 892.82891711 558.29115089 691.33156065
 688.40055808 736.94088572 751.42697053 771.41505879 758.51704959]
total_rewards_mean           761.4879572638173
total_rewards_std            111.02303299139808
total_rewards_max            992.8245172041177
total_rewards_min            558.2911508944269
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               31.109445872250944
(Previous) Eval Time (s)     9.83993616187945
Sample Time (s)              22.42264032550156
Epoch Time (s)               63.372022359631956
Total Train Time (s)         3756.5216640122235
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:20.123221 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #64 | Epoch Duration: 60.95832538604736
2020-01-11 01:05:20.123395 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019101772
Z variance train             0.0022646855
KL Divergence                12.866789
KL Loss                      1.2866789
QF Loss                      250.11778
VF Loss                      101.89681
Policy Loss                  -760.42346
Q Predictions Mean           757.59045
Q Predictions Std            502.99884
Q Predictions Max            1450.7306
Q Predictions Min            -8.148287
V Predictions Mean           763.76074
V Predictions Std            506.50778
V Predictions Max            1428.1176
V Predictions Min            -7.7807918
Log Pis Mean                 0.310915
Log Pis Std                  2.3448212
Log Pis Max                  10.8513155
Log Pis Min                  -4.331533
Policy mu Mean               -0.012735858
Policy mu Std                0.96478987
Policy mu Max                2.9788294
Policy mu Min                -3.595997
Policy log std Mean          -0.479926
Policy log std Std           0.26606455
Policy log std Max           -0.024235398
Policy log std Min           -1.892073
Z mean eval                  0.020636056
Z variance eval              0.0018704139
total_rewards                [ 777.70641028  713.96285828 1069.11247475 1097.68360266  748.74200421
  718.39529188  678.19071053  921.80396077  739.68207681  487.65943944]
total_rewards_mean           795.2938829606852
total_rewards_std            175.74705285932288
total_rewards_max            1097.6836026571455
total_rewards_min            487.6594394358865
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               31.650733227841556
(Previous) Eval Time (s)     7.42591840820387
Sample Time (s)              23.518520957324654
Epoch Time (s)               62.59517259337008
Total Train Time (s)         3819.907425425481
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:06:23.510684 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #65 | Epoch Duration: 63.387146949768066
2020-01-11 01:06:23.510871 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008304285
Z variance train             0.0023049046
KL Divergence                12.840621
KL Loss                      1.2840621
QF Loss                      1668.5383
VF Loss                      189.12218
Policy Loss                  -778.6342
Q Predictions Mean           769.49426
Q Predictions Std            499.07126
Q Predictions Max            1449.6244
Q Predictions Min            -3.9259238
V Predictions Mean           774.60034
V Predictions Std            499.83353
V Predictions Max            1430.0084
V Predictions Min            -4.380612
Log Pis Mean                 0.078560546
Log Pis Std                  2.222578
Log Pis Max                  9.384537
Log Pis Min                  -4.359651
Policy mu Mean               0.07032568
Policy mu Std                0.9349534
Policy mu Max                3.3084471
Policy mu Min                -2.8348837
Policy log std Mean          -0.49113455
Policy log std Std           0.29109958
Policy log std Max           0.08830714
Policy log std Min           -2.0632534
Z mean eval                  0.05337767
Z variance eval              0.0012164356
total_rewards                [ 332.78996513  325.96166233  889.31844551  316.83509071  307.10505611
  315.3350863  1053.83780734  950.03916935  315.41625041 1157.85534987]
total_rewards_mean           596.4493883066306
total_rewards_std            346.0878374320564
total_rewards_max            1157.8553498671708
total_rewards_min            307.1050561136909
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               31.384595174808055
(Previous) Eval Time (s)     8.217567430343479
Sample Time (s)              22.61632253602147
Epoch Time (s)               62.218485141173005
Total Train Time (s)         3880.4420325411484
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:24.051558 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #66 | Epoch Duration: 60.540539503097534
2020-01-11 01:07:24.051933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09451671
Z variance train             0.0009227355
KL Divergence                15.299358
KL Loss                      1.5299358
QF Loss                      450.07898
VF Loss                      282.70825
Policy Loss                  -834.71686
Q Predictions Mean           837.6764
Q Predictions Std            506.93265
Q Predictions Max            1430.3066
Q Predictions Min            -5.239202
V Predictions Mean           828.2705
V Predictions Std            500.94745
V Predictions Max            1440.1556
V Predictions Min            -2.5690415
Log Pis Mean                 -0.0047813617
Log Pis Std                  2.2098413
Log Pis Max                  6.495639
Log Pis Min                  -5.3794928
Policy mu Mean               -0.11629158
Policy mu Std                0.97232085
Policy mu Max                2.4990995
Policy mu Min                -2.7223532
Policy log std Mean          -0.48173702
Policy log std Std           0.27164614
Policy log std Max           0.042959124
Policy log std Min           -1.7332486
Z mean eval                  0.032155506
Z variance eval              0.0011887092
total_rewards                [336.7611165  323.22406675 299.46565988 312.83438002 300.96855401
 310.04944526 298.56757561 315.54996935 294.38349538 306.90902807]
total_rewards_mean           309.8713290842909
total_rewards_std            12.273447111915644
total_rewards_max            336.76111649820587
total_rewards_min            294.3834953839776
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               31.62238711118698
(Previous) Eval Time (s)     6.539289727807045
Sample Time (s)              19.86421667272225
Epoch Time (s)               58.025893511716276
Total Train Time (s)         3936.040702425409
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:19.648234 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #67 | Epoch Duration: 55.59601187705994
2020-01-11 01:08:19.648671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033181917
Z variance train             0.0019084985
KL Divergence                13.606923
KL Loss                      1.3606924
QF Loss                      333.5932
VF Loss                      133.26894
Policy Loss                  -746.77234
Q Predictions Mean           743.4722
Q Predictions Std            498.7202
Q Predictions Max            1381.7119
Q Predictions Min            3.0030072
V Predictions Mean           742.3531
V Predictions Std            497.09445
V Predictions Max            1379.6682
V Predictions Min            -6.990604
Log Pis Mean                 0.11849083
Log Pis Std                  2.3379273
Log Pis Max                  7.693313
Log Pis Min                  -6.9380302
Policy mu Mean               -0.019548817
Policy mu Std                0.9742273
Policy mu Max                2.3056097
Policy mu Min                -2.7071874
Policy log std Mean          -0.47153234
Policy log std Std           0.25299624
Policy log std Max           0.053500324
Policy log std Min           -1.5719966
Z mean eval                  0.016407618
Z variance eval              0.0020756007
total_rewards                [ 835.31426873  685.62396687  720.83101398  973.65559143  678.55862964
 1009.52480531  906.39827424 1089.70839244  618.64950353 1077.65711605]
total_rewards_mean           859.5921562230939
total_rewards_std            167.06956306599363
total_rewards_max            1089.708392438297
total_rewards_min            618.6495035320695
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               30.596093985717744
(Previous) Eval Time (s)     4.109112571924925
Sample Time (s)              18.658722328953445
Epoch Time (s)               53.36392888659611
Total Train Time (s)         3993.9751551947556
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:17.583616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #68 | Epoch Duration: 57.9346239566803
2020-01-11 01:09:17.583806 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009480854
Z variance train             0.0019010201
KL Divergence                13.596428
KL Loss                      1.3596429
QF Loss                      1269.157
VF Loss                      259.6372
Policy Loss                  -782.6272
Q Predictions Mean           774.44775
Q Predictions Std            492.31015
Q Predictions Max            1369.9094
Q Predictions Min            -8.863169
V Predictions Mean           773.5824
V Predictions Std            490.9816
V Predictions Max            1374.0774
V Predictions Min            1.1250168
Log Pis Mean                 0.20037505
Log Pis Std                  2.3623977
Log Pis Max                  7.902253
Log Pis Min                  -6.0504065
Policy mu Mean               0.055386472
Policy mu Std                0.9921385
Policy mu Max                2.8480666
Policy mu Min                -2.7020178
Policy log std Mean          -0.5201041
Policy log std Std           0.28352213
Policy log std Max           -0.06965852
Policy log std Min           -2.7261484
Z mean eval                  0.038042754
Z variance eval              0.001704944
total_rewards                [ 870.86404267 1074.4619616  1115.42980378 1113.13379595 1088.97133589
  942.93872364 1087.03207096 1366.50599289  906.27195768 1100.59911486]
total_rewards_mean           1066.62087999194
total_rewards_std            132.64192322944976
total_rewards_max            1366.5059928944386
total_rewards_min            870.8640426702385
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               31.494613281916827
(Previous) Eval Time (s)     8.679420141037554
Sample Time (s)              22.53777665225789
Epoch Time (s)               62.71181007521227
Total Train Time (s)         4058.2756252372637
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:21.885923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #69 | Epoch Duration: 64.30197429656982
2020-01-11 01:10:21.886119 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026807666
Z variance train             0.002058089
KL Divergence                13.506817
KL Loss                      1.3506817
QF Loss                      671.3554
VF Loss                      208.5358
Policy Loss                  -733.62415
Q Predictions Mean           735.1608
Q Predictions Std            507.56186
Q Predictions Max            1390.2574
Q Predictions Min            0.3635904
V Predictions Mean           743.4796
V Predictions Std            510.48053
V Predictions Max            1392.8088
V Predictions Min            -2.27598
Log Pis Mean                 0.22617735
Log Pis Std                  2.4122834
Log Pis Max                  9.007364
Log Pis Min                  -4.6253033
Policy mu Mean               0.12278219
Policy mu Std                0.9789453
Policy mu Max                2.83339
Policy mu Min                -2.7591357
Policy log std Mean          -0.49733317
Policy log std Std           0.2813553
Policy log std Max           -0.033547938
Policy log std Min           -2.5759645
Z mean eval                  0.022122907
Z variance eval              0.0015506411
total_rewards                [1025.1958049   844.98160586 1121.6243285  1316.68945962 1015.18870462
 1181.00333802 1027.0136124  1033.63097383 1083.67894685 1040.92105137]
total_rewards_mean           1068.9927825973834
total_rewards_std            116.48199993560426
total_rewards_max            1316.6894596231532
total_rewards_min            844.9816058589533
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               31.32272315490991
(Previous) Eval Time (s)     10.269289507996291
Sample Time (s)              21.876023137476295
Epoch Time (s)               63.468035800382495
Total Train Time (s)         4121.771725390572
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:11:25.383495 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #70 | Epoch Duration: 63.49723482131958
2020-01-11 01:11:25.383671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018825267
Z variance train             0.0023146826
KL Divergence                13.158678
KL Loss                      1.3158678
QF Loss                      602.7284
VF Loss                      297.56937
Policy Loss                  -789.33636
Q Predictions Mean           788.301
Q Predictions Std            509.19888
Q Predictions Max            1567.1266
Q Predictions Min            -10.405205
V Predictions Mean           801.8342
V Predictions Std            511.721
V Predictions Max            1611.5106
V Predictions Min            -1.0062444
Log Pis Mean                 0.2781535
Log Pis Std                  2.6064217
Log Pis Max                  11.967303
Log Pis Min                  -7.763087
Policy mu Mean               0.029620431
Policy mu Std                1.050583
Policy mu Max                3.5161495
Policy mu Min                -2.986843
Policy log std Mean          -0.49513957
Policy log std Std           0.26761314
Policy log std Max           0.13411108
Policy log std Min           -1.6262171
Z mean eval                  0.020689083
Z variance eval              0.0015698613
total_rewards                [ 954.51614012  994.98313063  981.85330259 1175.97478139 1163.82245797
 1582.65648286  915.3223554  1713.79500499 1110.91960985 1189.43751258]
total_rewards_mean           1178.3280778384585
total_rewards_std            254.27761635000033
total_rewards_max            1713.795004990802
total_rewards_min            915.3223554045527
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.43752789637074
(Previous) Eval Time (s)     10.298181657679379
Sample Time (s)              22.26599535997957
Epoch Time (s)               64.00170491402969
Total Train Time (s)         4186.476533967536
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:30.089801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #71 | Epoch Duration: 64.70599460601807
2020-01-11 01:12:30.089974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016782245
Z variance train             0.0018791826
KL Divergence                13.652192
KL Loss                      1.3652192
QF Loss                      547.53046
VF Loss                      321.82132
Policy Loss                  -749.09937
Q Predictions Mean           751.20667
Q Predictions Std            519.6049
Q Predictions Max            1499.6562
Q Predictions Min            -3.2553952
V Predictions Mean           749.78015
V Predictions Std            519.8207
V Predictions Max            1499.1902
V Predictions Min            -9.32043
Log Pis Mean                 0.31850487
Log Pis Std                  2.4776187
Log Pis Max                  10.806456
Log Pis Min                  -3.954931
Policy mu Mean               0.042050827
Policy mu Std                1.0113819
Policy mu Max                3.566072
Policy mu Min                -2.8920844
Policy log std Mean          -0.48962042
Policy log std Std           0.27842608
Policy log std Max           0.094392955
Policy log std Min           -1.9028971
Z mean eval                  0.009741169
Z variance eval              0.0019277697
total_rewards                [1143.16103992 1135.94723439 1176.88002977 1322.47960539 1107.45943054
 1114.83318705 1199.58228322 1078.01368911 1101.1731     1215.01935892]
total_rewards_mean           1159.4548958299206
total_rewards_std            68.64435233099096
total_rewards_max            1322.4796053949622
total_rewards_min            1078.013689106309
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               31.443903686013073
(Previous) Eval Time (s)     11.002163383178413
Sample Time (s)              21.776600126177073
Epoch Time (s)               64.22266719536856
Total Train Time (s)         4250.634960200172
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:34.248948 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #72 | Epoch Duration: 64.15883302688599
2020-01-11 01:13:34.249085 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017724615
Z variance train             0.0021817626
KL Divergence                13.321863
KL Loss                      1.3321863
QF Loss                      315.03937
VF Loss                      137.10445
Policy Loss                  -781.28973
Q Predictions Mean           776.95184
Q Predictions Std            498.29303
Q Predictions Max            1508.915
Q Predictions Min            -6.5622296
V Predictions Mean           788.8929
V Predictions Std            502.64703
V Predictions Max            1517.3031
V Predictions Min            -2.8486407
Log Pis Mean                 0.24624509
Log Pis Std                  2.3653996
Log Pis Max                  12.623093
Log Pis Min                  -3.4361799
Policy mu Mean               0.06330961
Policy mu Std                0.9905411
Policy mu Max                2.8542328
Policy mu Min                -2.8379235
Policy log std Mean          -0.49610648
Policy log std Std           0.27862906
Policy log std Max           0.05723363
Policy log std Min           -2.8141112
Z mean eval                  0.0070994594
Z variance eval              0.002298297
total_rewards                [1086.11152474 1230.84942282 1191.06665384 1442.17662256 1496.0513037
 1445.96329483 1624.07609379 1403.6878408  1433.84442554 1327.15916216]
total_rewards_mean           1368.0986344793018
total_rewards_std            151.79141552074066
total_rewards_max            1624.076093788728
total_rewards_min            1086.1115247402247
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               31.423165574204177
(Previous) Eval Time (s)     10.938011326361448
Sample Time (s)              22.271591797936708
Epoch Time (s)               64.63276869850233
Total Train Time (s)         4316.501613960136
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:14:40.118305 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #73 | Epoch Duration: 65.86909294128418
2020-01-11 01:14:40.118512 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010154422
Z variance train             0.0021545368
KL Divergence                13.286583
KL Loss                      1.3286583
QF Loss                      442.48236
VF Loss                      439.04172
Policy Loss                  -777.6672
Q Predictions Mean           774.0048
Q Predictions Std            489.29858
Q Predictions Max            1525.3619
Q Predictions Min            -13.225188
V Predictions Mean           793.05725
V Predictions Std            495.62228
V Predictions Max            1544.5486
V Predictions Min            -4.2592397
Log Pis Mean                 0.3263125
Log Pis Std                  2.6179802
Log Pis Max                  8.621355
Log Pis Min                  -5.836443
Policy mu Mean               -0.070278786
Policy mu Std                1.0595624
Policy mu Max                3.025901
Policy mu Min                -2.766285
Policy log std Mean          -0.47898176
Policy log std Std           0.24719015
Policy log std Max           0.004855603
Policy log std Min           -1.531194
Z mean eval                  0.013097537
Z variance eval              0.0024721618
total_rewards                [1185.04394977 1109.15559606 1204.51784339  881.07814025  940.39908986
 1192.38429864 1193.24773267 1368.7360765  1214.79140257 1683.40033411]
total_rewards_mean           1197.2754463835363
total_rewards_std            209.76092998102257
total_rewards_max            1683.400334109613
total_rewards_min            881.0781402474882
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               31.79815114568919
(Previous) Eval Time (s)     12.174002449028194
Sample Time (s)              23.065914426464587
Epoch Time (s)               67.03806802118197
Total Train Time (s)         4382.365161696915
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:45.984712 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #74 | Epoch Duration: 65.86604619026184
2020-01-11 01:15:45.984943 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025134081
Z variance train             0.0014033881
KL Divergence                14.543957
KL Loss                      1.4543957
QF Loss                      842.2291
VF Loss                      179.6433
Policy Loss                  -793.29065
Q Predictions Mean           792.1283
Q Predictions Std            490.90103
Q Predictions Max            1536.8287
Q Predictions Min            -17.458288
V Predictions Mean           798.9232
V Predictions Std            493.92297
V Predictions Max            1564.4417
V Predictions Min            -7.4096413
Log Pis Mean                 0.29471433
Log Pis Std                  2.384367
Log Pis Max                  9.831301
Log Pis Min                  -5.602939
Policy mu Mean               -0.025374943
Policy mu Std                1.0031145
Policy mu Max                2.5997133
Policy mu Min                -4.062233
Policy log std Mean          -0.5163262
Policy log std Std           0.2757732
Policy log std Max           0.06623718
Policy log std Min           -1.5370729
Z mean eval                  0.03444399
Z variance eval              0.0015825762
total_rewards                [1012.64385768 1415.57237598 1161.23549578 1167.33817787 1095.65423969
 1522.8998677  1127.38255776 1320.56011829 1066.208815   1080.94758705]
total_rewards_mean           1197.0443092790865
total_rewards_std            158.45814879399816
total_rewards_max            1522.8998676985134
total_rewards_min            1012.6438576783357
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               31.36084604077041
(Previous) Eval Time (s)     11.00166973983869
Sample Time (s)              22.32602625573054
Epoch Time (s)               64.68854203633964
Total Train Time (s)         4447.253034575842
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:16:50.874010 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #75 | Epoch Duration: 64.88891077041626
2020-01-11 01:16:50.874191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030768896
Z variance train             0.002287762
KL Divergence                12.981104
KL Loss                      1.2981104
QF Loss                      348.99365
VF Loss                      221.52884
Policy Loss                  -808.2331
Q Predictions Mean           802.07556
Q Predictions Std            531.8084
Q Predictions Max            1535.1605
Q Predictions Min            -4.507143
V Predictions Mean           801.2579
V Predictions Std            529.42444
V Predictions Max            1527.7922
V Predictions Min            -16.434614
Log Pis Mean                 -0.18129408
Log Pis Std                  2.1925
Log Pis Max                  8.272032
Log Pis Min                  -5.533373
Policy mu Mean               0.12888506
Policy mu Std                0.91122484
Policy mu Max                2.4103394
Policy mu Min                -2.9503508
Policy log std Mean          -0.50271213
Policy log std Std           0.2831264
Policy log std Max           0.07771206
Policy log std Min           -1.5894712
Z mean eval                  0.02731445
Z variance eval              0.0011684456
total_rewards                [1176.1795622  1367.79950953 2167.74057867 1698.22062401 1318.61467503
 1099.67702101 1146.98463153 1287.57037688 1412.18601751 1439.12498526]
total_rewards_mean           1411.4097981649825
total_rewards_std            300.55709688838954
total_rewards_max            2167.740578672304
total_rewards_min            1099.6770210120926
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               31.409025099128485
(Previous) Eval Time (s)     11.20170378498733
Sample Time (s)              22.34369611321017
Epoch Time (s)               64.95442499732599
Total Train Time (s)         4513.993155005388
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:57.615975 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #76 | Epoch Duration: 66.7416443824768
2020-01-11 01:17:57.616167 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012428267
Z variance train             0.0017563545
KL Divergence                13.62034
KL Loss                      1.3620341
QF Loss                      199.15878
VF Loss                      129.92934
Policy Loss                  -885.9191
Q Predictions Mean           885.167
Q Predictions Std            471.16086
Q Predictions Max            1531.6536
Q Predictions Min            -19.336206
V Predictions Mean           887.928
V Predictions Std            472.771
V Predictions Max            1533.244
V Predictions Min            -2.8604336
Log Pis Mean                 0.32702368
Log Pis Std                  2.2099469
Log Pis Max                  7.4440784
Log Pis Min                  -5.6652594
Policy mu Mean               -0.07728443
Policy mu Std                1.0317098
Policy mu Max                3.379962
Policy mu Min                -2.9532652
Policy log std Mean          -0.5102547
Policy log std Std           0.26179108
Policy log std Max           0.08963713
Policy log std Min           -1.7031031
Z mean eval                  0.014059802
Z variance eval              0.001897957
total_rewards                [1376.72976453 1180.38568559 1202.48803629 1210.05823747 1178.55897849
 1116.03230701 1099.51470025 1770.60548198 1347.93756421 1084.26692183]
total_rewards_mean           1256.657767765814
total_rewards_std            194.4485365523653
total_rewards_max            1770.6054819781514
total_rewards_min            1084.2669218319627
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.51836326625198
(Previous) Eval Time (s)     12.988589238375425
Sample Time (s)              23.443101861979812
Epoch Time (s)               67.95005436660722
Total Train Time (s)         4581.0362294930965
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:04.660641 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #77 | Epoch Duration: 67.04433107376099
2020-01-11 01:19:04.660837 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010168153
Z variance train             0.0015404861
KL Divergence                13.809985
KL Loss                      1.3809985
QF Loss                      247.0293
VF Loss                      135.7162
Policy Loss                  -851.93506
Q Predictions Mean           849.7954
Q Predictions Std            483.80548
Q Predictions Max            1511.6836
Q Predictions Min            -1.9839754
V Predictions Mean           851.7127
V Predictions Std            483.49988
V Predictions Max            1497.5851
V Predictions Min            -3.4640884
Log Pis Mean                 0.13308555
Log Pis Std                  2.2332082
Log Pis Max                  11.355452
Log Pis Min                  -4.446882
Policy mu Mean               0.13686442
Policy mu Std                1.0033568
Policy mu Max                2.6455035
Policy mu Min                -2.706985
Policy log std Mean          -0.51334494
Policy log std Std           0.2694237
Policy log std Max           0.059546232
Policy log std Min           -1.5577946
Z mean eval                  0.019035283
Z variance eval              0.0018632918
total_rewards                [1205.16877778 1479.86741528 2057.8084619  1830.39277451 2622.97527767
 1752.42837965  921.61316615 2107.43991795 1762.83910463 2553.191423  ]
total_rewards_mean           1829.3724698531958
total_rewards_std            512.7750881463405
total_rewards_max            2622.975277672923
total_rewards_min            921.6131661477202
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               32.090118386782706
(Previous) Eval Time (s)     12.082529908046126
Sample Time (s)              22.08201861847192
Epoch Time (s)               66.25466691330075
Total Train Time (s)         4652.488008960616
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:16.119440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #78 | Epoch Duration: 71.45846033096313
2020-01-11 01:20:16.119808 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016813055
Z variance train             0.0016547047
KL Divergence                13.547575
KL Loss                      1.3547575
QF Loss                      304.68292
VF Loss                      286.4366
Policy Loss                  -871.6414
Q Predictions Mean           870.8637
Q Predictions Std            490.00912
Q Predictions Max            1528.9888
Q Predictions Min            0.4923563
V Predictions Mean           877.271
V Predictions Std            491.353
V Predictions Max            1514.511
V Predictions Min            -2.5182214
Log Pis Mean                 0.12022966
Log Pis Std                  2.176725
Log Pis Max                  9.239218
Log Pis Min                  -7.0981417
Policy mu Mean               0.055216506
Policy mu Std                0.93479276
Policy mu Max                2.9123473
Policy mu Min                -2.9619231
Policy log std Mean          -0.51823336
Policy log std Std           0.3176981
Policy log std Max           0.04851547
Policy log std Min           -2.6613398
Z mean eval                  0.009747882
Z variance eval              0.0021744755
total_rewards                [ 883.3194256   788.2411783  1123.33388971 2204.54285886 1058.90456964
 1413.18448979 1174.36227532 2036.05964484  891.96108344 1106.94892401]
total_rewards_mean           1268.0858339510173
total_rewards_std            459.0222434718531
total_rewards_max            2204.5428588582695
total_rewards_min            788.2411782978362
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               30.953146771062165
(Previous) Eval Time (s)     17.28601965121925
Sample Time (s)              22.617318596225232
Epoch Time (s)               70.85648501850665
Total Train Time (s)         4718.078984173946
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:21.706517 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #79 | Epoch Duration: 65.58640885353088
2020-01-11 01:21:21.706701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #79 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007033372
Z variance train             0.0016472448
KL Divergence                13.555009
KL Loss                      1.3555009
QF Loss                      261.27197
VF Loss                      123.97095
Policy Loss                  -813.284
Q Predictions Mean           814.5185
Q Predictions Std            498.36646
Q Predictions Max            1492.6022
Q Predictions Min            -10.312973
V Predictions Mean           820.68774
V Predictions Std            499.3599
V Predictions Max            1499.1785
V Predictions Min            -3.2310882
Log Pis Mean                 -0.120335594
Log Pis Std                  2.144758
Log Pis Max                  7.3237233
Log Pis Min                  -5.731972
Policy mu Mean               -0.011150241
Policy mu Std                0.9548342
Policy mu Max                2.2241046
Policy mu Min                -2.734702
Policy log std Mean          -0.51597756
Policy log std Std           0.27359483
Policy log std Max           0.012973756
Policy log std Min           -2.0290756
Z mean eval                  0.007490759
Z variance eval              0.0019618578
total_rewards                [845.90730474 868.72697972 830.11064717 863.74734496 819.66326106
 836.31846541 822.88755176 824.01078193 832.62395766 818.43072392]
total_rewards_mean           836.2427018332615
total_rewards_std            16.958672435824877
total_rewards_max            868.7269797194188
total_rewards_min            818.430723918431
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.403785394970328
(Previous) Eval Time (s)     12.015607735142112
Sample Time (s)              22.313319814857095
Epoch Time (s)               65.73271294496953
Total Train Time (s)         4779.433374679182
Epoch                        80
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:22:23.062642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #80 | Epoch Duration: 61.355796813964844
2020-01-11 01:22:23.062819 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013426033
Z variance train             0.0017697432
KL Divergence                13.405304
KL Loss                      1.3405304
QF Loss                      447.90417
VF Loss                      76.44153
Policy Loss                  -899.9414
Q Predictions Mean           894.1543
Q Predictions Std            478.78873
Q Predictions Max            1536.6621
Q Predictions Min            -8.494236
V Predictions Mean           895.1316
V Predictions Std            478.55002
V Predictions Max            1528.3599
V Predictions Min            -1.3120627
Log Pis Mean                 0.25109297
Log Pis Std                  2.3770628
Log Pis Max                  6.9896994
Log Pis Min                  -6.3815613
Policy mu Mean               -0.0040169246
Policy mu Std                0.989384
Policy mu Max                2.7000132
Policy mu Min                -2.583014
Policy log std Mean          -0.5375115
Policy log std Std           0.27322596
Policy log std Max           0.11547369
Policy log std Min           -1.844747
Z mean eval                  0.0097289225
Z variance eval              0.001931315
total_rewards                [1159.65206219 1093.71256871 1188.68133728 1585.55217632  906.93820434
  924.82033707  875.19382099 1148.32258412 1199.39215278  954.50415461]
total_rewards_mean           1103.6769398418699
total_rewards_std            199.7422087406249
total_rewards_max            1585.5521763246286
total_rewards_min            875.1938209941194
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.466589097399265
(Previous) Eval Time (s)     7.6383731393143535
Sample Time (s)              23.4339695321396
Epoch Time (s)               62.53893176885322
Total Train Time (s)         4844.00432806788
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:27.635502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #81 | Epoch Duration: 64.5725462436676
2020-01-11 01:23:27.635685 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00979561
Z variance train             0.0020379785
KL Divergence                13.063165
KL Loss                      1.3063165
QF Loss                      456.12448
VF Loss                      89.4091
Policy Loss                  -870.21246
Q Predictions Mean           870.9765
Q Predictions Std            493.84488
Q Predictions Max            1502.6112
Q Predictions Min            -5.296627
V Predictions Mean           872.4357
V Predictions Std            494.08362
V Predictions Max            1514.3762
V Predictions Min            -2.2664464
Log Pis Mean                 0.38485035
Log Pis Std                  2.4860933
Log Pis Max                  10.189152
Log Pis Min                  -5.3357153
Policy mu Mean               0.076570265
Policy mu Std                0.99864584
Policy mu Max                3.1190677
Policy mu Min                -2.9895542
Policy log std Mean          -0.50420284
Policy log std Std           0.26829955
Policy log std Max           0.04571426
Policy log std Min           -2.6078765
Z mean eval                  0.007717899
Z variance eval              0.0022676713
total_rewards                [1136.15164934  946.82812999 1845.3248556  1504.40368804 1030.3921109
  717.79702515 1708.55143478 1139.35969156  724.8502599  1468.80597099]
total_rewards_mean           1222.2464816247968
total_rewards_std            373.3552734499414
total_rewards_max            1845.3248556018266
total_rewards_min            717.7970251461156
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               31.26290381187573
(Previous) Eval Time (s)     9.671654162928462
Sample Time (s)              22.749144858215004
Epoch Time (s)               63.6837028330192
Total Train Time (s)         4908.9885408151895
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:32.621354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #82 | Epoch Duration: 64.98553204536438
2020-01-11 01:24:32.621531 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007693514
Z variance train             0.002264909
KL Divergence                12.843893
KL Loss                      1.2843894
QF Loss                      226.2541
VF Loss                      147.4461
Policy Loss                  -809.74817
Q Predictions Mean           811.199
Q Predictions Std            511.55188
Q Predictions Max            1467.3164
Q Predictions Min            -4.015317
V Predictions Mean           816.3312
V Predictions Std            512.3095
V Predictions Max            1463.8407
V Predictions Min            0.32846692
Log Pis Mean                 0.07735446
Log Pis Std                  2.3831837
Log Pis Max                  8.887301
Log Pis Min                  -5.7062573
Policy mu Mean               0.10358039
Policy mu Std                0.9836594
Policy mu Max                2.9183323
Policy mu Min                -3.3919742
Policy log std Mean          -0.4855753
Policy log std Std           0.25205833
Policy log std Max           -0.023383707
Policy log std Min           -1.410835
Z mean eval                  0.02175486
Z variance eval              0.0021033813
total_rewards                [1155.69259626  891.44171574 1445.45453356 1178.39009495 1162.48558571
  885.10234914  881.06795308 1219.69533318  871.78582201 1391.083219  ]
total_rewards_mean           1108.2199202629583
total_rewards_std            205.07589039232198
total_rewards_max            1445.4545335590092
total_rewards_min            871.7858220076955
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               31.564379969146103
(Previous) Eval Time (s)     10.973135863430798
Sample Time (s)              22.74877089681104
Epoch Time (s)               65.28628672938794
Total Train Time (s)         4971.8013225840405
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:25:35.435287 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #83 | Epoch Duration: 62.813628911972046
2020-01-11 01:25:35.435447 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019946242
Z variance train             0.0022457193
KL Divergence                12.872098
KL Loss                      1.2872099
QF Loss                      3545.627
VF Loss                      123.90202
Policy Loss                  -877.6844
Q Predictions Mean           878.8412
Q Predictions Std            481.58502
Q Predictions Max            1491.688
Q Predictions Min            2.4494889
V Predictions Mean           881.282
V Predictions Std            479.75854
V Predictions Max            1479.7229
V Predictions Min            1.1895474
Log Pis Mean                 0.13109231
Log Pis Std                  2.2522461
Log Pis Max                  10.875055
Log Pis Min                  -5.0117335
Policy mu Mean               0.02872453
Policy mu Std                0.97181314
Policy mu Max                2.2999525
Policy mu Min                -3.187965
Policy log std Mean          -0.49574864
Policy log std Std           0.24881615
Policy log std Max           0.0076474845
Policy log std Min           -1.539907
Z mean eval                  0.020298792
Z variance eval              0.002458829
total_rewards                [1387.61354901 1070.93705192 1107.1185647  1035.73562711  742.68597702
 1073.26224821 1095.27433432  871.4984189  1205.75789445  834.72201433]
total_rewards_mean           1042.4605679955966
total_rewards_std            177.99426803884077
total_rewards_max            1387.6135490053578
total_rewards_min            742.6859770186628
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               31.769790476188064
(Previous) Eval Time (s)     8.500165699981153
Sample Time (s)              21.8416740456596
Epoch Time (s)               62.11163022182882
Total Train Time (s)         5035.0862955185585
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:38.722449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #84 | Epoch Duration: 63.28687286376953
2020-01-11 01:26:38.722630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020768797
Z variance train             0.002452422
KL Divergence                12.720631
KL Loss                      1.2720631
QF Loss                      1007.9204
VF Loss                      218.19693
Policy Loss                  -818.8082
Q Predictions Mean           818.2969
Q Predictions Std            512.52563
Q Predictions Max            1502.5402
Q Predictions Min            -5.555147
V Predictions Mean           825.18677
V Predictions Std            513.4906
V Predictions Max            1495.6072
V Predictions Min            -6.471518
Log Pis Mean                 0.1303769
Log Pis Std                  2.2832582
Log Pis Max                  8.0998
Log Pis Min                  -5.232876
Policy mu Mean               0.12526198
Policy mu Std                0.9866556
Policy mu Max                2.9477358
Policy mu Min                -3.5001736
Policy log std Mean          -0.48344764
Policy log std Std           0.25399995
Policy log std Max           0.14464122
Policy log std Min           -1.7325139
Z mean eval                  0.0073595108
Z variance eval              0.0018511948
total_rewards                [1114.72698126 1375.92922992  844.77707907 1403.12803057 1064.69619187
 1167.1007297   715.90893601  851.8536043   896.52582045  842.95451277]
total_rewards_mean           1027.7601115931745
total_rewards_std            224.39222838520337
total_rewards_max            1403.128030567321
total_rewards_min            715.908936009038
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               31.492939424235374
(Previous) Eval Time (s)     9.675104631111026
Sample Time (s)              23.52046369900927
Epoch Time (s)               64.68850775435567
Total Train Time (s)         5099.824258409906
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:43.463724 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #85 | Epoch Duration: 64.74090242385864
2020-01-11 01:27:43.464127 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007890135
Z variance train             0.0020698805
KL Divergence                13.065715
KL Loss                      1.3065715
QF Loss                      440.82306
VF Loss                      111.3824
Policy Loss                  -905.06665
Q Predictions Mean           901.4717
Q Predictions Std            490.04712
Q Predictions Max            1514.3685
Q Predictions Min            -2.725556
V Predictions Mean           901.17175
V Predictions Std            486.6594
V Predictions Max            1512.5597
V Predictions Min            -7.278631
Log Pis Mean                 0.041158788
Log Pis Std                  2.172872
Log Pis Max                  7.0919976
Log Pis Min                  -6.7412696
Policy mu Mean               0.06839908
Policy mu Std                0.94800216
Policy mu Max                2.2806888
Policy mu Min                -3.7320824
Policy log std Mean          -0.5093548
Policy log std Std           0.25812623
Policy log std Max           0.015432626
Policy log std Min           -1.7090722
Z mean eval                  0.0108152535
Z variance eval              0.002125056
total_rewards                [1521.82936888 1287.30262728 1005.11987812 2294.20626997 2374.03963302
 1550.03856068 1219.7801953  1410.846115   1157.640141   1198.89716702]
total_rewards_mean           1501.9699956259685
total_rewards_std            445.2124998311151
total_rewards_max            2374.039633016704
total_rewards_min            1005.119878122935
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.77139124367386
(Previous) Eval Time (s)     9.727115091402084
Sample Time (s)              22.39181673899293
Epoch Time (s)               63.890323074068874
Total Train Time (s)         5168.422714191955
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:28:52.062987 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #86 | Epoch Duration: 68.59861588478088
2020-01-11 01:28:52.063179 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009912269
Z variance train             0.0021044088
KL Divergence                13.039084
KL Loss                      1.3039085
QF Loss                      679.26556
VF Loss                      418.2909
Policy Loss                  -861.4526
Q Predictions Mean           862.59247
Q Predictions Std            489.74518
Q Predictions Max            1510.045
Q Predictions Min            -9.152622
V Predictions Mean           861.9542
V Predictions Std            486.43396
V Predictions Max            1513.0566
V Predictions Min            -9.212145
Log Pis Mean                 0.109326385
Log Pis Std                  2.3513267
Log Pis Max                  10.254009
Log Pis Min                  -5.1941214
Policy mu Mean               -0.057378203
Policy mu Std                0.9585965
Policy mu Max                3.3064177
Policy mu Min                -3.3855746
Policy log std Mean          -0.5149319
Policy log std Std           0.26780355
Policy log std Max           0.11290464
Policy log std Min           -1.6227
Z mean eval                  0.01293206
Z variance eval              0.0019956785
total_rewards                [1681.4818042   866.91776046 1230.15256447 1077.68383764  913.44996114
  928.07771708 1167.90176567 1186.39195768 1019.14955868  801.50395505]
total_rewards_mean           1087.2710882080385
total_rewards_std            240.90142369939682
total_rewards_max            1681.481804204744
total_rewards_min            801.5039550475959
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               31.617398218717426
(Previous) Eval Time (s)     14.435133035294712
Sample Time (s)              22.889202072285116
Epoch Time (s)               68.94173332629725
Total Train Time (s)         5232.391100123525
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:56.033038 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #87 | Epoch Duration: 63.969643354415894
2020-01-11 01:29:56.033216 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012802782
Z variance train             0.0020159376
KL Divergence                13.148251
KL Loss                      1.314825
QF Loss                      350.1645
VF Loss                      119.817375
Policy Loss                  -855.3724
Q Predictions Mean           850.6399
Q Predictions Std            506.87363
Q Predictions Max            1496.7561
Q Predictions Min            -11.986508
V Predictions Mean           856.529
V Predictions Std            506.83142
V Predictions Max            1497.1401
V Predictions Min            -6.596675
Log Pis Mean                 0.39219403
Log Pis Std                  2.4654973
Log Pis Max                  10.224598
Log Pis Min                  -4.23029
Policy mu Mean               0.05868764
Policy mu Std                1.0310618
Policy mu Max                3.5924568
Policy mu Min                -3.7309525
Policy log std Mean          -0.49916187
Policy log std Std           0.24938706
Policy log std Max           -0.034018934
Policy log std Min           -1.8085735
Z mean eval                  0.012215394
Z variance eval              0.0019036133
total_rewards                [ 957.26273937  944.35094163  861.2156244  1008.24784435  974.35626433
  909.59560492 1158.2267635  1218.43914692  970.99218058  952.77372978]
total_rewards_mean           995.5460839777828
total_rewards_std            104.26300730374737
total_rewards_max            1218.439146918012
total_rewards_min            861.215624399277
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               31.643891985993832
(Previous) Eval Time (s)     9.462700068950653
Sample Time (s)              22.41064176009968
Epoch Time (s)               63.517233815044165
Total Train Time (s)         5296.295418729074
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:59.939039 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #88 | Epoch Duration: 63.905688524246216
2020-01-11 01:30:59.939265 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #88 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01192291
Z variance train             0.001906851
KL Divergence                13.2299
KL Loss                      1.3229901
QF Loss                      172.85223
VF Loss                      74.824524
Policy Loss                  -968.2468
Q Predictions Mean           964.0812
Q Predictions Std            458.47687
Q Predictions Max            1474.8116
Q Predictions Min            -1.1929598
V Predictions Mean           966.2399
V Predictions Std            458.1229
V Predictions Max            1480.1213
V Predictions Min            1.6590388
Log Pis Mean                 0.11693842
Log Pis Std                  2.038889
Log Pis Max                  7.2629285
Log Pis Min                  -4.2082148
Policy mu Mean               0.045507
Policy mu Std                0.94387466
Policy mu Max                2.521125
Policy mu Min                -2.9267676
Policy log std Mean          -0.5457818
Policy log std Std           0.23910682
Policy log std Max           -0.0788185
Policy log std Min           -1.2462089
Z mean eval                  0.014460057
Z variance eval              0.0016414418
total_rewards                [1002.24287013  753.35008728  783.86871208 1041.64408785  765.0958413
  677.64744298  852.85775309 1078.91210079 1212.14686152  896.69208905]
total_rewards_mean           906.4457846065188
total_rewards_std            162.60755578738534
total_rewards_max            1212.1468615228343
total_rewards_min            677.647442976689
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               32.36880490090698
(Previous) Eval Time (s)     9.85084390686825
Sample Time (s)              23.822597857564688
Epoch Time (s)               66.04224666533992
Total Train Time (s)         5361.2582878149115
Epoch                        89
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:04.903795 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #89 | Epoch Duration: 64.96438837051392
2020-01-11 01:32:04.903971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014257215
Z variance train             0.0016415722
KL Divergence                13.585992
KL Loss                      1.3585992
QF Loss                      260.9606
VF Loss                      92.72293
Policy Loss                  -920.5367
Q Predictions Mean           918.8608
Q Predictions Std            466.6095
Q Predictions Max            1473.135
Q Predictions Min            -5.3920064
V Predictions Mean           920.9646
V Predictions Std            464.8609
V Predictions Max            1486.102
V Predictions Min            -0.94995606
Log Pis Mean                 0.095254615
Log Pis Std                  2.0250447
Log Pis Max                  6.601141
Log Pis Min                  -3.353747
Policy mu Mean               0.09392005
Policy mu Std                0.9389872
Policy mu Max                2.5276284
Policy mu Min                -2.6576536
Policy log std Mean          -0.54684836
Policy log std Std           0.27725142
Policy log std Max           -0.02295664
Policy log std Min           -2.564147
Z mean eval                  0.009020289
Z variance eval              0.0016588818
total_rewards                [1009.88563422 1068.95647462  865.79629628 1066.01462245  981.62088128
 1431.56709133 1047.20708948  864.92073661 1082.39717365 1163.72997854]
total_rewards_mean           1058.2095978450839
total_rewards_std            152.96972770163626
total_rewards_max            1431.5670913340616
total_rewards_min            864.9207366087513
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               31.483999819960445
(Previous) Eval Time (s)     8.772689851932228
Sample Time (s)              22.320017922203988
Epoch Time (s)               62.57670759409666
Total Train Time (s)         5425.226176760625
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:33:08.874894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #90 | Epoch Duration: 63.970781087875366
2020-01-11 01:33:08.875066 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009362815
Z variance train             0.0016512328
KL Divergence                13.616643
KL Loss                      1.3616643
QF Loss                      302.5418
VF Loss                      171.60153
Policy Loss                  -918.0151
Q Predictions Mean           914.0497
Q Predictions Std            472.37317
Q Predictions Max            1479.5912
Q Predictions Min            -1.9380076
V Predictions Mean           920.6102
V Predictions Std            472.1
V Predictions Max            1490.9613
V Predictions Min            -4.9070115
Log Pis Mean                 0.2878632
Log Pis Std                  2.2554817
Log Pis Max                  9.164811
Log Pis Min                  -4.0039034
Policy mu Mean               -0.039846707
Policy mu Std                0.9905584
Policy mu Max                2.4390252
Policy mu Min                -3.0417495
Policy log std Mean          -0.5148705
Policy log std Std           0.2553078
Policy log std Max           0.06181094
Policy log std Min           -1.7987607
Z mean eval                  0.033403683
Z variance eval              0.0013173174
total_rewards                [1004.17211116  818.30917595 1167.03566662  775.62058169  783.77677439
  792.29228119  810.22620012 1005.93999768 1012.69197384  867.77596965]
total_rewards_mean           903.7840732296241
total_rewards_std            127.39293251123706
total_rewards_max            1167.0356666233413
total_rewards_min            775.6205816942269
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.05762562062591
(Previous) Eval Time (s)     10.166423537768424
Sample Time (s)              23.114543164148927
Epoch Time (s)               65.33859232254326
Total Train Time (s)         5488.133574598003
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:34:11.784015 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #91 | Epoch Duration: 62.90881395339966
2020-01-11 01:34:11.784180 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03407365
Z variance train             0.0013433394
KL Divergence                14.140879
KL Loss                      1.4140879
QF Loss                      600.09735
VF Loss                      472.69186
Policy Loss                  -935.4282
Q Predictions Mean           934.75745
Q Predictions Std            482.04083
Q Predictions Max            1499.633
Q Predictions Min            -32.511223
V Predictions Mean           920.9086
V Predictions Std            471.05627
V Predictions Max            1458.9097
V Predictions Min            -9.049575
Log Pis Mean                 0.4744028
Log Pis Std                  2.4034493
Log Pis Max                  11.567973
Log Pis Min                  -4.103875
Policy mu Mean               0.22935063
Policy mu Std                1.044198
Policy mu Max                2.8662715
Policy mu Min                -3.4793854
Policy log std Mean          -0.52536696
Policy log std Std           0.24400237
Policy log std Max           -0.10761523
Policy log std Min           -2.0504932
Z mean eval                  0.029012615
Z variance eval              0.0010401064
total_rewards                [1043.58149074 1084.32458849 1115.79194094 1139.82440417 1080.58346574
 1041.16298042 1079.13112694 1110.23843874 1054.42269483 1123.27540918]
total_rewards_mean           1087.23365401814
total_rewards_std            32.60752515528708
total_rewards_max            1139.824404173238
total_rewards_min            1041.1629804205377
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               31.850151481106877
(Previous) Eval Time (s)     7.736316933296621
Sample Time (s)              23.300294027663767
Epoch Time (s)               62.886762442067266
Total Train Time (s)         5553.249309998006
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:16.901534 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #92 | Epoch Duration: 65.11720395088196
2020-01-11 01:35:16.901819 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031234369
Z variance train             0.0011780863
KL Divergence                14.531319
KL Loss                      1.4531319
QF Loss                      559.00195
VF Loss                      482.99936
Policy Loss                  -855.1383
Q Predictions Mean           854.6156
Q Predictions Std            514.6335
Q Predictions Max            1490.4679
Q Predictions Min            -2.5477972
V Predictions Mean           853.9388
V Predictions Std            514.0193
V Predictions Max            1487.567
V Predictions Min            -1.1299796
Log Pis Mean                 0.14073314
Log Pis Std                  2.3515759
Log Pis Max                  9.669829
Log Pis Min                  -7.0590506
Policy mu Mean               0.052252848
Policy mu Std                1.0062621
Policy mu Max                2.7093644
Policy mu Min                -2.8722568
Policy log std Mean          -0.4999589
Policy log std Std           0.2593289
Policy log std Max           -0.028355777
Policy log std Min           -1.5693216
Z mean eval                  0.020225603
Z variance eval              0.0011011355
total_rewards                [1197.72886007 1153.61241682  961.57662225 1432.89513509 1235.01845758
  858.48288617 1163.51770983 1020.78617073  974.67210655 1292.42759919]
total_rewards_mean           1129.0717964291493
total_rewards_std            165.39619781088655
total_rewards_max            1432.8951350902162
total_rewards_min            858.4828861701278
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               31.81351183867082
(Previous) Eval Time (s)     9.966473799198866
Sample Time (s)              23.015888893045485
Epoch Time (s)               64.79587453091517
Total Train Time (s)         5618.7912335763685
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:22.444640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #93 | Epoch Duration: 65.54251909255981
2020-01-11 01:36:22.444801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017859295
Z variance train             0.0012236324
KL Divergence                14.431528
KL Loss                      1.4431528
QF Loss                      310.47638
VF Loss                      76.23008
Policy Loss                  -956.6449
Q Predictions Mean           960.8329
Q Predictions Std            476.5083
Q Predictions Max            1499.5713
Q Predictions Min            -2.6768885
V Predictions Mean           959.72003
V Predictions Std            475.46234
V Predictions Max            1494.0891
V Predictions Min            -5.759401
Log Pis Mean                 -0.102732584
Log Pis Std                  2.1646538
Log Pis Max                  10.677504
Log Pis Min                  -6.324951
Policy mu Mean               0.10966608
Policy mu Std                0.94623625
Policy mu Max                2.7924013
Policy mu Min                -2.6524963
Policy log std Mean          -0.50290996
Policy log std Std           0.23769008
Policy log std Max           0.08944374
Policy log std Min           -1.4772
Z mean eval                  0.013829392
Z variance eval              0.0010933122
total_rewards                [1098.97335723 1115.64045151 1163.52516359 1198.10772951 2010.81108863
 1129.18321116 1750.12133988  863.61018885 1086.48041612 1385.25478075]
total_rewards_mean           1280.1707727228236
total_rewards_std            328.6047237543722
total_rewards_max            2010.811088630986
total_rewards_min            863.610188850211
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               33.25271926727146
(Previous) Eval Time (s)     10.712838226929307
Sample Time (s)              21.660434399265796
Epoch Time (s)               65.62599189346656
Total Train Time (s)         5686.169601794332
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:29.825027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #94 | Epoch Duration: 67.38009643554688
2020-01-11 01:37:29.825207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018138617
Z variance train             0.0010951319
KL Divergence                14.7215805
KL Loss                      1.4721581
QF Loss                      404.79877
VF Loss                      353.41006
Policy Loss                  -922.0232
Q Predictions Mean           924.6403
Q Predictions Std            483.24344
Q Predictions Max            1503.9126
Q Predictions Min            1.5329049
V Predictions Mean           916.9834
V Predictions Std            475.2736
V Predictions Max            1473.274
V Predictions Min            -0.72471243
Log Pis Mean                 0.25277364
Log Pis Std                  2.2370248
Log Pis Max                  8.93886
Log Pis Min                  -3.7883162
Policy mu Mean               -0.121196
Policy mu Std                0.9763951
Policy mu Max                2.884083
Policy mu Min                -3.0474718
Policy log std Mean          -0.5394779
Policy log std Std           0.27804032
Policy log std Max           0.04213476
Policy log std Min           -2.8299005
Z mean eval                  0.021651944
Z variance eval              0.0009470541
total_rewards                [ 810.46560497  808.60919776 1040.99631882  975.90939662 1133.88825862
  916.22904852 1423.02066593 1411.47959028  809.91805247  926.01793828]
total_rewards_mean           1025.6534072265633
total_rewards_std            219.78259161003186
total_rewards_max            1423.020665933415
total_rewards_min            808.6091977587329
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               33.71264647319913
(Previous) Eval Time (s)     12.466601382941008
Sample Time (s)              23.471799463499337
Epoch Time (s)               69.65104731963947
Total Train Time (s)         5753.026650275104
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:36.685287 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #95 | Epoch Duration: 66.85990810394287
2020-01-11 01:38:36.685586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06886276
Z variance train             0.00065710203
KL Divergence                15.951253
KL Loss                      1.5951253
QF Loss                      2165.5723
VF Loss                      113.55574
Policy Loss                  -929.61725
Q Predictions Mean           921.537
Q Predictions Std            489.54715
Q Predictions Max            1518.7256
Q Predictions Min            -5.215741
V Predictions Mean           924.5666
V Predictions Std            488.75717
V Predictions Max            1510.3959
V Predictions Min            -1.1582923
Log Pis Mean                 0.16443692
Log Pis Std                  2.254801
Log Pis Max                  7.483056
Log Pis Min                  -4.9655495
Policy mu Mean               0.12006706
Policy mu Std                0.96220016
Policy mu Max                2.431352
Policy mu Min                -2.8178074
Policy log std Mean          -0.5234497
Policy log std Std           0.26318198
Policy log std Max           0.056001604
Policy log std Min           -2.3880308
Z mean eval                  0.022966508
Z variance eval              0.0010918772
total_rewards                [1198.72644799 1183.55949719 1668.99107119 1792.64522713 2204.16901574
 1696.044638   1220.4940331  2112.01204799 1434.26728619 1636.87429136]
total_rewards_mean           1614.7783555862802
total_rewards_std            344.003494673982
total_rewards_max            2204.1690157353255
total_rewards_min            1183.55949719388
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               33.836236209608614
(Previous) Eval Time (s)     9.675077143125236
Sample Time (s)              24.31315773818642
Epoch Time (s)               67.82447109092027
Total Train Time (s)         5826.952252194285
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:39:50.612519 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #96 | Epoch Duration: 73.9267508983612
2020-01-11 01:39:50.612764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03567039
Z variance train             0.0007874484
KL Divergence                15.631966
KL Loss                      1.5631965
QF Loss                      488.1927
VF Loss                      217.98645
Policy Loss                  -954.1416
Q Predictions Mean           950.42194
Q Predictions Std            490.33347
Q Predictions Max            1517.2834
Q Predictions Min            -18.004505
V Predictions Mean           958.8661
V Predictions Std            487.4953
V Predictions Max            1532.365
V Predictions Min            -11.519532
Log Pis Mean                 0.04435505
Log Pis Std                  2.168882
Log Pis Max                  6.5609894
Log Pis Min                  -7.8746643
Policy mu Mean               0.042441454
Policy mu Std                0.9482875
Policy mu Max                3.0335221
Policy mu Min                -2.6882374
Policy log std Mean          -0.5229489
Policy log std Std           0.23791681
Policy log std Max           0.057401985
Policy log std Min           -1.3074883
Z mean eval                  0.0117344055
Z variance eval              0.0012394619
total_rewards                [1031.0293527  1040.10098418 1152.42034316 1117.5631509  1072.29004639
 1158.1505026  1093.39467724 1086.24699005 1691.67325605 1031.7149575 ]
total_rewards_mean           1147.4584260758872
total_rewards_std            186.54767859111558
total_rewards_max            1691.6732560459147
total_rewards_min            1031.0293526990413
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               33.81611088523641
(Previous) Eval Time (s)     15.776909321080893
Sample Time (s)              25.25420886138454
Epoch Time (s)               74.84722906770185
Total Train Time (s)         5896.782498312648
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:41:00.444836 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #97 | Epoch Duration: 69.83192205429077
2020-01-11 01:41:00.445020 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04794135
Z variance train             0.0008316368
KL Divergence                15.545271
KL Loss                      1.5545272
QF Loss                      310.09665
VF Loss                      67.42382
Policy Loss                  -859.08356
Q Predictions Mean           857.1975
Q Predictions Std            523.0993
Q Predictions Max            1504.4767
Q Predictions Min            0.78168625
V Predictions Mean           860.15405
V Predictions Std            522.5147
V Predictions Max            1502.8868
V Predictions Min            -1.565119
Log Pis Mean                 0.20794436
Log Pis Std                  2.4024534
Log Pis Max                  14.04647
Log Pis Min                  -5.453374
Policy mu Mean               0.082537435
Policy mu Std                0.99803865
Policy mu Max                2.5659482
Policy mu Min                -3.717324
Policy log std Mean          -0.4977709
Policy log std Std           0.24735421
Policy log std Max           -0.050432533
Policy log std Min           -2.1671329
Z mean eval                  0.016070912
Z variance eval              0.002277123
total_rewards                [ 970.93289687  737.90312944  756.30074998  808.39818128  738.84852541
  764.79789354  747.94155705  824.02960986  763.8432846  1001.84675715]
total_rewards_mean           811.4842585189823
total_rewards_std            91.67931323048276
total_rewards_max            1001.8467571467795
total_rewards_min            737.9031294362889
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               33.32095331698656
(Previous) Eval Time (s)     10.761138008441776
Sample Time (s)              22.761999771930277
Epoch Time (s)               66.84409109735861
Total Train Time (s)         5960.977595235221
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:04.642387 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #98 | Epoch Duration: 64.19719910621643
2020-01-11 01:42:04.642705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018149147
Z variance train             0.0017917445
KL Divergence                13.825418
KL Loss                      1.3825419
QF Loss                      691.9581
VF Loss                      274.33353
Policy Loss                  -995.7742
Q Predictions Mean           999.8718
Q Predictions Std            458.8944
Q Predictions Max            1520.8417
Q Predictions Min            -3.381932
V Predictions Mean           999.08997
V Predictions Std            455.8987
V Predictions Max            1531.1494
V Predictions Min            -5.1862965
Log Pis Mean                 0.23543598
Log Pis Std                  2.3372786
Log Pis Max                  7.480425
Log Pis Min                  -5.125511
Policy mu Mean               0.11607114
Policy mu Std                0.99426603
Policy mu Max                2.7553232
Policy mu Min                -2.5973055
Policy log std Mean          -0.52305984
Policy log std Std           0.23712839
Policy log std Max           0.035289466
Policy log std Min           -1.7541351
Z mean eval                  0.012622738
Z variance eval              0.0011727272
total_rewards                [1053.41895598 1124.79219607 1108.79332268  856.82291657 1354.29795621
 1208.43389295  393.49938217  795.04946884  865.47380326  859.43781434]
total_rewards_mean           962.0019709069032
total_rewards_std            255.5383168921733
total_rewards_max            1354.2979562126013
total_rewards_min            393.4993821667225
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               34.16481985012069
(Previous) Eval Time (s)     8.113880421966314
Sample Time (s)              24.35885852528736
Epoch Time (s)               66.63755879737437
Total Train Time (s)         6029.260368510149
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:12.926915 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #99 | Epoch Duration: 68.28403043746948
2020-01-11 01:43:12.927104 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012731562
Z variance train             0.0011949895
KL Divergence                14.802018
KL Loss                      1.4802018
QF Loss                      221.15836
VF Loss                      598.1226
Policy Loss                  -857.20605
Q Predictions Mean           854.57666
Q Predictions Std            530.5059
Q Predictions Max            1479.5503
Q Predictions Min            -2.0196698
V Predictions Mean           864.32983
V Predictions Std            532.27405
V Predictions Max            1489.5452
V Predictions Min            -0.87474144
Log Pis Mean                 0.05592817
Log Pis Std                  2.3937132
Log Pis Max                  10.335213
Log Pis Min                  -5.83091
Policy mu Mean               0.025314668
Policy mu Std                0.93900675
Policy mu Max                3.0524676
Policy mu Min                -2.7970018
Policy log std Mean          -0.4980363
Policy log std Std           0.24881119
Policy log std Max           0.030123949
Policy log std Min           -1.5395782
Z mean eval                  0.010627092
Z variance eval              0.0010576872
total_rewards                [1081.04033697 1126.9291906  1066.32017191  839.21027302  796.21651442
 1087.02433734 1101.1804578  1101.93953252  775.61349118 1104.37412912]
total_rewards_mean           1007.9848434870686
total_rewards_std            135.37578870692928
total_rewards_max            1126.9291906032329
total_rewards_min            775.6134911755183
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               33.75759833958
(Previous) Eval Time (s)     9.760002400260419
Sample Time (s)              23.202021580655128
Epoch Time (s)               66.71962232049555
Total Train Time (s)         6095.658438066021
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:44:19.327143 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #100 | Epoch Duration: 66.39988040924072
2020-01-11 01:44:19.327380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010745599
Z variance train             0.0010647671
KL Divergence                15.129033
KL Loss                      1.5129033
QF Loss                      224.59308
VF Loss                      102.225815
Policy Loss                  -983.4997
Q Predictions Mean           981.09705
Q Predictions Std            461.38846
Q Predictions Max            1502.7727
Q Predictions Min            -2.1860068
V Predictions Mean           981.1459
V Predictions Std            461.70706
V Predictions Max            1496.8069
V Predictions Min            -4.3754644
Log Pis Mean                 0.19917378
Log Pis Std                  2.1216347
Log Pis Max                  5.905014
Log Pis Min                  -6.0393095
Policy mu Mean               0.041675553
Policy mu Std                0.9586781
Policy mu Max                2.0890608
Policy mu Min                -2.7547505
Policy log std Mean          -0.52827066
Policy log std Std           0.22823149
Policy log std Max           0.07673365
Policy log std Min           -1.7429187
Z mean eval                  0.009477219
Z variance eval              0.0018274244
total_rewards                [2380.82987256 1089.06667126 2735.36109594 1925.35005476 1503.42111913
  917.8726716  1064.16163616 1096.99631729 1143.6499148   836.02629137]
total_rewards_mean           1469.273564487004
total_rewards_std            624.6137590778219
total_rewards_max            2735.361095944931
total_rewards_min            836.0262913689496
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               33.36952882958576
(Previous) Eval Time (s)     9.439816783182323
Sample Time (s)              22.500459812115878
Epoch Time (s)               65.30980542488396
Total Train Time (s)         6165.670403817669
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:29.341404 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #101 | Epoch Duration: 70.0138771533966
2020-01-11 01:45:29.341598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008847183
Z variance train             0.0019921542
KL Divergence                13.3415
KL Loss                      1.3341501
QF Loss                      220.8188
VF Loss                      125.787476
Policy Loss                  -962.3565
Q Predictions Mean           960.0532
Q Predictions Std            472.4936
Q Predictions Max            1487.3656
Q Predictions Min            -3.6634276
V Predictions Mean           968.9022
V Predictions Std            476.40802
V Predictions Max            1505.0991
V Predictions Min            -18.767315
Log Pis Mean                 0.011219576
Log Pis Std                  2.1681519
Log Pis Max                  8.104784
Log Pis Min                  -5.630805
Policy mu Mean               0.0033746052
Policy mu Std                0.92211115
Policy mu Max                2.2906702
Policy mu Min                -2.7298732
Policy log std Mean          -0.51415545
Policy log std Std           0.25229496
Policy log std Max           0.0747931
Policy log std Min           -1.3646758
Z mean eval                  0.021660987
Z variance eval              0.0019831683
total_rewards                [1486.84098754 2029.48252211 1177.16776616 2230.76969192 1161.94119712
 1218.35822212 1300.35902147  992.27560116 1238.70524369 1215.85482417]
total_rewards_mean           1405.1755077454586
total_rewards_std            383.2900876246911
total_rewards_max            2230.7696919173277
total_rewards_min            992.2756011555817
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               34.31761211436242
(Previous) Eval Time (s)     14.143534916918725
Sample Time (s)              24.187862779945135
Epoch Time (s)               72.64900981122628
Total Train Time (s)         6237.954852198716
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:41.627169 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #102 | Epoch Duration: 72.28542304039001
2020-01-11 01:46:41.627401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017929986
Z variance train             0.0012380076
KL Divergence                14.512064
KL Loss                      1.4512064
QF Loss                      261.75452
VF Loss                      220.21602
Policy Loss                  -1025.3983
Q Predictions Mean           1021.08405
Q Predictions Std            431.94202
Q Predictions Max            1490.8137
Q Predictions Min            -6.1909366
V Predictions Mean           1033.9553
V Predictions Std            435.79156
V Predictions Max            1509.32
V Predictions Min            1.5803217
Log Pis Mean                 0.003188569
Log Pis Std                  2.1496902
Log Pis Max                  7.5045414
Log Pis Min                  -4.554944
Policy mu Mean               0.05273543
Policy mu Std                0.9507221
Policy mu Max                2.7057173
Policy mu Min                -2.8289225
Policy log std Mean          -0.5000009
Policy log std Std           0.23116581
Policy log std Max           -0.03442976
Policy log std Min           -1.3620254
Z mean eval                  0.018061666
Z variance eval              0.0016015526
total_rewards                [1123.27542204  882.97411062  796.32750657  808.75611302 1149.39192397
  775.28966708  807.04713287  830.17929384  785.72241759 1174.23659774]
total_rewards_mean           913.3200185340696
total_rewards_std            157.15286877439206
total_rewards_max            1174.2365977416982
total_rewards_min            775.2896670806596
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               34.7415113337338
(Previous) Eval Time (s)     13.779544027987868
Sample Time (s)              22.900415294338018
Epoch Time (s)               71.42147065605968
Total Train Time (s)         6304.212262670975
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:47:47.886743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #103 | Epoch Duration: 66.25920343399048
2020-01-11 01:47:47.886938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018045453
Z variance train             0.0015321343
KL Divergence                13.97187
KL Loss                      1.3971871
QF Loss                      143.14517
VF Loss                      28.294626
Policy Loss                  -917.3627
Q Predictions Mean           913.36163
Q Predictions Std            510.7743
Q Predictions Max            1482.5435
Q Predictions Min            -7.559407
V Predictions Mean           917.9226
V Predictions Std            510.94925
V Predictions Max            1483.9368
V Predictions Min            -0.11566776
Log Pis Mean                 -0.1409874
Log Pis Std                  2.3216097
Log Pis Max                  7.6011267
Log Pis Min                  -6.743245
Policy mu Mean               0.18212384
Policy mu Std                0.8983779
Policy mu Max                2.493927
Policy mu Min                -2.5537271
Policy log std Mean          -0.46647587
Policy log std Std           0.24525611
Policy log std Max           -0.032290548
Policy log std Min           -2.0126965
Z mean eval                  0.027275309
Z variance eval              0.0017315928
total_rewards                [ 920.13899629 1477.90630306 1139.59190555  803.3044665  1105.85236756
 1091.96167644 1183.09835106 1124.08115542 1076.34791308 1142.77055172]
total_rewards_mean           1106.505368668791
total_rewards_std            165.6226310246535
total_rewards_max            1477.9063030617597
total_rewards_min            803.3044665024076
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               33.28197474125773
(Previous) Eval Time (s)     8.616980074904859
Sample Time (s)              23.020951377227902
Epoch Time (s)               64.91990619339049
Total Train Time (s)         6370.758280471433
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:54.434533 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #104 | Epoch Duration: 66.54744601249695
2020-01-11 01:48:54.434708 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027328696
Z variance train             0.001758058
KL Divergence                13.716352
KL Loss                      1.3716353
QF Loss                      216.89896
VF Loss                      112.12624
Policy Loss                  -979.4075
Q Predictions Mean           981.2284
Q Predictions Std            468.57178
Q Predictions Max            1517.9386
Q Predictions Min            5.524415
V Predictions Mean           975.57056
V Predictions Std            464.79117
V Predictions Max            1506.1978
V Predictions Min            -1.3507693
Log Pis Mean                 0.28185996
Log Pis Std                  2.1859288
Log Pis Max                  10.155451
Log Pis Min                  -4.083769
Policy mu Mean               0.1519512
Policy mu Std                0.9747481
Policy mu Max                2.7047873
Policy mu Min                -2.7454667
Policy log std Mean          -0.51879615
Policy log std Std           0.22896229
Policy log std Max           -0.046785444
Policy log std Min           -1.7922152
Z mean eval                  0.019482056
Z variance eval              0.0016099891
total_rewards                [ 762.30619344  868.44781794  817.59831327 1089.08628722  806.37416036
  885.85931568  892.85491258  933.26663542 1574.17283794 1004.64277602]
total_rewards_mean           963.4609249862795
total_rewards_std            223.1162254600721
total_rewards_max            1574.1728379358337
total_rewards_min            762.3061934428648
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               34.14280361775309
(Previous) Eval Time (s)     10.24418007908389
Sample Time (s)              23.838899445254356
Epoch Time (s)               68.22588314209133
Total Train Time (s)         6436.753278219141
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:50:00.432125 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #105 | Epoch Duration: 65.99725317955017
2020-01-11 01:50:00.432420 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019384975
Z variance train             0.001609223
KL Divergence                13.90644
KL Loss                      1.390644
QF Loss                      499.0935
VF Loss                      229.6997
Policy Loss                  -972.93365
Q Predictions Mean           965.25507
Q Predictions Std            493.30667
Q Predictions Max            1500.6
Q Predictions Min            0.10610901
V Predictions Mean           971.6338
V Predictions Std            493.27808
V Predictions Max            1487.0618
V Predictions Min            -4.3692403
Log Pis Mean                 0.21251963
Log Pis Std                  2.3802717
Log Pis Max                  12.9635315
Log Pis Min                  -8.335793
Policy mu Mean               0.22220965
Policy mu Std                0.9496714
Policy mu Max                2.7015574
Policy mu Min                -4.388223
Policy log std Mean          -0.52017844
Policy log std Std           0.2540037
Policy log std Max           0.019965827
Policy log std Min           -3.0706735
Z mean eval                  0.012951192
Z variance eval              0.0018327773
total_rewards                [1139.72297691 1058.13214405 1211.37689463 1198.3937168   922.90527293
  995.2089207  1032.58918588 1160.15421108 1108.21646959 1042.06374833]
total_rewards_mean           1086.8763540907378
total_rewards_std            88.10519102582708
total_rewards_max            1211.3768946292867
total_rewards_min            922.9052729293337
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               33.069417480845004
(Previous) Eval Time (s)     8.015081253834069
Sample Time (s)              24.740153032820672
Epoch Time (s)               65.82465176749974
Total Train Time (s)         6504.712927740067
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:08.397144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #106 | Epoch Duration: 67.96456027030945
2020-01-11 01:51:08.397329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012617676
Z variance train             0.001833617
KL Divergence                13.450167
KL Loss                      1.3450167
QF Loss                      759.28174
VF Loss                      184.43983
Policy Loss                  -991.39764
Q Predictions Mean           987.5134
Q Predictions Std            483.28915
Q Predictions Max            1502.1486
Q Predictions Min            -2.3341398
V Predictions Mean           993.27954
V Predictions Std            483.37042
V Predictions Max            1500.9554
V Predictions Min            -5.1127625
Log Pis Mean                 0.37622398
Log Pis Std                  2.5568733
Log Pis Max                  11.339369
Log Pis Min                  -9.890125
Policy mu Mean               0.15554148
Policy mu Std                1.0392725
Policy mu Max                2.9970255
Policy mu Min                -3.689248
Policy log std Mean          -0.49208865
Policy log std Std           0.21747003
Policy log std Max           -0.047822267
Policy log std Min           -1.2452459
Z mean eval                  0.011603707
Z variance eval              0.0016242331
total_rewards                [ 760.54749602  925.75947125 1252.28330473  706.1623829  1020.79460553
  890.70960883 1212.69989254  730.90157547  707.57243803  990.25120886]
total_rewards_mean           919.7681984139017
total_rewards_std            190.8156383818579
total_rewards_max            1252.2833047331062
total_rewards_min            706.1623828977014
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               31.593544751871377
(Previous) Eval Time (s)     10.154605692252517
Sample Time (s)              22.15481018135324
Epoch Time (s)               63.902960625477135
Total Train Time (s)         6566.410501252394
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:10.093063 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #107 | Epoch Duration: 61.695589780807495
2020-01-11 01:52:10.093232 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010829398
Z variance train             0.0016203185
KL Divergence                13.802398
KL Loss                      1.3802398
QF Loss                      489.73624
VF Loss                      128.92796
Policy Loss                  -967.3972
Q Predictions Mean           971.15906
Q Predictions Std            497.86884
Q Predictions Max            1503.4077
Q Predictions Min            -0.3071857
V Predictions Mean           967.0712
V Predictions Std            496.78827
V Predictions Max            1491.3262
V Predictions Min            0.976771
Log Pis Mean                 -0.123985104
Log Pis Std                  2.0737488
Log Pis Max                  7.3593416
Log Pis Min                  -7.769611
Policy mu Mean               -0.033286553
Policy mu Std                0.92722505
Policy mu Max                2.9589982
Policy mu Min                -2.6603951
Policy log std Mean          -0.5194501
Policy log std Std           0.2494176
Policy log std Max           0.03711191
Policy log std Min           -2.4801733
Z mean eval                  0.0072403015
Z variance eval              0.0015764972
total_rewards                [1184.22699996 1099.4267088  1006.15147707 1218.75750837 1131.9265278
 1526.81988576 1603.66466617 1139.33548132 1125.8603057   880.27686892]
total_rewards_mean           1191.6446429863577
total_rewards_std            208.17898673669035
total_rewards_max            1603.6646661650022
total_rewards_min            880.276868922361
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               31.85256846016273
(Previous) Eval Time (s)     7.946938368026167
Sample Time (s)              22.916978663299233
Epoch Time (s)               62.71648549148813
Total Train Time (s)         6632.811935564037
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:53:16.496962 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #108 | Epoch Duration: 66.40355181694031
2020-01-11 01:53:16.497229 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #108 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008448534
Z variance train             0.0015779635
KL Divergence                13.890661
KL Loss                      1.3890661
QF Loss                      131.78809
VF Loss                      80.18514
Policy Loss                  -1013.1224
Q Predictions Mean           1009.84503
Q Predictions Std            479.7524
Q Predictions Max            1518.4558
Q Predictions Min            -2.3330834
V Predictions Mean           1011.3644
V Predictions Std            479.6034
V Predictions Max            1529.8358
V Predictions Min            -2.988908
Log Pis Mean                 0.31016046
Log Pis Std                  2.205797
Log Pis Max                  9.19971
Log Pis Min                  -4.7290864
Policy mu Mean               0.18374185
Policy mu Std                0.95442104
Policy mu Max                2.5133212
Policy mu Min                -2.8305504
Policy log std Mean          -0.5472869
Policy log std Std           0.23303412
Policy log std Max           0.053530037
Policy log std Min           -1.5770117
Z mean eval                  0.008200803
Z variance eval              0.0015558015
total_rewards                [801.49261531 904.15435311 702.50098206 938.49129322 688.22085034
 696.40087664 896.26149366 833.60437523 682.54209654 831.19552244]
total_rewards_mean           797.4864458549042
total_rewards_std            93.7365883673198
total_rewards_max            938.491293224179
total_rewards_min            682.5420965361272
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               31.700272218789905
(Previous) Eval Time (s)     11.633648635819554
Sample Time (s)              22.801928830333054
Epoch Time (s)               66.13584968494251
Total Train Time (s)         6694.758695269469
Epoch                        109
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:18.445168 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #109 | Epoch Duration: 61.94774055480957
2020-01-11 01:54:18.445413 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008092205
Z variance train             0.0015548945
KL Divergence                13.844961
KL Loss                      1.3844961
QF Loss                      691.4214
VF Loss                      160.86823
Policy Loss                  -1033.1864
Q Predictions Mean           1033.2225
Q Predictions Std            460.27295
Q Predictions Max            1513.2151
Q Predictions Min            1.7893885
V Predictions Mean           1030.9226
V Predictions Std            457.79642
V Predictions Max            1507.943
V Predictions Min            2.564065
Log Pis Mean                 0.26034713
Log Pis Std                  2.3488784
Log Pis Max                  12.682526
Log Pis Min                  -7.245051
Policy mu Mean               0.07682493
Policy mu Std                1.0151522
Policy mu Max                3.5277069
Policy mu Min                -2.7887485
Policy log std Mean          -0.5245591
Policy log std Std           0.20884138
Policy log std Max           -0.045301497
Policy log std Min           -1.4345143
Z mean eval                  0.016714945
Z variance eval              0.0016846436
total_rewards                [ 802.96543593 1246.0451244   964.67585912 1263.02579462 1603.07140317
 2154.16954287 2054.17811607  841.69319733  811.0983756  1143.41190862]
total_rewards_mean           1288.4334757728175
total_rewards_std            471.8324152917686
total_rewards_max            2154.16954287151
total_rewards_min            802.9654359293417
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               31.529237180016935
(Previous) Eval Time (s)     7.445179554168135
Sample Time (s)              22.307517387904227
Epoch Time (s)               61.2819341220893
Total Train Time (s)         6760.718669323251
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:55:24.409272 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #110 | Epoch Duration: 65.96370077133179
2020-01-11 01:55:24.409479 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016989443
Z variance train             0.0016737959
KL Divergence                13.682011
KL Loss                      1.3682011
QF Loss                      295.04462
VF Loss                      90.42953
Policy Loss                  -951.11804
Q Predictions Mean           948.6094
Q Predictions Std            508.60175
Q Predictions Max            1501.9841
Q Predictions Min            -15.134637
V Predictions Mean           950.6682
V Predictions Std            508.07608
V Predictions Max            1505.6381
V Predictions Min            -1.0697842
Log Pis Mean                 -0.042695656
Log Pis Std                  2.2331426
Log Pis Max                  9.966654
Log Pis Min                  -5.6170077
Policy mu Mean               0.10561854
Policy mu Std                0.9156268
Policy mu Max                2.519543
Policy mu Min                -2.7819824
Policy log std Mean          -0.48613802
Policy log std Std           0.23123394
Policy log std Max           0.09880236
Policy log std Min           -1.6014508
Z mean eval                  0.04268862
Z variance eval              0.0011291627
total_rewards                [ 848.86560949  824.35284993  799.78178822  940.67419065  779.21194508
 1032.98221122  955.33891964  933.63083592  834.4258445   893.72719935]
total_rewards_mean           884.2991394003593
total_rewards_std            76.40477503973841
total_rewards_max            1032.9822112173936
total_rewards_min            779.2119450837499
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               31.45728185493499
(Previous) Eval Time (s)     12.126643673982471
Sample Time (s)              22.30430812621489
Epoch Time (s)               65.88823365513235
Total Train Time (s)         6822.522842367645
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:26.212460 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #111 | Epoch Duration: 61.80284309387207
2020-01-11 01:56:26.212623 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #111 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009135414
Z variance train             0.0013981713
KL Divergence                14.003866
KL Loss                      1.4003867
QF Loss                      321.65356
VF Loss                      129.5885
Policy Loss                  -1061.7946
Q Predictions Mean           1058.8318
Q Predictions Std            450.30643
Q Predictions Max            1537.9702
Q Predictions Min            -25.696146
V Predictions Mean           1060.4144
V Predictions Std            451.0991
V Predictions Max            1539.2686
V Predictions Min            0.2953688
Log Pis Mean                 0.013834212
Log Pis Std                  2.0880165
Log Pis Max                  7.6142282
Log Pis Min                  -4.228244
Policy mu Mean               0.0764847
Policy mu Std                0.96776295
Policy mu Max                2.7572238
Policy mu Min                -2.8520598
Policy log std Mean          -0.531804
Policy log std Std           0.22034629
Policy log std Max           -0.08760491
Policy log std Min           -1.3813384
Z mean eval                  0.009055641
Z variance eval              0.0016115576
total_rewards                [867.6121118  819.08610971 793.26626337 749.48555734 900.25007791
 775.73692357 953.90158756 981.47990175 952.60033006 832.66367326]
total_rewards_mean           862.6082536320897
total_rewards_std            77.42609367552701
total_rewards_max            981.4799017475374
total_rewards_min            749.4855573355663
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               31.90718658687547
(Previous) Eval Time (s)     8.040906261187047
Sample Time (s)              22.84487554524094
Epoch Time (s)               62.792968393303454
Total Train Time (s)         6884.801952536218
Epoch                        112
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:28.495923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #112 | Epoch Duration: 62.283164262771606
2020-01-11 01:57:28.496168 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011062532
Z variance train             0.0016459872
KL Divergence                13.572202
KL Loss                      1.3572202
QF Loss                      539.84546
VF Loss                      274.71826
Policy Loss                  -1041.6558
Q Predictions Mean           1033.0587
Q Predictions Std            453.85544
Q Predictions Max            1493.1555
Q Predictions Min            -14.646104
V Predictions Mean           1046.5106
V Predictions Std            455.56097
V Predictions Max            1505.0175
V Predictions Min            -17.428938
Log Pis Mean                 0.048997186
Log Pis Std                  2.2342577
Log Pis Max                  10.909004
Log Pis Min                  -4.709262
Policy mu Mean               -0.06394284
Policy mu Std                0.9552868
Policy mu Max                2.6709878
Policy mu Min                -2.9991903
Policy log std Mean          -0.53993183
Policy log std Std           0.23929082
Policy log std Max           -0.0038309395
Policy log std Min           -2.1355834
Z mean eval                  0.008140296
Z variance eval              0.0016350994
total_rewards                [1281.81980268 1137.31861802 1671.95708321  928.0485219   896.86039362
  974.03900847  985.43084841  989.34906392 1284.68939328  925.30125252]
total_rewards_mean           1107.4813986039183
total_rewards_std            231.8889902696665
total_rewards_max            1671.9570832095817
total_rewards_min            896.860393615103
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.94055645726621
(Previous) Eval Time (s)     7.530748903285712
Sample Time (s)              23.137207354418933
Epoch Time (s)               62.60851271497086
Total Train Time (s)         6949.604610180017
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:33.301581 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #113 | Epoch Duration: 64.80521893501282
2020-01-11 01:58:33.301777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008288813
Z variance train             0.0016486241
KL Divergence                13.617985
KL Loss                      1.3617985
QF Loss                      2001.7429
VF Loss                      56.82103
Policy Loss                  -1020.3516
Q Predictions Mean           1015.3799
Q Predictions Std            476.88037
Q Predictions Max            1521.6047
Q Predictions Min            -0.1374065
V Predictions Mean           1021.7202
V Predictions Std            475.31165
V Predictions Max            1523.7004
V Predictions Min            2.4700902
Log Pis Mean                 0.18895474
Log Pis Std                  2.0905404
Log Pis Max                  11.214855
Log Pis Min                  -4.331553
Policy mu Mean               0.036425058
Policy mu Std                0.9887475
Policy mu Max                2.8246982
Policy mu Min                -2.991194
Policy log std Mean          -0.49842724
Policy log std Std           0.21370628
Policy log std Max           0.035796106
Policy log std Min           -1.4759556
Z mean eval                  0.015475534
Z variance eval              0.0013729368
total_rewards                [1677.44637227  958.68321869  961.84656614 1440.52658615 1459.64932547
  887.19238969  968.19748319 1478.05502065  972.80825869 1153.14542592]
total_rewards_mean           1195.755064685905
total_rewards_std            273.98969730715925
total_rewards_max            1677.44637227445
total_rewards_min            887.1923896924401
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               31.790207100100815
(Previous) Eval Time (s)     9.727124707773328
Sample Time (s)              22.560329841915518
Epoch Time (s)               64.07766164978966
Total Train Time (s)         7014.309342572931
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:59:38.007949 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #114 | Epoch Duration: 64.70601773262024
2020-01-11 01:59:38.008131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015547663
Z variance train             0.0013700814
KL Divergence                14.0515995
KL Loss                      1.40516
QF Loss                      287.18512
VF Loss                      78.48245
Policy Loss                  -1011.66205
Q Predictions Mean           1008.13184
Q Predictions Std            510.14926
Q Predictions Max            1515.8433
Q Predictions Min            -5.0808
V Predictions Mean           1014.0708
V Predictions Std            511.37708
V Predictions Max            1510.49
V Predictions Min            0.37170532
Log Pis Mean                 -0.20607594
Log Pis Std                  1.9849283
Log Pis Max                  7.4775534
Log Pis Min                  -4.1443925
Policy mu Mean               0.054511327
Policy mu Std                0.8475437
Policy mu Max                3.1883266
Policy mu Min                -2.6019433
Policy log std Mean          -0.49054408
Policy log std Std           0.2257095
Policy log std Max           -0.058217615
Policy log std Min           -1.7167727
Z mean eval                  0.014993245
Z variance eval              0.0014653915
total_rewards                [1435.15428169  820.26897686  866.18700241 1902.4692132  1181.27613579
  794.93408225  833.96754469 1131.64166479 1047.67393243 1077.46990812]
total_rewards_mean           1109.1042742234683
total_rewards_std            326.0468409247047
total_rewards_max            1902.4692132021805
total_rewards_min            794.9340822545124
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               31.322141360957175
(Previous) Eval Time (s)     10.355155729223043
Sample Time (s)              23.576901051215827
Epoch Time (s)               65.25419814139605
Total Train Time (s)         7078.48516667122
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:00:42.185586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #115 | Epoch Duration: 64.17728352546692
2020-01-11 02:00:42.185895 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01451539
Z variance train             0.001468579
KL Divergence                13.938511
KL Loss                      1.3938512
QF Loss                      245.79144
VF Loss                      100.586174
Policy Loss                  -992.7171
Q Predictions Mean           989.5813
Q Predictions Std            500.59622
Q Predictions Max            1524.6428
Q Predictions Min            -2.6442692
V Predictions Mean           989.60065
V Predictions Std            495.90366
V Predictions Max            1514.2711
V Predictions Min            5.390441
Log Pis Mean                 0.21993822
Log Pis Std                  2.3564339
Log Pis Max                  11.930284
Log Pis Min                  -4.3432837
Policy mu Mean               -0.00259092
Policy mu Std                0.9796575
Policy mu Max                2.7239077
Policy mu Min                -3.4738917
Policy log std Mean          -0.5216593
Policy log std Std           0.22766137
Policy log std Max           -0.06410721
Policy log std Min           -1.5279131
Z mean eval                  0.009273229
Z variance eval              0.00206452
total_rewards                [1111.98644972 1035.60006304 1238.27061794 1239.91473158 1826.27743152
 1993.06849418 1619.41011631 1095.05145751 1024.56308453 1496.63897356]
total_rewards_mean           1368.0781419887976
total_rewards_std            328.9683607911398
total_rewards_max            1993.0684941769957
total_rewards_min            1024.5630845349986
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               32.01394703518599
(Previous) Eval Time (s)     9.277897550258785
Sample Time (s)              22.013478544540703
Epoch Time (s)               63.30532312998548
Total Train Time (s)         7145.506930813193
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:49.209388 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #116 | Epoch Duration: 67.02325630187988
2020-01-11 02:01:49.209634 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009221818
Z variance train             0.0019789413
KL Divergence                13.236684
KL Loss                      1.3236684
QF Loss                      168.23112
VF Loss                      74.95471
Policy Loss                  -1028.6224
Q Predictions Mean           1028.6199
Q Predictions Std            487.58572
Q Predictions Max            1530.9756
Q Predictions Min            -0.861689
V Predictions Mean           1026.7671
V Predictions Std            485.44928
V Predictions Max            1534.4541
V Predictions Min            1.2374693
Log Pis Mean                 0.060008246
Log Pis Std                  2.2461417
Log Pis Max                  9.123295
Log Pis Min                  -4.4950957
Policy mu Mean               0.12183096
Policy mu Std                0.9527239
Policy mu Max                2.4727228
Policy mu Min                -2.9915226
Policy log std Mean          -0.51585686
Policy log std Std           0.21483397
Policy log std Max           -0.050372154
Policy log std Min           -1.4722829
Z mean eval                  0.016673477
Z variance eval              0.001946444
total_rewards                [ 848.42547586  903.73756898  978.03548575  859.26697477 1244.65548667
  852.29219786  837.34932892  992.12633252 1364.22582809  995.13785719]
total_rewards_mean           987.5252536615277
total_rewards_std            170.8357559200066
total_rewards_max            1364.2258280940725
total_rewards_min            837.3493289173757
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               32.26851281709969
(Previous) Eval Time (s)     12.995484303683043
Sample Time (s)              24.06397003447637
Epoch Time (s)               69.3279671552591
Total Train Time (s)         7210.774957962334
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:54.479106 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #117 | Epoch Duration: 65.26930952072144
2020-01-11 02:02:54.479371 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016226519
Z variance train             0.002125504
KL Divergence                13.204731
KL Loss                      1.3204731
QF Loss                      1043.7128
VF Loss                      346.11328
Policy Loss                  -1016.4578
Q Predictions Mean           1011.1964
Q Predictions Std            483.6621
Q Predictions Max            1523.4613
Q Predictions Min            3.2530553
V Predictions Mean           1015.4494
V Predictions Std            482.36826
V Predictions Max            1520.1779
V Predictions Min            2.275794
Log Pis Mean                 -0.07876699
Log Pis Std                  2.1004462
Log Pis Max                  8.503837
Log Pis Min                  -4.980546
Policy mu Mean               0.08329234
Policy mu Std                0.9053098
Policy mu Max                2.2758927
Policy mu Min                -2.9102068
Policy log std Mean          -0.5086896
Policy log std Std           0.22149362
Policy log std Max           0.037820965
Policy log std Min           -1.453189
Z mean eval                  0.058757216
Z variance eval              0.0009230355
total_rewards                [ 730.76809159 1006.85919106  807.98808839  833.62713744  868.52086976
  978.55959487  784.7608058  1026.97854438  762.14905847  995.76230848]
total_rewards_mean           879.5973690246686
total_rewards_std            106.53950947890264
total_rewards_max            1026.9785443794717
total_rewards_min            730.7680915943478
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               31.45408810582012
(Previous) Eval Time (s)     8.936473555862904
Sample Time (s)              22.484086482785642
Epoch Time (s)               62.874648144468665
Total Train Time (s)         7272.924173371866
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:56.630186 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #118 | Epoch Duration: 62.15067219734192
2020-01-11 02:03:56.630356 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010931804
Z variance train             0.0017212725
KL Divergence                13.751047
KL Loss                      1.3751048
QF Loss                      2518.4634
VF Loss                      377.49515
Policy Loss                  -1077.3207
Q Predictions Mean           1078.9214
Q Predictions Std            429.3936
Q Predictions Max            1503.7627
Q Predictions Min            -3.7190237
V Predictions Mean           1091.5303
V Predictions Std            432.1722
V Predictions Max            1521.4424
V Predictions Min            -1.8837973
Log Pis Mean                 -0.21515378
Log Pis Std                  1.8923036
Log Pis Max                  7.850074
Log Pis Min                  -4.655223
Policy mu Mean               0.18547674
Policy mu Std                0.85460854
Policy mu Max                2.5870388
Policy mu Min                -3.014444
Policy log std Mean          -0.5453106
Policy log std Std           0.20907035
Policy log std Max           -0.09279969
Policy log std Min           -1.430069
Z mean eval                  0.012085396
Z variance eval              0.0017969297
total_rewards                [1165.96091262 1663.76497942  988.31370779  910.86825532 1014.96234906
 1223.30021179  769.82974238 1238.82025182  873.75449372 1028.39999046]
total_rewards_mean           1087.7974894370695
total_rewards_std            239.9935045382131
total_rewards_max            1663.764979418189
total_rewards_min            769.829742377509
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.22008751705289
(Previous) Eval Time (s)     8.212185979355127
Sample Time (s)              23.628883763682097
Epoch Time (s)               64.06115726009011
Total Train Time (s)         7338.607638916001
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:05:02.316695 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #119 | Epoch Duration: 65.68618369102478
2020-01-11 02:05:02.316938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011970672
Z variance train             0.001778977
KL Divergence                13.660357
KL Loss                      1.3660358
QF Loss                      206.19165
VF Loss                      60.030304
Policy Loss                  -1043.1838
Q Predictions Mean           1043.4774
Q Predictions Std            478.01807
Q Predictions Max            1519.6721
Q Predictions Min            -21.861252
V Predictions Mean           1045.1467
V Predictions Std            477.79724
V Predictions Max            1527.0188
V Predictions Min            -2.6772637
Log Pis Mean                 -0.15610294
Log Pis Std                  2.1155884
Log Pis Max                  7.9033093
Log Pis Min                  -5.350089
Policy mu Mean               0.043104205
Policy mu Std                0.8936925
Policy mu Max                2.4064407
Policy mu Min                -2.7718704
Policy log std Mean          -0.501295
Policy log std Std           0.22287525
Policy log std Max           -0.05186519
Policy log std Min           -1.7888964
Z mean eval                  0.011831638
Z variance eval              0.0017116113
total_rewards                [1142.43588791  944.23003823 1668.88321525 1067.91301149 1142.62645714
 1379.65639854  923.71748611 1021.34486893  857.91446688  843.40694431]
total_rewards_mean           1099.2128774804596
total_rewards_std            243.40272171678808
total_rewards_max            1668.8832152535392
total_rewards_min            843.4069443147115
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               32.66987591981888
(Previous) Eval Time (s)     9.836816066876054
Sample Time (s)              21.942647963296622
Epoch Time (s)               64.44933994999155
Total Train Time (s)         7403.225088127889
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:06.935377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #120 | Epoch Duration: 64.61825370788574
2020-01-11 02:06:06.935580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0118683595
Z variance train             0.0017128948
KL Divergence                13.917116
KL Loss                      1.3917116
QF Loss                      282.35452
VF Loss                      62.985203
Policy Loss                  -1055.2391
Q Predictions Mean           1051.001
Q Predictions Std            490.9184
Q Predictions Max            1565.3699
Q Predictions Min            -11.997095
V Predictions Mean           1057.0337
V Predictions Std            490.88235
V Predictions Max            1564.0338
V Predictions Min            -9.97756
Log Pis Mean                 -0.23499975
Log Pis Std                  2.1617177
Log Pis Max                  6.923059
Log Pis Min                  -5.2501483
Policy mu Mean               0.045189787
Policy mu Std                0.89145917
Policy mu Max                2.7126646
Policy mu Min                -2.9016523
Policy log std Mean          -0.5412433
Policy log std Std           0.23407833
Policy log std Max           -0.036788553
Policy log std Min           -2.1023076
Z mean eval                  0.01767407
Z variance eval              0.0016832463
total_rewards                [1124.18841713 1325.28796452 1040.84836894 1478.40515231 1082.20065149
  961.208122   1112.01452466 1260.34118245 1263.13284769 1208.52747807]
total_rewards_mean           1185.6154709249117
total_rewards_std            144.4137174601429
total_rewards_max            1478.405152314057
total_rewards_min            961.208121995494
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.783707682043314
(Previous) Eval Time (s)     10.00541721796617
Sample Time (s)              22.732796298805624
Epoch Time (s)               64.52192119881511
Total Train Time (s)         7468.762702585198
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:12.475273 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #121 | Epoch Duration: 65.53948760032654
2020-01-11 02:07:12.475467 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017513977
Z variance train             0.0016843078
KL Divergence                13.981091
KL Loss                      1.3981091
QF Loss                      440.8786
VF Loss                      125.94873
Policy Loss                  -1036.0515
Q Predictions Mean           1035.9849
Q Predictions Std            484.4045
Q Predictions Max            1519.9005
Q Predictions Min            -2.996539
V Predictions Mean           1042.4412
V Predictions Std            485.39343
V Predictions Max            1525.6715
V Predictions Min            -6.3103323
Log Pis Mean                 0.06647447
Log Pis Std                  2.196917
Log Pis Max                  10.151892
Log Pis Min                  -5.1187773
Policy mu Mean               0.12844642
Policy mu Std                0.94118476
Policy mu Max                2.9590824
Policy mu Min                -2.643815
Policy log std Mean          -0.5328174
Policy log std Std           0.21844201
Policy log std Max           -0.08885679
Policy log std Min           -1.6272638
Z mean eval                  0.012329834
Z variance eval              0.0017302148
total_rewards                [ 995.71491849 1005.33221669  925.55423987  990.21178289 1016.65062101
 1298.72461017  997.92673395  835.66985421 1436.32673363 1226.64386169]
total_rewards_mean           1072.8755572610949
total_rewards_std            176.30856362341683
total_rewards_max            1436.3267336331758
total_rewards_min            835.669854213437
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               32.313166114035994
(Previous) Eval Time (s)     11.022679736837745
Sample Time (s)              23.584591909777373
Epoch Time (s)               66.92043776065111
Total Train Time (s)         7534.365878439043
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:18.080220 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #122 | Epoch Duration: 65.60460186004639
2020-01-11 02:08:18.080393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0129089635
Z variance train             0.0017307943
KL Divergence                13.722155
KL Loss                      1.3722155
QF Loss                      635.80786
VF Loss                      69.57859
Policy Loss                  -1089.138
Q Predictions Mean           1085.6304
Q Predictions Std            458.99582
Q Predictions Max            1528.2812
Q Predictions Min            -4.787218
V Predictions Mean           1085.3481
V Predictions Std            456.61636
V Predictions Max            1523.0677
V Predictions Min            -1.7210218
Log Pis Mean                 -0.053543538
Log Pis Std                  2.1846259
Log Pis Max                  9.933333
Log Pis Min                  -6.101736
Policy mu Mean               0.025762396
Policy mu Std                0.917331
Policy mu Max                3.4539566
Policy mu Min                -2.869881
Policy log std Mean          -0.52169913
Policy log std Std           0.22796501
Policy log std Max           -0.08212507
Policy log std Min           -2.3520281
Z mean eval                  0.015246754
Z variance eval              0.0016154039
total_rewards                [1242.0887118  1169.28458305 1098.29842333  970.04427224 1011.58971346
 1249.17467487 1053.19260164 1154.05729458 1082.53864536 1119.26219718]
total_rewards_mean           1114.9531117513638
total_rewards_std            86.89275209952413
total_rewards_max            1249.174674873941
total_rewards_min            970.0442722430818
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               31.219034072943032
(Previous) Eval Time (s)     9.70650112722069
Sample Time (s)              23.1221858356148
Epoch Time (s)               64.04772103577852
Total Train Time (s)         7598.996479134541
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:22.712727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #123 | Epoch Duration: 64.63220429420471
2020-01-11 02:09:22.712888 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015395123
Z variance train             0.0016244797
KL Divergence                13.915152
KL Loss                      1.3915151
QF Loss                      197.46732
VF Loss                      101.53409
Policy Loss                  -1119.317
Q Predictions Mean           1115.4585
Q Predictions Std            399.31577
Q Predictions Max            1511.0533
Q Predictions Min            3.5539765
V Predictions Mean           1122.3577
V Predictions Std            400.1233
V Predictions Max            1536.6407
V Predictions Min            1.114053
Log Pis Mean                 0.30531174
Log Pis Std                  2.2960312
Log Pis Max                  7.66455
Log Pis Min                  -6.310295
Policy mu Mean               0.088049956
Policy mu Std                1.0101148
Policy mu Max                2.7015157
Policy mu Min                -2.8733459
Policy log std Mean          -0.55193347
Policy log std Std           0.22570477
Policy log std Max           0.040087074
Policy log std Min           -1.3799541
Z mean eval                  0.018248988
Z variance eval              0.001615212
total_rewards                [3091.3024236  1814.37070346 3136.05861814 3178.82015366 3120.52652446
 3030.91416771 1986.54756373 3078.0928091  3041.94961754 2993.06512787]
total_rewards_mean           2847.164770924867
total_rewards_std            477.6431725648466
total_rewards_max            3178.8201536566667
total_rewards_min            1814.3707034579345
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.0307574570179
(Previous) Eval Time (s)     10.290649722795933
Sample Time (s)              22.5216928855516
Epoch Time (s)               64.84310006536543
Total Train Time (s)         7681.379150646273
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:10:45.097709 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #124 | Epoch Duration: 82.38468503952026
2020-01-11 02:10:45.097896 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018059835
Z variance train             0.0016155426
KL Divergence                13.847304
KL Loss                      1.3847305
QF Loss                      199.93582
VF Loss                      115.62548
Policy Loss                  -1026.727
Q Predictions Mean           1027.0938
Q Predictions Std            511.29782
Q Predictions Max            1530.3448
Q Predictions Min            -16.421013
V Predictions Mean           1032.9229
V Predictions Std            514.20764
V Predictions Max            1537.3065
V Predictions Min            -3.608399
Log Pis Mean                 -0.2282278
Log Pis Std                  1.9597675
Log Pis Max                  8.105992
Log Pis Min                  -6.0172253
Policy mu Mean               0.04942952
Policy mu Std                0.8547444
Policy mu Max                2.268026
Policy mu Min                -2.70035
Policy log std Mean          -0.5171315
Policy log std Std           0.23748271
Policy log std Max           -0.048618317
Policy log std Min           -2.442593
Z mean eval                  0.022705799
Z variance eval              0.0017171141
total_rewards                [ 897.95830468 1466.61330131  943.91387915 1523.02171503 1165.16729781
  999.72729963 1275.07590261  720.83717253  833.33153805  924.11237068]
total_rewards_mean           1074.9758781480718
total_rewards_std            257.49568548003083
total_rewards_max            1523.0217150297815
total_rewards_min            720.8371725289066
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               31.79499982483685
(Previous) Eval Time (s)     27.831907426938415
Sample Time (s)              23.926759398542345
Epoch Time (s)               83.55366665031761
Total Train Time (s)         7746.586953735445
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:50.310923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #125 | Epoch Duration: 65.21285891532898
2020-01-11 02:11:50.311236 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022087822
Z variance train             0.0017171638
KL Divergence                13.603188
KL Loss                      1.3603188
QF Loss                      178.37726
VF Loss                      59.778786
Policy Loss                  -1085.6147
Q Predictions Mean           1086.7635
Q Predictions Std            466.2519
Q Predictions Max            1547.7196
Q Predictions Min            -0.9122055
V Predictions Mean           1088.7854
V Predictions Std            466.35287
V Predictions Max            1549.8896
V Predictions Min            3.1541278
Log Pis Mean                 -0.083429605
Log Pis Std                  2.11071
Log Pis Max                  10.514832
Log Pis Min                  -8.5966835
Policy mu Mean               0.0044377837
Policy mu Std                0.9272685
Policy mu Max                2.4478002
Policy mu Min                -2.740712
Policy log std Mean          -0.5235311
Policy log std Std           0.21823291
Policy log std Max           -0.024350852
Policy log std Min           -1.3167577
Z mean eval                  0.027093718
Z variance eval              0.0016332308
total_rewards                [1232.29553049 1001.34619582 1057.33657748  990.54198711 1445.59970695
  910.40507342 1007.55399618  931.83650466 1519.85203681 2029.15428172]
total_rewards_mean           1212.5921890646537
total_rewards_std            338.5380222016996
total_rewards_max            2029.1542817231116
total_rewards_min            910.4050734217466
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               31.711685802787542
(Previous) Eval Time (s)     9.49073030706495
Sample Time (s)              23.585667585022748
Epoch Time (s)               64.78808369487524
Total Train Time (s)         7813.051162790041
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:12:56.776013 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #126 | Epoch Duration: 66.46455216407776
2020-01-11 02:12:56.776199 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027351957
Z variance train             0.0016324859
KL Divergence                13.695583
KL Loss                      1.3695583
QF Loss                      161.58911
VF Loss                      96.52931
Policy Loss                  -1049.4938
Q Predictions Mean           1041.0474
Q Predictions Std            475.79773
Q Predictions Max            1516.7845
Q Predictions Min            -21.905752
V Predictions Mean           1044.1725
V Predictions Std            475.17636
V Predictions Max            1517.8745
V Predictions Min            -0.002569884
Log Pis Mean                 -0.020739269
Log Pis Std                  2.3514006
Log Pis Max                  7.8385196
Log Pis Min                  -7.695715
Policy mu Mean               0.066449724
Policy mu Std                0.93088025
Policy mu Max                2.5813413
Policy mu Min                -2.6500175
Policy log std Mean          -0.52150506
Policy log std Std           0.21453507
Policy log std Max           0.04557553
Policy log std Min           -1.3102447
Z mean eval                  0.012843115
Z variance eval              0.0016933011
total_rewards                [1064.44530441  989.45170221 1003.11378628 1255.84439534  935.80663597
  864.47740887  925.91154156  927.7477426   961.57217496 1023.43264149]
total_rewards_mean           995.1803333684662
total_rewards_std            102.33311182777095
total_rewards_max            1255.8443953382994
total_rewards_min            864.4774088694196
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.01371492398903
(Previous) Eval Time (s)     11.1668521608226
Sample Time (s)              23.155731444247067
Epoch Time (s)               66.3362985290587
Total Train Time (s)         7876.307691602036
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:14:00.034386 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #127 | Epoch Duration: 63.25804305076599
2020-01-11 02:14:00.034567 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0123462435
Z variance train             0.0016924407
KL Divergence                13.580257
KL Loss                      1.3580258
QF Loss                      256.22903
VF Loss                      80.07342
Policy Loss                  -1100.7764
Q Predictions Mean           1097.5273
Q Predictions Std            474.6948
Q Predictions Max            1546.8074
Q Predictions Min            -23.039097
V Predictions Mean           1099.1545
V Predictions Std            469.70007
V Predictions Max            1536.4891
V Predictions Min            -5.969883
Log Pis Mean                 -0.12799023
Log Pis Std                  2.1039052
Log Pis Max                  8.467161
Log Pis Min                  -4.025258
Policy mu Mean               0.104334675
Policy mu Std                0.9034049
Policy mu Max                3.5620549
Policy mu Min                -2.7611837
Policy log std Mean          -0.5273661
Policy log std Std           0.21659991
Policy log std Max           0.0076779723
Policy log std Min           -1.3160105
Z mean eval                  0.015624769
Z variance eval              0.0016820973
total_rewards                [1007.88707922 1002.4017447  1490.86148528 1119.30237918 1415.09822203
  951.76976872  859.67539289  811.89596691  998.51515215 2046.90859195]
total_rewards_mean           1170.4315783037002
total_rewards_std            359.23577458534027
total_rewards_max            2046.9085919497152
total_rewards_min            811.8959669072943
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               31.793992259074003
(Previous) Eval Time (s)     8.08826394379139
Sample Time (s)              23.521880402695388
Epoch Time (s)               63.40413660556078
Total Train Time (s)         7942.368080222048
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:06.097769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #128 | Epoch Duration: 66.0630521774292
2020-01-11 02:15:06.097991 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015586875
Z variance train             0.0016809234
KL Divergence                13.6012535
KL Loss                      1.3601254
QF Loss                      356.72693
VF Loss                      65.860374
Policy Loss                  -1104.6504
Q Predictions Mean           1098.835
Q Predictions Std            464.39743
Q Predictions Max            1534.7969
Q Predictions Min            -2.285679
V Predictions Mean           1102.739
V Predictions Std            460.22305
V Predictions Max            1535.6562
V Predictions Min            -0.32931232
Log Pis Mean                 -0.03930609
Log Pis Std                  2.1082976
Log Pis Max                  7.512782
Log Pis Min                  -4.600913
Policy mu Mean               0.063700974
Policy mu Std                0.91338825
Policy mu Max                2.3199298
Policy mu Min                -2.8945458
Policy log std Mean          -0.5119919
Policy log std Std           0.21633683
Policy log std Max           0.041646123
Policy log std Min           -1.4545312
Z mean eval                  0.015268716
Z variance eval              0.0013930784
total_rewards                [1053.00218473 1169.91598951 1913.35414711 1702.18257839 1901.95221959
 1051.73911483 1262.5338404  1187.21822124 1500.59488015 1371.42027503]
total_rewards_mean           1411.3913450984762
total_rewards_std            312.28931060417364
total_rewards_max            1913.3541471064375
total_rewards_min            1051.739114834511
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               31.74748288700357
(Previous) Eval Time (s)     10.746805590111762
Sample Time (s)              22.963151883799583
Epoch Time (s)               65.45744036091492
Total Train Time (s)         8009.873048410751
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:13.604613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #129 | Epoch Duration: 67.50646448135376
2020-01-11 02:16:13.604813 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046057582
Z variance train             0.0007900768
KL Divergence                15.520246
KL Loss                      1.5520246
QF Loss                      215.34293
VF Loss                      84.93751
Policy Loss                  -1095.1459
Q Predictions Mean           1103.97
Q Predictions Std            479.9296
Q Predictions Max            1541.096
Q Predictions Min            -1.3844973
V Predictions Mean           1100.2502
V Predictions Std            477.6922
V Predictions Max            1525.0085
V Predictions Min            -0.88358516
Log Pis Mean                 0.029625587
Log Pis Std                  2.180784
Log Pis Max                  9.290806
Log Pis Min                  -3.906745
Policy mu Mean               0.057418276
Policy mu Std                0.9102106
Policy mu Max                2.4005349
Policy mu Min                -2.8779821
Policy log std Mean          -0.5133588
Policy log std Std           0.21424018
Policy log std Max           0.037441283
Policy log std Min           -1.1997708
Z mean eval                  0.021067237
Z variance eval              0.0015261802
total_rewards                [ 916.5314996  1077.47891811 1527.61776493 1233.4896156  1252.93973757
 1042.30601526  811.88514634  938.97215523 1128.15535992  824.79562036]
total_rewards_mean           1075.4171832922434
total_rewards_std            209.9977716821851
total_rewards_max            1527.6177649319316
total_rewards_min            811.8851463431739
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               31.599049620795995
(Previous) Eval Time (s)     12.795523267704993
Sample Time (s)              23.822846819646657
Epoch Time (s)               68.21741970814764
Total Train Time (s)         8074.889944231138
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:18.625832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #130 | Epoch Duration: 65.02080631256104
2020-01-11 02:17:18.626110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021214763
Z variance train             0.0015263979
KL Divergence                13.995815
KL Loss                      1.3995816
QF Loss                      233.77408
VF Loss                      108.56071
Policy Loss                  -1128.8438
Q Predictions Mean           1125.7745
Q Predictions Std            438.0885
Q Predictions Max            1512.2703
Q Predictions Min            -1.6888558
V Predictions Mean           1129.0588
V Predictions Std            433.1278
V Predictions Max            1517.5148
V Predictions Min            1.2967297
Log Pis Mean                 -0.16153136
Log Pis Std                  2.304201
Log Pis Max                  19.053461
Log Pis Min                  -5.0771065
Policy mu Mean               0.098629914
Policy mu Std                0.912838
Policy mu Max                3.7670798
Policy mu Min                -4.252835
Policy log std Mean          -0.48573756
Policy log std Std           0.2145571
Policy log std Max           0.07967913
Policy log std Min           -1.3581557
Z mean eval                  0.020006867
Z variance eval              0.0016193573
total_rewards                [ 885.83716716 1213.92403192  985.10023659 1227.29713998 1249.21894491
  885.97046411  889.46123102 1460.93137624  926.30039292  999.19585253]
total_rewards_mean           1072.3236837373543
total_rewards_std            190.68223139038432
total_rewards_max            1460.931376241995
total_rewards_min            885.8371671632615
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               32.026851159054786
(Previous) Eval Time (s)     9.598528574220836
Sample Time (s)              21.41695816628635
Epoch Time (s)               63.04233789956197
Total Train Time (s)         8138.212771337479
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:18:21.951696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #131 | Epoch Duration: 63.3254029750824
2020-01-11 02:18:21.951934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017586488
Z variance train             0.0015880767
KL Divergence                14.106812
KL Loss                      1.4106811
QF Loss                      250.30316
VF Loss                      79.826775
Policy Loss                  -1119.0839
Q Predictions Mean           1119.0684
Q Predictions Std            448.68872
Q Predictions Max            1542.8663
Q Predictions Min            -14.19904
V Predictions Mean           1123.5068
V Predictions Std            448.49512
V Predictions Max            1540.8086
V Predictions Min            0.2475358
Log Pis Mean                 -0.22174433
Log Pis Std                  2.0676436
Log Pis Max                  13.9396515
Log Pis Min                  -4.506854
Policy mu Mean               0.09107027
Policy mu Std                0.90115273
Policy mu Max                3.2324157
Policy mu Min                -3.4135888
Policy log std Mean          -0.5046299
Policy log std Std           0.19194019
Policy log std Max           -0.030393153
Policy log std Min           -1.2080388
Z mean eval                  0.01691896
Z variance eval              0.0015055025
total_rewards                [1255.93626665 1226.4256134   798.57386774 1246.75034858  988.84103603
 1093.96007174 1222.21989395 1121.10467407 1043.88040501 1460.97361253]
total_rewards_mean           1145.8665789696652
total_rewards_std            171.1381798334614
total_rewards_max            1460.9736125283175
total_rewards_min            798.5738677352253
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               31.67612946825102
(Previous) Eval Time (s)     9.881253705359995
Sample Time (s)              22.843150994274765
Epoch Time (s)               64.40053416788578
Total Train Time (s)         8202.804516378324
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:19:26.545134 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #132 | Epoch Duration: 64.5930392742157
2020-01-11 02:19:26.545331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014798391
Z variance train             0.0015891099
KL Divergence                14.151285
KL Loss                      1.4151286
QF Loss                      1472.8776
VF Loss                      187.55847
Policy Loss                  -1050.7665
Q Predictions Mean           1054.4376
Q Predictions Std            490.16327
Q Predictions Max            1576.1765
Q Predictions Min            -2.7531085
V Predictions Mean           1057.824
V Predictions Std            489.032
V Predictions Max            1556.7987
V Predictions Min            0.13479814
Log Pis Mean                 -0.050401293
Log Pis Std                  2.0559227
Log Pis Max                  7.9995832
Log Pis Min                  -4.1298976
Policy mu Mean               0.06857737
Policy mu Std                0.91409016
Policy mu Max                3.0459328
Policy mu Min                -2.9179468
Policy log std Mean          -0.5026011
Policy log std Std           0.20979375
Policy log std Max           0.014392406
Policy log std Min           -2.0109737
Z mean eval                  0.016826982
Z variance eval              0.0015584504
total_rewards                [ 975.06289096  960.56118638 1116.5784696   978.1735507   950.03503938
  890.09596029  984.59178379 1225.338373   1000.25853358  962.14213889]
total_rewards_mean           1004.2837926557065
total_rewards_std            91.15052347176005
total_rewards_max            1225.3383730004186
total_rewards_min            890.0959602859305
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               31.924224191810936
(Previous) Eval Time (s)     10.07342731487006
Sample Time (s)              23.26737629622221
Epoch Time (s)               65.2650278029032
Total Train Time (s)         8266.787122534588
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:30.530622 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #133 | Epoch Duration: 63.985063314437866
2020-01-11 02:20:30.530928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015390855
Z variance train             0.0015933393
KL Divergence                14.128984
KL Loss                      1.4128984
QF Loss                      252.45724
VF Loss                      120.06457
Policy Loss                  -1075.5894
Q Predictions Mean           1075.1816
Q Predictions Std            477.25504
Q Predictions Max            1553.3939
Q Predictions Min            -6.59834
V Predictions Mean           1073.0684
V Predictions Std            476.63107
V Predictions Max            1550.9075
V Predictions Min            -4.444785
Log Pis Mean                 -0.068266466
Log Pis Std                  2.2081182
Log Pis Max                  10.214832
Log Pis Min                  -5.500793
Policy mu Mean               0.047657
Policy mu Std                0.9232386
Policy mu Max                2.9028888
Policy mu Min                -2.9898388
Policy log std Mean          -0.52107555
Policy log std Std           0.21787234
Policy log std Max           -0.05681795
Policy log std Min           -1.2294834
Z mean eval                  0.014705306
Z variance eval              0.0015269419
total_rewards                [1089.5373155   979.62881071  990.82031134  885.0923078   943.66586988
 1016.98226895 1083.8663667   214.70146496  221.57564457 1016.91953423]
total_rewards_mean           844.2789894637992
total_rewards_std            318.2215683217179
total_rewards_max            1089.537315501101
total_rewards_min            214.70146495552885
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               31.773135277908295
(Previous) Eval Time (s)     8.793094544205815
Sample Time (s)              23.585431691259146
Epoch Time (s)               64.15166151337326
Total Train Time (s)         8329.96267484082
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:33.707731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #134 | Epoch Duration: 63.176637172698975
2020-01-11 02:21:33.707919 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016254012
Z variance train             0.001527548
KL Divergence                14.08346
KL Loss                      1.408346
QF Loss                      210.57605
VF Loss                      135.45732
Policy Loss                  -1075.7476
Q Predictions Mean           1073.4312
Q Predictions Std            486.16772
Q Predictions Max            1554.2354
Q Predictions Min            1.1889468
V Predictions Mean           1077.2822
V Predictions Std            487.9692
V Predictions Max            1538.5144
V Predictions Min            1.1557292
Log Pis Mean                 -0.033922765
Log Pis Std                  2.077246
Log Pis Max                  8.842713
Log Pis Min                  -3.6738021
Policy mu Mean               0.038814675
Policy mu Std                0.9459272
Policy mu Max                2.126219
Policy mu Min                -2.6603866
Policy log std Mean          -0.49519607
Policy log std Std           0.21293014
Policy log std Max           0.00076186657
Policy log std Min           -1.3259228
Z mean eval                  0.026346311
Z variance eval              0.0024716132
total_rewards                [1249.69371951 2015.18809462 1070.15344583 1233.87089633 1009.54501684
  962.67338826 1767.70059657 1126.19993378 1377.15388907 1440.25487557]
total_rewards_mean           1325.2433856371738
total_rewards_std            322.1153129199985
total_rewards_max            2015.1880946178053
total_rewards_min            962.6733882631788
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               32.195932070259005
(Previous) Eval Time (s)     7.817748700268567
Sample Time (s)              21.581694283057004
Epoch Time (s)               61.595375053584576
Total Train Time (s)         8396.060298169032
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:39.807123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #135 | Epoch Duration: 66.09906840324402
2020-01-11 02:22:39.807307 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022377674
Z variance train             0.0023321467
KL Divergence                12.958223
KL Loss                      1.2958224
QF Loss                      186.32964
VF Loss                      75.649345
Policy Loss                  -1094.3286
Q Predictions Mean           1092.6653
Q Predictions Std            484.50314
Q Predictions Max            1556.4602
Q Predictions Min            1.60994
V Predictions Mean           1097.2922
V Predictions Std            483.88892
V Predictions Max            1561.4612
V Predictions Min            -0.605034
Log Pis Mean                 -0.15767732
Log Pis Std                  2.080028
Log Pis Max                  5.974038
Log Pis Min                  -4.519341
Policy mu Mean               -0.032017186
Policy mu Std                0.9612328
Policy mu Max                2.5208
Policy mu Min                -2.7472763
Policy log std Mean          -0.49401116
Policy log std Std           0.21356142
Policy log std Max           -0.073637396
Policy log std Min           -1.9510163
Z mean eval                  0.023493739
Z variance eval              0.0016458919
total_rewards                [1366.74805725  819.4284877   989.34918756 1250.93333859 1004.31985358
 1055.92406976 1043.56497161 1055.96253274 1208.56202397  996.56054428]
total_rewards_mean           1079.1353067042012
total_rewards_std            148.07195660572512
total_rewards_max            1366.7480572470963
total_rewards_min            819.4284877026794
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               31.422259150072932
(Previous) Eval Time (s)     12.321143839973956
Sample Time (s)              22.167293888982385
Epoch Time (s)               65.91069687902927
Total Train Time (s)         8459.31156805437
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:23:43.059554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #136 | Epoch Duration: 63.25211715698242
2020-01-11 02:23:43.059702 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022252506
Z variance train             0.0016476798
KL Divergence                14.052269
KL Loss                      1.405227
QF Loss                      160.4147
VF Loss                      100.99997
Policy Loss                  -1125.8035
Q Predictions Mean           1127.2888
Q Predictions Std            448.78918
Q Predictions Max            1566.8356
Q Predictions Min            4.5001607
V Predictions Mean           1128.6871
V Predictions Std            448.0559
V Predictions Max            1582.7733
V Predictions Min            5.2531447
Log Pis Mean                 -0.036351476
Log Pis Std                  1.9810696
Log Pis Max                  9.466751
Log Pis Min                  -4.243911
Policy mu Mean               0.14876775
Policy mu Std                0.93047667
Policy mu Max                2.588105
Policy mu Min                -2.673803
Policy log std Mean          -0.5382506
Policy log std Std           0.22203092
Policy log std Max           -0.036919326
Policy log std Min           -2.41738
Z mean eval                  0.023236426
Z variance eval              0.0016241223
total_rewards                [ 957.99463939  998.10470473  876.34680534  959.43521562  913.58395961
  965.71348835  838.65248991 1557.11096856  843.87608818 1240.55376621]
total_rewards_mean           1015.1372125901191
total_rewards_std            210.64236093247212
total_rewards_max            1557.1109685571516
total_rewards_min            838.6524899089094
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               32.056252853013575
(Previous) Eval Time (s)     9.662224673200399
Sample Time (s)              21.30139728449285
Epoch Time (s)               63.019874810706824
Total Train Time (s)         8520.202054053545
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:24:43.953276 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #137 | Epoch Duration: 60.89345574378967
2020-01-11 02:24:43.953470 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023260122
Z variance train             0.0016201793
KL Divergence                14.001175
KL Loss                      1.4001175
QF Loss                      305.24103
VF Loss                      109.60048
Policy Loss                  -1065.1849
Q Predictions Mean           1060.2
Q Predictions Std            500.9794
Q Predictions Max            1521.0714
Q Predictions Min            -0.4840059
V Predictions Mean           1059.9497
V Predictions Std            499.37634
V Predictions Max            1520.3585
V Predictions Min            -2.6481729
Log Pis Mean                 -0.3127696
Log Pis Std                  1.9705745
Log Pis Max                  6.5834074
Log Pis Min                  -6.3089104
Policy mu Mean               -0.050938338
Policy mu Std                0.85247725
Policy mu Max                2.1245449
Policy mu Min                -2.736879
Policy log std Mean          -0.50858396
Policy log std Std           0.23663357
Policy log std Max           0.012720495
Policy log std Min           -2.0591342
Z mean eval                  0.01032948
Z variance eval              0.0014423814
total_rewards                [1007.2353069   923.85626856  988.83053934  983.76682459  960.14522743
 1008.2383383   995.43137756  885.37526288 1147.07533748  993.6939248 ]
total_rewards_mean           989.3648407847113
total_rewards_std            64.49365975655012
total_rewards_max            1147.075337480885
total_rewards_min            885.3752628788711
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               31.687164755072445
(Previous) Eval Time (s)     7.535514818970114
Sample Time (s)              23.72973948577419
Epoch Time (s)               62.95241905981675
Total Train Time (s)         8584.83386451751
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:48.587027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #138 | Epoch Duration: 64.6334183216095
2020-01-11 02:25:48.587222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010466443
Z variance train             0.0014414487
KL Divergence                14.151023
KL Loss                      1.4151024
QF Loss                      207.97652
VF Loss                      53.89387
Policy Loss                  -1085.4331
Q Predictions Mean           1084.3425
Q Predictions Std            504.501
Q Predictions Max            1569.3674
Q Predictions Min            -10.66863
V Predictions Mean           1088.4402
V Predictions Std            504.64124
V Predictions Max            1575.6262
V Predictions Min            1.6608382
Log Pis Mean                 -0.081983976
Log Pis Std                  1.9284226
Log Pis Max                  8.8258915
Log Pis Min                  -4.2245474
Policy mu Mean               0.113812216
Policy mu Std                0.90557796
Policy mu Max                3.3643744
Policy mu Min                -3.124855
Policy log std Mean          -0.52858514
Policy log std Std           0.21824995
Policy log std Max           0.011799425
Policy log std Min           -1.5021102
Z mean eval                  0.024133513
Z variance eval              0.0018093595
total_rewards                [1269.11631713 1163.16166823  986.51324944  925.94148856  906.32656931
 2119.75848316 1191.12943261 1538.76501007 1049.82780727 1271.03144125]
total_rewards_mean           1242.1571467032982
total_rewards_std            344.0470696756804
total_rewards_max            2119.758483159519
total_rewards_min            906.3265693097735
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               31.939455308020115
(Previous) Eval Time (s)     9.216172656975687
Sample Time (s)              22.586457064840943
Epoch Time (s)               63.742085029836744
Total Train Time (s)         8650.460208999924
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:54.215740 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #139 | Epoch Duration: 65.62836980819702
2020-01-11 02:26:54.215930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021963112
Z variance train             0.001802989
KL Divergence                13.6556015
KL Loss                      1.3655602
QF Loss                      187.4055
VF Loss                      72.75143
Policy Loss                  -1158.4702
Q Predictions Mean           1154.532
Q Predictions Std            445.96625
Q Predictions Max            1560.8317
Q Predictions Min            -0.86276424
V Predictions Mean           1155.2891
V Predictions Std            443.3539
V Predictions Max            1561.4086
V Predictions Min            -0.6853879
Log Pis Mean                 -0.119441755
Log Pis Std                  2.021242
Log Pis Max                  7.6361527
Log Pis Min                  -4.5075126
Policy mu Mean               0.036712572
Policy mu Std                0.92920727
Policy mu Max                2.6860754
Policy mu Min                -3.224966
Policy log std Mean          -0.5307305
Policy log std Std           0.22231744
Policy log std Max           0.018395424
Policy log std Min           -2.1945643
Z mean eval                  0.015064272
Z variance eval              0.0016907919
total_rewards                [ 986.65333895  957.35968759  873.45816665  750.96211925  853.04486664
  992.35757213 1430.06834432  998.69282346 1237.84408208 1480.24543749]
total_rewards_mean           1056.0686438556652
total_rewards_std            232.89746628663895
total_rewards_max            1480.245437490138
total_rewards_min            750.9621192506816
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               31.669038340914994
(Previous) Eval Time (s)     11.102014233823866
Sample Time (s)              21.703532130923122
Epoch Time (s)               64.47458470566198
Total Train Time (s)         8712.49100044882
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:56.250313 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #140 | Epoch Duration: 62.034231185913086
2020-01-11 02:27:56.250551 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014619894
Z variance train             0.0016893176
KL Divergence                14.015877
KL Loss                      1.4015877
QF Loss                      1550.4269
VF Loss                      166.37427
Policy Loss                  -1086.9323
Q Predictions Mean           1085.4636
Q Predictions Std            451.39908
Q Predictions Max            1524.3085
Q Predictions Min            -5.8275833
V Predictions Mean           1093.579
V Predictions Std            451.66043
V Predictions Max            1531.9261
V Predictions Min            1.1801574
Log Pis Mean                 -0.011393227
Log Pis Std                  2.301458
Log Pis Max                  10.275006
Log Pis Min                  -6.836024
Policy mu Mean               0.070665285
Policy mu Std                0.9660585
Policy mu Max                2.5220861
Policy mu Min                -4.2592936
Policy log std Mean          -0.52632034
Policy log std Std           0.19821753
Policy log std Max           0.016811907
Policy log std Min           -1.1308477
Z mean eval                  0.021601828
Z variance eval              0.0016279578
total_rewards                [ 940.49781357  940.16650472  870.55569913  935.45396321  851.8616626
  865.27639823 1175.35818035  994.80397085 1239.31528236 1328.62605277]
total_rewards_mean           1014.1915527792138
total_rewards_std            161.9161407903804
total_rewards_max            1328.6260527686827
total_rewards_min            851.8616625975167
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               32.23410216299817
(Previous) Eval Time (s)     8.661319759208709
Sample Time (s)              22.876424768473953
Epoch Time (s)               63.77184669068083
Total Train Time (s)         8776.283825888764
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:29:00.046721 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #141 | Epoch Duration: 63.79597043991089
2020-01-11 02:29:00.047117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024936765
Z variance train             0.0016593415
KL Divergence                14.054287
KL Loss                      1.4054288
QF Loss                      189.94601
VF Loss                      135.53122
Policy Loss                  -1162.9542
Q Predictions Mean           1158.3235
Q Predictions Std            424.8971
Q Predictions Max            1524.9083
Q Predictions Min            -3.10632
V Predictions Mean           1155.8667
V Predictions Std            423.28925
V Predictions Max            1521.4252
V Predictions Min            -7.424117
Log Pis Mean                 -0.066910215
Log Pis Std                  2.0850089
Log Pis Max                  6.88352
Log Pis Min                  -5.124253
Policy mu Mean               0.05544686
Policy mu Std                0.8951602
Policy mu Max                2.302074
Policy mu Min                -3.2486963
Policy log std Mean          -0.5092408
Policy log std Std           0.20027943
Policy log std Max           -0.06868714
Policy log std Min           -1.8642217
Z mean eval                  0.024106368
Z variance eval              0.0017915476
total_rewards                [1154.11653958  980.42257388  865.59644822  852.70646171  845.8711434
  943.28030163  932.28499118  882.23459005  961.18089785  912.3647786 ]
total_rewards_mean           933.005872609206
total_rewards_std            85.80585704461609
total_rewards_max            1154.1165395753353
total_rewards_min            845.8711434023546
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               32.21273138420656
(Previous) Eval Time (s)     8.685017402749509
Sample Time (s)              24.426672723609954
Epoch Time (s)               65.32442151056603
Total Train Time (s)         8840.773917476181
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:04.536692 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #142 | Epoch Duration: 64.48926591873169
2020-01-11 02:30:04.536818 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02410973
Z variance train             0.0017827522
KL Divergence                13.999377
KL Loss                      1.3999377
QF Loss                      117.91435
VF Loss                      386.0344
Policy Loss                  -1115.4022
Q Predictions Mean           1111.6218
Q Predictions Std            476.61166
Q Predictions Max            1548.9629
Q Predictions Min            -22.090763
V Predictions Mean           1107.1511
V Predictions Std            471.46274
V Predictions Max            1534.4401
V Predictions Min            1.5736642
Log Pis Mean                 -0.21447274
Log Pis Std                  2.099544
Log Pis Max                  10.369804
Log Pis Min                  -4.3692555
Policy mu Mean               0.092188336
Policy mu Std                0.8871827
Policy mu Max                3.1210384
Policy mu Min                -3.8015597
Policy log std Mean          -0.4957912
Policy log std Std           0.20893121
Policy log std Max           -0.065077126
Policy log std Min           -2.2626143
Z mean eval                  0.03251758
Z variance eval              0.0012963241
total_rewards                [ 935.59632102  865.93029873 1151.61499597 1014.74887581  995.32856337
  982.8574746   873.87905805  749.06465787 1229.66451992 1065.90097441]
total_rewards_mean           986.4585739741073
total_rewards_std            134.07942026339808
total_rewards_max            1229.6645199166403
total_rewards_min            749.0646578669277
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               31.96341977501288
(Previous) Eval Time (s)     7.849527840036899
Sample Time (s)              23.19672228489071
Epoch Time (s)               63.00966989994049
Total Train Time (s)         8904.817998351064
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:31:08.583575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #143 | Epoch Duration: 64.04663634300232
2020-01-11 02:31:08.583758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013593738
Z variance train             0.0017267701
KL Divergence                13.794836
KL Loss                      1.3794836
QF Loss                      159.02899
VF Loss                      102.35739
Policy Loss                  -1103.041
Q Predictions Mean           1102.2595
Q Predictions Std            490.39093
Q Predictions Max            1545.9955
Q Predictions Min            -10.193071
V Predictions Mean           1106.3901
V Predictions Std            491.00568
V Predictions Max            1559.0421
V Predictions Min            -2.1841512
Log Pis Mean                 -0.026578352
Log Pis Std                  2.2570271
Log Pis Max                  12.943605
Log Pis Min                  -4.2776327
Policy mu Mean               0.08885745
Policy mu Std                0.9415504
Policy mu Max                3.0354717
Policy mu Min                -4.151617
Policy log std Mean          -0.49791202
Policy log std Std           0.21758266
Policy log std Max           0.06673643
Policy log std Min           -1.2992808
Z mean eval                  0.03757129
Z variance eval              0.00144975
total_rewards                [ 695.55750866  953.95350362  988.80726091  907.55571436 1149.03877936
 1097.34973194  872.01180711  880.87488071  970.14637414 1031.40544286]
total_rewards_mean           954.6701003666519
total_rewards_std            121.27142126480955
total_rewards_max            1149.038779357187
total_rewards_min            695.5575086558259
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               32.23869073903188
(Previous) Eval Time (s)     8.886194634716958
Sample Time (s)              22.520929171703756
Epoch Time (s)               63.645814545452595
Total Train Time (s)         8968.587399057578
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:12.354927 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #144 | Epoch Duration: 63.77103066444397
2020-01-11 02:32:12.355108 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03813706
Z variance train             0.0014661832
KL Divergence                14.036195
KL Loss                      1.4036195
QF Loss                      409.80847
VF Loss                      126.52938
Policy Loss                  -1124.5155
Q Predictions Mean           1125.9808
Q Predictions Std            476.1405
Q Predictions Max            1557.5885
Q Predictions Min            -3.3315349
V Predictions Mean           1123.9165
V Predictions Std            474.0261
V Predictions Max            1550.3617
V Predictions Min            2.0773807
Log Pis Mean                 -0.060688138
Log Pis Std                  2.1653895
Log Pis Max                  11.354614
Log Pis Min                  -6.908784
Policy mu Mean               0.03941046
Policy mu Std                0.927443
Policy mu Max                2.6053662
Policy mu Min                -3.0441794
Policy log std Mean          -0.5305688
Policy log std Std           0.22746797
Policy log std Max           0.00045883656
Policy log std Min           -1.3570514
Z mean eval                  0.022274897
Z variance eval              0.001713339
total_rewards                [ 997.48713116 1120.83300106 1002.05932429  985.81446206 1226.90505926
  874.43829768 1004.5075137   944.01639835  994.65204265  992.04405836]
total_rewards_mean           1014.2757288564783
total_rewards_std            91.25374546299918
total_rewards_max            1226.9050592609135
total_rewards_min            874.438297678115
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               33.484447611961514
(Previous) Eval Time (s)     9.011088322848082
Sample Time (s)              23.585103118792176
Epoch Time (s)               66.08063905360177
Total Train Time (s)         9034.97848110227
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:18.748645 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #145 | Epoch Duration: 66.39338517189026
2020-01-11 02:33:18.748840 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #145 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022392755
Z variance train             0.0017226379
KL Divergence                13.7425585
KL Loss                      1.3742559
QF Loss                      537.3234
VF Loss                      83.53306
Policy Loss                  -1113.0579
Q Predictions Mean           1111.9443
Q Predictions Std            486.09775
Q Predictions Max            1574.8451
Q Predictions Min            -1.2274263
V Predictions Mean           1114.8966
V Predictions Std            484.24612
V Predictions Max            1564.5591
V Predictions Min            1.5343192
Log Pis Mean                 -0.15018943
Log Pis Std                  2.1602833
Log Pis Max                  11.130956
Log Pis Min                  -4.1002836
Policy mu Mean               0.06908145
Policy mu Std                0.9141255
Policy mu Max                3.603528
Policy mu Min                -3.2571576
Policy log std Mean          -0.5267949
Policy log std Std           0.22607028
Policy log std Max           0.091864884
Policy log std Min           -1.4337041
Z mean eval                  0.03592139
Z variance eval              0.0020061175
total_rewards                [910.6655009  863.70074444 830.88863749 973.56001609 986.29521341
 910.40187556 885.43964919 928.47964571 924.09737742 887.64102577]
total_rewards_mean           910.116968597937
total_rewards_std            44.61714857995639
total_rewards_max            986.2952134145911
total_rewards_min            830.8886374858342
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               34.01703254878521
(Previous) Eval Time (s)     9.32347134128213
Sample Time (s)              24.377818550914526
Epoch Time (s)               67.71832244098186
Total Train Time (s)         9102.011581293773
Epoch                        146
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:25.784027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #146 | Epoch Duration: 67.03504300117493
2020-01-11 02:34:25.784226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036247797
Z variance train             0.002028045
KL Divergence                13.283173
KL Loss                      1.3283173
QF Loss                      146.4082
VF Loss                      57.934437
Policy Loss                  -1090.7396
Q Predictions Mean           1090.2544
Q Predictions Std            484.54437
Q Predictions Max            1563.2632
Q Predictions Min            -5.01447
V Predictions Mean           1089.3008
V Predictions Std            481.15088
V Predictions Max            1546.6172
V Predictions Min            -3.993529
Log Pis Mean                 -0.10526712
Log Pis Std                  2.024103
Log Pis Max                  8.330046
Log Pis Min                  -6.2170286
Policy mu Mean               0.043930043
Policy mu Std                0.8800344
Policy mu Max                2.5802085
Policy mu Min                -2.8506653
Policy log std Mean          -0.5192392
Policy log std Std           0.21191722
Policy log std Max           0.021837294
Policy log std Min           -1.3466656
Z mean eval                  0.019367706
Z variance eval              0.0023469757
total_rewards                [ 995.82028508  888.64653977  825.64669797 1040.17847813 1498.53806628
 1125.02505239 1146.55980237 1074.50165285 1061.47160855 1078.40852238]
total_rewards_mean           1073.479670578226
total_rewards_std            170.75310290536763
total_rewards_max            1498.5380662804018
total_rewards_min            825.6466979689776
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               34.63062167633325
(Previous) Eval Time (s)     8.639778611715883
Sample Time (s)              24.48816874437034
Epoch Time (s)               67.75856903241947
Total Train Time (s)         9171.011742530856
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:34.786206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #147 | Epoch Duration: 69.00184226036072
2020-01-11 02:35:34.786383 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020414758
Z variance train             0.0023176833
KL Divergence                12.904889
KL Loss                      1.290489
QF Loss                      116.3688
VF Loss                      49.62477
Policy Loss                  -1163.9741
Q Predictions Mean           1162.0864
Q Predictions Std            455.75076
Q Predictions Max            1575.0217
Q Predictions Min            -14.094016
V Predictions Mean           1162.6145
V Predictions Std            453.7599
V Predictions Max            1568.1598
V Predictions Min            -5.096978
Log Pis Mean                 0.1256409
Log Pis Std                  2.2678745
Log Pis Max                  7.5365753
Log Pis Min                  -4.8253207
Policy mu Mean               0.11441631
Policy mu Std                0.9663314
Policy mu Max                2.5394478
Policy mu Min                -2.8041778
Policy log std Mean          -0.52939266
Policy log std Std           0.19902548
Policy log std Max           0.08175337
Policy log std Min           -1.4258593
Z mean eval                  0.012845146
Z variance eval              0.0016355619
total_rewards                [1672.38911927 1222.12278751  776.66623469 1650.06951522 1126.50461943
 1882.77987501 1206.55923479 2888.9420787  1262.45509002 1283.72081348]
total_rewards_mean           1497.2209368110719
total_rewards_std            552.9086905319452
total_rewards_max            2888.9420787048775
total_rewards_min            776.666234694763
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               33.94494484690949
(Previous) Eval Time (s)     9.882628375198692
Sample Time (s)              24.46060854010284
Epoch Time (s)               68.28818176221102
Total Train Time (s)         9242.375353171024
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:36:46.151903 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #148 | Epoch Duration: 71.36538171768188
2020-01-11 02:36:46.152086 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012961557
Z variance train             0.0016354322
KL Divergence                13.950365
KL Loss                      1.3950366
QF Loss                      238.651
VF Loss                      148.81987
Policy Loss                  -1140.1407
Q Predictions Mean           1139.1627
Q Predictions Std            471.55948
Q Predictions Max            1573.4106
Q Predictions Min            -4.0655165
V Predictions Mean           1137.632
V Predictions Std            469.65213
V Predictions Max            1556.7141
V Predictions Min            -2.1743968
Log Pis Mean                 -0.09253504
Log Pis Std                  1.9876825
Log Pis Max                  7.3330965
Log Pis Min                  -3.8363338
Policy mu Mean               -0.011713549
Policy mu Std                0.8833755
Policy mu Max                1.9942364
Policy mu Min                -2.7423966
Policy log std Mean          -0.509006
Policy log std Std           0.21502149
Policy log std Max           0.08081412
Policy log std Min           -1.1738708
Z mean eval                  0.022599597
Z variance eval              0.0013974231
total_rewards                [1002.08617055 1006.12443843  891.66691219  908.34205193 1061.34321968
 1007.10340267  909.05384162 1160.37594449 1126.44481722 1258.42928265]
total_rewards_mean           1033.0970081421058
total_rewards_std            113.93158512545239
total_rewards_max            1258.4292826470967
total_rewards_min            891.6669121861175
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               34.33861857512966
(Previous) Eval Time (s)     12.959418845828623
Sample Time (s)              24.137303370516747
Epoch Time (s)               71.43534079147503
Total Train Time (s)         9310.583664242178
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:54.362545 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #149 | Epoch Duration: 68.2103168964386
2020-01-11 02:37:54.362726 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022225056
Z variance train             0.0013870082
KL Divergence                14.278221
KL Loss                      1.4278221
QF Loss                      498.87897
VF Loss                      148.00597
Policy Loss                  -1181.4376
Q Predictions Mean           1182.5493
Q Predictions Std            443.99686
Q Predictions Max            1577.4073
Q Predictions Min            -6.198615
V Predictions Mean           1179.7666
V Predictions Std            441.42117
V Predictions Max            1571.8497
V Predictions Min            -1.3403441
Log Pis Mean                 -0.09096472
Log Pis Std                  2.2957106
Log Pis Max                  7.9831734
Log Pis Min                  -7.5750246
Policy mu Mean               0.015365372
Policy mu Std                0.9444148
Policy mu Max                2.61584
Policy mu Min                -2.8695076
Policy log std Mean          -0.5679126
Policy log std Std           0.23409571
Policy log std Max           0.06273842
Policy log std Min           -2.1170967
Z mean eval                  0.011730927
Z variance eval              0.001383075
total_rewards                [1116.5691148  1540.482643   1016.98887579 1647.54937032 1480.85065729
 1666.72037956 1824.59617697 1152.43183665  845.61322446 1515.9554851 ]
total_rewards_mean           1380.775776392312
total_rewards_std            307.3092601975548
total_rewards_max            1824.5961769655637
total_rewards_min            845.6132244561746
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.5641750600189
(Previous) Eval Time (s)     9.734052354004234
Sample Time (s)              24.711429277434945
Epoch Time (s)               69.00965669145808
Total Train Time (s)         9383.080249832943
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:06.862204 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #150 | Epoch Duration: 72.49933314323425
2020-01-11 02:39:06.862443 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009992419
Z variance train             0.0013177438
KL Divergence                14.2871
KL Loss                      1.42871
QF Loss                      125.426895
VF Loss                      36.46852
Policy Loss                  -1155.5652
Q Predictions Mean           1151.766
Q Predictions Std            452.4718
Q Predictions Max            1603.1581
Q Predictions Min            -3.4662418
V Predictions Mean           1155.7604
V Predictions Std            451.1774
V Predictions Max            1590.4988
V Predictions Min            -3.7125375
Log Pis Mean                 -0.207773
Log Pis Std                  2.2918239
Log Pis Max                  8.612979
Log Pis Min                  -4.658949
Policy mu Mean               0.1844142
Policy mu Std                0.92289925
Policy mu Max                2.749727
Policy mu Min                -2.8181484
Policy log std Mean          -0.500974
Policy log std Std           0.21123973
Policy log std Max           0.03984925
Policy log std Min           -1.5014651
Z mean eval                  0.042260822
Z variance eval              0.0013389693
total_rewards                [1236.38887226 1183.84659025 1408.15469488  978.67180688  935.33794892
 1839.03621232  990.88421581 1179.6961598  1546.54213744  999.91131496]
total_rewards_mean           1229.84699535169
total_rewards_std            277.069137833026
total_rewards_max            1839.0362123192585
total_rewards_min            935.3379489169056
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               33.91960447607562
(Previous) Eval Time (s)     13.223262486048043
Sample Time (s)              23.108038195874542
Epoch Time (s)               70.2509051579982
Total Train Time (s)         9450.34835522715
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:40:14.137566 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #151 | Epoch Duration: 67.27496576309204
2020-01-11 02:40:14.137754 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04225129
Z variance train             0.0013389539
KL Divergence                14.355278
KL Loss                      1.4355278
QF Loss                      212.96883
VF Loss                      334.93634
Policy Loss                  -1161.9191
Q Predictions Mean           1157.9492
Q Predictions Std            447.04724
Q Predictions Max            1562.8617
Q Predictions Min            -4.6391277
V Predictions Mean           1161.9147
V Predictions Std            447.321
V Predictions Max            1567.2898
V Predictions Min            -1.9039073
Log Pis Mean                 -0.14270574
Log Pis Std                  2.0753992
Log Pis Max                  8.665043
Log Pis Min                  -4.462556
Policy mu Mean               -0.029715637
Policy mu Std                0.89934397
Policy mu Max                2.9811416
Policy mu Min                -3.2578526
Policy log std Mean          -0.5460405
Policy log std Std           0.20642187
Policy log std Max           -0.025905848
Policy log std Min           -1.4076335
Z mean eval                  0.012303724
Z variance eval              0.0012354504
total_rewards                [1109.67493693 1468.60660691  962.5840583  1084.01610046 1141.35407094
 1448.69658027 1262.99668976  819.6607187  1104.21051226 1601.52449247]
total_rewards_mean           1200.3324766994751
total_rewards_std            231.17937734203983
total_rewards_max            1601.524492472812
total_rewards_min            819.6607186984152
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               33.871064921841025
(Previous) Eval Time (s)     10.246957691852003
Sample Time (s)              23.50172087782994
Epoch Time (s)               67.61974349152297
Total Train Time (s)         9518.840075651184
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:41:22.626537 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #152 | Epoch Duration: 68.4886360168457
2020-01-11 02:41:22.626723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011565666
Z variance train             0.0012501361
KL Divergence                14.36974
KL Loss                      1.4369739
QF Loss                      182.5547
VF Loss                      85.53025
Policy Loss                  -1144.8667
Q Predictions Mean           1145.2582
Q Predictions Std            475.04855
Q Predictions Max            1579.312
Q Predictions Min            0.9407519
V Predictions Mean           1142.8035
V Predictions Std            471.50626
V Predictions Max            1568.4683
V Predictions Min            3.1575208
Log Pis Mean                 -0.05090271
Log Pis Std                  2.154989
Log Pis Max                  7.6590314
Log Pis Min                  -5.0839996
Policy mu Mean               0.079305984
Policy mu Std                0.9169918
Policy mu Max                2.9085128
Policy mu Min                -3.0830595
Policy log std Mean          -0.5400305
Policy log std Std           0.22086015
Policy log std Max           -0.03250286
Policy log std Min           -1.466485
Z mean eval                  0.030932505
Z variance eval              0.0018277382
total_rewards                [ 826.91317542  991.74063144  973.83703735 1039.66326068  977.91109487
  810.23186978 1163.33841823  937.97639161  818.00675964  966.48346675]
total_rewards_mean           950.6102105769263
total_rewards_std            104.48088593740502
total_rewards_max            1163.3384182264103
total_rewards_min            810.2318697785684
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               34.64985147723928
(Previous) Eval Time (s)     11.115458138752729
Sample Time (s)              23.66784378979355
Epoch Time (s)               69.43315340578556
Total Train Time (s)         9586.09092500247
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:29.880062 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #153 | Epoch Duration: 67.25316429138184
2020-01-11 02:42:29.880356 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03069464
Z variance train             0.0018334286
KL Divergence                13.44719
KL Loss                      1.344719
QF Loss                      669.9773
VF Loss                      102.20446
Policy Loss                  -1142.5718
Q Predictions Mean           1137.5984
Q Predictions Std            469.05844
Q Predictions Max            1584.9438
Q Predictions Min            -0.7305142
V Predictions Mean           1143.3472
V Predictions Std            468.04163
V Predictions Max            1573.042
V Predictions Min            -0.35233453
Log Pis Mean                 -0.08575159
Log Pis Std                  1.9173423
Log Pis Max                  6.5394754
Log Pis Min                  -7.323475
Policy mu Mean               0.13703
Policy mu Std                0.9190072
Policy mu Max                2.9382873
Policy mu Min                -2.7992818
Policy log std Mean          -0.5186376
Policy log std Std           0.21783699
Policy log std Max           -0.025734007
Policy log std Min           -2.128956
Z mean eval                  0.01905819
Z variance eval              0.0020681866
total_rewards                [1068.7906627  1016.58188075 1086.72532528  983.47332301  899.66685469
  955.55921439 1427.27101188 1129.30215646  984.80793489 1251.19826281]
total_rewards_mean           1080.3376626862296
total_rewards_std            149.30263945989955
total_rewards_max            1427.271011880522
total_rewards_min            899.6668546890319
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               35.129442216362804
(Previous) Eval Time (s)     8.935064958874136
Sample Time (s)              23.79149858094752
Epoch Time (s)               67.85600575618446
Total Train Time (s)         9654.628371952567
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:38.419673 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #154 | Epoch Duration: 68.53915810585022
2020-01-11 02:43:38.419855 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018220693
Z variance train             0.0021291682
KL Divergence                13.0869465
KL Loss                      1.3086947
QF Loss                      231.5283
VF Loss                      54.208054
Policy Loss                  -1117.5521
Q Predictions Mean           1115.8281
Q Predictions Std            477.94174
Q Predictions Max            1591.4575
Q Predictions Min            -0.4207336
V Predictions Mean           1116.9033
V Predictions Std            476.94183
V Predictions Max            1589.9524
V Predictions Min            0.8598393
Log Pis Mean                 -0.14286941
Log Pis Std                  2.0816925
Log Pis Max                  9.763349
Log Pis Min                  -4.6748934
Policy mu Mean               0.023701243
Policy mu Std                0.90863734
Policy mu Max                2.207135
Policy mu Min                -3.0282626
Policy log std Mean          -0.50809
Policy log std Std           0.20133008
Policy log std Max           0.020836204
Policy log std Min           -1.107835
Z mean eval                  0.007439308
Z variance eval              0.0024936176
total_rewards                [ 875.42592465  897.18047121  824.80289873  938.13615953 1006.84297991
  919.83896891  986.22308656 1734.34160703  853.23737489  900.35155114]
total_rewards_mean           993.6381022567375
total_rewards_std            252.5066484880669
total_rewards_max            1734.341607033933
total_rewards_min            824.8028987254937
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               33.83133052196354
(Previous) Eval Time (s)     9.617834809236228
Sample Time (s)              22.14186864439398
Epoch Time (s)               65.59103397559375
Total Train Time (s)         9719.647977400105
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:43.441861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #155 | Epoch Duration: 65.02185678482056
2020-01-11 02:44:43.442068 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075409366
Z variance train             0.002413615
KL Divergence                12.849287
KL Loss                      1.2849287
QF Loss                      244.60321
VF Loss                      89.244095
Policy Loss                  -1179.1903
Q Predictions Mean           1180.1685
Q Predictions Std            445.50513
Q Predictions Max            1600.7212
Q Predictions Min            2.312743
V Predictions Mean           1173.6387
V Predictions Std            441.4421
V Predictions Max            1585.2684
V Predictions Min            3.1013207
Log Pis Mean                 -0.11381708
Log Pis Std                  2.015345
Log Pis Max                  6.7040253
Log Pis Min                  -4.2660694
Policy mu Mean               0.08519436
Policy mu Std                0.87503016
Policy mu Max                2.438555
Policy mu Min                -2.864214
Policy log std Mean          -0.5510889
Policy log std Std           0.21077916
Policy log std Max           -0.05335614
Policy log std Min           -1.2496068
Z mean eval                  0.03335584
Z variance eval              0.0023012985
total_rewards                [ 919.1385375   993.49180386  955.67656009  860.29410019  881.46762097
  965.20568483  993.37151498 1104.46324335 1049.84448637  916.68999422]
total_rewards_mean           963.9643546357116
total_rewards_std            71.21774097130118
total_rewards_max            1104.463243352941
total_rewards_min            860.2941001942864
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               34.226571006234735
(Previous) Eval Time (s)     9.04832270508632
Sample Time (s)              24.55489746434614
Epoch Time (s)               67.8297911756672
Total Train Time (s)         9787.418751846999
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:45:51.214745 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #156 | Epoch Duration: 67.77251434326172
2020-01-11 02:45:51.214942 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032457225
Z variance train             0.00232813
KL Divergence                12.81654
KL Loss                      1.281654
QF Loss                      258.52686
VF Loss                      72.21067
Policy Loss                  -1164.9691
Q Predictions Mean           1167.7078
Q Predictions Std            465.44495
Q Predictions Max            1583.3341
Q Predictions Min            -4.372687
V Predictions Mean           1169.4358
V Predictions Std            466.0361
V Predictions Max            1585.7662
V Predictions Min            -0.57356846
Log Pis Mean                 -0.3874173
Log Pis Std                  1.9129814
Log Pis Max                  9.770425
Log Pis Min                  -4.6432924
Policy mu Mean               0.11579952
Policy mu Std                0.8212315
Policy mu Max                2.41662
Policy mu Min                -2.77793
Policy log std Mean          -0.49492785
Policy log std Std           0.19572817
Policy log std Max           -0.07353625
Policy log std Min           -1.3350805
Z mean eval                  0.013481183
Z variance eval              0.0022516071
total_rewards                [ 992.05754471  994.45285115  878.04275001  876.49631816  963.10793379
  867.50517601 1114.30370422  957.33042113  895.01503876  912.76071178]
total_rewards_mean           945.1072449703051
total_rewards_std            72.47268889121776
total_rewards_max            1114.3037042164538
total_rewards_min            867.5051760067843
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               33.57272712001577
(Previous) Eval Time (s)     8.990664785727859
Sample Time (s)              23.854134530760348
Epoch Time (s)               66.41752643650398
Total Train Time (s)         9853.207034992054
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:46:57.005378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #157 | Epoch Duration: 65.79029583930969
2020-01-11 02:46:57.005555 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014352898
Z variance train             0.002252064
KL Divergence                12.804736
KL Loss                      1.2804736
QF Loss                      140.39648
VF Loss                      65.495735
Policy Loss                  -1177.1869
Q Predictions Mean           1177.0203
Q Predictions Std            434.98233
Q Predictions Max            1594.4474
Q Predictions Min            -1.6907897
V Predictions Mean           1181.0787
V Predictions Std            435.05414
V Predictions Max            1599.7043
V Predictions Min            1.3481437
Log Pis Mean                 0.016384713
Log Pis Std                  2.1262536
Log Pis Max                  7.7495794
Log Pis Min                  -5.3262596
Policy mu Mean               0.05625074
Policy mu Std                0.9385168
Policy mu Max                2.367797
Policy mu Min                -2.9750724
Policy log std Mean          -0.53660053
Policy log std Std           0.20597944
Policy log std Max           -0.08279714
Policy log std Min           -1.4893237
Z mean eval                  0.022671968
Z variance eval              0.002030371
total_rewards                [ 851.34053147 1143.02305387 1250.95976627  967.88637948 1037.64759022
  945.0299845  1113.66884134 1017.94008279 1266.2201108  1004.27805078]
total_rewards_mean           1059.7994391514521
total_rewards_std            126.24600430592717
total_rewards_max            1266.2201107973012
total_rewards_min            851.3405314709142
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               32.24847837211564
(Previous) Eval Time (s)     8.363049047999084
Sample Time (s)              22.9375017574057
Epoch Time (s)               63.549029177520424
Total Train Time (s)         9917.337859147228
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:01.138585 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #158 | Epoch Duration: 64.13288450241089
2020-01-11 02:48:01.138780 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022983113
Z variance train             0.0019891083
KL Divergence                13.084796
KL Loss                      1.3084797
QF Loss                      167.14384
VF Loss                      68.59516
Policy Loss                  -1157.5245
Q Predictions Mean           1158.0669
Q Predictions Std            458.72836
Q Predictions Max            1558.518
Q Predictions Min            -3.5488281
V Predictions Mean           1161.3214
V Predictions Std            457.86597
V Predictions Max            1554.4521
V Predictions Min            -0.32653993
Log Pis Mean                 -0.10908072
Log Pis Std                  2.1864412
Log Pis Max                  7.244917
Log Pis Min                  -5.5393057
Policy mu Mean               -0.01799501
Policy mu Std                0.92561644
Policy mu Max                2.5359704
Policy mu Min                -3.0085936
Policy log std Mean          -0.50537956
Policy log std Std           0.2043081
Policy log std Max           -0.038294226
Policy log std Min           -1.2538384
Z mean eval                  0.026312307
Z variance eval              0.0016537437
total_rewards                [ 999.20055021 1030.27540083  979.95024531  879.43605094  994.59583218
 1004.3003778   905.7796709  1043.42089746  909.33904661 1408.54756731]
total_rewards_mean           1015.484563955219
total_rewards_std            141.2084439904867
total_rewards_max            1408.5475673141982
total_rewards_min            879.4360509359242
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               31.764187314081937
(Previous) Eval Time (s)     8.946556789334863
Sample Time (s)              23.653412462212145
Epoch Time (s)               64.36415656562895
Total Train Time (s)         9981.62545317784
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:49:05.428782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #159 | Epoch Duration: 64.28985166549683
2020-01-11 02:49:05.428992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025868708
Z variance train             0.0015176199
KL Divergence                13.744755
KL Loss                      1.3744755
QF Loss                      222.52975
VF Loss                      99.171715
Policy Loss                  -1190.8853
Q Predictions Mean           1190.0833
Q Predictions Std            444.57938
Q Predictions Max            1572.8976
Q Predictions Min            -20.456188
V Predictions Mean           1190.6868
V Predictions Std            440.9239
V Predictions Max            1558.7142
V Predictions Min            2.4558206
Log Pis Mean                 -0.026873834
Log Pis Std                  2.1183105
Log Pis Max                  11.145397
Log Pis Min                  -6.4419074
Policy mu Mean               0.05840504
Policy mu Std                0.9120917
Policy mu Max                3.3253546
Policy mu Min                -2.849456
Policy log std Mean          -0.52110547
Policy log std Std           0.2042402
Policy log std Max           -0.005350977
Policy log std Min           -1.9465225
Z mean eval                  0.06275093
Z variance eval              0.0015194642
total_rewards                [ 881.85721117  949.78806217 1033.99318699  899.84092173  985.04738501
 1188.17371425 1545.74345415  861.21209538 1122.13330302 1065.57391195]
total_rewards_mean           1053.3363245811474
total_rewards_std            192.6567177790183
total_rewards_max            1545.7434541486284
total_rewards_min            861.212095383715
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               31.942639411892742
(Previous) Eval Time (s)     8.871933659072965
Sample Time (s)              23.176668773405254
Epoch Time (s)               63.99124184437096
Total Train Time (s)         10044.971779344603
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:50:08.778023 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #160 | Epoch Duration: 63.34887933731079
2020-01-11 02:50:08.778203 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06266405
Z variance train             0.0015145978
KL Divergence                13.778329
KL Loss                      1.3778329
QF Loss                      304.63184
VF Loss                      87.773926
Policy Loss                  -1158.4413
Q Predictions Mean           1156.3059
Q Predictions Std            470.2344
Q Predictions Max            1577.7876
Q Predictions Min            -1.8915505
V Predictions Mean           1161.4006
V Predictions Std            469.85022
V Predictions Max            1579.6615
V Predictions Min            1.9923182
Log Pis Mean                 0.18145756
Log Pis Std                  2.0625749
Log Pis Max                  8.0125675
Log Pis Min                  -3.7951062
Policy mu Mean               0.09894744
Policy mu Std                0.976364
Policy mu Max                3.6831417
Policy mu Min                -2.8344631
Policy log std Mean          -0.52519685
Policy log std Std           0.21532704
Policy log std Max           0.008324772
Policy log std Min           -1.392672
Z mean eval                  0.016937252
Z variance eval              0.0015020979
total_rewards                [1013.0151292   973.91776506 1264.1425361   932.87992659 1022.02560235
  964.34121923 1000.7859076   855.06311253 1542.00755673  925.87651137]
total_rewards_mean           1049.4055266769121
total_rewards_std            193.06669248383014
total_rewards_max            1542.007556733392
total_rewards_min            855.0631125299639
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               32.355863044038415
(Previous) Eval Time (s)     8.229258480016142
Sample Time (s)              23.763073867186904
Epoch Time (s)               64.34819539124146
Total Train Time (s)         10110.710867359303
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:14.517540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #161 | Epoch Duration: 65.73921036720276
2020-01-11 02:51:14.517687 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #161 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016519764
Z variance train             0.0015178814
KL Divergence                13.775839
KL Loss                      1.3775839
QF Loss                      426.28732
VF Loss                      53.485115
Policy Loss                  -1155.3094
Q Predictions Mean           1155.1321
Q Predictions Std            471.26324
Q Predictions Max            1569.4204
Q Predictions Min            -6.681658
V Predictions Mean           1157.6326
V Predictions Std            470.6126
V Predictions Max            1577.5399
V Predictions Min            -3.2240736
Log Pis Mean                 -0.06330331
Log Pis Std                  2.1335387
Log Pis Max                  8.101987
Log Pis Min                  -5.607666
Policy mu Mean               -0.02486766
Policy mu Std                0.9259794
Policy mu Max                1.9781936
Policy mu Min                -2.855693
Policy log std Mean          -0.51511097
Policy log std Std           0.22296545
Policy log std Max           0.008851081
Policy log std Min           -1.5296106
Z mean eval                  0.08178347
Z variance eval              0.0019531073
total_rewards                [994.85299028 996.42711241 910.58092509 863.25352361 975.82589815
 933.66734871 977.11723379 782.73570095 868.73145537 897.45609294]
total_rewards_mean           920.0648281285387
total_rewards_std            65.80030252388528
total_rewards_max            996.4271124065261
total_rewards_min            782.7357009460525
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               32.89521724823862
(Previous) Eval Time (s)     9.6199762490578
Sample Time (s)              24.20323918107897
Epoch Time (s)               66.7184326783754
Total Train Time (s)         10176.302926116623
Epoch                        162
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:20.112964 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #162 | Epoch Duration: 65.5951635837555
2020-01-11 02:52:20.113198 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08202026
Z variance train             0.001952796
KL Divergence                13.296255
KL Loss                      1.3296255
QF Loss                      327.97467
VF Loss                      75.35312
Policy Loss                  -1240.8937
Q Predictions Mean           1237.7721
Q Predictions Std            409.54755
Q Predictions Max            1567.8262
Q Predictions Min            -0.21940899
V Predictions Mean           1236.208
V Predictions Std            407.2998
V Predictions Max            1565.3809
V Predictions Min            -1.202186
Log Pis Mean                 -0.028271839
Log Pis Std                  2.288511
Log Pis Max                  9.169273
Log Pis Min                  -4.9043064
Policy mu Mean               0.15150334
Policy mu Std                0.9486651
Policy mu Max                2.3350284
Policy mu Min                -2.7860594
Policy log std Mean          -0.49439415
Policy log std Std           0.19153753
Policy log std Max           0.09190628
Policy log std Min           -1.9602811
Z mean eval                  0.046110712
Z variance eval              0.0016364867
total_rewards                [1013.61115293 1124.66741389  988.75964727 1508.1091636  1006.66183406
  937.0741393   751.66773443 1237.98803425  862.03450612 1809.3498778 ]
total_rewards_mean           1123.9923503639825
total_rewards_std            302.76730842068633
total_rewards_max            1809.3498777965758
total_rewards_min            751.667734429658
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               31.908923513721675
(Previous) Eval Time (s)     8.496354431845248
Sample Time (s)              23.792611959390342
Epoch Time (s)               64.19788990495726
Total Train Time (s)         10242.438720433973
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:26.250968 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #163 | Epoch Duration: 66.13762283325195
2020-01-11 02:53:26.251145 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21411943
Z variance train             0.0003247737
KL Divergence                18.44077
KL Loss                      1.844077
QF Loss                      5004.4653
VF Loss                      347.761
Policy Loss                  -1053.4102
Q Predictions Mean           1047.8728
Q Predictions Std            467.5161
Q Predictions Max            1478.4309
Q Predictions Min            -14.800253
V Predictions Mean           1058.9481
V Predictions Std            468.877
V Predictions Max            1493.1489
V Predictions Min            -5.0089946
Log Pis Mean                 0.0020930693
Log Pis Std                  1.954437
Log Pis Max                  8.265749
Log Pis Min                  -3.2046356
Policy mu Mean               0.027605379
Policy mu Std                0.88369805
Policy mu Max                3.5107718
Policy mu Min                -2.7365994
Policy log std Mean          -0.50937265
Policy log std Std           0.21541655
Policy log std Max           0.0743908
Policy log std Min           -1.5899204
Z mean eval                  0.03287933
Z variance eval              0.0011563533
total_rewards                [1222.66745847  998.73296038 1416.45847092 1233.85457261  966.22968945
  869.37612758 1500.36650138  966.73984767 1429.55989735 1191.62598479]
total_rewards_mean           1179.5611510595468
total_rewards_std            211.23543232478397
total_rewards_max            1500.366501379141
total_rewards_min            869.3761275797995
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               31.90722512314096
(Previous) Eval Time (s)     10.435774583835155
Sample Time (s)              23.251319643575698
Epoch Time (s)               65.59431935055181
Total Train Time (s)         10307.782875370234
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:54:31.597450 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #164 | Epoch Duration: 65.3461434841156
2020-01-11 02:54:31.597642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04985113
Z variance train             0.0008747627
KL Divergence                15.304364
KL Loss                      1.5304364
QF Loss                      61.628952
VF Loss                      48.585625
Policy Loss                  -1172.6688
Q Predictions Mean           1172.9761
Q Predictions Std            482.6611
Q Predictions Max            1592.0695
Q Predictions Min            3.5693533
V Predictions Mean           1175.3448
V Predictions Std            482.53168
V Predictions Max            1595.013
V Predictions Min            3.4673338
Log Pis Mean                 -0.28641227
Log Pis Std                  2.0614402
Log Pis Max                  6.7643833
Log Pis Min                  -5.07686
Policy mu Mean               0.1566955
Policy mu Std                0.8922589
Policy mu Max                2.6068175
Policy mu Min                -2.868167
Policy log std Mean          -0.5249688
Policy log std Std           0.20435825
Policy log std Max           0.008461058
Policy log std Min           -1.5713608
Z mean eval                  0.0134224715
Z variance eval              0.00084858446
total_rewards                [ 899.64824551  922.7187144  1063.59442815  899.59561338  927.50406152
  902.80832386  967.82617435 1479.9388357   910.55355263  994.92759256]
total_rewards_mean           996.9115542064322
total_rewards_std            168.5756504496552
total_rewards_max            1479.9388357010341
total_rewards_min            899.5956133845445
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               31.955539382062852
(Previous) Eval Time (s)     10.187267936766148
Sample Time (s)              22.739173708949238
Epoch Time (s)               64.88198102777824
Total Train Time (s)         10371.99454966141
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:35.812630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #165 | Epoch Duration: 64.21484327316284
2020-01-11 02:55:35.812821 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014593206
Z variance train             0.0008198007
KL Divergence                15.433794
KL Loss                      1.5433794
QF Loss                      174.41794
VF Loss                      137.69814
Policy Loss                  -1176.9686
Q Predictions Mean           1176.3425
Q Predictions Std            438.24823
Q Predictions Max            1570.1227
Q Predictions Min            -1.4662818
V Predictions Mean           1184.5173
V Predictions Std            440.312
V Predictions Max            1580.916
V Predictions Min            5.8628745
Log Pis Mean                 -0.25674587
Log Pis Std                  1.8489176
Log Pis Max                  6.1500964
Log Pis Min                  -4.4428434
Policy mu Mean               0.07875836
Policy mu Std                0.87414384
Policy mu Max                3.421553
Policy mu Min                -2.6141124
Policy log std Mean          -0.5084769
Policy log std Std           0.19861858
Policy log std Max           0.11601809
Policy log std Min           -1.458339
Z mean eval                  0.012815359
Z variance eval              0.0007508278
total_rewards                [ 933.93395074 1415.44000659 1005.65157079  893.77318934  874.46875864
 1066.47992094  827.77438217 1954.01476954  897.22120596 1024.9588081 ]
total_rewards_mean           1089.3716562804752
total_rewards_std            328.56783272536927
total_rewards_max            1954.014769537033
total_rewards_min            827.7743821693828
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               31.87170336395502
(Previous) Eval Time (s)     9.519797233864665
Sample Time (s)              23.02362021477893
Epoch Time (s)               64.41512081259862
Total Train Time (s)         10436.839960678946
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:40.659242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #166 | Epoch Duration: 64.84624981880188
2020-01-11 02:56:40.659424 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010923174
Z variance train             0.00077130605
KL Divergence                15.654102
KL Loss                      1.5654103
QF Loss                      119.9467
VF Loss                      125.46437
Policy Loss                  -1160.4878
Q Predictions Mean           1161.9844
Q Predictions Std            460.49524
Q Predictions Max            1596.9537
Q Predictions Min            1.4355139
V Predictions Mean           1167.6239
V Predictions Std            460.1787
V Predictions Max            1595.3137
V Predictions Min            2.4354436
Log Pis Mean                 -0.12770636
Log Pis Std                  2.0311778
Log Pis Max                  7.6012306
Log Pis Min                  -5.360734
Policy mu Mean               0.0130330175
Policy mu Std                0.9161353
Policy mu Max                2.3769386
Policy mu Min                -2.695329
Policy log std Mean          -0.5304399
Policy log std Std           0.213107
Policy log std Max           0.045544207
Policy log std Min           -1.7217859
Z mean eval                  0.016299678
Z variance eval              0.001006265
total_rewards                [ 996.50315945 1250.87622364 1000.08334149  994.08270175  938.30518259
  983.73767522 1423.85850283  839.73179489 1527.43086563 1008.26520009]
total_rewards_mean           1096.2874647582255
total_rewards_std            213.9947764320436
total_rewards_max            1527.4308656339826
total_rewards_min            839.7317948854512
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.69128482788801
(Previous) Eval Time (s)     9.950610937085003
Sample Time (s)              23.399582700338215
Epoch Time (s)               66.04147846531123
Total Train Time (s)         10503.085648749024
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:46.907041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #167 | Epoch Duration: 66.24748754501343
2020-01-11 02:57:46.907275 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011727573
Z variance train             0.0009906318
KL Divergence                14.933744
KL Loss                      1.4933745
QF Loss                      301.41876
VF Loss                      196.93938
Policy Loss                  -1224.728
Q Predictions Mean           1221.7017
Q Predictions Std            391.83432
Q Predictions Max            1584.3046
Q Predictions Min            -9.375557
V Predictions Mean           1223.3201
V Predictions Std            390.754
V Predictions Max            1588.9225
V Predictions Min            -6.2256823
Log Pis Mean                 0.014686834
Log Pis Std                  2.3092892
Log Pis Max                  10.456488
Log Pis Min                  -4.2686305
Policy mu Mean               0.050743774
Policy mu Std                0.95146024
Policy mu Max                3.5891275
Policy mu Min                -2.7753189
Policy log std Mean          -0.47180033
Policy log std Std           0.18788591
Policy log std Max           0.10562304
Policy log std Min           -1.5007932
Z mean eval                  0.013590524
Z variance eval              0.000783553
total_rewards                [1338.38754489 1077.06468954 1355.31512204 1634.1345945  1222.33330535
 1154.42752179 1389.20761909 1004.78039798 1686.01723737 1024.21326402]
total_rewards_mean           1288.58812965622
total_rewards_std            226.26993707717523
total_rewards_max            1686.017237365669
total_rewards_min            1004.780397976774
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               32.775944008957595
(Previous) Eval Time (s)     10.15631252201274
Sample Time (s)              22.973338816780597
Epoch Time (s)               65.90559534775093
Total Train Time (s)         10570.731982507277
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:58:54.554867 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #168 | Epoch Duration: 67.64745450019836
2020-01-11 02:58:54.555007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013880414
Z variance train             0.0007876082
KL Divergence                15.576896
KL Loss                      1.5576895
QF Loss                      335.46112
VF Loss                      75.38687
Policy Loss                  -1201.4603
Q Predictions Mean           1199.3955
Q Predictions Std            425.3018
Q Predictions Max            1606.1165
Q Predictions Min            0.53256196
V Predictions Mean           1202.5168
V Predictions Std            424.5903
V Predictions Max            1603.8003
V Predictions Min            4.5965934
Log Pis Mean                 -0.058981165
Log Pis Std                  2.1541324
Log Pis Max                  8.44669
Log Pis Min                  -5.17161
Policy mu Mean               0.10190459
Policy mu Std                0.9010989
Policy mu Max                2.6511717
Policy mu Min                -3.0713274
Policy log std Mean          -0.5328023
Policy log std Std           0.2344052
Policy log std Max           0.12215203
Policy log std Min           -2.388114
Z mean eval                  0.027000476
Z variance eval              0.000747279
total_rewards                [1739.6310517  1100.83087023 1280.44726672 1580.37654682 1192.75460834
 1006.3008241  2267.59138808 1554.27465793 1259.36986739 1151.54080103]
total_rewards_mean           1413.311788232213
total_rewards_std            361.3698832318848
total_rewards_max            2267.591388075277
total_rewards_min            1006.3008240969176
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               32.502840633969754
(Previous) Eval Time (s)     11.89782206621021
Sample Time (s)              23.40414070012048
Epoch Time (s)               67.80480340030044
Total Train Time (s)         10639.116828487255
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:02.944239 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #169 | Epoch Duration: 68.38900017738342
2020-01-11 03:00:02.944706 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027193759
Z variance train             0.0007510163
KL Divergence                15.705618
KL Loss                      1.5705618
QF Loss                      180.73851
VF Loss                      84.968666
Policy Loss                  -1183.4937
Q Predictions Mean           1179.4897
Q Predictions Std            439.8979
Q Predictions Max            1557.9015
Q Predictions Min            -9.863665
V Predictions Mean           1184.1709
V Predictions Std            438.40045
V Predictions Max            1556.1198
V Predictions Min            -4.3047175
Log Pis Mean                 -0.16588603
Log Pis Std                  2.2198606
Log Pis Max                  6.815064
Log Pis Min                  -5.5454803
Policy mu Mean               0.05330235
Policy mu Std                0.8901841
Policy mu Max                2.5375514
Policy mu Min                -2.8484373
Policy log std Mean          -0.53926885
Policy log std Std           0.22685412
Policy log std Max           -0.011700124
Policy log std Min           -2.1683948
Z mean eval                  0.005351482
Z variance eval              0.0004398643
total_rewards                [ 889.57823888 1168.61055205  846.62092059  995.6256517  1035.01841366
 1368.73851899 1749.80518397  898.40494822  975.44014378 1000.08810074]
total_rewards_mean           1092.7930672582424
total_rewards_std            262.37152563647993
total_rewards_max            1749.8051839724355
total_rewards_min            846.6209205865437
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               32.296152513008565
(Previous) Eval Time (s)     12.481619941070676
Sample Time (s)              21.941435592249036
Epoch Time (s)               66.71920804632828
Total Train Time (s)         10703.438854776789
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:01:07.269189 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #170 | Epoch Duration: 64.32420539855957
2020-01-11 03:01:07.269389 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0054815197
Z variance train             0.00043976057
KL Divergence                16.945934
KL Loss                      1.6945934
QF Loss                      174.93326
VF Loss                      26.038128
Policy Loss                  -1207.0386
Q Predictions Mean           1202.9762
Q Predictions Std            434.64505
Q Predictions Max            1613.098
Q Predictions Min            2.275726
V Predictions Mean           1207.8634
V Predictions Std            433.5963
V Predictions Max            1608.4141
V Predictions Min            5.7403345
Log Pis Mean                 -0.055189103
Log Pis Std                  2.1034098
Log Pis Max                  7.739984
Log Pis Min                  -5.604174
Policy mu Mean               0.012884599
Policy mu Std                0.927597
Policy mu Max                2.8350058
Policy mu Min                -2.6745572
Policy log std Mean          -0.5199836
Policy log std Std           0.20702125
Policy log std Max           -0.0444763
Policy log std Min           -1.5319936
Z mean eval                  0.010328864
Z variance eval              0.00031962333
total_rewards                [ 996.3128276   997.21693575 1015.01675361 1370.81039746 1236.30812436
 1098.45279669  980.12886167  971.1447357   936.22480163 2250.35944483]
total_rewards_mean           1185.1975679293391
total_rewards_std            378.0203422050085
total_rewards_max            2250.3594448323015
total_rewards_min            936.2248016290425
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               32.30528573086485
(Previous) Eval Time (s)     10.086330767720938
Sample Time (s)              22.97445551957935
Epoch Time (s)               65.36607201816514
Total Train Time (s)         10769.575104251504
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:13.409072 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #171 | Epoch Duration: 66.1394579410553
2020-01-11 03:02:13.409372 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010276309
Z variance train             0.0003195089
KL Divergence                17.870682
KL Loss                      1.7870682
QF Loss                      188.4719
VF Loss                      48.912872
Policy Loss                  -1174.0148
Q Predictions Mean           1171.8279
Q Predictions Std            449.8642
Q Predictions Max            1586.7289
Q Predictions Min            2.7257798
V Predictions Mean           1175.0621
V Predictions Std            448.5657
V Predictions Max            1574.63
V Predictions Min            2.6048448
Log Pis Mean                 0.050277494
Log Pis Std                  2.1976876
Log Pis Max                  8.212402
Log Pis Min                  -4.5494967
Policy mu Mean               0.053346436
Policy mu Std                0.91160774
Policy mu Max                2.7215254
Policy mu Min                -2.6457212
Policy log std Mean          -0.5054322
Policy log std Std           0.21488355
Policy log std Max           0.04834193
Policy log std Min           -1.586854
Z mean eval                  0.020149577
Z variance eval              0.00030101434
total_rewards                [1126.64283009 1138.58863928 1030.55207951  840.02873902  901.90064736
  892.90572266  876.75913491  859.70379299  937.5515124   889.93249218]
total_rewards_mean           949.4565590403324
total_rewards_std            104.0200608778485
total_rewards_max            1138.5886392846514
total_rewards_min            840.0287390196825
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               32.18964773789048
(Previous) Eval Time (s)     10.85940046608448
Sample Time (s)              22.94533134577796
Epoch Time (s)               65.99437954975292
Total Train Time (s)         10832.864987418521
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:03:16.701490 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #172 | Epoch Duration: 63.29192781448364
2020-01-11 03:03:16.701728 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018484954
Z variance train             0.0003184406
KL Divergence                18.183233
KL Loss                      1.8183234
QF Loss                      101.61709
VF Loss                      43.662453
Policy Loss                  -1245.3994
Q Predictions Mean           1245.6699
Q Predictions Std            395.75555
Q Predictions Max            1565.9215
Q Predictions Min            -0.24734238
V Predictions Mean           1247.8079
V Predictions Std            394.96738
V Predictions Max            1563.0712
V Predictions Min            1.2322531
Log Pis Mean                 -0.11838508
Log Pis Std                  1.9115018
Log Pis Max                  5.9355073
Log Pis Min                  -7.186826
Policy mu Mean               0.14084104
Policy mu Std                0.8877131
Policy mu Max                2.1618724
Policy mu Min                -2.7114527
Policy log std Mean          -0.50057846
Policy log std Std           0.18495473
Policy log std Max           -0.0039975345
Policy log std Min           -1.2068406
Z mean eval                  0.5532387
Z variance eval              0.00047735497
total_rewards                [1797.06247114 1291.61055466 1012.69969318 1010.59449431  942.85482626
 1021.23613949 1210.62225541 1025.62337108 1130.77660568 1224.46237694]
total_rewards_mean           1166.7542788155588
total_rewards_std            236.3830883025725
total_rewards_max            1797.0624711414036
total_rewards_min            942.8548262635386
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               32.49945333786309
(Previous) Eval Time (s)     8.156593186315149
Sample Time (s)              23.4858988635242
Epoch Time (s)               64.14194538770244
Total Train Time (s)         10899.603781049605
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:23.443136 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #173 | Epoch Duration: 66.7412416934967
2020-01-11 03:04:23.443387 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5573218
Z variance train             0.00047911247
KL Divergence                19.415697
KL Loss                      1.9415697
QF Loss                      266.50696
VF Loss                      529.04
Policy Loss                  -1363.6152
Q Predictions Mean           1364.7194
Q Predictions Std            471.2712
Q Predictions Max            1753.824
Q Predictions Min            0.32666823
V Predictions Mean           1361.3247
V Predictions Std            473.70026
V Predictions Max            1760.902
V Predictions Min            -4.0972643
Log Pis Mean                 -0.2008174
Log Pis Std                  2.0625508
Log Pis Max                  8.593806
Log Pis Min                  -5.581519
Policy mu Mean               0.020520186
Policy mu Std                0.88369745
Policy mu Max                2.3605878
Policy mu Min                -2.8228168
Policy log std Mean          -0.5170262
Policy log std Std           0.18504278
Policy log std Max           -0.014407456
Policy log std Min           -1.3691537
Z mean eval                  0.26806396
Z variance eval              0.0005766886
total_rewards                [1307.85106665  997.1484394   976.82789336 1005.9847935   970.10964926
 1072.74704904 1542.846252   1241.42328796  994.76423582 1815.91236291]
total_rewards_mean           1192.5615029910225
total_rewards_std            273.7603096222822
total_rewards_max            1815.9123629132616
total_rewards_min            970.1096492649509
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               32.28633315721527
(Previous) Eval Time (s)     10.755562321748585
Sample Time (s)              22.637701945379376
Epoch Time (s)               65.67959742434323
Total Train Time (s)         10965.389397603925
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:05:29.232652 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #174 | Epoch Duration: 65.7890977859497
2020-01-11 03:05:29.232844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3180077
Z variance train             0.00056407525
KL Divergence                18.703558
KL Loss                      1.8703558
QF Loss                      597.03546
VF Loss                      50.918243
Policy Loss                  -1222.5524
Q Predictions Mean           1217.0017
Q Predictions Std            532.64404
Q Predictions Max            1683.1324
Q Predictions Min            -2.4119318
V Predictions Mean           1219.9526
V Predictions Std            529.55945
V Predictions Max            1685.255
V Predictions Min            0.06563905
Log Pis Mean                 -0.14483154
Log Pis Std                  2.070891
Log Pis Max                  7.8317075
Log Pis Min                  -5.471417
Policy mu Mean               0.07516799
Policy mu Std                0.8968072
Policy mu Max                2.7586527
Policy mu Min                -2.7470126
Policy log std Mean          -0.5048607
Policy log std Std           0.19810176
Policy log std Max           0.014367163
Policy log std Min           -1.5234674
Z mean eval                  0.23722406
Z variance eval              0.000663628
total_rewards                [1156.14562703  907.80098797  819.63336027  815.26130777  695.06053474
  913.36817251  991.24052475  884.53989704 1013.15570206 1147.03860532]
total_rewards_mean           934.3244719459417
total_rewards_std            138.60166401612392
total_rewards_max            1156.1456270261838
total_rewards_min            695.0605347387084
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               32.52976000867784
(Previous) Eval Time (s)     10.864715160802007
Sample Time (s)              23.098863881547004
Epoch Time (s)               66.49333905102685
Total Train Time (s)         11029.5767025752
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:33.422092 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #175 | Epoch Duration: 64.18908166885376
2020-01-11 03:06:33.422372 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21925588
Z variance train             0.00067032565
KL Divergence                18.446445
KL Loss                      1.8446445
QF Loss                      3464.476
VF Loss                      106.44945
Policy Loss                  -1293.1332
Q Predictions Mean           1288.9291
Q Predictions Std            437.96417
Q Predictions Max            1663.7366
Q Predictions Min            1.4734576
V Predictions Mean           1287.6302
V Predictions Std            434.9983
V Predictions Max            1660.9054
V Predictions Min            4.35674
Log Pis Mean                 0.0978683
Log Pis Std                  1.9801986
Log Pis Max                  10.617777
Log Pis Min                  -4.218561
Policy mu Mean               0.15313572
Policy mu Std                0.9313064
Policy mu Max                3.5067785
Policy mu Min                -2.9522796
Policy log std Mean          -0.53599674
Policy log std Std           0.1798171
Policy log std Max           -0.107829005
Policy log std Min           -1.2326325
Z mean eval                  0.1040773
Z variance eval              0.0005187575
total_rewards                [1001.7285066  1214.21718877  698.98167615  934.25531495  937.51696478
  870.54251183  869.49561395  848.81153988  999.33917926  698.24234781]
total_rewards_mean           907.3130843981573
total_rewards_std            143.71102145945886
total_rewards_max            1214.2171887703553
total_rewards_min            698.2423478123471
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               32.42857667990029
(Previous) Eval Time (s)     8.560132476035506
Sample Time (s)              23.1469628312625
Epoch Time (s)               64.1356719871983
Total Train Time (s)         11093.474036360625
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:37.321454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #176 | Epoch Duration: 63.89879655838013
2020-01-11 03:07:37.321761 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #176 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10912237
Z variance train             0.00051844504
KL Divergence                18.259174
KL Loss                      1.8259175
QF Loss                      271.0055
VF Loss                      250.85167
Policy Loss                  -1251.7816
Q Predictions Mean           1251.1438
Q Predictions Std            399.80698
Q Predictions Max            1600.9094
Q Predictions Min            -3.9303722
V Predictions Mean           1251.0444
V Predictions Std            395.56903
V Predictions Max            1600.5947
V Predictions Min            -4.8727756
Log Pis Mean                 -0.103718355
Log Pis Std                  1.8861147
Log Pis Max                  9.5829315
Log Pis Min                  -4.270714
Policy mu Mean               0.02954173
Policy mu Std                0.9115256
Policy mu Max                2.9375367
Policy mu Min                -2.6751232
Policy log std Mean          -0.5335297
Policy log std Std           0.18443833
Policy log std Max           -0.03317198
Policy log std Min           -1.5391932
Z mean eval                  0.06109202
Z variance eval              0.0010497737
total_rewards                [1150.59918685 1255.50655749 1180.22261967  825.15458328 2143.052482
 1003.98411744 1168.91325692 1073.85207795  963.47988052 1103.91922795]
total_rewards_mean           1186.8683990078202
total_rewards_std            339.78234732878104
total_rewards_max            2143.0524820021947
total_rewards_min            825.1545832794673
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               31.784067566972226
(Previous) Eval Time (s)     8.322925394866616
Sample Time (s)              22.92149540502578
Epoch Time (s)               63.02848836686462
Total Train Time (s)         11158.588453907054
Epoch                        177
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:08:42.439854 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #177 | Epoch Duration: 65.11791014671326
2020-01-11 03:08:42.440047 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0645781
Z variance train             0.0010498922
KL Divergence                16.991325
KL Loss                      1.6991326
QF Loss                      547.7027
VF Loss                      124.28879
Policy Loss                  -1239.554
Q Predictions Mean           1239.554
Q Predictions Std            411.37125
Q Predictions Max            1592.1603
Q Predictions Min            -12.124715
V Predictions Mean           1237.4967
V Predictions Std            406.10947
V Predictions Max            1578.8319
V Predictions Min            -4.8653216
Log Pis Mean                 0.022349387
Log Pis Std                  2.4631855
Log Pis Max                  16.452408
Log Pis Min                  -5.7743506
Policy mu Mean               0.16912161
Policy mu Std                0.9700435
Policy mu Max                3.4594917
Policy mu Min                -3.1639097
Policy log std Mean          -0.5080468
Policy log std Std           0.18488091
Policy log std Max           -0.073845655
Policy log std Min           -1.8868705
Z mean eval                  0.029369373
Z variance eval              0.0014539117
total_rewards                [1804.34478428 3159.35661817 2338.86581748 1811.99307394 2034.02172401
 1227.72129148 1157.37565148 3137.64091601  976.81378754 3084.0493823 ]
total_rewards_mean           2073.2183046699733
total_rewards_std            793.904515236963
total_rewards_max            3159.3566181741016
total_rewards_min            976.8137875420285
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               32.203729269094765
(Previous) Eval Time (s)     10.412008038256317
Sample Time (s)              23.031472694594413
Epoch Time (s)               65.6472100019455
Total Train Time (s)         11233.212560554035
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:57.064674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #178 | Epoch Duration: 74.62440276145935
2020-01-11 03:09:57.064962 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028415645
Z variance train             0.0014324964
KL Divergence                16.605183
KL Loss                      1.6605183
QF Loss                      409.55878
VF Loss                      336.61908
Policy Loss                  -1153.6993
Q Predictions Mean           1165.3477
Q Predictions Std            465.52576
Q Predictions Max            1586.9006
Q Predictions Min            -0.5658852
V Predictions Mean           1166.6089
V Predictions Std            462.81213
V Predictions Max            1575.2206
V Predictions Min            -7.7459555
Log Pis Mean                 -0.3291961
Log Pis Std                  2.1184676
Log Pis Max                  7.6494193
Log Pis Min                  -6.630984
Policy mu Mean               -0.091994606
Policy mu Std                0.8681291
Policy mu Max                2.2850764
Policy mu Min                -2.770722
Policy log std Mean          -0.49746016
Policy log std Std           0.1983123
Policy log std Max           -0.015901893
Policy log std Min           -1.7781099
Z mean eval                  0.032861974
Z variance eval              0.00054828747
total_rewards                [ 974.93614298 1001.00159935 1215.70571968 1069.66826072  895.30343428
 1237.06437149 3025.06565101 1534.00109665 1961.43836057 1135.30638603]
total_rewards_mean           1404.9491022766015
total_rewards_std            617.0943654224598
total_rewards_max            3025.0656510133063
total_rewards_min            895.3034342812725
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               32.768794290255755
(Previous) Eval Time (s)     19.388894994277507
Sample Time (s)              22.446081303525716
Epoch Time (s)               74.60377058805898
Total Train Time (s)         11301.329411391634
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:05.183314 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #179 | Epoch Duration: 68.1181743144989
2020-01-11 03:11:05.183549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028945308
Z variance train             0.00055246253
KL Divergence                18.534994
KL Loss                      1.8534994
QF Loss                      151.18181
VF Loss                      75.83807
Policy Loss                  -1150.671
Q Predictions Mean           1155.5
Q Predictions Std            489.97513
Q Predictions Max            1568.0764
Q Predictions Min            2.2832985
V Predictions Mean           1154.3911
V Predictions Std            490.90387
V Predictions Max            1559.8561
V Predictions Min            -3.8886223
Log Pis Mean                 -0.10274693
Log Pis Std                  2.2212353
Log Pis Max                  8.94339
Log Pis Min                  -6.7982273
Policy mu Mean               0.032457832
Policy mu Std                0.90543485
Policy mu Max                2.5797768
Policy mu Min                -2.844975
Policy log std Mean          -0.51330656
Policy log std Std           0.18980753
Policy log std Max           -0.03006512
Policy log std Min           -1.5862195
Z mean eval                  0.017787507
Z variance eval              0.000997106
total_rewards                [ 979.2930945   967.73851099  835.96576927 1001.13801    2147.2378498
 1812.02751125 1474.1565182  1333.30401451  941.19230451  819.98620805]
total_rewards_mean           1231.2039791089587
total_rewards_std            429.0859992114608
total_rewards_max            2147.2378498017606
total_rewards_min            819.9862080515453
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               32.17868913523853
(Previous) Eval Time (s)     12.902993639931083
Sample Time (s)              23.704524809960276
Epoch Time (s)               68.78620758512989
Total Train Time (s)         11368.83822321985
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:12.694733 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #180 | Epoch Duration: 67.51103043556213
2020-01-11 03:12:12.694942 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017981086
Z variance train             0.0009959583
KL Divergence                17.38117
KL Loss                      1.7381171
QF Loss                      118.32744
VF Loss                      34.291927
Policy Loss                  -1168.9552
Q Predictions Mean           1167.4587
Q Predictions Std            452.73764
Q Predictions Max            1598.0707
Q Predictions Min            2.303052
V Predictions Mean           1170.484
V Predictions Std            452.33444
V Predictions Max            1592.5123
V Predictions Min            3.657099
Log Pis Mean                 -0.20061794
Log Pis Std                  2.0858479
Log Pis Max                  8.306456
Log Pis Min                  -7.4200897
Policy mu Mean               0.023565814
Policy mu Std                0.90786487
Policy mu Max                2.3059418
Policy mu Min                -2.7327404
Policy log std Mean          -0.50071
Policy log std Std           0.1957841
Policy log std Max           -0.06642085
Policy log std Min           -1.0992162
Z mean eval                  0.022049021
Z variance eval              0.0010918978
total_rewards                [1940.68853831 1048.47546413 1121.55831005 1006.24195491 1734.55426143
  955.61487932 2156.19840302 1242.19854078 1246.20806892 1000.79902374]
total_rewards_mean           1345.2537444619904
total_rewards_std            413.23995870185433
total_rewards_max            2156.198403021069
total_rewards_min            955.6148793247577
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               32.52501734998077
(Previous) Eval Time (s)     11.627473948989064
Sample Time (s)              23.70241148583591
Epoch Time (s)               67.85490278480574
Total Train Time (s)         11437.76887892466
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:13:21.627861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #181 | Epoch Duration: 68.9327745437622
2020-01-11 03:13:21.628067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022124952
Z variance train             0.0010923925
KL Divergence                16.151894
KL Loss                      1.6151894
QF Loss                      126.67406
VF Loss                      61.56687
Policy Loss                  -1207.0509
Q Predictions Mean           1207.7065
Q Predictions Std            418.1675
Q Predictions Max            1548.6277
Q Predictions Min            -3.7068646
V Predictions Mean           1209.236
V Predictions Std            418.50684
V Predictions Max            1550.1367
V Predictions Min            4.2642026
Log Pis Mean                 -0.04871227
Log Pis Std                  2.090192
Log Pis Max                  10.110956
Log Pis Min                  -5.2606773
Policy mu Mean               0.028040959
Policy mu Std                0.89977306
Policy mu Max                2.9577134
Policy mu Min                -2.7277162
Policy log std Mean          -0.5219279
Policy log std Std           0.19001532
Policy log std Max           0.034612685
Policy log std Min           -1.1610558
Z mean eval                  0.008242262
Z variance eval              0.0015004596
total_rewards                [1407.59135202 1640.66960387  913.42278884  903.04059008  973.03633078
 2481.6879224  1845.65627546  974.51594047  996.08813808  994.77999781]
total_rewards_mean           1313.0488939811821
total_rewards_std            502.53771554469813
total_rewards_max            2481.6879224037452
total_rewards_min            903.0405900799715
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               32.31495871441439
(Previous) Eval Time (s)     12.705004959367216
Sample Time (s)              23.536941229831427
Epoch Time (s)               68.55690490361303
Total Train Time (s)         11505.237611125223
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:14:29.099657 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #182 | Epoch Duration: 67.47144889831543
2020-01-11 03:14:29.099971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009687484
Z variance train             0.0015009886
KL Divergence                14.894338
KL Loss                      1.4894338
QF Loss                      287.05457
VF Loss                      42.006176
Policy Loss                  -1220.9447
Q Predictions Mean           1218.8324
Q Predictions Std            414.89728
Q Predictions Max            1562.4824
Q Predictions Min            -0.22795376
V Predictions Mean           1218.4749
V Predictions Std            412.33417
V Predictions Max            1558.4572
V Predictions Min            -1.9515865
Log Pis Mean                 -0.33189708
Log Pis Std                  2.2443066
Log Pis Max                  9.138112
Log Pis Min                  -7.3278184
Policy mu Mean               0.040665302
Policy mu Std                0.9161256
Policy mu Max                2.8775737
Policy mu Min                -3.6581242
Policy log std Mean          -0.5079884
Policy log std Std           0.17783907
Policy log std Max           -0.07996076
Policy log std Min           -1.2671875
Z mean eval                  0.013928227
Z variance eval              0.0018431122
total_rewards                [ 856.85882815 2078.54469408 1045.26387568 1043.79525519 1028.93265218
 1543.8233126  1630.71164815  853.88800695  856.30871674  938.76584649]
total_rewards_mean           1187.6892836218
total_rewards_std            396.9339769938836
total_rewards_max            2078.5446940825964
total_rewards_min            853.8880069480832
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               32.39464753726497
(Previous) Eval Time (s)     11.619229008909315
Sample Time (s)              23.04928716039285
Epoch Time (s)               67.06316370656714
Total Train Time (s)         11570.628446147311
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:34.493279 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #183 | Epoch Duration: 65.39308071136475
2020-01-11 03:15:34.493472 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014634274
Z variance train             0.0018448827
KL Divergence                13.74142
KL Loss                      1.374142
QF Loss                      1868.8491
VF Loss                      339.1683
Policy Loss                  -1165.5237
Q Predictions Mean           1167.2034
Q Predictions Std            431.17142
Q Predictions Max            1550.4313
Q Predictions Min            1.7275636
V Predictions Mean           1164.2513
V Predictions Std            427.27493
V Predictions Max            1537.394
V Predictions Min            -1.3318008
Log Pis Mean                 0.02900245
Log Pis Std                  2.3259776
Log Pis Max                  9.551468
Log Pis Min                  -5.6556478
Policy mu Mean               0.10620997
Policy mu Std                0.9347099
Policy mu Max                2.8718545
Policy mu Min                -3.2859147
Policy log std Mean          -0.5203266
Policy log std Std           0.2041898
Policy log std Max           -0.04038143
Policy log std Min           -1.6765584
Z mean eval                  0.020953897
Z variance eval              0.0023233662
total_rewards                [ 990.57120171 1767.18162073 1162.47327813  900.42438756  974.74648312
  991.26613838 1217.17433083 1001.83717801 1102.24228129 1477.6191185 ]
total_rewards_mean           1158.5536018268062
total_rewards_std            256.910987636102
total_rewards_max            1767.181620725042
total_rewards_min            900.4243875647596
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               32.41678704181686
(Previous) Eval Time (s)     9.948818061035126
Sample Time (s)              23.978217012714595
Epoch Time (s)               66.34382211556658
Total Train Time (s)         11637.48419875605
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:41.349628 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #184 | Epoch Duration: 66.85603475570679
2020-01-11 03:16:41.349751 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022506122
Z variance train             0.0023281886
KL Divergence                12.930206
KL Loss                      1.2930206
QF Loss                      119.63407
VF Loss                      368.75757
Policy Loss                  -1210.5715
Q Predictions Mean           1205.1406
Q Predictions Std            457.75208
Q Predictions Max            1579.0159
Q Predictions Min            4.074231
V Predictions Mean           1205.0166
V Predictions Std            452.1678
V Predictions Max            1575.043
V Predictions Min            3.2449691
Log Pis Mean                 -0.3383971
Log Pis Std                  1.9981589
Log Pis Max                  13.206297
Log Pis Min                  -4.9169426
Policy mu Mean               0.033608656
Policy mu Std                0.8404126
Policy mu Max                2.6495323
Policy mu Min                -3.1257102
Policy log std Mean          -0.51027185
Policy log std Std           0.18260504
Policy log std Max           -0.060727358
Policy log std Min           -1.2911803
Z mean eval                  0.020918103
Z variance eval              0.002633528
total_rewards                [3188.26785609 2044.66249749 1778.78402789 1626.85113317 1329.72112315
 3110.92981326 1271.55961825 3173.7475031  2327.68965387 3270.16753513]
total_rewards_mean           2312.2380761393224
total_rewards_std            770.6931391807443
total_rewards_max            3270.167535130662
total_rewards_min            1271.559618251743
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               31.924570519011468
(Previous) Eval Time (s)     10.460678342264146
Sample Time (s)              23.942527399864048
Epoch Time (s)               66.32777626113966
Total Train Time (s)         11714.885345715564
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:58.753473 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #185 | Epoch Duration: 77.40360379219055
2020-01-11 03:17:58.753654 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0208669
Z variance train             0.002634307
KL Divergence                12.683533
KL Loss                      1.2683533
QF Loss                      135.2431
VF Loss                      37.591915
Policy Loss                  -1166.1395
Q Predictions Mean           1163.9515
Q Predictions Std            454.37274
Q Predictions Max            1553.5259
Q Predictions Min            0.63921773
V Predictions Mean           1165.1969
V Predictions Std            452.65762
V Predictions Max            1554.777
V Predictions Min            0.21407446
Log Pis Mean                 -0.12085298
Log Pis Std                  2.1158597
Log Pis Max                  7.2855434
Log Pis Min                  -4.769036
Policy mu Mean               -0.05969608
Policy mu Std                0.8843588
Policy mu Max                2.413131
Policy mu Min                -2.766073
Policy log std Mean          -0.5035582
Policy log std Std           0.20191526
Policy log std Max           -0.06773317
Policy log std Min           -1.6671633
Z mean eval                  0.019811083
Z variance eval              0.0028715916
total_rewards                [2155.82214953  974.385483   1592.98292379 3209.72523853 1828.23426173
 1256.97996557 1511.96741781  740.06494111 1293.59052398 1863.23261609]
total_rewards_mean           1642.6985521149695
total_rewards_std            659.8131967181881
total_rewards_max            3209.7252385275883
total_rewards_min            740.0649411063075
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               32.62081643473357
(Previous) Eval Time (s)     21.53613673336804
Sample Time (s)              22.828926508314908
Epoch Time (s)               76.98587967641652
Total Train Time (s)         11785.574661088176
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:09.445347 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #186 | Epoch Duration: 70.69155740737915
2020-01-11 03:19:09.445528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019016873
Z variance train             0.0028760426
KL Divergence                12.414953
KL Loss                      1.2414954
QF Loss                      186.75305
VF Loss                      233.86536
Policy Loss                  -1194.8307
Q Predictions Mean           1197.0614
Q Predictions Std            473.87015
Q Predictions Max            1587.8568
Q Predictions Min            -2.0461867
V Predictions Mean           1199.437
V Predictions Std            471.47318
V Predictions Max            1593.8116
V Predictions Min            -1.3467346
Log Pis Mean                 -0.14402233
Log Pis Std                  2.2363982
Log Pis Max                  8.055583
Log Pis Min                  -6.362528
Policy mu Mean               0.032011148
Policy mu Std                0.9147179
Policy mu Max                2.116799
Policy mu Min                -2.7212548
Policy log std Mean          -0.50127417
Policy log std Std           0.1859368
Policy log std Max           -0.08722633
Policy log std Min           -1.8100996
Z mean eval                  0.0055469745
Z variance eval              0.0032249764
total_rewards                [2356.62954884 1844.10836255 1589.65614525 1926.51705055 1299.47398457
 1377.27906758 1268.3256963  2131.7371415  1203.47904164 1530.22999452]
total_rewards_mean           1652.7436033306326
total_rewards_std            374.93307732414763
total_rewards_max            2356.629548844288
total_rewards_min            1203.4790416402927
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               31.240564563311636
(Previous) Eval Time (s)     15.241476716008037
Sample Time (s)              22.708541677799076
Epoch Time (s)               69.19058295711875
Total Train Time (s)         11854.915526831057
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:20:18.788984 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #187 | Epoch Duration: 69.3433198928833
2020-01-11 03:20:18.789155 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0048082145
Z variance train             0.0032344207
KL Divergence                12.152761
KL Loss                      1.2152761
QF Loss                      153.13162
VF Loss                      61.851852
Policy Loss                  -1150.3292
Q Predictions Mean           1146.178
Q Predictions Std            482.9197
Q Predictions Max            1568.5677
Q Predictions Min            -10.499268
V Predictions Mean           1146.9198
V Predictions Std            481.336
V Predictions Max            1566.3291
V Predictions Min            -1.5769612
Log Pis Mean                 -0.37104183
Log Pis Std                  2.1629193
Log Pis Max                  7.2077723
Log Pis Min                  -4.757771
Policy mu Mean               0.005138611
Policy mu Std                0.86934704
Policy mu Max                2.3918786
Policy mu Min                -2.887571
Policy log std Mean          -0.52073574
Policy log std Std           0.21191545
Policy log std Max           -0.040313214
Policy log std Min           -1.79977
Z mean eval                  0.007783021
Z variance eval              0.0028751087
total_rewards                [ 945.27489507 1252.49407727 1690.14212223 1678.94949651 1006.95831624
 1464.39858812  983.12275236 1109.66392098  973.53770863  907.02249073]
total_rewards_mean           1201.156436814029
total_rewards_std            289.2659843638838
total_rewards_max            1690.1421222316194
total_rewards_min            907.0224907294343
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               32.04051895905286
(Previous) Eval Time (s)     15.393889674916863
Sample Time (s)              23.574643636122346
Epoch Time (s)               71.00905227009207
Total Train Time (s)         11921.896917278413
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:25.773327 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #188 | Epoch Duration: 66.98403406143188
2020-01-11 03:21:25.773527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008335526
Z variance train             0.0028764005
KL Divergence                12.326464
KL Loss                      1.2326463
QF Loss                      198.64871
VF Loss                      115.961365
Policy Loss                  -1197.7882
Q Predictions Mean           1196.919
Q Predictions Std            440.96362
Q Predictions Max            1591.2035
Q Predictions Min            5.142582
V Predictions Mean           1193.5044
V Predictions Std            435.72754
V Predictions Max            1577.2349
V Predictions Min            -2.967859
Log Pis Mean                 -0.12126254
Log Pis Std                  2.0962548
Log Pis Max                  14.654613
Log Pis Min                  -6.03995
Policy mu Mean               0.049923625
Policy mu Std                0.92376816
Policy mu Max                2.399307
Policy mu Min                -4.8985066
Policy log std Mean          -0.5120639
Policy log std Std           0.18817541
Policy log std Max           -0.08899504
Policy log std Min           -1.4282717
Z mean eval                  0.018493272
Z variance eval              0.002893468
total_rewards                [2092.37157812 1295.43184031 1541.2706911  1117.89952234 1446.38698464
 1014.00618945 1915.66217243 1025.24368963 1421.11958559 1920.91228702]
total_rewards_mean           1479.0304540651216
total_rewards_std            368.33154266214
total_rewards_max            2092.3715781221263
total_rewards_min            1014.0061894538954
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               32.603341513779014
(Previous) Eval Time (s)     11.368542871903628
Sample Time (s)              23.880937930196524
Epoch Time (s)               67.85282231587917
Total Train Time (s)         11992.037773618475
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:35.916298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #189 | Epoch Duration: 70.1426248550415
2020-01-11 03:22:35.916501 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018066768
Z variance train             0.002892519
KL Divergence                12.324162
KL Loss                      1.2324162
QF Loss                      170.69284
VF Loss                      103.40668
Policy Loss                  -1177.4672
Q Predictions Mean           1179.5737
Q Predictions Std            444.47653
Q Predictions Max            1553.3049
Q Predictions Min            -2.0462878
V Predictions Mean           1174.3126
V Predictions Std            442.31445
V Predictions Max            1537.6089
V Predictions Min            -1.5188024
Log Pis Mean                 -0.1911332
Log Pis Std                  2.1366718
Log Pis Max                  8.136047
Log Pis Min                  -4.0905623
Policy mu Mean               0.059953183
Policy mu Std                0.896384
Policy mu Max                2.8326128
Policy mu Min                -2.6877866
Policy log std Mean          -0.4982334
Policy log std Std           0.20304142
Policy log std Max           -0.06902793
Policy log std Min           -1.5500749
Z mean eval                  0.014143085
Z variance eval              0.0030290086
total_rewards                [1255.85223183  979.29081739 1226.46638157 1272.18171671 2379.26784637
 1006.19624379 1771.10392101  980.90465192 1242.96900831 1037.3386953 ]
total_rewards_mean           1315.1571514202592
total_rewards_std            419.02637562721435
total_rewards_max            2379.2678463697157
total_rewards_min            979.2908173855785
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               32.40905013261363
(Previous) Eval Time (s)     13.658033846877515
Sample Time (s)              23.361056481022388
Epoch Time (s)               69.42814046051353
Total Train Time (s)         12059.275792998727
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:43.157949 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #190 | Epoch Duration: 67.24128866195679
2020-01-11 03:23:43.158269 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014377721
Z variance train             0.003028099
KL Divergence                12.12814
KL Loss                      1.2128141
QF Loss                      284.20203
VF Loss                      84.62216
Policy Loss                  -1193.2092
Q Predictions Mean           1183.4487
Q Predictions Std            434.65625
Q Predictions Max            1574.7393
Q Predictions Min            -20.76606
V Predictions Mean           1188.463
V Predictions Std            428.24362
V Predictions Max            1566.8293
V Predictions Min            1.9315419
Log Pis Mean                 -0.10851313
Log Pis Std                  2.1927679
Log Pis Max                  7.2415533
Log Pis Min                  -5.413657
Policy mu Mean               0.008710452
Policy mu Std                0.94348186
Policy mu Max                3.4486654
Policy mu Min                -3.1555734
Policy log std Mean          -0.5179394
Policy log std Std           0.19840428
Policy log std Max           0.08191386
Policy log std Min           -1.1871569
Z mean eval                  0.013654003
Z variance eval              0.0028380672
total_rewards                [ 928.84234301 1177.90480267 2045.07521684  824.66147142 1462.64327224
 1264.00751342 1966.74178796  950.08865459 1106.11439302 3169.13237946]
total_rewards_mean           1489.5211834632369
total_rewards_std            685.605176784787
total_rewards_max            3169.132379460695
total_rewards_min            824.661471418567
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               31.916598895099014
(Previous) Eval Time (s)     11.470850876998156
Sample Time (s)              23.739870194811374
Epoch Time (s)               67.12731996690854
Total Train Time (s)         12128.37262456771
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:24:52.259267 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #191 | Epoch Duration: 69.10068845748901
2020-01-11 03:24:52.259593 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013624063
Z variance train             0.0028506485
KL Divergence                12.362348
KL Loss                      1.2362348
QF Loss                      153.09406
VF Loss                      330.0028
Policy Loss                  -1258.6559
Q Predictions Mean           1253.9786
Q Predictions Std            401.65942
Q Predictions Max            1566.9147
Q Predictions Min            -13.160859
V Predictions Mean           1260.001
V Predictions Std            397.3831
V Predictions Max            1563.7377
V Predictions Min            0.69533885
Log Pis Mean                 -0.36918604
Log Pis Std                  2.1255734
Log Pis Max                  16.806675
Log Pis Min                  -5.72427
Policy mu Mean               0.06928282
Policy mu Std                0.8583668
Policy mu Max                2.5063202
Policy mu Min                -4.321377
Policy log std Mean          -0.51247364
Policy log std Std           0.19257726
Policy log std Max           -0.007873714
Policy log std Min           -1.7851135
Z mean eval                  0.026447365
Z variance eval              0.0027314574
total_rewards                [3294.92378989 3116.28791785 1840.28251556 3229.67763563 1039.9685838
 1022.85794784 1038.0361348  1123.70651048 1004.670766   1601.2200702 ]
total_rewards_mean           1831.1631872041962
total_rewards_std            943.1289302306839
total_rewards_max            3294.9237898855513
total_rewards_min            1004.6707659984445
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               32.78661653166637
(Previous) Eval Time (s)     13.443844594992697
Sample Time (s)              23.762368492782116
Epoch Time (s)               69.99282961944118
Total Train Time (s)         12202.148008584976
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:06.037821 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #192 | Epoch Duration: 73.77798819541931
2020-01-11 03:26:06.038002 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026885573
Z variance train             0.0027284615
KL Divergence                12.443641
KL Loss                      1.2443641
QF Loss                      206.06154
VF Loss                      51.952843
Policy Loss                  -1177.4254
Q Predictions Mean           1174.5752
Q Predictions Std            453.11398
Q Predictions Max            1556.7382
Q Predictions Min            -7.353804
V Predictions Mean           1173.5566
V Predictions Std            447.9937
V Predictions Max            1553.2853
V Predictions Min            3.2951655
Log Pis Mean                 -0.24466808
Log Pis Std                  2.1452563
Log Pis Max                  12.717401
Log Pis Min                  -5.085195
Policy mu Mean               0.1099424
Policy mu Std                0.88011706
Policy mu Max                4.2856174
Policy mu Min                -2.563917
Policy log std Mean          -0.5099714
Policy log std Std           0.19671723
Policy log std Max           -0.082832575
Policy log std Min           -1.302316
Z mean eval                  0.011353497
Z variance eval              0.0029019397
total_rewards                [2086.49452376 3152.45935444 2630.3007548  3136.87826504 1014.90772591
 3042.17301302 3121.39839849 1286.91097071 1682.93191643 1026.2835089 ]
total_rewards_mean           2218.073843150523
total_rewards_std            861.456369796937
total_rewards_max            3152.459354443667
total_rewards_min            1014.9077259147047
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               32.35005473671481
(Previous) Eval Time (s)     17.228622530121356
Sample Time (s)              21.89304142119363
Epoch Time (s)               71.4717186880298
Total Train Time (s)         12277.818994265515
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:21.710454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #193 | Epoch Duration: 75.67232155799866
2020-01-11 03:27:21.710626 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011614869
Z variance train             0.0028945399
KL Divergence                12.216087
KL Loss                      1.2216088
QF Loss                      177.12416
VF Loss                      96.641266
Policy Loss                  -1209.6272
Q Predictions Mean           1207.9792
Q Predictions Std            433.14767
Q Predictions Max            1601.2341
Q Predictions Min            2.7258015
V Predictions Mean           1203.7671
V Predictions Std            430.2452
V Predictions Max            1585.6245
V Predictions Min            0.66318285
Log Pis Mean                 -0.09881626
Log Pis Std                  2.284417
Log Pis Max                  9.394926
Log Pis Min                  -5.3147106
Policy mu Mean               0.0359655
Policy mu Std                0.9083923
Policy mu Max                2.4998147
Policy mu Min                -2.6249945
Policy log std Mean          -0.5226696
Policy log std Std           0.21088511
Policy log std Max           0.015922546
Policy log std Min           -1.5883924
Z mean eval                  0.050608702
Z variance eval              0.002042165
total_rewards                [1032.24201943 1578.15648508 1853.07484892 1148.16311714 3134.47439174
 3071.28143024 1004.88275531 3174.18746224 1011.77322871 1575.33739252]
total_rewards_mean           1858.357313133504
total_rewards_std            873.0220549769876
total_rewards_max            3174.187462238127
total_rewards_min            1004.8827553113597
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               33.98608610732481
(Previous) Eval Time (s)     21.428918472025543
Sample Time (s)              22.9063814105466
Epoch Time (s)               78.32138598989695
Total Train Time (s)         12352.668471637182
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:36.562913 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #194 | Epoch Duration: 74.85215258598328
2020-01-11 03:28:36.563098 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053120695
Z variance train             0.0023562605
KL Divergence                12.749533
KL Loss                      1.2749532
QF Loss                      190.52342
VF Loss                      80.748474
Policy Loss                  -1197.4832
Q Predictions Mean           1200.8917
Q Predictions Std            420.73395
Q Predictions Max            1577.1765
Q Predictions Min            3.0444589
V Predictions Mean           1194.7166
V Predictions Std            417.773
V Predictions Max            1564.7002
V Predictions Min            1.4429079
Log Pis Mean                 -0.26800227
Log Pis Std                  2.0258498
Log Pis Max                  6.8612905
Log Pis Min                  -4.9957347
Policy mu Mean               -0.012706511
Policy mu Std                0.87578946
Policy mu Max                2.376091
Policy mu Min                -3.0812933
Policy log std Mean          -0.5038492
Policy log std Std           0.21378012
Policy log std Max           -0.03447926
Policy log std Min           -1.7155697
Z mean eval                  0.041248538
Z variance eval              0.0018027602
total_rewards                [1773.29902775 2747.19805219 1314.06286822 1982.43976335 2944.65597135
 1282.61377661 1823.6292997   963.94091859 1325.09226335 3122.33502434]
total_rewards_mean           1927.9266965445622
total_rewards_std            724.9310354547789
total_rewards_max            3122.335024342719
total_rewards_min            963.940918592092
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               34.22530283778906
(Previous) Eval Time (s)     17.959343222901225
Sample Time (s)              23.926676894072443
Epoch Time (s)               76.11132295476273
Total Train Time (s)         12430.190401267726
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:54.087298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #195 | Epoch Duration: 77.52403283119202
2020-01-11 03:29:54.087484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038983095
Z variance train             0.0018064954
KL Divergence                13.429141
KL Loss                      1.3429141
QF Loss                      159.63614
VF Loss                      187.33875
Policy Loss                  -1217.8242
Q Predictions Mean           1221.1887
Q Predictions Std            437.22516
Q Predictions Max            1583.1647
Q Predictions Min            -2.6732812
V Predictions Mean           1228.175
V Predictions Std            437.18436
V Predictions Max            1582.0153
V Predictions Min            0.21733925
Log Pis Mean                 -0.022592459
Log Pis Std                  2.2228167
Log Pis Max                  8.507908
Log Pis Min                  -5.9737477
Policy mu Mean               -0.20480156
Policy mu Std                0.9284098
Policy mu Max                2.08056
Policy mu Min                -3.086259
Policy log std Mean          -0.5158797
Policy log std Std           0.19746825
Policy log std Max           0.03216076
Policy log std Min           -1.5322299
Z mean eval                  0.024616929
Z variance eval              0.001532899
total_rewards                [3024.95223529 1517.98629366 3180.16428022 1046.97917667 1847.03665239
 1296.35567625 1810.64195346  987.57990069  983.19706538 1290.21783839]
total_rewards_mean           1698.5111072402228
total_rewards_std            761.051125962628
total_rewards_max            3180.1642802204115
total_rewards_min            983.1970653788045
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               35.03308336017653
(Previous) Eval Time (s)     19.37169587612152
Sample Time (s)              24.747306934557855
Epoch Time (s)               79.15208617085591
Total Train Time (s)         12506.828197172377
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:10.728354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #196 | Epoch Duration: 76.64073133468628
2020-01-11 03:31:10.728548 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02800464
Z variance train             0.001522234
KL Divergence                13.977217
KL Loss                      1.3977216
QF Loss                      386.05048
VF Loss                      156.62613
Policy Loss                  -1246.1301
Q Predictions Mean           1245.0793
Q Predictions Std            394.258
Q Predictions Max            1578.041
Q Predictions Min            -5.871871
V Predictions Mean           1242.6775
V Predictions Std            390.34113
V Predictions Max            1567.8969
V Predictions Min            -1.2574283
Log Pis Mean                 -0.2797184
Log Pis Std                  1.964537
Log Pis Max                  9.341995
Log Pis Min                  -4.7043357
Policy mu Mean               0.03115577
Policy mu Std                0.8675877
Policy mu Max                3.1674416
Policy mu Min                -2.584064
Policy log std Mean          -0.4957473
Policy log std Std           0.18524279
Policy log std Max           0.07234022
Policy log std Min           -1.3942894
Z mean eval                  0.02318455
Z variance eval              0.0017843607
total_rewards                [1823.98310641 2732.35269792 2266.79016478  201.14523214 1204.95685868
 1931.88349243 1806.19032919 1544.4151727   198.49481608 1501.86918923]
total_rewards_mean           1521.2081059557936
total_rewards_std            771.8399783442968
total_rewards_max            2732.35269792173
total_rewards_min            198.49481607579918
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               34.67744483426213
(Previous) Eval Time (s)     16.859963693656027
Sample Time (s)              23.874445585533977
Epoch Time (s)               75.41185411345214
Total Train Time (s)         12578.70943867322
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:22.611609 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #197 | Epoch Duration: 71.88292288780212
2020-01-11 03:32:22.611788 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023538053
Z variance train             0.0017823598
KL Divergence                13.525833
KL Loss                      1.3525833
QF Loss                      583.33624
VF Loss                      171.146
Policy Loss                  -1154.6683
Q Predictions Mean           1155.9738
Q Predictions Std            489.1032
Q Predictions Max            1565.655
Q Predictions Min            -9.484184
V Predictions Mean           1157.8037
V Predictions Std            490.24753
V Predictions Max            1576.7739
V Predictions Min            -1.121738
Log Pis Mean                 -0.053615443
Log Pis Std                  2.1027806
Log Pis Max                  8.965125
Log Pis Min                  -4.320204
Policy mu Mean               -0.03043648
Policy mu Std                0.9186943
Policy mu Max                2.898023
Policy mu Min                -2.836758
Policy log std Mean          -0.487824
Policy log std Std           0.2079988
Policy log std Max           0.023851424
Policy log std Min           -1.2862394
Z mean eval                  0.015503081
Z variance eval              0.0017332544
total_rewards                [1109.40210632 2140.59228305 1519.93793746 1076.2585644  2093.19192011
 1014.78560379 3138.28310625 1016.78754709 1541.90152291 1408.42356828]
total_rewards_mean           1605.956415965607
total_rewards_std            643.857852955423
total_rewards_max            3138.2831062515643
total_rewards_min            1014.7856037930378
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               34.26530104968697
(Previous) Eval Time (s)     13.330710561014712
Sample Time (s)              23.513192788232118
Epoch Time (s)               71.1092043989338
Total Train Time (s)         12652.084450684022
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:33:35.989982 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #198 | Epoch Duration: 73.37802934646606
2020-01-11 03:33:35.990274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015788795
Z variance train             0.0017296709
KL Divergence                13.688587
KL Loss                      1.3688587
QF Loss                      136.66144
VF Loss                      159.49503
Policy Loss                  -1188.7394
Q Predictions Mean           1184.1682
Q Predictions Std            480.66257
Q Predictions Max            1593.482
Q Predictions Min            -18.341297
V Predictions Mean           1181.3363
V Predictions Std            478.48633
V Predictions Max            1596.7177
V Predictions Min            -0.38254702
Log Pis Mean                 -0.030029483
Log Pis Std                  2.042969
Log Pis Max                  6.104021
Log Pis Min                  -4.465418
Policy mu Mean               0.051089723
Policy mu Std                0.93803287
Policy mu Max                2.474129
Policy mu Min                -2.7669675
Policy log std Mean          -0.49988183
Policy log std Std           0.18857446
Policy log std Max           -0.084764004
Policy log std Min           -1.4039204
Z mean eval                  0.018116843
Z variance eval              0.001176515
total_rewards                [2314.00349198 1448.66698747  971.98911435 1629.70782341 1839.06111479
  974.22606655 1018.40161148  995.11554659 2574.51210261 1652.13523222]
total_rewards_mean           1541.7819091443848
total_rewards_std            547.6647216989223
total_rewards_max            2574.5121026067486
total_rewards_min            971.9891143489531
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               34.956593442708254
(Previous) Eval Time (s)     15.599121518898755
Sample Time (s)              23.811608073767275
Epoch Time (s)               74.36732303537428
Total Train Time (s)         12726.03547937423
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:49.945554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #199 | Epoch Duration: 73.95511388778687
2020-01-11 03:34:49.945688 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016999979
Z variance train             0.0011799017
KL Divergence                14.674641
KL Loss                      1.4674641
QF Loss                      116.09908
VF Loss                      128.46019
Policy Loss                  -1227.3966
Q Predictions Mean           1226.6924
Q Predictions Std            419.1303
Q Predictions Max            1582.2637
Q Predictions Min            -2.6594892
V Predictions Mean           1223.2052
V Predictions Std            416.69904
V Predictions Max            1575.4137
V Predictions Min            2.685093
Log Pis Mean                 -0.18817404
Log Pis Std                  1.9839466
Log Pis Max                  7.7432084
Log Pis Min                  -6.1993113
Policy mu Mean               0.058279827
Policy mu Std                0.8757294
Policy mu Max                2.8645449
Policy mu Min                -2.9505818
Policy log std Mean          -0.4973952
Policy log std Std           0.18451029
Policy log std Max           -0.02807349
Policy log std Min           -1.307089
Z mean eval                  0.023268156
Z variance eval              0.0013035142
total_rewards                [3271.6040755  1022.25863769  980.38595988 1002.72053749  978.17954846
  901.43502487 1149.25852029 2354.45479439 2027.5470935   984.0740725 ]
total_rewards_mean           1467.1918264577214
total_rewards_std            768.2131445414349
total_rewards_max            3271.6040754968635
total_rewards_min            901.4350248662748
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               34.10852917609736
(Previous) Eval Time (s)     15.186522143892944
Sample Time (s)              23.597891725599766
Epoch Time (s)               72.89294304559007
Total Train Time (s)         12797.508189278655
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:01.421253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #200 | Epoch Duration: 71.47545289993286
2020-01-11 03:36:01.421435 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023173254
Z variance train             0.0013006323
KL Divergence                14.547354
KL Loss                      1.4547354
QF Loss                      142.76117
VF Loss                      66.714355
Policy Loss                  -1242.8683
Q Predictions Mean           1238.9403
Q Predictions Std            391.59058
Q Predictions Max            1586.1766
Q Predictions Min            0.94719476
V Predictions Mean           1242.633
V Predictions Std            390.4152
V Predictions Max            1593.0961
V Predictions Min            4.7524176
Log Pis Mean                 0.23464271
Log Pis Std                  2.049382
Log Pis Max                  6.970715
Log Pis Min                  -6.325634
Policy mu Mean               -0.08601827
Policy mu Std                0.96689373
Policy mu Max                2.205608
Policy mu Min                -2.4915032
Policy log std Mean          -0.5041302
Policy log std Std           0.18639977
Policy log std Max           -0.016802073
Policy log std Min           -1.5430939
Z mean eval                  0.020324668
Z variance eval              0.0011638285
total_rewards                [ 995.55985241 3115.60761175 2517.52633081 1544.72983622  974.92672548
 2963.46720464 3068.7259393  1592.75100492 3076.7341721  1886.45060212]
total_rewards_mean           2173.647927975448
total_rewards_std            829.8415416642245
total_rewards_max            3115.607611752874
total_rewards_min            974.9267254775629
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               34.25992871914059
(Previous) Eval Time (s)     13.768670903984457
Sample Time (s)              22.760722475592047
Epoch Time (s)               70.7893220987171
Total Train Time (s)         12876.119791011792
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:37:20.037947 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #201 | Epoch Duration: 78.61637020111084
2020-01-11 03:37:20.038140 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018895522
Z variance train             0.0011679882
KL Divergence                14.898067
KL Loss                      1.4898068
QF Loss                      117.021164
VF Loss                      51.769962
Policy Loss                  -1229.862
Q Predictions Mean           1229.781
Q Predictions Std            417.6766
Q Predictions Max            1586.357
Q Predictions Min            -1.7248828
V Predictions Mean           1231.4976
V Predictions Std            417.06033
V Predictions Max            1591.7288
V Predictions Min            3.8076377
Log Pis Mean                 -0.09818219
Log Pis Std                  2.0661616
Log Pis Max                  7.1374054
Log Pis Min                  -3.5569992
Policy mu Mean               -0.051967368
Policy mu Std                0.87762266
Policy mu Max                2.6880043
Policy mu Min                -2.704781
Policy log std Mean          -0.50388175
Policy log std Std           0.18542652
Policy log std Max           -0.0020374358
Policy log std Min           -1.6534133
Z mean eval                  0.030904796
Z variance eval              0.0013534982
total_rewards                [1019.81266804 2775.57614863  981.9677245  1164.62994207 2669.60584663
  992.99158848 1115.44048043 2424.86013295  960.67021342 2163.68863007]
total_rewards_mean           1626.9243375225337
total_rewards_std            737.3638108963505
total_rewards_max            2775.576148634796
total_rewards_min            960.6702134202354
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               34.981767563614994
(Previous) Eval Time (s)     21.595390308182687
Sample Time (s)              25.11333484854549
Epoch Time (s)               81.69049272034317
Total Train Time (s)         12950.784556264058
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:34.705044 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #202 | Epoch Duration: 74.66672253608704
2020-01-11 03:38:34.705350 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031108122
Z variance train             0.0013590375
KL Divergence                14.550158
KL Loss                      1.4550158
QF Loss                      126.58194
VF Loss                      117.914276
Policy Loss                  -1218.4641
Q Predictions Mean           1215.5425
Q Predictions Std            433.3045
Q Predictions Max            1568.8826
Q Predictions Min            0.31437355
V Predictions Mean           1211.9539
V Predictions Std            429.59805
V Predictions Max            1567.3613
V Predictions Min            2.7299771
Log Pis Mean                 0.030022092
Log Pis Std                  2.071895
Log Pis Max                  7.9381104
Log Pis Min                  -4.815683
Policy mu Mean               0.16983156
Policy mu Std                0.9398599
Policy mu Max                2.8608494
Policy mu Min                -2.6624093
Policy log std Mean          -0.4987104
Policy log std Std           0.19512004
Policy log std Max           -0.07012305
Policy log std Min           -1.753272
Z mean eval                  0.017645365
Z variance eval              0.0015832105
total_rewards                [3174.53221978 1330.96418956 1692.12621832 2367.8069977  1039.03459311
 2415.01735252 1361.40712219 1068.27427827 1270.2927032  1377.84918011]
total_rewards_mean           1709.7304854771712
total_rewards_std            671.2519031836927
total_rewards_max            3174.5322197839605
total_rewards_min            1039.0345931116556
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               34.537951150909066
(Previous) Eval Time (s)     14.571191100869328
Sample Time (s)              23.85914665926248
Epoch Time (s)               72.96828891104087
Total Train Time (s)         13024.882518510334
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:48.805137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #203 | Epoch Duration: 74.09960985183716
2020-01-11 03:39:48.805342 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017732898
Z variance train             0.0015840002
KL Divergence                14.10298
KL Loss                      1.410298
QF Loss                      221.0911
VF Loss                      43.115387
Policy Loss                  -1247.4174
Q Predictions Mean           1245.4968
Q Predictions Std            392.58545
Q Predictions Max            1586.0054
Q Predictions Min            1.9942012
V Predictions Mean           1247.71
V Predictions Std            390.41678
V Predictions Max            1583.3635
V Predictions Min            -6.818566
Log Pis Mean                 -0.077285156
Log Pis Std                  2.0851011
Log Pis Max                  6.4867167
Log Pis Min                  -4.090596
Policy mu Mean               0.0358057
Policy mu Std                0.89976096
Policy mu Max                3.2825074
Policy mu Min                -3.269732
Policy log std Mean          -0.49657726
Policy log std Std           0.18911907
Policy log std Max           -0.068384826
Policy log std Min           -1.3054323
Z mean eval                  0.23263256
Z variance eval              0.0017084792
total_rewards                [2087.62621083  995.66468498 3276.28371659 2906.89158491 3005.23350349
 1464.48247985 1587.37052321  984.47236787 2457.35544754 3226.20829707]
total_rewards_mean           2199.1588816348944
total_rewards_std            853.3856870925788
total_rewards_max            3276.283716585758
total_rewards_min            984.4723678736018
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               34.672382913995534
(Previous) Eval Time (s)     15.702138016931713
Sample Time (s)              23.63302112556994
Epoch Time (s)               74.00754205649719
Total Train Time (s)         13102.657563535031
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:41:06.583001 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #204 | Epoch Duration: 77.77752208709717
2020-01-11 03:41:06.583179 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025057886
Z variance train             0.0014343166
KL Divergence                14.084213
KL Loss                      1.4084214
QF Loss                      205.5065
VF Loss                      132.72731
Policy Loss                  -1264.3595
Q Predictions Mean           1261.3782
Q Predictions Std            395.0593
Q Predictions Max            1584.8926
Q Predictions Min            -30.780056
V Predictions Mean           1263.5308
V Predictions Std            393.02798
V Predictions Max            1594.5491
V Predictions Min            2.856171
Log Pis Mean                 -0.121876486
Log Pis Std                  2.0362182
Log Pis Max                  8.878868
Log Pis Min                  -4.6427794
Policy mu Mean               0.009471598
Policy mu Std                0.8940939
Policy mu Max                2.4301975
Policy mu Min                -3.7090487
Policy log std Mean          -0.501784
Policy log std Std           0.18552415
Policy log std Max           -0.0035151243
Policy log std Min           -1.1225761
Z mean eval                  0.100170515
Z variance eval              0.0018823694
total_rewards                [2120.13625231  980.13677625 2131.8121096  3175.86105071 3287.71236397
 3231.00541025 1492.95877896 2688.91951594 1060.96564768 1603.44160325]
total_rewards_mean           2177.294950892602
total_rewards_std            841.6985677478201
total_rewards_max            3287.712363972309
total_rewards_min            980.1367762549514
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               34.68563881609589
(Previous) Eval Time (s)     19.471759513951838
Sample Time (s)              24.38645103480667
Epoch Time (s)               78.5438493648544
Total Train Time (s)         13181.244412508328
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:25.174603 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #205 | Epoch Duration: 78.59127140045166
2020-01-11 03:42:25.174802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10100838
Z variance train             0.001879346
KL Divergence                13.597113
KL Loss                      1.3597113
QF Loss                      89.151535
VF Loss                      111.01951
Policy Loss                  -1233.2925
Q Predictions Mean           1233.3247
Q Predictions Std            389.1326
Q Predictions Max            1556.4648
Q Predictions Min            1.802242
V Predictions Mean           1240.629
V Predictions Std            390.5048
V Predictions Max            1557.5913
V Predictions Min            5.552917
Log Pis Mean                 -0.25381887
Log Pis Std                  2.0645006
Log Pis Max                  6.117346
Log Pis Min                  -5.624899
Policy mu Mean               -0.041087303
Policy mu Std                0.8754756
Policy mu Max                2.116456
Policy mu Min                -2.568796
Policy log std Mean          -0.47577682
Policy log std Std           0.18588912
Policy log std Max           -0.07883182
Policy log std Min           -1.1583086
Z mean eval                  0.04259815
Z variance eval              0.0019778605
total_rewards                [3097.49316646 1390.80520835 2892.42313483 3142.75419124 3118.31247518
 3133.67306905  874.48436569 3134.74099753  994.62685267 2897.51340309]
total_rewards_mean           2467.682686410653
total_rewards_std            916.362933253868
total_rewards_max            3142.7541912422703
total_rewards_min            874.4843656857034
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               32.80293134087697
(Previous) Eval Time (s)     19.518788470886648
Sample Time (s)              22.650255947373807
Epoch Time (s)               74.97197575913742
Total Train Time (s)         13260.450293194503
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:43:44.382220 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #206 | Epoch Duration: 79.20726704597473
2020-01-11 03:43:44.382465 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043433256
Z variance train             0.001976102
KL Divergence                13.326544
KL Loss                      1.3326544
QF Loss                      166.34705
VF Loss                      69.13062
Policy Loss                  -1243.1699
Q Predictions Mean           1244.9875
Q Predictions Std            375.8142
Q Predictions Max            1558.1196
Q Predictions Min            -2.8630428
V Predictions Mean           1242.0245
V Predictions Std            374.8391
V Predictions Max            1555.7125
V Predictions Min            0.28456825
Log Pis Mean                 -0.110003084
Log Pis Std                  2.0650468
Log Pis Max                  5.965447
Log Pis Min                  -4.8240185
Policy mu Mean               -0.078561254
Policy mu Std                0.9038
Policy mu Max                3.1549428
Policy mu Min                -3.5366306
Policy log std Mean          -0.47897327
Policy log std Std           0.18842967
Policy log std Max           -0.06486118
Policy log std Min           -1.3031706
Z mean eval                  0.029927636
Z variance eval              0.0017314147
total_rewards                [1006.33832634  893.86940742 1323.19939162  836.41513163 2150.17909817
 1024.3398522   913.27522742  992.96187369  991.22611368  986.4690479 ]
total_rewards_mean           1111.8273470071135
total_rewards_std            367.2605822851295
total_rewards_max            2150.179098174171
total_rewards_min            836.4151316333816
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               32.54613654408604
(Previous) Eval Time (s)     23.753747661598027
Sample Time (s)              22.676763174124062
Epoch Time (s)               78.97664737980813
Total Train Time (s)         13325.956935908645
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:49.891328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #207 | Epoch Duration: 65.50869178771973
2020-01-11 03:44:49.891504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030659938
Z variance train             0.0017293297
KL Divergence                13.616629
KL Loss                      1.3616629
QF Loss                      170.82454
VF Loss                      145.84663
Policy Loss                  -1272.6116
Q Predictions Mean           1272.3481
Q Predictions Std            382.94016
Q Predictions Max            1591.4269
Q Predictions Min            2.105215
V Predictions Mean           1276.8854
V Predictions Std            383.69055
V Predictions Max            1597.0264
V Predictions Min            1.5318031
Log Pis Mean                 -0.20356455
Log Pis Std                  1.8502688
Log Pis Max                  5.907042
Log Pis Min                  -5.146513
Policy mu Mean               0.062346756
Policy mu Std                0.8629704
Policy mu Max                2.1044557
Policy mu Min                -2.6414106
Policy log std Mean          -0.516893
Policy log std Std           0.1790375
Policy log std Max           -0.10527578
Policy log std Min           -1.2502918
Z mean eval                  0.014584573
Z variance eval              0.0016977256
total_rewards                [1210.76894603  675.78703755 3129.83030695 1217.29576819  985.41609292
 1241.69656609  795.00127145 1331.34658995  906.24226809  969.75209898]
total_rewards_mean           1246.313694620226
total_rewards_std            659.2706749839416
total_rewards_max            3129.830306953404
total_rewards_min            675.7870375495568
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               32.58967105997726
(Previous) Eval Time (s)     10.285508322995156
Sample Time (s)              21.175076172687113
Epoch Time (s)               64.05025555565953
Total Train Time (s)         13391.312875553966
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:45:55.250003 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #208 | Epoch Duration: 65.3583619594574
2020-01-11 03:45:55.250205 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014418544
Z variance train             0.0017013786
KL Divergence                13.607401
KL Loss                      1.3607401
QF Loss                      226.56424
VF Loss                      107.461334
Policy Loss                  -1268.0454
Q Predictions Mean           1261.3025
Q Predictions Std            398.53412
Q Predictions Max            1571.4238
Q Predictions Min            1.2517599
V Predictions Mean           1271.1428
V Predictions Std            401.6321
V Predictions Max            1594.3618
V Predictions Min            -2.4980283
Log Pis Mean                 -0.33551317
Log Pis Std                  1.7439759
Log Pis Max                  6.333357
Log Pis Min                  -4.67553
Policy mu Mean               0.07647696
Policy mu Std                0.83977
Policy mu Max                2.4673686
Policy mu Min                -2.6417034
Policy log std Mean          -0.49405324
Policy log std Std           0.18385601
Policy log std Max           -0.036769688
Policy log std Min           -1.4725884
Z mean eval                  0.008226733
Z variance eval              0.001769644
total_rewards                [1764.15339181  456.16103836  974.68212886 1028.18396073 2793.28123559
  930.3687474  3075.37365317  201.56517146 1076.97945359 1005.61470797]
total_rewards_mean           1330.6363488920922
total_rewards_std            892.1468510683242
total_rewards_max            3075.373653166884
total_rewards_min            201.56517146006797
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               32.557115567848086
(Previous) Eval Time (s)     11.593289927579463
Sample Time (s)              22.78905849950388
Epoch Time (s)               66.93946399493143
Total Train Time (s)         13459.0732394699
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:03.011433 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #209 | Epoch Duration: 67.76109647750854
2020-01-11 03:47:03.011576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008158268
Z variance train             0.0017709933
KL Divergence                13.572355
KL Loss                      1.3572356
QF Loss                      77.67961
VF Loss                      31.203308
Policy Loss                  -1244.9563
Q Predictions Mean           1243.3618
Q Predictions Std            406.78726
Q Predictions Max            1572.8123
Q Predictions Min            2.6629605
V Predictions Mean           1245.8748
V Predictions Std            404.80463
V Predictions Max            1579.405
V Predictions Min            3.630656
Log Pis Mean                 -0.41749167
Log Pis Std                  1.9905385
Log Pis Max                  7.1593037
Log Pis Min                  -4.4327
Policy mu Mean               0.043631732
Policy mu Std                0.8344491
Policy mu Max                2.678685
Policy mu Min                -2.720705
Policy log std Mean          -0.4781841
Policy log std Std           0.19898333
Policy log std Max           0.028838605
Policy log std Min           -1.7310916
Z mean eval                  0.011275977
Z variance eval              0.0017636422
total_rewards                [ 955.74600784  705.51580578 1712.54935689  214.92760101 1179.08786714
  874.75477173 1289.35790027  611.33914363 1054.02514526 2467.62654682]
total_rewards_mean           1106.4930146377167
total_rewards_std            594.8720431145399
total_rewards_max            2467.6265468194874
total_rewards_min            214.9276010119543
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               32.67363090766594
(Previous) Eval Time (s)     12.414636936970055
Sample Time (s)              21.319335801526904
Epoch Time (s)               66.4076036461629
Total Train Time (s)         13522.727283380926
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:06.670319 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #210 | Epoch Duration: 63.65851330757141
2020-01-11 03:48:06.670704 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #210 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01051779
Z variance train             0.0017658519
KL Divergence                13.562447
KL Loss                      1.3562447
QF Loss                      198.49576
VF Loss                      56.193707
Policy Loss                  -1236.6007
Q Predictions Mean           1239.8794
Q Predictions Std            443.2857
Q Predictions Max            1627.8281
Q Predictions Min            6.2770886
V Predictions Mean           1239.3517
V Predictions Std            444.41037
V Predictions Max            1632.85
V Predictions Min            1.8889005
Log Pis Mean                 -0.42843193
Log Pis Std                  1.9531114
Log Pis Max                  6.618271
Log Pis Min                  -4.801468
Policy mu Mean               0.027389785
Policy mu Std                0.8462531
Policy mu Max                2.3084476
Policy mu Min                -2.7846155
Policy log std Mean          -0.4717163
Policy log std Std           0.18217842
Policy log std Max           0.009310663
Policy log std Min           -1.124519
Z mean eval                  0.036714014
Z variance eval              0.0019200144
total_rewards                [819.98599109 463.03506503 785.76416089 430.13447755 705.84167675
 201.28357017 665.43292551 460.00590484 766.90838192 582.56116107]
total_rewards_mean           588.0953314811482
total_rewards_std            187.4348486758025
total_rewards_max            819.9859910850264
total_rewards_min            201.28357016648766
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               33.70676553295925
(Previous) Eval Time (s)     9.665194456931204
Sample Time (s)              23.642635563854128
Epoch Time (s)               67.01459555374458
Total Train Time (s)         13585.997721490916
Epoch                        211
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:49:09.942380 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #211 | Epoch Duration: 63.2714569568634
2020-01-11 03:49:09.942580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #211 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03647175
Z variance train             0.0019214904
KL Divergence                13.397612
KL Loss                      1.3397611
QF Loss                      75.48088
VF Loss                      62.385685
Policy Loss                  -1272.6643
Q Predictions Mean           1274.5571
Q Predictions Std            371.75342
Q Predictions Max            1625.2365
Q Predictions Min            2.7316194
V Predictions Mean           1275.1243
V Predictions Std            370.61398
V Predictions Max            1625.546
V Predictions Min            0.63284355
Log Pis Mean                 -0.40096575
Log Pis Std                  1.8909492
Log Pis Max                  6.211441
Log Pis Min                  -6.431894
Policy mu Mean               -0.05372804
Policy mu Std                0.86833936
Policy mu Max                2.2231386
Policy mu Min                -2.9230244
Policy log std Mean          -0.48603797
Policy log std Std           0.17657797
Policy log std Max           0.06077522
Policy log std Min           -1.2539839
Z mean eval                  0.022677267
Z variance eval              0.0021904665
total_rewards                [591.67363099 420.32187293 661.49601109 610.32260418 887.35142899
 192.99207296  18.89336971 652.69255305 655.9736784  424.36166174]
total_rewards_mean           511.6078884023871
total_rewards_std            240.99373752352562
total_rewards_max            887.3514289926225
total_rewards_min            18.89336970636012
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               32.51645279210061
(Previous) Eval Time (s)     5.921771047171205
Sample Time (s)              19.82446401519701
Epoch Time (s)               58.26268785446882
Total Train Time (s)         13643.125975230243
Epoch                        212
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:07.073590 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #212 | Epoch Duration: 57.130784034729004
2020-01-11 03:50:07.073870 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022058595
Z variance train             0.002185834
KL Divergence                13.017111
KL Loss                      1.3017111
QF Loss                      140.8595
VF Loss                      33.925606
Policy Loss                  -1281.1282
Q Predictions Mean           1283.5873
Q Predictions Std            399.7824
Q Predictions Max            1579.3022
Q Predictions Min            2.3370667
V Predictions Mean           1278.1439
V Predictions Std            398.04184
V Predictions Max            1572.9432
V Predictions Min            4.517834
Log Pis Mean                 -0.39564377
Log Pis Std                  1.8153527
Log Pis Max                  6.4145665
Log Pis Min                  -5.743714
Policy mu Mean               0.024495617
Policy mu Std                0.8254433
Policy mu Max                1.9543307
Policy mu Min                -2.7742224
Policy log std Mean          -0.5117927
Policy log std Std           0.1812075
Policy log std Max           -0.029254913
Policy log std Min           -1.1990516
Z mean eval                  0.013368905
Z variance eval              0.0025293694
total_rewards                [ 193.45548738 1094.1099296     4.30426149  567.34272518  205.91396275
  434.68493111 1210.77392421  200.35607572  633.90750934  599.75060843]
total_rewards_mean           514.4599415222422
total_rewards_std            375.32847861038834
total_rewards_max            1210.7739242108626
total_rewards_min            4.304261485821845
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               32.7391717559658
(Previous) Eval Time (s)     4.7895510559901595
Sample Time (s)              19.76363790873438
Epoch Time (s)               57.29236072069034
Total Train Time (s)         13701.094590263441
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:51:05.044667 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #213 | Epoch Duration: 57.9706244468689
2020-01-11 03:51:05.044844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #213 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013214206
Z variance train             0.0025303978
KL Divergence                12.571934
KL Loss                      1.2571934
QF Loss                      204.81552
VF Loss                      59.628853
Policy Loss                  -1305.829
Q Predictions Mean           1305.0757
Q Predictions Std            304.32712
Q Predictions Max            1574.1796
Q Predictions Min            5.822961
V Predictions Mean           1306.5409
V Predictions Std            303.54074
V Predictions Max            1574.4697
V Predictions Min            6.7226887
Log Pis Mean                 0.009407628
Log Pis Std                  2.145683
Log Pis Max                  8.471709
Log Pis Min                  -5.045229
Policy mu Mean               0.12529899
Policy mu Std                0.9080056
Policy mu Max                2.7869165
Policy mu Min                -2.4938395
Policy log std Mean          -0.5324206
Policy log std Std           0.18068232
Policy log std Max           -0.11198306
Policy log std Min           -1.4808313
Z mean eval                  0.047974706
Z variance eval              0.003619209
total_rewards                [295.57415234   8.5637569  572.09568678 430.26480078 204.40977169
 193.05712012  13.31738498 317.71204965 208.18910675 673.00585085]
total_rewards_mean           291.6189680856084
total_rewards_std            206.37217610332334
total_rewards_max            673.0058508493398
total_rewards_min            8.56375690262535
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               32.926595989149064
(Previous) Eval Time (s)     5.46751292841509
Sample Time (s)              21.901793260127306
Epoch Time (s)               60.29590217769146
Total Train Time (s)         13759.014895315748
Epoch                        214
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:02.968191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #214 | Epoch Duration: 57.92319989204407
2020-01-11 03:52:02.968424 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #214 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052358307
Z variance train             0.0036465817
KL Divergence                12.054414
KL Loss                      1.2054414
QF Loss                      133.14835
VF Loss                      133.02383
Policy Loss                  -1242.9854
Q Predictions Mean           1243.0048
Q Predictions Std            373.4239
Q Predictions Max            1600.7639
Q Predictions Min            -4.809393
V Predictions Mean           1250.8969
V Predictions Std            374.382
V Predictions Max            1609.5552
V Predictions Min            1.0727009
Log Pis Mean                 -0.2810046
Log Pis Std                  1.8229539
Log Pis Max                  7.1720023
Log Pis Min                  -4.6585383
Policy mu Mean               0.023200043
Policy mu Std                0.82383305
Policy mu Max                2.667416
Policy mu Min                -2.761385
Policy log std Mean          -0.5134254
Policy log std Std           0.16173404
Policy log std Max           -0.108661145
Policy log std Min           -1.2709892
Z mean eval                  0.038067944
Z variance eval              0.0034948483
total_rewards                [543.43377568 566.34118009 191.48888445 274.01295559 331.03517697
 621.60273232 324.20097991 344.33536211 339.62108426 370.45498702]
total_rewards_mean           390.6527118394384
total_rewards_std            131.88821831861196
total_rewards_max            621.6027323207883
total_rewards_min            191.4888844463046
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               32.605213499162346
(Previous) Eval Time (s)     3.0944563690572977
Sample Time (s)              19.492234737612307
Epoch Time (s)               55.19190460583195
Total Train Time (s)         13814.634207842406
Epoch                        215
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:58.589353 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #215 | Epoch Duration: 55.62076783180237
2020-01-11 03:52:58.589530 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #215 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011378332
Z variance train             0.0039356975
KL Divergence                11.7092
KL Loss                      1.17092
QF Loss                      615.57007
VF Loss                      166.12473
Policy Loss                  -1238.327
Q Predictions Mean           1227.9792
Q Predictions Std            430.63232
Q Predictions Max            1622.9802
Q Predictions Min            1.8587419
V Predictions Mean           1232.4512
V Predictions Std            428.88425
V Predictions Max            1626.3655
V Predictions Min            4.746866
Log Pis Mean                 -0.25423467
Log Pis Std                  2.0540729
Log Pis Max                  8.28324
Log Pis Min                  -5.0596323
Policy mu Mean               -0.029428093
Policy mu Std                0.8721068
Policy mu Max                2.6511955
Policy mu Min                -2.6408286
Policy log std Mean          -0.50868636
Policy log std Std           0.16717829
Policy log std Max           -0.06884092
Policy log std Min           -1.0713892
Z mean eval                  0.022203712
Z variance eval              0.0022565038
total_rewards                [448.60331724 339.49526191 579.25208469   6.85089657  49.5697851
 212.65307697  10.33433296 192.14051611 250.47908476   9.65467738]
total_rewards_mean           209.9033033691531
total_rewards_std            189.47933123371695
total_rewards_max            579.252084686163
total_rewards_min            6.850896569952407
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               32.34052914194763
(Previous) Eval Time (s)     3.5230083391070366
Sample Time (s)              18.375830090604722
Epoch Time (s)               54.239367571659386
Total Train Time (s)         13868.202561412472
Epoch                        216
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:52.160929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #216 | Epoch Duration: 53.571264028549194
2020-01-11 03:53:52.161098 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #216 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021812217
Z variance train             0.0022539296
KL Divergence                12.935299
KL Loss                      1.2935299
QF Loss                      74.74376
VF Loss                      35.819588
Policy Loss                  -1263.5383
Q Predictions Mean           1263.9062
Q Predictions Std            356.6809
Q Predictions Max            1597.7294
Q Predictions Min            0.9001338
V Predictions Mean           1259.8102
V Predictions Std            355.15338
V Predictions Max            1586.8589
V Predictions Min            0.22077858
Log Pis Mean                 -0.327499
Log Pis Std                  1.8685049
Log Pis Max                  5.7177906
Log Pis Min                  -4.2369375
Policy mu Mean               -0.03323902
Policy mu Std                0.82385373
Policy mu Max                2.1203094
Policy mu Min                -2.9603865
Policy log std Mean          -0.5014668
Policy log std Std           0.17792799
Policy log std Max           -0.075089425
Policy log std Min           -1.4062877
Z mean eval                  0.007935012
Z variance eval              0.0015112167
total_rewards                [152.90860305 464.91015732 200.17992624  10.38774942 210.37817903
  11.36681099 418.86593723 210.0199365  558.65517872 221.75779544]
total_rewards_mean           245.94302739453124
total_rewards_std            173.21663733135878
total_rewards_max            558.6551787186223
total_rewards_min            10.387749424454654
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               32.92175732599571
(Previous) Eval Time (s)     2.854534226935357
Sample Time (s)              18.661732469219714
Epoch Time (s)               54.438024022150785
Total Train Time (s)         13922.755125795957
Epoch                        217
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:54:46.715824 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #217 | Epoch Duration: 54.55459117889404
2020-01-11 03:54:46.716003 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #217 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010263377
Z variance train             0.0015212817
KL Divergence                13.847073
KL Loss                      1.3847073
QF Loss                      281.00952
VF Loss                      237.36691
Policy Loss                  -1248.3774
Q Predictions Mean           1248.1611
Q Predictions Std            400.73444
Q Predictions Max            1578.5265
Q Predictions Min            2.7644887
V Predictions Mean           1248.6965
V Predictions Std            401.81213
V Predictions Max            1583.8833
V Predictions Min            -5.6731057
Log Pis Mean                 -0.25422195
Log Pis Std                  2.0060074
Log Pis Max                  7.897271
Log Pis Min                  -4.7944145
Policy mu Mean               0.089642435
Policy mu Std                0.87730795
Policy mu Max                3.6340435
Policy mu Min                -2.657425
Policy log std Mean          -0.48945686
Policy log std Std           0.17435637
Policy log std Max           -0.09782985
Policy log std Min           -1.0873404
Z mean eval                  0.035034154
Z variance eval              0.0014566726
total_rewards                [194.77600308 234.54493012 243.41584089 287.88151508 512.02014207
 525.50622669 361.84619991 212.59651199 376.01785221 362.26836381]
total_rewards_mean           331.08735858348535
total_rewards_std            112.23494369637555
total_rewards_max            525.5062266859159
total_rewards_min            194.7760030767082
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               32.39227351732552
(Previous) Eval Time (s)     2.9707770249806345
Sample Time (s)              18.552665625698864
Epoch Time (s)               53.91571616800502
Total Train Time (s)         13977.901405600831
Epoch                        218
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:55:41.865247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #218 | Epoch Duration: 55.14910340309143
2020-01-11 03:55:41.865439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #218 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034561858
Z variance train             0.0014564167
KL Divergence                14.122078
KL Loss                      1.4122078
QF Loss                      166.3154
VF Loss                      139.16022
Policy Loss                  -1301.4181
Q Predictions Mean           1300.489
Q Predictions Std            398.7032
Q Predictions Max            1638.2142
Q Predictions Min            4.60362
V Predictions Mean           1308.8257
V Predictions Std            401.4357
V Predictions Max            1649.2245
V Predictions Min            4.4917207
Log Pis Mean                 -0.1676309
Log Pis Std                  1.865614
Log Pis Max                  6.747891
Log Pis Min                  -5.1857386
Policy mu Mean               0.087786674
Policy mu Std                0.8714722
Policy mu Max                2.1689572
Policy mu Min                -2.67222
Policy log std Mean          -0.50743526
Policy log std Std           0.17802161
Policy log std Max           -0.06338978
Policy log std Min           -1.0512309
Z mean eval                  0.030719712
Z variance eval              0.0014089653
total_rewards                [556.42434772 196.48052336 257.0341836  219.46984984  43.74002687
 203.29081297 443.67532699 219.11368384  12.5726941  189.58786328]
total_rewards_mean           234.13893125801937
total_rewards_std            154.4138670507784
total_rewards_max            556.4243477188915
total_rewards_min            12.572694104164587
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               32.586755481082946
(Previous) Eval Time (s)     4.203815183136612
Sample Time (s)              17.588774194009602
Epoch Time (s)               54.37934485822916
Total Train Time (s)         14031.416945092846
Epoch                        219
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:35.383303 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #219 | Epoch Duration: 53.51771855354309
2020-01-11 03:56:35.383507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #219 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013031645
Z variance train             0.0015179099
KL Divergence                13.94985
KL Loss                      1.3949851
QF Loss                      97.93785
VF Loss                      84.01117
Policy Loss                  -1313.0577
Q Predictions Mean           1315.314
Q Predictions Std            384.86386
Q Predictions Max            1651.443
Q Predictions Min            1.7058215
V Predictions Mean           1308.5466
V Predictions Std            382.22614
V Predictions Max            1643.6549
V Predictions Min            4.824306
Log Pis Mean                 -0.1376502
Log Pis Std                  1.8144494
Log Pis Max                  7.525122
Log Pis Min                  -5.589406
Policy mu Mean               0.02868844
Policy mu Std                0.8652761
Policy mu Max                2.424176
Policy mu Min                -2.5270293
Policy log std Mean          -0.50210685
Policy log std Std           0.190717
Policy log std Max           -0.08502191
Policy log std Min           -1.786006
Z mean eval                  0.015828636
Z variance eval              0.0012816044
total_rewards                [312.04547002  14.86870181 251.31833522 234.87401756  28.92003445
 191.55620211   6.72595446 289.54634958 224.39836886 196.05760616]
total_rewards_mean           175.03110402210376
total_rewards_std            109.43809962551659
total_rewards_max            312.0454700150773
total_rewards_min            6.725954461776397
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               32.21103408141062
(Previous) Eval Time (s)     3.3418953330256045
Sample Time (s)              18.021620948798954
Epoch Time (s)               53.574550363235176
Total Train Time (s)         14084.283719316125
Epoch                        220
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:28.253111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #220 | Epoch Duration: 52.86946630477905
2020-01-11 03:57:28.253284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #220 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015650228
Z variance train             0.0012798756
KL Divergence                14.39264
KL Loss                      1.439264
QF Loss                      166.61877
VF Loss                      129.49997
Policy Loss                  -1281.5011
Q Predictions Mean           1282.6685
Q Predictions Std            370.0548
Q Predictions Max            1595.7915
Q Predictions Min            -0.10094097
V Predictions Mean           1286.196
V Predictions Std            367.27982
V Predictions Max            1597.8334
V Predictions Min            2.2946756
Log Pis Mean                 -0.06415342
Log Pis Std                  2.1547668
Log Pis Max                  9.257061
Log Pis Min                  -5.3264885
Policy mu Mean               -0.08072273
Policy mu Std                0.9279979
Policy mu Max                2.5359504
Policy mu Min                -3.0832384
Policy log std Mean          -0.5110193
Policy log std Std           0.18402193
Policy log std Max           0.0026780963
Policy log std Min           -1.5552859
Z mean eval                  0.009670686
Z variance eval              0.0014428229
total_rewards                [194.0769009  197.41977539 361.94218372 206.06353753 192.75080476
 186.47134364 202.40490833 199.77069767 177.69418022 189.15785408]
total_rewards_mean           210.77521862438653
total_rewards_std            50.989447845897104
total_rewards_max            361.9421837215296
total_rewards_min            177.6941802204676
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               32.475458960048854
(Previous) Eval Time (s)     2.636517711915076
Sample Time (s)              16.53467743145302
Epoch Time (s)               51.64665410341695
Total Train Time (s)         14136.200836455915
Epoch                        221
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:20.172278 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #221 | Epoch Duration: 51.918776988983154
2020-01-11 03:58:20.172639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #221 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045606356
Z variance train             0.0012772387
KL Divergence                14.475246
KL Loss                      1.4475247
QF Loss                      295.7721
VF Loss                      198.55365
Policy Loss                  -1269.4808
Q Predictions Mean           1263.2773
Q Predictions Std            394.703
Q Predictions Max            1642.6797
Q Predictions Min            5.52252
V Predictions Mean           1274.5972
V Predictions Std            393.70062
V Predictions Max            1646.2583
V Predictions Min            7.217606
Log Pis Mean                 0.12209296
Log Pis Std                  2.2241333
Log Pis Max                  11.137041
Log Pis Min                  -4.9689674
Policy mu Mean               0.051379025
Policy mu Std                0.9333685
Policy mu Max                2.9505997
Policy mu Min                -3.856933
Policy log std Mean          -0.4946917
Policy log std Std           0.1783407
Policy log std Max           -0.03942445
Policy log std Min           -1.4082541
Z mean eval                  0.01694935
Z variance eval              0.0015414779
total_rewards                [215.83682879 461.14150321 378.07746498 455.13219875 389.74237756
 223.20601183 223.31857569 567.16285048 227.94469614 209.43474325]
total_rewards_mean           335.0997250682298
total_rewards_std            124.69694426040259
total_rewards_max            567.1628504839522
total_rewards_min            209.43474325216667
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               32.139795020222664
(Previous) Eval Time (s)     2.9083144878968596
Sample Time (s)              16.37744714645669
Epoch Time (s)               51.42555665457621
Total Train Time (s)         14188.56686240714
Epoch                        222
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:12.541269 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #222 | Epoch Duration: 52.368443727493286
2020-01-11 03:59:12.541561 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #222 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014851895
Z variance train             0.0015487068
KL Divergence                13.895591
KL Loss                      1.3895591
QF Loss                      204.79497
VF Loss                      40.005188
Policy Loss                  -1298.7557
Q Predictions Mean           1294.4436
Q Predictions Std            369.0724
Q Predictions Max            1615.9056
Q Predictions Min            1.6354504
V Predictions Mean           1298.6277
V Predictions Std            369.7498
V Predictions Max            1619.2218
V Predictions Min            3.9950213
Log Pis Mean                 -0.18932232
Log Pis Std                  1.9307463
Log Pis Max                  5.6979046
Log Pis Min                  -5.576292
Policy mu Mean               -0.0960206
Policy mu Std                0.90900147
Policy mu Max                2.4953988
Policy mu Min                -2.617163
Policy log std Mean          -0.48144364
Policy log std Std           0.1785664
Policy log std Max           -0.014633715
Policy log std Min           -1.3383523
Z mean eval                  0.31412482
Z variance eval              0.0019704676
total_rewards                [204.75602149 553.97005424 627.66077549  14.11821787 476.75820403
 214.44913621 215.25321291 200.76266845 264.89298695 622.12426699]
total_rewards_mean           339.4745544639425
total_rewards_std            201.90809819688053
total_rewards_max            627.6607754928136
total_rewards_min            14.118217871768827
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               31.969830831047148
(Previous) Eval Time (s)     3.8508705222047865
Sample Time (s)              16.387629914097488
Epoch Time (s)               52.20833126734942
Total Train Time (s)         14240.961697734427
Epoch                        223
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:04.941088 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #223 | Epoch Duration: 52.39936280250549
2020-01-11 04:00:04.941430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #223 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023645634
Z variance train             0.0022740797
KL Divergence                13.153368
KL Loss                      1.3153368
QF Loss                      156.8616
VF Loss                      61.351418
Policy Loss                  -1272.6761
Q Predictions Mean           1271.2378
Q Predictions Std            411.0969
Q Predictions Max            1611.0275
Q Predictions Min            -13.6281595
V Predictions Mean           1276.892
V Predictions Std            408.93015
V Predictions Max            1617.1378
V Predictions Min            -9.2037735
Log Pis Mean                 -0.31962737
Log Pis Std                  1.9441489
Log Pis Max                  11.23616
Log Pis Min                  -4.7690163
Policy mu Mean               0.054276157
Policy mu Std                0.8638104
Policy mu Max                2.2643712
Policy mu Min                -2.744764
Policy log std Mean          -0.48452207
Policy log std Std           0.17318669
Policy log std Max           -0.04585746
Policy log std Min           -1.0819176
Z mean eval                  0.02404597
Z variance eval              0.002343303
total_rewards                [144.89520499 220.97776106 199.55189854   3.07274014  14.25668719
 558.91188587   8.63605923 194.97791732   6.48047665 202.05837062]
total_rewards_mean           155.3819001592607
total_rewards_std            161.17293353718935
total_rewards_max            558.9118858670379
total_rewards_min            3.0727401428991836
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               32.15449493331835
(Previous) Eval Time (s)     4.0416345237754285
Sample Time (s)              19.227646886836737
Epoch Time (s)               55.42377634393051
Total Train Time (s)         14294.285233017523
Epoch                        224
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:58.270352 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #224 | Epoch Duration: 53.32860970497131
2020-01-11 04:00:58.270774 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #224 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024268115
Z variance train             0.002342165
KL Divergence                13.18894
KL Loss                      1.318894
QF Loss                      110.777405
VF Loss                      82.97477
Policy Loss                  -1337.7623
Q Predictions Mean           1337.9944
Q Predictions Std            278.92606
Q Predictions Max            1602.9047
Q Predictions Min            1.5025953
V Predictions Mean           1334.7872
V Predictions Std            277.5394
V Predictions Max            1602.9336
V Predictions Min            -1.8759899
Log Pis Mean                 -0.012071248
Log Pis Std                  2.009755
Log Pis Max                  10.179168
Log Pis Min                  -4.686816
Policy mu Mean               0.103372715
Policy mu Std                0.92040175
Policy mu Max                2.4639468
Policy mu Min                -2.818831
Policy log std Mean          -0.50284463
Policy log std Std           0.15714017
Policy log std Max           -0.10887897
Policy log std Min           -1.2828523
Z mean eval                  0.01237455
Z variance eval              0.0021958523
total_rewards                [462.03198442 457.38082346 450.24545067   6.65151914   6.87678885
 262.24554682 261.04550851 252.86317152  16.0062198  476.07754524]
total_rewards_mean           265.14245584380905
total_rewards_std            187.14736123739786
total_rewards_max            476.0775452361052
total_rewards_min            6.651519135738013
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               32.673210768029094
(Previous) Eval Time (s)     1.9461469310335815
Sample Time (s)              17.05143326241523
Epoch Time (s)               51.670790961477906
Total Train Time (s)         14347.303446357604
Epoch                        225
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:51.287174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #225 | Epoch Duration: 53.01608657836914
2020-01-11 04:01:51.287396 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #225 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012241775
Z variance train             0.0021942868
KL Divergence                13.207744
KL Loss                      1.3207744
QF Loss                      132.22229
VF Loss                      59.02487
Policy Loss                  -1340.9115
Q Predictions Mean           1341.3506
Q Predictions Std            340.93854
Q Predictions Max            1659.5895
Q Predictions Min            1.2173522
V Predictions Mean           1344.7573
V Predictions Std            343.14423
V Predictions Max            1664.9861
V Predictions Min            1.7539078
Log Pis Mean                 -0.27203786
Log Pis Std                  2.1708908
Log Pis Max                  12.916452
Log Pis Min                  -4.970916
Policy mu Mean               -0.050155044
Policy mu Std                0.8841407
Policy mu Max                2.7865982
Policy mu Min                -3.7263439
Policy log std Mean          -0.5051189
Policy log std Std           0.16404659
Policy log std Max           0.20206451
Policy log std Min           -1.5207827
Z mean eval                  0.31584337
Z variance eval              0.00213148
total_rewards                [215.07026849 236.72793571 203.50133375  27.15208976 218.70499353
  15.50029309 211.56819785 193.6316722  218.07845721  39.1927758 ]
total_rewards_mean           157.9128017379212
total_rewards_std            86.31429921703732
total_rewards_max            236.72793570516382
total_rewards_min            15.500293089131688
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               33.10321337077767
(Previous) Eval Time (s)     3.2911783107556403
Sample Time (s)              16.985983293503523
Epoch Time (s)               53.38037497503683
Total Train Time (s)         14399.866511037573
Epoch                        226
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:43.852845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #226 | Epoch Duration: 52.565282106399536
2020-01-11 04:02:43.853026 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #226 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3251353
Z variance train             0.0021326577
KL Divergence                13.76041
KL Loss                      1.376041
QF Loss                      178.78122
VF Loss                      138.27977
Policy Loss                  -1411.6998
Q Predictions Mean           1410.4719
Q Predictions Std            430.15143
Q Predictions Max            1770.2404
Q Predictions Min            3.395587
V Predictions Mean           1404.8735
V Predictions Std            428.86206
V Predictions Max            1755.9325
V Predictions Min            2.4490716
Log Pis Mean                 -0.18429819
Log Pis Std                  2.095985
Log Pis Max                  11.559625
Log Pis Min                  -5.8938017
Policy mu Mean               0.1260656
Policy mu Std                0.9143453
Policy mu Max                2.2444131
Policy mu Min                -3.052838
Policy log std Mean          -0.48497665
Policy log std Std           0.16594547
Policy log std Max           -0.06722084
Policy log std Min           -1.6844292
Z mean eval                  0.27209026
Z variance eval              0.0019823727
total_rewards                [225.46391262 228.20534709 360.78952079 204.44795202 260.49906551
 209.65687048 217.64141784 485.67406317 341.23786205 198.16600086]
total_rewards_mean           273.1782012446022
total_rewards_std            89.102353866707
total_rewards_max            485.67406316675
total_rewards_min            198.1660008617169
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               32.81261128373444
(Previous) Eval Time (s)     2.4757722970098257
Sample Time (s)              16.354799972381443
Epoch Time (s)               51.64318355312571
Total Train Time (s)         14452.600326161832
Epoch                        227
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:03:36.589535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #227 | Epoch Duration: 52.736364126205444
2020-01-11 04:03:36.589723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #227 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2741758
Z variance train             0.0019820216
KL Divergence                13.76123
KL Loss                      1.3761231
QF Loss                      188.38803
VF Loss                      52.56033
Policy Loss                  -1411.3506
Q Predictions Mean           1410.2693
Q Predictions Std            385.71298
Q Predictions Max            1709.3862
Q Predictions Min            7.3700247
V Predictions Mean           1408.6931
V Predictions Std            384.8845
V Predictions Max            1710.6602
V Predictions Min            7.6336775
Log Pis Mean                 0.04351326
Log Pis Std                  2.0475855
Log Pis Max                  7.454721
Log Pis Min                  -4.398767
Policy mu Mean               -0.0315916
Policy mu Std                0.94273376
Policy mu Max                1.9419616
Policy mu Min                -2.7023141
Policy log std Mean          -0.502881
Policy log std Std           0.16294144
Policy log std Max           -0.076977134
Policy log std Min           -1.6344585
Z mean eval                  0.07726194
Z variance eval              0.0020229123
total_rewards                [454.49411557 184.0422781   15.16593192 328.86675824  11.19803969
  58.5236209   12.09595562  43.01617077 170.64866919  10.35635764]
total_rewards_mean           128.84078976440443
total_rewards_std            147.5112389399052
total_rewards_max            454.49411556812606
total_rewards_min            10.35635763768201
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               32.914001126307994
(Previous) Eval Time (s)     3.5686220210045576
Sample Time (s)              16.702110496349633
Epoch Time (s)               53.184733643662184
Total Train Time (s)         14504.092981082853
Epoch                        228
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:28.084377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #228 | Epoch Duration: 51.49451661109924
2020-01-11 04:04:28.084543 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #228 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09477186
Z variance train             0.002131114
KL Divergence                13.094402
KL Loss                      1.3094403
QF Loss                      129.01944
VF Loss                      48.96127
Policy Loss                  -1317.0806
Q Predictions Mean           1315.7817
Q Predictions Std            406.06818
Q Predictions Max            1631.5148
Q Predictions Min            4.4973474
V Predictions Mean           1320.3451
V Predictions Std            406.3974
V Predictions Max            1643.4596
V Predictions Min            3.4871442
Log Pis Mean                 -0.27393404
Log Pis Std                  2.1154451
Log Pis Max                  10.839375
Log Pis Min                  -3.757303
Policy mu Mean               0.032549918
Policy mu Std                0.9020558
Policy mu Max                2.3623576
Policy mu Min                -2.7790735
Policy log std Mean          -0.4717426
Policy log std Std           0.16694023
Policy log std Max           -0.031034231
Policy log std Min           -0.97751355
Z mean eval                  0.09077716
Z variance eval              0.002112768
total_rewards                [423.9653207   13.09602628 312.57025361 396.24840249  12.03567097
   7.53938578   9.77596502   8.19718278  11.62710387   9.0172101 ]
total_rewards_mean           120.40725215961243
total_rewards_std            170.3622487186748
total_rewards_max            423.96532069747605
total_rewards_min            7.539385779276113
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               32.975674154702574
(Previous) Eval Time (s)     1.878095380961895
Sample Time (s)              19.53155832691118
Epoch Time (s)               54.38532786257565
Total Train Time (s)         14558.008901293855
Epoch                        229
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:22.003429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #229 | Epoch Duration: 53.91875410079956
2020-01-11 04:05:22.003598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #229 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023055157
Z variance train             0.0020284741
KL Divergence                13.14278
KL Loss                      1.314278
QF Loss                      283.4331
VF Loss                      212.45566
Policy Loss                  -1280.5945
Q Predictions Mean           1279.3441
Q Predictions Std            354.2332
Q Predictions Max            1589.1868
Q Predictions Min            1.0601401
V Predictions Mean           1283.7395
V Predictions Std            346.16013
V Predictions Max            1602.4808
V Predictions Min            6.3933644
Log Pis Mean                 -0.093061976
Log Pis Std                  2.0870867
Log Pis Max                  9.134045
Log Pis Min                  -4.7800756
Policy mu Mean               0.017733509
Policy mu Std                0.9381872
Policy mu Max                2.6594753
Policy mu Min                -3.8533852
Policy log std Mean          -0.5377098
Policy log std Std           0.17093953
Policy log std Max           0.013251454
Policy log std Min           -1.4908737
Z mean eval                  0.1056429
Z variance eval              0.0024199828
total_rewards                [526.43510542  14.87282397   9.92583965 411.40193885  21.55381081
 393.55716643 404.87480375 525.04409978 378.44736417  12.61655985]
total_rewards_mean           269.87295126815184
total_rewards_std            213.7099456957281
total_rewards_max            526.4351054181095
total_rewards_min            9.925839646111436
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               32.173768635839224
(Previous) Eval Time (s)     1.4112068908289075
Sample Time (s)              17.860063459258527
Epoch Time (s)               51.44503898592666
Total Train Time (s)         14611.011347123887
Epoch                        230
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:06:15.008586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #230 | Epoch Duration: 53.00484538078308
2020-01-11 04:06:15.008777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #230 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.37625
Z variance train             0.005419663
KL Divergence                162.77315
KL Loss                      16.277315
QF Loss                      369.0769
VF Loss                      55.141136
Policy Loss                  -320.67276
Q Predictions Mean           319.5244
Q Predictions Std            62.145756
Q Predictions Max            363.54404
Q Predictions Min            -8.071311
V Predictions Mean           323.2724
V Predictions Std            62.360558
V Predictions Max            366.18622
V Predictions Min            -14.313235
Log Pis Mean                 -1.0408587
Log Pis Std                  1.2318101
Log Pis Max                  3.789506
Log Pis Min                  -5.801927
Policy mu Mean               -0.12569503
Policy mu Std                0.64224136
Policy mu Max                1.5375018
Policy mu Min                -1.6644479
Policy log std Mean          -0.38727298
Policy log std Std           0.13528238
Policy log std Max           0.01397264
Policy log std Min           -0.94192445
Z mean eval                  0.08870278
Z variance eval              0.0026397456
total_rewards                [323.16687402 415.61580972 458.95611698 396.55989083 309.98899571
 527.39979353 353.57939209 448.63951921 489.11977709 492.73429115]
total_rewards_mean           421.576046033145
total_rewards_std            70.97529893786121
total_rewards_max            527.3997935291401
total_rewards_min            309.9889957095162
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               32.33348611090332
(Previous) Eval Time (s)     2.9707003817893565
Sample Time (s)              19.885005382355303
Epoch Time (s)               55.18919187504798
Total Train Time (s)         14668.145089671947
Epoch                        231
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:12.145409 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #231 | Epoch Duration: 57.13648581504822
2020-01-11 04:07:12.145581 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #231 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08894712
Z variance train             0.002640728
KL Divergence                12.599506
KL Loss                      1.2599506
QF Loss                      463.09384
VF Loss                      61.62351
Policy Loss                  -1304.6609
Q Predictions Mean           1301.564
Q Predictions Std            351.76413
Q Predictions Max            1626.9883
Q Predictions Min            -3.692496
V Predictions Mean           1302.7312
V Predictions Std            350.23596
V Predictions Max            1622.6635
V Predictions Min            3.9624033
Log Pis Mean                 0.025312915
Log Pis Std                  2.1656203
Log Pis Max                  11.531657
Log Pis Min                  -5.605026
Policy mu Mean               -0.02777456
Policy mu Std                0.9691898
Policy mu Max                2.5180542
Policy mu Min                -3.1030269
Policy log std Mean          -0.4824818
Policy log std Std           0.16721764
Policy log std Max           0.055675805
Policy log std Min           -1.178468
Z mean eval                  0.09119971
Z variance eval              0.0034702986
total_rewards                [441.39182921 473.54391911 360.40605649 497.01808964 468.60526202
 534.88242228 333.19031308 329.86671167 521.65988724 444.89271959]
total_rewards_mean           440.5457210318449
total_rewards_std            71.24694614914112
total_rewards_max            534.882422281689
total_rewards_min            329.86671166796
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               32.341053823940456
(Previous) Eval Time (s)     4.917722147889435
Sample Time (s)              18.23660256387666
Epoch Time (s)               55.49537853570655
Total Train Time (s)         14723.106348155532
Epoch                        232
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:07.109893 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #232 | Epoch Duration: 54.9641649723053
2020-01-11 04:08:07.110118 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #232 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20541696
Z variance train             0.0018652243
KL Divergence                13.709711
KL Loss                      1.3709711
QF Loss                      380.10306
VF Loss                      146.4725
Policy Loss                  -1104.834
Q Predictions Mean           1107.5842
Q Predictions Std            345.18243
Q Predictions Max            1425.3423
Q Predictions Min            1.7050016
V Predictions Mean           1106.537
V Predictions Std            343.97076
V Predictions Max            1418.5427
V Predictions Min            3.1770465
Log Pis Mean                 0.08480793
Log Pis Std                  2.2373397
Log Pis Max                  6.3492317
Log Pis Min                  -5.0814857
Policy mu Mean               -0.194411
Policy mu Std                0.96731716
Policy mu Max                2.322957
Policy mu Min                -2.8273532
Policy log std Mean          -0.5000214
Policy log std Std           0.18437067
Policy log std Max           -0.03418687
Policy log std Min           -1.5432982
Z mean eval                  0.09923313
Z variance eval              0.0026373889
total_rewards                [522.49265134 485.66898266 280.56104877 479.87064114 514.1750772
 469.74705469 481.44581504 478.35415432 542.71384673 451.74920593]
total_rewards_mean           470.6778477828955
total_rewards_std            68.37663451793168
total_rewards_max            542.7138467283668
total_rewards_min            280.5610487699328
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               32.05539345089346
(Previous) Eval Time (s)     4.386237065773457
Sample Time (s)              19.40201623365283
Epoch Time (s)               55.84364675031975
Total Train Time (s)         14779.852359621786
Epoch                        233
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:09:03.860024 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #233 | Epoch Duration: 56.74968910217285
2020-01-11 04:09:03.860185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #233 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08601832
Z variance train             0.0025297585
KL Divergence                12.689791
KL Loss                      1.2689791
QF Loss                      252.14536
VF Loss                      252.81007
Policy Loss                  -1253.6011
Q Predictions Mean           1252.8566
Q Predictions Std            445.51816
Q Predictions Max            1605.0518
Q Predictions Min            -18.381676
V Predictions Mean           1253.4373
V Predictions Std            447.00784
V Predictions Max            1616.9423
V Predictions Min            -8.434365
Log Pis Mean                 -0.06233874
Log Pis Std                  2.0642262
Log Pis Max                  8.589604
Log Pis Min                  -5.1501374
Policy mu Mean               -0.023016071
Policy mu Std                0.9488425
Policy mu Max                2.1050677
Policy mu Min                -2.8789468
Policy log std Mean          -0.45721972
Policy log std Std           0.14700313
Policy log std Max           0.05013451
Policy log std Min           -1.0250301
Z mean eval                  7.3253126
Z variance eval              0.002890885
total_rewards                [342.86041702 489.54335318 335.97367008 346.05680261 375.94715888
 339.17422975 498.66516919 505.43603286 341.4386815  459.9600547 ]
total_rewards_mean           403.50555697698894
total_rewards_std            70.93928145028772
total_rewards_max            505.43603285918863
total_rewards_min            335.9736700757025
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               32.678757505025715
(Previous) Eval Time (s)     5.29200670029968
Sample Time (s)              19.412372060120106
Epoch Time (s)               57.3831362654455
Total Train Time (s)         14836.720112642273
Epoch                        234
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:00.730029 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #234 | Epoch Duration: 56.86970138549805
2020-01-11 04:10:00.730197 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #234 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6366141
Z variance train             0.0018251756
KL Divergence                14.52086
KL Loss                      1.452086
QF Loss                      1488.4729
VF Loss                      729.3784
Policy Loss                  -794.68506
Q Predictions Mean           778.58777
Q Predictions Std            233.21873
Q Predictions Max            1134.8318
Q Predictions Min            -8.777688
V Predictions Mean           799.9365
V Predictions Std            232.50534
V Predictions Max            1127.6113
V Predictions Min            3.563206
Log Pis Mean                 0.69814533
Log Pis Std                  1.933804
Log Pis Max                  6.6680584
Log Pis Min                  -4.7169952
Policy mu Mean               -0.020064272
Policy mu Std                1.1184044
Policy mu Max                2.734336
Policy mu Min                -2.7330813
Policy log std Mean          -0.5537452
Policy log std Std           0.175096
Policy log std Max           -0.045329154
Policy log std Min           -1.2171179
Z mean eval                  0.107176915
Z variance eval              0.002720732
total_rewards                [335.87691466 528.89869349 432.59711282 535.64898678 293.54546148
 314.95616857 394.4912382  500.43522673 475.75147557 360.87647158]
total_rewards_mean           417.30777498963334
total_rewards_std            85.52532471244945
total_rewards_max            535.6489867841905
total_rewards_min            293.54546148175973
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               32.73356126481667
(Previous) Eval Time (s)     4.7782661519013345
Sample Time (s)              19.309576612431556
Epoch Time (s)               56.82140402914956
Total Train Time (s)         14893.410940507893
Epoch                        235
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:57.425729 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #235 | Epoch Duration: 56.695390701293945
2020-01-11 04:10:57.425922 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #235 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10730122
Z variance train             0.0027168316
KL Divergence                12.517071
KL Loss                      1.2517071
QF Loss                      174.61522
VF Loss                      128.74896
Policy Loss                  -1310.2489
Q Predictions Mean           1306.3921
Q Predictions Std            337.1802
Q Predictions Max            1608.6174
Q Predictions Min            -3.662996
V Predictions Mean           1307.8285
V Predictions Std            336.36383
V Predictions Max            1617.5405
V Predictions Min            -4.85632
Log Pis Mean                 -0.28099135
Log Pis Std                  2.020738
Log Pis Max                  8.69307
Log Pis Min                  -4.9671597
Policy mu Mean               0.13751976
Policy mu Std                0.87043875
Policy mu Max                2.8147633
Policy mu Min                -2.8458822
Policy log std Mean          -0.4663746
Policy log std Std           0.15851942
Policy log std Max           -0.043147475
Policy log std Min           -1.5005887
Z mean eval                  0.017228875
Z variance eval              0.002296408
total_rewards                [351.71567478 347.08858756 342.49710962 340.10831604 342.66031948
 322.49031032 307.80148011 345.77371449 322.56800475 343.76520881]
total_rewards_mean           336.6468725948777
total_rewards_std            13.353336716184515
total_rewards_max            351.7156747821279
total_rewards_min            307.80148010835137
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               32.2089112047106
(Previous) Eval Time (s)     4.651958827860653
Sample Time (s)              19.695352705195546
Epoch Time (s)               56.5562227377668
Total Train Time (s)         14949.37770064827
Epoch                        236
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:53.393812 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #236 | Epoch Duration: 55.96771287918091
2020-01-11 04:11:53.394082 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #236 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.959903
Z variance train             0.0039782007
KL Divergence                142.0991
KL Loss                      14.20991
QF Loss                      236.2736
VF Loss                      158.4589
Policy Loss                  -576.8496
Q Predictions Mean           575.2545
Q Predictions Std            107.83706
Q Predictions Max            684.82513
Q Predictions Min            9.125948
V Predictions Mean           588.27026
V Predictions Std            107.89925
V Predictions Max            694.56256
V Predictions Min            5.047268
Log Pis Mean                 -0.62645763
Log Pis Std                  1.4317657
Log Pis Max                  4.327635
Log Pis Min                  -8.186537
Policy mu Mean               0.25886372
Policy mu Std                0.63528967
Policy mu Max                2.0898702
Policy mu Min                -2.0550044
Policy log std Mean          -0.5860173
Policy log std Std           0.16377631
Policy log std Max           -0.2315561
Policy log std Min           -1.0688262
Z mean eval                  0.14614184
Z variance eval              0.0024108805
total_rewards                [342.03869469 289.92858261 339.34017944 350.50645454 333.34746061
 328.70453472 329.17381341 318.27709006 318.92417979 487.17207997]
total_rewards_mean           343.74130698253236
total_rewards_std            50.345701459867755
total_rewards_max            487.17207996736136
total_rewards_min            289.92858260536605
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               32.15353875234723
(Previous) Eval Time (s)     4.063133784104139
Sample Time (s)              18.23491837643087
Epoch Time (s)               54.45159091288224
Total Train Time (s)         15003.059180948418
Epoch                        237
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:12:47.080738 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #237 | Epoch Duration: 53.68646574020386
2020-01-11 04:12:47.081014 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #237 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.794774
Z variance train             0.0029148739
KL Divergence                140.89548
KL Loss                      14.089548
QF Loss                      163.77196
VF Loss                      47.08402
Policy Loss                  -587.63245
Q Predictions Mean           584.305
Q Predictions Std            173.4337
Q Predictions Max            734.19586
Q Predictions Min            -6.312853
V Predictions Mean           587.70526
V Predictions Std            174.3653
V Predictions Max            737.4041
V Predictions Min            -8.296076
Log Pis Mean                 -0.4661016
Log Pis Std                  1.3341975
Log Pis Max                  5.6855087
Log Pis Min                  -4.0688863
Policy mu Mean               0.2501453
Policy mu Std                0.64468336
Policy mu Max                2.2648332
Policy mu Min                -2.2680602
Policy log std Mean          -0.5747302
Policy log std Std           0.16087773
Policy log std Max           -0.20230593
Policy log std Min           -1.0584884
Z mean eval                  0.14978158
Z variance eval              0.0020662565
total_rewards                [302.85997571 331.12064622 308.87908293 311.95890803 311.0911651
 304.67729175 307.6757357  321.3603222  318.50920571 300.17581337]
total_rewards_mean           311.83081467276077
total_rewards_std            8.952869986129768
total_rewards_max            331.12064622278604
total_rewards_min            300.17581336822457
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               32.150337021332234
(Previous) Eval Time (s)     3.297676818910986
Sample Time (s)              17.468588575255126
Epoch Time (s)               52.916602415498346
Total Train Time (s)         15056.220156813972
Epoch                        238
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:40.243650 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #238 | Epoch Duration: 53.16242575645447
2020-01-11 04:13:40.243844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #238 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.9953737
Z variance train             0.0009895776
KL Divergence                148.75186
KL Loss                      14.875186
QF Loss                      236.96481
VF Loss                      53.27319
Policy Loss                  -660.6001
Q Predictions Mean           657.6157
Q Predictions Std            137.73235
Q Predictions Max            792.9623
Q Predictions Min            10.039731
V Predictions Mean           659.1404
V Predictions Std            136.22554
V Predictions Max            798.66254
V Predictions Min            10.606519
Log Pis Mean                 -0.39204335
Log Pis Std                  1.5315872
Log Pis Max                  4.588462
Log Pis Min                  -5.2295403
Policy mu Mean               0.2782487
Policy mu Std                0.71158475
Policy mu Max                2.7295997
Policy mu Min                -1.9037505
Policy log std Mean          -0.60824466
Policy log std Std           0.15310605
Policy log std Max           -0.28121316
Policy log std Min           -1.1281596
Z mean eval                  0.15060112
Z variance eval              0.0022145626
total_rewards                [326.30692858 307.61217334 319.51543128 332.0412104  319.21933911
 312.65220364 331.44847219 330.99092814 322.61814372 313.36354527]
total_rewards_mean           321.57683756700953
total_rewards_std            8.191225506539393
total_rewards_max            332.0412104048132
total_rewards_min            307.61217333532625
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               32.64629861386493
(Previous) Eval Time (s)     3.5431835600174963
Sample Time (s)              17.777931961696595
Epoch Time (s)               53.96741413557902
Total Train Time (s)         15110.299225843046
Epoch                        239
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:34.331743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #239 | Epoch Duration: 54.08775472640991
2020-01-11 04:14:34.331934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #239 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14659333
Z variance train             0.0020083103
KL Divergence                13.463027
KL Loss                      1.3463027
QF Loss                      174.14328
VF Loss                      141.13078
Policy Loss                  -1286.2278
Q Predictions Mean           1286.0204
Q Predictions Std            388.72232
Q Predictions Max            1613.4061
Q Predictions Min            -0.22607899
V Predictions Mean           1282.6792
V Predictions Std            385.05573
V Predictions Max            1597.1102
V Predictions Min            8.586046
Log Pis Mean                 0.109588616
Log Pis Std                  2.183642
Log Pis Max                  7.8945327
Log Pis Min                  -4.8189163
Policy mu Mean               0.07882642
Policy mu Std                0.9895008
Policy mu Max                2.5287907
Policy mu Min                -2.6519759
Policy log std Mean          -0.475405
Policy log std Std           0.16228214
Policy log std Max           7.6919794e-05
Policy log std Min           -1.2704722
Z mean eval                  6.150672
Z variance eval              0.0007455732
total_rewards                [329.44436711 332.09537015 395.58716758 268.44601648 397.84902814
 296.91566651 303.2421602  322.69488487 304.54838947 457.65508803]
total_rewards_mean           340.84781385389704
total_rewards_std            55.0722566334172
total_rewards_max            457.655088034963
total_rewards_min            268.44601648121215
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               32.38174808816984
(Previous) Eval Time (s)     3.663184161297977
Sample Time (s)              16.762239050120115
Epoch Time (s)               52.807171299587935
Total Train Time (s)         15163.467857115436
Epoch                        240
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:27.497111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #240 | Epoch Duration: 53.16503715515137
2020-01-11 04:15:27.497292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #240 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14621887
Z variance train             0.0014312409
KL Divergence                14.120069
KL Loss                      1.4120069
QF Loss                      643.73
VF Loss                      134.42441
Policy Loss                  -1306.0599
Q Predictions Mean           1302.4688
Q Predictions Std            380.6219
Q Predictions Max            1587.5516
Q Predictions Min            4.776989
V Predictions Mean           1297.4314
V Predictions Std            377.53012
V Predictions Max            1578.714
V Predictions Min            1.3380611
Log Pis Mean                 -0.09305529
Log Pis Std                  2.22129
Log Pis Max                  7.8218985
Log Pis Min                  -7.0032783
Policy mu Mean               -0.043451417
Policy mu Std                0.92466325
Policy mu Max                2.2345145
Policy mu Min                -2.9731584
Policy log std Mean          -0.46343008
Policy log std Std           0.14826807
Policy log std Max           -0.08826724
Policy log std Min           -0.9627873
Z mean eval                  6.658826
Z variance eval              0.002770143
total_rewards                [443.02451349 484.5065376  315.14466933 298.91138898 292.64526401
 483.61410259 321.87578993 466.54811372 331.64471339 313.69829018]
total_rewards_mean           375.1613383234395
total_rewards_std            78.36519533252216
total_rewards_max            484.50653760113374
total_rewards_min            292.64526401343187
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               32.35479861171916
(Previous) Eval Time (s)     4.0207705199718475
Sample Time (s)              17.961740128230304
Epoch Time (s)               54.33730925992131
Total Train Time (s)         15217.886899957433
Epoch                        241
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:21.920390 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #241 | Epoch Duration: 54.422959327697754
2020-01-11 04:16:21.920580 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #241 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15122767
Z variance train             0.0013247461
KL Divergence                14.481246
KL Loss                      1.4481246
QF Loss                      383.90503
VF Loss                      198.43958
Policy Loss                  -1300.29
Q Predictions Mean           1296.3257
Q Predictions Std            370.61618
Q Predictions Max            1614.0596
Q Predictions Min            -13.4043665
V Predictions Mean           1294.1387
V Predictions Std            364.53113
V Predictions Max            1592.2327
V Predictions Min            -26.473646
Log Pis Mean                 0.07915494
Log Pis Std                  2.2378175
Log Pis Max                  7.736392
Log Pis Min                  -6.931288
Policy mu Mean               0.07069949
Policy mu Std                0.98351794
Policy mu Max                2.802803
Policy mu Min                -2.9768572
Policy log std Mean          -0.47661862
Policy log std Std           0.14374492
Policy log std Max           -0.074783474
Policy log std Min           -0.985072
Z mean eval                  6.463118
Z variance eval              0.0013821695
total_rewards                [451.28360132 318.89533713 317.01923714 341.11273584 454.80129627
 306.6666404  332.14035559 308.11912308 328.21217636 323.50247218]
total_rewards_mean           348.1752975304783
total_rewards_std            53.3574563519838
total_rewards_max            454.80129626901225
total_rewards_min            306.66664039747945
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               32.30345951486379
(Previous) Eval Time (s)     4.106114401947707
Sample Time (s)              17.434475146699697
Epoch Time (s)               53.84404906351119
Total Train Time (s)         15271.52034701081
Epoch                        242
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:17:15.554288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #242 | Epoch Duration: 53.63357949256897
2020-01-11 04:17:15.554429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #242 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17145963
Z variance train             0.0015765328
KL Divergence                14.218454
KL Loss                      1.4218454
QF Loss                      276.92633
VF Loss                      76.54059
Policy Loss                  -1310.345
Q Predictions Mean           1314.4172
Q Predictions Std            381.80627
Q Predictions Max            1625.019
Q Predictions Min            -7.4151506
V Predictions Mean           1315.271
V Predictions Std            379.32974
V Predictions Max            1618.3076
V Predictions Min            -19.950308
Log Pis Mean                 -0.04716655
Log Pis Std                  2.2131414
Log Pis Max                  7.850443
Log Pis Min                  -4.1911507
Policy mu Mean               -0.07030383
Policy mu Std                0.94487035
Policy mu Max                2.628577
Policy mu Min                -2.6820052
Policy log std Mean          -0.49199256
Policy log std Std           0.1541603
Policy log std Max           -0.051275074
Policy log std Min           -1.0266793
Z mean eval                  0.163438
Z variance eval              0.0013499263
total_rewards                [479.68249917 563.79363265 300.11290751 288.61520302 328.74685977
 335.30303003 568.8768226  422.01765881 299.10429484 474.36042833]
total_rewards_mean           406.06133367321524
total_rewards_std            104.48470912144786
total_rewards_max            568.8768226006429
total_rewards_min            288.6152030240299
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               32.84513292601332
(Previous) Eval Time (s)     3.8953370060771704
Sample Time (s)              18.229202622082084
Epoch Time (s)               54.969672554172575
Total Train Time (s)         15327.00212436961
Epoch                        243
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:11.041181 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #243 | Epoch Duration: 55.48654556274414
2020-01-11 04:18:11.041475 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #243 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.213032
Z variance train             0.0017881651
KL Divergence                117.12367
KL Loss                      11.712367
QF Loss                      281.24854
VF Loss                      59.667885
Policy Loss                  -735.7516
Q Predictions Mean           731.8461
Q Predictions Std            236.7452
Q Predictions Max            933.83887
Q Predictions Min            2.8558125
V Predictions Mean           733.8238
V Predictions Std            237.13554
V Predictions Max            933.75476
V Predictions Min            -4.446619
Log Pis Mean                 -0.34750462
Log Pis Std                  1.5318072
Log Pis Max                  4.6279936
Log Pis Min                  -4.331909
Policy mu Mean               0.3107293
Policy mu Std                0.7188216
Policy mu Max                2.2898645
Policy mu Min                -1.7559627
Policy log std Mean          -0.5754032
Policy log std Std           0.20644785
Policy log std Max           -0.026491135
Policy log std Min           -1.2833823
Z mean eval                  6.348043
Z variance eval              0.002378333
total_rewards                [549.04255073 301.06818498 311.19872606 269.87623938 305.22748333
 422.28199045 267.79168108 279.72147827 312.64455687 324.62471498]
total_rewards_mean           334.3477606127556
total_rewards_std            82.73667043517983
total_rewards_max            549.042550725891
total_rewards_min            267.79168107902836
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               32.68191224709153
(Previous) Eval Time (s)     4.411879966966808
Sample Time (s)              18.652155322022736
Epoch Time (s)               55.745947536081076
Total Train Time (s)         15382.125974213704
Epoch                        244
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:19:06.167101 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #244 | Epoch Duration: 55.12542200088501
2020-01-11 04:19:06.167466 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #244 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.554834
Z variance train             0.0018557484
KL Divergence                131.84923
KL Loss                      13.184923
QF Loss                      377.92456
VF Loss                      213.46207
Policy Loss                  -791.61176
Q Predictions Mean           788.6513
Q Predictions Std            269.2053
Q Predictions Max            997.8904
Q Predictions Min            -6.888071
V Predictions Mean           783.1441
V Predictions Std            266.6116
V Predictions Max            993.6609
V Predictions Min            -10.110335
Log Pis Mean                 -0.28934205
Log Pis Std                  1.7788013
Log Pis Max                  6.9019966
Log Pis Min                  -6.0336514
Policy mu Mean               0.30446598
Policy mu Std                0.7609706
Policy mu Max                2.2246802
Policy mu Min                -2.327815
Policy log std Mean          -0.5841763
Policy log std Std           0.20297414
Policy log std Max           0.13565654
Policy log std Min           -1.3297732
Z mean eval                  0.16873106
Z variance eval              0.0015367894
total_rewards                [313.73060847 504.03732986 499.58908292 526.11190692 470.53626598
 505.6584318  505.32274101 479.08440625 502.83964941 326.35278525]
total_rewards_mean           463.3263207860779
total_rewards_std            73.12478459589916
total_rewards_max            526.1119069168506
total_rewards_min            313.730608472503
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               32.012766419909894
(Previous) Eval Time (s)     3.7910015578381717
Sample Time (s)              18.423385959118605
Epoch Time (s)               54.22715393686667
Total Train Time (s)         15437.459894289263
Epoch                        245
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:01.504556 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #245 | Epoch Duration: 55.33678936958313
2020-01-11 04:20:01.504814 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #245 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16605142
Z variance train             0.0016101577
KL Divergence                13.7379265
KL Loss                      1.3737926
QF Loss                      347.9757
VF Loss                      310.62762
Policy Loss                  -1286.4045
Q Predictions Mean           1286.6266
Q Predictions Std            396.8037
Q Predictions Max            1601.9629
Q Predictions Min            1.7788539
V Predictions Mean           1271.7683
V Predictions Std            391.8243
V Predictions Max            1551.8398
V Predictions Min            -2.5528142
Log Pis Mean                 0.2996462
Log Pis Std                  2.23517
Log Pis Max                  10.418074
Log Pis Min                  -4.1400137
Policy mu Mean               0.08093708
Policy mu Std                1.0333344
Policy mu Max                2.6161366
Policy mu Min                -3.2304592
Policy log std Mean          -0.49371335
Policy log std Std           0.15691435
Policy log std Max           0.14008659
Policy log std Min           -1.038673
Z mean eval                  5.8355403
Z variance eval              0.014851664
total_rewards                [312.5114959  314.51837689 272.94620584 432.91635506 310.10333724
 372.45172454 304.46120101 276.94074325 256.02752789 281.26672993]
total_rewards_mean           313.4143697542078
total_rewards_std            50.153771562764845
total_rewards_max            432.91635506347546
total_rewards_min            256.02752789042216
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               31.982610777020454
(Previous) Eval Time (s)     4.900302769150585
Sample Time (s)              18.043913369067013
Epoch Time (s)               54.92682691523805
Total Train Time (s)         15491.185996477026
Epoch                        246
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:55.232934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #246 | Epoch Duration: 53.72795748710632
2020-01-11 04:20:55.233112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #246 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.8723664
Z variance train             0.020077234
KL Divergence                103.81933
KL Loss                      10.381933
QF Loss                      225.45633
VF Loss                      54.07002
Policy Loss                  -810.2056
Q Predictions Mean           807.8564
Q Predictions Std            227.34624
Q Predictions Max            993.0101
Q Predictions Min            -4.6182847
V Predictions Mean           813.0836
V Predictions Std            227.37027
V Predictions Max            993.419
V Predictions Min            -5.039444
Log Pis Mean                 -0.38177136
Log Pis Std                  1.895658
Log Pis Max                  7.195249
Log Pis Min                  -5.9484677
Policy mu Mean               0.4267876
Policy mu Std                0.6946668
Policy mu Max                2.812343
Policy mu Min                -2.8920574
Policy log std Mean          -0.550183
Policy log std Std           0.19754358
Policy log std Max           0.053970844
Policy log std Min           -1.3613248
Z mean eval                  5.818933
Z variance eval              0.015655022
total_rewards                [456.35451528 422.08372776 299.11528924 284.41318174 258.51584123
 394.07637099 382.02428374 364.1495875  279.5130671  329.63079774]
total_rewards_mean           346.9876662315613
total_rewards_std            63.426055506760804
total_rewards_max            456.3545152820463
total_rewards_min            258.5158412260131
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               32.24696293333545
(Previous) Eval Time (s)     3.70112608326599
Sample Time (s)              18.607324295211583
Epoch Time (s)               54.55541331181303
Total Train Time (s)         15546.136882020626
Epoch                        247
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:50.186723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #247 | Epoch Duration: 54.95347881317139
2020-01-11 04:21:50.186888 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #247 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14950678
Z variance train             0.0015722208
KL Divergence                13.710944
KL Loss                      1.3710945
QF Loss                      159.01169
VF Loss                      74.72621
Policy Loss                  -1263.2947
Q Predictions Mean           1263.0471
Q Predictions Std            382.07043
Q Predictions Max            1566.2023
Q Predictions Min            -4.072573
V Predictions Mean           1261.8411
V Predictions Std            380.11023
V Predictions Max            1560.3068
V Predictions Min            5.9486127
Log Pis Mean                 -0.11347008
Log Pis Std                  2.219329
Log Pis Max                  12.435252
Log Pis Min                  -5.6670628
Policy mu Mean               0.14623834
Policy mu Std                0.94057405
Policy mu Max                4.0017796
Policy mu Min                -2.7617595
Policy log std Mean          -0.4885815
Policy log std Std           0.16966219
Policy log std Max           -0.08390397
Policy log std Min           -1.2911258
Z mean eval                  5.5607214
Z variance eval              0.0041005393
total_rewards                [303.7231702  317.33678959 295.22204175 306.27279226 257.08592081
 275.01845177 266.16304048 463.84393473 381.94313699 290.92441433]
total_rewards_mean           315.75336929024195
total_rewards_std            59.28526909101646
total_rewards_max            463.8439347255284
total_rewards_min            257.08592081096486
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               32.433558602351695
(Previous) Eval Time (s)     4.098711708094925
Sample Time (s)              18.01411275519058
Epoch Time (s)               54.5463830656372
Total Train Time (s)         15600.2138158069
Epoch                        248
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:22:44.267040 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #248 | Epoch Duration: 54.08002161979675
2020-01-11 04:22:44.267253 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #248 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.645705
Z variance train             0.006900292
KL Divergence                97.45238
KL Loss                      9.745238
QF Loss                      92.298775
VF Loss                      28.132738
Policy Loss                  -835.3207
Q Predictions Mean           832.9813
Q Predictions Std            252.47699
Q Predictions Max            1024.3296
Q Predictions Min            -3.4110022
V Predictions Mean           835.10205
V Predictions Std            251.95473
V Predictions Max            1043.7728
V Predictions Min            -0.95706964
Log Pis Mean                 -0.3453904
Log Pis Std                  1.6058314
Log Pis Max                  7.0299864
Log Pis Min                  -5.298071
Policy mu Mean               0.49011698
Policy mu Std                0.62242454
Policy mu Max                2.9877203
Policy mu Min                -1.9866786
Policy log std Mean          -0.51781553
Policy log std Std           0.19651254
Policy log std Max           0.09364712
Policy log std Min           -1.4621673
Z mean eval                  0.16627054
Z variance eval              0.002110436
total_rewards                [317.03863101 300.10106094 308.53855668 279.54644803 264.9647027
 296.70015534 245.78980438 267.32240144 384.47928756 351.31680673]
total_rewards_mean           301.5797854808899
total_rewards_std            39.71362379013385
total_rewards_max            384.47928756446316
total_rewards_min            245.7898043786626
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               32.107325504068285
(Previous) Eval Time (s)     3.632014560047537
Sample Time (s)              17.960964601952583
Epoch Time (s)               53.700304666068405
Total Train Time (s)         15653.867796155624
Epoch                        249
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:23:37.924077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #249 | Epoch Duration: 53.656675577163696
2020-01-11 04:23:37.924273 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #249 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.4699044
Z variance train             0.0055257617
KL Divergence                91.75474
KL Loss                      9.175474
QF Loss                      458.60037
VF Loss                      524.4556
Policy Loss                  -860.1875
Q Predictions Mean           857.1289
Q Predictions Std            237.67851
Q Predictions Max            1044.7103
Q Predictions Min            9.133274
V Predictions Mean           840.4015
V Predictions Std            235.03699
V Predictions Max            1027.7577
V Predictions Min            -3.3186972
Log Pis Mean                 -0.82062864
Log Pis Std                  1.6183479
Log Pis Max                  7.452319
Log Pis Min                  -5.9593678
Policy mu Mean               0.365141
Policy mu Std                0.5907701
Policy mu Max                3.3398402
Policy mu Min                -2.078511
Policy log std Mean          -0.44429865
Policy log std Std           0.19128793
Policy log std Max           -0.01586324
Policy log std Min           -1.3993809
Z mean eval                  0.28421193
Z variance eval              0.0018206794
total_rewards                [323.09761939 283.17131453 273.21186013 283.32025852 308.17631413
 319.84021371 272.07205651 298.73767423 288.42241416 295.77512215]
total_rewards_mean           294.58248474697666
total_rewards_std            17.067419102564386
total_rewards_max            323.0976193926506
total_rewards_min            272.07205650930143
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               33.7377943219617
(Previous) Eval Time (s)     3.5880854595452547
Sample Time (s)              18.2911237902008
Epoch Time (s)               55.617003571707755
Total Train Time (s)         15708.891773271374
Epoch                        250
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:32.950974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #250 | Epoch Duration: 55.02654242515564
2020-01-11 04:24:32.951170 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #250 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.481665
Z variance train             0.0035718363
KL Divergence                93.17255
KL Loss                      9.317255
QF Loss                      190.92575
VF Loss                      45.758762
Policy Loss                  -879.4404
Q Predictions Mean           884.85443
Q Predictions Std            220.61977
Q Predictions Max            1070.63
Q Predictions Min            3.454152
V Predictions Mean           878.761
V Predictions Std            219.9675
V Predictions Max            1057.4202
V Predictions Min            1.8223614
Log Pis Mean                 -0.45279074
Log Pis Std                  1.5192776
Log Pis Max                  3.7914977
Log Pis Min                  -4.810678
Policy mu Mean               0.45695737
Policy mu Std                0.58739614
Policy mu Max                2.1550803
Policy mu Min                -2.5142283
Policy log std Mean          -0.5073673
Policy log std Std           0.19571944
Policy log std Max           -0.023014784
Policy log std Min           -1.3999125
Z mean eval                  0.24346519
Z variance eval              0.002596173
total_rewards                [599.15692533 527.33874192 554.90128949 558.30899488 565.17512938
 572.38576472 589.91862869 307.50156689 573.04833749 332.65531751]
total_rewards_mean           518.0390696300822
total_rewards_std            100.85054195131225
total_rewards_max            599.1569253278572
total_rewards_min            307.5015668897714
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               34.32095552608371
(Previous) Eval Time (s)     2.9972806577570736
Sample Time (s)              17.46750956773758
Epoch Time (s)               54.78574575157836
Total Train Time (s)         15766.186296520289
Epoch                        251
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:25:30.248535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #251 | Epoch Duration: 57.29706144332886
2020-01-11 04:25:30.248723 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #251 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23296504
Z variance train             0.0025975567
KL Divergence                13.007726
KL Loss                      1.3007725
QF Loss                      1425.8397
VF Loss                      1167.3889
Policy Loss                  -1205.2684
Q Predictions Mean           1200.7822
Q Predictions Std            451.94315
Q Predictions Max            1591.4606
Q Predictions Min            -5.852958
V Predictions Mean           1236.1016
V Predictions Std            456.21198
V Predictions Max            1630.0118
V Predictions Min            4.4449797
Log Pis Mean                 -0.041100383
Log Pis Std                  2.1189947
Log Pis Max                  12.715748
Log Pis Min                  -4.6439877
Policy mu Mean               -0.15845083
Policy mu Std                0.9407526
Policy mu Max                3.3732166
Policy mu Min                -2.789214
Policy log std Mean          -0.4698961
Policy log std Std           0.18964855
Policy log std Max           -0.066081166
Policy log std Min           -1.3678093
Z mean eval                  0.2827688
Z variance eval              0.0035244033
total_rewards                [289.3481648  315.05109601 270.07626995 433.46315467 268.23683382
 395.29816541 361.77645036 305.75500648 462.94901953 519.26661345]
total_rewards_mean           362.12207744974336
total_rewards_std            83.08226947225909
total_rewards_max            519.2666134487248
total_rewards_min            268.2368338242181
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               34.35961339389905
(Previous) Eval Time (s)     5.508167188614607
Sample Time (s)              20.99991857074201
Epoch Time (s)               60.86769915325567
Total Train Time (s)         15825.772673024796
Epoch                        252
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:29.841811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #252 | Epoch Duration: 59.59294366836548
2020-01-11 04:26:29.842007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #252 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.28286478
Z variance train             0.0035239826
KL Divergence                12.238043
KL Loss                      1.2238044
QF Loss                      278.9969
VF Loss                      414.86826
Policy Loss                  -1300.4429
Q Predictions Mean           1299.8801
Q Predictions Std            428.98615
Q Predictions Max            1622.0522
Q Predictions Min            -8.619945
V Predictions Mean           1296.9233
V Predictions Std            423.73114
V Predictions Max            1615.7286
V Predictions Min            -14.213455
Log Pis Mean                 0.08273101
Log Pis Std                  2.120825
Log Pis Max                  8.040945
Log Pis Min                  -5.0179224
Policy mu Mean               -0.039894283
Policy mu Std                0.9821818
Policy mu Max                2.4573944
Policy mu Min                -2.8295488
Policy log std Mean          -0.4943893
Policy log std Std           0.17338613
Policy log std Max           -0.07564449
Policy log std Min           -1.340132
Z mean eval                  0.26094118
Z variance eval              0.0031046886
total_rewards                [721.54170146 470.26884788 582.99937622 603.5502203  461.47957494
 562.28079039 573.38662614 601.55358333 615.1175956  313.46787883]
total_rewards_mean           550.5646195090997
total_rewards_std            105.41164273431406
total_rewards_max            721.5417014648483
total_rewards_min            313.46787882517805
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               35.53980523115024
(Previous) Eval Time (s)     4.233007246162742
Sample Time (s)              18.867118183523417
Epoch Time (s)               58.6399306608364
Total Train Time (s)         15885.898922652006
Epoch                        253
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:29.969713 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #253 | Epoch Duration: 60.12751030921936
2020-01-11 04:27:29.970127 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #253 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26145703
Z variance train             0.0031043119
KL Divergence                12.469076
KL Loss                      1.2469076
QF Loss                      381.00983
VF Loss                      107.41459
Policy Loss                  -1237.1973
Q Predictions Mean           1237.7217
Q Predictions Std            433.7044
Q Predictions Max            1614.5087
Q Predictions Min            -6.268881
V Predictions Mean           1233.6976
V Predictions Std            436.78378
V Predictions Max            1615.2412
V Predictions Min            -31.400644
Log Pis Mean                 0.13181174
Log Pis Std                  2.1446538
Log Pis Max                  8.882165
Log Pis Min                  -4.313237
Policy mu Mean               0.052582297
Policy mu Std                0.9518846
Policy mu Max                3.076905
Policy mu Min                -2.6226447
Policy log std Mean          -0.51892376
Policy log std Std           0.17567182
Policy log std Max           -0.09096816
Policy log std Min           -1.3392923
Z mean eval                  0.2440255
Z variance eval              0.003477731
total_rewards                [411.1147779  494.59023821 527.92757886 458.51049668 451.12017955
 473.93647729 461.90822471 544.09105214 583.75125063 559.16761269]
total_rewards_mean           496.61178886624276
total_rewards_std            52.24462048062945
total_rewards_max            583.7512506348904
total_rewards_min            411.11477790357384
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               35.32959913276136
(Previous) Eval Time (s)     5.720133105758578
Sample Time (s)              20.418521084357053
Epoch Time (s)               61.46825332287699
Total Train Time (s)         15946.020261796191
Epoch                        254
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:28:30.093716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #254 | Epoch Duration: 60.12333917617798
2020-01-11 04:28:30.093993 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #254 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23654473
Z variance train             0.003399557
KL Divergence                12.264105
KL Loss                      1.2264105
QF Loss                      223.85683
VF Loss                      66.607796
Policy Loss                  -1287.9785
Q Predictions Mean           1284.0474
Q Predictions Std            420.2963
Q Predictions Max            1607.4911
Q Predictions Min            8.5441675
V Predictions Mean           1285.7496
V Predictions Std            423.20837
V Predictions Max            1612.4039
V Predictions Min            -4.8695774
Log Pis Mean                 0.0066358447
Log Pis Std                  2.1974022
Log Pis Max                  6.6548176
Log Pis Min                  -5.2621737
Policy mu Mean               0.050038915
Policy mu Std                0.97558117
Policy mu Max                2.274855
Policy mu Min                -3.3153698
Policy log std Mean          -0.47658917
Policy log std Std           0.1703814
Policy log std Max           -0.08174449
Policy log std Min           -1.1337984
Z mean eval                  0.23773539
Z variance eval              0.0032279238
total_rewards                [520.27571194 655.61789496 419.4801739  428.45677699 610.49677501
 517.80623129 607.49957739 272.39837528 506.02360116 551.15182307]
total_rewards_mean           508.9206941004335
total_rewards_std            106.75774992769767
total_rewards_max            655.617894963905
total_rewards_min            272.3983752833754
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               33.87566292611882
(Previous) Eval Time (s)     4.374771979171783
Sample Time (s)              19.77190603967756
Epoch Time (s)               58.022340944968164
Total Train Time (s)         16004.992060346063
Epoch                        255
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:29.068537 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #255 | Epoch Duration: 58.97434687614441
2020-01-11 04:29:29.068741 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #255 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22807972
Z variance train             0.0031881835
KL Divergence                12.2828865
KL Loss                      1.2282887
QF Loss                      216.24791
VF Loss                      51.65263
Policy Loss                  -1299.464
Q Predictions Mean           1297.5165
Q Predictions Std            404.0496
Q Predictions Max            1611.8295
Q Predictions Min            12.783472
V Predictions Mean           1295.1934
V Predictions Std            404.0678
V Predictions Max            1609.1367
V Predictions Min            -1.3753359
Log Pis Mean                 -0.058072157
Log Pis Std                  2.1435366
Log Pis Max                  7.1821117
Log Pis Min                  -4.414736
Policy mu Mean               -0.009712565
Policy mu Std                0.93702024
Policy mu Max                2.6117961
Policy mu Min                -2.8519857
Policy log std Mean          -0.4816443
Policy log std Std           0.16954613
Policy log std Max           -0.08922374
Policy log std Min           -1.0644113
Z mean eval                  4.8004036
Z variance eval              0.0041811476
total_rewards                [466.12398678 455.32126298 621.95408498 723.17760745 593.28375012
 578.53177358 447.7458254  606.32143346 593.1875738  542.47802144]
total_rewards_mean           562.8125319987387
total_rewards_std            82.31817846280596
total_rewards_max            723.1776074506133
total_rewards_min            447.74582539580416
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               34.52208007313311
(Previous) Eval Time (s)     5.326422362122685
Sample Time (s)              20.325926914345473
Epoch Time (s)               60.17442934960127
Total Train Time (s)         16065.734934995882
Epoch                        256
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:30:29.815247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #256 | Epoch Duration: 60.74633431434631
2020-01-11 04:30:29.815457 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #256 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21705778
Z variance train             0.002992338
KL Divergence                12.55629
KL Loss                      1.255629
QF Loss                      150.44124
VF Loss                      49.737675
Policy Loss                  -1299.7002
Q Predictions Mean           1297.6595
Q Predictions Std            393.40485
Q Predictions Max            1605.2216
Q Predictions Min            -10.205392
V Predictions Mean           1299.5356
V Predictions Std            392.00015
V Predictions Max            1603.9486
V Predictions Min            4.5802116
Log Pis Mean                 0.19014019
Log Pis Std                  2.363461
Log Pis Max                  7.1052027
Log Pis Min                  -4.548917
Policy mu Mean               0.04233429
Policy mu Std                0.97355986
Policy mu Max                2.6677673
Policy mu Min                -2.8219202
Policy log std Mean          -0.47404695
Policy log std Std           0.16388372
Policy log std Max           -0.0071641207
Policy log std Min           -1.2804956
Z mean eval                  0.20623894
Z variance eval              0.002766808
total_rewards                [623.17515433 576.94237774 678.84760759 678.67831936 610.48884163
 718.04966719 658.55298607 575.77336741 603.65767452 728.78560452]
total_rewards_mean           645.295160037676
total_rewards_std            52.55443063792423
total_rewards_max            728.7856045220374
total_rewards_min            575.7733674114843
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               34.52495922893286
(Previous) Eval Time (s)     5.897914313245565
Sample Time (s)              19.327750669326633
Epoch Time (s)               59.750624211505055
Total Train Time (s)         16125.469488067552
Epoch                        257
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:31:29.558769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #257 | Epoch Duration: 59.743163108825684
2020-01-11 04:31:29.558933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #257 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17599559
Z variance train             0.002829033
KL Divergence                12.760332
KL Loss                      1.2760333
QF Loss                      161.37491
VF Loss                      31.007956
Policy Loss                  -1298.7721
Q Predictions Mean           1300.2102
Q Predictions Std            418.5997
Q Predictions Max            1622.3942
Q Predictions Min            -4.7098336
V Predictions Mean           1298.0457
V Predictions Std            415.31467
V Predictions Max            1613.0243
V Predictions Min            5.261627
Log Pis Mean                 -0.14480357
Log Pis Std                  2.2998512
Log Pis Max                  8.150684
Log Pis Min                  -4.382175
Policy mu Mean               -0.021350414
Policy mu Std                0.9371088
Policy mu Max                2.0974061
Policy mu Min                -2.8895862
Policy log std Mean          -0.4716606
Policy log std Std           0.16712329
Policy log std Max           -0.011304289
Policy log std Min           -1.1456146
Z mean eval                  0.20714298
Z variance eval              0.0028422517
total_rewards                [736.77701905 546.26608273 748.3096318  649.80802316 627.66928576
 629.92680819 669.2699685  675.32927933 698.55180676 533.06591201]
total_rewards_mean           651.4973817274102
total_rewards_std            67.73384120604383
total_rewards_max            748.3096317961614
total_rewards_min            533.06591200594
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               33.934900112915784
(Previous) Eval Time (s)     5.890065892133862
Sample Time (s)              21.148708258289844
Epoch Time (s)               60.97367426333949
Total Train Time (s)         16186.749639344867
Epoch                        258
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:30.839568 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #258 | Epoch Duration: 61.28045058250427
2020-01-11 04:32:30.839871 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #258 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.647415
Z variance train             0.006581108
KL Divergence                71.93319
KL Loss                      7.193319
QF Loss                      2791.1162
VF Loss                      211.77905
Policy Loss                  -955.0634
Q Predictions Mean           977.9403
Q Predictions Std            229.60748
Q Predictions Max            1174.6294
Q Predictions Min            2.3750656
V Predictions Mean           942.82715
V Predictions Std            243.11395
V Predictions Max            1144.5358
V Predictions Min            -17.543226
Log Pis Mean                 -0.011956569
Log Pis Std                  1.6635563
Log Pis Max                  5.757737
Log Pis Min                  -4.6373796
Policy mu Mean               0.4737269
Policy mu Std                0.7302757
Policy mu Max                1.9226098
Policy mu Min                -2.4447567
Policy log std Mean          -0.50800306
Policy log std Std           0.1828911
Policy log std Max           0.0068598986
Policy log std Min           -1.2899176
Z mean eval                  4.6773934
Z variance eval              0.0053910986
total_rewards                [810.25594852 768.2994793  671.88971928 653.80680972 870.66052085
 822.28967219 580.99379493 612.69762215 569.55734421 694.70307307]
total_rewards_mean           705.5153984225842
total_rewards_std            101.16733602198423
total_rewards_max            870.6605208516368
total_rewards_min            569.5573442129848
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               34.524840749334544
(Previous) Eval Time (s)     6.1964228972792625
Sample Time (s)              21.96209533372894
Epoch Time (s)               62.683358980342746
Total Train Time (s)         16248.835556183942
Epoch                        259
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:32.928934 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #259 | Epoch Duration: 62.08886408805847
2020-01-11 04:33:32.929228 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #259 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2346529
Z variance train             0.0030376168
KL Divergence                12.694324
KL Loss                      1.2694324
QF Loss                      179.62744
VF Loss                      77.09988
Policy Loss                  -1300.8938
Q Predictions Mean           1300.127
Q Predictions Std            414.3779
Q Predictions Max            1599.1189
Q Predictions Min            9.367755
V Predictions Mean           1299.2449
V Predictions Std            412.03986
V Predictions Max            1602.6765
V Predictions Min            4.5624733
Log Pis Mean                 0.19266799
Log Pis Std                  2.4074755
Log Pis Max                  9.345376
Log Pis Min                  -5.8120565
Policy mu Mean               -0.104031004
Policy mu Std                1.0123619
Policy mu Max                2.9752822
Policy mu Min                -3.1375105
Policy log std Mean          -0.45132625
Policy log std Std           0.16841939
Policy log std Max           0.060873806
Policy log std Min           -1.050339
Z mean eval                  0.22292432
Z variance eval              0.0029459526
total_rewards                [539.14332912 600.21040401 548.99913619 603.01412485 494.42535042
 503.97762915 628.72744649 564.44625152 427.29324037 618.14842485]
total_rewards_mean           552.8385336969129
total_rewards_std            60.56759890893387
total_rewards_max            628.7274464901391
total_rewards_min            427.29324037080823
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               35.22222946723923
(Previous) Eval Time (s)     5.601586367934942
Sample Time (s)              22.8811829960905
Epoch Time (s)               63.704998831264675
Total Train Time (s)         16312.571039204486
Epoch                        260
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:36.667005 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #260 | Epoch Duration: 63.73759841918945
2020-01-11 04:34:36.667213 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #260 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21875449
Z variance train             0.002940398
KL Divergence                12.8019905
KL Loss                      1.280199
QF Loss                      127.42122
VF Loss                      285.20898
Policy Loss                  -1209.6737
Q Predictions Mean           1210.4641
Q Predictions Std            483.36395
Q Predictions Max            1603.919
Q Predictions Min            0.2234292
V Predictions Mean           1221.5186
V Predictions Std            487.21332
V Predictions Max            1620.43
V Predictions Min            2.6848917
Log Pis Mean                 -0.22639659
Log Pis Std                  2.0007417
Log Pis Max                  7.6926584
Log Pis Min                  -4.4031267
Policy mu Mean               0.090384215
Policy mu Std                0.90325487
Policy mu Max                2.959879
Policy mu Min                -2.69438
Policy log std Mean          -0.45689586
Policy log std Std           0.17823412
Policy log std Max           -0.0834668
Policy log std Min           -1.080108
Z mean eval                  0.21071815
Z variance eval              0.002760306
total_rewards                [597.82272413 637.41038154 649.21752017 626.80743965 627.04591888
 674.12176466 636.20036367 641.72181599 581.74873352 592.06997246]
total_rewards_mean           626.4166634673754
total_rewards_std            26.906443932533243
total_rewards_max            674.1217646580594
total_rewards_min            581.7487335194176
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               35.166706073097885
(Previous) Eval Time (s)     5.63385179778561
Sample Time (s)              21.81073949439451
Epoch Time (s)               62.611297365278006
Total Train Time (s)         16375.621439914219
Epoch                        261
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:39.723740 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #261 | Epoch Duration: 63.05636405944824
2020-01-11 04:35:39.724044 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #261 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3944306
Z variance train             0.027984586
KL Divergence                65.96234
KL Loss                      6.5962343
QF Loss                      1121.2345
VF Loss                      163.68423
Policy Loss                  -924.9114
Q Predictions Mean           927.6367
Q Predictions Std            250.61688
Q Predictions Max            1116.4268
Q Predictions Min            5.229498
V Predictions Mean           935.6144
V Predictions Std            252.27534
V Predictions Max            1130.2983
V Predictions Min            4.3202934
Log Pis Mean                 -0.1357895
Log Pis Std                  1.7081366
Log Pis Max                  7.770779
Log Pis Min                  -6.9152756
Policy mu Mean               0.4687232
Policy mu Std                0.7622354
Policy mu Max                2.3305728
Policy mu Min                -3.490028
Policy log std Mean          -0.5261322
Policy log std Std           0.19778624
Policy log std Max           -0.106235445
Policy log std Min           -1.3725321
Z mean eval                  0.21728325
Z variance eval              0.002464456
total_rewards                [616.06967724 636.5300789  686.11831596 676.34166502 760.18389305
 648.43884476 797.13804866 766.96153196 748.96666989 680.00925043]
total_rewards_mean           701.6757975876658
total_rewards_std            58.987058541907274
total_rewards_max            797.1380486571413
total_rewards_min            616.0696772399513
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               34.673155383672565
(Previous) Eval Time (s)     6.07853863062337
Sample Time (s)              23.706474729813635
Epoch Time (s)               64.45816874410957
Total Train Time (s)         16440.83403285453
Epoch                        262
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:44.937836 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #262 | Epoch Duration: 65.2135283946991
2020-01-11 04:36:44.938349 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #262 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07768758
Z variance train             0.0033362075
KL Divergence                12.76029
KL Loss                      1.276029
QF Loss                      337.28815
VF Loss                      81.499405
Policy Loss                  -1131.8658
Q Predictions Mean           1130.5663
Q Predictions Std            416.1038
Q Predictions Max            1493.2007
Q Predictions Min            -34.93329
V Predictions Mean           1129.728
V Predictions Std            411.63498
V Predictions Max            1479.3252
V Predictions Min            -15.243869
Log Pis Mean                 -0.2125564
Log Pis Std                  2.0195844
Log Pis Max                  7.8982563
Log Pis Min                  -5.49085
Policy mu Mean               -0.1819609
Policy mu Std                0.9005225
Policy mu Max                2.4165602
Policy mu Min                -2.674746
Policy log std Mean          -0.47158766
Policy log std Std           0.16647103
Policy log std Max           0.08791581
Policy log std Min           -0.9193357
Z mean eval                  0.20639741
Z variance eval              0.0030495434
total_rewards                [646.60800334 650.10081634 602.0068114  654.98020583 648.69716532
 640.87267859 675.27984303 598.99140351 605.21402855 584.13010767]
total_rewards_mean           630.6881063575465
total_rewards_std            28.776293637716286
total_rewards_max            675.2798430261399
total_rewards_min            584.1301076674354
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               34.998479827772826
(Previous) Eval Time (s)     6.83344607707113
Sample Time (s)              23.779034191276878
Epoch Time (s)               65.61096009612083
Total Train Time (s)         16505.456922682468
Epoch                        263
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:49.563157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #263 | Epoch Duration: 64.62445092201233
2020-01-11 04:37:49.563367 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #263 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19263265
Z variance train             0.0034208088
KL Divergence                12.616175
KL Loss                      1.2616175
QF Loss                      334.74057
VF Loss                      586.1128
Policy Loss                  -1270.9855
Q Predictions Mean           1269.4358
Q Predictions Std            422.72748
Q Predictions Max            1619.793
Q Predictions Min            1.1816483
V Predictions Mean           1270.8722
V Predictions Std            418.24207
V Predictions Max            1613.3857
V Predictions Min            3.0559347
Log Pis Mean                 -0.10959904
Log Pis Std                  2.0327268
Log Pis Max                  6.8770766
Log Pis Min                  -5.6167665
Policy mu Mean               0.15934789
Policy mu Std                0.9319069
Policy mu Max                2.985195
Policy mu Min                -2.810463
Policy log std Mean          -0.46932864
Policy log std Std           0.16749233
Policy log std Max           -0.10760635
Policy log std Min           -0.92540383
Z mean eval                  0.19780993
Z variance eval              0.0034093116
total_rewards                [861.14387369 740.81083443 833.23689696 810.37983413 879.19708358
 751.00096485 795.8751904  707.80320946 823.7946851  737.4067791 ]
total_rewards_mean           794.0649351704024
total_rewards_std            54.56789992044516
total_rewards_max            879.1970835847293
total_rewards_min            707.8032094611995
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               33.84992598230019
(Previous) Eval Time (s)     5.84657298726961
Sample Time (s)              23.21245241817087
Epoch Time (s)               62.90895138774067
Total Train Time (s)         16569.46389441332
Epoch                        264
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:38:53.573978 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #264 | Epoch Duration: 64.01045417785645
2020-01-11 04:38:53.574212 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #264 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20625362
Z variance train             0.0033868984
KL Divergence                12.953254
KL Loss                      1.2953254
QF Loss                      142.34787
VF Loss                      192.41562
Policy Loss                  -1249.916
Q Predictions Mean           1247.8962
Q Predictions Std            417.6816
Q Predictions Max            1567.9944
Q Predictions Min            -1.6905824
V Predictions Mean           1239.0886
V Predictions Std            414.99463
V Predictions Max            1552.91
V Predictions Min            2.1878936
Log Pis Mean                 0.07366171
Log Pis Std                  2.1235955
Log Pis Max                  8.132034
Log Pis Min                  -6.318871
Policy mu Mean               -0.14264837
Policy mu Std                0.9555548
Policy mu Max                2.3180914
Policy mu Min                -2.8349733
Policy log std Mean          -0.5034774
Policy log std Std           0.15651673
Policy log std Max           -0.033837557
Policy log std Min           -1.0782552
Z mean eval                  0.16843864
Z variance eval              0.0032682992
total_rewards                [890.15148114 880.80761492 866.71468535 781.39993523 754.15405195
 781.13879508 587.99324364 868.39752733 651.94263544 841.79654359]
total_rewards_mean           790.4496513663405
total_rewards_std            97.10432379198183
total_rewards_max            890.1514811404728
total_rewards_min            587.9932436359154
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               32.393432955257595
(Previous) Eval Time (s)     6.947710703127086
Sample Time (s)              22.137758628930897
Epoch Time (s)               61.47890228731558
Total Train Time (s)         16630.968338032253
Epoch                        265
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:55.081619 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #265 | Epoch Duration: 61.50723433494568
2020-01-11 04:39:55.081815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #265 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17879154
Z variance train             0.0032954682
KL Divergence                12.7329235
KL Loss                      1.2732924
QF Loss                      1164.492
VF Loss                      1324.701
Policy Loss                  -1277.0088
Q Predictions Mean           1272.3683
Q Predictions Std            412.2256
Q Predictions Max            1592.6688
Q Predictions Min            14.127406
V Predictions Mean           1243.972
V Predictions Std            402.2034
V Predictions Max            1558.6943
V Predictions Min            2.2375143
Log Pis Mean                 0.13444686
Log Pis Std                  2.637354
Log Pis Max                  16.83017
Log Pis Min                  -4.5414543
Policy mu Mean               -0.061319884
Policy mu Std                1.0163935
Policy mu Max                3.9051654
Policy mu Min                -5.3065634
Policy log std Mean          -0.4910771
Policy log std Std           0.16538079
Policy log std Max           -0.08579561
Policy log std Min           -1.2685232
Z mean eval                  5.1484327
Z variance eval              0.010733792
total_rewards                [753.05536507 821.2511952  842.57562844 687.63997549 276.10694877
 517.9958783  832.74453885 785.02811032 872.19616718 644.44190656]
total_rewards_mean           703.303571417918
total_rewards_std            175.58134905569077
total_rewards_max            872.1961671755807
total_rewards_min            276.1069487726849
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               32.63533086888492
(Previous) Eval Time (s)     6.9756688619963825
Sample Time (s)              22.858861189801246
Epoch Time (s)               62.46986092068255
Total Train Time (s)         16693.287941630464
Epoch                        266
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:57.404996 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #266 | Epoch Duration: 62.32303762435913
2020-01-11 04:40:57.405174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #266 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8745475
Z variance train             0.0127998935
KL Divergence                78.980125
KL Loss                      7.8980126
QF Loss                      2037.0444
VF Loss                      540.67566
Policy Loss                  -1117.117
Q Predictions Mean           1109.6714
Q Predictions Std            324.49524
Q Predictions Max            1355.9053
Q Predictions Min            2.7405665
V Predictions Mean           1105.4884
V Predictions Std            328.86356
V Predictions Max            1345.3772
V Predictions Min            -0.74725795
Log Pis Mean                 0.23825535
Log Pis Std                  1.9843851
Log Pis Max                  6.399364
Log Pis Min                  -6.5510087
Policy mu Mean               0.6347913
Policy mu Std                0.80856144
Policy mu Max                3.069829
Policy mu Min                -2.9932368
Policy log std Mean          -0.5101599
Policy log std Std           0.15080214
Policy log std Max           0.032619238
Policy log std Min           -1.438436
Z mean eval                  5.091298
Z variance eval              0.012360243
total_rewards                [722.53807697 807.59692013 759.1243843  810.12919863 892.02696851
 805.88412054 778.24168336 929.87610344 818.576402   706.36369276]
total_rewards_mean           803.0357550635176
total_rewards_std            65.34292187398593
total_rewards_max            929.8761034368296
total_rewards_min            706.3636927606251
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               32.64564978238195
(Previous) Eval Time (s)     6.828556528314948
Sample Time (s)              21.02083275653422
Epoch Time (s)               60.49503906723112
Total Train Time (s)         16754.046917241532
Epoch                        267
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:41:58.166210 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #267 | Epoch Duration: 60.760902404785156
2020-01-11 04:41:58.166386 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17691536
Z variance train             0.0033107973
KL Divergence                12.542704
KL Loss                      1.2542704
QF Loss                      175.15405
VF Loss                      102.829666
Policy Loss                  -1248.4745
Q Predictions Mean           1246.6492
Q Predictions Std            413.6164
Q Predictions Max            1563.7086
Q Predictions Min            4.048704
V Predictions Mean           1242.6816
V Predictions Std            412.0577
V Predictions Max            1559.8431
V Predictions Min            8.2686205
Log Pis Mean                 0.1176638
Log Pis Std                  2.2190838
Log Pis Max                  8.007393
Log Pis Min                  -4.276729
Policy mu Mean               0.03356066
Policy mu Std                0.9740124
Policy mu Max                3.1319544
Policy mu Min                -2.8650587
Policy log std Mean          -0.4688702
Policy log std Std           0.14987874
Policy log std Max           -0.056239814
Policy log std Min           -1.0996807
Z mean eval                  0.28579164
Z variance eval              0.006394514
total_rewards                [ 963.49598223  788.70584187  825.19021028  877.49523007  888.64295599
  819.902546    784.45435399  783.0966189  1003.13845841  929.26338333]
total_rewards_mean           866.3385581068053
total_rewards_std            74.99722702667793
total_rewards_max            1003.1384584144434
total_rewards_min            783.0966188969792
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               32.59776422707364
(Previous) Eval Time (s)     7.094106158707291
Sample Time (s)              23.781492904294282
Epoch Time (s)               63.47336329007521
Total Train Time (s)         16818.427044110373
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:02.549437 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #268 | Epoch Duration: 64.3829128742218
2020-01-11 04:43:02.549613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.813794
Z variance train             0.013650003
KL Divergence                78.754845
KL Loss                      7.8754845
QF Loss                      172.07228
VF Loss                      94.769646
Policy Loss                  -1128.7616
Q Predictions Mean           1127.3931
Q Predictions Std            351.13687
Q Predictions Max            1392.8542
Q Predictions Min            0.68098056
V Predictions Mean           1135.8386
V Predictions Std            352.4365
V Predictions Max            1409.2222
V Predictions Min            3.3610535
Log Pis Mean                 0.00298357
Log Pis Std                  1.8369339
Log Pis Max                  6.924964
Log Pis Min                  -5.6260247
Policy mu Mean               0.50399464
Policy mu Std                0.8325463
Policy mu Max                2.3828483
Policy mu Min                -2.7196164
Policy log std Mean          -0.502212
Policy log std Std           0.17338447
Policy log std Max           -0.027900487
Policy log std Min           -1.3985623
Z mean eval                  0.19883105
Z variance eval              0.0039709387
total_rewards                [ 855.2596325   779.17375958  732.04606789  812.47874681  584.39790644
  750.22680264  588.48276764  756.36800115 1033.79849347  581.09854658]
total_rewards_mean           747.3330724705286
total_rewards_std            133.68143828711587
total_rewards_max            1033.7984934747747
total_rewards_min            581.0985465755186
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               32.47718432499096
(Previous) Eval Time (s)     8.003330861218274
Sample Time (s)              22.646805016323924
Epoch Time (s)               63.127320202533156
Total Train Time (s)         16880.563662671484
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:04.689510 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #269 | Epoch Duration: 62.139739751815796
2020-01-11 04:44:04.689743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #269 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.9756737
Z variance train             0.007147978
KL Divergence                82.67175
KL Loss                      8.267176
QF Loss                      318.431
VF Loss                      153.21745
Policy Loss                  -1159.7887
Q Predictions Mean           1156.4218
Q Predictions Std            412.29684
Q Predictions Max            1465.7222
Q Predictions Min            -2.2337885
V Predictions Mean           1158.0203
V Predictions Std            409.04733
V Predictions Max            1470.6068
V Predictions Min            -1.0442313
Log Pis Mean                 0.38114786
Log Pis Std                  2.066932
Log Pis Max                  8.511885
Log Pis Min                  -6.7270937
Policy mu Mean               0.5428236
Policy mu Std                0.8761495
Policy mu Max                2.3570004
Policy mu Min                -3.044165
Policy log std Mean          -0.5299496
Policy log std Std           0.17851926
Policy log std Max           -0.028822243
Policy log std Min           -1.5756696
Z mean eval                  0.18842581
Z variance eval              0.0037539895
total_rewards                [815.46285674 597.15980609 690.35689926 505.98126324 771.01495418
 839.00499856 746.04812012 755.09763373 367.90549162 773.2023597 ]
total_rewards_mean           686.1234383244961
total_rewards_std            143.13821524960116
total_rewards_max            839.00499856399
total_rewards_min            367.9054916196596
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               32.859526487998664
(Previous) Eval Time (s)     7.015394723042846
Sample Time (s)              23.423041372094303
Epoch Time (s)               63.29796258313581
Total Train Time (s)         16943.51061526267
Epoch                        270
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:45:07.640123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #270 | Epoch Duration: 62.95021343231201
2020-01-11 04:45:07.640317 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.021276
Z variance train             0.0058872597
KL Divergence                83.232666
KL Loss                      8.323267
QF Loss                      438.28558
VF Loss                      98.59271
Policy Loss                  -1203.6874
Q Predictions Mean           1198.1509
Q Predictions Std            394.69873
Q Predictions Max            1501.2184
Q Predictions Min            -7.0847874
V Predictions Mean           1202.9287
V Predictions Std            397.8901
V Predictions Max            1500.0719
V Predictions Min            0.36092573
Log Pis Mean                 0.11086027
Log Pis Std                  1.988032
Log Pis Max                  9.102588
Log Pis Min                  -4.243372
Policy mu Mean               0.386844
Policy mu Std                0.8565326
Policy mu Max                2.4743073
Policy mu Min                -3.412662
Policy log std Mean          -0.5391547
Policy log std Std           0.21165094
Policy log std Max           0.09422809
Policy log std Min           -1.5672551
Z mean eval                  0.1758261
Z variance eval              0.0038099743
total_rewards                [ 874.40143455  848.60729129  616.23901595  958.72454049 1115.28078327
  785.02047488  923.53627128  709.13863214  751.16831695  306.76823296]
total_rewards_mean           788.8884993767248
total_rewards_std            208.4299961702551
total_rewards_max            1115.280783273509
total_rewards_min            306.7682329585751
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               32.331419489812106
(Previous) Eval Time (s)     6.667302838061005
Sample Time (s)              22.93070700066164
Epoch Time (s)               61.92942932853475
Total Train Time (s)         17005.53490568977
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:09.668438 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #271 | Epoch Duration: 62.02796769142151
2020-01-11 04:46:09.668655 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #271 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25257513
Z variance train             0.003937234
KL Divergence                12.365201
KL Loss                      1.2365202
QF Loss                      1058.9648
VF Loss                      282.73657
Policy Loss                  -1265.3822
Q Predictions Mean           1268.0021
Q Predictions Std            448.29996
Q Predictions Max            1608.8334
Q Predictions Min            -0.5311971
V Predictions Mean           1263.429
V Predictions Std            447.38083
V Predictions Max            1606.4424
V Predictions Min            2.1400275
Log Pis Mean                 0.10324025
Log Pis Std                  2.1686056
Log Pis Max                  9.690624
Log Pis Min                  -4.9025245
Policy mu Mean               0.15475833
Policy mu Std                0.9912257
Policy mu Max                2.678687
Policy mu Min                -3.287169
Policy log std Mean          -0.48873115
Policy log std Std           0.15584205
Policy log std Max           0.10387114
Policy log std Min           -0.96334696
Z mean eval                  4.0795875
Z variance eval              0.006274569
total_rewards                [719.50632173 566.83894754 619.50972239 731.17836319 759.66918603
 539.16700529 745.22854198 778.73961856 476.00289312 710.07269778]
total_rewards_mean           664.591329761282
total_rewards_std            100.48620499359274
total_rewards_max            778.739618555821
total_rewards_min            476.00289311751976
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               32.902236172929406
(Previous) Eval Time (s)     6.7654938087798655
Sample Time (s)              23.153204006608576
Epoch Time (s)               62.82093398831785
Total Train Time (s)         17067.349286816083
Epoch                        272
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:11.487360 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #272 | Epoch Duration: 61.81854844093323
2020-01-11 04:47:11.487528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #272 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1285295
Z variance train             0.006199751
KL Divergence                60.795654
KL Loss                      6.0795655
QF Loss                      158.90842
VF Loss                      265.10602
Policy Loss                  -1098.2424
Q Predictions Mean           1093.8743
Q Predictions Std            297.3342
Q Predictions Max            1357.8246
Q Predictions Min            -2.0058913
V Predictions Mean           1086.1892
V Predictions Std            295.48633
V Predictions Max            1345.8453
V Predictions Min            2.1286693
Log Pis Mean                 0.0793331
Log Pis Std                  1.9918286
Log Pis Max                  8.9052925
Log Pis Min                  -4.5772114
Policy mu Mean               0.33254126
Policy mu Std                0.89891994
Policy mu Max                2.4988532
Policy mu Min                -2.9174454
Policy log std Mean          -0.49849746
Policy log std Std           0.17624189
Policy log std Max           -0.054138243
Policy log std Min           -1.3856229
Z mean eval                  4.721555
Z variance eval              0.0007739707
total_rewards                [852.30189341 673.89706626 931.85534451 933.92318098 894.43711145
 996.80268068 687.58775207 882.65349572 630.75547449 872.01285306]
total_rewards_mean           835.6226852609041
total_rewards_std            119.25446263241791
total_rewards_max            996.8026806769952
total_rewards_min            630.755474490594
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               32.21058908337727
(Previous) Eval Time (s)     5.762787397950888
Sample Time (s)              21.86532122734934
Epoch Time (s)               59.8386977086775
Total Train Time (s)         17129.53856535768
Epoch                        273
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:48:13.678734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #273 | Epoch Duration: 62.19107532501221
2020-01-11 04:48:13.678902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.98125
Z variance train             0.0036107483
KL Divergence                56.445545
KL Loss                      5.6445546
QF Loss                      84.473854
VF Loss                      50.334568
Policy Loss                  -1033.9373
Q Predictions Mean           1027.6285
Q Predictions Std            353.97778
Q Predictions Max            1327.043
Q Predictions Min            2.252081
V Predictions Mean           1035.3677
V Predictions Std            356.18045
V Predictions Max            1348.3873
V Predictions Min            1.9757959
Log Pis Mean                 0.19270265
Log Pis Std                  1.9492122
Log Pis Max                  8.899194
Log Pis Min                  -6.3998766
Policy mu Mean               0.4912827
Policy mu Std                0.844799
Policy mu Max                2.991579
Policy mu Min                -2.8717513
Policy log std Mean          -0.47858414
Policy log std Std           0.17210563
Policy log std Max           -0.013808429
Policy log std Min           -1.4193884
Z mean eval                  4.420892
Z variance eval              0.0022486243
total_rewards                [1066.43582781  859.04341378 1027.87427543  895.82641975  861.15369847
 1053.56056867  837.13212474 1021.40672645 1014.68335906  712.36907088]
total_rewards_mean           934.9485485029576
total_rewards_std            112.10399197494051
total_rewards_max            1066.4358278149928
total_rewards_min            712.369070877137
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               32.62471725419164
(Previous) Eval Time (s)     8.114808831829578
Sample Time (s)              22.761229456868023
Epoch Time (s)               63.50075554288924
Total Train Time (s)         17194.220573269762
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:18.363758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #274 | Epoch Duration: 64.68469572067261
2020-01-11 04:49:18.363930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #274 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16222134
Z variance train             0.0050117197
KL Divergence                11.941218
KL Loss                      1.1941218
QF Loss                      232.29861
VF Loss                      147.43698
Policy Loss                  -1245.7253
Q Predictions Mean           1243.8394
Q Predictions Std            391.283
Q Predictions Max            1564.5212
Q Predictions Min            7.477794
V Predictions Mean           1236.5825
V Predictions Std            389.24576
V Predictions Max            1554.986
V Predictions Min            4.665797
Log Pis Mean                 0.21052928
Log Pis Std                  2.3604739
Log Pis Max                  8.354305
Log Pis Min                  -5.060907
Policy mu Mean               0.19768268
Policy mu Std                0.9938855
Policy mu Max                2.5336463
Policy mu Min                -2.7568567
Policy log std Mean          -0.5058505
Policy log std Std           0.15708958
Policy log std Max           0.0383275
Policy log std Min           -1.2185836
Z mean eval                  4.062819
Z variance eval              0.004870828
total_rewards                [758.19845365 719.64865748 679.10849363 642.96516308 737.87834084
 691.09311279 586.56875839 782.17126247 596.16893525 727.17330929]
total_rewards_mean           692.0974486878855
total_rewards_std            62.84122633467224
total_rewards_max            782.17126246823
total_rewards_min            586.5687583948021
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               32.86905964789912
(Previous) Eval Time (s)     9.298424378968775
Sample Time (s)              23.10243594739586
Epoch Time (s)               65.26991997426376
Total Train Time (s)         17257.12566466164
Epoch                        275
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:21.274864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #275 | Epoch Duration: 62.91076898574829
2020-01-11 04:50:21.275144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #275 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.896192
Z variance train             0.0066305893
KL Divergence                51.575813
KL Loss                      5.1575813
QF Loss                      112.59457
VF Loss                      49.20971
Policy Loss                  -1048.7339
Q Predictions Mean           1045.0403
Q Predictions Std            377.28348
Q Predictions Max            1373.1259
Q Predictions Min            -0.61698425
V Predictions Mean           1053.0421
V Predictions Std            375.90768
V Predictions Max            1378.3743
V Predictions Min            0.6144781
Log Pis Mean                 0.10974939
Log Pis Std                  1.9102561
Log Pis Max                  8.42829
Log Pis Min                  -5.556095
Policy mu Mean               0.4382074
Policy mu Std                0.8658639
Policy mu Max                2.496763
Policy mu Min                -2.7399383
Policy log std Mean          -0.48293626
Policy log std Std           0.14740491
Policy log std Max           -0.12256175
Policy log std Min           -1.0715308
Z mean eval                  3.861238
Z variance eval              0.0034352448
total_rewards                [722.22244478 497.99632901 731.49797343 654.31241233 634.46681359
 449.73836755 583.55991571 543.21532389 509.01189144 551.30939799]
total_rewards_mean           587.7330869702162
total_rewards_std            90.54875170870088
total_rewards_max            731.4979734254
total_rewards_min            449.7383675511325
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               32.75485492590815
(Previous) Eval Time (s)     6.938950835261494
Sample Time (s)              22.4387890486978
Epoch Time (s)               62.13259480986744
Total Train Time (s)         17318.36149216676
Epoch                        276
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:22.513186 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #276 | Epoch Duration: 61.237804889678955
2020-01-11 04:51:22.513369 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.750517
Z variance train             0.0040990873
KL Divergence                51.196083
KL Loss                      5.1196084
QF Loss                      229.27554
VF Loss                      77.01401
Policy Loss                  -1045.6725
Q Predictions Mean           1045.8335
Q Predictions Std            347.09174
Q Predictions Max            1377.9397
Q Predictions Min            2.2758934
V Predictions Mean           1045.5199
V Predictions Std            346.63544
V Predictions Max            1390.8079
V Predictions Min            1.3301749
Log Pis Mean                 -0.13848841
Log Pis Std                  1.9490545
Log Pis Max                  8.504364
Log Pis Min                  -5.5030475
Policy mu Mean               0.34686288
Policy mu Std                0.85812175
Policy mu Max                2.7082684
Policy mu Min                -2.9292798
Policy log std Mean          -0.46001175
Policy log std Std           0.15759729
Policy log std Max           -0.11244719
Policy log std Min           -1.2690799
Z mean eval                  3.4185662
Z variance eval              0.003748861
total_rewards                [ 610.28260479  974.36261879 1087.41617798  936.83853398  943.06044581
  816.08547388 1104.39887925 1050.51877289  997.77139703  992.36013206]
total_rewards_mean           951.3095036467766
total_rewards_std            138.21776675271175
total_rewards_max            1104.3988792520067
total_rewards_min            610.2826047891405
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               32.51231800625101
(Previous) Eval Time (s)     6.043854807969183
Sample Time (s)              23.63374242419377
Epoch Time (s)               62.18991523841396
Total Train Time (s)         17382.82232304616
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:52:26.977056 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #277 | Epoch Duration: 64.46355056762695
2020-01-11 04:52:26.977242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #277 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.518277
Z variance train             0.0031719822
KL Divergence                46.593857
KL Loss                      4.6593857
QF Loss                      142.5845
VF Loss                      69.18761
Policy Loss                  -1010.94586
Q Predictions Mean           1010.6734
Q Predictions Std            324.24854
Q Predictions Max            1326.4701
Q Predictions Min            -12.509731
V Predictions Mean           1011.92554
V Predictions Std            323.96323
V Predictions Max            1332.4735
V Predictions Min            7.2264676
Log Pis Mean                 0.17554675
Log Pis Std                  1.912413
Log Pis Max                  6.8065615
Log Pis Min                  -6.714222
Policy mu Mean               0.38272694
Policy mu Std                0.92042196
Policy mu Max                3.4626312
Policy mu Min                -2.8044884
Policy log std Mean          -0.48353946
Policy log std Std           0.1670921
Policy log std Max           0.040228188
Policy log std Min           -1.2869077
Z mean eval                  3.0634978
Z variance eval              0.0050332816
total_rewards                [326.57473322 522.01795158 560.78918082 517.36160135 680.79053038
 701.92860989 555.17048228 688.86987039 531.69758688 641.35665522]
total_rewards_mean           572.6557202005991
total_rewards_std            107.2062296191504
total_rewards_max            701.9286098948941
total_rewards_min            326.57473321706084
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               32.69221623474732
(Previous) Eval Time (s)     8.317144321743399
Sample Time (s)              23.43553014891222
Epoch Time (s)               64.44489070540294
Total Train Time (s)         17445.050745709334
Epoch                        278
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:29.208648 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #278 | Epoch Duration: 62.231281042099
2020-01-11 04:53:29.208813 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #278 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2199154
Z variance train             0.0038061787
KL Divergence                40.78811
KL Loss                      4.078811
QF Loss                      269.94556
VF Loss                      72.563225
Policy Loss                  -972.3438
Q Predictions Mean           970.6738
Q Predictions Std            293.79797
Q Predictions Max            1272.0997
Q Predictions Min            0.011002749
V Predictions Mean           974.9608
V Predictions Std            291.83047
V Predictions Max            1281.2793
V Predictions Min            3.6832845
Log Pis Mean                 -0.11449843
Log Pis Std                  1.7721778
Log Pis Max                  5.788716
Log Pis Min                  -6.1524744
Policy mu Mean               0.32095942
Policy mu Std                0.888617
Policy mu Max                3.172911
Policy mu Min                -3.0464396
Policy log std Mean          -0.47640157
Policy log std Std           0.15311867
Policy log std Max           0.005856231
Policy log std Min           -1.2513667
Z mean eval                  3.17883
Z variance eval              0.0072500603
total_rewards                [541.6880011  967.24025075 750.61896786 519.7695916  853.65964538
 607.55095697 819.09187728 874.23128246 987.86491702 600.06614439]
total_rewards_mean           752.1781634812379
total_rewards_std            165.4842065992333
total_rewards_max            987.8649170192444
total_rewards_min            519.7695916024787
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               32.5144346090965
(Previous) Eval Time (s)     6.103172491770238
Sample Time (s)              21.787771612405777
Epoch Time (s)               60.40537871327251
Total Train Time (s)         17506.520458713174
Epoch                        279
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:30.681647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #279 | Epoch Duration: 61.47269797325134
2020-01-11 04:54:30.681832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1930447
Z variance train             0.007495639
KL Divergence                41.022453
KL Loss                      4.1022453
QF Loss                      232.41496
VF Loss                      112.258804
Policy Loss                  -977.12994
Q Predictions Mean           977.5083
Q Predictions Std            320.30585
Q Predictions Max            1333.1875
Q Predictions Min            7.7383714
V Predictions Mean           974.08417
V Predictions Std            317.8648
V Predictions Max            1320.5067
V Predictions Min            5.522905
Log Pis Mean                 -0.040350884
Log Pis Std                  1.9762573
Log Pis Max                  6.4503083
Log Pis Min                  -6.885211
Policy mu Mean               0.311415
Policy mu Std                0.93204623
Policy mu Max                2.3923082
Policy mu Min                -2.7816577
Policy log std Mean          -0.48530862
Policy log std Std           0.15565278
Policy log std Max           -0.10369735
Policy log std Min           -1.2099383
Z mean eval                  3.2350051
Z variance eval              0.0028060523
total_rewards                [ 518.00411234 1348.56428403  626.46078709  520.99547     522.64703165
 1035.29132295  902.29512664 1106.69143246  952.9478089  1138.8229952 ]
total_rewards_mean           867.2720371257561
total_rewards_std            286.03377920641566
total_rewards_max            1348.5642840338858
total_rewards_min            518.0041123444134
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               32.46467844303697
(Previous) Eval Time (s)     7.170147137250751
Sample Time (s)              22.331928212661296
Epoch Time (s)               61.96675379294902
Total Train Time (s)         17570.159696748015
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:34.324526 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #280 | Epoch Duration: 63.64255213737488
2020-01-11 04:55:34.324705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2299361
Z variance train             0.0028214415
KL Divergence                42.390015
KL Loss                      4.2390018
QF Loss                      148.2922
VF Loss                      218.54529
Policy Loss                  -1039.3645
Q Predictions Mean           1037.177
Q Predictions Std            302.0904
Q Predictions Max            1316.5643
Q Predictions Min            -12.194763
V Predictions Mean           1045.6287
V Predictions Std            295.06052
V Predictions Max            1323.746
V Predictions Min            -4.3197184
Log Pis Mean                 0.06043987
Log Pis Std                  2.0073307
Log Pis Max                  8.401577
Log Pis Min                  -5.272653
Policy mu Mean               0.28970662
Policy mu Std                0.93066597
Policy mu Max                2.6314542
Policy mu Min                -3.4811878
Policy log std Mean          -0.4941635
Policy log std Std           0.16219102
Policy log std Max           -0.14236617
Policy log std Min           -1.2881969
Z mean eval                  3.1951938
Z variance eval              0.0020664888
total_rewards                [ 864.43202581 1196.41238628  294.10924188 1128.34076082  615.40323306
  964.66126799  776.94905494  947.46367113  951.47829945 1034.82936888]
total_rewards_mean           877.4079310208972
total_rewards_std            250.3326167442097
total_rewards_max            1196.4123862756003
total_rewards_min            294.1092418785359
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               33.050783338956535
(Previous) Eval Time (s)     8.845639233943075
Sample Time (s)              23.138509639073163
Epoch Time (s)               65.03493221197277
Total Train Time (s)         17635.64056396857
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:56:39.808206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #281 | Epoch Duration: 65.4833574295044
2020-01-11 04:56:39.808390 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1981304
Z variance train             0.0019578305
KL Divergence                41.805832
KL Loss                      4.1805835
QF Loss                      200.05164
VF Loss                      79.82855
Policy Loss                  -1019.957
Q Predictions Mean           1017.34784
Q Predictions Std            357.72906
Q Predictions Max            1337.4193
Q Predictions Min            4.998329
V Predictions Mean           1016.912
V Predictions Std            357.9433
V Predictions Max            1346.3573
V Predictions Min            3.8598733
Log Pis Mean                 0.29940107
Log Pis Std                  2.0565789
Log Pis Max                  9.554629
Log Pis Min                  -4.1566067
Policy mu Mean               0.32709375
Policy mu Std                0.96086246
Policy mu Max                2.7183893
Policy mu Min                -3.4294128
Policy log std Mean          -0.44834104
Policy log std Std           0.1616789
Policy log std Max           -0.12232302
Policy log std Min           -1.4287957
Z mean eval                  3.0812612
Z variance eval              0.0025970112
total_rewards                [ 963.6170861   564.68404182  314.9961379   938.09814822 1024.7749246
  725.72659825  933.86113703  310.89372058  846.21781194  795.09097875]
total_rewards_mean           741.7960585175869
total_rewards_std            248.57820780154537
total_rewards_max            1024.774924596684
total_rewards_min            310.89372057639133
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               32.91303488286212
(Previous) Eval Time (s)     9.293719734996557
Sample Time (s)              22.522098049521446
Epoch Time (s)               64.72885266738012
Total Train Time (s)         17699.750133284833
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:43.921193 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #282 | Epoch Duration: 64.1126639842987
2020-01-11 04:57:43.921378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.117718
Z variance train             0.0020446484
KL Divergence                40.947586
KL Loss                      4.0947585
QF Loss                      130.26682
VF Loss                      48.343567
Policy Loss                  -1017.3876
Q Predictions Mean           1015.9192
Q Predictions Std            343.76178
Q Predictions Max            1304.103
Q Predictions Min            -2.1293101
V Predictions Mean           1018.4636
V Predictions Std            342.29333
V Predictions Max            1315.7478
V Predictions Min            2.7501667
Log Pis Mean                 0.30803522
Log Pis Std                  2.1454058
Log Pis Max                  8.065975
Log Pis Min                  -5.6080427
Policy mu Mean               0.08392199
Policy mu Std                0.9890987
Policy mu Max                2.5402496
Policy mu Min                -3.0998275
Policy log std Mean          -0.473287
Policy log std Std           0.16006404
Policy log std Max           -0.11826876
Policy log std Min           -1.2679936
Z mean eval                  2.9558468
Z variance eval              0.005155415
total_rewards                [ 937.0484531   891.00274816  984.74728519  339.28894284  347.09020287
  323.87708483 1880.47021443 1087.23893485  359.13118248  379.54588387]
total_rewards_mean           752.9440932625146
total_rewards_std            480.02050116100395
total_rewards_max            1880.4702144342036
total_rewards_min            323.877084831833
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               32.51688719494268
(Previous) Eval Time (s)     8.677185907959938
Sample Time (s)              21.02155816135928
Epoch Time (s)               62.2156312642619
Total Train Time (s)         17762.676457128488
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:46.850854 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #283 | Epoch Duration: 62.929319858551025
2020-01-11 04:58:46.851049 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0488248
Z variance train             0.003221043
KL Divergence                39.08876
KL Loss                      3.9088762
QF Loss                      165.57445
VF Loss                      81.65967
Policy Loss                  -1059.4481
Q Predictions Mean           1056.0981
Q Predictions Std            307.88937
Q Predictions Max            1306.8708
Q Predictions Min            4.7767525
V Predictions Mean           1058.9011
V Predictions Std            306.47638
V Predictions Max            1308.8193
V Predictions Min            -5.910803
Log Pis Mean                 -0.06618506
Log Pis Std                  1.6660029
Log Pis Max                  5.509231
Log Pis Min                  -5.283306
Policy mu Mean               0.30608952
Policy mu Std                0.8659823
Policy mu Max                2.3756015
Policy mu Min                -2.8273335
Policy log std Mean          -0.41902038
Policy log std Std           0.1565107
Policy log std Max           0.047075838
Policy log std Min           -1.334385
Z mean eval                  2.8800836
Z variance eval              0.0044417046
total_rewards                [ 415.74256723  343.12653674  813.99700582  354.32743276  738.62250302
  398.1354021  1007.40816741  779.27453544  910.85926867  352.03381362]
total_rewards_mean           611.3527232820311
total_rewards_std            249.1992507734989
total_rewards_max            1007.4081674115895
total_rewards_min            343.1265367386404
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               32.51055541075766
(Previous) Eval Time (s)     9.390579723287374
Sample Time (s)              19.95154942991212
Epoch Time (s)               61.852684563957155
Total Train Time (s)         17822.33329142118
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:59:46.511514 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #284 | Epoch Duration: 59.66030526161194
2020-01-11 04:59:46.511731 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9789653
Z variance train             0.0033817687
KL Divergence                38.04664
KL Loss                      3.804664
QF Loss                      177.14743
VF Loss                      36.149586
Policy Loss                  -1056.377
Q Predictions Mean           1056.912
Q Predictions Std            301.09488
Q Predictions Max            1305.5074
Q Predictions Min            1.724926
V Predictions Mean           1057.9326
V Predictions Std            294.25424
V Predictions Max            1305.0894
V Predictions Min            -3.281066
Log Pis Mean                 0.1234802
Log Pis Std                  1.8624774
Log Pis Max                  11.211128
Log Pis Min                  -4.338257
Policy mu Mean               0.21796133
Policy mu Std                0.9406051
Policy mu Max                1.9509678
Policy mu Min                -3.2126582
Policy log std Mean          -0.45428053
Policy log std Std           0.16543706
Policy log std Max           -0.03902924
Policy log std Min           -1.639044
Z mean eval                  2.9243636
Z variance eval              0.0015398514
total_rewards                [1260.55267938 1253.5835365  1358.02267247  382.01380528  346.03332641
  537.06058161  732.90114483  389.70835655 1121.65047453  350.1839988 ]
total_rewards_mean           773.1710576366684
total_rewards_std            406.27681028798855
total_rewards_max            1358.0226724702688
total_rewards_min            346.03332641332884
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               32.728631182573736
(Previous) Eval Time (s)     7.197873599361628
Sample Time (s)              22.0398969091475
Epoch Time (s)               61.966401691082865
Total Train Time (s)         17885.834753729403
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:50.015999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #285 | Epoch Duration: 63.50412321090698
2020-01-11 05:00:50.016175 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9231918
Z variance train             0.0015390589
KL Divergence                37.965675
KL Loss                      3.7965677
QF Loss                      127.86671
VF Loss                      53.515827
Policy Loss                  -1018.7567
Q Predictions Mean           1019.4637
Q Predictions Std            332.5695
Q Predictions Max            1293.6237
Q Predictions Min            6.8888364
V Predictions Mean           1020.682
V Predictions Std            332.5381
V Predictions Max            1301.1953
V Predictions Min            6.2087436
Log Pis Mean                 -0.30487502
Log Pis Std                  1.7746329
Log Pis Max                  7.030822
Log Pis Min                  -4.9947596
Policy mu Mean               0.19324751
Policy mu Std                0.86845267
Policy mu Max                2.46042
Policy mu Min                -3.219438
Policy log std Mean          -0.42857575
Policy log std Std           0.15564105
Policy log std Max           0.0035963655
Policy log std Min           -1.0451224
Z mean eval                  2.7728393
Z variance eval              0.0065728626
total_rewards                [ 928.16708266 1167.85497223 1102.36778228 1114.5155612  1180.7642142
 1246.2429487   974.38293211 1549.00301529 1254.21213489 1222.37724711]
total_rewards_mean           1173.9887890675132
total_rewards_std            162.3744236485065
total_rewards_max            1549.0030152852955
total_rewards_min            928.1670826594857
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               32.59127787081525
(Previous) Eval Time (s)     8.735267660114914
Sample Time (s)              21.637046818621457
Epoch Time (s)               62.96359234955162
Total Train Time (s)         17951.991747142747
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:01:56.177654 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #286 | Epoch Duration: 66.16133141517639
2020-01-11 05:01:56.177882 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6748302
Z variance train             0.007037456
KL Divergence                31.083092
KL Loss                      3.1083093
QF Loss                      318.67712
VF Loss                      70.69132
Policy Loss                  -984.1293
Q Predictions Mean           981.8354
Q Predictions Std            301.86624
Q Predictions Max            1226.813
Q Predictions Min            -1.5223453
V Predictions Mean           986.0426
V Predictions Std            296.39584
V Predictions Max            1224.4506
V Predictions Min            -3.78606
Log Pis Mean                 -0.15431508
Log Pis Std                  2.0339463
Log Pis Max                  10.8532715
Log Pis Min                  -5.4177446
Policy mu Mean               0.0018745326
Policy mu Std                0.9205156
Policy mu Max                2.807047
Policy mu Min                -3.727981
Policy log std Mean          -0.44924128
Policy log std Std           0.16136605
Policy log std Max           -0.11554672
Policy log std Min           -1.0595243
Z mean eval                  2.507356
Z variance eval              0.013313365
total_rewards                [ 958.77049789 1057.49669523 1158.91995246  992.5113601  1262.87717764
  976.17308602 1128.18618208 1215.04738986 1151.46271326 1846.77453836]
total_rewards_mean           1174.8219592909047
total_rewards_std            244.33736516587356
total_rewards_max            1846.7745383587983
total_rewards_min            958.7704978871599
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               32.869366283062845
(Previous) Eval Time (s)     11.932672528084368
Sample Time (s)              22.636696332134306
Epoch Time (s)               67.43873514328152
Total Train Time (s)         18019.48043584125
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:03.669222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #287 | Epoch Duration: 67.49110984802246
2020-01-11 05:03:03.669528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #287 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5267885
Z variance train             0.011193143
KL Divergence                27.916014
KL Loss                      2.7916014
QF Loss                      347.51132
VF Loss                      106.96687
Policy Loss                  -917.78094
Q Predictions Mean           920.69824
Q Predictions Std            334.4181
Q Predictions Max            1201.0238
Q Predictions Min            -8.297804
V Predictions Mean           914.29425
V Predictions Std            334.9682
V Predictions Max            1194.1538
V Predictions Min            -2.8305426
Log Pis Mean                 -0.3200507
Log Pis Std                  1.9216502
Log Pis Max                  8.910229
Log Pis Min                  -4.6172523
Policy mu Mean               0.037169088
Policy mu Std                0.8695447
Policy mu Max                1.8856856
Policy mu Min                -3.5325582
Policy log std Mean          -0.40344533
Policy log std Std           0.14968304
Policy log std Max           -0.07543704
Policy log std Min           -1.0369707
Z mean eval                  2.5843863
Z variance eval              0.015958045
total_rewards                [1332.70496286  957.37154011  936.67831739  913.04886325  846.820008
 1328.75871288  844.88529212 1268.0550009  1058.00183254  994.02980562]
total_rewards_mean           1048.0354335658953
total_rewards_std            182.17195117282938
total_rewards_max            1332.7049628565294
total_rewards_min            844.885292116184
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               32.425904023926705
(Previous) Eval Time (s)     11.984702843707055
Sample Time (s)              23.6449179276824
Epoch Time (s)               68.05552479531616
Total Train Time (s)         18085.978426929563
Epoch                        288
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:10.169105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #288 | Epoch Duration: 66.49940013885498
2020-01-11 05:04:10.169274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6313996
Z variance train             0.015818935
KL Divergence                29.696926
KL Loss                      2.9696927
QF Loss                      259.67087
VF Loss                      120.71386
Policy Loss                  -959.2365
Q Predictions Mean           956.44226
Q Predictions Std            361.02902
Q Predictions Max            1263.4753
Q Predictions Min            0.27047306
V Predictions Mean           951.5657
V Predictions Std            359.33432
V Predictions Max            1252.5591
V Predictions Min            -0.65869576
Log Pis Mean                 -0.19435242
Log Pis Std                  1.9600413
Log Pis Max                  6.965539
Log Pis Min                  -5.373967
Policy mu Mean               -0.02766358
Policy mu Std                0.90244704
Policy mu Max                2.6204584
Policy mu Min                -2.9053924
Policy log std Mean          -0.43401513
Policy log std Std           0.15346704
Policy log std Max           -0.087090075
Policy log std Min           -1.089804
Z mean eval                  2.5942345
Z variance eval              0.013159273
total_rewards                [1084.69845187 1284.92610799 1757.0532594  1066.25091662 1953.92731479
 1198.74220048  993.04629247 1204.36875879 1302.26337411 1187.70459564]
total_rewards_mean           1303.298127215223
total_rewards_std            293.9157850252682
total_rewards_max            1953.9273147853585
total_rewards_min            993.0462924739244
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               32.338205753825605
(Previous) Eval Time (s)     10.428228789009154
Sample Time (s)              23.875937876291573
Epoch Time (s)               66.64237241912633
Total Train Time (s)         18154.632354329806
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:05:18.826892 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #289 | Epoch Duration: 68.6574776172638
2020-01-11 05:05:18.827104 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.610667
Z variance train             0.012565553
KL Divergence                29.014988
KL Loss                      2.9014988
QF Loss                      220.67719
VF Loss                      40.988255
Policy Loss                  -995.5723
Q Predictions Mean           992.83325
Q Predictions Std            339.13995
Q Predictions Max            1265.3057
Q Predictions Min            -1.0001707
V Predictions Mean           998.0226
V Predictions Std            339.29697
V Predictions Max            1264.3292
V Predictions Min            0.009510875
Log Pis Mean                 -0.4689691
Log Pis Std                  1.9716253
Log Pis Max                  11.719895
Log Pis Min                  -5.140933
Policy mu Mean               -0.012737371
Policy mu Std                0.8593742
Policy mu Max                2.462491
Policy mu Min                -3.6303883
Policy log std Mean          -0.3992219
Policy log std Std           0.13381374
Policy log std Max           -0.099788636
Policy log std Min           -1.0214427
Z mean eval                  2.5549893
Z variance eval              0.011832965
total_rewards                [1087.93254965  922.2122953  1023.66725909  916.95127101 1357.46150429
 1013.11676011  911.12187484 1038.1151845   870.43155326 1238.56623508]
total_rewards_mean           1037.957648713625
total_rewards_std            147.59307424454914
total_rewards_max            1357.461504290256
total_rewards_min            870.4315532617697
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               32.481805575080216
(Previous) Eval Time (s)     12.443002902902663
Sample Time (s)              23.740130546037108
Epoch Time (s)               68.66493902401999
Total Train Time (s)         18220.123590415344
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:24.322077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #290 | Epoch Duration: 65.49460506439209
2020-01-11 05:06:24.322431 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5489962
Z variance train             0.011944316
KL Divergence                28.702572
KL Loss                      2.8702571
QF Loss                      804.7157
VF Loss                      58.159447
Policy Loss                  -995.3643
Q Predictions Mean           996.70105
Q Predictions Std            336.9461
Q Predictions Max            1276.466
Q Predictions Min            4.9037066
V Predictions Mean           997.6994
V Predictions Std            339.81516
V Predictions Max            1283.7031
V Predictions Min            2.2821975
Log Pis Mean                 -0.41138148
Log Pis Std                  1.9739196
Log Pis Max                  7.7628374
Log Pis Min                  -4.8262935
Policy mu Mean               -0.010749782
Policy mu Std                0.8809263
Policy mu Max                2.19321
Policy mu Min                -3.0258298
Policy log std Mean          -0.41792282
Policy log std Std           0.14757954
Policy log std Max           -0.13325053
Policy log std Min           -1.0000085
Z mean eval                  2.2646897
Z variance eval              0.013663283
total_rewards                [ 921.70142989 1202.26542168 1003.61138595  988.20477609  999.85475047
 1015.60755374  826.37844851  836.48721472 1006.97196263  999.16820321]
total_rewards_mean           980.0251146885719
total_rewards_std            100.18880523433127
total_rewards_max            1202.265421678668
total_rewards_min            826.3784485131315
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               33.10695054894313
(Previous) Eval Time (s)     9.272437285166234
Sample Time (s)              22.3191363918595
Epoch Time (s)               64.69852422596887
Total Train Time (s)         18284.65528974915
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:07:28.856627 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #291 | Epoch Duration: 64.5339424610138
2020-01-11 05:07:28.856889 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.267451
Z variance train             0.014100017
KL Divergence                24.177837
KL Loss                      2.4177837
QF Loss                      201.15332
VF Loss                      30.700163
Policy Loss                  -879.8337
Q Predictions Mean           878.6481
Q Predictions Std            320.92343
Q Predictions Max            1175.264
Q Predictions Min            2.9754167
V Predictions Mean           879.68945
V Predictions Std            321.4622
V Predictions Max            1166.8171
V Predictions Min            -6.293554
Log Pis Mean                 -0.5670205
Log Pis Std                  1.7651278
Log Pis Max                  7.5455403
Log Pis Min                  -4.7470193
Policy mu Mean               -0.01439732
Policy mu Std                0.8370791
Policy mu Max                2.630109
Policy mu Min                -2.38027
Policy log std Mean          -0.3935512
Policy log std Std           0.14008668
Policy log std Max           -0.12828924
Policy log std Min           -0.910447
Z mean eval                  2.2935047
Z variance eval              0.013949578
total_rewards                [ 936.5072651   919.02940577 1006.08968511 1168.09826415 1077.35560976
  844.66879673  915.59517849 1152.94930994  853.73088676  969.14848908]
total_rewards_mean           984.3172890887734
total_rewards_std            109.26939579095047
total_rewards_max            1168.0982641519415
total_rewards_min            844.6687967307993
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               32.6501916279085
(Previous) Eval Time (s)     9.107493318617344
Sample Time (s)              22.535429851617664
Epoch Time (s)               64.2931147981435
Total Train Time (s)         18349.61210943805
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:33.816007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #292 | Epoch Duration: 64.95887064933777
2020-01-11 05:08:33.816207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #292 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4082055
Z variance train             0.01205233
KL Divergence                26.82579
KL Loss                      2.682579
QF Loss                      151.02197
VF Loss                      62.720722
Policy Loss                  -1003.0908
Q Predictions Mean           1000.65186
Q Predictions Std            362.92673
Q Predictions Max            1304.2666
Q Predictions Min            0.08562261
V Predictions Mean           998.85986
V Predictions Std            361.55713
V Predictions Max            1305.3512
V Predictions Min            3.5964637
Log Pis Mean                 -0.41938296
Log Pis Std                  1.8095385
Log Pis Max                  5.756171
Log Pis Min                  -7.262374
Policy mu Mean               0.021694789
Policy mu Std                0.8445509
Policy mu Max                2.0719042
Policy mu Min                -2.8568342
Policy log std Mean          -0.4127023
Policy log std Std           0.15734755
Policy log std Max           -0.06530887
Policy log std Min           -1.1411774
Z mean eval                  2.404141
Z variance eval              0.012506561
total_rewards                [ 244.33689057 1152.80735686  245.52197242 1105.92265441  956.289167
  909.9097058   996.38555257  992.77328718 1182.4265514  1127.94878815]
total_rewards_mean           891.4321926358537
total_rewards_std            334.1715674334102
total_rewards_max            1182.426551401379
total_rewards_min            244.33689056742136
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               32.23664979962632
(Previous) Eval Time (s)     9.772936031222343
Sample Time (s)              22.33948668697849
Epoch Time (s)               64.34907251782715
Total Train Time (s)         18412.34035130171
Epoch                        293
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:36.547337 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #293 | Epoch Duration: 62.73100566864014
2020-01-11 05:09:36.547540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4031997
Z variance train             0.012522982
KL Divergence                25.945044
KL Loss                      2.5945044
QF Loss                      240.52835
VF Loss                      84.32837
Policy Loss                  -1015.40784
Q Predictions Mean           1011.8403
Q Predictions Std            371.86792
Q Predictions Max            1347.3582
Q Predictions Min            -3.0313513
V Predictions Mean           1016.021
V Predictions Std            373.39856
V Predictions Max            1344.0828
V Predictions Min            -2.034576
Log Pis Mean                 -0.25240058
Log Pis Std                  2.1083455
Log Pis Max                  7.690113
Log Pis Min                  -6.115632
Policy mu Mean               0.021854976
Policy mu Std                0.8924963
Policy mu Max                2.694589
Policy mu Min                -2.9097466
Policy log std Mean          -0.4136562
Policy log std Std           0.14510259
Policy log std Max           -0.120566696
Policy log std Min           -1.0067581
Z mean eval                  2.3464575
Z variance eval              0.020353924
total_rewards                [1012.03494985  844.72447502  889.58138475  227.16661406  905.42178687
  928.14431679  260.04070357  925.54897891  209.94240492  913.82198523]
total_rewards_mean           711.6427599981515
total_rewards_std            316.39037743869204
total_rewards_max            1012.0349498536583
total_rewards_min            209.94240492423285
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               32.72031470015645
(Previous) Eval Time (s)     8.154519556090236
Sample Time (s)              23.95807882025838
Epoch Time (s)               64.83291307650506
Total Train Time (s)         18475.54540455155
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:39.754283 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #294 | Epoch Duration: 63.206626176834106
2020-01-11 05:10:39.754411 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #294 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3465862
Z variance train             0.020327192
KL Divergence                24.661663
KL Loss                      2.4661663
QF Loss                      109.593994
VF Loss                      135.8438
Policy Loss                  -1076.3639
Q Predictions Mean           1073.9333
Q Predictions Std            311.46365
Q Predictions Max            1367.3378
Q Predictions Min            3.7605102
V Predictions Mean           1077.2981
V Predictions Std            307.88336
V Predictions Max            1370.7523
V Predictions Min            0.7804406
Log Pis Mean                 -0.27821943
Log Pis Std                  2.055336
Log Pis Max                  8.715641
Log Pis Min                  -5.327854
Policy mu Mean               -0.05623595
Policy mu Std                0.9122193
Policy mu Max                2.3619761
Policy mu Min                -3.2583027
Policy log std Mean          -0.40863934
Policy log std Std           0.15089864
Policy log std Max           -0.019966379
Policy log std Min           -1.5995083
Z mean eval                  2.2978902
Z variance eval              0.018505564
total_rewards                [975.32445647 864.71391562 868.52764983 960.10119297 860.47246647
 981.44425404 813.0383947  795.62812079 743.5595324  857.1192419 ]
total_rewards_mean           871.9929225179139
total_rewards_std            75.26045544009611
total_rewards_max            981.4442540386062
total_rewards_min            743.5595323990792
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               32.2860362958163
(Previous) Eval Time (s)     6.527849034871906
Sample Time (s)              21.573840751312673
Epoch Time (s)               60.38772608200088
Total Train Time (s)         18537.781211432535
Epoch                        295
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:41.994238 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #295 | Epoch Duration: 62.239701986312866
2020-01-11 05:11:41.994438 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2964275
Z variance train             0.01850868
KL Divergence                24.153942
KL Loss                      2.4153943
QF Loss                      498.28073
VF Loss                      66.17276
Policy Loss                  -989.89734
Q Predictions Mean           986.5068
Q Predictions Std            373.00415
Q Predictions Max            1343.6702
Q Predictions Min            3.68849
V Predictions Mean           989.2384
V Predictions Std            372.8489
V Predictions Max            1354.7354
V Predictions Min            -3.9093318
Log Pis Mean                 -0.06221246
Log Pis Std                  1.9448756
Log Pis Max                  6.632607
Log Pis Min                  -4.505627
Policy mu Mean               0.119942844
Policy mu Std                0.938491
Policy mu Max                2.8608375
Policy mu Min                -2.6089509
Policy log std Mean          -0.41504225
Policy log std Std           0.15603274
Policy log std Max           0.10780758
Policy log std Min           -1.4614342
Z mean eval                  2.2399201
Z variance eval              0.02415345
total_rewards                [ 796.06651784  759.70106575  658.80033296  690.72145772  741.55918517
  726.44176581  681.44914756  682.80173504  712.56155954 1006.39442393]
total_rewards_mean           745.6497191309412
total_rewards_std            95.30955436572279
total_rewards_max            1006.3944239318989
total_rewards_min            658.8003329563251
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               32.08231252990663
(Previous) Eval Time (s)     8.379509577061981
Sample Time (s)              23.811975526157767
Epoch Time (s)               64.27379763312638
Total Train Time (s)         18600.649255814962
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:44.865787 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #296 | Epoch Duration: 62.87120342254639
2020-01-11 05:12:44.865983 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2389436
Z variance train             0.024306465
KL Divergence                22.785381
KL Loss                      2.2785382
QF Loss                      258.12567
VF Loss                      59.551617
Policy Loss                  -1019.6386
Q Predictions Mean           1015.1391
Q Predictions Std            326.98746
Q Predictions Max            1331.0547
Q Predictions Min            0.37745872
V Predictions Mean           1016.4069
V Predictions Std            326.36554
V Predictions Max            1342.2067
V Predictions Min            4.4526873
Log Pis Mean                 0.015162993
Log Pis Std                  2.092545
Log Pis Max                  8.182384
Log Pis Min                  -3.9565248
Policy mu Mean               0.1832313
Policy mu Std                0.9397362
Policy mu Max                2.6580122
Policy mu Min                -2.6803281
Policy log std Mean          -0.42748007
Policy log std Std           0.13646598
Policy log std Max           0.053819984
Policy log std Min           -1.1793581
Z mean eval                  2.1612742
Z variance eval              0.03949279
total_rewards                [1006.72670899  696.9075772   730.09644497  690.59667593  708.83438455
  675.11209091  654.11769488  695.04733784  713.61727873  701.3138255 ]
total_rewards_mean           727.2370019491423
total_rewards_std            95.22648707625453
total_rewards_max            1006.7267089876855
total_rewards_min            654.1176948819609
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               32.7558073583059
(Previous) Eval Time (s)     6.976593122817576
Sample Time (s)              23.268352398183197
Epoch Time (s)               63.000752879306674
Total Train Time (s)         18663.34899458615
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:13:47.569041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #297 | Epoch Duration: 62.702913761138916
2020-01-11 05:13:47.569227 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #297 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603534
Z variance train             0.039553586
KL Divergence                21.341
KL Loss                      2.1341
QF Loss                      252.16711
VF Loss                      71.37209
Policy Loss                  -1015.93066
Q Predictions Mean           1014.5918
Q Predictions Std            346.06458
Q Predictions Max            1358.2019
Q Predictions Min            1.5791057
V Predictions Mean           1017.24475
V Predictions Std            347.10858
V Predictions Max            1359.0793
V Predictions Min            1.6225164
Log Pis Mean                 -0.07672472
Log Pis Std                  2.0602283
Log Pis Max                  9.2367935
Log Pis Min                  -5.2078156
Policy mu Mean               0.10615656
Policy mu Std                0.9271644
Policy mu Max                2.634233
Policy mu Min                -2.9972563
Policy log std Mean          -0.41981778
Policy log std Std           0.1442334
Policy log std Max           -0.14925338
Policy log std Min           -0.943693
Z mean eval                  2.191613
Z variance eval              0.020174628
total_rewards                [799.49080966 755.96645329 880.70434461 860.43368444 813.72888964
 782.21918982 835.87946043 729.40718364 770.18051976 676.24015201]
total_rewards_mean           790.4250687301119
total_rewards_std            58.45413867042743
total_rewards_max            880.7043446079488
total_rewards_min            676.2401520057755
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               32.93324295524508
(Previous) Eval Time (s)     6.678428725339472
Sample Time (s)              23.642157705500722
Epoch Time (s)               63.25382938608527
Total Train Time (s)         18727.059000554495
Epoch                        298
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:51.282686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #298 | Epoch Duration: 63.713310956954956
2020-01-11 05:14:51.282901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #298 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.189106
Z variance train             0.020213952
KL Divergence                22.298847
KL Loss                      2.2298849
QF Loss                      210.58228
VF Loss                      46.028984
Policy Loss                  -987.109
Q Predictions Mean           985.63074
Q Predictions Std            387.71478
Q Predictions Max            1374.4026
Q Predictions Min            -1.4195633
V Predictions Mean           989.98376
V Predictions Std            388.62238
V Predictions Max            1380.8984
V Predictions Min            1.2174655
Log Pis Mean                 -0.18154398
Log Pis Std                  2.0668406
Log Pis Max                  8.6581745
Log Pis Min                  -4.697648
Policy mu Mean               0.15459812
Policy mu Std                0.9289997
Policy mu Max                2.5907092
Policy mu Min                -2.9164665
Policy log std Mean          -0.4182057
Policy log std Std           0.14895752
Policy log std Max           -0.1035483
Policy log std Min           -1.405204
Z mean eval                  2.173111
Z variance eval              0.015572032
total_rewards                [692.06986831 664.7588514  787.17041298 731.27929781 683.56983056
 629.62227139 667.00238153 696.46328827 733.17254182 585.74277811]
total_rewards_mean           687.0851522176395
total_rewards_std            53.56624363655592
total_rewards_max            787.1704129761637
total_rewards_min            585.7427781101538
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               32.706282613798976
(Previous) Eval Time (s)     7.137537057045847
Sample Time (s)              23.165383752435446
Epoch Time (s)               63.00920342328027
Total Train Time (s)         18787.489416672383
Epoch                        299
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:51.716400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #299 | Epoch Duration: 60.43333840370178
2020-01-11 05:15:51.716586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #299 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1697822
Z variance train             0.015579224
KL Divergence                22.612019
KL Loss                      2.2612019
QF Loss                      142.69263
VF Loss                      93.193344
Policy Loss                  -1037.7305
Q Predictions Mean           1037.3754
Q Predictions Std            348.46555
Q Predictions Max            1386.2379
Q Predictions Min            0.4146137
V Predictions Mean           1038.113
V Predictions Std            347.96286
V Predictions Max            1387.2264
V Predictions Min            1.3601838
Log Pis Mean                 0.16941488
Log Pis Std                  2.0056853
Log Pis Max                  7.35583
Log Pis Min                  -5.1005425
Policy mu Mean               0.28545037
Policy mu Std                0.9352441
Policy mu Max                2.846672
Policy mu Min                -2.589038
Policy log std Mean          -0.46186534
Policy log std Std           0.15066628
Policy log std Max           -0.13395019
Policy log std Min           -1.2306855
Z mean eval                  2.1390865
Z variance eval              0.012766844
total_rewards                [829.37678015 772.50721723 758.11940671 710.98212402 721.16533526
 829.41304225 799.25634293 800.97776579 655.44665567 780.49996898]
total_rewards_mean           765.7744638999368
total_rewards_std            52.85887104202836
total_rewards_max            829.4130422538177
total_rewards_min            655.446655670975
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               33.04763901280239
(Previous) Eval Time (s)     4.561336940154433
Sample Time (s)              22.870284335222095
Epoch Time (s)               60.47926028817892
Total Train Time (s)         18850.08259785315
Epoch                        300
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:54.312817 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #300 | Epoch Duration: 62.59609341621399
2020-01-11 05:16:54.312999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1390965
Z variance train             0.012785727
KL Divergence                22.530758
KL Loss                      2.2530758
QF Loss                      150.92438
VF Loss                      42.779945
Policy Loss                  -978.2889
Q Predictions Mean           974.63446
Q Predictions Std            388.74927
Q Predictions Max            1357.4926
Q Predictions Min            -5.0904465
V Predictions Mean           977.33026
V Predictions Std            389.19672
V Predictions Max            1376.5409
V Predictions Min            3.1377692
Log Pis Mean                 -0.18227737
Log Pis Std                  1.938218
Log Pis Max                  6.677473
Log Pis Min                  -4.339033
Policy mu Mean               0.20230253
Policy mu Std                0.8984362
Policy mu Max                2.7576823
Policy mu Min                -2.6033165
Policy log std Mean          -0.43649164
Policy log std Std           0.14213441
Policy log std Max           -0.08141188
Policy log std Min           -1.0091399
Z mean eval                  2.1587977
Z variance eval              0.019764934
total_rewards                [1172.71912895  869.99671692  917.64851856  741.02674776  891.56651433
  672.97873044  849.78375155  791.80108563  807.49070121  677.19993948]
total_rewards_mean           839.2211834833967
total_rewards_std            137.0968761780372
total_rewards_max            1172.719128953902
total_rewards_min            672.9787304401435
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               32.237820284906775
(Previous) Eval Time (s)     6.677820383105427
Sample Time (s)              23.41437038127333
Epoch Time (s)               62.33001104928553
Total Train Time (s)         18913.641260891687
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:57.874602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #301 | Epoch Duration: 63.561463832855225
2020-01-11 05:17:57.874783 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #301 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1611638
Z variance train             0.019711575
KL Divergence                22.1272
KL Loss                      2.21272
QF Loss                      226.27693
VF Loss                      65.901146
Policy Loss                  -1075.3629
Q Predictions Mean           1073.8286
Q Predictions Std            385.30484
Q Predictions Max            1427.7623
Q Predictions Min            -26.76051
V Predictions Mean           1074.6317
V Predictions Std            383.2308
V Predictions Max            1425.0564
V Predictions Min            -5.4957495
Log Pis Mean                 -0.2603246
Log Pis Std                  2.1004272
Log Pis Max                  8.14384
Log Pis Min                  -4.9570236
Policy mu Mean               0.09964857
Policy mu Std                0.91234094
Policy mu Max                2.1080418
Policy mu Min                -2.8442316
Policy log std Mean          -0.4607751
Policy log std Std           0.14624633
Policy log std Max           -0.124449655
Policy log std Min           -1.2619028
Z mean eval                  2.0962572
Z variance eval              0.013301912
total_rewards                [810.69587068 961.03389653 852.20309264 868.53100216 743.83887714
 817.11246378 965.40332614 925.86314321 826.0374194  883.89789773]
total_rewards_mean           865.4616989417976
total_rewards_std            67.06649092196288
total_rewards_max            965.4033261447745
total_rewards_min            743.8388771368147
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               32.64601009013131
(Previous) Eval Time (s)     7.908934727776796
Sample Time (s)              23.126164087560028
Epoch Time (s)               63.681108905468136
Total Train Time (s)         18977.397484149784
Epoch                        302
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:01.634126 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #302 | Epoch Duration: 63.75920653343201
2020-01-11 05:19:01.634308 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1008017
Z variance train             0.013335313
KL Divergence                21.830166
KL Loss                      2.1830165
QF Loss                      109.9144
VF Loss                      82.57806
Policy Loss                  -1040.968
Q Predictions Mean           1039.0409
Q Predictions Std            368.47427
Q Predictions Max            1387.455
Q Predictions Min            2.7135558
V Predictions Mean           1034.9592
V Predictions Std            365.77005
V Predictions Max            1380.6051
V Predictions Min            2.4781523
Log Pis Mean                 -0.24866699
Log Pis Std                  2.0290987
Log Pis Max                  7.5870514
Log Pis Min                  -4.815896
Policy mu Mean               0.23649687
Policy mu Std                0.8886512
Policy mu Max                2.3203664
Policy mu Min                -2.7626798
Policy log std Mean          -0.4507105
Policy log std Std           0.14307782
Policy log std Max           -0.1433205
Policy log std Min           -1.1376816
Z mean eval                  2.0841715
Z variance eval              0.020223016
total_rewards                [ 836.71967655  897.90691003 1149.76282331  841.0085601   728.6622633
 1349.72106479  764.69941734  931.69404745  812.16240964  819.29380617]
total_rewards_mean           913.1630978693953
total_rewards_std            182.5603777512368
total_rewards_max            1349.721064793013
total_rewards_min            728.662263299136
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               33.625358927063644
(Previous) Eval Time (s)     7.986724880989641
Sample Time (s)              23.377144975587726
Epoch Time (s)               64.98922878364101
Total Train Time (s)         19042.872320039198
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:20:07.113042 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #303 | Epoch Duration: 65.4785852432251
2020-01-11 05:20:07.113290 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.083091
Z variance train             0.020175604
KL Divergence                21.643286
KL Loss                      2.1643286
QF Loss                      152.5741
VF Loss                      127.18746
Policy Loss                  -1005.4741
Q Predictions Mean           1002.8428
Q Predictions Std            394.39328
Q Predictions Max            1366.1611
Q Predictions Min            -0.25372502
V Predictions Mean           1011.0273
V Predictions Std            392.74448
V Predictions Max            1378.8717
V Predictions Min            2.9528697
Log Pis Mean                 -0.20845932
Log Pis Std                  2.0193932
Log Pis Max                  6.1891074
Log Pis Min                  -5.357729
Policy mu Mean               0.1435047
Policy mu Std                0.88555527
Policy mu Max                2.1949055
Policy mu Min                -3.0007753
Policy log std Mean          -0.420005
Policy log std Std           0.1410396
Policy log std Max           -0.055506438
Policy log std Min           -1.3803846
Z mean eval                  2.0795884
Z variance eval              0.014654261
total_rewards                [1341.47139611  872.00661698  775.98954365  837.81111898  925.26195475
  855.28514313  929.3927608   891.55732948  898.78629764 1995.85417611]
total_rewards_mean           1032.3416337641206
total_rewards_std            352.73988139203647
total_rewards_max            1995.8541761122501
total_rewards_min            775.9895436511821
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               34.51858790870756
(Previous) Eval Time (s)     8.475743995048106
Sample Time (s)              24.0005812542513
Epoch Time (s)               66.99491315800697
Total Train Time (s)         19111.062483399175
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:15.307305 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #304 | Epoch Duration: 68.19384360313416
2020-01-11 05:21:15.307546 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0770066
Z variance train             0.0146648185
KL Divergence                22.201496
KL Loss                      2.2201498
QF Loss                      212.81485
VF Loss                      78.36639
Policy Loss                  -1072.6678
Q Predictions Mean           1072.4934
Q Predictions Std            335.31934
Q Predictions Max            1396.4369
Q Predictions Min            5.5881944
V Predictions Mean           1076.6588
V Predictions Std            335.8185
V Predictions Max            1402.6204
V Predictions Min            5.708309
Log Pis Mean                 -0.11450486
Log Pis Std                  2.063694
Log Pis Max                  6.5334406
Log Pis Min                  -5.9769087
Policy mu Mean               0.10544589
Policy mu Std                0.92533666
Policy mu Max                2.5425794
Policy mu Min                -2.9936032
Policy log std Mean          -0.45633757
Policy log std Std           0.13810453
Policy log std Max           -0.13334586
Policy log std Min           -1.1946692
Z mean eval                  2.0453792
Z variance eval              0.015771095
total_rewards                [ 872.98291956 2005.69952946 1299.091634    966.25455069  741.66052037
  820.41926699  686.51288069  843.57961537  932.72957289 1386.88125283]
total_rewards_mean           1055.5811742852807
total_rewards_std            382.5178721399524
total_rewards_max            2005.6995294583412
total_rewards_min            686.5128806923514
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               35.317736654076725
(Previous) Eval Time (s)     9.674283874221146
Sample Time (s)              23.539462660439312
Epoch Time (s)               68.53148318873718
Total Train Time (s)         19179.45526559651
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:23.703423 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #305 | Epoch Duration: 68.39572882652283
2020-01-11 05:22:23.703616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.04487
Z variance train             0.015765516
KL Divergence                21.593775
KL Loss                      2.1593776
QF Loss                      130.74084
VF Loss                      28.963387
Policy Loss                  -1070.3953
Q Predictions Mean           1072.0085
Q Predictions Std            383.16556
Q Predictions Max            1428.5181
Q Predictions Min            0.99638534
V Predictions Mean           1071.1381
V Predictions Std            383.0212
V Predictions Max            1424.9022
V Predictions Min            2.0013933
Log Pis Mean                 -0.2177048
Log Pis Std                  1.8864424
Log Pis Max                  6.423112
Log Pis Min                  -5.828253
Policy mu Mean               0.2840099
Policy mu Std                0.85410976
Policy mu Max                2.4703565
Policy mu Min                -2.8933852
Policy log std Mean          -0.4535307
Policy log std Std           0.14209005
Policy log std Max           -0.10497016
Policy log std Min           -0.9882717
Z mean eval                  2.0122542
Z variance eval              0.017041873
total_rewards                [ 761.50304588 1721.18155668  741.05525631  749.96532192  734.28085791
 1019.8397557   788.48764734  751.4825363   753.95368593  744.71652299]
total_rewards_mean           876.6466186963484
total_rewards_std            292.84806885490394
total_rewards_max            1721.1815566757177
total_rewards_min            734.2808579073486
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               35.71868700813502
(Previous) Eval Time (s)     9.538163817953318
Sample Time (s)              25.01502265781164
Epoch Time (s)               70.27187348389998
Total Train Time (s)         19249.016013438348
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:23:33.267554 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #306 | Epoch Duration: 69.56380152702332
2020-01-11 05:23:33.267736 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0145988
Z variance train             0.017078202
KL Divergence                20.659323
KL Loss                      2.0659323
QF Loss                      119.911316
VF Loss                      73.02709
Policy Loss                  -1074.3917
Q Predictions Mean           1070.678
Q Predictions Std            393.56076
Q Predictions Max            1411.721
Q Predictions Min            -0.11012083
V Predictions Mean           1069.4271
V Predictions Std            393.82166
V Predictions Max            1425.2029
V Predictions Min            -0.020374775
Log Pis Mean                 -0.09143976
Log Pis Std                  1.9281309
Log Pis Max                  6.6809864
Log Pis Min                  -5.7324047
Policy mu Mean               0.105703466
Policy mu Std                0.9478968
Policy mu Max                2.6458879
Policy mu Min                -2.8552976
Policy log std Mean          -0.4637978
Policy log std Std           0.15349337
Policy log std Max           -0.049132064
Policy log std Min           -0.9636844
Z mean eval                  2.0022266
Z variance eval              0.018846044
total_rewards                [ 797.78868211  746.3054177   706.20876598  787.46278265  750.99144579
  821.75876767 1042.78069809  754.19924617  753.24078188  739.17037254]
total_rewards_mean           789.9906960595579
total_rewards_std            89.80102486553122
total_rewards_max            1042.7806980921002
total_rewards_min            706.2087659762323
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               34.636622737161815
(Previous) Eval Time (s)     8.829698737710714
Sample Time (s)              24.085935504175723
Epoch Time (s)               67.55225697904825
Total Train Time (s)         19315.362979666796
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:39.619174 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #307 | Epoch Duration: 66.35128331184387
2020-01-11 05:24:39.619442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9977468
Z variance train             0.018811386
KL Divergence                20.101044
KL Loss                      2.0101044
QF Loss                      146.5818
VF Loss                      95.12597
Policy Loss                  -1096.1967
Q Predictions Mean           1097.3566
Q Predictions Std            416.72363
Q Predictions Max            1443.486
Q Predictions Min            0.08309218
V Predictions Mean           1102.3164
V Predictions Std            418.82047
V Predictions Max            1457.2263
V Predictions Min            0.6189802
Log Pis Mean                 -0.043536223
Log Pis Std                  1.9231826
Log Pis Max                  8.294214
Log Pis Min                  -4.287535
Policy mu Mean               0.10151148
Policy mu Std                0.9468396
Policy mu Max                2.7245078
Policy mu Min                -2.7245405
Policy log std Mean          -0.45063904
Policy log std Std           0.15546125
Policy log std Max           -0.113137946
Policy log std Min           -0.9054526
Z mean eval                  1.9686205
Z variance eval              0.022355082
total_rewards                [ 738.69582456 1037.64503956 1021.70726859  997.17235834  763.29268364
  780.93773545  802.42451118  839.97862422 1001.59463045 1321.39046157]
total_rewards_mean           930.4839137564534
total_rewards_std            171.40807308810744
total_rewards_max            1321.3904615674412
total_rewards_min            738.6958245557983
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               34.95273442706093
(Previous) Eval Time (s)     7.628328334074467
Sample Time (s)              24.100395478773862
Epoch Time (s)               66.68145823990926
Total Train Time (s)         19383.008654777892
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:25:47.267407 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #308 | Epoch Duration: 67.64779758453369
2020-01-11 05:25:47.267589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9686339
Z variance train             0.02232663
KL Divergence                19.551392
KL Loss                      1.9551392
QF Loss                      101.34958
VF Loss                      102.8499
Policy Loss                  -1070.1428
Q Predictions Mean           1070.7715
Q Predictions Std            410.49234
Q Predictions Max            1425.7731
Q Predictions Min            6.842884
V Predictions Mean           1068.071
V Predictions Std            410.69736
V Predictions Max            1438.9128
V Predictions Min            0.88763565
Log Pis Mean                 -0.27134672
Log Pis Std                  1.9832183
Log Pis Max                  6.636053
Log Pis Min                  -4.4676304
Policy mu Mean               0.11312851
Policy mu Std                0.8930703
Policy mu Max                2.5623865
Policy mu Min                -3.0041792
Policy log std Mean          -0.42893848
Policy log std Std           0.17184757
Policy log std Max           -0.04913202
Policy log std Min           -1.2136352
Z mean eval                  1.9518852
Z variance eval              0.016959328
total_rewards                [ 826.36322324  976.97228447  779.66539191 1081.38047953 1305.23477529
  803.95667465  823.64506141  906.71385235 1271.39721446 1013.36083613]
total_rewards_mean           978.868979343905
total_rewards_std            180.72756034712032
total_rewards_max            1305.2347752942655
total_rewards_min            779.6653919123015
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               35.24090714100748
(Previous) Eval Time (s)     8.59431963134557
Sample Time (s)              24.82575329300016
Epoch Time (s)               68.66098006535321
Total Train Time (s)         19451.983322257176
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:56.245559 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #309 | Epoch Duration: 68.9778368473053
2020-01-11 05:26:56.245735 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #309 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9481428
Z variance train             0.01697075
KL Divergence                20.197634
KL Loss                      2.0197635
QF Loss                      166.20428
VF Loss                      82.060844
Policy Loss                  -1090.7666
Q Predictions Mean           1091.8672
Q Predictions Std            363.6638
Q Predictions Max            1401.558
Q Predictions Min            -5.413406
V Predictions Mean           1095.1396
V Predictions Std            363.1244
V Predictions Max            1407.7152
V Predictions Min            2.7619922
Log Pis Mean                 -0.07695139
Log Pis Std                  2.403163
Log Pis Max                  16.309048
Log Pis Min                  -4.624259
Policy mu Mean               0.1227979
Policy mu Std                0.980304
Policy mu Max                3.4317696
Policy mu Min                -3.7984803
Policy log std Mean          -0.45314303
Policy log std Std           0.1475215
Policy log std Max           0.09333062
Policy log std Min           -1.0519454
Z mean eval                  1.9327234
Z variance eval              0.012858527
total_rewards                [776.86373609 781.84116825 763.95751584 754.81226541 772.97968134
 750.78965821 765.40990563 996.32826415 773.38256365 757.83874575]
total_rewards_mean           789.4203504311545
total_rewards_std            69.61738907729242
total_rewards_max            996.3282641469667
total_rewards_min            750.7896582064697
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               34.398003227077425
(Previous) Eval Time (s)     8.910827514715493
Sample Time (s)              23.750524670816958
Epoch Time (s)               67.05935541260988
Total Train Time (s)         19517.85375353601
Epoch                        310
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:02.121691 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #310 | Epoch Duration: 65.87576651573181
2020-01-11 05:28:02.122076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9356763
Z variance train             0.012829076
KL Divergence                21.414059
KL Loss                      2.1414058
QF Loss                      127.137024
VF Loss                      104.96304
Policy Loss                  -1123.811
Q Predictions Mean           1123.3167
Q Predictions Std            385.6993
Q Predictions Max            1467.424
Q Predictions Min            6.119239
V Predictions Mean           1123.9138
V Predictions Std            387.56628
V Predictions Max            1462.2954
V Predictions Min            -0.52357507
Log Pis Mean                 -0.03282083
Log Pis Std                  2.113306
Log Pis Max                  8.141229
Log Pis Min                  -4.125712
Policy mu Mean               -0.019716999
Policy mu Std                0.94816333
Policy mu Max                2.228557
Policy mu Min                -2.9034421
Policy log std Mean          -0.4434577
Policy log std Std           0.15655954
Policy log std Max           -0.023406446
Policy log std Min           -1.2035997
Z mean eval                  1.9060314
Z variance eval              0.0102012865
total_rewards                [ 756.30886252  730.29582728  779.93337252  726.58863781  740.3532558
  677.71603141  755.74342625  740.86351305  762.7110615  1006.51061503]
total_rewards_mean           767.7024603167534
total_rewards_std            83.74493695932571
total_rewards_max            1006.5106150331669
total_rewards_min            677.7160314108964
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               34.79464655695483
(Previous) Eval Time (s)     7.726809488143772
Sample Time (s)              23.609369191806763
Epoch Time (s)               66.13082523690537
Total Train Time (s)         19583.775098732207
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:08.045867 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #311 | Epoch Duration: 65.92358779907227
2020-01-11 05:29:08.046075 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #311 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9024614
Z variance train             0.010185463
KL Divergence                21.583513
KL Loss                      2.1583514
QF Loss                      105.45112
VF Loss                      85.81811
Policy Loss                  -1058.931
Q Predictions Mean           1060.2297
Q Predictions Std            384.79413
Q Predictions Max            1424.1339
Q Predictions Min            -1.5318382
V Predictions Mean           1063.1532
V Predictions Std            384.46017
V Predictions Max            1414.2449
V Predictions Min            -0.9232071
Log Pis Mean                 -0.04785938
Log Pis Std                  2.0070662
Log Pis Max                  6.937602
Log Pis Min                  -3.4495356
Policy mu Mean               0.031724945
Policy mu Std                0.9310849
Policy mu Max                2.716627
Policy mu Min                -2.714142
Policy log std Mean          -0.43829992
Policy log std Std           0.16494769
Policy log std Max           -0.092881516
Policy log std Min           -1.1845194
Z mean eval                  1.8867352
Z variance eval              0.009237812
total_rewards                [795.52361386 755.47923876 794.51814918 784.91420768 754.08098338
 759.92400801 820.88610942 882.8076036  894.20254217 707.44730695]
total_rewards_mean           794.9783763012146
total_rewards_std            55.18667496022075
total_rewards_max            894.2025421716962
total_rewards_min            707.4473069526554
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               35.61821725592017
(Previous) Eval Time (s)     7.519201144110411
Sample Time (s)              23.30388665944338
Epoch Time (s)               66.44130505947396
Total Train Time (s)         19650.54611261608
Epoch                        312
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:14.821347 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #312 | Epoch Duration: 66.77510070800781
2020-01-11 05:30:14.821639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8915523
Z variance train             0.0092326
KL Divergence                21.619493
KL Loss                      2.1619494
QF Loss                      155.93124
VF Loss                      128.54205
Policy Loss                  -1148.3241
Q Predictions Mean           1144.4015
Q Predictions Std            383.29547
Q Predictions Max            1475.9146
Q Predictions Min            5.384886
V Predictions Mean           1140.5234
V Predictions Std            381.56238
V Predictions Max            1469.1439
V Predictions Min            2.3983712
Log Pis Mean                 -0.18602124
Log Pis Std                  1.9643731
Log Pis Max                  6.926322
Log Pis Min                  -4.7341413
Policy mu Mean               0.03961483
Policy mu Std                0.9053661
Policy mu Max                2.3007398
Policy mu Min                -2.8848627
Policy log std Mean          -0.43763545
Policy log std Std           0.16008067
Policy log std Max           0.0044737756
Policy log std Min           -1.2700738
Z mean eval                  1.8739411
Z variance eval              0.007121616
total_rewards                [ 821.80319328  765.73515871  972.69468602  756.16404673  988.63769103
  774.2850765  1591.49849067 1001.30248082  778.29238     786.24987512]
total_rewards_mean           923.666307886926
total_rewards_std            241.735230963335
total_rewards_max            1591.4984906722748
total_rewards_min            756.1640467304636
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               34.72214429313317
(Previous) Eval Time (s)     7.852574548218399
Sample Time (s)              22.59659207984805
Epoch Time (s)               65.17131092119962
Total Train Time (s)         19716.542133462615
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:20.820508 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #313 | Epoch Duration: 65.99869203567505
2020-01-11 05:31:20.820711 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #313 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8719075
Z variance train             0.0071243444
KL Divergence                21.656782
KL Loss                      2.1656783
QF Loss                      135.67609
VF Loss                      85.19528
Policy Loss                  -1136.8665
Q Predictions Mean           1135.4438
Q Predictions Std            333.78638
Q Predictions Max            1446.0536
Q Predictions Min            1.2917088
V Predictions Mean           1142.4647
V Predictions Std            332.92987
V Predictions Max            1455.1713
V Predictions Min            3.440158
Log Pis Mean                 -0.17547631
Log Pis Std                  1.9464749
Log Pis Max                  6.2442136
Log Pis Min                  -6.6508756
Policy mu Mean               0.16358854
Policy mu Std                0.92023057
Policy mu Max                2.289792
Policy mu Min                -2.8948994
Policy log std Mean          -0.43708977
Policy log std Std           0.1458114
Policy log std Max           -0.13221142
Policy log std Min           -1.0427556
Z mean eval                  1.8427699
Z variance eval              0.0074481345
total_rewards                [716.73468213 772.50123097 769.84052794 746.60686829 781.5375751
 748.25521457 749.66297239 771.56819807 771.30286336 748.92574704]
total_rewards_mean           757.6935879853132
total_rewards_std            18.286780417199836
total_rewards_max            781.5375750977386
total_rewards_min            716.7346821336135
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               34.894298809114844
(Previous) Eval Time (s)     8.679577950853854
Sample Time (s)              23.774072968401015
Epoch Time (s)               67.34794972836971
Total Train Time (s)         19782.342195982113
Epoch                        314
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:32:26.624605 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #314 | Epoch Duration: 65.80373120307922
2020-01-11 05:32:26.624845 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8409119
Z variance train             0.0074524013
KL Divergence                21.43037
KL Loss                      2.143037
QF Loss                      242.6705
VF Loss                      139.56793
Policy Loss                  -1108.0226
Q Predictions Mean           1106.4542
Q Predictions Std            392.53616
Q Predictions Max            1419.4983
Q Predictions Min            -2.6023338
V Predictions Mean           1107.988
V Predictions Std            393.22354
V Predictions Max            1435.1327
V Predictions Min            4.314736
Log Pis Mean                 -0.2247275
Log Pis Std                  2.0640488
Log Pis Max                  7.0544457
Log Pis Min                  -5.4912314
Policy mu Mean               0.09989443
Policy mu Std                0.90917087
Policy mu Max                2.0878823
Policy mu Min                -2.6166525
Policy log std Mean          -0.45724893
Policy log std Std           0.15983166
Policy log std Max           -0.12852485
Policy log std Min           -1.1364957
Z mean eval                  1.8225237
Z variance eval              0.011670564
total_rewards                [ 786.51545875  680.94975584 1005.14556115 1036.35956423  771.97080001
  985.50441247  983.26874062  759.02669522 1022.71703523  778.93540301]
total_rewards_mean           881.0393426527274
total_rewards_std            129.28338984315937
total_rewards_max            1036.359564230044
total_rewards_min            680.9497558359715
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               35.391778389923275
(Previous) Eval Time (s)     7.134963947348297
Sample Time (s)              23.77506431005895
Epoch Time (s)               66.30180664733052
Total Train Time (s)         19848.28073054459
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:32.566315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #315 | Epoch Duration: 65.94130444526672
2020-01-11 05:33:32.566510 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8204848
Z variance train             0.011624394
KL Divergence                19.878643
KL Loss                      1.9878644
QF Loss                      203.5033
VF Loss                      67.161095
Policy Loss                  -1141.6112
Q Predictions Mean           1136.397
Q Predictions Std            366.02673
Q Predictions Max            1464.4376
Q Predictions Min            2.4876602
V Predictions Mean           1141.0189
V Predictions Std            366.48114
V Predictions Max            1476.9648
V Predictions Min            6.116787
Log Pis Mean                 -0.15067354
Log Pis Std                  2.223019
Log Pis Max                  7.762355
Log Pis Min                  -6.319518
Policy mu Mean               0.021789119
Policy mu Std                0.9531222
Policy mu Max                2.3650084
Policy mu Min                -2.8137636
Policy log std Mean          -0.47494578
Policy log std Std           0.16499552
Policy log std Max           -0.093006074
Policy log std Min           -1.238231
Z mean eval                  1.7936976
Z variance eval              0.017400203
total_rewards                [ 755.17140588  996.86070664  936.79051892  753.12859226 1290.7403359
  750.16490241  987.8864555  1274.12231128 1257.97893093  770.21972292]
total_rewards_mean           977.306388264152
total_rewards_std            214.7862260326768
total_rewards_max            1290.7403358994513
total_rewards_min            750.164902414685
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               32.422423257958144
(Previous) Eval Time (s)     6.774086380843073
Sample Time (s)              24.17436612676829
Epoch Time (s)               63.37087576556951
Total Train Time (s)         19913.621491022408
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:37.912991 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #316 | Epoch Duration: 65.34633564949036
2020-01-11 05:34:37.913200 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7952454
Z variance train             0.017363513
KL Divergence                18.62324
KL Loss                      1.862324
QF Loss                      128.80965
VF Loss                      68.17123
Policy Loss                  -1182.3044
Q Predictions Mean           1178.7142
Q Predictions Std            403.6288
Q Predictions Max            1511.7473
Q Predictions Min            -5.574181
V Predictions Mean           1177.5566
V Predictions Std            401.8797
V Predictions Max            1511.5968
V Predictions Min            2.7137268
Log Pis Mean                 0.109058075
Log Pis Std                  2.2943203
Log Pis Max                  8.23208
Log Pis Min                  -4.327264
Policy mu Mean               0.032712337
Policy mu Std                0.9903142
Policy mu Max                2.960691
Policy mu Min                -3.1357625
Policy log std Mean          -0.46209088
Policy log std Std           0.14686261
Policy log std Max           -0.10809681
Policy log std Min           -0.9353793
Z mean eval                  1.7908016
Z variance eval              0.018417774
total_rewards                [ 681.96629676  797.38477524  746.89501774  911.81040216  761.23180707
  774.80065169  798.13255513 1030.32948447 1002.2427975   970.46573249]
total_rewards_mean           847.5259520241382
total_rewards_std            114.81602340821533
total_rewards_max            1030.3294844655466
total_rewards_min            681.9662967550022
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               32.44637123728171
(Previous) Eval Time (s)     8.74912777915597
Sample Time (s)              22.822599363978952
Epoch Time (s)               64.01809838041663
Total Train Time (s)         19977.152136879973
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:41.447679 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #317 | Epoch Duration: 63.53429174423218
2020-01-11 05:35:41.447931 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.790934
Z variance train             0.018332608
KL Divergence                18.393076
KL Loss                      1.8393077
QF Loss                      245.94196
VF Loss                      64.97844
Policy Loss                  -1170.7916
Q Predictions Mean           1170.4655
Q Predictions Std            415.6631
Q Predictions Max            1530.0276
Q Predictions Min            -5.7833033
V Predictions Mean           1171.7056
V Predictions Std            415.3651
V Predictions Max            1529.1653
V Predictions Min            -1.2909505
Log Pis Mean                 0.1946326
Log Pis Std                  2.3489082
Log Pis Max                  9.56497
Log Pis Min                  -5.635646
Policy mu Mean               -0.0015229707
Policy mu Std                0.9912223
Policy mu Max                3.5281777
Policy mu Min                -3.3711703
Policy log std Mean          -0.4877437
Policy log std Std           0.17710428
Policy log std Max           0.1191155
Policy log std Min           -1.0819488
Z mean eval                  1.7664906
Z variance eval              0.012528365
total_rewards                [1230.26935499  765.23235929  757.62563122 1289.75490396 1269.50192328
 1571.11372084  765.28050535 1121.79287073 1587.56649034  784.05260358]
total_rewards_mean           1114.219036357686
total_rewards_std            313.20596246298214
total_rewards_max            1587.5664903378163
total_rewards_min            757.6256312214512
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               32.529102051630616
(Previous) Eval Time (s)     8.264976567123085
Sample Time (s)              22.81793325813487
Epoch Time (s)               63.61201187688857
Total Train Time (s)         20043.061713575386
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:47.360633 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #318 | Epoch Duration: 65.91253638267517
2020-01-11 05:36:47.360844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.770896
Z variance train             0.012507321
KL Divergence                19.340471
KL Loss                      1.9340471
QF Loss                      219.31903
VF Loss                      85.59368
Policy Loss                  -1122.323
Q Predictions Mean           1117.3225
Q Predictions Std            374.2278
Q Predictions Max            1476.2969
Q Predictions Min            -1.8308595
V Predictions Mean           1116.1606
V Predictions Std            372.00568
V Predictions Max            1480.7179
V Predictions Min            3.0606315
Log Pis Mean                 -0.33025393
Log Pis Std                  2.319651
Log Pis Max                  14.657052
Log Pis Min                  -5.6342
Policy mu Mean               -0.05027902
Policy mu Std                0.8943251
Policy mu Max                2.240724
Policy mu Min                -3.7456145
Policy log std Mean          -0.460672
Policy log std Std           0.1749981
Policy log std Max           -0.09724404
Policy log std Min           -1.2415037
Z mean eval                  1.7462234
Z variance eval              0.017477002
total_rewards                [ 757.52932011  790.69867684  792.34086655  872.52729925  810.93624967
 1007.08600435  967.69465353  751.49009365 1287.4127435   721.38383344]
total_rewards_mean           875.9099740885765
total_rewards_std            163.3451896515059
total_rewards_max            1287.412743498035
total_rewards_min            721.3838334359214
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               32.30873655481264
(Previous) Eval Time (s)     10.565188122913241
Sample Time (s)              22.97243063384667
Epoch Time (s)               65.84635531157255
Total Train Time (s)         20105.566742889117
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:49.869089 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #319 | Epoch Duration: 62.508105754852295
2020-01-11 05:37:49.869261 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7466984
Z variance train             0.017496468
KL Divergence                18.490705
KL Loss                      1.8490705
QF Loss                      83.637764
VF Loss                      46.98076
Policy Loss                  -1145.5725
Q Predictions Mean           1143.5444
Q Predictions Std            384.1192
Q Predictions Max            1481.4408
Q Predictions Min            -0.21650833
V Predictions Mean           1146.8225
V Predictions Std            382.7851
V Predictions Max            1476.7856
V Predictions Min            4.2757654
Log Pis Mean                 -0.3782987
Log Pis Std                  2.0545533
Log Pis Max                  7.4277143
Log Pis Min                  -6.8099737
Policy mu Mean               0.104780056
Policy mu Std                0.8831088
Policy mu Max                2.3531103
Policy mu Min                -2.8916943
Policy log std Mean          -0.45870018
Policy log std Std           0.17760208
Policy log std Max           -0.014330924
Policy log std Min           -2.1010246
Z mean eval                  1.7414268
Z variance eval              0.01641508
total_rewards                [ 799.64303421  756.83712208 1308.6449905   715.13728381 1258.41283069
 1009.68439473  832.4854538  1524.88827666 2704.74043083  736.42888127]
total_rewards_mean           1164.6902698579404
total_rewards_std            578.8350561398366
total_rewards_max            2704.740430825182
total_rewards_min            715.1372838087799
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               32.95675844326615
(Previous) Eval Time (s)     7.2266281908378005
Sample Time (s)              22.969931818079203
Epoch Time (s)               63.15331845218316
Total Train Time (s)         20171.931641013827
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:56.237329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #320 | Epoch Duration: 66.36793065071106
2020-01-11 05:38:56.237508 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7406721
Z variance train             0.01639303
KL Divergence                18.40895
KL Loss                      1.840895
QF Loss                      144.13257
VF Loss                      46.71664
Policy Loss                  -1101.9618
Q Predictions Mean           1100.7177
Q Predictions Std            429.60962
Q Predictions Max            1482.518
Q Predictions Min            2.307569
V Predictions Mean           1104.1387
V Predictions Std            429.29547
V Predictions Max            1486.2487
V Predictions Min            1.474926
Log Pis Mean                 -0.17000222
Log Pis Std                  2.198
Log Pis Max                  6.167099
Log Pis Min                  -5.1780486
Policy mu Mean               -0.08111185
Policy mu Std                0.9227624
Policy mu Max                2.6299706
Policy mu Min                -2.8366919
Policy log std Mean          -0.4272381
Policy log std Std           0.17346972
Policy log std Max           0.07489011
Policy log std Min           -1.7102774
Z mean eval                  1.7178558
Z variance eval              0.011614457
total_rewards                [ 981.52205439 1575.88931684 1634.81640226  761.36921726  699.72012194
  767.93511921  723.658712    987.8908171   970.27292042 2166.96503517]
total_rewards_mean           1127.003971659459
total_rewards_std            470.5157503222246
total_rewards_max            2166.9650351749747
total_rewards_min            699.7201219365786
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               32.73242940194905
(Previous) Eval Time (s)     10.440864059142768
Sample Time (s)              23.45354223297909
Epoch Time (s)               66.6268356940709
Total Train Time (s)         20238.767187785357
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:03.076925 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #321 | Epoch Duration: 66.83927750587463
2020-01-11 05:40:03.077111 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7198632
Z variance train             0.011650046
KL Divergence                18.936104
KL Loss                      1.8936104
QF Loss                      118.627686
VF Loss                      92.85716
Policy Loss                  -1067.0448
Q Predictions Mean           1063.7286
Q Predictions Std            415.1896
Q Predictions Max            1418.9132
Q Predictions Min            1.0747216
V Predictions Mean           1065.9161
V Predictions Std            416.38098
V Predictions Max            1440.477
V Predictions Min            2.4877696
Log Pis Mean                 -0.21618941
Log Pis Std                  2.2231827
Log Pis Max                  7.21733
Log Pis Min                  -5.309928
Policy mu Mean               0.048755866
Policy mu Std                0.95495605
Policy mu Max                2.4503777
Policy mu Min                -2.9912183
Policy log std Mean          -0.44493377
Policy log std Std           0.16212353
Policy log std Max           -0.026323408
Policy log std Min           -0.9901003
Z mean eval                  1.6965568
Z variance eval              0.011562471
total_rewards                [1276.18272162  951.18403598  921.86502671  759.53701906 1531.28242609
  737.40365503 1019.3582351   750.62420516  691.70048412 1015.86729572]
total_rewards_mean           965.5005104588781
total_rewards_std            252.9360616994685
total_rewards_max            1531.2824260880807
total_rewards_min            691.7004841171804
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               33.119361764751375
(Previous) Eval Time (s)     10.652980360668153
Sample Time (s)              22.37729296972975
Epoch Time (s)               66.14963509514928
Total Train Time (s)         20303.64736670023
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:07.961259 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #322 | Epoch Duration: 64.8840069770813
2020-01-11 05:41:07.961445 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6917156
Z variance train             0.011576789
KL Divergence                18.563112
KL Loss                      1.8563112
QF Loss                      180.33235
VF Loss                      111.08659
Policy Loss                  -1099.1124
Q Predictions Mean           1099.6024
Q Predictions Std            388.5142
Q Predictions Max            1436.159
Q Predictions Min            0.097927034
V Predictions Mean           1105.8262
V Predictions Std            388.66965
V Predictions Max            1447.0267
V Predictions Min            4.6331906
Log Pis Mean                 0.13769633
Log Pis Std                  2.1276295
Log Pis Max                  8.441939
Log Pis Min                  -4.3116584
Policy mu Mean               -0.08826667
Policy mu Std                0.9931445
Policy mu Max                2.639935
Policy mu Min                -2.8046746
Policy log std Mean          -0.45267937
Policy log std Std           0.15523565
Policy log std Max           -0.027883738
Policy log std Min           -1.0911956
Z mean eval                  1.6824051
Z variance eval              0.01242586
total_rewards                [ 913.33561928 1293.56497428  762.03186269  751.80795899  983.41876608
  892.73722496  768.53762991  966.62046205  983.94109208 2540.30108858]
total_rewards_mean           1085.6296678910064
total_rewards_std            507.72526300522003
total_rewards_max            2540.3010885829926
total_rewards_min            751.8079589888159
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               32.99334329366684
(Previous) Eval Time (s)     9.387055497150868
Sample Time (s)              23.518958622124046
Epoch Time (s)               65.89935741294175
Total Train Time (s)         20370.410231334157
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:14.728074 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #323 | Epoch Duration: 66.76647615432739
2020-01-11 05:42:14.728262 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6819
Z variance train             0.012464701
KL Divergence                18.239399
KL Loss                      1.8239399
QF Loss                      173.04901
VF Loss                      97.09714
Policy Loss                  -1169.4016
Q Predictions Mean           1170.4707
Q Predictions Std            341.55585
Q Predictions Max            1458.2651
Q Predictions Min            5.854508
V Predictions Mean           1168.2911
V Predictions Std            343.5191
V Predictions Max            1456.3934
V Predictions Min            1.8494468
Log Pis Mean                 -0.28729862
Log Pis Std                  2.1514988
Log Pis Max                  7.3345118
Log Pis Min                  -6.3285213
Policy mu Mean               -0.014896055
Policy mu Std                0.96487635
Policy mu Max                2.5238128
Policy mu Min                -2.8880575
Policy log std Mean          -0.45863095
Policy log std Std           0.14106975
Policy log std Max           -0.10882607
Policy log std Min           -0.8299511
Z mean eval                  1.6602758
Z variance eval              0.013539225
total_rewards                [ 925.96104717  986.97901316  763.07301741  805.94625003  884.33259727
 1024.69070692 1208.56047651 1981.29161448 1296.68643133 2295.94720941]
total_rewards_mean           1217.3468363682387
total_rewards_std            491.4231765991414
total_rewards_max            2295.947209411688
total_rewards_min            763.0730174091217
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               32.98292176378891
(Previous) Eval Time (s)     10.253841985017061
Sample Time (s)              21.4844630532898
Epoch Time (s)               64.72122680209577
Total Train Time (s)         20435.708500230685
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:20.028224 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #324 | Epoch Duration: 65.29983925819397
2020-01-11 05:43:20.028342 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6581684
Z variance train             0.013559476
KL Divergence                18.023743
KL Loss                      1.8023742
QF Loss                      104.99139
VF Loss                      56.125946
Policy Loss                  -1077.5494
Q Predictions Mean           1075.417
Q Predictions Std            428.15942
Q Predictions Max            1459.6437
Q Predictions Min            -0.22987682
V Predictions Mean           1081.1398
V Predictions Std            427.07242
V Predictions Max            1460.3037
V Predictions Min            7.1885443
Log Pis Mean                 -0.14134791
Log Pis Std                  2.0316217
Log Pis Max                  7.135158
Log Pis Min                  -3.4644132
Policy mu Mean               -0.056760643
Policy mu Std                0.9243665
Policy mu Max                2.1497648
Policy mu Min                -2.8789659
Policy log std Mean          -0.4319965
Policy log std Std           0.15981746
Policy log std Max           -0.13766265
Policy log std Min           -0.9091227
Z mean eval                  1.6147964
Z variance eval              0.022442434
total_rewards                [ 834.28334555  768.28153242  771.60596457 1216.5806478   766.88100058
  926.8692074  1556.03352608 1276.71729886  889.38984928  968.79182864]
total_rewards_mean           997.5434201186899
total_rewards_std            252.74750326951818
total_rewards_max            1556.033526081695
total_rewards_min            766.8810005779955
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               32.80500362999737
(Previous) Eval Time (s)     10.832093422301114
Sample Time (s)              21.789969440549612
Epoch Time (s)               65.4270664928481
Total Train Time (s)         20500.124550064094
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:24.451532 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #325 | Epoch Duration: 64.42308354377747
2020-01-11 05:44:24.451719 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6185362
Z variance train             0.022276348
KL Divergence                16.591898
KL Loss                      1.6591898
QF Loss                      228.6553
VF Loss                      110.69786
Policy Loss                  -1120.2476
Q Predictions Mean           1116.4829
Q Predictions Std            392.92682
Q Predictions Max            1449.4127
Q Predictions Min            -1.9386582
V Predictions Mean           1114.3215
V Predictions Std            390.3392
V Predictions Max            1441.8643
V Predictions Min            2.9077935
Log Pis Mean                 0.12816188
Log Pis Std                  2.0403278
Log Pis Max                  6.7750845
Log Pis Min                  -4.8834577
Policy mu Mean               -0.0148083465
Policy mu Std                0.9846598
Policy mu Max                2.3714266
Policy mu Min                -2.8223662
Policy log std Mean          -0.46494076
Policy log std Std           0.17308913
Policy log std Max           -0.102255166
Policy log std Min           -1.5369427
Z mean eval                  1.6401193
Z variance eval              0.023967404
total_rewards                [ 770.04084265  753.1961595   817.74743766  871.63171231  838.28619416
 1448.01472008 2056.98111015 3067.62478185  838.56184013 3082.28247943]
total_rewards_mean           1454.4367277908723
total_rewards_std            898.8588777771711
total_rewards_max            3082.2824794267485
total_rewards_min            753.196159496613
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               32.28310384135693
(Previous) Eval Time (s)     9.82781970500946
Sample Time (s)              22.98415785189718
Epoch Time (s)               65.09508139826357
Total Train Time (s)         20568.19461468747
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:45:32.521647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #326 | Epoch Duration: 68.06978917121887
2020-01-11 05:45:32.521822 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6373934
Z variance train             0.024049275
KL Divergence                16.522259
KL Loss                      1.6522259
QF Loss                      298.34637
VF Loss                      64.343475
Policy Loss                  -1198.9337
Q Predictions Mean           1199.616
Q Predictions Std            356.97534
Q Predictions Max            1487.4452
Q Predictions Min            -0.44405955
V Predictions Mean           1201.9785
V Predictions Std            356.55734
V Predictions Max            1487.3209
V Predictions Min            0.4680605
Log Pis Mean                 -0.123851314
Log Pis Std                  1.997474
Log Pis Max                  9.449802
Log Pis Min                  -4.7237616
Policy mu Mean               -0.06418898
Policy mu Std                0.93156755
Policy mu Max                2.0274758
Policy mu Min                -3.0936937
Policy log std Mean          -0.45475706
Policy log std Std           0.16710527
Policy log std Max           -0.06457716
Policy log std Min           -1.1667954
Z mean eval                  1.6300209
Z variance eval              0.016188378
total_rewards                [ 775.15251221  762.40358583  859.31909714 1365.31285468  775.23761883
  799.99209704  848.32379071  916.31799453 1802.45920956 1046.26149069]
total_rewards_mean           995.0780251211545
total_rewards_std            320.40932210501245
total_rewards_max            1802.459209561453
total_rewards_min            762.4035858303962
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               32.34499703766778
(Previous) Eval Time (s)     12.802228223066777
Sample Time (s)              23.351810585241765
Epoch Time (s)               68.49903584597632
Total Train Time (s)         20632.22080638539
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:36.551757 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #327 | Epoch Duration: 64.02980351448059
2020-01-11 05:46:36.551937 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.630037
Z variance train             0.016204167
KL Divergence                17.090351
KL Loss                      1.7090352
QF Loss                      135.7606
VF Loss                      67.74404
Policy Loss                  -1124.8549
Q Predictions Mean           1121.8896
Q Predictions Std            395.0298
Q Predictions Max            1436.3984
Q Predictions Min            -3.1969268
V Predictions Mean           1125.6213
V Predictions Std            393.66312
V Predictions Max            1444.8788
V Predictions Min            -0.59254
Log Pis Mean                 -0.1309064
Log Pis Std                  2.3026366
Log Pis Max                  9.655909
Log Pis Min                  -4.751862
Policy mu Mean               -0.12654002
Policy mu Std                0.9398436
Policy mu Max                2.0585072
Policy mu Min                -3.3543246
Policy log std Mean          -0.43882695
Policy log std Std           0.17328225
Policy log std Max           0.008788854
Policy log std Min           -1.0799515
Z mean eval                  1.5972487
Z variance eval              0.017495777
total_rewards                [ 751.3780875  1476.37402858 1223.99477948 1508.11491219  682.80426217
  769.38525487 1180.41404823  737.45065146  753.68028276  776.87199594]
total_rewards_mean           986.0468303172413
total_rewards_std            309.9822223200585
total_rewards_max            1508.1149121885658
total_rewards_min            682.8042621703155
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               33.005033534020185
(Previous) Eval Time (s)     8.332697718404233
Sample Time (s)              23.569527476560324
Epoch Time (s)               64.90725872898474
Total Train Time (s)         20698.367665797472
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:42.703637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #328 | Epoch Duration: 66.15155744552612
2020-01-11 05:47:42.703815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5959071
Z variance train             0.017524863
KL Divergence                16.818819
KL Loss                      1.6818819
QF Loss                      624.2933
VF Loss                      72.091736
Policy Loss                  -1161.1832
Q Predictions Mean           1157.1381
Q Predictions Std            362.87747
Q Predictions Max            1452.2253
Q Predictions Min            -11.362404
V Predictions Mean           1166.0819
V Predictions Std            362.79138
V Predictions Max            1457.5426
V Predictions Min            -8.525162
Log Pis Mean                 -0.10789202
Log Pis Std                  2.1899168
Log Pis Max                  8.230607
Log Pis Min                  -4.3554487
Policy mu Mean               -0.017737558
Policy mu Std                0.9461919
Policy mu Max                2.1585848
Policy mu Min                -2.7526674
Policy log std Mean          -0.46372923
Policy log std Std           0.15413614
Policy log std Max           -0.09953106
Policy log std Min           -1.0165305
Z mean eval                  1.5963589
Z variance eval              0.01867785
total_rewards                [1524.54617442  942.60516293  959.2393409   747.31500964  746.71154905
  719.00960699  930.17884184 1282.33565061  762.7806961   904.29876283]
total_rewards_mean           951.9020795308425
total_rewards_std            247.7802800043188
total_rewards_max            1524.5461744191318
total_rewards_min            719.0096069882052
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               32.729007645044476
(Previous) Eval Time (s)     9.576669399160892
Sample Time (s)              22.55012006824836
Epoch Time (s)               64.85579711245373
Total Train Time (s)         20762.38136378443
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:46.720106 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #329 | Epoch Duration: 64.01616740226746
2020-01-11 05:48:46.720290 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5961246
Z variance train             0.01870282
KL Divergence                16.646187
KL Loss                      1.6646187
QF Loss                      464.8418
VF Loss                      159.11844
Policy Loss                  -1180.15
Q Predictions Mean           1177.1082
Q Predictions Std            393.00714
Q Predictions Max            1511.6749
Q Predictions Min            3.3717177
V Predictions Mean           1179.6838
V Predictions Std            392.53598
V Predictions Max            1512.6877
V Predictions Min            3.0857515
Log Pis Mean                 -0.089999765
Log Pis Std                  2.054341
Log Pis Max                  7.4885497
Log Pis Min                  -5.5152717
Policy mu Mean               -0.09373834
Policy mu Std                0.92172456
Policy mu Max                2.2840047
Policy mu Min                -2.8640683
Policy log std Mean          -0.4544588
Policy log std Std           0.18174762
Policy log std Max           -0.08843163
Policy log std Min           -2.161078
Z mean eval                  1.5850838
Z variance eval              0.019007955
total_rewards                [3167.65538765  776.99690892 3073.27831272 2589.3497227  3162.54701988
 1478.99011279 3233.27707727 3145.30998233 1440.28270194  843.13219007]
total_rewards_mean           2291.081941627065
total_rewards_std            980.735891780379
total_rewards_max            3233.277077272498
total_rewards_min            776.9969089208238
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               32.5356868528761
(Previous) Eval Time (s)     8.736659205053002
Sample Time (s)              22.990300667006522
Epoch Time (s)               64.26264672493562
Total Train Time (s)         20838.270131213125
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:50:02.612218 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #330 | Epoch Duration: 75.89179253578186
2020-01-11 05:50:02.612392 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.582352
Z variance train             0.019017521
KL Divergence                16.416088
KL Loss                      1.6416088
QF Loss                      72.123
VF Loss                      51.671936
Policy Loss                  -1193.4281
Q Predictions Mean           1193.5144
Q Predictions Std            400.60992
Q Predictions Max            1525.5182
Q Predictions Min            -5.926075
V Predictions Mean           1196.2993
V Predictions Std            399.67676
V Predictions Max            1523.4681
V Predictions Min            1.3207531
Log Pis Mean                 -0.42639863
Log Pis Std                  1.8462489
Log Pis Max                  7.317626
Log Pis Min                  -4.630019
Policy mu Mean               0.005352979
Policy mu Std                0.84280837
Policy mu Max                2.2611732
Policy mu Min                -2.8566253
Policy log std Mean          -0.42591083
Policy log std Std           0.15395518
Policy log std Max           -0.08994368
Policy log std Min           -0.9325196
Z mean eval                  1.5663406
Z variance eval              0.015968552
total_rewards                [ 699.94077539  793.68827568  840.85282644 1074.62432822  693.14211041
 1898.23274277  809.81272081 1053.7183596   799.55669496  864.44481421]
total_rewards_mean           952.8013648488962
total_rewards_std            337.6111642570368
total_rewards_max            1898.2327427667653
total_rewards_min            693.1421104129257
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               33.40109696611762
(Previous) Eval Time (s)     20.36545882327482
Sample Time (s)              23.104691048618406
Epoch Time (s)               76.87124683801085
Total Train Time (s)         20902.69518309692
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:07.040705 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #331 | Epoch Duration: 64.42819118499756
2020-01-11 05:51:07.040890 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5643065
Z variance train             0.015962292
KL Divergence                17.04205
KL Loss                      1.7042049
QF Loss                      134.34805
VF Loss                      75.27263
Policy Loss                  -1110.7954
Q Predictions Mean           1107.9421
Q Predictions Std            404.33588
Q Predictions Max            1457.476
Q Predictions Min            -5.036683
V Predictions Mean           1111.7867
V Predictions Std            404.85873
V Predictions Max            1455.0527
V Predictions Min            3.4111028
Log Pis Mean                 -0.21116424
Log Pis Std                  2.0134687
Log Pis Max                  7.142273
Log Pis Min                  -4.759484
Policy mu Mean               -0.033477265
Policy mu Std                0.8800453
Policy mu Max                2.0989761
Policy mu Min                -2.6845622
Policy log std Mean          -0.43942857
Policy log std Std           0.16681017
Policy log std Max           0.033542067
Policy log std Min           -0.95269084
Z mean eval                  1.5458429
Z variance eval              0.015089284
total_rewards                [1020.93808818 2059.10345808 2042.3999104   891.95833088 2030.95673299
 2076.2346042  1455.18063737  977.66775378  965.08368289 3153.5703685 ]
total_rewards_mean           1667.3093567267472
total_rewards_std            695.364413088237
total_rewards_max            3153.5703685046506
total_rewards_min            891.9583308818977
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               33.04014790710062
(Previous) Eval Time (s)     7.922019835095853
Sample Time (s)              23.440921985544264
Epoch Time (s)               64.40308972774073
Total Train Time (s)         20974.770957491826
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:19.120058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #332 | Epoch Duration: 72.07903242111206
2020-01-11 05:52:19.120231 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5426311
Z variance train             0.015075264
KL Divergence                17.081694
KL Loss                      1.7081693
QF Loss                      127.42459
VF Loss                      54.469673
Policy Loss                  -1201.0795
Q Predictions Mean           1198.7585
Q Predictions Std            425.9526
Q Predictions Max            1531.8126
Q Predictions Min            -2.8164515
V Predictions Mean           1203.8203
V Predictions Std            425.4562
V Predictions Max            1535.9722
V Predictions Min            -4.0190754
Log Pis Mean                 -0.29744986
Log Pis Std                  2.1232083
Log Pis Max                  7.718331
Log Pis Min                  -4.5512996
Policy mu Mean               0.13661735
Policy mu Std                0.8968149
Policy mu Max                2.6460583
Policy mu Min                -2.8930721
Policy log std Mean          -0.4478997
Policy log std Std           0.15393539
Policy log std Max           -0.06387451
Policy log std Min           -1.064441
Z mean eval                  1.5343277
Z variance eval              0.022539314
total_rewards                [ 815.9048312   763.81459407  752.6433855  1068.22008144 2039.40368662
  872.09796773  824.88862448  782.51231572  855.84691702  806.93880399]
total_rewards_mean           958.2271207747372
total_rewards_std            370.24325706451395
total_rewards_max            2039.4036866176973
total_rewards_min            752.6433854965454
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               33.218703197781
(Previous) Eval Time (s)     15.597612579353154
Sample Time (s)              23.27729763649404
Epoch Time (s)               72.09361341362819
Total Train Time (s)         21040.169534566347
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:53:24.522666 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #333 | Epoch Duration: 65.4022786617279
2020-01-11 05:53:24.522937 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5336072
Z variance train             0.022536345
KL Divergence                16.070448
KL Loss                      1.6070448
QF Loss                      332.3954
VF Loss                      59.57066
Policy Loss                  -1170.9878
Q Predictions Mean           1170.4758
Q Predictions Std            413.90216
Q Predictions Max            1518.864
Q Predictions Min            -18.027231
V Predictions Mean           1173.1951
V Predictions Std            412.5333
V Predictions Max            1515.5599
V Predictions Min            -4.2976537
Log Pis Mean                 -0.21097615
Log Pis Std                  2.0567734
Log Pis Max                  7.0304446
Log Pis Min                  -5.117305
Policy mu Mean               0.08872626
Policy mu Std                0.900319
Policy mu Max                2.1697412
Policy mu Min                -2.9615993
Policy log std Mean          -0.44429764
Policy log std Std           0.157763
Policy log std Max           -0.12597814
Policy log std Min           -1.0947218
Z mean eval                  1.584115
Z variance eval              0.010611172
total_rewards                [1002.23848083 1009.76265382 2851.93068935  965.71156608  851.55132545
 1512.4070779   811.26820096 1603.41713278 1317.49589144  871.45441961]
total_rewards_mean           1279.7237438223817
total_rewards_std            587.3778276677047
total_rewards_max            2851.930689350998
total_rewards_min            811.2682009639445
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               32.69510099897161
(Previous) Eval Time (s)     8.905918071046472
Sample Time (s)              22.974857249762863
Epoch Time (s)               64.57587631978095
Total Train Time (s)         21107.43043546425
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:31.788911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #334 | Epoch Duration: 67.26576519012451
2020-01-11 05:54:31.789242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5826689
Z variance train             0.010628777
KL Divergence                18.246166
KL Loss                      1.8246167
QF Loss                      363.16852
VF Loss                      403.0155
Policy Loss                  -1176.8577
Q Predictions Mean           1177.169
Q Predictions Std            390.32043
Q Predictions Max            1484.458
Q Predictions Min            -0.12117964
V Predictions Mean           1176.9294
V Predictions Std            387.61765
V Predictions Max            1477.1141
V Predictions Min            -1.6766684
Log Pis Mean                 -0.11391621
Log Pis Std                  2.4035878
Log Pis Max                  9.080917
Log Pis Min                  -5.747783
Policy mu Mean               -0.09487299
Policy mu Std                0.9806764
Policy mu Max                2.4530056
Policy mu Min                -3.456738
Policy log std Mean          -0.44344965
Policy log std Std           0.16478199
Policy log std Max           -0.021653533
Policy log std Min           -1.016402
Z mean eval                  1.5440922
Z variance eval              0.012607297
total_rewards                [ 753.82391017  785.12505939 1517.09895851  870.14232669  759.22326149
  781.47652635 1859.76873111  767.73715502  909.96365213  748.73326507]
total_rewards_mean           975.309284593266
total_rewards_std            368.1097259995553
total_rewards_max            1859.768731108023
total_rewards_min            748.7332650654815
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               32.866021789610386
(Previous) Eval Time (s)     11.595486192032695
Sample Time (s)              24.207602922338992
Epoch Time (s)               68.66911090398207
Total Train Time (s)         21173.757326480933
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:38.119087 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #335 | Epoch Duration: 66.32961940765381
2020-01-11 05:55:38.119442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5447174
Z variance train             0.012630859
KL Divergence                17.883945
KL Loss                      1.7883946
QF Loss                      312.18344
VF Loss                      84.5152
Policy Loss                  -1154.5399
Q Predictions Mean           1152.9304
Q Predictions Std            408.82254
Q Predictions Max            1509.2133
Q Predictions Min            -16.528612
V Predictions Mean           1156.7732
V Predictions Std            410.45102
V Predictions Max            1515.2539
V Predictions Min            -4.105711
Log Pis Mean                 -0.13259308
Log Pis Std                  2.0637064
Log Pis Max                  7.092746
Log Pis Min                  -3.9980276
Policy mu Mean               -0.020133635
Policy mu Std                0.89691633
Policy mu Max                2.251366
Policy mu Min                -2.9424946
Policy log std Mean          -0.4311769
Policy log std Std           0.16224097
Policy log std Max           0.059369624
Policy log std Min           -1.0152236
Z mean eval                  1.5154308
Z variance eval              0.0192624
total_rewards                [3158.07126027  815.53535054  846.24578194 1007.45866395  931.28487808
  935.02168766 1126.0463982  1518.59767398 1031.47387503 1565.54185673]
total_rewards_mean           1293.527742636767
total_rewards_std            668.4319556317231
total_rewards_max            3158.071260266737
total_rewards_min            815.5353505353206
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               32.94190987898037
(Previous) Eval Time (s)     9.255661817267537
Sample Time (s)              22.638983711134642
Epoch Time (s)               64.83655540738255
Total Train Time (s)         21241.208095556125
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:56:45.572400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #336 | Epoch Duration: 67.45276856422424
2020-01-11 05:56:45.572559 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.517189
Z variance train             0.019235747
KL Divergence                17.148027
KL Loss                      1.7148027
QF Loss                      114.068375
VF Loss                      55.538624
Policy Loss                  -1117.29
Q Predictions Mean           1113.1932
Q Predictions Std            411.127
Q Predictions Max            1454.1296
Q Predictions Min            2.5802944
V Predictions Mean           1115.6267
V Predictions Std            411.8624
V Predictions Max            1455.135
V Predictions Min            4.8660655
Log Pis Mean                 -0.32304975
Log Pis Std                  2.0539746
Log Pis Max                  6.6489882
Log Pis Min                  -6.015284
Policy mu Mean               0.07595509
Policy mu Std                0.9082519
Policy mu Max                2.3992848
Policy mu Min                -3.2047405
Policy log std Mean          -0.4505829
Policy log std Std           0.16700968
Policy log std Max           0.0031303763
Policy log std Min           -1.0297017
Z mean eval                  1.5185492
Z variance eval              0.01272168
total_rewards                [ 941.98499494  936.53894752  933.26603072  900.61514945 1270.97939438
  886.65007689  976.76826733  988.79773927  934.95125404  858.42649678]
total_rewards_mean           962.8978351319874
total_rewards_std            109.16764550417795
total_rewards_max            1270.9793943772627
total_rewards_min            858.4264967777556
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               33.147381061222404
(Previous) Eval Time (s)     11.871555054094642
Sample Time (s)              23.496254635043442
Epoch Time (s)               68.51519075036049
Total Train Time (s)         21306.604046218563
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:50.972274 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #337 | Epoch Duration: 65.39957761764526
2020-01-11 05:57:50.972482 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5152525
Z variance train             0.01270886
KL Divergence                17.342709
KL Loss                      1.7342709
QF Loss                      583.8948
VF Loss                      583.4266
Policy Loss                  -1136.5718
Q Predictions Mean           1132.6093
Q Predictions Std            389.87265
Q Predictions Max            1462.9131
Q Predictions Min            -18.106625
V Predictions Mean           1139.9768
V Predictions Std            388.24612
V Predictions Max            1459.6823
V Predictions Min            -0.7579144
Log Pis Mean                 -0.21502495
Log Pis Std                  1.9084035
Log Pis Max                  8.059594
Log Pis Min                  -4.6752205
Policy mu Mean               0.009550647
Policy mu Std                0.8980236
Policy mu Max                2.5390947
Policy mu Min                -3.2674644
Policy log std Mean          -0.42954472
Policy log std Std           0.16884987
Policy log std Max           -0.03242919
Policy log std Min           -1.3606305
Z mean eval                  1.5011429
Z variance eval              0.0124468375
total_rewards                [ 976.01391974  844.40702599  824.98697958  810.41133153  795.97258143
 1191.99807176  862.15605975  840.31820921 1930.70416772  747.30496461]
total_rewards_mean           982.4273311313679
total_rewards_std            337.83496580546205
total_rewards_max            1930.7041677183886
total_rewards_min            747.3049646100038
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               33.00093340082094
(Previous) Eval Time (s)     8.755633830092847
Sample Time (s)              22.201666021253914
Epoch Time (s)               63.9582332521677
Total Train Time (s)         21371.074688401073
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:55.446808 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #338 | Epoch Duration: 64.4741702079773
2020-01-11 05:58:55.446992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5027412
Z variance train             0.012519604
KL Divergence                17.103142
KL Loss                      1.7103142
QF Loss                      125.86845
VF Loss                      53.14121
Policy Loss                  -1146.1091
Q Predictions Mean           1145.9185
Q Predictions Std            385.2117
Q Predictions Max            1459.3198
Q Predictions Min            -2.827213
V Predictions Mean           1143.1663
V Predictions Std            383.40186
V Predictions Max            1453.9657
V Predictions Min            4.1721854
Log Pis Mean                 -0.24514602
Log Pis Std                  1.9244132
Log Pis Max                  7.4401336
Log Pis Min                  -4.888887
Policy mu Mean               0.012581308
Policy mu Std                0.8853242
Policy mu Max                2.7288635
Policy mu Min                -2.8143706
Policy log std Mean          -0.42849454
Policy log std Std           0.16838238
Policy log std Max           0.032257766
Policy log std Min           -1.3899307
Z mean eval                  1.5002086
Z variance eval              0.015495459
total_rewards                [ 797.04586402 1665.65493497  808.0344991   753.284362   3151.92477368
 2113.63439459 2868.48468427 1000.31923354 1403.67160287  759.46070022]
total_rewards_mean           1532.151504925831
total_rewards_std            856.3387660716683
total_rewards_max            3151.924773682925
total_rewards_min            753.2843619971186
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               32.92219720967114
(Previous) Eval Time (s)     9.27122011827305
Sample Time (s)              23.66398503538221
Epoch Time (s)               65.8574023633264
Total Train Time (s)         21441.632356669288
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:00:06.008375 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #339 | Epoch Duration: 70.56124997138977
2020-01-11 06:00:06.008542 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4968379
Z variance train             0.015574607
KL Divergence                16.463175
KL Loss                      1.6463175
QF Loss                      184.76993
VF Loss                      34.003586
Policy Loss                  -1219.0674
Q Predictions Mean           1220.3356
Q Predictions Std            361.68573
Q Predictions Max            1516.6622
Q Predictions Min            -3.86836
V Predictions Mean           1221.0724
V Predictions Std            361.4264
V Predictions Max            1508.2812
V Predictions Min            -5.065764
Log Pis Mean                 -0.10753478
Log Pis Std                  2.080863
Log Pis Max                  7.5131106
Log Pis Min                  -5.290297
Policy mu Mean               0.043960523
Policy mu Std                0.93543905
Policy mu Max                2.4366918
Policy mu Min                -2.884256
Policy log std Mean          -0.4000844
Policy log std Std           0.15332687
Policy log std Max           -0.05178106
Policy log std Min           -0.83639115
Z mean eval                  1.4863174
Z variance eval              0.012769972
total_rewards                [2066.14541808  819.14064073  985.96750342 1451.83178929 2364.3607994
  838.26918816 2168.2523746  1063.06908476 1972.26057778  730.48506504]
total_rewards_mean           1445.9782441262182
total_rewards_std            604.9063227217681
total_rewards_max            2364.360799402352
total_rewards_min            730.4850650408096
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               32.865561484359205
(Previous) Eval Time (s)     13.974385856185108
Sample Time (s)              22.45669951522723
Epoch Time (s)               69.29664685577154
Total Train Time (s)         21509.94132625498
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:14.321798 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #340 | Epoch Duration: 68.3131160736084
2020-01-11 06:01:14.322014 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4871273
Z variance train             0.012713909
KL Divergence                17.022402
KL Loss                      1.7022402
QF Loss                      115.58348
VF Loss                      43.44953
Policy Loss                  -1176.1079
Q Predictions Mean           1175.7273
Q Predictions Std            456.0505
Q Predictions Max            1574.8081
Q Predictions Min            1.9289991
V Predictions Mean           1178.509
V Predictions Std            457.65192
V Predictions Max            1574.8011
V Predictions Min            3.9673223
Log Pis Mean                 -0.3994678
Log Pis Std                  1.930398
Log Pis Max                  5.8722205
Log Pis Min                  -4.4438696
Policy mu Mean               0.06403878
Policy mu Std                0.87384665
Policy mu Max                2.3081973
Policy mu Min                -2.8706715
Policy log std Mean          -0.42691267
Policy log std Std           0.16201887
Policy log std Max           -0.069063395
Policy log std Min           -0.87844616
Z mean eval                  1.4713217
Z variance eval              0.012739782
total_rewards                [ 726.48717519 1185.43780971  930.49255397  674.89402248 1937.24836521
  839.588512   1446.42244187  741.88282831  798.04166929  868.55465932]
total_rewards_mean           1014.9050037348812
total_rewards_std            380.2168981429717
total_rewards_max            1937.248365207779
total_rewards_min            674.8940224813178
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               33.021322812885046
(Previous) Eval Time (s)     12.990470195189118
Sample Time (s)              23.796080419328064
Epoch Time (s)               69.80787342740223
Total Train Time (s)         21575.81859562872
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:20.202270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #341 | Epoch Duration: 65.88010931015015
2020-01-11 06:02:20.202455 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4728541
Z variance train             0.012766527
KL Divergence                16.81306
KL Loss                      1.6813061
QF Loss                      117.39395
VF Loss                      88.0074
Policy Loss                  -1137.4474
Q Predictions Mean           1135.7972
Q Predictions Std            425.34467
Q Predictions Max            1467.3403
Q Predictions Min            1.6714544
V Predictions Mean           1130.3411
V Predictions Std            424.23383
V Predictions Max            1457.1619
V Predictions Min            0.39284682
Log Pis Mean                 -0.21051309
Log Pis Std                  1.9560198
Log Pis Max                  8.716227
Log Pis Min                  -4.738209
Policy mu Mean               0.041725278
Policy mu Std                0.86499673
Policy mu Max                2.3963401
Policy mu Min                -2.7890375
Policy log std Mean          -0.40369663
Policy log std Std           0.14739187
Policy log std Max           -0.053801373
Policy log std Min           -1.1102594
Z mean eval                  1.4602517
Z variance eval              0.016133677
total_rewards                [1630.46501953 1689.6890263   949.65070604  695.72481126  790.7494849
 1408.93985473  178.24763354 1652.42153801  806.62306734  850.88505643]
total_rewards_mean           1065.3396198075407
total_rewards_std            479.2870933936163
total_rewards_max            1689.6890262952359
total_rewards_min            178.24763353759107
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               32.49928934779018
(Previous) Eval Time (s)     9.062374830711633
Sample Time (s)              23.525271030608565
Epoch Time (s)               65.08693520911038
Total Train Time (s)         21642.014698375016
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:03:26.401802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #342 | Epoch Duration: 66.19921684265137
2020-01-11 06:03:26.401975 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #342 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4611452
Z variance train             0.016133748
KL Divergence                16.148922
KL Loss                      1.6148922
QF Loss                      110.856125
VF Loss                      42.381523
Policy Loss                  -1095.4838
Q Predictions Mean           1093.3011
Q Predictions Std            427.59503
Q Predictions Max            1432.7792
Q Predictions Min            5.6671243
V Predictions Mean           1096.1497
V Predictions Std            427.48306
V Predictions Max            1436.3514
V Predictions Min            3.41836
Log Pis Mean                 -0.18663257
Log Pis Std                  2.2206862
Log Pis Max                  8.295807
Log Pis Min                  -4.827225
Policy mu Mean               0.13551252
Policy mu Std                0.9242849
Policy mu Max                2.084946
Policy mu Min                -2.9524524
Policy log std Mean          -0.40232107
Policy log std Std           0.16048865
Policy log std Max           -0.0752254
Policy log std Min           -1.1399877
Z mean eval                  1.4458637
Z variance eval              0.014524418
total_rewards                [1971.05531907  912.33514584  920.82165196  978.16883364  830.569243
 1817.85193932  866.25636204 1044.19476142  974.12337873  803.30932573]
total_rewards_mean           1111.8685960748055
total_rewards_std            398.6250715479857
total_rewards_max            1971.0553190700693
total_rewards_min            803.3093257268097
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               32.49241023370996
(Previous) Eval Time (s)     10.17426183493808
Sample Time (s)              22.774236257188022
Epoch Time (s)               65.44090832583606
Total Train Time (s)         21707.087586553767
Epoch                        343
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:31.478709 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #343 | Epoch Duration: 65.07659196853638
2020-01-11 06:04:31.478896 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4451759
Z variance train             0.014503749
KL Divergence                16.327284
KL Loss                      1.6327285
QF Loss                      310.6276
VF Loss                      81.465126
Policy Loss                  -1206.591
Q Predictions Mean           1207.6462
Q Predictions Std            386.35577
Q Predictions Max            1510.4973
Q Predictions Min            2.294546
V Predictions Mean           1207.85
V Predictions Std            386.31317
V Predictions Max            1505.2377
V Predictions Min            1.5022751
Log Pis Mean                 -0.32046223
Log Pis Std                  1.9232697
Log Pis Max                  6.089832
Log Pis Min                  -4.789469
Policy mu Mean               -0.053309698
Policy mu Std                0.89369285
Policy mu Max                2.2922242
Policy mu Min                -2.6569757
Policy log std Mean          -0.42028412
Policy log std Std           0.15042582
Policy log std Max           -0.07594189
Policy log std Min           -0.95833904
Z mean eval                  1.4162462
Z variance eval              0.015745092
total_rewards                [ 863.86000237  918.56223578 1067.07390913 1823.33066865 1351.61037369
 1270.28519126 1038.12299502  710.76924267 1079.48322439  821.00554294]
total_rewards_mean           1094.4103385899177
total_rewards_std            306.3582411408825
total_rewards_max            1823.3306686515948
total_rewards_min            710.7692426672671
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               33.03937710635364
(Previous) Eval Time (s)     9.809671472758055
Sample Time (s)              23.47580903675407
Epoch Time (s)               66.32485761586577
Total Train Time (s)         21774.8300850112
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:39.225401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #344 | Epoch Duration: 67.74636483192444
2020-01-11 06:05:39.225575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #344 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4122037
Z variance train             0.015736928
KL Divergence                16.341373
KL Loss                      1.6341374
QF Loss                      115.53612
VF Loss                      75.40083
Policy Loss                  -1122.6793
Q Predictions Mean           1123.5679
Q Predictions Std            444.237
Q Predictions Max            1473.9495
Q Predictions Min            -2.7950654
V Predictions Mean           1128.3672
V Predictions Std            443.76285
V Predictions Max            1478.8538
V Predictions Min            5.5414667
Log Pis Mean                 -0.3081239
Log Pis Std                  2.1204758
Log Pis Max                  6.489958
Log Pis Min                  -7.7230663
Policy mu Mean               -0.17391276
Policy mu Std                0.87321407
Policy mu Max                2.167072
Policy mu Min                -2.8711767
Policy log std Mean          -0.38934204
Policy log std Std           0.16488999
Policy log std Max           -0.0657357
Policy log std Min           -1.0900145
Z mean eval                  1.4298737
Z variance eval              0.015029987
total_rewards                [778.82861778 831.22385316 789.95861423 887.15001299 765.33788719
 674.30494387 812.55646215 650.04769826 816.92888455 759.70572956]
total_rewards_mean           776.6042703739115
total_rewards_std            67.2307898792881
total_rewards_max            887.1500129881586
total_rewards_min            650.0476982565907
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               32.775759282987565
(Previous) Eval Time (s)     11.230856106150895
Sample Time (s)              23.551350858528167
Epoch Time (s)               67.55796624766663
Total Train Time (s)         21838.374322231393
Epoch                        345
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:42.773601 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #345 | Epoch Duration: 63.54787850379944
2020-01-11 06:06:42.773796 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4355867
Z variance train             0.01506131
KL Divergence                16.826693
KL Loss                      1.6826693
QF Loss                      291.8238
VF Loss                      180.57576
Policy Loss                  -1186.8544
Q Predictions Mean           1180.8467
Q Predictions Std            454.4019
Q Predictions Max            1548.8297
Q Predictions Min            1.0695996
V Predictions Mean           1178.0745
V Predictions Std            447.43002
V Predictions Max            1538.3331
V Predictions Min            1.5754279
Log Pis Mean                 -0.60700214
Log Pis Std                  2.1960576
Log Pis Max                  11.604984
Log Pis Min                  -7.7055035
Policy mu Mean               -0.103729725
Policy mu Std                0.84719473
Policy mu Max                2.2916818
Policy mu Min                -2.9587572
Policy log std Mean          -0.38232636
Policy log std Std           0.16614631
Policy log std Max           0.09141764
Policy log std Min           -1.3644549
Z mean eval                  1.4276264
Z variance eval              0.017527133
total_rewards                [ 769.12624758  802.51157466  860.3169468   967.5415869   863.07735512
 3122.79793436  833.09472632 1132.01072269 2286.16505247 1136.06564123]
total_rewards_mean           1277.2707788129876
total_rewards_std            747.470126946978
total_rewards_max            3122.797934356013
total_rewards_min            769.1262475835217
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               33.016463454812765
(Previous) Eval Time (s)     7.220419245772064
Sample Time (s)              23.7471076361835
Epoch Time (s)               63.98399033676833
Total Train Time (s)         21906.377982856706
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:50.780997 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #346 | Epoch Duration: 68.00705695152283
2020-01-11 06:07:50.781181 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4268042
Z variance train             0.017530581
KL Divergence                16.180958
KL Loss                      1.6180958
QF Loss                      1698.221
VF Loss                      165.70963
Policy Loss                  -1186.26
Q Predictions Mean           1184.0474
Q Predictions Std            411.82135
Q Predictions Max            1522.3182
Q Predictions Min            -2.4355605
V Predictions Mean           1188.6545
V Predictions Std            410.64435
V Predictions Max            1522.201
V Predictions Min            0.517406
Log Pis Mean                 -0.36377847
Log Pis Std                  2.1412728
Log Pis Max                  9.711772
Log Pis Min                  -5.0484924
Policy mu Mean               -0.07053819
Policy mu Std                0.89297897
Policy mu Max                2.3326805
Policy mu Min                -2.9344857
Policy log std Mean          -0.40590253
Policy log std Std           0.16602865
Policy log std Max           -0.01987192
Policy log std Min           -1.0702031
Z mean eval                  1.4068792
Z variance eval              0.017373761
total_rewards                [1362.7931216  3049.93756399  781.05924424 2903.86164133 1906.52966511
  782.91312599 1985.72630109  798.89536291  962.20466218  786.45708277]
total_rewards_mean           1532.0377771207127
total_rewards_std            842.8461503571189
total_rewards_max            3049.937563988684
total_rewards_min            781.0592442387351
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               33.109361737035215
(Previous) Eval Time (s)     11.243157627992332
Sample Time (s)              22.11734822811559
Epoch Time (s)               66.46986759314314
Total Train Time (s)         21976.85018099891
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:01.257506 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #347 | Epoch Duration: 70.47616505622864
2020-01-11 06:09:01.257868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.409136
Z variance train             0.017367046
KL Divergence                15.937949
KL Loss                      1.593795
QF Loss                      156.26498
VF Loss                      61.081024
Policy Loss                  -1174.9822
Q Predictions Mean           1171.4297
Q Predictions Std            369.3367
Q Predictions Max            1488.1101
Q Predictions Min            4.60246
V Predictions Mean           1172.1453
V Predictions Std            369.6123
V Predictions Max            1493.0112
V Predictions Min            6.0805745
Log Pis Mean                 -0.30929053
Log Pis Std                  1.9905344
Log Pis Max                  6.3324213
Log Pis Min                  -4.9931903
Policy mu Mean               0.0444781
Policy mu Std                0.872566
Policy mu Max                2.2694957
Policy mu Min                -2.7183523
Policy log std Mean          -0.42067456
Policy log std Std           0.16246516
Policy log std Max           -0.035320505
Policy log std Min           -1.287009
Z mean eval                  1.4077519
Z variance eval              0.013755958
total_rewards                [1273.1643126  2629.50879639  660.1466746   788.67897505 1305.48187359
 1603.63476968 1301.88474755  811.11306148 1253.7328131  1411.62981667]
total_rewards_mean           1303.897584070901
total_rewards_std            527.7180435184998
total_rewards_max            2629.508796392889
total_rewards_min            660.1466746011404
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               33.60612944327295
(Previous) Eval Time (s)     15.249139534309506
Sample Time (s)              22.30701728956774
Epoch Time (s)               71.1622862671502
Total Train Time (s)         22045.25525957253
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:09.665586 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #348 | Epoch Duration: 68.40746760368347
2020-01-11 06:10:09.665772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4094765
Z variance train             0.013789895
KL Divergence                16.753887
KL Loss                      1.6753887
QF Loss                      134.70503
VF Loss                      134.70271
Policy Loss                  -1140.861
Q Predictions Mean           1139.6183
Q Predictions Std            419.206
Q Predictions Max            1467.4246
Q Predictions Min            1.2971529
V Predictions Mean           1135.4446
V Predictions Std            418.09964
V Predictions Max            1460.3027
V Predictions Min            1.8119714
Log Pis Mean                 -0.51132524
Log Pis Std                  1.7656056
Log Pis Max                  4.4965444
Log Pis Min                  -4.2476172
Policy mu Mean               0.009480814
Policy mu Std                0.86221075
Policy mu Max                2.584179
Policy mu Min                -2.8405955
Policy log std Mean          -0.38380137
Policy log std Std           0.1618613
Policy log std Max           0.007997498
Policy log std Min           -0.9377184
Z mean eval                  1.377716
Z variance eval              0.01747067
total_rewards                [2928.13546947 1020.16676531 3095.99855205 2050.60790339 1562.15357264
 1462.67841634 2289.14816578  870.96253997  814.10665054  732.90194017]
total_rewards_mean           1682.6859975650484
total_rewards_std            828.7965732156101
total_rewards_max            3095.998552045175
total_rewards_min            732.9019401725274
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               32.7000956046395
(Previous) Eval Time (s)     12.493986246176064
Sample Time (s)              23.79105949215591
Epoch Time (s)               68.98514134297147
Total Train Time (s)         22117.87758236006
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:11:22.291992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #349 | Epoch Duration: 72.62607026100159
2020-01-11 06:11:22.292207 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3774213
Z variance train             0.0174087
KL Divergence                16.333172
KL Loss                      1.6333172
QF Loss                      966.963
VF Loss                      104.56747
Policy Loss                  -1059.4675
Q Predictions Mean           1056.3367
Q Predictions Std            428.2496
Q Predictions Max            1422.5409
Q Predictions Min            -3.9107318
V Predictions Mean           1061.7571
V Predictions Std            426.58688
V Predictions Max            1421.606
V Predictions Min            6.699667
Log Pis Mean                 -0.26162642
Log Pis Std                  2.0570643
Log Pis Max                  9.149731
Log Pis Min                  -5.0612645
Policy mu Mean               0.11344361
Policy mu Std                0.8959168
Policy mu Max                2.327716
Policy mu Min                -2.8453362
Policy log std Mean          -0.40552115
Policy log std Std           0.16680034
Policy log std Max           -0.0053721964
Policy log std Min           -1.5411086
Z mean eval                  1.3979698
Z variance eval              0.015003431
total_rewards                [ 839.22003826 2463.67299774  711.62318736 1582.03456247  926.82757533
  699.92819424  768.08568106 2167.94906857 1923.82041208 2403.81513046]
total_rewards_mean           1448.697684756788
total_rewards_std            701.0168172059279
total_rewards_max            2463.6729977364334
total_rewards_min            699.9281942389591
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               32.44737457903102
(Previous) Eval Time (s)     16.134576288051903
Sample Time (s)              22.633541465271264
Epoch Time (s)               71.21549233235419
Total Train Time (s)         22186.11601352645
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:30.534406 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #350 | Epoch Duration: 68.2420289516449
2020-01-11 06:12:30.534600 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4001787
Z variance train             0.014936505
KL Divergence                16.824806
KL Loss                      1.6824807
QF Loss                      188.39316
VF Loss                      100.303696
Policy Loss                  -1210.8469
Q Predictions Mean           1207.3649
Q Predictions Std            426.3105
Q Predictions Max            1540.4847
Q Predictions Min            -36.769344
V Predictions Mean           1209.9895
V Predictions Std            423.8328
V Predictions Max            1540.1224
V Predictions Min            -4.785091
Log Pis Mean                 -0.6387259
Log Pis Std                  1.9174501
Log Pis Max                  7.149114
Log Pis Min                  -4.9883695
Policy mu Mean               0.04532987
Policy mu Std                0.85855854
Policy mu Max                2.757329
Policy mu Min                -2.8366227
Policy log std Mean          -0.399317
Policy log std Std           0.16329406
Policy log std Max           0.10760042
Policy log std Min           -1.0105021
Z mean eval                  1.3735117
Z variance eval              0.011116468
total_rewards                [ 651.02683771  850.38837721 1901.90583577 2453.29684551 2498.33495577
 3026.06618035 1229.61724776 1381.43340636  928.48372832  799.96812365]
total_rewards_mean           1572.052153839502
total_rewards_std            799.4078906136232
total_rewards_max            3026.0661803469566
total_rewards_min            651.026837706576
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               32.53839502763003
(Previous) Eval Time (s)     13.160787435248494
Sample Time (s)              22.14373946748674
Epoch Time (s)               67.84292193036526
Total Train Time (s)         22255.69242018694
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:40.115427 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #351 | Epoch Duration: 69.58067870140076
2020-01-11 06:13:40.115617 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3777399
Z variance train             0.011092724
KL Divergence                17.739025
KL Loss                      1.7739025
QF Loss                      393.8756
VF Loss                      88.76771
Policy Loss                  -1166.4783
Q Predictions Mean           1160.6199
Q Predictions Std            375.3042
Q Predictions Max            1460.2709
Q Predictions Min            -0.00048571825
V Predictions Mean           1161.8257
V Predictions Std            374.10526
V Predictions Max            1456.5201
V Predictions Min            2.1271424
Log Pis Mean                 -0.3152327
Log Pis Std                  2.0752492
Log Pis Max                  7.0851316
Log Pis Min                  -7.8914375
Policy mu Mean               0.036338907
Policy mu Std                0.90620404
Policy mu Max                3.1936023
Policy mu Min                -2.9543836
Policy log std Mean          -0.41760126
Policy log std Std           0.16957945
Policy log std Max           -0.08475706
Policy log std Min           -1.1724659
Z mean eval                  1.3879149
Z variance eval              0.011940147
total_rewards                [ 982.91623684 1897.77114786 2527.77747186 2201.10520654  844.81238132
 1020.33066444  810.60503808 3005.48683838  766.25695024  793.87062186]
total_rewards_mean           1485.093255741239
total_rewards_std            800.5846313269953
total_rewards_max            3005.486838375102
total_rewards_min            766.2569502357379
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               33.0195273081772
(Previous) Eval Time (s)     14.898216285277158
Sample Time (s)              23.08788240235299
Epoch Time (s)               71.00562599580735
Total Train Time (s)         22326.23724842863
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:50.665058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #352 | Epoch Duration: 70.54928779602051
2020-01-11 06:14:50.665309 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3872485
Z variance train             0.011940693
KL Divergence                17.12626
KL Loss                      1.7126261
QF Loss                      92.06914
VF Loss                      239.7478
Policy Loss                  -1226.8202
Q Predictions Mean           1227.1709
Q Predictions Std            360.6089
Q Predictions Max            1527.3909
Q Predictions Min            -11.276768
V Predictions Mean           1227.4491
V Predictions Std            358.4411
V Predictions Max            1537.051
V Predictions Min            -1.4232101
Log Pis Mean                 -0.25806838
Log Pis Std                  1.9409862
Log Pis Max                  5.277231
Log Pis Min                  -4.7421594
Policy mu Mean               -0.060442265
Policy mu Std                0.8982974
Policy mu Max                2.8767996
Policy mu Min                -2.8020654
Policy log std Mean          -0.40476382
Policy log std Std           0.1545768
Policy log std Max           -0.054648876
Policy log std Min           -0.9816627
Z mean eval                  1.3809812
Z variance eval              0.010759893
total_rewards                [ 853.23754538 1026.01395738 1339.79880286  991.50078879 1789.9034055
 1208.59323818 1022.16803838  845.9307152   852.11160459  761.05054085]
total_rewards_mean           1069.030863710738
total_rewards_std            293.38608055655584
total_rewards_max            1789.9034055043326
total_rewards_min            761.0505408469899
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               33.06505060987547
(Previous) Eval Time (s)     14.441547592170537
Sample Time (s)              22.552813629619777
Epoch Time (s)               70.05941183166578
Total Train Time (s)         22391.13336600922
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:55.563277 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #353 | Epoch Duration: 64.89766430854797
2020-01-11 06:15:55.563480 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3809017
Z variance train             0.010772752
KL Divergence                17.155521
KL Loss                      1.7155522
QF Loss                      149.51877
VF Loss                      88.463356
Policy Loss                  -1152.4663
Q Predictions Mean           1150.2019
Q Predictions Std            412.34628
Q Predictions Max            1487.102
Q Predictions Min            2.8766298
V Predictions Mean           1152.4209
V Predictions Std            412.23016
V Predictions Max            1467.8257
V Predictions Min            2.999277
Log Pis Mean                 -0.36492395
Log Pis Std                  2.0282123
Log Pis Max                  7.655431
Log Pis Min                  -4.6260276
Policy mu Mean               0.09687772
Policy mu Std                0.8856161
Policy mu Max                2.283509
Policy mu Min                -2.6346786
Policy log std Mean          -0.41017365
Policy log std Std           0.1651703
Policy log std Max           0.10048142
Policy log std Min           -0.9528809
Z mean eval                  1.3479027
Z variance eval              0.016766544
total_rewards                [1106.701829   1588.08686593  918.26299183 2247.5810092  1383.40759802
 1379.27697335 1672.95500612 1874.54473514 2917.47155214 1261.41695379]
total_rewards_mean           1634.9705514516863
total_rewards_std            560.5425998848458
total_rewards_max            2917.4715521422045
total_rewards_min            918.2629918306286
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               34.393181235995144
(Previous) Eval Time (s)     9.27944247610867
Sample Time (s)              23.410208912100643
Epoch Time (s)               67.08283262420446
Total Train Time (s)         22465.60461803805
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:10.038338 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #354 | Epoch Duration: 74.47468495368958
2020-01-11 06:17:10.038589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3480031
Z variance train             0.016773593
KL Divergence                15.644676
KL Loss                      1.5644677
QF Loss                      434.50812
VF Loss                      121.17159
Policy Loss                  -1157.016
Q Predictions Mean           1156.6003
Q Predictions Std            453.3451
Q Predictions Max            1505.9441
Q Predictions Min            0.17989641
V Predictions Mean           1159.384
V Predictions Std            451.8837
V Predictions Max            1513.1692
V Predictions Min            4.959029
Log Pis Mean                 -0.16992694
Log Pis Std                  2.167166
Log Pis Max                  13.332423
Log Pis Min                  -4.0677047
Policy mu Mean               -0.10956609
Policy mu Std                0.91892093
Policy mu Max                1.9710428
Policy mu Min                -3.5331686
Policy log std Mean          -0.40486884
Policy log std Std           0.17135246
Policy log std Max           0.14256358
Policy log std Min           -1.343232
Z mean eval                  1.3520688
Z variance eval              0.017605942
total_rewards                [1237.86229924 2770.10077665 1584.08914263  887.79870401  817.19117119
 1091.16967527 2814.73163826 2866.64040599  810.29456455  809.99293443]
total_rewards_mean           1568.9871312220082
total_rewards_std            848.3831725263374
total_rewards_max            2866.6404059903534
total_rewards_min            809.9929344267805
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               35.029075247235596
(Previous) Eval Time (s)     16.67093777190894
Sample Time (s)              24.22453672485426
Epoch Time (s)               75.9245497439988
Total Train Time (s)         22540.105370652862
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:18:24.545301 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #355 | Epoch Duration: 74.50649404525757
2020-01-11 06:18:24.545703 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3507254
Z variance train             0.01762876
KL Divergence                15.157396
KL Loss                      1.5157397
QF Loss                      383.23987
VF Loss                      48.52217
Policy Loss                  -1130.926
Q Predictions Mean           1128.6799
Q Predictions Std            441.46384
Q Predictions Max            1507.044
Q Predictions Min            0.8469238
V Predictions Mean           1131.301
V Predictions Std            438.5912
V Predictions Max            1499.5293
V Predictions Min            1.0093384
Log Pis Mean                 -0.403218
Log Pis Std                  2.12873
Log Pis Max                  11.33509
Log Pis Min                  -6.310993
Policy mu Mean               0.025091866
Policy mu Std                0.9186582
Policy mu Max                2.6680422
Policy mu Min                -3.0987558
Policy log std Mean          -0.40044752
Policy log std Std           0.16667466
Policy log std Max           -0.053123623
Policy log std Min           -0.9983929
Z mean eval                  1.3286248
Z variance eval              0.020781647
total_rewards                [2025.03573199 2754.99603251 2762.0899071   786.12565236  837.49191101
  835.27531116 1018.3596203  1411.97004124  792.45590484  991.09500853]
total_rewards_mean           1421.489512103311
total_rewards_std            759.7125547256655
total_rewards_max            2762.0899071037456
total_rewards_min            786.1256523641816
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               35.905920998193324
(Previous) Eval Time (s)     15.25248290784657
Sample Time (s)              23.21044586552307
Epoch Time (s)               74.36884977156296
Total Train Time (s)         22613.466118576005
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:37.908409 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #356 | Epoch Duration: 73.36246156692505
2020-01-11 06:19:37.908616 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3291395
Z variance train             0.020872977
KL Divergence                14.85067
KL Loss                      1.485067
QF Loss                      176.97455
VF Loss                      45.87792
Policy Loss                  -1142.5398
Q Predictions Mean           1139.7123
Q Predictions Std            446.37595
Q Predictions Max            1501.9912
Q Predictions Min            -2.047804
V Predictions Mean           1142.9651
V Predictions Std            446.09143
V Predictions Max            1498.6436
V Predictions Min            4.051429
Log Pis Mean                 -0.6373395
Log Pis Std                  1.8904787
Log Pis Max                  5.3809705
Log Pis Min                  -4.742097
Policy mu Mean               -0.012677923
Policy mu Std                0.816369
Policy mu Max                2.0261183
Policy mu Min                -2.802599
Policy log std Mean          -0.379704
Policy log std Std           0.16398498
Policy log std Max           -0.09122458
Policy log std Min           -0.9078932
Z mean eval                  1.3660784
Z variance eval              0.021743143
total_rewards                [2837.80002584 2974.48673306 2990.52892444 1112.13911359 2850.68825964
 1103.54464286 2932.92481166 2850.17512556 2856.24822005 2137.60936094]
total_rewards_mean           2464.6145217650123
total_rewards_std            716.5792184368687
total_rewards_max            2990.528924440484
total_rewards_min            1103.5446428646662
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               34.6328856558539
(Previous) Eval Time (s)     14.245734992902726
Sample Time (s)              24.82456513494253
Epoch Time (s)               73.70318578369915
Total Train Time (s)         22698.54998669168
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:21:02.996440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #357 | Epoch Duration: 85.08762240409851
2020-01-11 06:21:02.996696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3692803
Z variance train             0.021802872
KL Divergence                14.872384
KL Loss                      1.4872384
QF Loss                      154.29922
VF Loss                      151.59813
Policy Loss                  -1239.0471
Q Predictions Mean           1235.6344
Q Predictions Std            395.8768
Q Predictions Max            1511.91
Q Predictions Min            -20.2793
V Predictions Mean           1229.5099
V Predictions Std            394.635
V Predictions Max            1506.9846
V Predictions Min            -6.2424846
Log Pis Mean                 -0.27436328
Log Pis Std                  2.1193666
Log Pis Max                  6.9000382
Log Pis Min                  -4.186369
Policy mu Mean               -0.04707479
Policy mu Std                0.9193314
Policy mu Max                2.527113
Policy mu Min                -2.7709403
Policy log std Mean          -0.3963262
Policy log std Std           0.15202017
Policy log std Max           -0.09182878
Policy log std Min           -0.954612
Z mean eval                  1.3278666
Z variance eval              0.020238923
total_rewards                [1884.99477537 1972.84449447 1424.05226072 1327.80050362  974.26570193
 2901.45333865  871.9541906  1605.24835846 1500.57315438 1063.9890566 ]
total_rewards_mean           1552.717583479522
total_rewards_std            567.0559780229212
total_rewards_max            2901.4533386505755
total_rewards_min            871.9541905961498
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               35.272150326985866
(Previous) Eval Time (s)     25.629762563854456
Sample Time (s)              23.51165440073237
Epoch Time (s)               84.41356729157269
Total Train Time (s)         22773.042794826906
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:17.493161 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #358 | Epoch Duration: 74.4962911605835
2020-01-11 06:22:17.493364 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3277206
Z variance train             0.020130819
KL Divergence                15.091
KL Loss                      1.5091
QF Loss                      307.4583
VF Loss                      56.60963
Policy Loss                  -1181.7606
Q Predictions Mean           1179.0071
Q Predictions Std            446.58594
Q Predictions Max            1568.6857
Q Predictions Min            3.8763924
V Predictions Mean           1183.7626
V Predictions Std            443.5602
V Predictions Max            1570.5039
V Predictions Min            1.3462621
Log Pis Mean                 -0.18159695
Log Pis Std                  2.179462
Log Pis Max                  7.796667
Log Pis Min                  -5.8849087
Policy mu Mean               -0.09965516
Policy mu Std                0.93931407
Policy mu Max                2.7009914
Policy mu Min                -3.684736
Policy log std Mean          -0.40079245
Policy log std Std           0.17393783
Policy log std Max           0.01956287
Policy log std Min           -1.1676186
Z mean eval                  1.3496187
Z variance eval              0.021656903
total_rewards                [2102.35261537 2247.24742812 2238.20726919 2383.25455723 2633.4142837
 2826.55038018 1787.94949373 1474.55574057 2947.01089614 2548.64928923]
total_rewards_mean           2318.9191953458762
total_rewards_std            431.4442638894203
total_rewards_max            2947.0108961372084
total_rewards_min            1474.5557405739996
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               34.90488436166197
(Previous) Eval Time (s)     15.712082272861153
Sample Time (s)              24.47318290406838
Epoch Time (s)               75.0901495385915
Total Train Time (s)         22855.54644455947
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:40.000734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #359 | Epoch Duration: 82.50722670555115
2020-01-11 06:23:40.000923 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3484102
Z variance train             0.021690687
KL Divergence                15.156212
KL Loss                      1.5156212
QF Loss                      454.43
VF Loss                      110.42781
Policy Loss                  -1227.3816
Q Predictions Mean           1221.9344
Q Predictions Std            366.91113
Q Predictions Max            1499.0109
Q Predictions Min            -0.6052664
V Predictions Mean           1224.4658
V Predictions Std            366.74625
V Predictions Max            1489.5375
V Predictions Min            4.205428
Log Pis Mean                 -0.4552632
Log Pis Std                  1.936161
Log Pis Max                  6.0274696
Log Pis Min                  -4.9139104
Policy mu Mean               -0.10383437
Policy mu Std                0.86517817
Policy mu Max                2.56727
Policy mu Min                -2.6678667
Policy log std Mean          -0.39404523
Policy log std Std           0.17163353
Policy log std Max           0.0070236325
Policy log std Min           -1.1501696
Z mean eval                  1.3076853
Z variance eval              0.019338753
total_rewards                [ 815.80656778 1876.01833213  965.47659336 2868.11983932 1795.89966399
 2266.82575381 2296.60148611 3130.88595303 2094.40967686  788.36728555]
total_rewards_mean           1889.8411151942298
total_rewards_std            779.5448612074244
total_rewards_max            3130.8859530250643
total_rewards_min            788.3672855517987
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               34.7873713709414
(Previous) Eval Time (s)     23.128770464099944
Sample Time (s)              23.849695664830506
Epoch Time (s)               81.76583749987185
Total Train Time (s)         22933.653125583194
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:58.114076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #360 | Epoch Duration: 78.11301374435425
2020-01-11 06:24:58.114271 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3098543
Z variance train             0.019377645
KL Divergence                15.363179
KL Loss                      1.536318
QF Loss                      139.47421
VF Loss                      87.51271
Policy Loss                  -1210.9812
Q Predictions Mean           1209.4635
Q Predictions Std            409.54422
Q Predictions Max            1520.8486
Q Predictions Min            7.5225563
V Predictions Mean           1209.9343
V Predictions Std            410.99414
V Predictions Max            1520.7014
V Predictions Min            4.8960204
Log Pis Mean                 -0.37831402
Log Pis Std                  1.9530278
Log Pis Max                  5.5086794
Log Pis Min                  -5.9783816
Policy mu Mean               0.043186378
Policy mu Std                0.87137145
Policy mu Max                2.378407
Policy mu Min                -3.0182383
Policy log std Mean          -0.40878877
Policy log std Std           0.16351534
Policy log std Max           -0.09378831
Policy log std Min           -1.1009606
Z mean eval                  1.3070767
Z variance eval              0.018554814
total_rewards                [2885.2289531  1203.85836828 2890.73839434 1969.58586037  822.42809387
 2189.50543755 2952.56589048 1127.75804765 2872.67176608 2919.41962186]
total_rewards_mean           2183.3760433579228
total_rewards_std            810.7532379163748
total_rewards_max            2952.5658904792213
total_rewards_min            822.4280938687963
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               35.65914657432586
(Previous) Eval Time (s)     19.475570197682828
Sample Time (s)              24.775745268911123
Epoch Time (s)               79.91046204091981
Total Train Time (s)         23016.866249842104
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:26:21.330185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #361 | Epoch Duration: 83.21573686599731
2020-01-11 06:26:21.330528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3094422
Z variance train             0.018644677
KL Divergence                14.910905
KL Loss                      1.4910905
QF Loss                      141.74506
VF Loss                      77.26355
Policy Loss                  -1132.113
Q Predictions Mean           1129.4424
Q Predictions Std            424.4736
Q Predictions Max            1450.1902
Q Predictions Min            1.1157862
V Predictions Mean           1127.1272
V Predictions Std            423.58783
V Predictions Max            1445.9384
V Predictions Min            0.49820113
Log Pis Mean                 -0.23298036
Log Pis Std                  2.03598
Log Pis Max                  8.178014
Log Pis Min                  -4.9573727
Policy mu Mean               -0.016040718
Policy mu Std                0.88193345
Policy mu Max                2.3112104
Policy mu Min                -2.6641095
Policy log std Mean          -0.37739134
Policy log std Std           0.15065786
Policy log std Max           -0.08639248
Policy log std Min           -0.9237689
Z mean eval                  1.306853
Z variance eval              0.032050967
total_rewards                [2930.36444284 1274.2816517  2930.48140137 2949.21955091 3006.10072782
 2899.47027199 2038.00565155 1574.43797215 2972.31663128 2906.33892869]
total_rewards_mean           2548.101723030668
total_rewards_std            626.544996207926
total_rewards_max            3006.100727817922
total_rewards_min            1274.2816517024216
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               34.863441521301866
(Previous) Eval Time (s)     22.780388216022402
Sample Time (s)              25.502702981699258
Epoch Time (s)               83.14653271902353
Total Train Time (s)         23103.41349985171
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:47.880176 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #362 | Epoch Duration: 86.5494396686554
2020-01-11 06:27:47.880373 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3094933
Z variance train             0.032099076
KL Divergence                14.055868
KL Loss                      1.4055868
QF Loss                      146.46954
VF Loss                      75.349464
Policy Loss                  -1086.1217
Q Predictions Mean           1086.1539
Q Predictions Std            376.85452
Q Predictions Max            1395.4415
Q Predictions Min            5.3616114
V Predictions Mean           1088.2848
V Predictions Std            376.60944
V Predictions Max            1396.5397
V Predictions Min            -1.4809322
Log Pis Mean                 -0.7187807
Log Pis Std                  1.7016928
Log Pis Max                  5.8338118
Log Pis Min                  -4.87833
Policy mu Mean               0.005645352
Policy mu Std                0.801383
Policy mu Max                2.224031
Policy mu Min                -2.539369
Policy log std Mean          -0.38609323
Policy log std Std           0.16203897
Policy log std Max           -0.073973745
Policy log std Min           -1.0689658
Z mean eval                  1.3129203
Z variance eval              0.02072228
total_rewards                [2949.05681046 2639.04789524 2579.45057726 3016.22271525 2959.49706258
 2495.82302345 2696.41121619 2906.77035214 1661.05308759 2331.03874047]
total_rewards_mean           2623.43714806485
total_rewards_std            385.8745442353132
total_rewards_max            3016.222715250866
total_rewards_min            1661.0530875885663
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               35.09339044895023
(Previous) Eval Time (s)     26.182911964133382
Sample Time (s)              24.337378789205104
Epoch Time (s)               85.61368120228872
Total Train Time (s)         23189.58795808535
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:14.059560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #363 | Epoch Duration: 86.17900609970093
2020-01-11 06:29:14.059918 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3099425
Z variance train             0.020705897
KL Divergence                14.465215
KL Loss                      1.4465215
QF Loss                      103.167076
VF Loss                      55.994408
Policy Loss                  -1153.937
Q Predictions Mean           1153.7286
Q Predictions Std            418.8419
Q Predictions Max            1478.2643
Q Predictions Min            2.9445117
V Predictions Mean           1158.2196
V Predictions Std            420.12973
V Predictions Max            1482.3717
V Predictions Min            5.630689
Log Pis Mean                 -0.42827952
Log Pis Std                  1.9327173
Log Pis Max                  6.7836943
Log Pis Min                  -6.410944
Policy mu Mean               0.023332484
Policy mu Std                0.8658477
Policy mu Max                2.5842266
Policy mu Min                -2.6613936
Policy log std Mean          -0.41540697
Policy log std Std           0.17377065
Policy log std Max           -0.024911717
Policy log std Min           -1.1539309
Z mean eval                  1.285285
Z variance eval              0.024343425
total_rewards                [2798.97273044 1421.27075745 2994.41140578 2895.89853064 1406.10189078
 2640.14640338 2738.7853435  1684.25894991 1889.47006099 2700.8146506 ]
total_rewards_mean           2317.0130723473776
total_rewards_std            605.9007277788361
total_rewards_max            2994.4114057835573
total_rewards_min            1406.1018907798075
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               33.91590176708996
(Previous) Eval Time (s)     26.747851757798344
Sample Time (s)              24.925767535343766
Epoch Time (s)               85.58952106023207
Total Train Time (s)         23270.921820751857
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:35.396825 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #364 | Epoch Duration: 81.33665704727173
2020-01-11 06:30:35.397062 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2861588
Z variance train             0.024420876
KL Divergence                14.168227
KL Loss                      1.4168228
QF Loss                      1029.2363
VF Loss                      92.84311
Policy Loss                  -1247.539
Q Predictions Mean           1243.1252
Q Predictions Std            362.1143
Q Predictions Max            1508.1849
Q Predictions Min            -3.7565336
V Predictions Mean           1245.0485
V Predictions Std            357.80658
V Predictions Max            1515.8245
V Predictions Min            -8.648117
Log Pis Mean                 -0.22342494
Log Pis Std                  2.1910026
Log Pis Max                  7.476329
Log Pis Min                  -5.2448773
Policy mu Mean               0.02333721
Policy mu Std                0.93278474
Policy mu Max                2.4873228
Policy mu Min                -3.0510066
Policy log std Mean          -0.4150765
Policy log std Std           0.16315605
Policy log std Max           0.043902844
Policy log std Min           -1.2109582
Z mean eval                  1.2605982
Z variance eval              0.019872868
total_rewards                [ 976.62215668 2096.26109944 1015.02237708 1221.8129795   882.98954744
 3135.1442208  2068.86348658 2669.69370515 1275.37651941  934.33258661]
total_rewards_mean           1627.6118678687458
total_rewards_std            767.8422997393319
total_rewards_max            3135.1442208002663
total_rewards_min            882.9895474418968
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               32.910031952895224
(Previous) Eval Time (s)     22.494619882199913
Sample Time (s)              23.201858999673277
Epoch Time (s)               78.60651083476841
Total Train Time (s)         23341.930407424923
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:46.411776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #365 | Epoch Duration: 71.01452493667603
2020-01-11 06:31:46.412055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2630259
Z variance train             0.01976568
KL Divergence                14.178238
KL Loss                      1.4178238
QF Loss                      194.18631
VF Loss                      87.33501
Policy Loss                  -1161.8607
Q Predictions Mean           1157.4827
Q Predictions Std            415.78625
Q Predictions Max            1500.2769
Q Predictions Min            -5.529807
V Predictions Mean           1160.6008
V Predictions Std            415.15436
V Predictions Max            1507.4922
V Predictions Min            0.6062472
Log Pis Mean                 -0.52859795
Log Pis Std                  2.1083574
Log Pis Max                  11.964316
Log Pis Min                  -4.626698
Policy mu Mean               0.124232285
Policy mu Std                0.8662427
Policy mu Max                2.18207
Policy mu Min                -3.5752985
Policy log std Mean          -0.3945968
Policy log std Std           0.15400693
Policy log std Max           -0.0024683475
Policy log std Min           -0.991989
Z mean eval                  1.2691485
Z variance eval              0.022046244
total_rewards                [1397.26482204 1254.49680309 3123.55688478 2271.40751703 1424.49158914
 1692.21332079 1927.15143506 2008.33973211 1728.63073197 3180.41148913]
total_rewards_mean           2000.7964325121575
total_rewards_std            644.4712624054225
total_rewards_max            3180.4114891308327
total_rewards_min            1254.4968030913997
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               33.079624156001955
(Previous) Eval Time (s)     14.902323015965521
Sample Time (s)              23.42312674690038
Epoch Time (s)               71.40507391886786
Total Train Time (s)         23417.203149566427
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:01.688999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #366 | Epoch Duration: 75.27661633491516
2020-01-11 06:33:01.689284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2706051
Z variance train             0.02209354
KL Divergence                13.837836
KL Loss                      1.3837837
QF Loss                      159.5125
VF Loss                      57.583466
Policy Loss                  -1183.8683
Q Predictions Mean           1181.6138
Q Predictions Std            368.67352
Q Predictions Max            1468.9625
Q Predictions Min            4.661851
V Predictions Mean           1183.986
V Predictions Std            367.54172
V Predictions Max            1484.511
V Predictions Min            3.0383642
Log Pis Mean                 -0.46702278
Log Pis Std                  1.9254057
Log Pis Max                  5.268526
Log Pis Min                  -5.52385
Policy mu Mean               -0.018021667
Policy mu Std                0.84912837
Policy mu Max                2.6349392
Policy mu Min                -3.0050502
Policy log std Mean          -0.3933293
Policy log std Std           0.16321258
Policy log std Max           -0.057595134
Policy log std Min           -1.1392419
Z mean eval                  1.2561197
Z variance eval              0.0144667905
total_rewards                [1289.23519896 1301.11225718 2445.70627436 1030.91476298 2922.9493077
 2185.10635101 1763.92688027 2106.04225106 3066.82986284 1244.19630415]
total_rewards_mean           1935.6019450503131
total_rewards_std            689.3751017987267
total_rewards_max            3066.829862837661
total_rewards_min            1030.9147629751126
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               33.03433510893956
(Previous) Eval Time (s)     18.773550142068416
Sample Time (s)              22.982151557691395
Epoch Time (s)               74.79003680869937
Total Train Time (s)         23492.807066450827
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:34:17.300724 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #367 | Epoch Duration: 75.61119771003723
2020-01-11 06:34:17.301025 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.252442
Z variance train             0.01448815
KL Divergence                14.8521595
KL Loss                      1.485216
QF Loss                      92.656784
VF Loss                      71.29322
Policy Loss                  -1270.2228
Q Predictions Mean           1271.4852
Q Predictions Std            314.57568
Q Predictions Max            1501.305
Q Predictions Min            -0.13455778
V Predictions Mean           1270.3862
V Predictions Std            312.82495
V Predictions Max            1500.7812
V Predictions Min            4.8285193
Log Pis Mean                 -0.5109006
Log Pis Std                  2.1598852
Log Pis Max                  11.194794
Log Pis Min                  -5.5168033
Policy mu Mean               0.073124334
Policy mu Std                0.8326256
Policy mu Max                2.2141538
Policy mu Min                -3.5736299
Policy log std Mean          -0.39055693
Policy log std Std           0.16232659
Policy log std Max           -0.05134523
Policy log std Min           -1.1642122
Z mean eval                  1.2615999
Z variance eval              0.013347271
total_rewards                [1143.52893367  814.98396981 1727.03194863  808.43229037 2928.3644842
  870.20491131 1864.69372604 1852.65079845 3060.94049624 1005.58641217]
total_rewards_mean           1607.6417970905425
total_rewards_std            799.0914529746696
total_rewards_max            3060.940496236226
total_rewards_min            808.4322903719276
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               32.76726493379101
(Previous) Eval Time (s)     19.59436800284311
Sample Time (s)              23.427661593537778
Epoch Time (s)               75.7892945301719
Total Train Time (s)         23564.719324274454
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:35:29.221517 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #368 | Epoch Duration: 71.9202651977539
2020-01-11 06:35:29.221782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2628132
Z variance train             0.013394711
KL Divergence                15.356342
KL Loss                      1.5356343
QF Loss                      132.51349
VF Loss                      228.82733
Policy Loss                  -1154.114
Q Predictions Mean           1152.1965
Q Predictions Std            436.19455
Q Predictions Max            1518.8649
Q Predictions Min            -7.69135
V Predictions Mean           1155.2073
V Predictions Std            434.14227
V Predictions Max            1534.1907
V Predictions Min            -5.2976265
Log Pis Mean                 -0.19816294
Log Pis Std                  1.9757687
Log Pis Max                  6.7661896
Log Pis Min                  -4.6543365
Policy mu Mean               -0.057391673
Policy mu Std                0.8960991
Policy mu Max                2.5009818
Policy mu Min                -2.7188673
Policy log std Mean          -0.4062027
Policy log std Std           0.18793684
Policy log std Max           0.07337153
Policy log std Min           -1.5017639
Z mean eval                  1.2587645
Z variance eval              0.011572225
total_rewards                [ 972.72761927 1751.95305019 3133.00992432 1553.5370845   778.34498927
 3002.91231736 2624.35058267 1337.90882496 2590.05040145 3017.58478895]
total_rewards_mean           2076.237958293247
total_rewards_std            851.5764750636745
total_rewards_max            3133.0099243161067
total_rewards_min            778.344989272755
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               33.09053873317316
(Previous) Eval Time (s)     15.725003141909838
Sample Time (s)              22.659103060141206
Epoch Time (s)               71.4746449352242
Total Train Time (s)         23640.850671063177
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:45.352261 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #369 | Epoch Duration: 76.13032388687134
2020-01-11 06:36:45.352428 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2586737
Z variance train             0.011551788
KL Divergence                15.796406
KL Loss                      1.5796406
QF Loss                      267.79517
VF Loss                      60.370815
Policy Loss                  -1124.0817
Q Predictions Mean           1127.0566
Q Predictions Std            383.3097
Q Predictions Max            1447.3322
Q Predictions Min            8.70988
V Predictions Mean           1125.5393
V Predictions Std            383.98334
V Predictions Max            1452.732
V Predictions Min            2.0983093
Log Pis Mean                 -0.54841936
Log Pis Std                  1.8733021
Log Pis Max                  5.8981466
Log Pis Min                  -5.5082173
Policy mu Mean               0.020905653
Policy mu Std                0.8287642
Policy mu Max                2.7327926
Policy mu Min                -2.6219792
Policy log std Mean          -0.3984172
Policy log std Std           0.18181388
Policy log std Max           -0.08802678
Policy log std Min           -1.1355741
Z mean eval                  1.2346594
Z variance eval              0.013923412
total_rewards                [2921.3233321  1160.59672941  935.424443   2866.90888788 2894.09591903
 2970.44697875 1910.47613621 1790.54115703 2210.87405368 1760.80370499]
total_rewards_mean           2142.1491342104027
total_rewards_std            716.307756482884
total_rewards_max            2970.4469787537496
total_rewards_min            935.4244430023494
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               32.96066749794409
(Previous) Eval Time (s)     20.38035613996908
Sample Time (s)              23.97468065842986
Epoch Time (s)               77.31570429634303
Total Train Time (s)         23719.70303899655
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:38:04.208671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #370 | Epoch Duration: 78.85610246658325
2020-01-11 06:38:04.208858 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2343476
Z variance train             0.013949958
KL Divergence                15.455565
KL Loss                      1.5455565
QF Loss                      85.79424
VF Loss                      50.87129
Policy Loss                  -1164.6356
Q Predictions Mean           1162.5178
Q Predictions Std            375.5102
Q Predictions Max            1460.7474
Q Predictions Min            -0.032771647
V Predictions Mean           1165.2283
V Predictions Std            373.63837
V Predictions Max            1466.5348
V Predictions Min            5.721894
Log Pis Mean                 -0.39627677
Log Pis Std                  2.137612
Log Pis Max                  6.993444
Log Pis Min                  -5.648664
Policy mu Mean               -0.14296369
Policy mu Std                0.88481563
Policy mu Max                1.9931469
Policy mu Min                -3.0254815
Policy log std Mean          -0.391534
Policy log std Std           0.18028349
Policy log std Max           -0.014410883
Policy log std Min           -1.2948049
Z mean eval                  1.2622806
Z variance eval              0.009422321
total_rewards                [2954.8764172  2801.93817756 2973.72954597 1285.04288801 3043.34837649
 2310.66779438 1808.10393596 2995.51110154 2999.77024182 1724.0643738 ]
total_rewards_mean           2489.7052852732204
total_rewards_std            624.8785338997938
total_rewards_max            3043.3483764895304
total_rewards_min            1285.0428880147872
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               32.915891837794334
(Previous) Eval Time (s)     21.920448207762092
Sample Time (s)              22.968044369015843
Epoch Time (s)               77.80438441457227
Total Train Time (s)         23800.114678115584
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:24.624672 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #371 | Epoch Duration: 80.41566324234009
2020-01-11 06:39:24.624864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2597353
Z variance train             0.009424937
KL Divergence                16.422705
KL Loss                      1.6422704
QF Loss                      284.02136
VF Loss                      42.33726
Policy Loss                  -1164.8994
Q Predictions Mean           1164.1838
Q Predictions Std            376.77383
Q Predictions Max            1464.5594
Q Predictions Min            -16.582071
V Predictions Mean           1166.6052
V Predictions Std            375.20554
V Predictions Max            1470.2084
V Predictions Min            3.3530617
Log Pis Mean                 -0.39416677
Log Pis Std                  1.93979
Log Pis Max                  5.632192
Log Pis Min                  -5.9282455
Policy mu Mean               0.020405779
Policy mu Std                0.8636769
Policy mu Max                2.5592737
Policy mu Min                -2.80366
Policy log std Mean          -0.4051609
Policy log std Std           0.17675744
Policy log std Max           0.036874503
Policy log std Min           -1.1297143
Z mean eval                  1.2177067
Z variance eval              0.011987755
total_rewards                [1387.07082806 1721.90572147 2975.22548477 2367.2128483  1983.32129887
 1215.83891508 1547.89107031 1301.13235064 2290.04980608 2249.25120609]
total_rewards_mean           1903.8899529680534
total_rewards_std            538.5923805442328
total_rewards_max            2975.2254847664335
total_rewards_min            1215.8389150807036
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               32.8065400137566
(Previous) Eval Time (s)     24.531419727951288
Sample Time (s)              22.06881119357422
Epoch Time (s)               79.40677093528211
Total Train Time (s)         23873.736510873772
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:38.250119 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #372 | Epoch Duration: 73.62511038780212
2020-01-11 06:40:38.250357 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2171679
Z variance train             0.012019503
KL Divergence                15.580651
KL Loss                      1.5580652
QF Loss                      213.34814
VF Loss                      134.10425
Policy Loss                  -1209.206
Q Predictions Mean           1209.9443
Q Predictions Std            407.83124
Q Predictions Max            1507.9589
Q Predictions Min            3.3124564
V Predictions Mean           1213.922
V Predictions Std            409.85522
V Predictions Max            1510.1978
V Predictions Min            5.306715
Log Pis Mean                 -0.46303254
Log Pis Std                  1.871872
Log Pis Max                  6.5008264
Log Pis Min                  -5.9478188
Policy mu Mean               -0.008505133
Policy mu Std                0.83893037
Policy mu Max                2.6580157
Policy mu Min                -2.6709352
Policy log std Mean          -0.39791933
Policy log std Std           0.17044419
Policy log std Max           0.006122023
Policy log std Min           -1.3245572
Z mean eval                  1.2204044
Z variance eval              0.01356619
total_rewards                [1384.70874992 2732.25056361 1383.36995779  813.58566597  844.64443166
 2821.22739758 1456.61299673 1389.5043307  2868.89902436 2462.20946372]
total_rewards_mean           1815.701258205546
total_rewards_std            775.163463874889
total_rewards_max            2868.8990243616267
total_rewards_min            813.5856659746383
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               32.99870905606076
(Previous) Eval Time (s)     18.749471307732165
Sample Time (s)              23.228878178168088
Epoch Time (s)               74.97705854196101
Total Train Time (s)         23946.83022059733
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:41:51.347481 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #373 | Epoch Duration: 73.09695935249329
2020-01-11 06:41:51.347749 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2209308
Z variance train             0.013566347
KL Divergence                15.114486
KL Loss                      1.5114486
QF Loss                      67.33978
VF Loss                      41.616867
Policy Loss                  -1173.4473
Q Predictions Mean           1170.6682
Q Predictions Std            441.56165
Q Predictions Max            1494.0964
Q Predictions Min            -2.9474826
V Predictions Mean           1172.5222
V Predictions Std            441.00153
V Predictions Max            1495.6768
V Predictions Min            -3.5119545
Log Pis Mean                 -0.6536504
Log Pis Std                  1.7595949
Log Pis Max                  5.6048822
Log Pis Min                  -4.873255
Policy mu Mean               -0.020670163
Policy mu Std                0.83686936
Policy mu Max                2.0866935
Policy mu Min                -2.844453
Policy log std Mean          -0.38393643
Policy log std Std           0.16363819
Policy log std Max           -0.054922134
Policy log std Min           -1.0072476
Z mean eval                  1.2188021
Z variance eval              0.01228894
total_rewards                [ 795.7373771  1492.53118542 2040.76423553 1246.59165008 2067.31574475
  833.70949839  786.5367665  1221.27801048 3156.11290463 2208.67099395]
total_rewards_mean           1584.9248366827294
total_rewards_std            733.3479083561875
total_rewards_max            3156.1129046252686
total_rewards_min            786.5367664987159
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               33.31541301589459
(Previous) Eval Time (s)     16.869051716756076
Sample Time (s)              23.819365406408906
Epoch Time (s)               74.00383013905957
Total Train Time (s)         24019.20646173926
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:03.727810 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #374 | Epoch Duration: 72.3799135684967
2020-01-11 06:43:03.728323 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2179472
Z variance train             0.012261172
KL Divergence                15.421425
KL Loss                      1.5421425
QF Loss                      1521.8491
VF Loss                      174.6994
Policy Loss                  -1176.4121
Q Predictions Mean           1176.5051
Q Predictions Std            429.2319
Q Predictions Max            1514.8909
Q Predictions Min            4.099381
V Predictions Mean           1179.1542
V Predictions Std            426.8168
V Predictions Max            1512.0734
V Predictions Min            -16.04995
Log Pis Mean                 -0.5858019
Log Pis Std                  1.9476129
Log Pis Max                  8.757332
Log Pis Min                  -5.0098176
Policy mu Mean               0.10179929
Policy mu Std                0.8400552
Policy mu Max                3.4247627
Policy mu Min                -2.775874
Policy log std Mean          -0.38046908
Policy log std Std           0.16998072
Policy log std Max           -0.04944189
Policy log std Min           -1.2336107
Z mean eval                  1.2135087
Z variance eval              0.015928488
total_rewards                [1895.23143792 2737.69912055  887.09996609 1285.79064916 2944.46900211
 2707.9181697  3045.07942883 2638.51613426 3158.00943517 2775.97019277]
total_rewards_mean           2407.5783536567023
total_rewards_std            740.1888996670634
total_rewards_max            3158.0094351711427
total_rewards_min            887.0999660897426
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               32.772381572052836
(Previous) Eval Time (s)     15.24476463533938
Sample Time (s)              22.39275318617001
Epoch Time (s)               70.40989939356223
Total Train Time (s)         24092.93071424635
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:17.454165 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #375 | Epoch Duration: 73.72552442550659
2020-01-11 06:44:17.454288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2136595
Z variance train             0.016012723
KL Divergence                14.157986
KL Loss                      1.4157985
QF Loss                      123.62535
VF Loss                      39.338615
Policy Loss                  -1248.0762
Q Predictions Mean           1248.6963
Q Predictions Std            434.8555
Q Predictions Max            1558.063
Q Predictions Min            -3.5473354
V Predictions Mean           1248.8201
V Predictions Std            434.9442
V Predictions Max            1561.8964
V Predictions Min            5.546673
Log Pis Mean                 -0.46440887
Log Pis Std                  2.017529
Log Pis Max                  7.508536
Log Pis Min                  -4.0491815
Policy mu Mean               -0.020786786
Policy mu Std                0.86443
Policy mu Max                2.1517546
Policy mu Min                -2.8820941
Policy log std Mean          -0.40755257
Policy log std Std           0.18223678
Policy log std Max           -0.06712891
Policy log std Min           -1.2053307
Z mean eval                  1.2067598
Z variance eval              0.01957842
total_rewards                [3013.67463721 2984.85878075  823.95892948 2859.55801692 2772.9039139
 2331.21171751 1627.52903619 2912.71439347 3088.66889781  815.70338122]
total_rewards_mean           2323.0781704450046
total_rewards_std            856.86772171369
total_rewards_max            3088.6688978070647
total_rewards_min            815.7033812164932
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               32.887973472010344
(Previous) Eval Time (s)     18.560071940999478
Sample Time (s)              22.47457612771541
Epoch Time (s)               73.92262154072523
Total Train Time (s)         24171.00972561119
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:35.538910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #376 | Epoch Duration: 78.08448266983032
2020-01-11 06:45:35.539280 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.206205
Z variance train             0.019654235
KL Divergence                13.737144
KL Loss                      1.3737144
QF Loss                      368.4651
VF Loss                      231.23466
Policy Loss                  -1229.2098
Q Predictions Mean           1224.2688
Q Predictions Std            402.20697
Q Predictions Max            1553.1588
Q Predictions Min            -5.213516
V Predictions Mean           1228.2598
V Predictions Std            399.8142
V Predictions Max            1558.289
V Predictions Min            1.2703269
Log Pis Mean                 -0.4792714
Log Pis Std                  1.9392025
Log Pis Max                  8.856272
Log Pis Min                  -4.864285
Policy mu Mean               0.03948243
Policy mu Std                0.8310673
Policy mu Max                2.51682
Policy mu Min                -2.8628051
Policy log std Mean          -0.39730415
Policy log std Std           0.1786838
Policy log std Max           -0.029470205
Policy log std Min           -1.7552395
Z mean eval                  1.2146873
Z variance eval              0.020478375
total_rewards                [1306.45912238 3055.53442078 3114.16744881  822.22875424 3018.35842365
 1194.234109   1592.30455431  920.80266236 3040.28857394 1469.14395484]
total_rewards_mean           1953.352202430191
total_rewards_std            926.4507208390299
total_rewards_max            3114.1674488091135
total_rewards_min            822.228754235313
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               33.1567621328868
(Previous) Eval Time (s)     22.721595144830644
Sample Time (s)              23.517342244740576
Epoch Time (s)               79.39569952245802
Total Train Time (s)         24246.215238235425
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:50.747866 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #377 | Epoch Duration: 75.20832538604736
2020-01-11 06:46:50.748071 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2143948
Z variance train             0.02040999
KL Divergence                14.060302
KL Loss                      1.4060302
QF Loss                      208.38434
VF Loss                      117.398056
Policy Loss                  -1210.2144
Q Predictions Mean           1208.4891
Q Predictions Std            399.04718
Q Predictions Max            1507.0269
Q Predictions Min            0.3072613
V Predictions Mean           1204.9612
V Predictions Std            399.53653
V Predictions Max            1508.0093
V Predictions Min            -3.3257122
Log Pis Mean                 -0.31272975
Log Pis Std                  2.0427496
Log Pis Max                  7.291115
Log Pis Min                  -4.7423887
Policy mu Mean               0.053167313
Policy mu Std                0.8776428
Policy mu Max                2.445887
Policy mu Min                -2.931637
Policy log std Mean          -0.41086963
Policy log std Std           0.19157885
Policy log std Max           -0.0696463
Policy log std Min           -1.5983065
Z mean eval                  1.2137492
Z variance eval              0.017652115
total_rewards                [2997.07809307 1362.09314918 3066.91822932 2998.64420351 2972.11293351
 1987.14635512 2599.04526367 1979.53199166  943.53836692 2633.77211151]
total_rewards_mean           2353.988069747179
total_rewards_std            714.5516288214423
total_rewards_max            3066.9182293201907
total_rewards_min            943.5383669219217
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               33.076872766949236
(Previous) Eval Time (s)     18.533911906182766
Sample Time (s)              21.700813364703208
Epoch Time (s)               73.31159803783521
Total Train Time (s)         24324.599597923923
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:09.136125 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #378 | Epoch Duration: 78.38791084289551
2020-01-11 06:48:09.136311 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2138046
Z variance train             0.017635256
KL Divergence                14.372492
KL Loss                      1.4372492
QF Loss                      166.09456
VF Loss                      55.438187
Policy Loss                  -1253.3195
Q Predictions Mean           1250.284
Q Predictions Std            402.93027
Q Predictions Max            1546.7737
Q Predictions Min            -4.020822
V Predictions Mean           1252.8269
V Predictions Std            403.0893
V Predictions Max            1550.212
V Predictions Min            -1.6052824
Log Pis Mean                 -0.47847226
Log Pis Std                  1.9866902
Log Pis Max                  8.069878
Log Pis Min                  -4.2295637
Policy mu Mean               -0.07861363
Policy mu Std                0.80650455
Policy mu Max                1.6808773
Policy mu Min                -3.4497352
Policy log std Mean          -0.40751132
Policy log std Std           0.18116833
Policy log std Max           -0.015536338
Policy log std Min           -1.3982205
Z mean eval                  1.2168503
Z variance eval              0.017501388
total_rewards                [3012.95261018 2891.65655752 3027.55107954 2983.49276621 3021.26530591
 2643.53051304 3068.43574643 2928.50908093 2930.03942524 2077.67405987]
total_rewards_mean           2858.510714486508
total_rewards_std            283.8383653363598
total_rewards_max            3068.4357464279756
total_rewards_min            2077.674059865046
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               33.25225745514035
(Previous) Eval Time (s)     23.6099163251929
Sample Time (s)              22.353210240602493
Epoch Time (s)               79.21538402093574
Total Train Time (s)         24406.424957387615
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:30.965135 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #379 | Epoch Duration: 81.82869911193848
2020-01-11 06:49:30.965292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2182068
Z variance train             0.017468156
KL Divergence                14.399395
KL Loss                      1.4399395
QF Loss                      3662.1074
VF Loss                      61.86804
Policy Loss                  -1241.1177
Q Predictions Mean           1244.6942
Q Predictions Std            453.10388
Q Predictions Max            1587.5663
Q Predictions Min            -5.471004
V Predictions Mean           1243.7292
V Predictions Std            452.7167
V Predictions Max            1584.895
V Predictions Min            -1.4760921
Log Pis Mean                 -0.51601154
Log Pis Std                  2.2927926
Log Pis Max                  10.212676
Log Pis Min                  -5.270804
Policy mu Mean               -0.033791304
Policy mu Std                0.87798715
Policy mu Max                2.8533819
Policy mu Min                -3.1858118
Policy log std Mean          -0.4001343
Policy log std Std           0.19206381
Policy log std Max           -0.039680213
Policy log std Min           -2.1645608
Z mean eval                  1.1912762
Z variance eval              0.01733556
total_rewards                [3114.41312137 3051.27168854 2056.14304278 2077.76828783 2203.70750086
 1003.12315145 3034.93061083 1748.11481387 2953.25978576 3068.47706573]
total_rewards_mean           2431.120906903159
total_rewards_std            686.8603587929659
total_rewards_max            3114.4131213710025
total_rewards_min            1003.1231514532956
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               33.27038618084043
(Previous) Eval Time (s)     26.22296018199995
Sample Time (s)              23.47276590531692
Epoch Time (s)               82.9661122681573
Total Train Time (s)         24486.63603178179
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:51.180039 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #380 | Epoch Duration: 80.21461653709412
2020-01-11 06:50:51.180226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.19098
Z variance train             0.0173382
KL Divergence                13.788567
KL Loss                      1.3788567
QF Loss                      116.87955
VF Loss                      43.82958
Policy Loss                  -1238.7623
Q Predictions Mean           1238.0637
Q Predictions Std            400.11118
Q Predictions Max            1563.0342
Q Predictions Min            4.6876125
V Predictions Mean           1241.8511
V Predictions Std            399.93176
V Predictions Max            1559.391
V Predictions Min            3.1610045
Log Pis Mean                 -0.5830863
Log Pis Std                  1.9619583
Log Pis Max                  6.490725
Log Pis Min                  -6.9874
Policy mu Mean               0.019764563
Policy mu Std                0.8588815
Policy mu Max                2.7580414
Policy mu Min                -2.674275
Policy log std Mean          -0.39090323
Policy log std Std           0.17108244
Policy log std Max           -0.057002753
Policy log std Min           -1.0564466
Z mean eval                  1.1814321
Z variance eval              0.015511045
total_rewards                [ 936.24400454 2511.13239404 3063.54469818  905.31878411 3108.1597068
  812.62666913 2967.91690292 3015.96056702 1385.76186348 3082.71312119]
total_rewards_mean           2178.937871140183
total_rewards_std            977.6793120824658
total_rewards_max            3108.1597067988205
total_rewards_min            812.6266691313009
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               33.097369600087404
(Previous) Eval Time (s)     23.47118333214894
Sample Time (s)              22.54822332179174
Epoch Time (s)               79.11677625402808
Total Train Time (s)         24562.160635245964
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:06.709192 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #381 | Epoch Duration: 75.52883911132812
2020-01-11 06:52:06.709336 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1846823
Z variance train             0.015410575
KL Divergence                14.329882
KL Loss                      1.4329882
QF Loss                      4108.921
VF Loss                      142.71762
Policy Loss                  -1170.0
Q Predictions Mean           1169.0088
Q Predictions Std            427.55716
Q Predictions Max            1496.3816
Q Predictions Min            -0.64801484
V Predictions Mean           1169.0995
V Predictions Std            425.00253
V Predictions Max            1496.351
V Predictions Min            0.6294905
Log Pis Mean                 -0.31082866
Log Pis Std                  1.9132134
Log Pis Max                  5.4756293
Log Pis Min                  -4.8143272
Policy mu Mean               0.056658607
Policy mu Std                0.88289577
Policy mu Max                2.253659
Policy mu Min                -2.6542177
Policy log std Mean          -0.40945062
Policy log std Std           0.17874752
Policy log std Max           -0.077020116
Policy log std Min           -1.8435595
Z mean eval                  1.1869026
Z variance eval              0.014792301
total_rewards                [2436.19454349 3023.12277887  724.76583546  767.7445824  1083.7795707
 1465.48759869 2072.23731658  921.17762336 1541.135299   3105.15366556]
total_rewards_mean           1714.0798814086866
total_rewards_std            853.8371693516075
total_rewards_max            3105.153665555417
total_rewards_min            724.7658354601856
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               32.442316397093236
(Previous) Eval Time (s)     19.882916938047856
Sample Time (s)              22.872482294682413
Epoch Time (s)               75.1977156298235
Total Train Time (s)         24633.261390547268
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:17.819778 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #382 | Epoch Duration: 71.11032819747925
2020-01-11 06:53:17.819973 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1875408
Z variance train             0.014797874
KL Divergence                14.531906
KL Loss                      1.4531907
QF Loss                      1373.5366
VF Loss                      88.66173
Policy Loss                  -1156.9459
Q Predictions Mean           1151.9077
Q Predictions Std            471.8073
Q Predictions Max            1533.1627
Q Predictions Min            0.48259658
V Predictions Mean           1157.1685
V Predictions Std            465.0949
V Predictions Max            1530.4362
V Predictions Min            -0.013537347
Log Pis Mean                 -0.6308528
Log Pis Std                  2.0226076
Log Pis Max                  10.668035
Log Pis Min                  -5.7640185
Policy mu Mean               0.051159512
Policy mu Std                0.8250945
Policy mu Max                3.0440059
Policy mu Min                -3.9985619
Policy log std Mean          -0.38521692
Policy log std Std           0.17363603
Policy log std Max           -0.033848077
Policy log std Min           -1.1201587
Z mean eval                  1.1930375
Z variance eval              0.012821943
total_rewards                [2683.28683472 1043.11277883 3001.0030201  3109.22940565 2141.89739565
 1417.75224153 1210.86456465 2156.91598479 2715.15041207 2968.78604984]
total_rewards_mean           2244.7998687825007
total_rewards_std            739.7386310434728
total_rewards_max            3109.229405651107
total_rewards_min            1043.112778834285
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               33.2744532530196
(Previous) Eval Time (s)     15.795203039888293
Sample Time (s)              23.76987505191937
Epoch Time (s)               72.83953134482726
Total Train Time (s)         24712.11915896181
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:36.677766 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #383 | Epoch Duration: 78.85764908790588
2020-01-11 06:54:36.677999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1915653
Z variance train             0.012805397
KL Divergence                15.15877
KL Loss                      1.515877
QF Loss                      139.20418
VF Loss                      94.35822
Policy Loss                  -1189.3835
Q Predictions Mean           1188.3733
Q Predictions Std            424.58972
Q Predictions Max            1514.7266
Q Predictions Min            2.171126
V Predictions Mean           1192.9855
V Predictions Std            423.31372
V Predictions Max            1520.2418
V Predictions Min            2.3760724
Log Pis Mean                 -0.36566743
Log Pis Std                  2.0117285
Log Pis Max                  8.572489
Log Pis Min                  -4.411445
Policy mu Mean               0.07753544
Policy mu Std                0.8705263
Policy mu Max                2.7809896
Policy mu Min                -2.749817
Policy log std Mean          -0.39717022
Policy log std Std           0.16169494
Policy log std Max           -0.03609979
Policy log std Min           -1.0861026
Z mean eval                  1.1859305
Z variance eval              0.012880904
total_rewards                [ 815.53386679 3022.53061203 3024.18301727 1339.02884586 3008.41994591
 3006.06738196 2978.56018087 2989.18688935 2797.06883849 1267.23635066]
total_rewards_mean           2424.781592917339
total_rewards_std            852.4894702564528
total_rewards_max            3024.183017265694
total_rewards_min            815.5338667932373
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               32.76573948794976
(Previous) Eval Time (s)     21.812980874907225
Sample Time (s)              24.269204150419682
Epoch Time (s)               78.84792451327667
Total Train Time (s)         24792.688797091134
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:57.251910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #384 | Epoch Duration: 80.57372951507568
2020-01-11 06:55:57.252192 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1860799
Z variance train             0.012856195
KL Divergence                15.549713
KL Loss                      1.5549713
QF Loss                      52.482086
VF Loss                      32.359715
Policy Loss                  -1225.3336
Q Predictions Mean           1224.7224
Q Predictions Std            394.55203
Q Predictions Max            1526.8695
Q Predictions Min            -2.2453098
V Predictions Mean           1225.3253
V Predictions Std            393.7237
V Predictions Max            1530.3982
V Predictions Min            0.7802709
Log Pis Mean                 -0.5096347
Log Pis Std                  1.912936
Log Pis Max                  6.9980965
Log Pis Min                  -5.463514
Policy mu Mean               -0.031642314
Policy mu Std                0.8269671
Policy mu Max                2.3744047
Policy mu Min                -2.7356606
Policy log std Mean          -0.40382084
Policy log std Std           0.16494556
Policy log std Max           -0.06419285
Policy log std Min           -1.2709376
Z mean eval                  1.1456492
Z variance eval              0.01207013
total_rewards                [1879.84316897  971.90471339 1355.60112734 2990.95762332 3036.93103614
 2716.02218253 3036.91811154 3083.16400973 1350.67376032 2026.92600535]
total_rewards_mean           2244.8941738625067
total_rewards_std            782.7924178029107
total_rewards_max            3083.1640097323016
total_rewards_min            971.9047133862932
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               33.4500022046268
(Previous) Eval Time (s)     23.538430126849562
Sample Time (s)              22.67128828726709
Epoch Time (s)               79.65972061874345
Total Train Time (s)         24870.79994939128
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:57:15.367398 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #385 | Epoch Duration: 78.11496901512146
2020-01-11 06:57:15.367640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1465786
Z variance train             0.012110912
KL Divergence                15.020466
KL Loss                      1.5020466
QF Loss                      198.2305
VF Loss                      65.49219
Policy Loss                  -1203.58
Q Predictions Mean           1199.1321
Q Predictions Std            430.0942
Q Predictions Max            1512.9375
Q Predictions Min            -1.1218612
V Predictions Mean           1200.983
V Predictions Std            428.27673
V Predictions Max            1516.2104
V Predictions Min            0.4253592
Log Pis Mean                 -0.5072703
Log Pis Std                  1.8790247
Log Pis Max                  6.424032
Log Pis Min                  -5.8623686
Policy mu Mean               0.01380679
Policy mu Std                0.85921323
Policy mu Max                2.8249207
Policy mu Min                -2.709538
Policy log std Mean          -0.41768137
Policy log std Std           0.17893074
Policy log std Max           -0.11292922
Policy log std Min           -1.3289919
Z mean eval                  1.1609858
Z variance eval              0.011264746
total_rewards                [2908.67071539 2961.99637377 2873.34710603 1352.15464798 3049.94902817
 2971.17256328 2959.84955399 3152.3071949  2620.44216196 3075.59343487]
total_rewards_mean           2792.548278035102
total_rewards_std            498.87597560454145
total_rewards_max            3152.3071948955676
total_rewards_min            1352.1546479825784
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               32.42267069220543
(Previous) Eval Time (s)     21.99333182675764
Sample Time (s)              23.734825919382274
Epoch Time (s)               78.15082843834534
Total Train Time (s)         24953.298890680075
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:37.871156 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #386 | Epoch Duration: 82.50327229499817
2020-01-11 06:58:37.871502 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.155762
Z variance train             0.0112041235
KL Divergence                15.415248
KL Loss                      1.5415248
QF Loss                      158.38763
VF Loss                      161.99611
Policy Loss                  -1164.627
Q Predictions Mean           1162.5448
Q Predictions Std            415.15216
Q Predictions Max            1507.4697
Q Predictions Min            -0.15621066
V Predictions Mean           1159.686
V Predictions Std            414.9375
V Predictions Max            1498.4912
V Predictions Min            1.1126711
Log Pis Mean                 -0.44733077
Log Pis Std                  1.9137189
Log Pis Max                  6.8134904
Log Pis Min                  -4.714991
Policy mu Mean               0.009222633
Policy mu Std                0.8233524
Policy mu Max                2.5086136
Policy mu Min                -3.2802947
Policy log std Mean          -0.3900257
Policy log std Std           0.17834182
Policy log std Max           -0.022778451
Policy log std Min           -1.1520823
Z mean eval                  1.1672719
Z variance eval              0.011184329
total_rewards                [3031.12498912 3137.16371142 3067.22554743 2296.23469904 1641.92681136
  790.93435592  852.05276287 1042.81036892 3067.43806199 1567.56128151]
total_rewards_mean           2049.4472589580437
total_rewards_std            933.2263043990537
total_rewards_max            3137.1637114239143
total_rewards_min            790.9343559157546
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               33.09390604868531
(Previous) Eval Time (s)     26.345408173277974
Sample Time (s)              22.97203672071919
Epoch Time (s)               82.41135094268247
Total Train Time (s)         25029.158895293716
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:53.736328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #387 | Epoch Duration: 75.86463570594788
2020-01-11 06:59:53.736546 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1640463
Z variance train             0.011239728
KL Divergence                15.381283
KL Loss                      1.5381283
QF Loss                      143.95438
VF Loss                      61.399574
Policy Loss                  -1179.3057
Q Predictions Mean           1177.3977
Q Predictions Std            407.98132
Q Predictions Max            1485.0492
Q Predictions Min            -10.717055
V Predictions Mean           1175.2361
V Predictions Std            405.88202
V Predictions Max            1477.0352
V Predictions Min            -0.98182416
Log Pis Mean                 -0.43595448
Log Pis Std                  2.0557618
Log Pis Max                  5.3749914
Log Pis Min                  -5.1784635
Policy mu Mean               -0.1072086
Policy mu Std                0.85711163
Policy mu Max                2.4845438
Policy mu Min                -2.7980995
Policy log std Mean          -0.39825788
Policy log std Std           0.18441713
Policy log std Max           0.042299956
Policy log std Min           -1.1989772
Z mean eval                  1.1626949
Z variance eval              0.011723586
total_rewards                [ 801.78767519 3002.23938488 3111.90087667 1871.62774607 3143.91177734
 3211.02641851 3246.01195232 1673.75730729 3113.61215739 3143.98820629]
total_rewards_mean           2631.9863501949903
total_rewards_std            817.4272053520353
total_rewards_max            3246.0119523239355
total_rewards_min            801.7876751895334
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               32.995542308781296
(Previous) Eval Time (s)     19.798373667988926
Sample Time (s)              23.138798616360873
Epoch Time (s)               75.9327145931311
Total Train Time (s)         25110.096985866316
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:14.678512 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #388 | Epoch Duration: 80.94173526763916
2020-01-11 07:01:14.678801 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1643206
Z variance train             0.0117513165
KL Divergence                15.632856
KL Loss                      1.5632857
QF Loss                      84.482925
VF Loss                      52.929337
Policy Loss                  -1283.3624
Q Predictions Mean           1280.6743
Q Predictions Std            411.03152
Q Predictions Max            1601.1656
Q Predictions Min            -2.6238704
V Predictions Mean           1283.2118
V Predictions Std            411.71478
V Predictions Max            1598.8625
V Predictions Min            -0.19885117
Log Pis Mean                 -0.38602006
Log Pis Std                  1.8296356
Log Pis Max                  6.0758953
Log Pis Min                  -5.2542925
Policy mu Mean               -0.029921234
Policy mu Std                0.84081197
Policy mu Max                1.9120197
Policy mu Min                -2.8491695
Policy log std Mean          -0.3962953
Policy log std Std           0.17861502
Policy log std Max           -0.015244037
Policy log std Min           -1.1586925
Z mean eval                  1.1409823
Z variance eval              0.0138085615
total_rewards                [2991.21252525 1110.06343431 2996.39364221 1326.41171008 2870.43722074
 1473.08984394 2899.06307667 2734.83076958  829.40715571 2896.90984665]
total_rewards_mean           2212.781922513623
total_rewards_std            855.9538652239751
total_rewards_max            2996.3936422125093
total_rewards_min            829.407155707945
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               33.249724846333265
(Previous) Eval Time (s)     24.80705154594034
Sample Time (s)              23.306649496313184
Epoch Time (s)               81.36342588858679
Total Train Time (s)         25188.661695916206
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:33.245759 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #389 | Epoch Duration: 78.56679773330688
2020-01-11 07:02:33.245918 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1377586
Z variance train             0.013831872
KL Divergence                14.127018
KL Loss                      1.4127018
QF Loss                      101.306335
VF Loss                      85.77263
Policy Loss                  -1249.3527
Q Predictions Mean           1249.1711
Q Predictions Std            415.84686
Q Predictions Max            1552.9169
Q Predictions Min            -7.1655774
V Predictions Mean           1255.3483
V Predictions Std            416.59848
V Predictions Max            1567.2778
V Predictions Min            -3.5407338
Log Pis Mean                 -0.599628
Log Pis Std                  1.7717476
Log Pis Max                  6.175006
Log Pis Min                  -4.8851924
Policy mu Mean               -0.0370069
Policy mu Std                0.83532006
Policy mu Max                2.3555803
Policy mu Min                -2.9687972
Policy log std Mean          -0.41001925
Policy log std Std           0.17976806
Policy log std Max           0.007078588
Policy log std Min           -1.2255135
Z mean eval                  1.1848675
Z variance eval              0.011123478
total_rewards                [2036.14408645 2269.50736414  868.86166886 1218.83523202 3029.38324088
 1058.86490714  813.85923014 2813.46565167 1528.45969225 1001.46124918]
total_rewards_mean           1663.8842322731477
total_rewards_std            778.9317140013949
total_rewards_max            3029.3832408778453
total_rewards_min            813.8592301378651
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               32.83028550306335
(Previous) Eval Time (s)     22.010092118754983
Sample Time (s)              21.938800031784922
Epoch Time (s)               76.77917765360326
Total Train Time (s)         25259.957749076653
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:44.546061 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #390 | Epoch Duration: 71.3000123500824
2020-01-11 07:03:44.546249 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1863862
Z variance train             0.01111127
KL Divergence                14.729675
KL Loss                      1.4729675
QF Loss                      245.39246
VF Loss                      62.177303
Policy Loss                  -1102.8126
Q Predictions Mean           1101.6533
Q Predictions Std            435.9748
Q Predictions Max            1470.2557
Q Predictions Min            -4.827721
V Predictions Mean           1104.1069
V Predictions Std            436.48874
V Predictions Max            1474.7452
V Predictions Min            -1.943164
Log Pis Mean                 -0.56761336
Log Pis Std                  1.940308
Log Pis Max                  9.481724
Log Pis Min                  -5.126793
Policy mu Mean               0.032319885
Policy mu Std                0.8312473
Policy mu Max                2.2284014
Policy mu Min                -2.6998427
Policy log std Mean          -0.38531235
Policy log std Std           0.16067572
Policy log std Max           -0.048297197
Policy log std Min           -1.0869644
Z mean eval                  1.1382354
Z variance eval              0.012485279
total_rewards                [2358.11644823 3087.8027488  3185.97923648 1039.7879217  1408.14736594
 3144.27939089 2427.12557755 3101.1754858  3077.83130926 2609.11795826]
total_rewards_mean           2543.936344292193
total_rewards_std            725.8706717950098
total_rewards_max            3185.979236476323
total_rewards_min            1039.7879217046352
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               32.716653887182474
(Previous) Eval Time (s)     16.530614187940955
Sample Time (s)              23.727371456101537
Epoch Time (s)               72.97463953122497
Total Train Time (s)         25340.697482404765
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:05.289879 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #391 | Epoch Duration: 80.74348139762878
2020-01-11 07:05:05.290068 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1371342
Z variance train             0.012514794
KL Divergence                15.092732
KL Loss                      1.5092733
QF Loss                      130.90436
VF Loss                      67.03933
Policy Loss                  -1131.0613
Q Predictions Mean           1128.8162
Q Predictions Std            460.6918
Q Predictions Max            1485.5936
Q Predictions Min            -20.593117
V Predictions Mean           1131.0911
V Predictions Std            459.32715
V Predictions Max            1490.9922
V Predictions Min            0.03942883
Log Pis Mean                 -0.50965846
Log Pis Std                  1.9304539
Log Pis Max                  7.8625097
Log Pis Min                  -5.288884
Policy mu Mean               -0.0037556987
Policy mu Std                0.86148906
Policy mu Max                2.4919105
Policy mu Min                -2.8827987
Policy log std Mean          -0.38669124
Policy log std Std           0.171357
Policy log std Max           -0.11929822
Policy log std Min           -1.3376577
Z mean eval                  1.1320492
Z variance eval              0.016624775
total_rewards                [2982.19593438 3009.08076424 2571.05441635 2976.67972801 2987.8944844
 2049.76132682 3011.29696738 2998.5267036  1979.96363125  787.65377488]
total_rewards_mean           2535.4107731310896
total_rewards_std            697.4730089101676
total_rewards_max            3011.2969673841317
total_rewards_min            787.6537748816693
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               33.128856756258756
(Previous) Eval Time (s)     24.299153037834913
Sample Time (s)              23.434039054904133
Epoch Time (s)               80.8620488489978
Total Train Time (s)         25422.18355925847
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:26.778638 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #392 | Epoch Duration: 81.48844242095947
2020-01-11 07:06:26.778779 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1321462
Z variance train             0.016630558
KL Divergence                13.997307
KL Loss                      1.3997307
QF Loss                      177.11331
VF Loss                      112.353096
Policy Loss                  -1153.865
Q Predictions Mean           1150.7136
Q Predictions Std            428.1302
Q Predictions Max            1485.6451
Q Predictions Min            -3.7423313
V Predictions Mean           1152.7173
V Predictions Std            426.73505
V Predictions Max            1484.2141
V Predictions Min            4.1079135
Log Pis Mean                 -0.43176657
Log Pis Std                  1.9469558
Log Pis Max                  5.532961
Log Pis Min                  -4.871928
Policy mu Mean               0.0060931644
Policy mu Std                0.8744256
Policy mu Max                2.561392
Policy mu Min                -2.8707974
Policy log std Mean          -0.39954233
Policy log std Std           0.16150883
Policy log std Max           -0.12371068
Policy log std Min           -1.3180215
Z mean eval                  1.1128536
Z variance eval              0.018152084
total_rewards                [2947.24226459 1767.93837112 3011.28655981 2477.14548631 3024.92765865
 2985.18562491 3078.61539875 1556.88725953 3062.8786101  2976.08288054]
total_rewards_mean           2688.819011430579
total_rewards_std            540.3747545158197
total_rewards_max            3078.6153987501557
total_rewards_min            1556.8872595269452
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               32.75345228007063
(Previous) Eval Time (s)     24.925217276904732
Sample Time (s)              23.4023971054703
Epoch Time (s)               81.08106666244566
Total Train Time (s)         25504.60252844682
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:49.202041 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #393 | Epoch Duration: 82.42313528060913
2020-01-11 07:07:49.202242 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1118437
Z variance train             0.01811533
KL Divergence                13.404955
KL Loss                      1.3404955
QF Loss                      116.06598
VF Loss                      63.16607
Policy Loss                  -1305.0741
Q Predictions Mean           1302.7263
Q Predictions Std            362.18085
Q Predictions Max            1583.649
Q Predictions Min            -1.0518334
V Predictions Mean           1306.6582
V Predictions Std            363.4506
V Predictions Max            1590.244
V Predictions Min            6.43077
Log Pis Mean                 -0.67808384
Log Pis Std                  1.9342334
Log Pis Max                  7.380981
Log Pis Min                  -4.576191
Policy mu Mean               -0.018743357
Policy mu Std                0.83220255
Policy mu Max                2.1678927
Policy mu Min                -3.0087402
Policy log std Mean          -0.38798976
Policy log std Std           0.15777625
Policy log std Max           -0.08042048
Policy log std Min           -1.2973845
Z mean eval                  1.1688216
Z variance eval              0.012481957
total_rewards                [ 999.32653022  975.62028269  799.89745664 2925.87011554 2910.87079183
 2984.63421026 3035.68328887 1437.20921987  827.48334649 1991.15817093]
total_rewards_mean           1888.7753413330124
total_rewards_std            937.4385570269723
total_rewards_max            3035.6832888694494
total_rewards_min            799.8974566414785
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               32.74342788010836
(Previous) Eval Time (s)     26.266928112134337
Sample Time (s)              23.356401006225497
Epoch Time (s)               82.36675699846819
Total Train Time (s)         25579.214126240462
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:09:03.817102 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #394 | Epoch Duration: 74.61473441123962
2020-01-11 07:09:03.817225 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.163718
Z variance train             0.0124777425
KL Divergence                14.32979
KL Loss                      1.432979
QF Loss                      228.26245
VF Loss                      113.0775
Policy Loss                  -1161.1444
Q Predictions Mean           1162.2095
Q Predictions Std            467.64267
Q Predictions Max            1536.231
Q Predictions Min            -3.823698
V Predictions Mean           1168.2595
V Predictions Std            467.21036
V Predictions Max            1546.8923
V Predictions Min            5.0824404
Log Pis Mean                 -0.34882492
Log Pis Std                  2.0462012
Log Pis Max                  6.768385
Log Pis Min                  -10.863186
Policy mu Mean               -0.01651013
Policy mu Std                0.889598
Policy mu Max                2.5585802
Policy mu Min                -2.7087977
Policy log std Mean          -0.39923143
Policy log std Std           0.1854462
Policy log std Max           -0.07753512
Policy log std Min           -1.2966324
Z mean eval                  1.1360903
Z variance eval              0.01643012
total_rewards                [2968.89778283 2915.82706499 2977.41375554 2895.44310716 2891.89205252
 2845.43884947  851.95285042 2933.09372009 3024.08514217 2919.07593507]
total_rewards_mean           2722.31202602805
total_rewards_std            625.274090884902
total_rewards_max            3024.0851421725765
total_rewards_min            851.9528504201949
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               32.67322147497907
(Previous) Eval Time (s)     18.514609267935157
Sample Time (s)              23.227053571958095
Epoch Time (s)               74.41488431487232
Total Train Time (s)         25662.870921285823
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:27.479419 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #395 | Epoch Duration: 83.66207981109619
2020-01-11 07:10:27.479638 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1371663
Z variance train             0.016396958
KL Divergence                13.651093
KL Loss                      1.3651093
QF Loss                      105.685425
VF Loss                      30.235085
Policy Loss                  -1184.6455
Q Predictions Mean           1183.6781
Q Predictions Std            427.55737
Q Predictions Max            1564.9604
Q Predictions Min            3.9907613
V Predictions Mean           1182.8656
V Predictions Std            426.40826
V Predictions Max            1556.647
V Predictions Min            5.598044
Log Pis Mean                 -0.48797584
Log Pis Std                  2.0846298
Log Pis Max                  7.3260183
Log Pis Min                  -6.3249836
Policy mu Mean               0.013295256
Policy mu Std                0.8811798
Policy mu Max                2.6549351
Policy mu Min                -2.9443603
Policy log std Mean          -0.41153654
Policy log std Std           0.16719218
Policy log std Max           -0.109103024
Policy log std Min           -1.1388031
Z mean eval                  1.1240776
Z variance eval              0.018136283
total_rewards                [2960.87912273 3107.09470451 2827.14424861 3011.75847322 3021.84328807
  959.52258209 2956.65067675 3003.11648884 3036.62904378 2984.07538514]
total_rewards_mean           2786.871401373889
total_rewards_std            612.8856724151658
total_rewards_max            3107.094704508635
total_rewards_min            959.5225820854611
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               33.56311881914735
(Previous) Eval Time (s)     27.761418730951846
Sample Time (s)              22.490310985594988
Epoch Time (s)               83.81484853569418
Total Train Time (s)         25746.976671104785
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:51.590986 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #396 | Epoch Duration: 84.11108255386353
2020-01-11 07:11:51.591403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1226175
Z variance train             0.018140469
KL Divergence                13.23244
KL Loss                      1.323244
QF Loss                      132.66078
VF Loss                      38.59841
Policy Loss                  -1167.647
Q Predictions Mean           1168.9756
Q Predictions Std            443.7548
Q Predictions Max            1503.8115
Q Predictions Min            3.8883069
V Predictions Mean           1170.6117
V Predictions Std            444.12616
V Predictions Max            1502.2411
V Predictions Min            2.4972048
Log Pis Mean                 -0.6465833
Log Pis Std                  1.932558
Log Pis Max                  6.508391
Log Pis Min                  -5.57807
Policy mu Mean               0.07252335
Policy mu Std                0.7716396
Policy mu Max                2.0329075
Policy mu Min                -2.7686923
Policy log std Mean          -0.38344884
Policy log std Std           0.16568422
Policy log std Max           -0.03690228
Policy log std Min           -1.1737188
Z mean eval                  1.1428715
Z variance eval              0.014763966
total_rewards                [2384.50378207 1341.09482529 2911.67799553 1840.60239286 2898.00864524
 2879.04647809 2979.87897625 2905.71232488 2884.08893496 2935.97405954]
total_rewards_mean           2596.0588414689832
total_rewards_std            538.7933438334532
total_rewards_max            2979.8789762525785
total_rewards_min            1341.0948252858282
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               34.823618384078145
(Previous) Eval Time (s)     28.057269207201898
Sample Time (s)              24.344871199689806
Epoch Time (s)               87.22575879096985
Total Train Time (s)         25831.89690910466
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:16.514199 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #397 | Epoch Duration: 84.92259955406189
2020-01-11 07:13:16.514393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1424993
Z variance train             0.014700191
KL Divergence                13.984459
KL Loss                      1.398446
QF Loss                      237.51137
VF Loss                      128.3318
Policy Loss                  -1253.1493
Q Predictions Mean           1251.2092
Q Predictions Std            407.4616
Q Predictions Max            1554.8542
Q Predictions Min            -3.8671098
V Predictions Mean           1257.3601
V Predictions Std            407.1247
V Predictions Max            1568.0594
V Predictions Min            5.328376
Log Pis Mean                 -0.44587964
Log Pis Std                  2.0753565
Log Pis Max                  7.3854365
Log Pis Min                  -4.619046
Policy mu Mean               0.044270594
Policy mu Std                0.84705967
Policy mu Max                2.4961512
Policy mu Min                -2.8110714
Policy log std Mean          -0.38530123
Policy log std Std           0.1761761
Policy log std Max           0.051360935
Policy log std Min           -1.3036491
Z mean eval                  1.1027443
Z variance eval              0.017856643
total_rewards                [ 805.44666155 3110.21061317  828.6769702  1661.39131487 3149.65522847
 3176.00691839 3105.11579384 2175.38649556 3102.35409931 2859.0730725 ]
total_rewards_mean           2397.331716785193
total_rewards_std            920.7271960462009
total_rewards_max            3176.0069183924184
total_rewards_min            805.4466615460636
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               36.38080421509221
(Previous) Eval Time (s)     25.75375834899023
Sample Time (s)              23.062436556443572
Epoch Time (s)               85.19699912052602
Total Train Time (s)         25915.014802183025
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:39.637403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #398 | Epoch Duration: 83.12276315689087
2020-01-11 07:14:39.637747 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1024135
Z variance train             0.017855499
KL Divergence                13.632873
KL Loss                      1.3632873
QF Loss                      1019.4509
VF Loss                      102.71651
Policy Loss                  -1119.1506
Q Predictions Mean           1117.0494
Q Predictions Std            405.44568
Q Predictions Max            1436.609
Q Predictions Min            2.5346732
V Predictions Mean           1119.32
V Predictions Std            402.96872
V Predictions Max            1437.6025
V Predictions Min            1.8587372
Log Pis Mean                 -0.46743667
Log Pis Std                  2.0443938
Log Pis Max                  7.501133
Log Pis Min                  -4.2467217
Policy mu Mean               0.001374313
Policy mu Std                0.84579533
Policy mu Max                2.2323966
Policy mu Min                -2.814113
Policy log std Mean          -0.4139054
Policy log std Std           0.19074698
Policy log std Max           -0.027914152
Policy log std Min           -1.4615741
Z mean eval                  1.1247652
Z variance eval              0.017327057
total_rewards                [2476.46425769  969.30480032  788.93012176  849.734617   1593.69721541
 3133.09689845  843.26917596 1078.89792267 2828.61353206 3101.64846411]
total_rewards_mean           1766.3657005427672
total_rewards_std            952.3117724864505
total_rewards_max            3133.096898453331
total_rewards_min            788.9301217610476
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               35.70619674725458
(Previous) Eval Time (s)     23.6791758290492
Sample Time (s)              25.04054706543684
Epoch Time (s)               84.42591964174062
Total Train Time (s)         25992.120336655993
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:56.747521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #399 | Epoch Duration: 77.10957789421082
2020-01-11 07:15:56.747823 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1228453
Z variance train             0.017285137
KL Divergence                13.396379
KL Loss                      1.339638
QF Loss                      265.58698
VF Loss                      104.54515
Policy Loss                  -1175.1847
Q Predictions Mean           1174.0902
Q Predictions Std            390.1942
Q Predictions Max            1504.2208
Q Predictions Min            3.8209128
V Predictions Mean           1171.0392
V Predictions Std            389.03156
V Predictions Max            1492.2317
V Predictions Min            4.682136
Log Pis Mean                 -0.56232816
Log Pis Std                  1.9067099
Log Pis Max                  6.275936
Log Pis Min                  -5.1255255
Policy mu Mean               0.016640529
Policy mu Std                0.8222556
Policy mu Max                2.4807029
Policy mu Min                -2.683546
Policy log std Mean          -0.40432063
Policy log std Std           0.18473318
Policy log std Max           -0.09511244
Policy log std Min           -1.8237578
Z mean eval                  1.1238538
Z variance eval              0.016577478
total_rewards                [ 984.75427286  833.13318022 3102.83119913 1908.81326639  593.8201747
 3221.91102403 3183.61670256  852.81597805  796.14024454 2804.67666658]
total_rewards_mean           1828.2512709062662
total_rewards_std            1077.313708044645
total_rewards_max            3221.911024033563
total_rewards_min            593.8201746979536
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               35.428918602876365
(Previous) Eval Time (s)     16.362424107734114
Sample Time (s)              23.991099931299686
Epoch Time (s)               75.78244264191017
Total Train Time (s)         26069.265573016834
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:13.897738 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #400 | Epoch Duration: 77.14971208572388
2020-01-11 07:17:13.897957 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1189411
Z variance train             0.01660309
KL Divergence                13.469934
KL Loss                      1.3469934
QF Loss                      77.25327
VF Loss                      78.37749
Policy Loss                  -1226.764
Q Predictions Mean           1228.8044
Q Predictions Std            442.68082
Q Predictions Max            1574.3828
Q Predictions Min            1.710479
V Predictions Mean           1232.0173
V Predictions Std            443.13126
V Predictions Max            1574.6656
V Predictions Min            4.5986657
Log Pis Mean                 -0.5731181
Log Pis Std                  1.8261038
Log Pis Max                  5.705723
Log Pis Min                  -5.672455
Policy mu Mean               0.021796077
Policy mu Std                0.8026781
Policy mu Max                2.129655
Policy mu Min                -2.7303512
Policy log std Mean          -0.391665
Policy log std Std           0.16764285
Policy log std Max           -0.104482636
Policy log std Min           -1.105861
Z mean eval                  1.1142544
Z variance eval              0.021248728
total_rewards                [3105.731907   3093.34789828 3064.93813664  880.76732699 1527.85893119
 2423.07183263 2092.24793548 3198.68721253 3168.80524279 3097.66833664]
total_rewards_mean           2565.312476015053
total_rewards_std            776.3565472734787
total_rewards_max            3198.6872125251607
total_rewards_min            880.7673269911745
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               35.62200064677745
(Previous) Eval Time (s)     17.729320395272225
Sample Time (s)              24.54176747146994
Epoch Time (s)               77.89308851351961
Total Train Time (s)         26154.972735530697
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:18:39.609858 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #401 | Epoch Duration: 85.71172332763672
2020-01-11 07:18:39.610074 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1144284
Z variance train             0.021259673
KL Divergence                13.091686
KL Loss                      1.3091687
QF Loss                      131.42526
VF Loss                      80.44821
Policy Loss                  -1241.2754
Q Predictions Mean           1242.3193
Q Predictions Std            388.2188
Q Predictions Max            1538.8241
Q Predictions Min            5.0015206
V Predictions Mean           1238.8811
V Predictions Std            386.3878
V Predictions Max            1536.517
V Predictions Min            4.149639
Log Pis Mean                 -0.24911201
Log Pis Std                  2.0198457
Log Pis Max                  10.202218
Log Pis Min                  -3.6821713
Policy mu Mean               -0.04520676
Policy mu Std                0.8679772
Policy mu Max                2.2874713
Policy mu Min                -3.4371011
Policy log std Mean          -0.40424833
Policy log std Std           0.1733904
Policy log std Max           -0.037650257
Policy log std Min           -1.638297
Z mean eval                  1.0898994
Z variance eval              0.024550509
total_rewards                [3148.12874549 2071.80497848 3078.46012109 1655.99099668 3214.49891732
 1543.48552053  822.14041454 3231.00176997  805.43267065 3190.05887245]
total_rewards_mean           2276.1003007194513
total_rewards_std            962.9030643239578
total_rewards_max            3231.0017699694135
total_rewards_min            805.4326706472959
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               34.82593549974263
(Previous) Eval Time (s)     25.54749573627487
Sample Time (s)              23.772625538054854
Epoch Time (s)               84.14605677407235
Total Train Time (s)         26235.067591009196
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:59.708564 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #402 | Epoch Duration: 80.0983338356018
2020-01-11 07:19:59.708756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0896775
Z variance train             0.024620451
KL Divergence                12.570274
KL Loss                      1.2570275
QF Loss                      97.75021
VF Loss                      78.84642
Policy Loss                  -1203.9973
Q Predictions Mean           1203.124
Q Predictions Std            416.9203
Q Predictions Max            1533.2965
Q Predictions Min            6.547588
V Predictions Mean           1202.5802
V Predictions Std            416.5122
V Predictions Max            1534.3549
V Predictions Min            4.145273
Log Pis Mean                 -0.44560266
Log Pis Std                  2.025602
Log Pis Max                  7.0375695
Log Pis Min                  -5.070996
Policy mu Mean               0.019453442
Policy mu Std                0.85685873
Policy mu Max                2.9161344
Policy mu Min                -2.6501493
Policy log std Mean          -0.40407023
Policy log std Std           0.1790485
Policy log std Max           -0.10079626
Policy log std Min           -1.4927617
Z mean eval                  1.0814276
Z variance eval              0.01882136
total_rewards                [3027.55348237 3034.33391147 3091.7464187  3049.15336818 1515.3125201
 2346.89680956 2426.75451216 3133.0566126  1547.6298681  3045.05519588]
total_rewards_mean           2621.7492699108816
total_rewards_std            605.8547214661055
total_rewards_max            3133.056612595068
total_rewards_min            1515.312520097312
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               35.53460245812312
(Previous) Eval Time (s)     21.499440923333168
Sample Time (s)              24.306499235797673
Epoch Time (s)               81.34054261725396
Total Train Time (s)         26320.50473385537
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:25.150281 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #403 | Epoch Duration: 85.44136190414429
2020-01-11 07:21:25.150549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0823559
Z variance train             0.01882433
KL Divergence                13.335609
KL Loss                      1.333561
QF Loss                      214.38744
VF Loss                      50.393066
Policy Loss                  -1119.6578
Q Predictions Mean           1120.5464
Q Predictions Std            401.41855
Q Predictions Max            1458.722
Q Predictions Min            2.068466
V Predictions Mean           1117.105
V Predictions Std            401.15857
V Predictions Max            1461.4214
V Predictions Min            2.2974482
Log Pis Mean                 -0.18152596
Log Pis Std                  2.2145314
Log Pis Max                  8.298313
Log Pis Min                  -4.17829
Policy mu Mean               0.006045031
Policy mu Std                0.9189914
Policy mu Max                2.309453
Policy mu Min                -2.8152685
Policy log std Mean          -0.4005673
Policy log std Std           0.18479039
Policy log std Max           -0.08287339
Policy log std Min           -1.1888027
Z mean eval                  1.1186898
Z variance eval              0.020240497
total_rewards                [2786.21325708 2736.92786598 2941.06709374 2853.61503687 2142.76980011
 2891.95688416 2835.79598707 2909.89873    2781.51826182 2384.49976974]
total_rewards_mean           2726.426268657611
total_rewards_std            244.859230943343
total_rewards_max            2941.0670937429672
total_rewards_min            2142.7698001061513
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               36.24966267403215
(Previous) Eval Time (s)     25.599871366284788
Sample Time (s)              24.075493860058486
Epoch Time (s)               85.92502790037543
Total Train Time (s)         26410.237323296256
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:54.886754 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #404 | Epoch Duration: 89.73605442047119
2020-01-11 07:22:54.886974 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1188971
Z variance train             0.020243224
KL Divergence                12.791611
KL Loss                      1.2791611
QF Loss                      125.14148
VF Loss                      64.70022
Policy Loss                  -1152.7173
Q Predictions Mean           1150.6755
Q Predictions Std            411.57242
Q Predictions Max            1500.0968
Q Predictions Min            -0.14594948
V Predictions Mean           1149.7513
V Predictions Std            408.5684
V Predictions Max            1493.1064
V Predictions Min            5.6043944
Log Pis Mean                 -0.46215674
Log Pis Std                  2.0582397
Log Pis Max                  8.882776
Log Pis Min                  -5.1361995
Policy mu Mean               -0.16955908
Policy mu Std                0.8503572
Policy mu Max                2.68087
Policy mu Min                -2.7698212
Policy log std Mean          -0.3895701
Policy log std Std           0.1763858
Policy log std Max           -0.085800305
Policy log std Min           -1.2706041
Z mean eval                  1.0814673
Z variance eval              0.017324904
total_rewards                [1522.42622859 3008.35834146 2779.93911713 2925.30020457   75.06675458
 3045.46660446 3041.50951465  132.44193916 2948.63539448 1832.55927055]
total_rewards_mean           2131.170336962739
total_rewards_std            1132.966075554306
total_rewards_max            3045.466604464392
total_rewards_min            75.0667545849151
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               35.14747421396896
(Previous) Eval Time (s)     29.410516659729183
Sample Time (s)              24.44281268492341
Epoch Time (s)               89.00080355862156
Total Train Time (s)         26491.49518192606
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:16.150338 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #405 | Epoch Duration: 81.26317811012268
2020-01-11 07:24:16.150640 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0824115
Z variance train             0.017378304
KL Divergence                12.918152
KL Loss                      1.2918152
QF Loss                      123.639694
VF Loss                      57.798695
Policy Loss                  -1244.1411
Q Predictions Mean           1242.138
Q Predictions Std            393.4963
Q Predictions Max            1554.317
Q Predictions Min            -0.7214889
V Predictions Mean           1242.4829
V Predictions Std            395.45706
V Predictions Max            1563.0366
V Predictions Min            0.2329889
Log Pis Mean                 -0.37182504
Log Pis Std                  2.0001965
Log Pis Max                  7.019276
Log Pis Min                  -4.436661
Policy mu Mean               -0.23224586
Policy mu Std                0.85162807
Policy mu Max                2.0776064
Policy mu Min                -2.8502998
Policy log std Mean          -0.37822542
Policy log std Std           0.17129673
Policy log std Max           -0.05215168
Policy log std Min           -1.1184095
Z mean eval                  1.08163
Z variance eval              0.012158251
total_rewards                [3078.11574078 2990.08569676 1256.02411153 1491.9152259  3073.30932718
 2979.8442564  2705.96865258 1866.31647334  750.54334678 1961.42877829]
total_rewards_mean           2215.3551609520823
total_rewards_std            817.40170136929
total_rewards_max            3078.115740781537
total_rewards_min            750.5433467763169
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               35.838924480136484
(Previous) Eval Time (s)     21.672521982807666
Sample Time (s)              23.964217303320765
Epoch Time (s)               81.47566376626492
Total Train Time (s)         26573.124514145777
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:37.800829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #406 | Epoch Duration: 81.64995288848877
2020-01-11 07:25:37.801514 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0816598
Z variance train             0.012157933
KL Divergence                14.005394
KL Loss                      1.4005394
QF Loss                      159.3197
VF Loss                      87.09715
Policy Loss                  -1237.0295
Q Predictions Mean           1236.0837
Q Predictions Std            384.69165
Q Predictions Max            1573.639
Q Predictions Min            -0.5543359
V Predictions Mean           1234.2521
V Predictions Std            383.85413
V Predictions Max            1577.3693
V Predictions Min            2.266615
Log Pis Mean                 -0.40423477
Log Pis Std                  1.9704152
Log Pis Max                  7.6954446
Log Pis Min                  -4.309946
Policy mu Mean               -0.11713632
Policy mu Std                0.8675303
Policy mu Max                2.3300207
Policy mu Min                -2.870671
Policy log std Mean          -0.40557826
Policy log std Std           0.17400172
Policy log std Max           -0.0042999685
Policy log std Min           -1.5445886
Z mean eval                  1.0888164
Z variance eval              0.014240694
total_rewards                [2973.08927768 1960.30828933 2982.35384275 1972.90984185 3058.07697781
 2979.18259392 3079.31490222 1825.13527538 3034.75285816 3080.67963873]
total_rewards_mean           2694.5803497828597
total_rewards_std            510.1194205821548
total_rewards_max            3080.679638730359
total_rewards_min            1825.1352753777364
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               33.6491517778486
(Previous) Eval Time (s)     21.846364833880216
Sample Time (s)              23.633770620450377
Epoch Time (s)               79.1292872321792
Total Train Time (s)         26657.134748775978
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:01.807468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #407 | Epoch Duration: 84.0054395198822
2020-01-11 07:27:01.807646 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0889195
Z variance train             0.014219321
KL Divergence                13.582415
KL Loss                      1.3582414
QF Loss                      228.93262
VF Loss                      95.28101
Policy Loss                  -1258.509
Q Predictions Mean           1260.7766
Q Predictions Std            421.6657
Q Predictions Max            1569.7224
Q Predictions Min            3.4077282
V Predictions Mean           1258.1802
V Predictions Std            422.36548
V Predictions Max            1575.7711
V Predictions Min            3.7311716
Log Pis Mean                 -0.5153247
Log Pis Std                  1.8849206
Log Pis Max                  7.2918415
Log Pis Min                  -4.2654886
Policy mu Mean               0.020833327
Policy mu Std                0.8772376
Policy mu Max                2.230667
Policy mu Min                -2.873709
Policy log std Mean          -0.39123395
Policy log std Std           0.15957259
Policy log std Max           -0.0023218095
Policy log std Min           -1.0217727
Z mean eval                  1.090592
Z variance eval              0.008103559
total_rewards                [2200.23207227 2540.09700514 2987.8933146  2893.52604997 2973.14603928
 3012.17847356  974.1217923  1786.99196105 1486.72208654 1859.50675335]
total_rewards_mean           2271.441554805891
total_rewards_std            687.1552990820152
total_rewards_max            3012.178473556445
total_rewards_min            974.1217923014113
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               33.22852616989985
(Previous) Eval Time (s)     26.722163863945752
Sample Time (s)              23.165973770897835
Epoch Time (s)               83.11666380474344
Total Train Time (s)         26735.383168352302
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:20.062131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #408 | Epoch Duration: 78.25435280799866
2020-01-11 07:28:20.062315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.089422
Z variance train             0.008104166
KL Divergence                15.116363
KL Loss                      1.5116363
QF Loss                      152.97726
VF Loss                      144.34752
Policy Loss                  -1213.0828
Q Predictions Mean           1213.1924
Q Predictions Std            467.30743
Q Predictions Max            1565.1733
Q Predictions Min            -4.1360855
V Predictions Mean           1213.5537
V Predictions Std            465.36948
V Predictions Max            1566.179
V Predictions Min            -6.68382
Log Pis Mean                 -0.4716974
Log Pis Std                  2.0478044
Log Pis Max                  9.395391
Log Pis Min                  -6.9450293
Policy mu Mean               -0.078320496
Policy mu Std                0.87503034
Policy mu Max                2.5370932
Policy mu Min                -3.8031428
Policy log std Mean          -0.39171728
Policy log std Std           0.18962273
Policy log std Max           -0.1145827
Policy log std Min           -1.4859697
Z mean eval                  1.07724
Z variance eval              0.008547382
total_rewards                [3115.48084333 3187.43014425 3210.27614384 1785.43388514 3235.24438408
 1861.0810852  1031.76097053 1460.1715448  2679.1804329  3140.28921659]
total_rewards_mean           2470.634865066786
total_rewards_std            805.3382736194643
total_rewards_max            3235.2443840840137
total_rewards_min            1031.7609705337443
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               33.255675595253706
(Previous) Eval Time (s)     21.85952855506912
Sample Time (s)              24.313405429944396
Epoch Time (s)               79.42860958026722
Total Train Time (s)         26816.065157074016
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:40.748324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #409 | Epoch Duration: 80.68587446212769
2020-01-11 07:29:40.748493 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0793698
Z variance train             0.008549904
KL Divergence                15.109741
KL Loss                      1.5109742
QF Loss                      619.19714
VF Loss                      581.7615
Policy Loss                  -1273.6273
Q Predictions Mean           1271.3931
Q Predictions Std            396.1568
Q Predictions Max            1573.1835
Q Predictions Min            -2.272234
V Predictions Mean           1262.7057
V Predictions Std            393.72223
V Predictions Max            1567.0874
V Predictions Min            0.39719552
Log Pis Mean                 -0.33203757
Log Pis Std                  2.0712516
Log Pis Max                  7.04541
Log Pis Min                  -4.849588
Policy mu Mean               0.038729023
Policy mu Std                0.8973731
Policy mu Max                2.623483
Policy mu Min                -3.1783304
Policy log std Mean          -0.40946993
Policy log std Std           0.18808728
Policy log std Max           -0.03804475
Policy log std Min           -1.8051505
Z mean eval                  1.0784338
Z variance eval              0.01155835
total_rewards                [2847.17908263 2785.62074034 1949.75001132 2878.85448284 2916.44679407
 2906.68686538 2762.31394096 2880.10496583 2781.52215068 1601.55042668]
total_rewards_mean           2631.0029460730307
total_rewards_std            437.6502550770445
total_rewards_max            2916.4467940675772
total_rewards_min            1601.5504266808803
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               34.29696946917102
(Previous) Eval Time (s)     23.116466014180332
Sample Time (s)              22.434253150131553
Epoch Time (s)               79.8476886334829
Total Train Time (s)         26901.024411148857
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:05.710097 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #410 | Epoch Duration: 84.96147871017456
2020-01-11 07:31:05.710240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0795645
Z variance train             0.011596296
KL Divergence                14.297369
KL Loss                      1.429737
QF Loss                      81.734665
VF Loss                      165.98955
Policy Loss                  -1293.7709
Q Predictions Mean           1291.452
Q Predictions Std            351.64505
Q Predictions Max            1586.3877
Q Predictions Min            0.9720232
V Predictions Mean           1283.2844
V Predictions Std            350.56058
V Predictions Max            1573.7518
V Predictions Min            2.1955807
Log Pis Mean                 -0.5188634
Log Pis Std                  1.8260655
Log Pis Max                  6.1821985
Log Pis Min                  -4.961009
Policy mu Mean               0.029619271
Policy mu Std                0.8211021
Policy mu Max                2.7006643
Policy mu Min                -2.8791034
Policy log std Mean          -0.41849682
Policy log std Std           0.15718602
Policy log std Max           -0.053480536
Policy log std Min           -1.0578502
Z mean eval                  1.0775278
Z variance eval              0.018281711
total_rewards                [2911.78504791 2317.40684032 2449.72469571  967.05727787 3065.29105613
 3081.99473867 2995.35710946 2971.21338508 2328.36208641  960.40513579]
total_rewards_mean           2404.859737335741
total_rewards_std            773.9726080949665
total_rewards_max            3081.9947386744793
total_rewards_min            960.4051357933743
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               32.95895586209372
(Previous) Eval Time (s)     28.229979482013732
Sample Time (s)              23.713548979721963
Epoch Time (s)               84.90248432382941
Total Train Time (s)         26981.157701618504
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:25.850081 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #411 | Epoch Duration: 80.13968992233276
2020-01-11 07:32:25.850299 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0785656
Z variance train             0.018303413
KL Divergence                13.274491
KL Loss                      1.3274492
QF Loss                      126.19229
VF Loss                      51.923042
Policy Loss                  -1328.3788
Q Predictions Mean           1327.6891
Q Predictions Std            401.07617
Q Predictions Max            1655.6515
Q Predictions Min            -1.7405009
V Predictions Mean           1327.8181
V Predictions Std            401.0553
V Predictions Max            1661.5469
V Predictions Min            2.5268774
Log Pis Mean                 -0.52767754
Log Pis Std                  1.9107804
Log Pis Max                  7.307398
Log Pis Min                  -5.282143
Policy mu Mean               0.069127925
Policy mu Std                0.82488716
Policy mu Max                2.380341
Policy mu Min                -2.8140423
Policy log std Mean          -0.41697025
Policy log std Std           0.16417934
Policy log std Max           -0.0712682
Policy log std Min           -1.1725384
Z mean eval                  1.0657549
Z variance eval              0.014893839
total_rewards                [3082.44830189 1601.49632115 2411.43596249 1431.73639743 1697.00249088
 2938.10337284 2970.94312425 2510.17722822 2928.69077889 2959.39860009]
total_rewards_mean           2453.1432578138106
total_rewards_std            610.4984423072585
total_rewards_max            3082.448301889534
total_rewards_min            1431.7363974262148
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               32.823699882254004
(Previous) Eval Time (s)     23.466852874029428
Sample Time (s)              23.620948165655136
Epoch Time (s)               79.91150092193857
Total Train Time (s)         27062.723946031183
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:47.423675 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #412 | Epoch Duration: 81.57322239875793
2020-01-11 07:33:47.423940 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0630318
Z variance train             0.014866238
KL Divergence                13.8638525
KL Loss                      1.3863853
QF Loss                      231.03763
VF Loss                      66.29703
Policy Loss                  -1161.3982
Q Predictions Mean           1159.2104
Q Predictions Std            405.46298
Q Predictions Max            1512.1968
Q Predictions Min            -8.919178
V Predictions Mean           1164.3867
V Predictions Std            407.14148
V Predictions Max            1514.4222
V Predictions Min            -3.5552528
Log Pis Mean                 -0.34521276
Log Pis Std                  2.0685449
Log Pis Max                  9.588148
Log Pis Min                  -4.2260222
Policy mu Mean               -0.03397653
Policy mu Std                0.876653
Policy mu Max                2.6173356
Policy mu Min                -3.475725
Policy log std Mean          -0.43550992
Policy log std Std           0.18420762
Policy log std Max           -0.066602275
Policy log std Min           -1.1686229
Z mean eval                  1.0556533
Z variance eval              0.012247838
total_rewards                [2884.96536912 2981.21561092 2904.47770693 2274.25356415 1096.68204935
 2910.81114334 2890.13616811 2903.12306466 2977.10609319 2945.50147067]
total_rewards_mean           2676.8272240441015
total_rewards_std            562.1863643162037
total_rewards_max            2981.215610919874
total_rewards_min            1096.6820493545179
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               32.9162467638962
(Previous) Eval Time (s)     25.12822941876948
Sample Time (s)              23.016133116558194
Epoch Time (s)               81.06060929922387
Total Train Time (s)         27145.36467990419
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:10.068604 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #413 | Epoch Duration: 82.64443612098694
2020-01-11 07:35:10.068864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0524565
Z variance train             0.012258793
KL Divergence                14.190842
KL Loss                      1.4190842
QF Loss                      170.57965
VF Loss                      232.47366
Policy Loss                  -1250.4954
Q Predictions Mean           1254.3516
Q Predictions Std            403.3559
Q Predictions Max            1562.5325
Q Predictions Min            5.9097095
V Predictions Mean           1260.6897
V Predictions Std            406.20578
V Predictions Max            1562.762
V Predictions Min            3.1753116
Log Pis Mean                 -0.44726127
Log Pis Std                  2.0696824
Log Pis Max                  6.0506597
Log Pis Min                  -8.368693
Policy mu Mean               -0.12180152
Policy mu Std                0.8807665
Policy mu Max                2.043541
Policy mu Min                -2.767695
Policy log std Mean          -0.38584003
Policy log std Std           0.16047738
Policy log std Max           0.014477685
Policy log std Min           -1.0559942
Z mean eval                  1.0719601
Z variance eval              0.01734507
total_rewards                [3014.55714245  858.30901113 2962.72222932 2483.46885424 1489.73236095
 2995.22902962 2454.21844384 3161.61462983 1411.10476032  876.92236285]
total_rewards_mean           2170.787882454657
total_rewards_std            872.7137867291548
total_rewards_max            3161.6146298282347
total_rewards_min            858.3090111303952
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               33.64543708693236
(Previous) Eval Time (s)     26.71172507898882
Sample Time (s)              23.845617258921266
Epoch Time (s)               84.20277942484245
Total Train Time (s)         27223.61300239805
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:28.321403 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #414 | Epoch Duration: 78.25238680839539
2020-01-11 07:36:28.321597 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0781819
Z variance train             0.017368037
KL Divergence                14.700466
KL Loss                      1.4700466
QF Loss                      224.49721
VF Loss                      173.22101
Policy Loss                  -1176.5679
Q Predictions Mean           1175.2285
Q Predictions Std            426.5963
Q Predictions Max            1522.3453
Q Predictions Min            5.823868
V Predictions Mean           1166.7754
V Predictions Std            425.6167
V Predictions Max            1529.4642
V Predictions Min            6.359294
Log Pis Mean                 -0.17118828
Log Pis Std                  2.044231
Log Pis Max                  5.2915597
Log Pis Min                  -5.852798
Policy mu Mean               -0.013664335
Policy mu Std                0.88590485
Policy mu Max                2.9838057
Policy mu Min                -2.7010221
Policy log std Mean          -0.41797018
Policy log std Std           0.193307
Policy log std Max           -0.018584102
Policy log std Min           -1.2633501
Z mean eval                  1.0466582
Z variance eval              0.011599449
total_rewards                [2707.50761794 3060.99895047 1024.33518624 2414.16636602 2973.0943339
 1879.00675133  913.8096413  3067.37802179 3138.52760665 3040.46962514]
total_rewards_mean           2421.929410077511
total_rewards_std            814.1852723163738
total_rewards_max            3138.527606649223
total_rewards_min            913.8096412989365
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               33.00351982191205
(Previous) Eval Time (s)     20.761024159844965
Sample Time (s)              21.62043973337859
Epoch Time (s)               75.3849837151356
Total Train Time (s)         27301.57500432711
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:46.286772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #415 | Epoch Duration: 77.96504998207092
2020-01-11 07:37:46.286902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0449903
Z variance train             0.011593945
KL Divergence                13.918712
KL Loss                      1.3918712
QF Loss                      341.828
VF Loss                      116.49615
Policy Loss                  -1261.2052
Q Predictions Mean           1260.1345
Q Predictions Std            338.26483
Q Predictions Max            1546.69
Q Predictions Min            3.4282541
V Predictions Mean           1264.9275
V Predictions Std            336.88446
V Predictions Max            1550.7146
V Predictions Min            5.887926
Log Pis Mean                 -0.39705837
Log Pis Std                  2.0809639
Log Pis Max                  8.6964035
Log Pis Min                  -5.731353
Policy mu Mean               -0.025315957
Policy mu Std                0.8667111
Policy mu Max                2.5603776
Policy mu Min                -3.7079587
Policy log std Mean          -0.40875685
Policy log std Std           0.1728353
Policy log std Max           -0.04424344
Policy log std Min           -1.2752794
Z mean eval                  1.063027
Z variance eval              0.012708964
total_rewards                [1091.03484692 3018.39345822  830.35943369 1560.15756625 3175.61566804
 1470.85774047 1541.54979363 3082.68054213 1224.96952093  817.9422945 ]
total_rewards_mean           1781.356086479063
total_rewards_std            893.8222327364995
total_rewards_max            3175.61566803531
total_rewards_min            817.942294502911
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               32.988776018843055
(Previous) Eval Time (s)     23.34080448327586
Sample Time (s)              23.04708032729104
Epoch Time (s)               79.37666082940996
Total Train Time (s)         27374.31464442052
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:59.030874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #416 | Epoch Duration: 72.74385595321655
2020-01-11 07:38:59.031059 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628399
Z variance train             0.012670383
KL Divergence                13.641874
KL Loss                      1.3641875
QF Loss                      127.68895
VF Loss                      30.142004
Policy Loss                  -1227.037
Q Predictions Mean           1225.2476
Q Predictions Std            434.4431
Q Predictions Max            1551.7284
Q Predictions Min            -0.41623503
V Predictions Mean           1226.1355
V Predictions Std            434.98132
V Predictions Max            1546.5161
V Predictions Min            -0.04419017
Log Pis Mean                 -0.3955041
Log Pis Std                  1.9953929
Log Pis Max                  7.6774197
Log Pis Min                  -4.302561
Policy mu Mean               0.016612263
Policy mu Std                0.8951856
Policy mu Max                2.5977113
Policy mu Min                -2.660421
Policy log std Mean          -0.39241084
Policy log std Std           0.16176045
Policy log std Max           0.11007416
Policy log std Min           -1.1900047
Z mean eval                  1.0414441
Z variance eval              0.009714458
total_rewards                [2394.12136543 3059.81734952 2309.14854158  890.12946703 2551.0571413
 2945.85131816 3132.77367319 3033.82767433 3121.46786265 3139.32029235]
total_rewards_mean           2657.7514685540627
total_rewards_std            662.2367689389497
total_rewards_max            3139.3202923503723
total_rewards_min            890.1294670288075
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               32.90753849130124
(Previous) Eval Time (s)     16.707634733989835
Sample Time (s)              23.705583185423166
Epoch Time (s)               73.32075641071424
Total Train Time (s)         27455.342651006766
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:20.063123 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #417 | Epoch Duration: 81.03191018104553
2020-01-11 07:40:20.063352 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0421536
Z variance train             0.009719332
KL Divergence                14.486601
KL Loss                      1.4486601
QF Loss                      196.13297
VF Loss                      169.61609
Policy Loss                  -1243.0171
Q Predictions Mean           1239.1606
Q Predictions Std            443.52652
Q Predictions Max            1564.5427
Q Predictions Min            -2.6846874
V Predictions Mean           1240.5826
V Predictions Std            439.90442
V Predictions Max            1571.2675
V Predictions Min            3.2426157
Log Pis Mean                 -0.29283863
Log Pis Std                  2.1294286
Log Pis Max                  6.7275457
Log Pis Min                  -4.6259394
Policy mu Mean               -0.0020604108
Policy mu Std                0.91190875
Policy mu Max                2.8117757
Policy mu Min                -3.6765265
Policy log std Mean          -0.410396
Policy log std Std           0.17468533
Policy log std Max           0.038891047
Policy log std Min           -1.1175821
Z mean eval                  1.0655667
Z variance eval              0.009027256
total_rewards                [1608.82655363 2979.63214151 2942.59209114 1044.54933182 2208.1539918
  911.36881456 1556.28979037 2971.57660658 1522.57596254 3062.40030715]
total_rewards_mean           2080.7965591101824
total_rewards_std            810.844911606247
total_rewards_max            3062.400307150085
total_rewards_min            911.3688145622293
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               33.655080537777394
(Previous) Eval Time (s)     24.41848113760352
Sample Time (s)              23.474501193501055
Epoch Time (s)               81.54806286888197
Total Train Time (s)         27532.85146175744
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:37.576196 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #418 | Epoch Duration: 77.51270580291748
2020-01-11 07:41:37.576378 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0664179
Z variance train             0.009022263
KL Divergence                14.613289
KL Loss                      1.4613289
QF Loss                      165.22092
VF Loss                      93.29785
Policy Loss                  -1241.4626
Q Predictions Mean           1241.7273
Q Predictions Std            426.94324
Q Predictions Max            1588.9172
Q Predictions Min            0.79893607
V Predictions Mean           1235.523
V Predictions Std            426.0036
V Predictions Max            1591.8237
V Predictions Min            1.051698
Log Pis Mean                 -0.38412878
Log Pis Std                  1.9275894
Log Pis Max                  6.748355
Log Pis Min                  -4.9580765
Policy mu Mean               -0.058644604
Policy mu Std                0.83246744
Policy mu Max                2.36356
Policy mu Min                -2.7564027
Policy log std Mean          -0.39699996
Policy log std Std           0.17325187
Policy log std Max           0.16104239
Policy log std Min           -1.2070572
Z mean eval                  1.0524094
Z variance eval              0.010474824
total_rewards                [2270.03244414 3022.18986466 3001.15465129 1739.28606499 2972.54534695
 3013.49859299 1026.76517905 2865.59058042 2909.26554811  934.98112981]
total_rewards_mean           2375.5309402394546
total_rewards_std            800.5200254553627
total_rewards_max            3022.1898646552563
total_rewards_min            934.9811298141666
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               33.187317855190486
(Previous) Eval Time (s)     20.38279165001586
Sample Time (s)              23.402281287126243
Epoch Time (s)               76.97239079233259
Total Train Time (s)         27612.94599464722
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:57.683449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #419 | Epoch Duration: 80.10693025588989
2020-01-11 07:42:57.683647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054231
Z variance train             0.010473376
KL Divergence                14.269262
KL Loss                      1.4269263
QF Loss                      87.16214
VF Loss                      29.667475
Policy Loss                  -1314.5889
Q Predictions Mean           1312.4489
Q Predictions Std            404.7722
Q Predictions Max            1628.1086
Q Predictions Min            1.6483192
V Predictions Mean           1313.7808
V Predictions Std            403.80707
V Predictions Max            1630.3374
V Predictions Min            4.66984
Log Pis Mean                 -0.5077146
Log Pis Std                  1.9060314
Log Pis Max                  7.6262665
Log Pis Min                  -4.2432704
Policy mu Mean               -0.019828098
Policy mu Std                0.8254708
Policy mu Max                2.3619478
Policy mu Min                -2.9193664
Policy log std Mean          -0.3803568
Policy log std Std           0.16157593
Policy log std Max           0.053754747
Policy log std Min           -1.0916597
Z mean eval                  1.0542655
Z variance eval              0.010362705
total_rewards                [1698.13948017  972.95989274 2487.48823467 2277.92937812 1434.88401935
 2865.15444649 2663.77232842 1423.30938966 2885.72983869  994.49592862]
total_rewards_mean           1970.3862936926369
total_rewards_std            713.3456941841288
total_rewards_max            2885.729838692506
total_rewards_min            972.9598927359935
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               33.92771780397743
(Previous) Eval Time (s)     23.517035722732544
Sample Time (s)              23.49315678142011
Epoch Time (s)               80.93791030813009
Total Train Time (s)         27688.956881590653
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:13.690107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #420 | Epoch Duration: 76.00632357597351
2020-01-11 07:44:13.690298 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.055331
Z variance train             0.010359446
KL Divergence                13.9570265
KL Loss                      1.3957027
QF Loss                      172.89145
VF Loss                      65.235756
Policy Loss                  -1278.9391
Q Predictions Mean           1277.1753
Q Predictions Std            394.1562
Q Predictions Max            1570.952
Q Predictions Min            2.29717
V Predictions Mean           1276.8545
V Predictions Std            392.11884
V Predictions Max            1576.4618
V Predictions Min            -2.3370926
Log Pis Mean                 -0.4310161
Log Pis Std                  2.1092603
Log Pis Max                  8.129559
Log Pis Min                  -7.9084196
Policy mu Mean               0.029457157
Policy mu Std                0.8535874
Policy mu Max                2.1246748
Policy mu Min                -2.7565262
Policy log std Mean          -0.4220066
Policy log std Std           0.1800651
Policy log std Max           0.021067113
Policy log std Min           -1.1697713
Z mean eval                  1.0587541
Z variance eval              0.011192018
total_rewards                [3122.87123879 3050.67827872 2556.50829398 3113.23621774 3079.92397514
 1030.41954999 3133.58651968 2937.26606731 2512.7611161  2878.14684376]
total_rewards_mean           2741.539810121335
total_rewards_std            609.8214560933516
total_rewards_max            3133.5865196757095
total_rewards_min            1030.4195499919595
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               32.794207458384335
(Previous) Eval Time (s)     18.585109042935073
Sample Time (s)              23.31549445539713
Epoch Time (s)               74.69481095671654
Total Train Time (s)         27772.36299381638
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:37.099589 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #421 | Epoch Duration: 83.40915656089783
2020-01-11 07:45:37.099747 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0582473
Z variance train             0.011229539
KL Divergence                13.839845
KL Loss                      1.3839844
QF Loss                      309.1016
VF Loss                      40.511368
Policy Loss                  -1225.3472
Q Predictions Mean           1219.9253
Q Predictions Std            419.69968
Q Predictions Max            1540.1552
Q Predictions Min            2.724485
V Predictions Mean           1227.0465
V Predictions Std            415.30667
V Predictions Max            1541.2914
V Predictions Min            4.5324225
Log Pis Mean                 -0.46751237
Log Pis Std                  2.053285
Log Pis Max                  11.781247
Log Pis Min                  -7.268454
Policy mu Mean               0.051320925
Policy mu Std                0.84660316
Policy mu Max                3.0957828
Policy mu Min                -3.9865046
Policy log std Mean          -0.40229073
Policy log std Std           0.16697109
Policy log std Max           0.10603824
Policy log std Min           -1.1634555
Z mean eval                  1.0660305
Z variance eval              0.009127271
total_rewards                [3082.01217881 3027.91469653 3080.48547422 3072.73785779 3152.6500084
 3038.66249722 1466.10809493 2970.29684919 2477.13883614 3078.88499243]
total_rewards_mean           2844.6891485659994
total_rewards_std            493.5756715637765
total_rewards_max            3152.650008402896
total_rewards_min            1466.1080949322868
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               32.87428359221667
(Previous) Eval Time (s)     27.29915933078155
Sample Time (s)              22.90430259006098
Epoch Time (s)               83.0777455130592
Total Train Time (s)         27855.071813335177
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:46:59.811300 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #422 | Epoch Duration: 82.7114429473877
2020-01-11 07:46:59.811439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0681791
Z variance train             0.009116466
KL Divergence                14.312281
KL Loss                      1.431228
QF Loss                      172.7793
VF Loss                      93.44111
Policy Loss                  -1306.7607
Q Predictions Mean           1303.6484
Q Predictions Std            393.35278
Q Predictions Max            1589.8026
Q Predictions Min            -0.9534544
V Predictions Mean           1301.6077
V Predictions Std            393.26456
V Predictions Max            1588.859
V Predictions Min            4.658011
Log Pis Mean                 -0.8195386
Log Pis Std                  1.5702788
Log Pis Max                  5.8007903
Log Pis Min                  -5.4253454
Policy mu Mean               -0.0371641
Policy mu Std                0.75580585
Policy mu Max                2.7527514
Policy mu Min                -2.6460307
Policy log std Mean          -0.38654938
Policy log std Std           0.14948922
Policy log std Max           -0.0830003
Policy log std Min           -1.1610564
Z mean eval                  1.0391352
Z variance eval              0.0125827845
total_rewards                [2903.37956086 2928.28395189 2946.64044474 2973.98813268 2688.24038748
 2924.94916726 2908.72552191 2958.41317336 2943.61937665 2840.33453672]
total_rewards_mean           2901.6574253552308
total_rewards_std            79.27733166871413
total_rewards_max            2973.9881326796435
total_rewards_min            2688.240387481104
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               32.98697636928409
(Previous) Eval Time (s)     26.9325430681929
Sample Time (s)              24.10039698285982
Epoch Time (s)               84.01991642033681
Total Train Time (s)         27941.072452377994
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:25.818278 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #423 | Epoch Duration: 86.0066168308258
2020-01-11 07:48:25.818621 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0365757
Z variance train             0.012537341
KL Divergence                13.333165
KL Loss                      1.3333166
QF Loss                      806.51575
VF Loss                      61.970108
Policy Loss                  -1252.4749
Q Predictions Mean           1251.3745
Q Predictions Std            367.23795
Q Predictions Max            1546.1711
Q Predictions Min            2.522289
V Predictions Mean           1256.0266
V Predictions Std            366.64304
V Predictions Max            1540.735
V Predictions Min            1.7365024
Log Pis Mean                 -0.46385053
Log Pis Std                  2.054857
Log Pis Max                  10.976774
Log Pis Min                  -5.4627395
Policy mu Mean               0.0056520044
Policy mu Std                0.8434366
Policy mu Max                3.1646392
Policy mu Min                -2.7185807
Policy log std Mean          -0.421209
Policy log std Std           0.16872467
Policy log std Max           -0.08100748
Policy log std Min           -1.1753283
Z mean eval                  1.0570227
Z variance eval              0.012142228
total_rewards                [3094.83622999  984.49873041 3081.13875306 1594.95221088 2929.83785228
 3005.69906302 3113.62521568 2933.75234652 3082.44082624 1311.5704762 ]
total_rewards_mean           2513.235170427955
total_rewards_std            810.0881104137688
total_rewards_max            3113.625215682706
total_rewards_min            984.4987304069997
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               32.85179383913055
(Previous) Eval Time (s)     28.918851302936673
Sample Time (s)              23.901281708385795
Epoch Time (s)               85.67192685045302
Total Train Time (s)         28022.333737145644
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:47.084105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #424 | Epoch Duration: 81.26527714729309
2020-01-11 07:49:47.084369 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0551794
Z variance train             0.012176502
KL Divergence                14.046986
KL Loss                      1.4046986
QF Loss                      162.73795
VF Loss                      117.64231
Policy Loss                  -1295.9219
Q Predictions Mean           1292.9888
Q Predictions Std            395.74902
Q Predictions Max            1576.591
Q Predictions Min            -28.56688
V Predictions Mean           1298.3302
V Predictions Std            395.41583
V Predictions Max            1579.6125
V Predictions Min            4.8331885
Log Pis Mean                 -0.45309722
Log Pis Std                  1.9259063
Log Pis Max                  7.2748814
Log Pis Min                  -5.4164257
Policy mu Mean               -0.0038631558
Policy mu Std                0.84641
Policy mu Max                1.6757772
Policy mu Min                -2.9178243
Policy log std Mean          -0.42625487
Policy log std Std           0.1701791
Policy log std Max           0.07187042
Policy log std Min           -1.1879299
Z mean eval                  1.0553836
Z variance eval              0.008742126
total_rewards                [ 894.12490773  940.56326227 2399.3437104  1535.51418953 1623.25162312
 2974.83810734 2928.16968808 3126.09788026 1530.68137097 1663.0969626 ]
total_rewards_mean           1961.5681702286486
total_rewards_std            791.2917316444871
total_rewards_max            3126.0978802567724
total_rewards_min            894.124907729012
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               33.263694087043405
(Previous) Eval Time (s)     24.511882500257343
Sample Time (s)              23.26748379971832
Epoch Time (s)               81.04306038701907
Total Train Time (s)         28097.341202819254
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:02.096451 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #425 | Epoch Duration: 75.01179647445679
2020-01-11 07:51:02.096870 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0527077
Z variance train             0.008749223
KL Divergence                14.624594
KL Loss                      1.4624594
QF Loss                      114.7825
VF Loss                      58.023563
Policy Loss                  -1313.8037
Q Predictions Mean           1313.9994
Q Predictions Std            383.21466
Q Predictions Max            1617.2692
Q Predictions Min            0.6402598
V Predictions Mean           1317.2911
V Predictions Std            383.99893
V Predictions Max            1614.2445
V Predictions Min            -3.2978575
Log Pis Mean                 -0.46881106
Log Pis Std                  1.9291459
Log Pis Max                  5.711061
Log Pis Min                  -4.1247997
Policy mu Mean               0.054769
Policy mu Std                0.84355885
Policy mu Max                2.1387138
Policy mu Min                -2.9297097
Policy log std Mean          -0.4165034
Policy log std Std           0.1762883
Policy log std Max           -0.036593407
Policy log std Min           -1.2634101
Z mean eval                  1.0423443
Z variance eval              0.011420147
total_rewards                [3074.54520729 1710.41966372  858.33046606  834.79348991 3113.29885261
 2264.56625858  973.29988149 3057.32029741 1661.33212154 3088.18487133]
total_rewards_mean           2063.6091109938825
total_rewards_std            929.4874797810877
total_rewards_max            3113.2988526086096
total_rewards_min            834.7934899111796
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               33.350986961741
(Previous) Eval Time (s)     18.480242318008095
Sample Time (s)              22.020819348748773
Epoch Time (s)               73.85204862849787
Total Train Time (s)         28172.22581027262
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:52:16.984150 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #426 | Epoch Duration: 74.88707160949707
2020-01-11 07:52:16.984329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0418136
Z variance train             0.011449523
KL Divergence                13.563544
KL Loss                      1.3563545
QF Loss                      138.35226
VF Loss                      99.9507
Policy Loss                  -1228.9226
Q Predictions Mean           1228.2174
Q Predictions Std            400.5745
Q Predictions Max            1539.9663
Q Predictions Min            -0.6812114
V Predictions Mean           1228.0339
V Predictions Std            398.55188
V Predictions Max            1535.7548
V Predictions Min            5.9606495
Log Pis Mean                 -0.57202363
Log Pis Std                  1.8656198
Log Pis Max                  5.5594616
Log Pis Min                  -5.7324886
Policy mu Mean               -0.016761309
Policy mu Std                0.81614405
Policy mu Max                2.1774952
Policy mu Min                -2.9103057
Policy log std Mean          -0.41989532
Policy log std Std           0.17891617
Policy log std Max           0.062705666
Policy log std Min           -1.3961781
Z mean eval                  1.0435617
Z variance eval              0.013366732
total_rewards                [3107.70350855 2150.08266179 1713.16940443  958.90144414 3133.25370776
 1509.64058882 2302.97133861 2538.24492578  849.55778638 2450.34235875]
total_rewards_mean           2071.386772500549
total_rewards_std            761.3980710711099
total_rewards_max            3133.253707760842
total_rewards_min            849.5577863806702
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               33.30205583292991
(Previous) Eval Time (s)     19.514964333735406
Sample Time (s)              22.713738836813718
Epoch Time (s)               75.53075900347903
Total Train Time (s)         28247.747529151384
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:32.510901 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #427 | Epoch Duration: 75.52641415596008
2020-01-11 07:53:32.511160 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0440266
Z variance train             0.013355563
KL Divergence                13.934266
KL Loss                      1.3934267
QF Loss                      126.999435
VF Loss                      90.547195
Policy Loss                  -1321.5531
Q Predictions Mean           1320.3984
Q Predictions Std            322.25488
Q Predictions Max            1562.7932
Q Predictions Min            0.36793387
V Predictions Mean           1315.1843
V Predictions Std            322.24295
V Predictions Max            1555.3148
V Predictions Min            1.3652129
Log Pis Mean                 -0.49157354
Log Pis Std                  1.967165
Log Pis Max                  7.418954
Log Pis Min                  -5.961
Policy mu Mean               0.03193519
Policy mu Std                0.8432855
Policy mu Max                2.9683783
Policy mu Min                -2.632947
Policy log std Mean          -0.407204
Policy log std Std           0.1728044
Policy log std Max           -0.06515869
Policy log std Min           -1.190562
Z mean eval                  1.0410327
Z variance eval              0.010624825
total_rewards                [3218.56137433 1287.33832084  943.24199253  964.50511883 3090.10378475
 3289.09197145 3171.42606074 3219.79953738 3202.50704937 2995.12863162]
total_rewards_mean           2538.1703841824446
total_rewards_std            971.1864136144347
total_rewards_max            3289.09197144566
total_rewards_min            943.2419925268996
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               33.16518386406824
(Previous) Eval Time (s)     19.510288106743246
Sample Time (s)              23.37242423836142
Epoch Time (s)               76.0478962091729
Total Train Time (s)         28327.969086124096
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:52.736964 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #428 | Epoch Duration: 80.22561454772949
2020-01-11 07:54:52.737153 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0404403
Z variance train             0.010624093
KL Divergence                13.8563595
KL Loss                      1.385636
QF Loss                      104.31761
VF Loss                      44.64256
Policy Loss                  -1400.1178
Q Predictions Mean           1399.9016
Q Predictions Std            350.6993
Q Predictions Max            1659.583
Q Predictions Min            5.9114203
V Predictions Mean           1397.9241
V Predictions Std            349.67618
V Predictions Max            1659.568
V Predictions Min            3.009037
Log Pis Mean                 -0.69053704
Log Pis Std                  1.7391201
Log Pis Max                  6.717148
Log Pis Min                  -5.3435054
Policy mu Mean               0.05272012
Policy mu Std                0.7692897
Policy mu Max                2.5733395
Policy mu Min                -2.650767
Policy log std Mean          -0.39582703
Policy log std Std           0.16911095
Policy log std Max           -0.040831476
Policy log std Min           -1.1669883
Z mean eval                  1.044125
Z variance eval              0.009419956
total_rewards                [1104.23280432 2445.5619721  1398.57519974  892.5537774  3056.1280053
 3247.71028855 2591.5435956  1247.27745321 2820.19485771 1052.46905018]
total_rewards_mean           1985.6247004110999
total_rewards_std            880.127471728509
total_rewards_max            3247.7102885484355
total_rewards_min            892.5537774043339
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               33.55683508096263
(Previous) Eval Time (s)     23.68768321396783
Sample Time (s)              23.391854436602443
Epoch Time (s)               80.6363727315329
Total Train Time (s)         28403.434440207202
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:08.206359 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #429 | Epoch Duration: 75.46905946731567
2020-01-11 07:56:08.206570 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0440743
Z variance train             0.009414509
KL Divergence                14.603485
KL Loss                      1.4603485
QF Loss                      79.24698
VF Loss                      49.969578
Policy Loss                  -1387.2507
Q Predictions Mean           1386.3281
Q Predictions Std            305.51044
Q Predictions Max            1613.6283
Q Predictions Min            12.695158
V Predictions Mean           1382.9457
V Predictions Std            303.11264
V Predictions Max            1602.8914
V Predictions Min            14.9799385
Log Pis Mean                 -0.597147
Log Pis Std                  1.7494326
Log Pis Max                  5.4808965
Log Pis Min                  -4.601125
Policy mu Mean               0.07388898
Policy mu Std                0.8056471
Policy mu Max                2.579442
Policy mu Min                -2.7882934
Policy log std Mean          -0.38190627
Policy log std Std           0.15205665
Policy log std Max           -0.0771708
Policy log std Min           -1.0136052
Z mean eval                  1.0490372
Z variance eval              0.00899154
total_rewards                [ 847.2751647   897.38060356 3177.37982544 1627.99660306  837.36802838
  968.88774904 1963.81714771 2403.75313529 1390.46286558 2501.48164923]
total_rewards_mean           1661.5802771998265
total_rewards_std            782.6956946056198
total_rewards_max            3177.379825444085
total_rewards_min            837.3680283813501
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               33.40124863293022
(Previous) Eval Time (s)     18.520005657803267
Sample Time (s)              22.97997470293194
Epoch Time (s)               74.90122899366543
Total Train Time (s)         28473.64336321922
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:18.420410 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #430 | Epoch Duration: 70.21367835998535
2020-01-11 07:57:18.420625 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.049523
Z variance train             0.009024026
KL Divergence                14.953922
KL Loss                      1.4953922
QF Loss                      101.43097
VF Loss                      45.056
Policy Loss                  -1331.6681
Q Predictions Mean           1330.9407
Q Predictions Std            391.9701
Q Predictions Max            1640.6365
Q Predictions Min            -3.6162364
V Predictions Mean           1328.7323
V Predictions Std            392.2348
V Predictions Max            1636.3092
V Predictions Min            -1.765902
Log Pis Mean                 -0.47736335
Log Pis Std                  1.7861758
Log Pis Max                  6.5417023
Log Pis Min                  -4.275028
Policy mu Mean               0.043856498
Policy mu Std                0.8324065
Policy mu Max                2.5421371
Policy mu Min                -2.7461247
Policy log std Mean          -0.40865874
Policy log std Std           0.14951086
Policy log std Max           -0.057412058
Policy log std Min           -0.98771816
Z mean eval                  1.0640265
Z variance eval              0.012043557
total_rewards                [ 933.3005966  3111.24288944 3182.57960405 3220.07672238 2498.61496432
 2909.42571352 1671.81763175 2782.95806491 3219.55355407 3187.54494512]
total_rewards_mean           2671.711468616668
total_rewards_std            737.6855706499578
total_rewards_max            3220.07672237751
total_rewards_min            933.3005966043955
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               33.31959367822856
(Previous) Eval Time (s)     13.832109237089753
Sample Time (s)              22.409796459134668
Epoch Time (s)               69.56149937445298
Total Train Time (s)         28553.40880423924
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:58:38.190107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #431 | Epoch Duration: 79.7693133354187
2020-01-11 07:58:38.190334 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609226
Z variance train             0.012064801
KL Divergence                15.009446
KL Loss                      1.5009446
QF Loss                      174.94467
VF Loss                      74.20582
Policy Loss                  -1316.487
Q Predictions Mean           1316.7903
Q Predictions Std            403.12524
Q Predictions Max            1595.5061
Q Predictions Min            -2.0332751
V Predictions Mean           1319.9932
V Predictions Std            400.3641
V Predictions Max            1601.0815
V Predictions Min            4.3467617
Log Pis Mean                 -0.7247469
Log Pis Std                  1.6600667
Log Pis Max                  7.657606
Log Pis Min                  -4.577573
Policy mu Mean               0.0023065582
Policy mu Std                0.7737388
Policy mu Max                2.6746523
Policy mu Min                -2.6408222
Policy log std Mean          -0.38780424
Policy log std Std           0.14670151
Policy log std Max           -0.06480101
Policy log std Min           -1.0391406
Z mean eval                  1.0809214
Z variance eval              0.01770511
total_rewards                [3129.31002072  867.87865322 1265.69704973 1245.08909777 1644.17885461
 3179.64562507  855.23234708 3131.97849588  924.5624267  3131.31321591]
total_rewards_mean           1937.4885786709383
total_rewards_std            1008.6392184989827
total_rewards_max            3179.6456250704587
total_rewards_min            855.2323470837399
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               32.86813480965793
(Previous) Eval Time (s)     24.039591622073203
Sample Time (s)              22.597780093550682
Epoch Time (s)               79.50550652528182
Total Train Time (s)         28626.483992409892
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:51.275636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #432 | Epoch Duration: 73.08513569831848
2020-01-11 07:59:51.276077 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0803493
Z variance train             0.017668517
KL Divergence                14.348564
KL Loss                      1.4348564
QF Loss                      59.643692
VF Loss                      37.502426
Policy Loss                  -1322.673
Q Predictions Mean           1321.7085
Q Predictions Std            386.14136
Q Predictions Max            1602.5256
Q Predictions Min            1.1716392
V Predictions Mean           1324.1274
V Predictions Std            385.3575
V Predictions Max            1606.3632
V Predictions Min            2.8444967
Log Pis Mean                 -0.66183674
Log Pis Std                  1.9637772
Log Pis Max                  6.7821183
Log Pis Min                  -4.9336305
Policy mu Mean               -0.0077266567
Policy mu Std                0.81897753
Policy mu Max                3.1469936
Policy mu Min                -2.9325886
Policy log std Mean          -0.39443263
Policy log std Std           0.15876491
Policy log std Max           0.029754966
Policy log std Min           -1.1336479
Z mean eval                  1.06922
Z variance eval              0.013614638
total_rewards                [1506.52699572 2332.69040656 3092.83620453 1050.85790226 1585.86718411
 1015.54407992 2977.74352591  848.18082173 2540.87875326 2072.10757904]
total_rewards_mean           1902.3233453036187
total_rewards_std            779.4248850147876
total_rewards_max            3092.8362045250888
total_rewards_min            848.1808217324879
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               33.340230260044336
(Previous) Eval Time (s)     17.618873017840087
Sample Time (s)              23.49815666442737
Epoch Time (s)               74.4572599423118
Total Train Time (s)         28701.49036486866
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:06.300163 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #433 | Epoch Duration: 75.0237250328064
2020-01-11 08:01:06.300408 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0689695
Z variance train             0.013661939
KL Divergence                15.458571
KL Loss                      1.5458572
QF Loss                      180.68416
VF Loss                      152.8669
Policy Loss                  -1351.4746
Q Predictions Mean           1351.8203
Q Predictions Std            395.57812
Q Predictions Max            1623.1903
Q Predictions Min            -1.4088895
V Predictions Mean           1345.1514
V Predictions Std            390.7546
V Predictions Max            1615.6143
V Predictions Min            1.4642942
Log Pis Mean                 -0.7970271
Log Pis Std                  1.7460631
Log Pis Max                  6.5464616
Log Pis Min                  -5.8177557
Policy mu Mean               0.02646631
Policy mu Std                0.7614672
Policy mu Max                2.2349756
Policy mu Min                -2.8266878
Policy log std Mean          -0.38438508
Policy log std Std           0.15113297
Policy log std Max           -0.076456785
Policy log std Min           -1.1691017
Z mean eval                  1.0666304
Z variance eval              0.01267087
total_rewards                [ 935.0683425  2420.0402229  1168.96756721 2261.39354404 1300.62424242
 1273.26147913 1426.45915788 1025.40647489 3286.43337294 2484.96387088]
total_rewards_mean           1758.2618274787837
total_rewards_std            753.0762920524668
total_rewards_max            3286.4333729353752
total_rewards_min            935.0683425039889
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               33.555647226050496
(Previous) Eval Time (s)     18.185028430074453
Sample Time (s)              22.26265487074852
Epoch Time (s)               74.00333052687347
Total Train Time (s)         28772.555730439257
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:02:17.351249 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #434 | Epoch Duration: 71.05063891410828
2020-01-11 08:02:17.351429 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702856
Z variance train             0.012657173
KL Divergence                15.57036
KL Loss                      1.557036
QF Loss                      169.35477
VF Loss                      106.29888
Policy Loss                  -1363.2117
Q Predictions Mean           1362.0066
Q Predictions Std            381.46194
Q Predictions Max            1661.6838
Q Predictions Min            -3.7007723
V Predictions Mean           1356.5691
V Predictions Std            378.58014
V Predictions Max            1651.0625
V Predictions Min            4.7314095
Log Pis Mean                 -0.76486915
Log Pis Std                  1.8200188
Log Pis Max                  5.552407
Log Pis Min                  -4.0822678
Policy mu Mean               0.002861794
Policy mu Std                0.78121096
Policy mu Max                2.6131437
Policy mu Min                -2.8034682
Policy log std Mean          -0.38787177
Policy log std Std           0.16940436
Policy log std Max           -0.10716293
Policy log std Min           -1.2987134
Z mean eval                  1.055096
Z variance eval              0.010341478
total_rewards                [1521.85615288 1425.39070137 3166.22330376 3088.11543832 3079.60262174
 3147.29752562 3099.42886176 2692.76699692 1852.92247527 2475.67455816]
total_rewards_mean           2554.927863580987
total_rewards_std            666.4699167247599
total_rewards_max            3166.2233037632523
total_rewards_min            1425.3907013736796
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               33.5770917981863
(Previous) Eval Time (s)     15.232029550243169
Sample Time (s)              22.487240409478545
Epoch Time (s)               71.29636175790802
Total Train Time (s)         28853.541880534962
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:38.343115 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #435 | Epoch Duration: 80.99156498908997
2020-01-11 08:03:38.343304 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0521252
Z variance train             0.010296587
KL Divergence                15.119347
KL Loss                      1.5119346
QF Loss                      72.14963
VF Loss                      30.11464
Policy Loss                  -1363.9254
Q Predictions Mean           1364.7598
Q Predictions Std            328.92303
Q Predictions Max            1593.1353
Q Predictions Min            -1.1876984
V Predictions Mean           1365.7043
V Predictions Std            328.29257
V Predictions Max            1591.903
V Predictions Min            5.3670793
Log Pis Mean                 -0.52306414
Log Pis Std                  1.7518688
Log Pis Max                  7.639308
Log Pis Min                  -4.5762825
Policy mu Mean               -0.023491526
Policy mu Std                0.79393435
Policy mu Max                2.4405785
Policy mu Min                -2.7154284
Policy log std Mean          -0.3891559
Policy log std Std           0.16153897
Policy log std Max           -0.042935967
Policy log std Min           -1.3471568
Z mean eval                  1.0362033
Z variance eval              0.017474476
total_rewards                [3245.37782679 3238.23530366 3185.87759578 3222.65772517 3215.83429895
 1562.45905423  912.78148109 1009.67040512 3291.31304145 3215.82542873]
total_rewards_mean           2610.003216094457
total_rewards_std            961.3825319586206
total_rewards_max            3291.313041452071
total_rewards_min            912.7814810876664
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               33.26303449086845
(Previous) Eval Time (s)     24.92691066628322
Sample Time (s)              23.688213566783816
Epoch Time (s)               81.87815872393548
Total Train Time (s)         28935.010206087958
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:59.816000 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #436 | Epoch Duration: 81.47252130508423
2020-01-11 08:04:59.816252 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0377175
Z variance train             0.017500173
KL Divergence                12.709735
KL Loss                      1.2709736
QF Loss                      213.44748
VF Loss                      77.38911
Policy Loss                  -1314.8528
Q Predictions Mean           1313.4346
Q Predictions Std            340.5233
Q Predictions Max            1583.3734
Q Predictions Min            10.36954
V Predictions Mean           1311.2473
V Predictions Std            339.53107
V Predictions Max            1576.4475
V Predictions Min            3.3706694
Log Pis Mean                 -0.65465117
Log Pis Std                  1.6222367
Log Pis Max                  5.145171
Log Pis Min                  -4.805562
Policy mu Mean               0.013255513
Policy mu Std                0.76765037
Policy mu Max                1.8740809
Policy mu Min                -2.5803206
Policy log std Mean          -0.4107243
Policy log std Std           0.17410496
Policy log std Max           -0.065438405
Policy log std Min           -1.3244032
Z mean eval                  1.0537375
Z variance eval              0.0122171715
total_rewards                [1662.86940546 1536.62895697 3142.01753203 3151.33226186 3168.3580336
 3176.43703801 1824.11279501 3153.09030934 2184.06227503 2906.83425756]
total_rewards_mean           2590.5742864873246
total_rewards_std            666.0484490318805
total_rewards_max            3176.437038011721
total_rewards_min            1536.62895697431
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               33.38231573672965
(Previous) Eval Time (s)     24.520952473860234
Sample Time (s)              22.460432754829526
Epoch Time (s)               80.36370096541941
Total Train Time (s)         29015.817637751345
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:20.627124 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #437 | Epoch Duration: 80.81070709228516
2020-01-11 08:06:20.627400 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0561879
Z variance train             0.012221487
KL Divergence                13.528006
KL Loss                      1.3528006
QF Loss                      74.84961
VF Loss                      90.07936
Policy Loss                  -1385.9424
Q Predictions Mean           1387.3066
Q Predictions Std            340.5712
Q Predictions Max            1625.8003
Q Predictions Min            3.7978783
V Predictions Mean           1393.0144
V Predictions Std            340.9475
V Predictions Max            1626.0211
V Predictions Min            5.0240583
Log Pis Mean                 -0.71925807
Log Pis Std                  1.7636211
Log Pis Max                  5.877299
Log Pis Min                  -4.83674
Policy mu Mean               0.0334845
Policy mu Std                0.7895506
Policy mu Max                2.1468763
Policy mu Min                -2.6278684
Policy log std Mean          -0.40560937
Policy log std Std           0.15586229
Policy log std Max           -0.06585339
Policy log std Min           -1.0892943
Z mean eval                  1.0846093
Z variance eval              0.01680641
total_rewards                [3175.39193226 3130.75378365 3098.72251162 1248.49415947 3167.89692618
  262.50987072  248.41545059 1836.79894192 2539.48937822 3193.33590346]
total_rewards_mean           2190.180885809388
total_rewards_std            1151.6532625989275
total_rewards_max            3193.3359034613122
total_rewards_min            248.4154505927605
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               33.49769293284044
(Previous) Eval Time (s)     24.967637876048684
Sample Time (s)              22.636818469967693
Epoch Time (s)               81.10214927885681
Total Train Time (s)         29092.888640917838
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:37.702945 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #438 | Epoch Duration: 77.07540917396545
2020-01-11 08:07:37.703131 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0853676
Z variance train             0.016797509
KL Divergence                13.437697
KL Loss                      1.3437698
QF Loss                      89.910545
VF Loss                      32.01306
Policy Loss                  -1419.6718
Q Predictions Mean           1419.7373
Q Predictions Std            322.63705
Q Predictions Max            1656.7845
Q Predictions Min            4.275228
V Predictions Mean           1418.3398
V Predictions Std            320.79208
V Predictions Max            1652.8429
V Predictions Min            3.889669
Log Pis Mean                 -0.59454393
Log Pis Std                  1.7807089
Log Pis Max                  6.082367
Log Pis Min                  -4.729945
Policy mu Mean               -0.0005947811
Policy mu Std                0.8195278
Policy mu Max                2.4060168
Policy mu Min                -2.743879
Policy log std Mean          -0.39223608
Policy log std Std           0.14744811
Policy log std Max           -0.1035738
Policy log std Min           -1.080835
Z mean eval                  1.0295271
Z variance eval              0.01618689
total_rewards                [3080.97760734 3215.891818   3056.32290082 2425.32097439 2874.91294752
 3116.05614849 3110.82075063 3070.10324076 2787.41288582 3147.31450751]
total_rewards_mean           2988.513378128848
total_rewards_std            223.26706552171555
total_rewards_max            3215.891818004521
total_rewards_min            2425.3209743863713
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               35.37691903114319
(Previous) Eval Time (s)     20.940583295188844
Sample Time (s)              22.47290934761986
Epoch Time (s)               78.7904116739519
Total Train Time (s)         29179.720994281117
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:04.538682 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #439 | Epoch Duration: 86.83539080619812
2020-01-11 08:09:04.538827 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0338898
Z variance train             0.015798816
KL Divergence                13.096419
KL Loss                      1.309642
QF Loss                      182.29245
VF Loss                      91.14768
Policy Loss                  -1413.3903
Q Predictions Mean           1406.814
Q Predictions Std            314.87827
Q Predictions Max            1635.29
Q Predictions Min            -6.9975386
V Predictions Mean           1413.9922
V Predictions Std            314.07678
V Predictions Max            1635.2188
V Predictions Min            2.5800347
Log Pis Mean                 -0.6879133
Log Pis Std                  1.774505
Log Pis Max                  6.918976
Log Pis Min                  -4.0483437
Policy mu Mean               0.104588725
Policy mu Std                0.7854226
Policy mu Max                2.43805
Policy mu Min                -2.9380107
Policy log std Mean          -0.36902764
Policy log std Std           0.14025307
Policy log std Max           -0.09280641
Policy log std Min           -0.9988758
Z mean eval                  1.028729
Z variance eval              0.028604697
total_rewards                [3106.7505949  3099.57486101 3150.5755576  3154.81238899 3102.28256301
 3185.71514173 3133.187237   3160.98879863 3135.13244067 3166.73779845]
total_rewards_mean           3139.5757381988515
total_rewards_std            27.94134884325801
total_rewards_max            3185.715141734
total_rewards_min            3099.5748610098785
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               35.92293333867565
(Previous) Eval Time (s)     28.985153893008828
Sample Time (s)              24.531074893195182
Epoch Time (s)               89.43916212487966
Total Train Time (s)         29271.042140200734
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:35.864852 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #440 | Epoch Duration: 91.32589101791382
2020-01-11 08:10:35.865122 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0284164
Z variance train             0.02862975
KL Divergence                12.208845
KL Loss                      1.2208846
QF Loss                      160.10828
VF Loss                      44.334126
Policy Loss                  -1422.7755
Q Predictions Mean           1421.325
Q Predictions Std            348.62842
Q Predictions Max            1681.4828
Q Predictions Min            4.8499026
V Predictions Mean           1423.3094
V Predictions Std            346.18372
V Predictions Max            1682.6165
V Predictions Min            6.0160174
Log Pis Mean                 -0.4867906
Log Pis Std                  1.952325
Log Pis Max                  7.197135
Log Pis Min                  -4.2227917
Policy mu Mean               -0.010633388
Policy mu Std                0.84927833
Policy mu Max                2.5814936
Policy mu Min                -2.7729492
Policy log std Mean          -0.3940721
Policy log std Std           0.17559645
Policy log std Max           -0.07097116
Policy log std Min           -1.4639069
Z mean eval                  1.0511299
Z variance eval              0.01443845
total_rewards                [3240.8936193  1272.37366662 2907.19965263 2131.86420412 3228.91002681
 1850.49334787 3243.8353989  3244.75783257 3300.65519712  540.92985332]
total_rewards_mean           2496.191279925358
total_rewards_std            943.25547227764
total_rewards_max            3300.6551971191075
total_rewards_min            540.9298533166169
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               35.174538732971996
(Previous) Eval Time (s)     30.871472583152354
Sample Time (s)              25.543601005338132
Epoch Time (s)               91.58961232146248
Total Train Time (s)         29355.240121221635
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:00.068315 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #441 | Epoch Duration: 84.20303773880005
2020-01-11 08:12:00.068553 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520127
Z variance train             0.014436321
KL Divergence                13.27939
KL Loss                      1.327939
QF Loss                      154.03244
VF Loss                      31.743061
Policy Loss                  -1459.343
Q Predictions Mean           1457.593
Q Predictions Std            328.60965
Q Predictions Max            1670.1069
Q Predictions Min            -9.381327
V Predictions Mean           1457.263
V Predictions Std            328.318
V Predictions Max            1670.2472
V Predictions Min            2.3697424
Log Pis Mean                 -0.5071006
Log Pis Std                  1.795124
Log Pis Max                  6.3781023
Log Pis Min                  -4.489067
Policy mu Mean               -0.024798073
Policy mu Std                0.78812426
Policy mu Max                2.0638638
Policy mu Min                -2.8219004
Policy log std Mean          -0.3905162
Policy log std Std           0.1535521
Policy log std Max           -0.08044667
Policy log std Min           -1.1773268
Z mean eval                  1.0719849
Z variance eval              0.011324603
total_rewards                [1665.58470581 2757.80293117 1264.45237946 2006.24612061 3215.7367633
 3240.54541282 1267.46794031 1281.6962602  3197.19888363 1933.47424173]
total_rewards_mean           2183.020563903766
total_rewards_std            799.9653769343851
total_rewards_max            3240.5454128170786
total_rewards_min            1264.452379460933
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               35.44337919540703
(Previous) Eval Time (s)     23.484454358927906
Sample Time (s)              23.701739489566535
Epoch Time (s)               82.62957304390147
Total Train Time (s)         29435.140429697465
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:19.972938 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #442 | Epoch Duration: 79.90423560142517
2020-01-11 08:13:19.973120 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0719669
Z variance train             0.011314721
KL Divergence                13.889677
KL Loss                      1.3889678
QF Loss                      207.00577
VF Loss                      90.85549
Policy Loss                  -1433.4939
Q Predictions Mean           1434.3467
Q Predictions Std            316.8125
Q Predictions Max            1668.2155
Q Predictions Min            23.46359
V Predictions Mean           1438.0625
V Predictions Std            317.53616
V Predictions Max            1676.5901
V Predictions Min            25.124678
Log Pis Mean                 -0.4254901
Log Pis Std                  1.8808513
Log Pis Max                  5.8980303
Log Pis Min                  -5.801648
Policy mu Mean               -0.07581643
Policy mu Std                0.85525215
Policy mu Max                2.0602643
Policy mu Min                -2.7211916
Policy log std Mean          -0.4045746
Policy log std Std           0.14735271
Policy log std Max           -0.006244123
Policy log std Min           -1.2596146
Z mean eval                  1.0247093
Z variance eval              0.01101264
total_rewards                [3190.9437153  3122.10054009 3149.2445657  3175.22281195 1320.3520481
 3118.49001108 3177.4887882  3187.77371262 3100.25264391 3174.09165191]
total_rewards_mean           2971.5960488866585
total_rewards_std            551.2398781075088
total_rewards_max            3190.9437153022773
total_rewards_min            1320.3520480962482
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               35.589056792669
(Previous) Eval Time (s)     20.758768701925874
Sample Time (s)              23.457292444072664
Epoch Time (s)               79.80511793866754
Total Train Time (s)         29523.055326925125
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:14:47.892351 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #443 | Epoch Duration: 87.91910004615784
2020-01-11 08:14:47.892543 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0250546
Z variance train             0.011043287
KL Divergence                13.683428
KL Loss                      1.3683428
QF Loss                      84.34367
VF Loss                      72.681175
Policy Loss                  -1370.354
Q Predictions Mean           1370.4812
Q Predictions Std            333.17508
Q Predictions Max            1594.8315
Q Predictions Min            7.662837
V Predictions Mean           1371.8079
V Predictions Std            333.25876
V Predictions Max            1589.4873
V Predictions Min            5.1261754
Log Pis Mean                 -0.42050475
Log Pis Std                  1.9358997
Log Pis Max                  7.938266
Log Pis Min                  -4.8827777
Policy mu Mean               -0.047617164
Policy mu Std                0.8600398
Policy mu Max                3.3922303
Policy mu Min                -2.7068486
Policy log std Mean          -0.4149541
Policy log std Std           0.15848881
Policy log std Max           -0.05239615
Policy log std Min           -1.0691123
Z mean eval                  1.0425928
Z variance eval              0.009633384
total_rewards                [1018.41842877 1175.60468536 2395.69175311 3136.1228252  3136.46007607
 3156.60905844 1296.95967455 1322.24794312 3159.75670196  997.55864132]
total_rewards_mean           2079.542978789911
total_rewards_std            946.5743527153206
total_rewards_max            3159.756701957325
total_rewards_min            997.55864131816
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               35.132893305271864
(Previous) Eval Time (s)     28.87238884717226
Sample Time (s)              24.016335084103048
Epoch Time (s)               88.02161723654717
Total Train Time (s)         29602.444126349874
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:16:07.285816 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #444 | Epoch Duration: 79.3931348323822
2020-01-11 08:16:07.286000 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0423291
Z variance train             0.009626275
KL Divergence                14.508681
KL Loss                      1.4508681
QF Loss                      140.3212
VF Loss                      29.473082
Policy Loss                  -1421.4508
Q Predictions Mean           1420.9572
Q Predictions Std            317.42526
Q Predictions Max            1632.4133
Q Predictions Min            4.347717
V Predictions Mean           1419.0406
V Predictions Std            316.51447
V Predictions Max            1627.816
V Predictions Min            2.2123196
Log Pis Mean                 -0.72655916
Log Pis Std                  1.6111106
Log Pis Max                  5.3988276
Log Pis Min                  -5.3621216
Policy mu Mean               -0.03737588
Policy mu Std                0.7781189
Policy mu Max                2.031158
Policy mu Min                -2.821335
Policy log std Mean          -0.3814505
Policy log std Std           0.15556729
Policy log std Max           -0.03647977
Policy log std Min           -1.1426818
Z mean eval                  1.0691814
Z variance eval              0.016491672
total_rewards                [1354.21906135 2845.68686907 3239.63678654 3088.74252129 3235.93779099
 3129.12411455 3171.35347487 1186.12209656 3148.09736863 3154.6889502 ]
total_rewards_mean           2755.3609034039246
total_rewards_std            750.7956999838233
total_rewards_max            3239.6367865367943
total_rewards_min            1186.1220965576365
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               36.18305180687457
(Previous) Eval Time (s)     20.24355548620224
Sample Time (s)              23.751956227235496
Epoch Time (s)               80.17856352031231
Total Train Time (s)         29689.74490476679
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:34.592235 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #445 | Epoch Duration: 87.30607461929321
2020-01-11 08:17:34.592483 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0669773
Z variance train             0.016470384
KL Divergence                14.414482
KL Loss                      1.4414482
QF Loss                      139.8233
VF Loss                      180.46483
Policy Loss                  -1460.0837
Q Predictions Mean           1464.5565
Q Predictions Std            260.99597
Q Predictions Max            1682.7719
Q Predictions Min            7.8866754
V Predictions Mean           1467.1716
V Predictions Std            261.52484
V Predictions Max            1683.1776
V Predictions Min            5.7332234
Log Pis Mean                 -0.46689725
Log Pis Std                  1.8775761
Log Pis Max                  4.9183664
Log Pis Min                  -5.204694
Policy mu Mean               -0.009651761
Policy mu Std                0.87756044
Policy mu Max                2.0924118
Policy mu Min                -2.6862712
Policy log std Mean          -0.41644016
Policy log std Std           0.16038585
Policy log std Max           -0.093372576
Policy log std Min           -1.0547934
Z mean eval                  1.0113695
Z variance eval              0.027572852
total_rewards                [2907.56459527 3109.87253569 3175.11213586 3058.30862568 3093.17759415
 3099.34143328 1570.00330819 1540.23422476 3117.33989233 3149.02907074]
total_rewards_mean           2781.9983415946535
total_rewards_std            617.2332589269313
total_rewards_max            3175.1121358559267
total_rewards_min            1540.2342247625352
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               35.39515143400058
(Previous) Eval Time (s)     27.370678312610835
Sample Time (s)              25.366202150005847
Epoch Time (s)               88.13203189661726
Total Train Time (s)         29777.866587566212
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:02.721157 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #446 | Epoch Duration: 88.12837839126587
2020-01-11 08:19:02.721652 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0102861
Z variance train             0.027507782
KL Divergence                13.531494
KL Loss                      1.3531494
QF Loss                      136.46002
VF Loss                      39.522556
Policy Loss                  -1446.3838
Q Predictions Mean           1444.4233
Q Predictions Std            274.88293
Q Predictions Max            1653.4362
Q Predictions Min            5.4329
V Predictions Mean           1449.1603
V Predictions Std            274.88528
V Predictions Max            1662.7213
V Predictions Min            13.762198
Log Pis Mean                 -0.6817046
Log Pis Std                  1.6132715
Log Pis Max                  6.105335
Log Pis Min                  -4.670588
Policy mu Mean               0.025162235
Policy mu Std                0.7706975
Policy mu Max                2.140467
Policy mu Min                -2.6862154
Policy log std Mean          -0.37898913
Policy log std Std           0.14666013
Policy log std Max           -0.06997213
Policy log std Min           -0.9897584
Z mean eval                  1.0133358
Z variance eval              0.0238263
total_rewards                [3120.44296888 1086.61059425 3116.86886203 3089.13757246 3107.84427322
 3145.77110046 3080.78238209 1205.76361082 3065.15403507 2232.69734556]
total_rewards_mean           2625.1072744849857
total_rewards_std            783.7991984163496
total_rewards_max            3145.7711004590124
total_rewards_min            1086.6105942531944
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               35.18963471474126
(Previous) Eval Time (s)     27.366625481750816
Sample Time (s)              23.459576067514718
Epoch Time (s)               86.0158362640068
Total Train Time (s)         29860.55969138397
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:25.417684 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #447 | Epoch Duration: 82.6957471370697
2020-01-11 08:20:25.417992 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0125444
Z variance train             0.02383651
KL Divergence                12.666479
KL Loss                      1.2666479
QF Loss                      192.8548
VF Loss                      261.8964
Policy Loss                  -1353.5763
Q Predictions Mean           1351.6721
Q Predictions Std            336.5757
Q Predictions Max            1570.9432
Q Predictions Min            -7.806036
V Predictions Mean           1358.7981
V Predictions Std            334.9736
V Predictions Max            1578.0327
V Predictions Min            4.379007
Log Pis Mean                 -0.6170158
Log Pis Std                  1.8715869
Log Pis Max                  5.942801
Log Pis Min                  -4.811013
Policy mu Mean               0.006992905
Policy mu Std                0.81446254
Policy mu Max                1.995537
Policy mu Min                -2.917346
Policy log std Mean          -0.40929258
Policy log std Std           0.15891601
Policy log std Max           -0.08289924
Policy log std Min           -1.0760587
Z mean eval                  1.0043442
Z variance eval              0.02245279
total_rewards                [1279.25141548 2876.0464824  3197.31124313 2993.93071778 3169.00445423
 3219.0526738  3188.96513916 3214.70831175 3243.13865116 3176.37719673]
total_rewards_mean           2955.7786285621273
total_rewards_std            569.5904505176801
total_rewards_max            3243.1386511574215
total_rewards_min            1279.251415478575
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               35.2847806699574
(Previous) Eval Time (s)     24.046215232927352
Sample Time (s)              24.28200046811253
Epoch Time (s)               83.61299637099728
Total Train Time (s)         29947.68215335207
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:21:52.545023 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #448 | Epoch Duration: 87.12676644325256
2020-01-11 08:21:52.545306 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0045059
Z variance train             0.022465074
KL Divergence                11.860392
KL Loss                      1.1860392
QF Loss                      94.40271
VF Loss                      49.045673
Policy Loss                  -1288.8711
Q Predictions Mean           1287.3677
Q Predictions Std            272.34708
Q Predictions Max            1517.0828
Q Predictions Min            8.272027
V Predictions Mean           1290.6578
V Predictions Std            273.2477
V Predictions Max            1512.9884
V Predictions Min            13.493846
Log Pis Mean                 -0.6274694
Log Pis Std                  1.6844693
Log Pis Max                  5.18699
Log Pis Min                  -4.0309086
Policy mu Mean               -0.009642194
Policy mu Std                0.8285162
Policy mu Max                2.2581336
Policy mu Min                -2.6199844
Policy log std Mean          -0.40228245
Policy log std Std           0.15078232
Policy log std Max           -0.03063023
Policy log std Min           -1.0430483
Z mean eval                  1.008631
Z variance eval              0.01966574
total_rewards                [3278.98465766 2953.24477982 3279.93049354 1996.96133486 1346.88009779
 3258.04179654 1046.80421136 1285.86884732 1084.85661538 3219.24127953]
total_rewards_mean           2275.081411379141
total_rewards_std            958.0108471760296
total_rewards_max            3279.9304935402242
total_rewards_min            1046.8042113555903
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               33.23810817301273
(Previous) Eval Time (s)     27.559650528244674
Sample Time (s)              24.019827058073133
Epoch Time (s)               84.81758575933054
Total Train Time (s)         30024.20099601196
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:09.067759 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #449 | Epoch Duration: 76.52230286598206
2020-01-11 08:23:09.067925 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0093887
Z variance train             0.019631995
KL Divergence                12.214765
KL Loss                      1.2214764
QF Loss                      100.239
VF Loss                      30.366602
Policy Loss                  -1476.5737
Q Predictions Mean           1476.3564
Q Predictions Std            254.83118
Q Predictions Max            1678.6821
Q Predictions Min            3.4678397
V Predictions Mean           1473.6055
V Predictions Std            253.44617
V Predictions Max            1669.287
V Predictions Min            5.569145
Log Pis Mean                 -0.7405
Log Pis Std                  1.6087284
Log Pis Max                  4.7792077
Log Pis Min                  -4.4398527
Policy mu Mean               0.04509483
Policy mu Std                0.7773392
Policy mu Max                2.3349485
Policy mu Min                -2.6436043
Policy log std Mean          -0.39423373
Policy log std Std           0.14510374
Policy log std Max           -0.040539414
Policy log std Min           -1.0157444
Z mean eval                  0.9927921
Z variance eval              0.020106196
total_rewards                [ 765.1097114  2147.4101406  3064.81162131 3202.41092232 2743.31298013
 3183.55868948 2209.94736636 3159.65282617 3159.14300696 3161.64436045]
total_rewards_mean           2679.7001625175567
total_rewards_std            744.4195418361711
total_rewards_max            3202.4109223164132
total_rewards_min            765.1097113986431
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               33.55613607773557
(Previous) Eval Time (s)     19.264017588924617
Sample Time (s)              22.788893068674952
Epoch Time (s)               75.60904673533514
Total Train Time (s)         30104.99643840408
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:29.867092 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #450 | Epoch Duration: 80.79905223846436
2020-01-11 08:24:29.867291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99353695
Z variance train             0.020158669
KL Divergence                12.026512
KL Loss                      1.2026513
QF Loss                      230.55319
VF Loss                      92.84144
Policy Loss                  -1368.8085
Q Predictions Mean           1367.8375
Q Predictions Std            260.34198
Q Predictions Max            1577.1016
Q Predictions Min            20.740839
V Predictions Mean           1363.2849
V Predictions Std            258.22287
V Predictions Max            1565.8888
V Predictions Min            16.530485
Log Pis Mean                 -0.5015001
Log Pis Std                  1.8184811
Log Pis Max                  6.7013226
Log Pis Min                  -5.4280167
Policy mu Mean               -0.06974461
Policy mu Std                0.8212233
Policy mu Max                1.924339
Policy mu Min                -2.742686
Policy log std Mean          -0.39932704
Policy log std Std           0.1574021
Policy log std Max           -0.05956766
Policy log std Min           -1.1387355
Z mean eval                  1.0030844
Z variance eval              0.016215805
total_rewards                [1235.59944944 3336.1544902  1798.60326463 3258.63209368 3250.86253393
 3312.42568925 3214.90798505 3322.23117656 3251.44980392 3234.8256173 ]
total_rewards_mean           2921.569210396031
total_rewards_std            714.4067610252389
total_rewards_max            3336.154490203767
total_rewards_min            1235.5994494445074
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               33.53725341614336
(Previous) Eval Time (s)     24.453712347429246
Sample Time (s)              23.69090596586466
Epoch Time (s)               81.68187172943726
Total Train Time (s)         30188.99187021097
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:53.868414 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #451 | Epoch Duration: 84.00097513198853
2020-01-11 08:25:53.868630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0044861
Z variance train             0.016264405
KL Divergence                12.9948
KL Loss                      1.29948
QF Loss                      85.42585
VF Loss                      57.095985
Policy Loss                  -1375.9962
Q Predictions Mean           1376.9834
Q Predictions Std            228.28688
Q Predictions Max            1583.8279
Q Predictions Min            12.062069
V Predictions Mean           1370.7686
V Predictions Std            225.44598
V Predictions Max            1574.8612
V Predictions Min            18.055199
Log Pis Mean                 -0.54028404
Log Pis Std                  1.8347746
Log Pis Max                  5.610224
Log Pis Min                  -4.282825
Policy mu Mean               0.10104779
Policy mu Std                0.8252862
Policy mu Max                2.5341516
Policy mu Min                -2.7656357
Policy log std Mean          -0.40847287
Policy log std Std           0.15249562
Policy log std Max           -0.112326674
Policy log std Min           -1.1262965
Z mean eval                  1.0028079
Z variance eval              0.015998954
total_rewards                [2467.05788698 2761.60057725 3121.84778055 3149.37134562 1374.23068252
 2316.68951072 2195.50608709 1966.53919488 2860.91859269 3136.968844  ]
total_rewards_mean           2535.0730502296074
total_rewards_std            554.9634642953007
total_rewards_max            3149.3713456218547
total_rewards_min            1374.2306825197209
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               32.974846662953496
(Previous) Eval Time (s)     26.77246316941455
Sample Time (s)              23.744419708848
Epoch Time (s)               83.49172954121605
Total Train Time (s)         30269.189411411528
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:27:14.069499 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #452 | Epoch Duration: 80.20071840286255
2020-01-11 08:27:14.069671 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0013502
Z variance train             0.01599444
KL Divergence                12.934865
KL Loss                      1.2934865
QF Loss                      181.42374
VF Loss                      53.48559
Policy Loss                  -1394.2157
Q Predictions Mean           1393.6276
Q Predictions Std            243.46834
Q Predictions Max            1582.4401
Q Predictions Min            11.117734
V Predictions Mean           1397.1481
V Predictions Std            241.34543
V Predictions Max            1588.6742
V Predictions Min            23.918194
Log Pis Mean                 -0.40027755
Log Pis Std                  1.8460919
Log Pis Max                  7.20561
Log Pis Min                  -5.2640867
Policy mu Mean               0.09849417
Policy mu Std                0.8196433
Policy mu Max                2.5816836
Policy mu Min                -2.6555989
Policy log std Mean          -0.4015529
Policy log std Std           0.15859275
Policy log std Max           -0.093948275
Policy log std Min           -1.1053469
Z mean eval                  0.9933971
Z variance eval              0.015107912
total_rewards                [3159.68318002  166.13110551 1307.00496348  784.06559544 1171.42696248
 1598.45398705 2906.60016009 1289.41072249 3212.34551984 1854.50693468]
total_rewards_mean           1744.9629131058543
total_rewards_std            983.9625491991703
total_rewards_max            3212.345519839207
total_rewards_min            166.13110550737352
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               33.27932595089078
(Previous) Eval Time (s)     23.48115499317646
Sample Time (s)              22.58130910806358
Epoch Time (s)               79.34179005213082
Total Train Time (s)         30342.37592401309
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:27.260805 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #453 | Epoch Duration: 73.19100141525269
2020-01-11 08:28:27.260967 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9936659
Z variance train             0.0151369795
KL Divergence                12.78792
KL Loss                      1.278792
QF Loss                      83.10467
VF Loss                      32.17729
Policy Loss                  -1422.5299
Q Predictions Mean           1421.7064
Q Predictions Std            197.38228
Q Predictions Max            1578.0518
Q Predictions Min            10.307169
V Predictions Mean           1423.3953
V Predictions Std            197.48877
V Predictions Max            1580.0205
V Predictions Min            12.301
Log Pis Mean                 -0.4303573
Log Pis Std                  1.7674917
Log Pis Max                  6.7945886
Log Pis Min                  -4.7289653
Policy mu Mean               0.02272585
Policy mu Std                0.83760726
Policy mu Max                1.8727459
Policy mu Min                -2.7707758
Policy log std Mean          -0.41037297
Policy log std Std           0.15754381
Policy log std Max           -0.075871795
Policy log std Min           -1.150604
Z mean eval                  0.9817627
Z variance eval              0.01779924
total_rewards                [3049.38525395 2934.57550851 3128.16000565 1048.74538823 1630.87195332
 2697.49260828 3091.57690968 3084.25851959 3074.55389459 3044.33098484]
total_rewards_mean           2678.3951026651184
total_rewards_std            691.7567052553129
total_rewards_max            3128.1600056532684
total_rewards_min            1048.7453882334817
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               33.00450460892171
(Previous) Eval Time (s)     17.330085618887097
Sample Time (s)              23.379230634775013
Epoch Time (s)               73.71382086258382
Total Train Time (s)         30424.511682900134
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:49.400776 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #454 | Epoch Duration: 82.13968324661255
2020-01-11 08:29:49.400953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9826759
Z variance train             0.017825762
KL Divergence                12.640722
KL Loss                      1.2640723
QF Loss                      110.29744
VF Loss                      180.31947
Policy Loss                  -1462.657
Q Predictions Mean           1460.2922
Q Predictions Std            199.20888
Q Predictions Max            1638.8717
Q Predictions Min            40.864933
V Predictions Mean           1458.792
V Predictions Std            200.81776
V Predictions Max            1630.6698
V Predictions Min            21.933693
Log Pis Mean                 -0.44054553
Log Pis Std                  1.9873326
Log Pis Max                  6.802993
Log Pis Min                  -8.132811
Policy mu Mean               -0.04397871
Policy mu Std                0.8870023
Policy mu Max                2.4132223
Policy mu Min                -2.8469632
Policy log std Mean          -0.39352033
Policy log std Std           0.15213828
Policy log std Max           -0.020672515
Policy log std Min           -1.0450468
Z mean eval                  0.97652876
Z variance eval              0.021056604
total_rewards                [1252.79934137 3119.52023597 3177.63624351 1120.12911853 3249.70526428
 1734.44206677 3134.45394384 3165.33704248 2496.73333273 3148.94524227]
total_rewards_mean           2559.970183175767
total_rewards_std            817.3779922989115
total_rewards_max            3249.705264281706
total_rewards_min            1120.1291185292068
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               33.21718855202198
(Previous) Eval Time (s)     25.755594263784587
Sample Time (s)              24.10677511198446
Epoch Time (s)               83.07955792779103
Total Train Time (s)         30505.240420949645
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:10.134598 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #455 | Epoch Duration: 80.73347187042236
2020-01-11 08:31:10.134832 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9787852
Z variance train             0.02108668
KL Divergence                11.913782
KL Loss                      1.1913782
QF Loss                      141.90662
VF Loss                      68.88385
Policy Loss                  -1429.9132
Q Predictions Mean           1428.0964
Q Predictions Std            207.71454
Q Predictions Max            1619.769
Q Predictions Min            48.576664
V Predictions Mean           1424.936
V Predictions Std            206.83955
V Predictions Max            1610.7054
V Predictions Min            20.265184
Log Pis Mean                 -0.47000948
Log Pis Std                  2.0400357
Log Pis Max                  10.43145
Log Pis Min                  -3.7482932
Policy mu Mean               -0.04707669
Policy mu Std                0.83531904
Policy mu Max                3.0407577
Policy mu Min                -2.8055582
Policy log std Mean          -0.40005806
Policy log std Std           0.16150175
Policy log std Max           -0.11494717
Policy log std Min           -1.0843515
Z mean eval                  0.99279135
Z variance eval              0.013890959
total_rewards                [3286.73892878 3214.29662534 1392.69306394 3259.43407835 3335.83071981
 3311.60251578 3266.7791069  3252.002545   3216.52144857 1483.3383884 ]
total_rewards_mean           2901.923742087148
total_rewards_std            733.1025247217624
total_rewards_max            3335.8307198108964
total_rewards_min            1392.6930639408313
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               33.85720175597817
(Previous) Eval Time (s)     23.40909078111872
Sample Time (s)              22.52047119382769
Epoch Time (s)               79.78676373092458
Total Train Time (s)         30589.230480974074
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:34.130576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #456 | Epoch Duration: 83.99548602104187
2020-01-11 08:32:34.130927 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98974526
Z variance train             0.013905883
KL Divergence                13.099727
KL Loss                      1.3099726
QF Loss                      109.535164
VF Loss                      31.8909
Policy Loss                  -1392.0228
Q Predictions Mean           1389.8866
Q Predictions Std            206.26471
Q Predictions Max            1566.1903
Q Predictions Min            -7.208816
V Predictions Mean           1391.0978
V Predictions Std            205.06136
V Predictions Max            1563.3545
V Predictions Min            3.5836596
Log Pis Mean                 -0.5055023
Log Pis Std                  1.8056264
Log Pis Max                  6.938448
Log Pis Min                  -4.7854767
Policy mu Mean               0.0060676853
Policy mu Std                0.80845404
Policy mu Max                2.2636533
Policy mu Min                -2.9127414
Policy log std Mean          -0.38321352
Policy log std Std           0.15172733
Policy log std Max           -0.0652356
Policy log std Min           -1.0391183
Z mean eval                  1.0037801
Z variance eval              0.0141722085
total_rewards                [3286.73896672 1363.55711341 3264.01700702 3216.55140751 1218.44905989
 2108.23422567 3194.44478378 3225.54655159 3216.64492155 1324.50767515]
total_rewards_mean           2541.869171228228
total_rewards_std            876.9255959041512
total_rewards_max            3286.738966717776
total_rewards_min            1218.4490598908806
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               33.24799809418619
(Previous) Eval Time (s)     27.617454521358013
Sample Time (s)              24.107087895274162
Epoch Time (s)               84.97254051081836
Total Train Time (s)         30670.368199815042
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:55.272498 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #457 | Epoch Duration: 81.14136624336243
2020-01-11 08:33:55.272716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9977419
Z variance train             0.014168091
KL Divergence                13.116124
KL Loss                      1.3116125
QF Loss                      61.849384
VF Loss                      51.39077
Policy Loss                  -1379.9226
Q Predictions Mean           1382.3496
Q Predictions Std            260.2344
Q Predictions Max            1581.3207
Q Predictions Min            5.331466
V Predictions Mean           1384.5693
V Predictions Std            258.57114
V Predictions Max            1576.5382
V Predictions Min            2.6888702
Log Pis Mean                 -0.86655223
Log Pis Std                  1.6152978
Log Pis Max                  6.048401
Log Pis Min                  -5.6559596
Policy mu Mean               0.058595106
Policy mu Std                0.75406957
Policy mu Max                2.3056
Policy mu Min                -2.7693262
Policy log std Mean          -0.36851367
Policy log std Std           0.14126782
Policy log std Max           -0.048436552
Policy log std Min           -0.9059896
Z mean eval                  0.9829439
Z variance eval              0.012538863
total_rewards                [ 156.44376961 3133.32715877 2597.37647088  167.64571541 3144.97136975
  262.48110427 3153.58770682  170.69797257 3127.29398684 1114.16467059]
total_rewards_mean           1702.7989925510597
total_rewards_std            1362.9660423643131
total_rewards_max            3153.5877068160617
total_rewards_min            156.44376961261167
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               32.848567731212825
(Previous) Eval Time (s)     23.78588433098048
Sample Time (s)              24.53421053290367
Epoch Time (s)               81.16866259509698
Total Train Time (s)         30744.159594559576
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:09.068572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #458 | Epoch Duration: 73.79569149017334
2020-01-11 08:35:09.068758 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98275965
Z variance train             0.012521143
KL Divergence                13.389
KL Loss                      1.3389
QF Loss                      70.79628
VF Loss                      43.07847
Policy Loss                  -1373.8271
Q Predictions Mean           1373.2515
Q Predictions Std            220.03485
Q Predictions Max            1562.3481
Q Predictions Min            -2.786074
V Predictions Mean           1377.0172
V Predictions Std            219.15443
V Predictions Max            1567.2385
V Predictions Min            -0.44044268
Log Pis Mean                 -0.5164236
Log Pis Std                  1.8767631
Log Pis Max                  7.8771505
Log Pis Min                  -4.6710863
Policy mu Mean               0.036189977
Policy mu Std                0.8224758
Policy mu Max                2.7220774
Policy mu Min                -2.8897934
Policy log std Mean          -0.36888584
Policy log std Std           0.15786393
Policy log std Max           -0.0314402
Policy log std Min           -1.1389841
Z mean eval                  0.9799452
Z variance eval              0.014974763
total_rewards                [2634.3986339  3116.3076013  3237.27028232 3011.477451   3248.29587775
 3206.04296222 3241.93389836 3223.14996434 3169.08171211 3190.58794534]
total_rewards_mean           3127.854632866177
total_rewards_std            178.18460021788795
total_rewards_max            3248.2958777545205
total_rewards_min            2634.3986339012845
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               33.21506361523643
(Previous) Eval Time (s)     16.41258138185367
Sample Time (s)              23.324838375207037
Epoch Time (s)               72.95248337229714
Total Train Time (s)         30829.978999510873
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:36:34.893669 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #459 | Epoch Duration: 85.82471060752869
2020-01-11 08:36:34.893970 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9827547
Z variance train             0.014914306
KL Divergence                12.8198185
KL Loss                      1.2819818
QF Loss                      188.55693
VF Loss                      78.32319
Policy Loss                  -1418.9714
Q Predictions Mean           1413.7356
Q Predictions Std            241.2017
Q Predictions Max            1597.0421
Q Predictions Min            0.8964466
V Predictions Mean           1412.7017
V Predictions Std            239.06833
V Predictions Max            1586.3169
V Predictions Min            2.4595265
Log Pis Mean                 -0.65529525
Log Pis Std                  1.6521587
Log Pis Max                  4.483102
Log Pis Min                  -3.9347486
Policy mu Mean               -0.056220394
Policy mu Std                0.7870055
Policy mu Max                1.881985
Policy mu Min                -2.8289254
Policy log std Mean          -0.37710175
Policy log std Std           0.14149483
Policy log std Max           -0.028019413
Policy log std Min           -0.8149761
Z mean eval                  0.95189655
Z variance eval              0.014487381
total_rewards                [3148.19596432  718.62298644 3131.11953364 1550.40734722 3215.64483144
 1273.50268969 3021.71247673 1259.66108974 3146.93319882 3196.98893263]
total_rewards_mean           2366.278905067106
total_rewards_std            971.908980604705
total_rewards_max            3215.6448314363
total_rewards_min            718.6229864430255
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               33.58690929878503
(Previous) Eval Time (s)     29.284480136819184
Sample Time (s)              23.108735247515142
Epoch Time (s)               85.98012468311936
Total Train Time (s)         30909.49844130315
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:54.417846 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #460 | Epoch Duration: 79.52370882034302
2020-01-11 08:37:54.418046 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479186
Z variance train             0.014410233
KL Divergence                13.299567
KL Loss                      1.3299568
QF Loss                      245.0428
VF Loss                      58.997612
Policy Loss                  -1422.347
Q Predictions Mean           1426.105
Q Predictions Std            198.07384
Q Predictions Max            1591.7894
Q Predictions Min            16.423779
V Predictions Mean           1423.7126
V Predictions Std            198.98033
V Predictions Max            1584.5221
V Predictions Min            18.866144
Log Pis Mean                 -0.79780614
Log Pis Std                  1.6688259
Log Pis Max                  5.5049744
Log Pis Min                  -4.6215196
Policy mu Mean               -0.015839493
Policy mu Std                0.782489
Policy mu Max                2.3259373
Policy mu Min                -2.6338205
Policy log std Mean          -0.37082553
Policy log std Std           0.15426198
Policy log std Max           -0.030965358
Policy log std Min           -1.0511837
Z mean eval                  0.9782944
Z variance eval              0.01853257
total_rewards                [ 680.747017    707.42575489  701.19152579  761.97908975  985.88085311
 1540.85916025  795.50792157  727.55691329 1325.11299255  714.3281288 ]
total_rewards_mean           894.0589356998865
total_rewards_std            285.8854011794007
total_rewards_max            1540.8591602532417
total_rewards_min            680.7470170032321
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               32.64542364189401
(Previous) Eval Time (s)     22.82775945821777
Sample Time (s)              23.407455030828714
Epoch Time (s)               78.8806381309405
Total Train Time (s)         30974.67272722721
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:59.596764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #461 | Epoch Duration: 65.17856693267822
2020-01-11 08:38:59.596941 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97943497
Z variance train             0.018512106
KL Divergence                12.668897
KL Loss                      1.2668897
QF Loss                      161.892
VF Loss                      160.96478
Policy Loss                  -1340.8604
Q Predictions Mean           1340.5493
Q Predictions Std            242.25404
Q Predictions Max            1560.8403
Q Predictions Min            11.006289
V Predictions Mean           1335.8834
V Predictions Std            241.44463
V Predictions Max            1547.4021
V Predictions Min            10.632616
Log Pis Mean                 -0.45810398
Log Pis Std                  1.981222
Log Pis Max                  8.98159
Log Pis Min                  -4.9335656
Policy mu Mean               -0.025518509
Policy mu Std                0.8636102
Policy mu Max                2.2047286
Policy mu Min                -3.0060005
Policy log std Mean          -0.39649728
Policy log std Std           0.16889392
Policy log std Max           -0.017373592
Policy log std Min           -1.1781921
Z mean eval                  0.95936745
Z variance eval              0.012336185
total_rewards                [3200.06392101 3145.86721798 1234.45777257 1109.00265728 3067.49342688
 3172.29984286 2006.44048394 3156.93710469 3184.30160529 3124.25479047]
total_rewards_mean           2640.111882297929
total_rewards_std            809.602201830871
total_rewards_max            3200.0639210127547
total_rewards_min            1109.0026572837899
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               32.808167894836515
(Previous) Eval Time (s)     9.125376409385353
Sample Time (s)              23.03857024712488
Epoch Time (s)               64.97211455134675
Total Train Time (s)         31055.07885845285
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:20.006932 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #462 | Epoch Duration: 80.40985989570618
2020-01-11 08:40:20.007114 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95994914
Z variance train             0.012388713
KL Divergence                13.37752
KL Loss                      1.337752
QF Loss                      90.494934
VF Loss                      88.40311
Policy Loss                  -1389.4106
Q Predictions Mean           1388.7808
Q Predictions Std            209.43167
Q Predictions Max            1567.908
Q Predictions Min            -3.6602871
V Predictions Mean           1392.9111
V Predictions Std            211.03662
V Predictions Max            1569.9202
V Predictions Min            7.4987144
Log Pis Mean                 -0.7639941
Log Pis Std                  1.8066878
Log Pis Max                  7.4455857
Log Pis Min                  -5.390932
Policy mu Mean               0.04472351
Policy mu Std                0.7593594
Policy mu Max                2.639053
Policy mu Min                -2.9370809
Policy log std Mean          -0.38496447
Policy log std Std           0.1491837
Policy log std Max           -0.10232164
Policy log std Min           -1.094767
Z mean eval                  0.96359694
Z variance eval              0.013508404
total_rewards                [3225.71476738 2421.55701508 1216.1310732  3181.76062342 3188.8070188
  976.05782518 3250.13335958 3151.96325288 2143.29896225 1589.90549722]
total_rewards_mean           2434.5329395002
total_rewards_std            856.9242364496223
total_rewards_max            3250.1333595847977
total_rewards_min            976.0578251847594
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               33.37402247497812
(Previous) Eval Time (s)     24.56277366168797
Sample Time (s)              23.245260717347264
Epoch Time (s)               81.18205685401335
Total Train Time (s)         31134.65892878361
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:39.589902 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #463 | Epoch Duration: 79.58262991905212
2020-01-11 08:41:39.590045 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96274245
Z variance train             0.013527334
KL Divergence                13.239925
KL Loss                      1.3239926
QF Loss                      138.36642
VF Loss                      238.25171
Policy Loss                  -1481.5684
Q Predictions Mean           1484.1179
Q Predictions Std            157.4795
Q Predictions Max            1659.6957
Q Predictions Min            327.65167
V Predictions Mean           1494.6052
V Predictions Std            157.03146
V Predictions Max            1658.9641
V Predictions Min            335.08533
Log Pis Mean                 -0.5799408
Log Pis Std                  1.6890764
Log Pis Max                  8.087502
Log Pis Min                  -4.268874
Policy mu Mean               0.016209763
Policy mu Std                0.78117067
Policy mu Max                2.027102
Policy mu Min                -2.828053
Policy log std Mean          -0.3631854
Policy log std Std           0.15104374
Policy log std Max           0.017473504
Policy log std Min           -0.89400214
Z mean eval                  0.92362976
Z variance eval              0.013766773
total_rewards                [1094.81063558 3266.43830389 3263.98957673 3278.29344061 3297.78954357
 3340.34587559 3242.97599145 1226.52612813 3238.40699057 3302.04293417]
total_rewards_mean           2855.1619420290585
total_rewards_std            848.2288400304524
total_rewards_max            3340.3458755888187
total_rewards_min            1094.8106355788104
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               33.43381212512031
(Previous) Eval Time (s)     22.963074143975973
Sample Time (s)              22.235402000602335
Epoch Time (s)               78.63228826969862
Total Train Time (s)         31215.761041274294
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:00.697121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #464 | Epoch Duration: 81.10692572593689
2020-01-11 08:43:00.697457 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9253645
Z variance train             0.0137337
KL Divergence                13.2087555
KL Loss                      1.3208755
QF Loss                      133.27922
VF Loss                      63.957504
Policy Loss                  -1358.006
Q Predictions Mean           1356.1611
Q Predictions Std            188.40674
Q Predictions Max            1516.2692
Q Predictions Min            6.5281253
V Predictions Mean           1352.3065
V Predictions Std            188.76215
V Predictions Max            1514.4406
V Predictions Min            8.469824
Log Pis Mean                 -0.5932025
Log Pis Std                  1.7381696
Log Pis Max                  5.1081223
Log Pis Min                  -4.0081167
Policy mu Mean               -0.09227126
Policy mu Std                0.779161
Policy mu Max                1.9719634
Policy mu Min                -2.7281682
Policy log std Mean          -0.38125446
Policy log std Std           0.15679337
Policy log std Max           -0.0051164627
Policy log std Min           -0.95244575
Z mean eval                  0.95923203
Z variance eval              0.012524714
total_rewards                [  27.37488867 3189.55740459 1416.2945393  3190.35060288 3262.76163982
 3233.88236986 1211.26314725 2955.92416556 3230.85884559 1216.36978419]
total_rewards_mean           2293.463738769936
total_rewards_std            1139.5066002140002
total_rewards_max            3262.7616398154414
total_rewards_min            27.37488866503026
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               32.84589056717232
(Previous) Eval Time (s)     25.437350531108677
Sample Time (s)              24.01494421530515
Epoch Time (s)               82.29818531358615
Total Train Time (s)         31293.37542416202
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:18.317129 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #465 | Epoch Duration: 77.61945152282715
2020-01-11 08:44:18.317442 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9598039
Z variance train             0.012511136
KL Divergence                13.257729
KL Loss                      1.3257729
QF Loss                      1318.9802
VF Loss                      91.37011
Policy Loss                  -1431.1599
Q Predictions Mean           1426.3148
Q Predictions Std            187.20836
Q Predictions Max            1610.6161
Q Predictions Min            21.766273
V Predictions Mean           1429.8899
V Predictions Std            184.88318
V Predictions Max            1614.249
V Predictions Min            18.52064
Log Pis Mean                 -0.68796164
Log Pis Std                  1.9389505
Log Pis Max                  10.163458
Log Pis Min                  -6.302731
Policy mu Mean               -0.038450632
Policy mu Std                0.77390355
Policy mu Max                2.1098678
Policy mu Min                -2.7051547
Policy log std Mean          -0.39956117
Policy log std Std           0.16331603
Policy log std Max           -0.013176426
Policy log std Min           -1.5063479
Z mean eval                  0.9388688
Z variance eval              0.013851047
total_rewards                [3285.83444615 3310.37999771 3250.83490635 3328.2456649  3273.32926201
 3265.38125555 3277.24995005 3307.42214774 3287.67601514 3325.71270995]
total_rewards_mean           3291.206635554388
total_rewards_std            24.587927003267165
total_rewards_max            3328.245664898017
total_rewards_min            3250.8349063483656
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               33.22490174230188
(Previous) Eval Time (s)     20.7583095501177
Sample Time (s)              23.88228819426149
Epoch Time (s)               77.86549948668107
Total Train Time (s)         31379.794564402197
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:44.746552 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #466 | Epoch Duration: 86.42889070510864
2020-01-11 08:45:44.746811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9398039
Z variance train             0.013881167
KL Divergence                12.960262
KL Loss                      1.2960262
QF Loss                      108.79689
VF Loss                      50.020813
Policy Loss                  -1416.1307
Q Predictions Mean           1414.1174
Q Predictions Std            186.19797
Q Predictions Max            1574.8182
Q Predictions Min            4.6286287
V Predictions Mean           1413.1484
V Predictions Std            184.63298
V Predictions Max            1570.4723
V Predictions Min            1.6979115
Log Pis Mean                 -0.5422641
Log Pis Std                  1.7608736
Log Pis Max                  8.282249
Log Pis Min                  -4.1029654
Policy mu Mean               0.0073470604
Policy mu Std                0.8055179
Policy mu Max                2.217687
Policy mu Min                -2.7226732
Policy log std Mean          -0.39051902
Policy log std Std           0.17936175
Policy log std Max           0.020599172
Policy log std Min           -1.1780658
Z mean eval                  0.93346155
Z variance eval              0.019225249
total_rewards                [3241.9728879  3311.34803484 3295.93298426 3302.02330367 3348.19810466
 3319.10582962 3240.52468503 3297.16293618 3475.47605437 3351.57459315]
total_rewards_mean           3318.33194136735
total_rewards_std            63.119880876761435
total_rewards_max            3475.476054366287
total_rewards_min            3240.5246850339963
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               33.66216396307573
(Previous) Eval Time (s)     29.321349726989865
Sample Time (s)              22.499026236589998
Epoch Time (s)               85.48253992665559
Total Train Time (s)         31466.0150442156
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:10.971036 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #467 | Epoch Duration: 86.22405338287354
2020-01-11 08:47:10.971331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93215764
Z variance train             0.0191336
KL Divergence                12.074933
KL Loss                      1.2074933
QF Loss                      85.89898
VF Loss                      62.688248
Policy Loss                  -1376.4138
Q Predictions Mean           1376.7222
Q Predictions Std            175.52069
Q Predictions Max            1544.6552
Q Predictions Min            0.7241041
V Predictions Mean           1377.7145
V Predictions Std            174.16557
V Predictions Max            1540.662
V Predictions Min            6.57118
Log Pis Mean                 -0.45480797
Log Pis Std                  1.884239
Log Pis Max                  5.9036584
Log Pis Min                  -6.3924046
Policy mu Mean               0.059777856
Policy mu Std                0.84925985
Policy mu Max                2.5528154
Policy mu Min                -2.6707659
Policy log std Mean          -0.4122099
Policy log std Std           0.16228628
Policy log std Max           0.024931878
Policy log std Min           -1.0739906
Z mean eval                  0.90626717
Z variance eval              0.01660626
total_rewards                [3225.68174675 3160.49384736 1937.74340916 3152.58712951 3286.7635704
 1378.59865466 3223.10045045 3245.24401677 3232.43570033 3225.78150106]
total_rewards_mean           2906.84300264533
total_rewards_std            637.7834984471273
total_rewards_max            3286.7635703975056
total_rewards_min            1378.5986546609815
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               32.93118119472638
(Previous) Eval Time (s)     30.062532026786357
Sample Time (s)              23.468584034126252
Epoch Time (s)               86.46229725563899
Total Train Time (s)         31548.661959506106
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:48:33.623339 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #468 | Epoch Duration: 82.65184760093689
2020-01-11 08:48:33.623572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9015333
Z variance train             0.016707713
KL Divergence                12.326628
KL Loss                      1.2326628
QF Loss                      104.99583
VF Loss                      69.086395
Policy Loss                  -1374.852
Q Predictions Mean           1376.007
Q Predictions Std            225.25821
Q Predictions Max            1547.2041
Q Predictions Min            -6.627902
V Predictions Mean           1377.4746
V Predictions Std            225.49013
V Predictions Max            1547.666
V Predictions Min            6.060463
Log Pis Mean                 -0.35062677
Log Pis Std                  1.9600903
Log Pis Max                  7.066057
Log Pis Min                  -4.949498
Policy mu Mean               -0.02033072
Policy mu Std                0.86989695
Policy mu Max                3.3887413
Policy mu Min                -2.817033
Policy log std Mean          -0.40130106
Policy log std Std           0.15559022
Policy log std Max           -0.046113864
Policy log std Min           -1.0439845
Z mean eval                  0.93975466
Z variance eval              0.011998633
total_rewards                [1208.64183343 1150.66890569 2921.72516094 3105.88545543 3210.40603432
 2858.07999228 2763.31352353 1072.48769454 1861.16865408 1112.50779213]
total_rewards_mean           2126.48850463594
total_rewards_std            878.1460450883432
total_rewards_max            3210.406034321693
total_rewards_min            1072.487694540825
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               32.91983507713303
(Previous) Eval Time (s)     26.251765547785908
Sample Time (s)              22.278933177236468
Epoch Time (s)               81.4505338021554
Total Train Time (s)         31623.405389543623
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:48.370944 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #469 | Epoch Duration: 74.74719667434692
2020-01-11 08:49:48.371144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9374712
Z variance train             0.011946257
KL Divergence                13.131401
KL Loss                      1.3131402
QF Loss                      117.65233
VF Loss                      58.12697
Policy Loss                  -1511.1152
Q Predictions Mean           1510.8892
Q Predictions Std            129.28407
Q Predictions Max            1656.4594
Q Predictions Min            423.42853
V Predictions Mean           1515.961
V Predictions Std            126.89946
V Predictions Max            1657.7173
V Predictions Min            509.4437
Log Pis Mean                 -0.8498554
Log Pis Std                  1.6578153
Log Pis Max                  7.385412
Log Pis Min                  -5.102912
Policy mu Mean               0.0020005424
Policy mu Std                0.7533103
Policy mu Max                2.6440687
Policy mu Min                -2.747797
Policy log std Mean          -0.36885324
Policy log std Std           0.14907962
Policy log std Max           0.0026323646
Policy log std Min           -0.92213285
Z mean eval                  0.9358309
Z variance eval              0.010365447
total_rewards                [3164.22216087 1389.73579223 3259.71610722 1226.49305222 3219.99969838
 3250.65698802 1743.06127729 3176.39677106 3171.08666486 3170.8579759 ]
total_rewards_mean           2677.22264880572
total_rewards_std            810.6509460856618
total_rewards_max            3259.716107219186
total_rewards_min            1226.4930522219404
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               33.159111557062715
(Previous) Eval Time (s)     19.548147932160646
Sample Time (s)              23.39403626602143
Epoch Time (s)               76.10129575524479
Total Train Time (s)         31704.500109313056
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:09.470291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #470 | Epoch Duration: 81.09897041320801
2020-01-11 08:51:09.470471 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93522054
Z variance train             0.010352189
KL Divergence                13.413708
KL Loss                      1.3413708
QF Loss                      77.631714
VF Loss                      82.72067
Policy Loss                  -1501.0391
Q Predictions Mean           1499.2141
Q Predictions Std            155.40697
Q Predictions Max            1651.056
Q Predictions Min            10.159387
V Predictions Mean           1504.5647
V Predictions Std            156.81287
V Predictions Max            1650.6539
V Predictions Min            -0.24144274
Log Pis Mean                 -0.6357439
Log Pis Std                  1.6974088
Log Pis Max                  5.863169
Log Pis Min                  -5.9233603
Policy mu Mean               0.061376378
Policy mu Std                0.79044956
Policy mu Max                1.8891398
Policy mu Min                -2.733122
Policy log std Mean          -0.38116845
Policy log std Std           0.13982369
Policy log std Max           -0.03952314
Policy log std Min           -1.0005441
Z mean eval                  0.89692557
Z variance eval              0.010930839
total_rewards                [3160.86218859 3248.44973654 3222.63652881 1275.56351702 3278.10431709
 1263.91747999 3236.47953108 3216.94454871 3284.76262266 3277.71013974]
total_rewards_mean           2846.543061022362
total_rewards_std            789.1695957249359
total_rewards_max            3284.762622661939
total_rewards_min            1263.9174799886123
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               33.787393344100565
(Previous) Eval Time (s)     24.545497206039727
Sample Time (s)              22.846804607193917
Epoch Time (s)               81.17969515733421
Total Train Time (s)         31787.66213407507
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:32.637613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #471 | Epoch Duration: 83.1670036315918
2020-01-11 08:52:32.637809 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89544785
Z variance train             0.010949049
KL Divergence                12.950639
KL Loss                      1.2950639
QF Loss                      170.7219
VF Loss                      59.59966
Policy Loss                  -1335.2456
Q Predictions Mean           1334.3052
Q Predictions Std            136.32945
Q Predictions Max            1510.3815
Q Predictions Min            411.1639
V Predictions Mean           1335.6995
V Predictions Std            133.6528
V Predictions Max            1506.452
V Predictions Min            456.89862
Log Pis Mean                 -0.2733189
Log Pis Std                  1.9057704
Log Pis Max                  6.8478093
Log Pis Min                  -5.034096
Policy mu Mean               -0.19531925
Policy mu Std                0.86423063
Policy mu Max                3.0885718
Policy mu Min                -2.8173885
Policy log std Mean          -0.4194342
Policy log std Std           0.1556312
Policy log std Max           -0.058027968
Policy log std Min           -1.0306286
Z mean eval                  0.90932214
Z variance eval              0.012063265
total_rewards                [3217.58031689 1598.31047875 3159.02456034 3161.12752598 3141.00065178
 3179.42900254 3194.18470328 3189.35372085 1227.61254671 3206.92564816]
total_rewards_mean           2827.4549155291134
total_rewards_std            712.4199272028573
total_rewards_max            3217.580316893173
total_rewards_min            1227.6125467090465
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               33.231703266035765
(Previous) Eval Time (s)     26.53247303934768
Sample Time (s)              23.463673131540418
Epoch Time (s)               83.22784943692386
Total Train Time (s)         31870.92957907915
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:55.911011 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #472 | Epoch Duration: 83.27304720878601
2020-01-11 08:53:55.911230 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90825194
Z variance train             0.012066288
KL Divergence                12.972991
KL Loss                      1.2972991
QF Loss                      3160.2532
VF Loss                      426.32562
Policy Loss                  -1430.1096
Q Predictions Mean           1430.6537
Q Predictions Std            168.29724
Q Predictions Max            1592.1013
Q Predictions Min            242.30261
V Predictions Mean           1438.8572
V Predictions Std            164.10307
V Predictions Max            1589.3533
V Predictions Min            285.19003
Log Pis Mean                 -0.6024023
Log Pis Std                  1.922552
Log Pis Max                  10.437118
Log Pis Min                  -4.606531
Policy mu Mean               -0.061134856
Policy mu Std                0.81767327
Policy mu Max                3.331848
Policy mu Min                -2.833265
Policy log std Mean          -0.39029106
Policy log std Std           0.14779507
Policy log std Max           -0.05618976
Policy log std Min           -1.0314561
Z mean eval                  0.8996604
Z variance eval              0.0071405075
total_rewards                [3202.96944858 3206.45160149 3143.28522818 3184.50331042 3168.98420551
 3159.5123912  3180.91560073 3220.76130986 3190.14589026 3156.23304011]
total_rewards_mean           3181.3762026335744
total_rewards_std            23.34056072182114
total_rewards_max            3220.7613098623237
total_rewards_min            3143.2852281769474
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               33.65586093487218
(Previous) Eval Time (s)     26.577274406328797
Sample Time (s)              23.907646343577653
Epoch Time (s)               84.14078168477863
Total Train Time (s)         31958.22391790012
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:23.208484 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #473 | Epoch Duration: 87.29711055755615
2020-01-11 08:55:23.208659 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90198594
Z variance train             0.0071307076
KL Divergence                14.553553
KL Loss                      1.4553553
QF Loss                      87.6977
VF Loss                      80.8707
Policy Loss                  -1404.8116
Q Predictions Mean           1403.6462
Q Predictions Std            122.3296
Q Predictions Max            1547.7533
Q Predictions Min            379.98865
V Predictions Mean           1399.2383
V Predictions Std            120.37965
V Predictions Max            1533.4269
V Predictions Min            389.9966
Log Pis Mean                 -0.5947969
Log Pis Std                  1.7877305
Log Pis Max                  5.383047
Log Pis Min                  -5.512602
Policy mu Mean               -0.0012970393
Policy mu Std                0.81163895
Policy mu Max                2.8319383
Policy mu Min                -2.7774189
Policy log std Mean          -0.38239363
Policy log std Std           0.13931099
Policy log std Max           -0.06519526
Policy log std Min           -0.8527886
Z mean eval                  0.9127806
Z variance eval              0.008634296
total_rewards                [3185.88735485 3175.17792215 3177.47529766 3167.833159   3172.73586234
 3146.42443714 3019.48758024 3204.20260832 3158.42191785 3161.29877872]
total_rewards_mean           3156.894491827191
total_rewards_std            48.186214847694394
total_rewards_max            3204.2026083187106
total_rewards_min            3019.4875802446777
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               33.355407604947686
(Previous) Eval Time (s)     29.733264330308884
Sample Time (s)              22.058618251234293
Epoch Time (s)               85.14729018649086
Total Train Time (s)         32042.468528181314
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:47.458291 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #474 | Epoch Duration: 84.24948573112488
2020-01-11 08:56:47.458521 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9124163
Z variance train             0.008655995
KL Divergence                14.111624
KL Loss                      1.4111624
QF Loss                      72.33974
VF Loss                      53.75807
Policy Loss                  -1460.0305
Q Predictions Mean           1458.2949
Q Predictions Std            152.19496
Q Predictions Max            1597.4276
Q Predictions Min            451.13586
V Predictions Mean           1462.5433
V Predictions Std            149.39009
V Predictions Max            1598.8898
V Predictions Min            440.60004
Log Pis Mean                 -0.74329424
Log Pis Std                  1.6523623
Log Pis Max                  5.3278084
Log Pis Min                  -5.0725274
Policy mu Mean               0.05886078
Policy mu Std                0.78708243
Policy mu Max                3.7223346
Policy mu Min                -2.64966
Policy log std Mean          -0.39850745
Policy log std Std           0.152867
Policy log std Max           -0.09405778
Policy log std Min           -1.095197
Z mean eval                  0.9232222
Z variance eval              0.012887508
total_rewards                [3194.84450336 1715.41550547 2310.22374854 3156.83968475 2303.30165485
 3191.91686326 1183.43323981 3154.8376152  3209.20647461 1510.5766608 ]
total_rewards_mean           2493.059595063847
total_rewards_std            756.7618718292177
total_rewards_max            3209.2064746111905
total_rewards_min            1183.4332398055117
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               33.30371182691306
(Previous) Eval Time (s)     28.8351542619057
Sample Time (s)              23.6138155721128
Epoch Time (s)               85.75268166093156
Total Train Time (s)         32123.526068123057
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:58:08.521112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #475 | Epoch Duration: 81.06242275238037
2020-01-11 08:58:08.521330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9211338
Z variance train             0.012905719
KL Divergence                12.671057
KL Loss                      1.2671057
QF Loss                      118.75329
VF Loss                      52.17835
Policy Loss                  -1380.6926
Q Predictions Mean           1381.5232
Q Predictions Std            177.48355
Q Predictions Max            1536.5089
Q Predictions Min            6.933389
V Predictions Mean           1380.8909
V Predictions Std            179.89041
V Predictions Max            1538.4651
V Predictions Min            6.4504128
Log Pis Mean                 -0.8402416
Log Pis Std                  1.7325934
Log Pis Max                  5.3797355
Log Pis Min                  -4.942882
Policy mu Mean               -0.014253237
Policy mu Std                0.7620243
Policy mu Max                1.8051037
Policy mu Min                -3.2953508
Policy log std Mean          -0.38819656
Policy log std Std           0.14934821
Policy log std Max           -0.102595896
Policy log std Min           -1.2559496
Z mean eval                  0.89758444
Z variance eval              0.01611882
total_rewards                [3193.21753425 1243.13724522 1506.47208826 1996.98848139 3222.64346012
 3178.96588609 3218.95134893 1174.87254312 1111.89885693 1038.85939879]
total_rewards_mean           2088.600684310126
total_rewards_std            944.7590998675765
total_rewards_max            3222.643460123243
total_rewards_min            1038.859398791163
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               33.41629005828872
(Previous) Eval Time (s)     24.144541586283594
Sample Time (s)              23.230573794338852
Epoch Time (s)               80.79140543891117
Total Train Time (s)         32198.85991456313
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:23.859491 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #476 | Epoch Duration: 75.33800864219666
2020-01-11 08:59:23.859667 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8992268
Z variance train             0.016075358
KL Divergence                12.218831
KL Loss                      1.2218832
QF Loss                      79.803955
VF Loss                      39.715473
Policy Loss                  -1392.228
Q Predictions Mean           1389.1921
Q Predictions Std            197.66475
Q Predictions Max            1551.4952
Q Predictions Min            -4.8443203
V Predictions Mean           1391.7789
V Predictions Std            198.6739
V Predictions Max            1558.7709
V Predictions Min            3.675652
Log Pis Mean                 -0.6740841
Log Pis Std                  1.8582464
Log Pis Max                  6.166747
Log Pis Min                  -4.3851233
Policy mu Mean               -0.038779125
Policy mu Std                0.8474498
Policy mu Max                1.8822862
Policy mu Min                -2.9119835
Policy log std Mean          -0.39071882
Policy log std Std           0.15931301
Policy log std Max           0.0612092
Policy log std Min           -1.0596391
Z mean eval                  0.87858325
Z variance eval              0.020958282
total_rewards                [3197.3204464  3247.41080337 3197.94158771 3173.55658472 3164.99307345
 3167.88034541 3278.98165282 3181.91209471 3139.62863157 3149.63062151]
total_rewards_mean           3189.92558416774
total_rewards_std            41.16761390444412
total_rewards_max            3278.981652820511
total_rewards_min            3139.6286315663065
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               33.61959351086989
(Previous) Eval Time (s)     18.690829084720463
Sample Time (s)              23.87409936171025
Epoch Time (s)               76.1845219573006
Total Train Time (s)         32285.745895095635
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:50.749994 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #477 | Epoch Duration: 86.89019417762756
2020-01-11 09:00:50.750166 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88159627
Z variance train             0.021042699
KL Divergence                12.743141
KL Loss                      1.2743142
QF Loss                      79.38492
VF Loss                      55.90866
Policy Loss                  -1425.9205
Q Predictions Mean           1424.7888
Q Predictions Std            152.67741
Q Predictions Max            1570.5552
Q Predictions Min            0.51343304
V Predictions Mean           1425.8627
V Predictions Std            150.59973
V Predictions Max            1578.944
V Predictions Min            4.145683
Log Pis Mean                 -0.6150577
Log Pis Std                  1.7679127
Log Pis Max                  6.9548774
Log Pis Min                  -4.8895793
Policy mu Mean               -0.05221198
Policy mu Std                0.79597735
Policy mu Max                3.1061788
Policy mu Min                -2.7159042
Policy log std Mean          -0.39074335
Policy log std Std           0.14880246
Policy log std Max           -0.041273013
Policy log std Min           -0.9761665
Z mean eval                  0.9050482
Z variance eval              0.015533512
total_rewards                [1224.60540068 1508.54620591 2246.69259183 3183.43161962 3119.18883463
 2825.00713014 3202.79984796 3217.9116171  3215.41348525 3170.11980604]
total_rewards_mean           2691.3716539140396
total_rewards_std            723.4535579729169
total_rewards_max            3217.9116170956713
total_rewards_min            1224.6054006765787
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               33.25127606326714
(Previous) Eval Time (s)     29.396179114002734
Sample Time (s)              24.49478452047333
Epoch Time (s)               87.14223969774321
Total Train Time (s)         32367.77334340755
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:02:12.782527 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #478 | Epoch Duration: 82.03222870826721
2020-01-11 09:02:12.782722 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9062273
Z variance train             0.015555163
KL Divergence                12.948111
KL Loss                      1.2948111
QF Loss                      53.46834
VF Loss                      104.69111
Policy Loss                  -1481.0519
Q Predictions Mean           1481.9177
Q Predictions Std            157.68849
Q Predictions Max            1645.7311
Q Predictions Min            12.261931
V Predictions Mean           1474.979
V Predictions Std            157.5695
V Predictions Max            1626.1154
V Predictions Min            5.58562
Log Pis Mean                 -0.8613926
Log Pis Std                  1.4801517
Log Pis Max                  5.143091
Log Pis Min                  -5.3571973
Policy mu Mean               0.09972372
Policy mu Std                0.6994503
Policy mu Max                2.1340873
Policy mu Min                -2.661584
Policy log std Mean          -0.3668878
Policy log std Std           0.13301855
Policy log std Max           -0.053634584
Policy log std Min           -0.9237759
Z mean eval                  0.8621132
Z variance eval              0.012748529
total_rewards                [3098.30288276 1349.1114433  3152.94045647 3322.25961897 1359.45424143
 3106.75413172 3105.08960262 3089.35284172 3103.93074106 3070.67374951]
total_rewards_mean           2775.786970956439
total_rewards_std            713.9492046376248
total_rewards_max            3322.2596189726146
total_rewards_min            1349.1114432963543
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               35.60405554110184
(Previous) Eval Time (s)     24.285779307596385
Sample Time (s)              23.12375072715804
Epoch Time (s)               83.01358557585627
Total Train Time (s)         32453.77011747798
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:38.786184 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #479 | Epoch Duration: 86.00327849388123
2020-01-11 09:03:38.786553 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86139095
Z variance train             0.012694955
KL Divergence                13.299292
KL Loss                      1.3299292
QF Loss                      147.77478
VF Loss                      29.849659
Policy Loss                  -1381.7079
Q Predictions Mean           1382.5308
Q Predictions Std            136.59497
Q Predictions Max            1529.0138
Q Predictions Min            238.5356
V Predictions Mean           1383.7721
V Predictions Std            136.18192
V Predictions Max            1526.2207
V Predictions Min            240.57999
Log Pis Mean                 -0.42517123
Log Pis Std                  1.8915106
Log Pis Max                  5.794701
Log Pis Min                  -5.9349947
Policy mu Mean               0.026803369
Policy mu Std                0.831461
Policy mu Max                2.616793
Policy mu Min                -2.6712415
Policy log std Mean          -0.39465484
Policy log std Std           0.1543874
Policy log std Max           -0.045549482
Policy log std Min           -0.96350634
Z mean eval                  0.9127041
Z variance eval              0.015103986
total_rewards                [3220.92912479 1192.30472293 3177.57962149 3207.73180392 3190.36648968
 1266.95465717 1401.86464306 2698.45081107 2712.06746335 3138.36962916]
total_rewards_mean           2520.661896663575
total_rewards_std            829.476590218388
total_rewards_max            3220.9291247940932
total_rewards_min            1192.3047229324081
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               35.47100878180936
(Previous) Eval Time (s)     27.27509280713275
Sample Time (s)              24.641924949828535
Epoch Time (s)               87.38802653877065
Total Train Time (s)         32538.085651688743
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:03.106507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #480 | Epoch Duration: 84.3197340965271
2020-01-11 09:05:03.106746 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91249675
Z variance train             0.015109
KL Divergence                13.381115
KL Loss                      1.3381115
QF Loss                      58.654438
VF Loss                      27.518919
Policy Loss                  -1479.1777
Q Predictions Mean           1477.737
Q Predictions Std            134.67078
Q Predictions Max            1646.0078
Q Predictions Min            597.4064
V Predictions Mean           1481.3293
V Predictions Std            133.31288
V Predictions Max            1650.5387
V Predictions Min            642.1633
Log Pis Mean                 -0.6881331
Log Pis Std                  1.7479304
Log Pis Max                  6.2886267
Log Pis Min                  -4.6591754
Policy mu Mean               -0.03706857
Policy mu Std                0.7668601
Policy mu Max                2.937821
Policy mu Min                -2.7617607
Policy log std Mean          -0.37527665
Policy log std Std           0.14209579
Policy log std Max           -0.072374195
Policy log std Min           -1.0287149
Z mean eval                  0.88290054
Z variance eval              0.0149388015
total_rewards                [3297.94009915 3233.6983889  1186.13052507 3211.32961774 3277.93847817
 1433.73943935 3241.3461403  3195.08894178 3235.65368368 3219.38576449]
total_rewards_mean           2853.2251078615377
total_rewards_std            774.1530596648042
total_rewards_max            3297.940099145133
total_rewards_min            1186.1305250707283
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               36.41435968130827
(Previous) Eval Time (s)     24.206418767105788
Sample Time (s)              24.39156984211877
Epoch Time (s)               85.01234829053283
Total Train Time (s)         32626.22270407714
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:31.248117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #481 | Epoch Duration: 88.14121770858765
2020-01-11 09:06:31.248381 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8814634
Z variance train             0.014970134
KL Divergence                12.022265
KL Loss                      1.2022265
QF Loss                      199.0803
VF Loss                      56.60644
Policy Loss                  -1420.2069
Q Predictions Mean           1418.6075
Q Predictions Std            134.81401
Q Predictions Max            1569.8068
Q Predictions Min            451.3844
V Predictions Mean           1423.3619
V Predictions Std            134.83662
V Predictions Max            1575.5409
V Predictions Min            441.01294
Log Pis Mean                 -0.6363476
Log Pis Std                  1.8585826
Log Pis Max                  6.8260183
Log Pis Min                  -5.411596
Policy mu Mean               0.012959587
Policy mu Std                0.8124844
Policy mu Max                1.7146119
Policy mu Min                -2.9770074
Policy log std Mean          -0.4036804
Policy log std Std           0.14545268
Policy log std Max           -0.07919696
Policy log std Min           -0.9643152
Z mean eval                  0.8331375
Z variance eval              0.024694871
total_rewards                [3185.99214732 3168.24581908 3154.13245534 3153.7455353  3186.96480364
 3141.93522896 1868.89764909 3130.37561972 3097.61539907 3176.25095204]
total_rewards_mean           3026.4155609569107
total_rewards_std            386.70419715997224
total_rewards_max            3186.9648036397502
total_rewards_min            1868.8976490914815
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               35.1092351176776
(Previous) Eval Time (s)     27.334934765007347
Sample Time (s)              24.15473169228062
Epoch Time (s)               86.59890157496557
Total Train Time (s)         32715.222052981146
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:00.251999 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #482 | Epoch Duration: 89.00347471237183
2020-01-11 09:08:00.252193 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83405364
Z variance train             0.024836522
KL Divergence                11.292623
KL Loss                      1.1292623
QF Loss                      84.322945
VF Loss                      102.69514
Policy Loss                  -1424.371
Q Predictions Mean           1423.3293
Q Predictions Std            118.79059
Q Predictions Max            1564.1382
Q Predictions Min            724.586
V Predictions Mean           1428.1365
V Predictions Std            118.86284
V Predictions Max            1573.934
V Predictions Min            765.016
Log Pis Mean                 -0.534764
Log Pis Std                  1.609826
Log Pis Max                  4.5309124
Log Pis Min                  -3.9895177
Policy mu Mean               0.0005481082
Policy mu Std                0.8265589
Policy mu Max                2.441512
Policy mu Min                -2.8516762
Policy log std Mean          -0.3842049
Policy log std Std           0.14449456
Policy log std Max           -0.068989575
Policy log std Min           -1.0435878
Z mean eval                  0.8539381
Z variance eval              0.028070608
total_rewards                [1049.2136559  3128.54286812 3158.9368443  1164.04430033 3142.11700123
 1258.8302713  3109.34325857 3116.67672003 3141.6845485  2193.2922041 ]
total_rewards_mean           2446.2681672380136
total_rewards_std            888.8299109152111
total_rewards_max            3158.936844296464
total_rewards_min            1049.2136559000621
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               36.248803530819714
(Previous) Eval Time (s)     29.73914160905406
Sample Time (s)              24.924502927344292
Epoch Time (s)               90.91244806721807
Total Train Time (s)         32800.72399552073
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:09:25.759283 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #483 | Epoch Duration: 85.50695180892944
2020-01-11 09:09:25.759476 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8524748
Z variance train             0.028082728
KL Divergence                10.852905
KL Loss                      1.0852906
QF Loss                      144.26048
VF Loss                      163.17543
Policy Loss                  -1483.8405
Q Predictions Mean           1483.5281
Q Predictions Std            187.85405
Q Predictions Max            1646.9366
Q Predictions Min            12.759567
V Predictions Mean           1488.2823
V Predictions Std            187.70636
V Predictions Max            1649.2743
V Predictions Min            16.633677
Log Pis Mean                 -0.76663303
Log Pis Std                  1.5575609
Log Pis Max                  5.82847
Log Pis Min                  -6.6158824
Policy mu Mean               0.15851156
Policy mu Std                0.7421018
Policy mu Max                1.9563363
Policy mu Min                -2.788352
Policy log std Mean          -0.38891506
Policy log std Std           0.13943751
Policy log std Max           -0.062109277
Policy log std Min           -1.279521
Z mean eval                  0.9186171
Z variance eval              0.027860666
total_rewards                [3181.3092191  3238.84912713 1103.04381105 3190.51263078 3236.20364785
 3266.63160418 1098.41960647 3239.64867241 3174.6573976  2487.8897828 ]
total_rewards_mean           2721.7165499368175
total_rewards_std            839.2454428768325
total_rewards_max            3266.631604178523
total_rewards_min            1098.419606470576
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               34.66418053396046
(Previous) Eval Time (s)     24.333207183983177
Sample Time (s)              24.36231322027743
Epoch Time (s)               83.35970093822107
Total Train Time (s)         32885.4169505965
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:50.457519 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #484 | Epoch Duration: 84.69790315628052
2020-01-11 09:10:50.457706 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91938746
Z variance train             0.027828401
KL Divergence                10.856152
KL Loss                      1.0856152
QF Loss                      40.517357
VF Loss                      23.701092
Policy Loss                  -1530.144
Q Predictions Mean           1529.9622
Q Predictions Std            129.03415
Q Predictions Max            1671.6887
Q Predictions Min            918.62646
V Predictions Mean           1527.3042
V Predictions Std            129.88742
V Predictions Max            1666.0089
V Predictions Min            906.2847
Log Pis Mean                 -0.8726492
Log Pis Std                  1.3122197
Log Pis Max                  4.9445767
Log Pis Min                  -5.1428328
Policy mu Mean               0.10603476
Policy mu Std                0.65695715
Policy mu Max                1.929989
Policy mu Min                -2.6559336
Policy log std Mean          -0.36540684
Policy log std Std           0.12212061
Policy log std Max           -0.05548221
Policy log std Min           -0.9463939
Z mean eval                  0.8449251
Z variance eval              0.024444284
total_rewards                [3112.26914964 3107.19020646 1328.51186213 1035.2076005  3156.94331333
 3136.11049132 1083.4950734  3131.03030097 1990.88928209  960.42616982]
total_rewards_mean           2204.20734496631
total_rewards_std            962.1330243315261
total_rewards_max            3156.9433133346693
total_rewards_min            960.4261698173736
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               35.56504255300388
(Previous) Eval Time (s)     25.671032798010856
Sample Time (s)              23.830848598387092
Epoch Time (s)               85.06692394940183
Total Train Time (s)         32966.814608922694
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:12:11.859661 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #485 | Epoch Duration: 81.4017915725708
2020-01-11 09:12:11.859952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8455469
Z variance train             0.024445469
KL Divergence                11.082682
KL Loss                      1.1082681
QF Loss                      51.96792
VF Loss                      16.764936
Policy Loss                  -1512.4143
Q Predictions Mean           1511.794
Q Predictions Std            97.0029
Q Predictions Max            1629.8418
Q Predictions Min            1142.153
V Predictions Mean           1510.4541
V Predictions Std            96.868965
V Predictions Max            1629.9852
V Predictions Min            1131.5156
Log Pis Mean                 -0.9631905
Log Pis Std                  1.4690888
Log Pis Max                  5.2115507
Log Pis Min                  -6.0130863
Policy mu Mean               0.10293347
Policy mu Std                0.67367
Policy mu Max                1.8953767
Policy mu Min                -2.623786
Policy log std Mean          -0.359921
Policy log std Std           0.13894476
Policy log std Max           -0.05127217
Policy log std Min           -0.8752642
Z mean eval                  0.8668852
Z variance eval              0.013448216
total_rewards                [3266.81233505 3225.1616182  3273.45611413 3363.10905078 2457.88039218
 3295.63144628 3249.00549602 3346.45873814 3286.08961272 3203.6093032 ]
total_rewards_mean           3196.7214106707142
total_rewards_std            250.629787086105
total_rewards_max            3363.109050784877
total_rewards_min            2457.8803921823746
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               36.90036032581702
(Previous) Eval Time (s)     22.00556904776022
Sample Time (s)              25.128205843735486
Epoch Time (s)               84.03413521731272
Total Train Time (s)         33057.90063756332
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:42.950735 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #486 | Epoch Duration: 91.09061312675476
2020-01-11 09:13:42.950955 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8678837
Z variance train             0.013450019
KL Divergence                12.631026
KL Loss                      1.2631027
QF Loss                      82.62341
VF Loss                      73.51305
Policy Loss                  -1466.4202
Q Predictions Mean           1465.7423
Q Predictions Std            104.70809
Q Predictions Max            1591.3359
Q Predictions Min            773.02057
V Predictions Mean           1469.2435
V Predictions Std            104.252975
V Predictions Max            1601.4794
V Predictions Min            764.9548
Log Pis Mean                 -0.7515938
Log Pis Std                  1.7254919
Log Pis Max                  5.3624883
Log Pis Min                  -6.8917084
Policy mu Mean               -0.046756644
Policy mu Std                0.7454434
Policy mu Max                1.6949077
Policy mu Min                -2.4629402
Policy log std Mean          -0.379601
Policy log std Std           0.14549212
Policy log std Max           -0.07618111
Policy log std Min           -0.9651102
Z mean eval                  0.84550846
Z variance eval              0.011134905
total_rewards                [3274.78154485 3262.28001284 3237.13118765 3287.40182436 3254.88161838
 3229.41684796 3255.51797078 1607.95626837 1815.87264811 3224.44554191]
total_rewards_mean           2944.968546522114
total_rewards_std            618.5505155649696
total_rewards_max            3287.401824357839
total_rewards_min            1607.9562683743588
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               35.28866782784462
(Previous) Eval Time (s)     29.061611732002348
Sample Time (s)              23.597430442925543
Epoch Time (s)               87.94771000277251
Total Train Time (s)         33141.85044148285
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:06.906528 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #487 | Epoch Duration: 83.95541572570801
2020-01-11 09:15:06.906799 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8435303
Z variance train             0.011151133
KL Divergence                13.043236
KL Loss                      1.3043236
QF Loss                      39.911205
VF Loss                      32.27377
Policy Loss                  -1447.1859
Q Predictions Mean           1449.7882
Q Predictions Std            112.304565
Q Predictions Max            1587.2611
Q Predictions Min            1037.397
V Predictions Mean           1451.0326
V Predictions Std            111.96714
V Predictions Max            1588.1025
V Predictions Min            1047.2408
Log Pis Mean                 -0.66407657
Log Pis Std                  1.7679915
Log Pis Max                  5.2081456
Log Pis Min                  -4.886651
Policy mu Mean               0.049413193
Policy mu Std                0.7766803
Policy mu Max                1.8954265
Policy mu Min                -2.9606075
Policy log std Mean          -0.38040757
Policy log std Std           0.13864791
Policy log std Max           -0.06556293
Policy log std Min           -0.9389857
Z mean eval                  0.83605975
Z variance eval              0.01242987
total_rewards                [1460.82263087 3326.31713675 3321.87415789 3115.39938987 3026.2783124
 1467.67211388 3189.21615447 1626.42461202 1161.60414448 3215.98424576]
total_rewards_mean           2491.1592898417857
total_rewards_std            877.5455015427938
total_rewards_max            3326.3171367518116
total_rewards_min            1161.6041444805778
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               36.018146719783545
(Previous) Eval Time (s)     25.06890406506136
Sample Time (s)              24.962275438476354
Epoch Time (s)               86.04932622332126
Total Train Time (s)         33226.4310586364
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:31.492262 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #488 | Epoch Duration: 84.5853054523468
2020-01-11 09:16:31.492448 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8363854
Z variance train             0.01244464
KL Divergence                12.960517
KL Loss                      1.2960517
QF Loss                      37.015793
VF Loss                      19.587162
Policy Loss                  -1435.8376
Q Predictions Mean           1434.4407
Q Predictions Std            123.508736
Q Predictions Max            1574.4744
Q Predictions Min            883.0047
V Predictions Mean           1434.1339
V Predictions Std            122.53755
V Predictions Max            1573.4203
V Predictions Min            883.03143
Log Pis Mean                 -0.8007068
Log Pis Std                  1.6728872
Log Pis Max                  8.216572
Log Pis Min                  -4.7168584
Policy mu Mean               0.06508403
Policy mu Std                0.76640326
Policy mu Max                2.2135005
Policy mu Min                -2.7325056
Policy log std Mean          -0.37874302
Policy log std Std           0.14689219
Policy log std Max           -0.005049765
Policy log std Min           -1.0377929
Z mean eval                  0.87369597
Z variance eval              0.009503498
total_rewards                [1017.63012374 3262.10951251 3256.71964339 3247.19074846 1364.01082935
 3233.48971129 3188.18353734 3242.70273878 1261.88569012 3267.14244423]
total_rewards_mean           2634.1064979202374
total_rewards_std            932.9748941040574
total_rewards_max            3267.142444230959
total_rewards_min            1017.6301237350789
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               33.15743237780407
(Previous) Eval Time (s)     23.60450525721535
Sample Time (s)              21.480227237567306
Epoch Time (s)               78.24216487258673
Total Train Time (s)         33305.82408580836
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:17:50.889737 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #489 | Epoch Duration: 79.3971495628357
2020-01-11 09:17:50.889928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87334967
Z variance train             0.009533814
KL Divergence                13.442496
KL Loss                      1.3442496
QF Loss                      82.06675
VF Loss                      20.2276
Policy Loss                  -1476.2129
Q Predictions Mean           1475.439
Q Predictions Std            128.42488
Q Predictions Max            1613.0643
Q Predictions Min            449.58255
V Predictions Mean           1477.5481
V Predictions Std            128.41199
V Predictions Max            1617.2198
V Predictions Min            429.04218
Log Pis Mean                 -0.73266935
Log Pis Std                  1.7030312
Log Pis Max                  6.8508854
Log Pis Min                  -5.603237
Policy mu Mean               0.0685801
Policy mu Std                0.7554529
Policy mu Max                1.7778968
Policy mu Min                -2.824382
Policy log std Mean          -0.37712368
Policy log std Std           0.14954492
Policy log std Max           -0.07949287
Policy log std Min           -0.9943105
Z mean eval                  0.83456564
Z variance eval              0.011471378
total_rewards                [3296.64712954 3254.67121979 3304.45850408 3277.67894146 1572.1848608
  958.45798106 3230.78746569 3253.07079969 3253.72764711 3310.26009653]
total_rewards_mean           2871.1944645741182
total_rewards_std            814.9383708327365
total_rewards_max            3310.2600965259976
total_rewards_min            958.457981056222
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               33.19567116815597
(Previous) Eval Time (s)     24.759176631923765
Sample Time (s)              22.931588228791952
Epoch Time (s)               80.88643602887169
Total Train Time (s)         33388.04610384861
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:13.117294 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #490 | Epoch Duration: 82.22721719741821
2020-01-11 09:19:13.117507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8385952
Z variance train             0.011475755
KL Divergence                12.543808
KL Loss                      1.2543808
QF Loss                      138.6033
VF Loss                      36.99041
Policy Loss                  -1397.4933
Q Predictions Mean           1397.2051
Q Predictions Std            117.10517
Q Predictions Max            1529.8196
Q Predictions Min            665.6498
V Predictions Mean           1395.1573
V Predictions Std            116.34389
V Predictions Max            1530.5902
V Predictions Min            659.71313
Log Pis Mean                 -0.58582664
Log Pis Std                  1.6982598
Log Pis Max                  6.212344
Log Pis Min                  -4.664024
Policy mu Mean               0.04831465
Policy mu Std                0.82230526
Policy mu Max                2.003464
Policy mu Min                -2.9005837
Policy log std Mean          -0.3984097
Policy log std Std           0.14517105
Policy log std Max           -0.09467363
Policy log std Min           -1.1188588
Z mean eval                  0.8010217
Z variance eval              0.008446204
total_rewards                [1296.4043535  3264.6093433  3234.64442499 1373.05575177 3225.83543445
 3247.32781028 3251.66507367 3258.1620267  3211.97103672 3257.49900639]
total_rewards_mean           2862.117426178098
total_rewards_std            764.0378833519458
total_rewards_max            3264.6093433046467
total_rewards_min            1296.404353495261
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               33.62419065274298
(Previous) Eval Time (s)     26.099616983905435
Sample Time (s)              23.747964423149824
Epoch Time (s)               83.47177205979824
Total Train Time (s)         33471.92141920002
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:36.996012 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #491 | Epoch Duration: 83.87831497192383
2020-01-11 09:20:36.996252 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8010026
Z variance train             0.008452984
KL Divergence                13.400856
KL Loss                      1.3400856
QF Loss                      76.62106
VF Loss                      58.145527
Policy Loss                  -1482.7076
Q Predictions Mean           1481.3817
Q Predictions Std            125.15834
Q Predictions Max            1617.272
Q Predictions Min            814.8434
V Predictions Mean           1484.2798
V Predictions Std            123.93668
V Predictions Max            1623.272
V Predictions Min            814.6846
Log Pis Mean                 -0.6280357
Log Pis Std                  1.7862341
Log Pis Max                  7.458334
Log Pis Min                  -8.137881
Policy mu Mean               0.010764745
Policy mu Std                0.80317444
Policy mu Max                2.4150896
Policy mu Min                -2.6685038
Policy log std Mean          -0.37924448
Policy log std Std           0.15438579
Policy log std Max           -0.0023221672
Policy log std Min           -1.0070024
Z mean eval                  0.8219601
Z variance eval              0.00799312
total_rewards                [1044.406081   1446.24442369 3217.69262002 3207.40297723 3234.75743093
 1802.42437826 3227.68176037 1526.89540737 3207.68953271  772.02511128]
total_rewards_mean           2268.7219722873515
total_rewards_std            984.8561363636891
total_rewards_max            3234.757430932863
total_rewards_min            772.0251112753388
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               33.323436863254756
(Previous) Eval Time (s)     26.505785257089883
Sample Time (s)              22.86550196260214
Epoch Time (s)               82.69472408294678
Total Train Time (s)         33549.60624301573
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:54.685878 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #492 | Epoch Duration: 77.68948864936829
2020-01-11 09:21:54.686071 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8221591
Z variance train             0.007982637
KL Divergence                13.683886
KL Loss                      1.3683885
QF Loss                      80.0811
VF Loss                      48.62411
Policy Loss                  -1508.4553
Q Predictions Mean           1507.4054
Q Predictions Std            127.679886
Q Predictions Max            1688.845
Q Predictions Min            716.6566
V Predictions Mean           1508.2828
V Predictions Std            124.51618
V Predictions Max            1693.7928
V Predictions Min            711.591
Log Pis Mean                 -0.7274195
Log Pis Std                  1.8864534
Log Pis Max                  11.730263
Log Pis Min                  -4.702346
Policy mu Mean               0.06334794
Policy mu Std                0.76087743
Policy mu Max                2.8964872
Policy mu Min                -2.8320267
Policy log std Mean          -0.36506882
Policy log std Std           0.14082913
Policy log std Max           -0.008710623
Policy log std Min           -1.020159
Z mean eval                  0.82767934
Z variance eval              0.009516662
total_rewards                [3197.83360613 3205.42349611 3282.57579588 3160.44728499 3227.76786125
 3233.28383777 1399.44980029 1488.71176005 3267.98025614 3265.04168447]
total_rewards_mean           2872.8515383072095
total_rewards_std            715.4980917369771
total_rewards_max            3282.575795875435
total_rewards_min            1399.4498002949254
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               33.35019771102816
(Previous) Eval Time (s)     21.500231896992773
Sample Time (s)              22.27339019952342
Epoch Time (s)               77.12381980754435
Total Train Time (s)         33632.01698394958
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:23:17.102145 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #493 | Epoch Duration: 82.41585373878479
2020-01-11 09:23:17.102444 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8274706
Z variance train             0.0095099555
KL Divergence                13.075823
KL Loss                      1.3075823
QF Loss                      50.143944
VF Loss                      80.83301
Policy Loss                  -1518.9509
Q Predictions Mean           1519.061
Q Predictions Std            106.00481
Q Predictions Max            1655.1044
Q Predictions Min            989.37885
V Predictions Mean           1519.9734
V Predictions Std            104.99901
V Predictions Max            1653.1785
V Predictions Min            1003.5921
Log Pis Mean                 -0.954554
Log Pis Std                  1.5106738
Log Pis Max                  3.501108
Log Pis Min                  -6.9831514
Policy mu Mean               0.033462886
Policy mu Std                0.7193834
Policy mu Max                1.4442729
Policy mu Min                -2.7242272
Policy log std Mean          -0.37491632
Policy log std Std           0.14068553
Policy log std Max           -0.051781654
Policy log std Min           -0.9528372
Z mean eval                  0.8047155
Z variance eval              0.019116605
total_rewards                [3099.36159547 3118.47733114 3107.99321619 1009.04288796 1235.76405137
 3177.32676718 1125.5412137  1033.96895777 1351.86203919 1158.75137672]
total_rewards_mean           1941.8089436685918
total_rewards_std            971.1437350010575
total_rewards_max            3177.3267671772956
total_rewards_min            1009.0428879586776
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               33.536452749278396
(Previous) Eval Time (s)     26.79196489835158
Sample Time (s)              22.347161277662963
Epoch Time (s)               82.67557892529294
Total Train Time (s)         33704.154445888475
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:29.243625 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #494 | Epoch Duration: 72.14102053642273
2020-01-11 09:24:29.243811 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8058082
Z variance train             0.018927267
KL Divergence                11.561644
KL Loss                      1.1561644
QF Loss                      73.285034
VF Loss                      66.98702
Policy Loss                  -1427.6705
Q Predictions Mean           1427.6849
Q Predictions Std            113.30833
Q Predictions Max            1588.654
Q Predictions Min            967.10986
V Predictions Mean           1430.1843
V Predictions Std            113.35167
V Predictions Max            1581.245
V Predictions Min            964.5555
Log Pis Mean                 -0.7052358
Log Pis Std                  1.7299562
Log Pis Max                  8.253024
Log Pis Min                  -6.06621
Policy mu Mean               0.023318877
Policy mu Std                0.77475005
Policy mu Max                1.9536238
Policy mu Min                -2.7460232
Policy log std Mean          -0.39582643
Policy log std Std           0.16043907
Policy log std Max           0.05039853
Policy log std Min           -1.0162638
Z mean eval                  0.81905496
Z variance eval              0.009024406
total_rewards                [1191.51010312 1112.47612296 1251.44019965  933.20752456 3243.96608132
 2711.09044927 3198.41419484 3271.66989218 1087.90224452 1219.35641391]
total_rewards_mean           1922.103322632992
total_rewards_std            981.1642289769568
total_rewards_max            3271.6698921768843
total_rewards_min            933.2075245613014
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               33.22412983700633
(Previous) Eval Time (s)     16.2570665567182
Sample Time (s)              23.79366422770545
Epoch Time (s)               73.27486062142998
Total Train Time (s)         33777.38429816952
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:42.479745 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #495 | Epoch Duration: 73.2357885837555
2020-01-11 09:25:42.479948 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8161375
Z variance train             0.009039355
KL Divergence                13.390261
KL Loss                      1.3390261
QF Loss                      2103.5063
VF Loss                      225.21606
Policy Loss                  -1542.5432
Q Predictions Mean           1540.9912
Q Predictions Std            123.361084
Q Predictions Max            1674.1177
Q Predictions Min            680.6762
V Predictions Mean           1551.414
V Predictions Std            114.75697
V Predictions Max            1685.0818
V Predictions Min            930.8497
Log Pis Mean                 -0.6798486
Log Pis Std                  1.7899827
Log Pis Max                  6.9219565
Log Pis Min                  -6.4173994
Policy mu Mean               -0.024525532
Policy mu Std                0.78840756
Policy mu Max                1.7595034
Policy mu Min                -3.6701286
Policy log std Mean          -0.3998039
Policy log std Std           0.16798134
Policy log std Max           -0.0706667
Policy log std Min           -1.6374838
Z mean eval                  0.814196
Z variance eval              0.014740892
total_rewards                [1145.28968992 1356.14297029 1621.43754023 3180.21296035 1106.95650233
 3201.23514641 3194.56137132 2378.66275645 3144.48599197 2435.89058443]
total_rewards_mean           2276.4875513695983
total_rewards_std            850.1496222463411
total_rewards_max            3201.235146413109
total_rewards_min            1106.9565023314753
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               33.27034474397078
(Previous) Eval Time (s)     16.217656020075083
Sample Time (s)              22.565303437411785
Epoch Time (s)               72.05330420145765
Total Train Time (s)         33854.464255324565
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:26:59.563732 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #496 | Epoch Duration: 77.08363699913025
2020-01-11 09:26:59.563911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8142325
Z variance train             0.014771268
KL Divergence                12.44195
KL Loss                      1.244195
QF Loss                      41.275475
VF Loss                      31.218716
Policy Loss                  -1481.0262
Q Predictions Mean           1480.9932
Q Predictions Std            109.63967
Q Predictions Max            1631.0144
Q Predictions Min            882.9271
V Predictions Mean           1480.1548
V Predictions Std            109.10189
V Predictions Max            1627.8915
V Predictions Min            887.1763
Log Pis Mean                 -1.0944299
Log Pis Std                  1.6621459
Log Pis Max                  8.348611
Log Pis Min                  -9.061763
Policy mu Mean               0.071666814
Policy mu Std                0.702084
Policy mu Max                1.8048484
Policy mu Min                -2.6585233
Policy log std Mean          -0.35345212
Policy log std Std           0.13989097
Policy log std Max           -0.075666815
Policy log std Min           -1.186497
Z mean eval                  0.78411376
Z variance eval              0.012987619
total_rewards                [1060.30668364 3217.41663934 3187.722833   1047.62784453 1405.08326612
 1270.54241309 1050.00815457 1140.66167184 3253.2490761  1175.1426952 ]
total_rewards_mean           1780.7761277427744
total_rewards_std            947.6411753108795
total_rewards_max            3253.2490760968694
total_rewards_min            1047.6278445342145
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               33.27962249936536
(Previous) Eval Time (s)     21.247449465095997
Sample Time (s)              22.87566323718056
Epoch Time (s)               77.40273520164192
Total Train Time (s)         33926.73574802093
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:11.840504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #497 | Epoch Duration: 72.27645468711853
2020-01-11 09:28:11.840694 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78560406
Z variance train             0.012995357
KL Divergence                12.460946
KL Loss                      1.2460946
QF Loss                      67.62253
VF Loss                      32.16524
Policy Loss                  -1429.2708
Q Predictions Mean           1427.688
Q Predictions Std            108.21719
Q Predictions Max            1545.0591
Q Predictions Min            410.47717
V Predictions Mean           1426.8228
V Predictions Std            108.40809
V Predictions Max            1538.4757
V Predictions Min            382.35428
Log Pis Mean                 -0.32936245
Log Pis Std                  1.9322145
Log Pis Max                  7.6374836
Log Pis Min                  -3.9688156
Policy mu Mean               -0.066107094
Policy mu Std                0.8767148
Policy mu Max                2.3197813
Policy mu Min                -2.8292568
Policy log std Mean          -0.3911915
Policy log std Std           0.16521908
Policy log std Max           -0.087164536
Policy log std Min           -1.0422866
Z mean eval                  0.80119
Z variance eval              0.01629167
total_rewards                [3205.16385281 1581.10581582 3203.2961906  3179.12498323 3179.04026044
 3214.30118872 3206.24320741 3214.14911316 1242.56948357 3175.69753174]
total_rewards_mean           2840.0691627487863
total_rewards_std            718.2476903163177
total_rewards_max            3214.3011887220496
total_rewards_min            1242.5694835684487
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               33.158788511995226
(Previous) Eval Time (s)     16.120834997389466
Sample Time (s)              23.389641186688095
Epoch Time (s)               72.66926469607279
Total Train Time (s)         34009.16632748069
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:34.275713 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #498 | Epoch Duration: 82.4348795413971
2020-01-11 09:29:34.275900 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8026959
Z variance train             0.016297799
KL Divergence                11.927187
KL Loss                      1.1927187
QF Loss                      71.21517
VF Loss                      27.026293
Policy Loss                  -1486.6471
Q Predictions Mean           1485.79
Q Predictions Std            88.31924
Q Predictions Max            1599.032
Q Predictions Min            1197.7852
V Predictions Mean           1483.6238
V Predictions Std            88.544815
V Predictions Max            1598.1324
V Predictions Min            1196.9294
Log Pis Mean                 -0.9791903
Log Pis Std                  1.4421293
Log Pis Max                  4.8212557
Log Pis Min                  -4.616624
Policy mu Mean               0.00080474373
Policy mu Std                0.69210964
Policy mu Max                1.5701632
Policy mu Min                -2.4854305
Policy log std Mean          -0.35994753
Policy log std Std           0.14689495
Policy log std Max           0.0005494654
Policy log std Min           -1.1492468
Z mean eval                  0.82739353
Z variance eval              0.014985936
total_rewards                [3266.43181121 1168.76658722 3258.23739884 3243.95481078 3263.71606292
 3177.04593552 3231.88638916 3206.18629176 3248.00799312 3217.41503123]
total_rewards_mean           3028.164831176572
total_rewards_std            620.3726637107188
total_rewards_max            3266.4318112085157
total_rewards_min            1168.7665872186242
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               33.443756722379476
(Previous) Eval Time (s)     25.88613132480532
Sample Time (s)              22.862415284849703
Epoch Time (s)               82.1923033320345
Total Train Time (s)         34093.03070799541
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:58.144837 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #499 | Epoch Duration: 83.86879706382751
2020-01-11 09:30:58.145033 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Iteration #499 | Started Training: True
2020-01-11 09:30:58.824703 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] Variant:
2020-01-11 09:30:58.825256 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_seed567",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015201619
Z variance train             0.69264114
KL Divergence                0.14971898
KL Loss                      0.014971899
QF Loss                      32.371784
VF Loss                      16.538906
Policy Loss                  -4.035804
Q Predictions Mean           0.0036291555
Q Predictions Std            0.002453938
Q Predictions Max            0.013234481
Q Predictions Min            -0.0022524772
V Predictions Mean           0.0029185028
V Predictions Std            0.0014939969
V Predictions Max            0.0071519334
V Predictions Min            -0.000653669
Log Pis Mean                 -4.064831
Log Pis Std                  0.5246426
Log Pis Max                  -2.2257078
Log Pis Min                  -5.3402777
Policy mu Mean               -0.0006778512
Policy mu Std                0.0014411181
Policy mu Max                0.0035296434
Policy mu Min                -0.0050696675
Policy log std Mean          0.000738925
Policy log std Std           0.0011386123
Policy log std Max           0.0049709105
Policy log std Min           -0.0033788155
Z mean eval                  0.07993744
Z variance eval              0.32485247
total_rewards                [-200.82907101 -202.76848645 -168.74245878 -232.31895182 -220.13140052
 -212.3383889  -226.08169056 -120.83841821 -218.3369065  -135.31654978]
total_rewards_mean           -193.77023225472038
total_rewards_std            36.96797392052177
total_rewards_max            -120.8384182108695
total_rewards_min            -232.3189518241989
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               31.282528204843402
(Previous) Eval Time (s)     0
Sample Time (s)              30.15089809242636
Epoch Time (s)               61.43342629726976
Total Train Time (s)         88.84280491713434
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:27.762176 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Epoch Duration: 88.84666299819946
2020-01-11 09:32:27.762379 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07835974
Z variance train             0.33578882
KL Divergence                1.1684575
KL Loss                      0.11684575
QF Loss                      14.789925
VF Loss                      3.5173538
Policy Loss                  -14.803765
Q Predictions Mean           10.779072
Q Predictions Std            6.6848345
Q Predictions Max            28.215405
Q Predictions Min            -6.1339226
V Predictions Mean           15.420614
V Predictions Std            6.321533
V Predictions Max            30.021038
V Predictions Min            -1.2740269
Log Pis Mean                 -3.2535362
Log Pis Std                  1.3246145
Log Pis Max                  0.6511984
Log Pis Min                  -6.5906816
Policy mu Mean               0.09648109
Policy mu Std                0.4450997
Policy mu Max                1.1736729
Policy mu Min                -1.3065996
Policy log std Mean          -0.18879552
Policy log std Std           0.077634394
Policy log std Max           -0.08752225
Policy log std Min           -0.43323752
Z mean eval                  0.22500324
Z variance eval              0.13169323
total_rewards                [-200.14584303 -242.15254698 -284.64994695 -242.56218723 -235.53361072
 -198.37059878 -235.11872719 -236.8546247  -214.17362031 -264.53065285]
total_rewards_mean           -235.4092358749761
total_rewards_std            25.372917462329237
total_rewards_max            -198.37059878300934
total_rewards_min            -284.64994694706746
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               30.879661465995014
(Previous) Eval Time (s)     27.412906241137534
Sample Time (s)              22.467444519046694
Epoch Time (s)               80.76001222617924
Total Train Time (s)         169.52885462203994
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:48.451266 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Epoch Duration: 80.68870210647583
2020-01-11 09:33:48.451571 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22587089
Z variance train             0.13049558
KL Divergence                3.1642394
KL Loss                      0.31642395
QF Loss                      34.187645
VF Loss                      5.099211
Policy Loss                  -28.973028
Q Predictions Mean           25.473892
Q Predictions Std            10.219346
Q Predictions Max            62.92463
Q Predictions Min            -3.5590649
V Predictions Mean           29.424427
V Predictions Std            9.8846
V Predictions Max            68.13687
V Predictions Min            5.0687485
Log Pis Mean                 -3.5062134
Log Pis Std                  1.0859234
Log Pis Max                  0.0016558766
Log Pis Min                  -7.534276
Policy mu Mean               0.020472305
Policy mu Std                0.37830496
Policy mu Max                1.3228645
Policy mu Min                -1.2648107
Policy log std Mean          -0.18281329
Policy log std Std           0.06932604
Policy log std Max           -0.05493781
Policy log std Min           -0.4418341
Z mean eval                  0.4366208
Z variance eval              0.08436639
total_rewards                [-264.47025993 -277.17459009 -254.08721252 -247.84073219 -242.9712891
 -263.57358716 -292.24720484 -241.42823686 -245.26586305 -245.56727435]
total_rewards_mean           -257.46262500927
total_rewards_std            15.957175147557543
total_rewards_max            -241.4282368622492
total_rewards_min            -292.2472048401007
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               31.203827689867467
(Previous) Eval Time (s)     27.341280607972294
Sample Time (s)              23.04788814811036
Epoch Time (s)               81.59299644595012
Total Train Time (s)         251.59368136012927
Epoch                        2
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:10.515292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Epoch Duration: 82.0635118484497
2020-01-11 09:35:10.515471 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.43565378
Z variance train             0.084201396
KL Divergence                4.8077207
KL Loss                      0.48077208
QF Loss                      36.738667
VF Loss                      7.615075
Policy Loss                  -43.12816
Q Predictions Mean           39.194317
Q Predictions Std            13.250546
Q Predictions Max            85.675735
Q Predictions Min            -3.2411332
V Predictions Mean           43.626335
V Predictions Std            12.417139
V Predictions Max            79.00407
V Predictions Min            -0.5445509
Log Pis Mean                 -3.1287332
Log Pis Std                  1.5452608
Log Pis Max                  1.7656198
Log Pis Min                  -8.724302
Policy mu Mean               0.066637784
Policy mu Std                0.47198477
Policy mu Max                1.8134552
Policy mu Min                -1.3583819
Policy log std Mean          -0.20153923
Policy log std Std           0.09314299
Policy log std Max           7.034652e-05
Policy log std Min           -0.6536395
Z mean eval                  0.65564376
Z variance eval              0.0458109
total_rewards                [-161.97096196 -181.25996467 -160.20721111 -212.30009532 -203.11699627
 -179.74121454 -151.54230731 -171.16730712 -136.22365779 -218.70594424]
total_rewards_mean           -177.62356603179987
total_rewards_std            25.57742651214993
total_rewards_max            -136.22365778745254
total_rewards_min            -218.70594423686362
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               30.50432626903057
(Previous) Eval Time (s)     27.811487597879022
Sample Time (s)              21.65523344743997
Epoch Time (s)               79.97104731434956
Total Train Time (s)         331.9024976002984
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:30.825816 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Epoch Duration: 80.31020545959473
2020-01-11 09:36:30.826020 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6630057
Z variance train             0.044580724
KL Divergence                7.3903823
KL Loss                      0.7390382
QF Loss                      33.999825
VF Loss                      8.407857
Policy Loss                  -59.162487
Q Predictions Mean           55.42431
Q Predictions Std            15.97362
Q Predictions Max            110.08674
Q Predictions Min            -9.916785
V Predictions Mean           58.90364
V Predictions Std            15.103675
V Predictions Max            107.87996
V Predictions Min            0.15744306
Log Pis Mean                 -2.9543755
Log Pis Std                  1.7350848
Log Pis Max                  3.798399
Log Pis Min                  -7.824932
Policy mu Mean               0.018923905
Policy mu Std                0.51861316
Policy mu Max                1.8961312
Policy mu Min                -1.7239045
Policy log std Mean          -0.2119714
Policy log std Std           0.10100964
Policy log std Max           -0.06413683
Policy log std Min           -0.5824467
Z mean eval                  0.8020009
Z variance eval              0.050723605
total_rewards                [-153.02118313 -166.25615525 -224.9905118  -157.353563   -151.70931495
 -151.67136606 -145.34570543 -173.69564171 -183.47780554 -108.58247541]
total_rewards_mean           -161.61037222773217
total_rewards_std            28.333849668781042
total_rewards_max            -108.58247540695703
total_rewards_min            -224.99051180276723
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.629740813281387
(Previous) Eval Time (s)     28.150364140048623
Sample Time (s)              22.358004365116358
Epoch Time (s)               81.13810931844637
Total Train Time (s)         412.80799443414435
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:51.731560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Epoch Duration: 80.9054012298584
2020-01-11 09:37:51.731743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8057186
Z variance train             0.04912064
KL Divergence                8.044588
KL Loss                      0.8044588
QF Loss                      41.17598
VF Loss                      11.064675
Policy Loss                  -73.76578
Q Predictions Mean           69.34883
Q Predictions Std            17.089077
Q Predictions Max            119.19427
Q Predictions Min            9.302284
V Predictions Mean           71.62541
V Predictions Std            16.807451
V Predictions Max            118.83016
V Predictions Min            8.948689
Log Pis Mean                 -3.061572
Log Pis Std                  1.7076039
Log Pis Max                  3.2548497
Log Pis Min                  -7.445352
Policy mu Mean               -0.008753528
Policy mu Std                0.49865893
Policy mu Max                1.8039142
Policy mu Min                -1.9925624
Policy log std Mean          -0.20137449
Policy log std Std           0.103393145
Policy log std Max           -0.056216855
Policy log std Min           -0.6666055
Z mean eval                  0.901347
Z variance eval              0.051752865
total_rewards                [-158.12344484 -112.1703421  -189.88269211 -158.47393257 -193.03128145
 -177.54146635 -158.08879611 -139.09107738 -150.04927092 -189.59665954]
total_rewards_mean           -162.60489633579056
total_rewards_std            24.358223582763216
total_rewards_max            -112.17034209850152
total_rewards_min            -193.03128145128008
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               30.80589438881725
(Previous) Eval Time (s)     27.917344293091446
Sample Time (s)              23.297137051355094
Epoch Time (s)               82.02037573326379
Total Train Time (s)         495.4503342662938
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:14.374535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Epoch Duration: 82.64265465736389
2020-01-11 09:39:14.374689 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9027621
Z variance train             0.051680595
KL Divergence                8.843341
KL Loss                      0.8843341
QF Loss                      33.450153
VF Loss                      6.4520445
Policy Loss                  -85.952385
Q Predictions Mean           81.73154
Q Predictions Std            19.306187
Q Predictions Max            164.27942
Q Predictions Min            19.26034
V Predictions Mean           85.901886
V Predictions Std            19.529678
V Predictions Max            167.90323
V Predictions Min            39.925488
Log Pis Mean                 -3.1801076
Log Pis Std                  1.6333816
Log Pis Max                  3.4466276
Log Pis Min                  -6.481405
Policy mu Mean               -0.012619029
Policy mu Std                0.46316916
Policy mu Max                1.8580676
Policy mu Min                -1.928293
Policy log std Mean          -0.20114447
Policy log std Std           0.09241416
Policy log std Max           0.0064579993
Policy log std Min           -0.696
Z mean eval                  0.9766189
Z variance eval              0.04702075
total_rewards                [-149.07605836 -145.53239557 -146.88562668 -148.95878947  -90.98746393
 -163.70930106 -128.32661636 -171.68806721 -118.97231745  -97.44061771]
total_rewards_mean           -136.15772537889487
total_rewards_std            25.399308748104495
total_rewards_max            -90.98746392741118
total_rewards_min            -171.6880672061502
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               31.502125311177224
(Previous) Eval Time (s)     28.539308989886194
Sample Time (s)              22.301208697259426
Epoch Time (s)               82.34264299832284
Total Train Time (s)         576.8459163047373
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:35.772669 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Epoch Duration: 81.39785718917847
2020-01-11 09:40:35.772861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97602445
Z variance train             0.04694254
KL Divergence                9.758129
KL Loss                      0.9758129
QF Loss                      57.943726
VF Loss                      18.13096
Policy Loss                  -98.24181
Q Predictions Mean           96.45314
Q Predictions Std            24.753475
Q Predictions Max            164.3506
Q Predictions Min            41.61074
V Predictions Mean           100.26493
V Predictions Std            24.65675
V Predictions Max            177.36543
V Predictions Min            53.839314
Log Pis Mean                 -3.0864115
Log Pis Std                  1.4867457
Log Pis Max                  2.2095249
Log Pis Min                  -7.0574064
Policy mu Mean               0.048770864
Policy mu Std                0.4794033
Policy mu Max                1.809677
Policy mu Min                -1.9506223
Policy log std Mean          -0.20490937
Policy log std Std           0.083888486
Policy log std Max           0.12673739
Policy log std Min           -0.6467075
Z mean eval                  1.0186815
Z variance eval              0.050217815
total_rewards                [ -44.41206089  -79.48092391  -70.81271431 -146.84353258 -114.38220065
  -84.89470599 -117.734346   -131.61554423 -144.30347488  -83.26479511]
total_rewards_mean           -101.77442985578094
total_rewards_std            32.431021986847945
total_rewards_max            -44.41206089256293
total_rewards_min            -146.8435325752307
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               31.23419266194105
(Previous) Eval Time (s)     27.594204633962363
Sample Time (s)              23.25204490032047
Epoch Time (s)               82.08044219622388
Total Train Time (s)         658.0619021113962
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:56.989240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Epoch Duration: 81.21623992919922
2020-01-11 09:41:56.989439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0185368
Z variance train             0.050598264
KL Divergence                10.043104
KL Loss                      1.0043105
QF Loss                      41.45702
VF Loss                      12.81398
Policy Loss                  -111.64321
Q Predictions Mean           106.722916
Q Predictions Std            27.16031
Q Predictions Max            193.7343
Q Predictions Min            70.06034
V Predictions Mean           109.72436
V Predictions Std            25.983679
V Predictions Max            195.03882
V Predictions Min            75.16518
Log Pis Mean                 -3.1263309
Log Pis Std                  1.5191318
Log Pis Max                  2.7373748
Log Pis Min                  -7.1388397
Policy mu Mean               -0.030586729
Policy mu Std                0.4794564
Policy mu Max                1.5562617
Policy mu Min                -2.002719
Policy log std Mean          -0.21957035
Policy log std Std           0.09361458
Policy log std Max           0.09777486
Policy log std Min           -0.72312665
Z mean eval                  1.0942835
Z variance eval              0.04344431
total_rewards                [-56.27239054   1.69540573   5.72586809 -61.7749005  -29.92085982
 -32.97786786   5.04803372 -28.97104048 -51.09173236   4.40024093]
total_rewards_mean           -24.413924308035945
total_rewards_std            25.564256140392047
total_rewards_max            5.725868093499321
total_rewards_min            -61.77490049563736
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               31.158348460216075
(Previous) Eval Time (s)     26.729710310697556
Sample Time (s)              22.90138601604849
Epoch Time (s)               80.78944478696212
Total Train Time (s)         740.0623128400184
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:18.990441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Epoch Duration: 82.00086569786072
2020-01-11 09:43:18.990619 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.09183
Z variance train             0.043615095
KL Divergence                11.392872
KL Loss                      1.1392872
QF Loss                      32.58496
VF Loss                      17.83353
Policy Loss                  -122.612335
Q Predictions Mean           119.35448
Q Predictions Std            30.67128
Q Predictions Max            216.82132
Q Predictions Min            75.554535
V Predictions Mean           125.10418
V Predictions Std            31.594719
V Predictions Max            229.34958
V Predictions Min            84.95755
Log Pis Mean                 -3.2488508
Log Pis Std                  1.474577
Log Pis Max                  2.0143466
Log Pis Min                  -7.5491924
Policy mu Mean               -0.005070189
Policy mu Std                0.47742093
Policy mu Max                1.8484424
Policy mu Min                -1.8989244
Policy log std Mean          -0.21700753
Policy log std Std           0.08917145
Policy log std Max           0.03202007
Policy log std Min           -0.7190094
Z mean eval                  1.1381837
Z variance eval              0.04430213
total_rewards                [ 20.56950252  14.02535825  73.89255714  91.3083509   92.53113151
  82.08657403   4.39718752 149.59806207  73.19182402  66.12986567]
total_rewards_mean           66.77304136287702
total_rewards_std            41.545256201266014
total_rewards_max            149.59806206599572
total_rewards_min            4.397187516308273
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               30.566280148923397
(Previous) Eval Time (s)     27.9408347918652
Sample Time (s)              23.24390358151868
Epoch Time (s)               81.75101852230728
Total Train Time (s)         821.5306851188652
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:40.460055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Epoch Duration: 81.46929216384888
2020-01-11 09:44:40.460260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.133028
Z variance train             0.044331484
KL Divergence                12.234659
KL Loss                      1.2234659
QF Loss                      35.513264
VF Loss                      19.547712
Policy Loss                  -128.97498
Q Predictions Mean           126.09135
Q Predictions Std            32.016544
Q Predictions Max            244.68954
Q Predictions Min            86.734436
V Predictions Mean           132.01956
V Predictions Std            32.9003
V Predictions Max            256.5565
V Predictions Min            95.96737
Log Pis Mean                 -3.0672739
Log Pis Std                  1.683093
Log Pis Max                  5.0131574
Log Pis Min                  -7.2425747
Policy mu Mean               -0.011444359
Policy mu Std                0.50485533
Policy mu Max                1.7981929
Policy mu Min                -2.1223986
Policy log std Mean          -0.22838606
Policy log std Std           0.09285361
Policy log std Max           0.020523667
Policy log std Min           -0.7683546
Z mean eval                  1.1322503
Z variance eval              0.039528586
total_rewards                [ 33.5665265  122.36252509 193.16586231 135.33365709 153.98854041
 171.82841966  57.1803142  101.56130533 131.69781382  78.15365863]
total_rewards_mean           117.88386230365184
total_rewards_std            47.99538561943817
total_rewards_max            193.16586230634329
total_rewards_min            33.56652649890937
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               31.3660002136603
(Previous) Eval Time (s)     27.65877843508497
Sample Time (s)              22.83519466686994
Epoch Time (s)               81.8599733156152
Total Train Time (s)         903.9868268193677
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:02.917538 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Epoch Duration: 82.45713329315186
2020-01-11 09:46:02.917726 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1347691
Z variance train             0.03951291
KL Divergence                12.276606
KL Loss                      1.2276605
QF Loss                      33.68023
VF Loss                      10.375688
Policy Loss                  -147.69983
Q Predictions Mean           142.5132
Q Predictions Std            39.87548
Q Predictions Max            279.19415
Q Predictions Min            98.349144
V Predictions Mean           146.49722
V Predictions Std            39.639725
V Predictions Max            283.80582
V Predictions Min            103.64554
Log Pis Mean                 -3.0778902
Log Pis Std                  1.5110328
Log Pis Max                  2.0815492
Log Pis Min                  -8.04791
Policy mu Mean               -0.020445859
Policy mu Std                0.47572753
Policy mu Max                1.6900885
Policy mu Min                -1.4956285
Policy log std Mean          -0.23273455
Policy log std Std           0.09489862
Policy log std Max           0.07173778
Policy log std Min           -0.7228459
Z mean eval                  1.1641713
Z variance eval              0.03627351
total_rewards                [109.88897122 105.43027799 230.13187946 255.41306564 141.23434957
 183.73054183 190.73140345 158.55002862 174.90547836 193.85448763]
total_rewards_mean           174.38704837737822
total_rewards_std            45.46574668063686
total_rewards_max            255.4130656408421
total_rewards_min            105.43027798734101
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               30.954024689737707
(Previous) Eval Time (s)     28.25562819512561
Sample Time (s)              23.060216513928026
Epoch Time (s)               82.26986939879134
Total Train Time (s)         985.7231395915151
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:24.655263 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Epoch Duration: 81.73738884925842
2020-01-11 09:47:24.655468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1616275
Z variance train             0.036166646
KL Divergence                12.779986
KL Loss                      1.2779987
QF Loss                      43.357536
VF Loss                      8.479563
Policy Loss                  -156.5703
Q Predictions Mean           152.84154
Q Predictions Std            42.583286
Q Predictions Max            314.51566
Q Predictions Min            106.26481
V Predictions Mean           156.96124
V Predictions Std            42.01075
V Predictions Max            309.15826
V Predictions Min            110.86297
Log Pis Mean                 -2.970049
Log Pis Std                  1.5612094
Log Pis Max                  2.2961462
Log Pis Min                  -6.757117
Policy mu Mean               -0.058495235
Policy mu Std                0.48692524
Policy mu Max                1.6990263
Policy mu Min                -1.5769061
Policy log std Mean          -0.24607833
Policy log std Std           0.1010238
Policy log std Max           0.036857665
Policy log std Min           -0.7095067
Z mean eval                  1.1796161
Z variance eval              0.035937134
total_rewards                [313.04626655 270.02617913 217.76333964 390.89539388 198.41489171
 172.97877122 310.36162047 346.27241507 279.10284536 197.11646193]
total_rewards_mean           269.5978184967797
total_rewards_std            68.24565142332685
total_rewards_max            390.89539387911736
total_rewards_min            172.9787712181966
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.73579427599907
(Previous) Eval Time (s)     27.722824529279023
Sample Time (s)              23.074334785807878
Epoch Time (s)               81.53295359108597
Total Train Time (s)         1066.883723301813
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:45.816829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Epoch Duration: 81.16121053695679
2020-01-11 09:48:45.817057 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1805618
Z variance train             0.035982534
KL Divergence                12.948805
KL Loss                      1.2948805
QF Loss                      33.65877
VF Loss                      10.2216835
Policy Loss                  -159.26308
Q Predictions Mean           155.32071
Q Predictions Std            41.23714
Q Predictions Max            319.36438
Q Predictions Min            111.01356
V Predictions Mean           158.66278
V Predictions Std            40.30182
V Predictions Max            317.04443
V Predictions Min            118.16551
Log Pis Mean                 -3.0218148
Log Pis Std                  1.5203948
Log Pis Max                  4.1830196
Log Pis Min                  -6.6819253
Policy mu Mean               0.045301702
Policy mu Std                0.48875883
Policy mu Max                1.8024282
Policy mu Min                -1.9853652
Policy log std Mean          -0.23462623
Policy log std Std           0.10225036
Policy log std Max           0.14872093
Policy log std Min           -0.71061534
Z mean eval                  1.1844629
Z variance eval              0.04272435
total_rewards                [513.91443674 445.07862697 418.89370057 276.35928426 397.46738212
 397.16801522 306.34192605 372.31540449 397.6663129  276.4861728 ]
total_rewards_mean           380.1691262136316
total_rewards_std            71.78701972184412
total_rewards_max            513.9144367449906
total_rewards_min            276.3592842630214
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               30.616104275919497
(Previous) Eval Time (s)     27.35073783993721
Sample Time (s)              22.226598078384995
Epoch Time (s)               80.1934401942417
Total Train Time (s)         1148.1272029485554
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:07.061324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Epoch Duration: 81.24409055709839
2020-01-11 09:50:07.061515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1838614
Z variance train             0.042702354
KL Divergence                13.127537
KL Loss                      1.3127537
QF Loss                      35.101772
VF Loss                      12.881174
Policy Loss                  -173.2161
Q Predictions Mean           169.15393
Q Predictions Std            48.646175
Q Predictions Max            355.24738
Q Predictions Min            115.96021
V Predictions Mean           172.30122
V Predictions Std            48.912655
V Predictions Max            347.97458
V Predictions Min            121.21125
Log Pis Mean                 -2.7489102
Log Pis Std                  1.5877421
Log Pis Max                  2.3705928
Log Pis Min                  -7.446942
Policy mu Mean               0.021554159
Policy mu Std                0.5356501
Policy mu Max                1.9423994
Policy mu Min                -1.6323805
Policy log std Mean          -0.25923833
Policy log std Std           0.12519392
Policy log std Max           0.11545859
Policy log std Min           -0.91879785
Z mean eval                  1.1798432
Z variance eval              0.033920567
total_rewards                [1080.10432338 1318.944368    350.92123176  419.75815047  840.20825756
  479.94070331 1275.34411813  405.07643646  664.64394018  794.60671968]
total_rewards_mean           762.9548248935638
total_rewards_std            344.18243748662786
total_rewards_max            1318.9443680042398
total_rewards_min            350.9212317618292
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               31.174784757662565
(Previous) Eval Time (s)     28.401082387194037
Sample Time (s)              22.178720062598586
Epoch Time (s)               81.75458720745519
Total Train Time (s)         1229.0617710277438
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:27.997070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Epoch Duration: 80.93541383743286
2020-01-11 09:51:27.997258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1786008
Z variance train             0.033883102
KL Divergence                13.491608
KL Loss                      1.3491608
QF Loss                      41.049576
VF Loss                      13.280671
Policy Loss                  -203.02661
Q Predictions Mean           199.25887
Q Predictions Std            65.033745
Q Predictions Max            376.96426
Q Predictions Min            127.3021
V Predictions Mean           201.32588
V Predictions Std            64.84946
V Predictions Max            374.60956
V Predictions Min            131.13881
Log Pis Mean                 -2.715607
Log Pis Std                  1.6946076
Log Pis Max                  4.4224405
Log Pis Min                  -6.8258114
Policy mu Mean               0.016896686
Policy mu Std                0.5880427
Policy mu Max                2.0395164
Policy mu Min                -2.0384872
Policy log std Mean          -0.27519205
Policy log std Std           0.1221252
Policy log std Max           0.049510993
Policy log std Min           -0.8148135
Z mean eval                  1.2357035
Z variance eval              0.03492287
total_rewards                [1821.02729056  701.50676868 1519.87409679 1234.50205444 1801.67373143
 1536.34244705 1137.5319286  1494.85745685 1822.82791939  624.70914657]
total_rewards_mean           1369.4852840358367
total_rewards_std            416.5672209385302
total_rewards_max            1822.8279193909525
total_rewards_min            624.7091465665416
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.072036435827613
(Previous) Eval Time (s)     27.581547719892114
Sample Time (s)              22.41868360200897
Epoch Time (s)               81.0722677577287
Total Train Time (s)         1308.8397087650374
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:47.776933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Epoch Duration: 79.77953886985779
2020-01-11 09:52:47.777110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2368205
Z variance train             0.03492842
KL Divergence                13.544209
KL Loss                      1.3544209
QF Loss                      43.87442
VF Loss                      15.074235
Policy Loss                  -205.66624
Q Predictions Mean           201.05676
Q Predictions Std            72.37625
Q Predictions Max            408.06833
Q Predictions Min            134.45547
V Predictions Mean           206.97675
V Predictions Std            73.79414
V Predictions Max            415.86432
V Predictions Min            139.20882
Log Pis Mean                 -2.408657
Log Pis Std                  2.077685
Log Pis Max                  5.4321384
Log Pis Min                  -7.7204423
Policy mu Mean               0.024089614
Policy mu Std                0.6172652
Policy mu Max                2.3932045
Policy mu Min                -1.7264677
Policy log std Mean          -0.27551207
Policy log std Std           0.13703531
Policy log std Max           0.10670206
Policy log std Min           -1.0834877
Z mean eval                  1.2656448
Z variance eval              0.031946324
total_rewards                [2055.93768758 1955.13873017 2029.61739805 2191.98630611  926.14471931
 2130.19329615 2123.3880868  2106.1428148  2109.62418764 1248.24340049]
total_rewards_mean           1887.6416627096278
total_rewards_std            411.14417831085075
total_rewards_max            2191.9863061120595
total_rewards_min            926.1447193084119
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               31.14617990097031
(Previous) Eval Time (s)     26.28848956199363
Sample Time (s)              22.552295421250165
Epoch Time (s)               79.9869648842141
Total Train Time (s)         1389.9355632211082
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:08.873401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Epoch Duration: 81.09614562988281
2020-01-11 09:54:08.873613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2692006
Z variance train             0.03188368
KL Divergence                14.859533
KL Loss                      1.4859533
QF Loss                      44.182533
VF Loss                      20.94289
Policy Loss                  -235.49886
Q Predictions Mean           230.97327
Q Predictions Std            90.757835
Q Predictions Max            457.3693
Q Predictions Min            143.67831
V Predictions Mean           233.48508
V Predictions Std            88.46681
V Predictions Max            452.8161
V Predictions Min            146.75853
Log Pis Mean                 -1.9479457
Log Pis Std                  2.3873606
Log Pis Max                  5.521472
Log Pis Min                  -7.4464626
Policy mu Mean               0.0320873
Policy mu Std                0.6907971
Policy mu Max                2.0358553
Policy mu Min                -2.0057642
Policy log std Mean          -0.311577
Policy log std Std           0.16038263
Policy log std Max           -0.038918905
Policy log std Min           -1.0441618
Z mean eval                  1.3201697
Z variance eval              0.026469907
total_rewards                [2140.91034703 2172.5857636  2253.58421676 2185.12443549 2240.48129377
 2181.18646232 2167.10508605 2042.93949895  612.3757868  2342.97468337]
total_rewards_mean           2033.926757413198
total_rewards_std            479.6110530678901
total_rewards_max            2342.9746833714867
total_rewards_min            612.375786797576
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.007586885243654
(Previous) Eval Time (s)     27.39729680912569
Sample Time (s)              23.08671848429367
Epoch Time (s)               81.49160217866302
Total Train Time (s)         1472.7163184694946
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:31.654614 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Epoch Duration: 82.78083848953247
2020-01-11 09:55:31.654773 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170698
Z variance train             0.02650646
KL Divergence                15.612611
KL Loss                      1.561261
QF Loss                      76.17983
VF Loss                      17.641594
Policy Loss                  -283.33002
Q Predictions Mean           279.27545
Q Predictions Std            116.150154
Q Predictions Max            510.45593
Q Predictions Min            151.87903
V Predictions Mean           284.24774
V Predictions Std            115.18494
V Predictions Max            515.0004
V Predictions Min            161.26428
Log Pis Mean                 -1.9163857
Log Pis Std                  2.3108473
Log Pis Max                  6.192054
Log Pis Min                  -6.736388
Policy mu Mean               -0.0199283
Policy mu Std                0.69060296
Policy mu Max                1.940068
Policy mu Min                -2.324714
Policy log std Mean          -0.33289167
Policy log std Std           0.16259013
Policy log std Max           -0.0580066
Policy log std Min           -1.0386759
Z mean eval                  1.3549879
Z variance eval              0.028707916
total_rewards                [ 881.28183339 2614.60223307 1025.92089835 2494.0007342  2393.80208523
 2610.69360139 2480.51524847  997.25732629 2631.61443176 2614.12455688]
total_rewards_mean           2074.381294901762
total_rewards_std            728.5127030549461
total_rewards_max            2631.614431759717
total_rewards_min            881.2818333911125
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.919151170179248
(Previous) Eval Time (s)     28.686214711982757
Sample Time (s)              22.387102692387998
Epoch Time (s)               81.99246857455
Total Train Time (s)         1554.1737942122854
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:53.113642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Epoch Duration: 81.45872473716736
2020-01-11 09:56:53.113833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3551931
Z variance train             0.028780153
KL Divergence                15.7446995
KL Loss                      1.5744699
QF Loss                      69.863594
VF Loss                      28.553965
Policy Loss                  -289.918
Q Predictions Mean           285.71964
Q Predictions Std            120.274284
Q Predictions Max            557.13794
Q Predictions Min            160.3371
V Predictions Mean           291.44238
V Predictions Std            119.49723
V Predictions Max            564.1017
V Predictions Min            167.31177
Log Pis Mean                 -1.5050884
Log Pis Std                  2.4119902
Log Pis Max                  7.00255
Log Pis Min                  -6.3680797
Policy mu Mean               0.061992038
Policy mu Std                0.7387179
Policy mu Max                2.1461446
Policy mu Min                -2.1810036
Policy log std Mean          -0.33011582
Policy log std Std           0.16480318
Policy log std Max           -0.024815135
Policy log std Min           -1.0989262
Z mean eval                  1.3994142
Z variance eval              0.022932207
total_rewards                [2775.66955567 2773.10287566 1968.3092764  2920.4988994  2059.98008743
 2727.31423354 1220.15871892 2717.63646318 2735.11275622 2708.96805601]
total_rewards_mean           2460.675092242788
total_rewards_std            512.2717078391642
total_rewards_max            2920.498899395399
total_rewards_min            1220.1587189215456
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               31.250473340041935
(Previous) Eval Time (s)     28.152134232223034
Sample Time (s)              22.786119532305747
Epoch Time (s)               82.18872710457072
Total Train Time (s)         1636.1405198709108
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:15.084879 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Epoch Duration: 81.97090816497803
2020-01-11 09:58:15.085152 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3987851
Z variance train             0.02287886
KL Divergence                16.299252
KL Loss                      1.6299251
QF Loss                      75.50303
VF Loss                      30.106155
Policy Loss                  -308.59656
Q Predictions Mean           306.16443
Q Predictions Std            141.7257
Q Predictions Max            606.37006
Q Predictions Min            158.54907
V Predictions Mean           311.66693
V Predictions Std            140.27504
V Predictions Max            613.7364
V Predictions Min            166.7363
Log Pis Mean                 -1.4629819
Log Pis Std                  2.686466
Log Pis Max                  8.187489
Log Pis Min                  -9.898722
Policy mu Mean               0.068701655
Policy mu Std                0.76305723
Policy mu Max                2.1524034
Policy mu Min                -2.0959938
Policy log std Mean          -0.34218946
Policy log std Std           0.17343818
Policy log std Max           -0.039045908
Policy log std Min           -1.1252127
Z mean eval                  1.4300785
Z variance eval              0.030331725
total_rewards                [2790.06859174 2803.74423108 1176.69020632  725.52845988 2805.31894118
 2841.38621487 2700.32560025 2948.85036194 2755.94171939 2811.86998389]
total_rewards_mean           2435.972431053963
total_rewards_std            751.6271252667807
total_rewards_max            2948.8503619394724
total_rewards_min            725.5284598794142
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               32.64294188283384
(Previous) Eval Time (s)     27.93399286363274
Sample Time (s)              22.26885146368295
Epoch Time (s)               82.84578621014953
Total Train Time (s)         1719.5642258808948
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:38.506868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Epoch Duration: 83.42148447036743
2020-01-11 09:59:38.507107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4298657
Z variance train             0.03043807
KL Divergence                15.579622
KL Loss                      1.5579623
QF Loss                      89.93002
VF Loss                      48.363453
Policy Loss                  -362.60373
Q Predictions Mean           358.3661
Q Predictions Std            156.83704
Q Predictions Max            669.961
Q Predictions Min            172.89629
V Predictions Mean           359.66238
V Predictions Std            153.92207
V Predictions Max            644.98694
V Predictions Min            179.02591
Log Pis Mean                 -1.269341
Log Pis Std                  2.7269034
Log Pis Max                  7.0305924
Log Pis Min                  -8.673935
Policy mu Mean               0.07143982
Policy mu Std                0.80241597
Policy mu Max                2.2005517
Policy mu Min                -2.4863932
Policy log std Mean          -0.37559056
Policy log std Std           0.17814064
Policy log std Max           -0.05009433
Policy log std Min           -1.0794735
Z mean eval                  1.4743454
Z variance eval              0.032330833
total_rewards                [2946.161615   3103.62101661 3009.21172601 2941.98683816 2945.60401413
 2873.05083868 3030.74439769 2931.79228848 2940.40434882 3090.60319312]
total_rewards_mean           2981.3180276704197
total_rewards_std            70.73133089782851
total_rewards_max            3103.6210166058113
total_rewards_min            2873.050838680747
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               33.13077902700752
(Previous) Eval Time (s)     28.509332423098385
Sample Time (s)              23.53684837091714
Epoch Time (s)               85.17695982102305
Total Train Time (s)         1805.2259539235383
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:04.170224 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Epoch Duration: 85.66290950775146
2020-01-11 10:01:04.170464 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4731365
Z variance train             0.03265255
KL Divergence                15.984253
KL Loss                      1.5984253
QF Loss                      72.32254
VF Loss                      48.85364
Policy Loss                  -371.4996
Q Predictions Mean           369.98425
Q Predictions Std            175.52034
Q Predictions Max            727.9038
Q Predictions Min            183.38359
V Predictions Mean           376.2398
V Predictions Std            176.53116
V Predictions Max            723.2956
V Predictions Min            189.74956
Log Pis Mean                 -1.2138946
Log Pis Std                  2.9987116
Log Pis Max                  8.656765
Log Pis Min                  -7.5642166
Policy mu Mean               0.085791595
Policy mu Std                0.7878126
Policy mu Max                2.7732449
Policy mu Min                -2.2590654
Policy log std Mean          -0.3838047
Policy log std Std           0.19350566
Policy log std Max           -0.07561052
Policy log std Min           -1.1758821
Z mean eval                  1.5196606
Z variance eval              0.026429653
total_rewards                [2927.40869478 3057.57765496 3147.15026365 3189.55025218 2806.54301728
 2104.50023151 1850.04292095 3017.68996436 3250.69188759 2932.6555651 ]
total_rewards_mean           2828.381045234907
total_rewards_std            447.3340898288127
total_rewards_max            3250.691887589831
total_rewards_min            1850.0429209526621
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               33.67555905133486
(Previous) Eval Time (s)     28.994902901817113
Sample Time (s)              23.040207132697105
Epoch Time (s)               85.71066908584908
Total Train Time (s)         1890.3942754934542
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:29.340285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Epoch Duration: 85.16963386535645
2020-01-11 10:02:29.340606 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5178933
Z variance train             0.02650084
KL Divergence                16.8987
KL Loss                      1.6898701
QF Loss                      139.18611
VF Loss                      30.888386
Policy Loss                  -445.29916
Q Predictions Mean           437.4017
Q Predictions Std            193.56242
Q Predictions Max            752.95544
Q Predictions Min            190.37123
V Predictions Mean           447.3595
V Predictions Std            194.86687
V Predictions Max            760.57416
V Predictions Min            196.65929
Log Pis Mean                 -0.8625451
Log Pis Std                  2.8413756
Log Pis Max                  6.8236313
Log Pis Min                  -7.6027412
Policy mu Mean               0.055795997
Policy mu Std                0.8558265
Policy mu Max                2.5082383
Policy mu Min                -2.2316067
Policy log std Mean          -0.4000986
Policy log std Std           0.18913463
Policy log std Max           -0.018077075
Policy log std Min           -1.1232285
Z mean eval                  1.5382296
Z variance eval              0.043498676
total_rewards                [3119.71499602 3259.79939536 3195.88615725 3197.57831615 3296.82222448
 3126.2025427  1761.09795542 3170.0976506  3334.47897664 3022.89900382]
total_rewards_mean           3048.457721844851
total_rewards_std            437.72103300965426
total_rewards_max            3334.478976639122
total_rewards_min            1761.0979554156593
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               32.47954228706658
(Previous) Eval Time (s)     28.45322960615158
Sample Time (s)              23.275572823826224
Epoch Time (s)               84.20834471704438
Total Train Time (s)         1974.9011042262428
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:53.847943 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Epoch Duration: 84.50712561607361
2020-01-11 10:03:53.848132 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.538862
Z variance train             0.043508217
KL Divergence                15.297827
KL Loss                      1.5297827
QF Loss                      107.296814
VF Loss                      42.32123
Policy Loss                  -470.53595
Q Predictions Mean           466.27853
Q Predictions Std            209.80774
Q Predictions Max            836.1322
Q Predictions Min            201.60175
V Predictions Mean           470.83176
V Predictions Std            208.58983
V Predictions Max            842.0093
V Predictions Min            204.3878
Log Pis Mean                 -0.60493946
Log Pis Std                  2.928569
Log Pis Max                  7.4657974
Log Pis Min                  -7.850007
Policy mu Mean               0.12478397
Policy mu Std                0.85901165
Policy mu Max                2.36241
Policy mu Min                -2.08647
Policy log std Mean          -0.41054782
Policy log std Std           0.19582534
Policy log std Max           -0.027548462
Policy log std Min           -1.2293991
Z mean eval                  1.6017148
Z variance eval              0.038147435
total_rewards                [3225.26231821 3175.84733054 3231.04830286 3230.20429382 3254.14164909
 3220.41640235 3272.39114732 3230.96672965 3331.72168981 3121.12072564]
total_rewards_mean           3229.3120589298273
total_rewards_std            52.56041509458865
total_rewards_max            3331.7216898097417
total_rewards_min            3121.120725642358
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               33.56406134273857
(Previous) Eval Time (s)     28.75166823901236
Sample Time (s)              22.968437008094043
Epoch Time (s)               85.28416658984497
Total Train Time (s)         2061.003243458923
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:19.952128 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Epoch Duration: 86.10382771492004
2020-01-11 10:05:19.952451 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6009958
Z variance train             0.03813895
KL Divergence                15.8843775
KL Loss                      1.5884378
QF Loss                      101.90107
VF Loss                      34.421326
Policy Loss                  -479.44955
Q Predictions Mean           476.30164
Q Predictions Std            230.4271
Q Predictions Max            878.4982
Q Predictions Min            204.78773
V Predictions Mean           481.58096
V Predictions Std            229.94565
V Predictions Max            870.4342
V Predictions Min            207.95317
Log Pis Mean                 -0.5105235
Log Pis Std                  3.0908217
Log Pis Max                  8.409803
Log Pis Min                  -7.072196
Policy mu Mean               0.06995011
Policy mu Std                0.873976
Policy mu Max                2.299274
Policy mu Min                -2.5432096
Policy log std Mean          -0.41862914
Policy log std Std           0.21255104
Policy log std Max           -0.041984946
Policy log std Min           -1.3219897
Z mean eval                  1.6756713
Z variance eval              0.026377996
total_rewards                [3256.80054167 3378.74960159 2228.34692517 3410.2457355  3551.80671901
 3316.79798904 3515.9079766  3587.12709579 3442.19820997 3461.87945687]
total_rewards_mean           3314.9860251222076
total_rewards_std            374.91180664099716
total_rewards_max            3587.127095788458
total_rewards_min            2228.3469251742454
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               32.52485264604911
(Previous) Eval Time (s)     29.570984139107168
Sample Time (s)              22.677499408833683
Epoch Time (s)               84.77333619398996
Total Train Time (s)         2143.6060259547085
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:42.555460 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Epoch Duration: 82.60279369354248
2020-01-11 10:06:42.555639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6768005
Z variance train             0.02645328
KL Divergence                17.421984
KL Loss                      1.7421983
QF Loss                      108.68051
VF Loss                      45.463932
Policy Loss                  -525.11115
Q Predictions Mean           518.7407
Q Predictions Std            244.03227
Q Predictions Max            901.0218
Q Predictions Min            211.43459
V Predictions Mean           522.2763
V Predictions Std            243.26256
V Predictions Max            888.92633
V Predictions Min            219.65639
Log Pis Mean                 -0.49691117
Log Pis Std                  3.1934493
Log Pis Max                  7.10886
Log Pis Min                  -8.308132
Policy mu Mean               0.11413791
Policy mu Std                0.9046226
Policy mu Max                2.4826894
Policy mu Min                -2.8455997
Policy log std Mean          -0.42471138
Policy log std Std           0.21628374
Policy log std Max           0.059777007
Policy log std Min           -1.4481275
Z mean eval                  1.7323917
Z variance eval              0.021093944
total_rewards                [ 587.88087872 3643.90123568 3693.46157817 3456.28085848 3391.99685875
 3496.84858481 3429.96975902 3524.44296196 3443.19442827 3301.43947399]
total_rewards_mean           3196.941661784772
total_rewards_std            876.4627763093397
total_rewards_max            3693.461578167049
total_rewards_min            587.8808787182994
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               32.815090311691165
(Previous) Eval Time (s)     27.40008606389165
Sample Time (s)              23.01055916491896
Epoch Time (s)               83.22573554050177
Total Train Time (s)         2229.0768666104414
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:08.027976 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Epoch Duration: 85.4721908569336
2020-01-11 10:08:08.028185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7304657
Z variance train             0.021068295
KL Divergence                18.692509
KL Loss                      1.8692509
QF Loss                      128.73743
VF Loss                      38.20308
Policy Loss                  -552.62445
Q Predictions Mean           547.7346
Q Predictions Std            259.22888
Q Predictions Max            972.52313
Q Predictions Min            219.99603
V Predictions Mean           553.68915
V Predictions Std            258.22043
V Predictions Max            965.98114
V Predictions Min            224.93562
Log Pis Mean                 -0.41006547
Log Pis Std                  3.11503
Log Pis Max                  9.351208
Log Pis Min                  -6.5640807
Policy mu Mean               0.091566205
Policy mu Std                0.8975853
Policy mu Max                2.4113617
Policy mu Min                -2.46001
Policy log std Mean          -0.43226162
Policy log std Std           0.20771381
Policy log std Max           -0.022678092
Policy log std Min           -1.3974218
Z mean eval                  1.7464516
Z variance eval              0.022124996
total_rewards                [3624.6538856  3410.59195999 3483.08327611 3484.49044225 3530.76160805
 3599.57289556 3565.16843471 3539.12845504 3573.15175312 3535.60510094]
total_rewards_mean           3534.620781138131
total_rewards_std            59.43990831909798
total_rewards_max            3624.653885598101
total_rewards_min            3410.5919599897793
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               33.833372300025076
(Previous) Eval Time (s)     29.646165372803807
Sample Time (s)              23.93695364613086
Epoch Time (s)               87.41649131895974
Total Train Time (s)         2316.230979983695
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:35.183630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Epoch Duration: 87.1552906036377
2020-01-11 10:09:35.183891 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7488823
Z variance train             0.022139642
KL Divergence                18.781567
KL Loss                      1.8781567
QF Loss                      147.2796
VF Loss                      36.620266
Policy Loss                  -591.0202
Q Predictions Mean           587.872
Q Predictions Std            272.9128
Q Predictions Max            980.7149
Q Predictions Min            229.08015
V Predictions Mean           587.86035
V Predictions Std            271.4249
V Predictions Max            979.1401
V Predictions Min            227.57732
Log Pis Mean                 -0.030872919
Log Pis Std                  3.5383313
Log Pis Max                  10.63592
Log Pis Min                  -9.051558
Policy mu Mean               0.071513735
Policy mu Std                0.96545476
Policy mu Max                2.4331594
Policy mu Min                -2.5206296
Policy log std Mean          -0.44340536
Policy log std Std           0.21780662
Policy log std Max           0.025141433
Policy log std Min           -1.4918679
Z mean eval                  1.8110771
Z variance eval              0.015109161
total_rewards                [3518.24394529 3538.41329594 3494.12662046 3418.02692999 3445.42847491
 3422.99634584 3492.53637054 3548.58153737 3461.06727053 3545.03311157]
total_rewards_mean           3488.445390241738
total_rewards_std            47.004933546974804
total_rewards_max            3548.5815373743685
total_rewards_min            3418.026929987102
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               32.71275597810745
(Previous) Eval Time (s)     29.38447932386771
Sample Time (s)              23.38550410233438
Epoch Time (s)               85.48273940430954
Total Train Time (s)         2401.1964098997414
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:00.152027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Epoch Duration: 84.96794080734253
2020-01-11 10:11:00.152350 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8121979
Z variance train             0.015128637
KL Divergence                20.748886
KL Loss                      2.0748887
QF Loss                      146.43983
VF Loss                      109.70557
Policy Loss                  -642.3956
Q Predictions Mean           632.53784
Q Predictions Std            290.73505
Q Predictions Max            1076.512
Q Predictions Min            222.21414
V Predictions Mean           633.91174
V Predictions Std            286.59183
V Predictions Max            1065.6129
V Predictions Min            223.87663
Log Pis Mean                 -0.10686302
Log Pis Std                  3.2410183
Log Pis Max                  8.875432
Log Pis Min                  -7.308128
Policy mu Mean               0.04848659
Policy mu Std                0.9127369
Policy mu Max                2.3790493
Policy mu Min                -2.5961432
Policy log std Mean          -0.44376835
Policy log std Std           0.21413638
Policy log std Max           0.07748029
Policy log std Min           -1.3711109
Z mean eval                  1.8401861
Z variance eval              0.01794907
total_rewards                [3623.96936929 3594.50135236 3765.01054227 3725.2656945  3686.68142535
 3463.59744698 3617.79519233 1679.96880924 3572.86589905 3651.41115023]
total_rewards_mean           3438.106688159192
total_rewards_std            591.4190924377835
total_rewards_max            3765.0105422683528
total_rewards_min            1679.9688092438644
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               33.78640498733148
(Previous) Eval Time (s)     28.86929231416434
Sample Time (s)              23.54719650838524
Epoch Time (s)               86.20289380988106
Total Train Time (s)         2487.9705864698626
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:26.926712 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Epoch Duration: 86.77418065071106
2020-01-11 10:12:26.926928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8398006
Z variance train             0.017942
KL Divergence                20.81009
KL Loss                      2.081009
QF Loss                      120.728745
VF Loss                      41.64657
Policy Loss                  -647.42896
Q Predictions Mean           641.0531
Q Predictions Std            296.68732
Q Predictions Max            1067.5123
Q Predictions Min            231.43747
V Predictions Mean           645.25574
V Predictions Std            293.94064
V Predictions Max            1062.1227
V Predictions Min            241.50479
Log Pis Mean                 -0.12664983
Log Pis Std                  3.4233148
Log Pis Max                  10.379229
Log Pis Min                  -7.02652
Policy mu Mean               0.089868404
Policy mu Std                0.9293665
Policy mu Max                2.4633155
Policy mu Min                -2.6430335
Policy log std Mean          -0.44893527
Policy log std Std           0.21689178
Policy log std Max           -0.015713274
Policy log std Min           -1.3272274
Z mean eval                  1.8777685
Z variance eval              0.017170548
total_rewards                [3708.2668536  3517.87909508 3636.16037642 3679.19766056 3828.54193038
 3721.84528943 3723.65480674 3688.70256514 3800.28549023 3772.54141498]
total_rewards_mean           3707.707548255699
total_rewards_std            83.76001410774504
total_rewards_max            3828.5419303791045
total_rewards_min            3517.879095076308
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.22840493079275
(Previous) Eval Time (s)     29.440172566100955
Sample Time (s)              23.16971821244806
Epoch Time (s)               83.83829570934176
Total Train Time (s)         2570.2249971553683
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:49.182478 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Epoch Duration: 82.25540161132812
2020-01-11 10:13:49.182674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8793666
Z variance train             0.017193278
KL Divergence                21.576355
KL Loss                      2.1576355
QF Loss                      137.11826
VF Loss                      33.997726
Policy Loss                  -691.6441
Q Predictions Mean           690.1566
Q Predictions Std            331.315
Q Predictions Max            1120.1852
Q Predictions Min            248.82622
V Predictions Mean           690.1187
V Predictions Std            327.3913
V Predictions Max            1117.6963
V Predictions Min            256.10886
Log Pis Mean                 -0.73449486
Log Pis Std                  3.063672
Log Pis Max                  9.348474
Log Pis Min                  -6.1808577
Policy mu Mean               0.097212255
Policy mu Std                0.8502805
Policy mu Max                2.4793155
Policy mu Min                -2.2739499
Policy log std Mean          -0.43777624
Policy log std Std           0.22781686
Policy log std Max           -0.0017333776
Policy log std Min           -1.5364562
Z mean eval                  1.9071783
Z variance eval              0.01624388
total_rewards                [3665.29945252 3886.91349322 3704.72907322 3729.9791925  3744.35345209
 3893.19202414 3760.491664   3852.91473361 3751.27407058 3839.98437297]
total_rewards_mean           3782.9131528848898
total_rewards_std            75.41431422906484
total_rewards_max            3893.1920241365174
total_rewards_min            3665.2994525151857
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.35969841014594
(Previous) Eval Time (s)     27.856947750784457
Sample Time (s)              22.845608113799244
Epoch Time (s)               82.06225427472964
Total Train Time (s)         2651.475520135835
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:10.434070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Epoch Duration: 81.25126266479492
2020-01-11 10:15:10.434244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.90476
Z variance train             0.016243717
KL Divergence                22.027493
KL Loss                      2.2027493
QF Loss                      328.57697
VF Loss                      65.946884
Policy Loss                  -727.00183
Q Predictions Mean           718.5487
Q Predictions Std            310.13074
Q Predictions Max            1116.3743
Q Predictions Min            236.84848
V Predictions Mean           730.88116
V Predictions Std            310.68066
V Predictions Max            1129.0526
V Predictions Min            245.04022
Log Pis Mean                 0.14851418
Log Pis Std                  3.4882627
Log Pis Max                  11.905404
Log Pis Min                  -9.163441
Policy mu Mean               0.071284175
Policy mu Std                0.9448283
Policy mu Max                2.659757
Policy mu Min                -2.6055253
Policy log std Mean          -0.48339257
Policy log std Std           0.24482764
Policy log std Max           -0.04086697
Policy log std Min           -1.7101657
Z mean eval                  1.9403751
Z variance eval              0.01496958
total_rewards                [3974.91709047 4007.68219731 3787.87073162 3766.40245606 3983.84932462
 3737.69876501 3808.59270405 3926.29901713 3962.1137315  4049.40519187]
total_rewards_mean           3900.483120964965
total_rewards_std            107.80831496267845
total_rewards_max            4049.4051918726245
total_rewards_min            3737.6987650090723
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.354226001072675
(Previous) Eval Time (s)     27.045585389714688
Sample Time (s)              22.745321285910904
Epoch Time (s)               81.14513267669827
Total Train Time (s)         2733.8255157768726
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:32.785548 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Epoch Duration: 82.3511643409729
2020-01-11 10:16:32.785739 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9409113
Z variance train             0.014993122
KL Divergence                22.889397
KL Loss                      2.2889397
QF Loss                      108.40101
VF Loss                      40.850517
Policy Loss                  -763.2809
Q Predictions Mean           758.7499
Q Predictions Std            335.92856
Q Predictions Max            1197.0276
Q Predictions Min            263.5823
V Predictions Mean           764.1343
V Predictions Std            336.28552
V Predictions Max            1200.9287
V Predictions Min            265.62228
Log Pis Mean                 0.21919185
Log Pis Std                  3.4577909
Log Pis Max                  15.36074
Log Pis Min                  -8.152205
Policy mu Mean               0.1522629
Policy mu Std                0.94765407
Policy mu Max                2.9142678
Policy mu Min                -2.411192
Policy log std Mean          -0.47828832
Policy log std Std           0.24390684
Policy log std Max           -0.050852835
Policy log std Min           -1.6868677
Z mean eval                  1.9485435
Z variance eval              0.021703295
total_rewards                [3752.04013712 3967.17709752 3834.03479214 3832.98832179 3798.80596356
 3847.5608693  3967.71351442 3958.24899573 3898.44745856 3614.9299917 ]
total_rewards_mean           3847.1947141840456
total_rewards_std            104.68923345356362
total_rewards_max            3967.713514417897
total_rewards_min            3614.929991703674
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.177020700648427
(Previous) Eval Time (s)     28.251252529211342
Sample Time (s)              22.593506139703095
Epoch Time (s)               82.02177936956286
Total Train Time (s)         2815.370868950151
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:54.332244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Epoch Duration: 81.54636526107788
2020-01-11 10:17:54.332440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9478829
Z variance train             0.0216609
KL Divergence                21.522484
KL Loss                      2.1522484
QF Loss                      123.83351
VF Loss                      82.66338
Policy Loss                  -760.066
Q Predictions Mean           757.7439
Q Predictions Std            359.1161
Q Predictions Max            1251.12
Q Predictions Min            253.76935
V Predictions Mean           766.40735
V Predictions Std            356.84497
V Predictions Max            1260.9072
V Predictions Min            269.12213
Log Pis Mean                 0.007882997
Log Pis Std                  3.486558
Log Pis Max                  11.322649
Log Pis Min                  -9.627664
Policy mu Mean               0.07583495
Policy mu Std                0.9324827
Policy mu Max                2.4416218
Policy mu Min                -2.3711135
Policy log std Mean          -0.48182616
Policy log std Std           0.24553402
Policy log std Max           -0.044685513
Policy log std Min           -1.7263768
Z mean eval                  1.9752792
Z variance eval              0.018091237
total_rewards                [4111.87340473 4057.3067137  3997.31360685 3869.5127553  3945.82298633
 4054.71457358 4099.42160353 4160.31674355 4010.48175588 4027.59346127]
total_rewards_mean           4033.4357604706347
total_rewards_std            80.02535115338911
total_rewards_max            4160.316743554317
total_rewards_min            3869.512755298018
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               31.32300064060837
(Previous) Eval Time (s)     27.77557635633275
Sample Time (s)              20.873764706775546
Epoch Time (s)               79.97234170371667
Total Train Time (s)         2895.498157621827
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:14.469270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Epoch Duration: 80.13666796684265
2020-01-11 10:19:14.469806 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9738508
Z variance train             0.018072994
KL Divergence                22.510391
KL Loss                      2.2510393
QF Loss                      180.54262
VF Loss                      78.8511
Policy Loss                  -833.8063
Q Predictions Mean           832.9532
Q Predictions Std            368.88608
Q Predictions Max            1279.563
Q Predictions Min            264.76996
V Predictions Mean           833.90735
V Predictions Std            368.4531
V Predictions Max            1279.9772
V Predictions Min            265.98312
Log Pis Mean                 0.47465172
Log Pis Std                  3.5525868
Log Pis Max                  10.971694
Log Pis Min                  -6.4417667
Policy mu Mean               0.021831928
Policy mu Std                0.9690475
Policy mu Max                2.7301314
Policy mu Min                -2.6212683
Policy log std Mean          -0.4811581
Policy log std Std           0.23689565
Policy log std Max           -0.038725376
Policy log std Min           -1.6664307
Z mean eval                  1.9792624
Z variance eval              0.019367019
total_rewards                [4036.96242894 4002.57641686 4105.59422135 4112.86660275 4058.9972871
 4213.21863698 4148.80280842 3971.43099708 3976.5590829  3973.71164173]
total_rewards_mean           4060.0720124106447
total_rewards_std            78.94129911683392
total_rewards_max            4213.21863698148
total_rewards_min            3971.4309970781296
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.748200244270265
(Previous) Eval Time (s)     27.93953431583941
Sample Time (s)              22.10673202201724
Epoch Time (s)               80.79446658212692
Total Train Time (s)         2976.2918414375745
Epoch                        35
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:35.256454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Epoch Duration: 80.7862377166748
2020-01-11 10:20:35.256639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9802281
Z variance train             0.019334689
KL Divergence                22.69873
KL Loss                      2.2698731
QF Loss                      176.94846
VF Loss                      64.42146
Policy Loss                  -848.0074
Q Predictions Mean           841.088
Q Predictions Std            382.28098
Q Predictions Max            1296.5256
Q Predictions Min            272.61603
V Predictions Mean           846.66406
V Predictions Std            380.4301
V Predictions Max            1298.0669
V Predictions Min            276.2732
Log Pis Mean                 -0.007447321
Log Pis Std                  3.3079772
Log Pis Max                  10.378077
Log Pis Min                  -6.1354537
Policy mu Mean               0.017157031
Policy mu Std                0.933511
Policy mu Max                2.4217062
Policy mu Min                -2.4967015
Policy log std Mean          -0.48188722
Policy log std Std           0.24573044
Policy log std Max           0.0011275262
Policy log std Min           -1.5996387
Z mean eval                  2.0062916
Z variance eval              0.017677048
total_rewards                [4024.29235209 3956.70523291 4106.39947703 4175.88926679 4216.64980534
 4118.75040051 4196.24436349 4205.66408173 3981.37906082 4080.08309547]
total_rewards_mean           4106.205713618532
total_rewards_std            89.74090711987198
total_rewards_max            4216.649805341771
total_rewards_min            3956.705232911302
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.259476360864937
(Previous) Eval Time (s)     27.931023311801255
Sample Time (s)              22.651144224684685
Epoch Time (s)               81.84164389735088
Total Train Time (s)         3057.277790784836
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:56.243144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Epoch Duration: 80.98637223243713
2020-01-11 10:21:56.243361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0046673
Z variance train             0.017643198
KL Divergence                23.185955
KL Loss                      2.3185956
QF Loss                      183.84326
VF Loss                      65.10809
Policy Loss                  -851.7425
Q Predictions Mean           845.90216
Q Predictions Std            389.0508
Q Predictions Max            1335.7449
Q Predictions Min            263.22018
V Predictions Mean           855.404
V Predictions Std            389.66666
V Predictions Max            1344.719
V Predictions Min            270.31503
Log Pis Mean                 -0.095661126
Log Pis Std                  3.4616923
Log Pis Max                  12.76536
Log Pis Min                  -6.856677
Policy mu Mean               0.07142859
Policy mu Std                0.9423389
Policy mu Max                2.501352
Policy mu Min                -2.30604
Policy log std Mean          -0.46090773
Policy log std Std           0.23270959
Policy log std Max           0.035345957
Policy log std Min           -1.3933423
Z mean eval                  2.013846
Z variance eval              0.017405102
total_rewards                [4177.7819984  4129.83696847 4146.91397364 4298.5115515  4215.03507575
 4103.30409745 4161.38258734 4302.24543809 4072.95941915 4078.14239225]
total_rewards_mean           4168.61135020351
total_rewards_std            77.84397227473646
total_rewards_max            4302.245438089036
total_rewards_min            4072.959419147781
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               31.85145627707243
(Previous) Eval Time (s)     27.075440646149218
Sample Time (s)              21.500817864201963
Epoch Time (s)               80.42771478742361
Total Train Time (s)         3138.736484156456
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:17.703430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Epoch Duration: 81.45994806289673
2020-01-11 10:23:17.703615 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0126405
Z variance train             0.017392967
KL Divergence                23.351387
KL Loss                      2.3351388
QF Loss                      231.42125
VF Loss                      52.57604
Policy Loss                  -905.81976
Q Predictions Mean           900.40784
Q Predictions Std            407.25793
Q Predictions Max            1402.3134
Q Predictions Min            272.41724
V Predictions Mean           908.5509
V Predictions Std            405.0556
V Predictions Max            1423.9669
V Predictions Min            280.26617
Log Pis Mean                 0.46162832
Log Pis Std                  3.6594849
Log Pis Max                  11.790085
Log Pis Min                  -6.7382255
Policy mu Mean               0.04119908
Policy mu Std                0.9802458
Policy mu Max                2.478971
Policy mu Min                -2.3752806
Policy log std Mean          -0.4901866
Policy log std Std           0.252759
Policy log std Max           -0.035702378
Policy log std Min           -1.8814162
Z mean eval                  2.023473
Z variance eval              0.019995693
total_rewards                [4188.65671144 4415.9649545  4407.7754186  4441.66458094 4320.01388196
 4424.10194262 4465.0843004  4415.07479688 4471.89169425 4389.57801331]
total_rewards_mean           4393.980629489235
total_rewards_std            79.41905533543586
total_rewards_max            4471.891694251296
total_rewards_min            4188.656711437787
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               31.029344724025577
(Previous) Eval Time (s)     28.107383267953992
Sample Time (s)              22.79334571538493
Epoch Time (s)               81.9300737073645
Total Train Time (s)         3221.105213801842
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:40.074137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Epoch Duration: 82.37037253379822
2020-01-11 10:24:40.074358 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236516
Z variance train             0.01996401
KL Divergence                23.072716
KL Loss                      2.3072717
QF Loss                      167.72864
VF Loss                      102.06381
Policy Loss                  -937.0148
Q Predictions Mean           936.602
Q Predictions Std            407.29858
Q Predictions Max            1395.5293
Q Predictions Min            266.954
V Predictions Mean           938.0705
V Predictions Std            403.44547
V Predictions Max            1382.4348
V Predictions Min            275.17932
Log Pis Mean                 0.7910099
Log Pis Std                  3.6843047
Log Pis Max                  10.510146
Log Pis Min                  -7.5885653
Policy mu Mean               0.0563129
Policy mu Std                1.0156212
Policy mu Max                2.6234434
Policy mu Min                -2.5435517
Policy log std Mean          -0.4961364
Policy log std Std           0.26275483
Policy log std Max           -0.013640389
Policy log std Min           -1.6974229
Z mean eval                  2.0429032
Z variance eval              0.013954902
total_rewards                [4351.4290198  4361.12377422 4466.7724219  4398.65726286 4399.84422075
 4343.84568833 4393.32183941 4385.74107443 4284.24060191 4262.07009303]
total_rewards_mean           4364.704599664143
total_rewards_std            56.30217644457159
total_rewards_max            4466.772421895949
total_rewards_min            4262.070093033316
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               31.81956434296444
(Previous) Eval Time (s)     28.547343663405627
Sample Time (s)              21.99971121083945
Epoch Time (s)               82.36661921720952
Total Train Time (s)         3303.930345137138
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:02.900526 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Epoch Duration: 82.82601261138916
2020-01-11 10:26:02.900719 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0420988
Z variance train             0.013915581
KL Divergence                24.488659
KL Loss                      2.448866
QF Loss                      373.81067
VF Loss                      75.65582
Policy Loss                  -946.5494
Q Predictions Mean           939.4425
Q Predictions Std            425.78574
Q Predictions Max            1462.3452
Q Predictions Min            269.34604
V Predictions Mean           943.54083
V Predictions Std            422.20294
V Predictions Max            1470.1844
V Predictions Min            280.62677
Log Pis Mean                 0.3869719
Log Pis Std                  3.5401373
Log Pis Max                  10.419273
Log Pis Min                  -6.801856
Policy mu Mean               0.00092670694
Policy mu Std                0.9758509
Policy mu Max                2.5289237
Policy mu Min                -2.2757843
Policy log std Mean          -0.48688698
Policy log std Std           0.25407597
Policy log std Max           -0.045001
Policy log std Min           -1.5372269
Z mean eval                  2.035019
Z variance eval              0.015154158
total_rewards                [4304.1627912  4550.19694116 4425.91323538 4535.25125089 4462.165037
 4498.31488309 4295.70876727 4462.22241687 4480.61985208 4693.62930493]
total_rewards_mean           4470.818447985714
total_rewards_std            110.25066454161379
total_rewards_max            4693.6293049274755
total_rewards_min            4295.708767268059
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               31.738999634981155
(Previous) Eval Time (s)     29.00643179891631
Sample Time (s)              22.23379666497931
Epoch Time (s)               82.97922809887677
Total Train Time (s)         3386.074085570406
Epoch                        40
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:25.045377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Epoch Duration: 82.14451503753662
2020-01-11 10:27:25.045565 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0355237
Z variance train             0.01523519
KL Divergence                23.670883
KL Loss                      2.3670883
QF Loss                      223.66342
VF Loss                      65.56641
Policy Loss                  -984.54926
Q Predictions Mean           985.2811
Q Predictions Std            418.87955
Q Predictions Max            1511.8523
Q Predictions Min            261.6789
V Predictions Mean           988.3817
V Predictions Std            417.05368
V Predictions Max            1503.659
V Predictions Min            269.33276
Log Pis Mean                 0.4930182
Log Pis Std                  3.640217
Log Pis Max                  9.048473
Log Pis Min                  -8.764563
Policy mu Mean               0.05126953
Policy mu Std                1.0047516
Policy mu Max                2.7711482
Policy mu Min                -2.428476
Policy log std Mean          -0.50416213
Policy log std Std           0.26825914
Policy log std Max           -0.043543786
Policy log std Min           -1.8605369
Z mean eval                  1.9935888
Z variance eval              0.07588675
total_rewards                [4175.86776715 4380.40621634 4405.07400553 4419.47539358 4222.00287182
 4378.48111776 4373.57546051 4323.2441621  4434.78141015 4283.95297706]
total_rewards_mean           4339.686138199341
total_rewards_std            82.49788136243853
total_rewards_max            4434.781410153428
total_rewards_min            4175.867767150898
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               31.121267006266862
(Previous) Eval Time (s)     28.171402517240494
Sample Time (s)              23.047017930075526
Epoch Time (s)               82.33968745358288
Total Train Time (s)         3469.083707562182
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:48.056874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Epoch Duration: 83.01115822792053
2020-01-11 10:28:48.057090 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.993887
Z variance train             0.07526262
KL Divergence                21.435652
KL Loss                      2.1435652
QF Loss                      184.67133
VF Loss                      74.748024
Policy Loss                  -964.0892
Q Predictions Mean           964.234
Q Predictions Std            432.24625
Q Predictions Max            1548.9978
Q Predictions Min            265.36325
V Predictions Mean           966.8187
V Predictions Std            432.0748
V Predictions Max            1554.5219
V Predictions Min            269.3691
Log Pis Mean                 0.17747094
Log Pis Std                  3.4141943
Log Pis Max                  10.897291
Log Pis Min                  -9.020287
Policy mu Mean               -0.010112348
Policy mu Std                0.9801398
Policy mu Max                2.3578756
Policy mu Min                -2.3249097
Policy log std Mean          -0.4769791
Policy log std Std           0.2529658
Policy log std Max           -0.055658385
Policy log std Min           -1.5748355
Z mean eval                  2.0230165
Z variance eval              0.044674855
total_rewards                [4648.63261138 4629.41398654 4589.25944983 4656.92718448 4579.48914545
 4597.71774049 4458.23036563 4550.23315279 4641.18291924 4662.85291203]
total_rewards_mean           4601.393946786975
total_rewards_std            59.34200867090498
total_rewards_max            4662.852912029577
total_rewards_min            4458.230365626417
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               31.421416639350355
(Previous) Eval Time (s)     28.84252368938178
Sample Time (s)              22.59837858332321
Epoch Time (s)               82.86231891205534
Total Train Time (s)         3550.5812860717997
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:09.557807 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Epoch Duration: 81.50052809715271
2020-01-11 10:30:09.558100 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0205379
Z variance train             0.044591166
KL Divergence                22.185968
KL Loss                      2.218597
QF Loss                      256.0641
VF Loss                      73.85019
Policy Loss                  -1057.3815
Q Predictions Mean           1051.379
Q Predictions Std            460.973
Q Predictions Max            1598.9381
Q Predictions Min            279.13824
V Predictions Mean           1057.5535
V Predictions Std            459.51157
V Predictions Max            1601.4326
V Predictions Min            286.20358
Log Pis Mean                 0.37084842
Log Pis Std                  3.6416245
Log Pis Max                  10.496767
Log Pis Min                  -7.481943
Policy mu Mean               0.06352362
Policy mu Std                1.0138581
Policy mu Max                3.1743298
Policy mu Min                -2.5674188
Policy log std Mean          -0.49380842
Policy log std Std           0.26857635
Policy log std Max           0.00443615
Policy log std Min           -1.6397294
Z mean eval                  2.0388005
Z variance eval              0.029388988
total_rewards                [4579.40108003 4635.32868659 4589.82300123 4473.87223172 4596.62214183
 4528.63401111 4431.42446427 4535.27879355 4568.64873041 4429.1730798 ]
total_rewards_mean           4536.820622056781
total_rewards_std            67.560104896262
total_rewards_max            4635.3286865919445
total_rewards_min            4429.173079804523
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               31.60208289604634
(Previous) Eval Time (s)     27.480404898058623
Sample Time (s)              22.25041037797928
Epoch Time (s)               81.33289817208424
Total Train Time (s)         3631.9321217220277
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:30.909015 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Epoch Duration: 81.35068655014038
2020-01-11 10:31:30.909247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0401275
Z variance train             0.029361105
KL Divergence                22.984314
KL Loss                      2.2984314
QF Loss                      259.0703
VF Loss                      72.77893
Policy Loss                  -1103.6119
Q Predictions Mean           1096.6392
Q Predictions Std            444.48672
Q Predictions Max            1631.3965
Q Predictions Min            266.16794
V Predictions Mean           1099.6592
V Predictions Std            440.5605
V Predictions Max            1614.9246
V Predictions Min            271.0834
Log Pis Mean                 1.2116547
Log Pis Std                  3.8815448
Log Pis Max                  13.026007
Log Pis Min                  -5.7804437
Policy mu Mean               0.0572494
Policy mu Std                1.074131
Policy mu Max                2.4792116
Policy mu Min                -2.8657053
Policy log std Mean          -0.5115985
Policy log std Std           0.28123385
Policy log std Max           -0.027022704
Policy log std Min           -1.8635153
Z mean eval                  2.0653927
Z variance eval              0.021079166
total_rewards                [4760.21583577 4725.79256396 4849.97742806 4667.96369635 4807.28050003
 4624.01954468 5019.55272899 4571.47103889 4731.49151269 4720.36689579]
total_rewards_mean           4747.813174519113
total_rewards_std            119.27785287972603
total_rewards_max            5019.552728986684
total_rewards_min            4571.471038889534
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               31.140321366954595
(Previous) Eval Time (s)     27.49784696381539
Sample Time (s)              21.060775371734053
Epoch Time (s)               79.69894370250404
Total Train Time (s)         3712.3602463994175
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:51.338330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Epoch Duration: 80.42892003059387
2020-01-11 10:32:51.338515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0657783
Z variance train             0.021055453
KL Divergence                23.984676
KL Loss                      2.3984678
QF Loss                      201.30704
VF Loss                      77.72123
Policy Loss                  -1113.5012
Q Predictions Mean           1108.2661
Q Predictions Std            435.5848
Q Predictions Max            1625.7754
Q Predictions Min            267.67224
V Predictions Mean           1108.9104
V Predictions Std            430.73566
V Predictions Max            1617.376
V Predictions Min            269.94724
Log Pis Mean                 1.0020742
Log Pis Std                  3.6742427
Log Pis Max                  10.624571
Log Pis Min                  -6.990963
Policy mu Mean               0.08176132
Policy mu Std                1.0386329
Policy mu Max                2.6924875
Policy mu Min                -2.533888
Policy log std Mean          -0.5091723
Policy log std Std           0.26561403
Policy log std Max           0.032076538
Policy log std Min           -1.6706741
Z mean eval                  2.0710201
Z variance eval              0.017879738
total_rewards                [4587.26497838 4655.26861478 4628.47715599 4686.38639619 4897.09225552
 4829.34076359 4715.25055015 4716.67935509 4651.18232008 4708.05454579]
total_rewards_mean           4707.499693556814
total_rewards_std            88.30724057200281
total_rewards_max            4897.092255523622
total_rewards_min            4587.264978376738
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               31.355830643791705
(Previous) Eval Time (s)     28.22748169116676
Sample Time (s)              22.204573074821383
Epoch Time (s)               81.78788540977985
Total Train Time (s)         3793.924988921266
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:12.905971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Epoch Duration: 81.56729412078857
2020-01-11 10:34:12.906260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0703704
Z variance train             0.017906923
KL Divergence                24.410831
KL Loss                      2.4410832
QF Loss                      204.93094
VF Loss                      112.79609
Policy Loss                  -1124.469
Q Predictions Mean           1119.8071
Q Predictions Std            476.6844
Q Predictions Max            1672.9882
Q Predictions Min            279.53442
V Predictions Mean           1122.8269
V Predictions Std            474.74945
V Predictions Max            1673.1393
V Predictions Min            278.446
Log Pis Mean                 1.172645
Log Pis Std                  3.875973
Log Pis Max                  13.403608
Log Pis Min                  -7.0309086
Policy mu Mean               0.085123055
Policy mu Std                1.0561439
Policy mu Max                3.0788853
Policy mu Min                -2.8191946
Policy log std Mean          -0.5110636
Policy log std Std           0.27512676
Policy log std Max           -0.042955175
Policy log std Min           -1.7486303
Z mean eval                  2.072871
Z variance eval              0.015657576
total_rewards                [4949.59896733 4762.52721436 4905.89596348 4750.77963264 5009.43601909
 4931.87414516 4819.3113862  4821.42626426 4761.67849827 5010.34658505]
total_rewards_mean           4872.287467584832
total_rewards_std            96.41906173944491
total_rewards_max            5010.346585053749
total_rewards_min            4750.779632639114
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               31.542483313009143
(Previous) Eval Time (s)     28.006522127892822
Sample Time (s)              21.531737339217216
Epoch Time (s)               81.08074278011918
Total Train Time (s)         3874.5143678183667
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:33.496007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Epoch Duration: 80.58957552909851
2020-01-11 10:35:33.496191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0763588
Z variance train             0.015775451
KL Divergence                25.042408
KL Loss                      2.5042408
QF Loss                      207.28114
VF Loss                      203.66766
Policy Loss                  -1191.5206
Q Predictions Mean           1188.9609
Q Predictions Std            474.15118
Q Predictions Max            1684.2894
Q Predictions Min            260.7245
V Predictions Mean           1180.4968
V Predictions Std            466.57254
V Predictions Max            1661.7896
V Predictions Min            269.21957
Log Pis Mean                 0.60410345
Log Pis Std                  3.5007372
Log Pis Max                  11.96684
Log Pis Min                  -6.654749
Policy mu Mean               0.023665795
Policy mu Std                1.0116143
Policy mu Max                2.7916465
Policy mu Min                -2.7262201
Policy log std Mean          -0.4992796
Policy log std Std           0.27105367
Policy log std Max           -0.03634625
Policy log std Min           -1.837738
Z mean eval                  2.0676816
Z variance eval              0.015228677
total_rewards                [4891.72504992 4327.12215365 4879.68161515 4979.28072382 4838.77355613
 4799.34870944 4753.52267441 4961.5201512  4823.02113221 4976.08188804]
total_rewards_mean           4823.0077653978615
total_rewards_std            180.69632677247742
total_rewards_max            4979.2807238191035
total_rewards_min            4327.122153648742
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               31.24342101207003
(Previous) Eval Time (s)     27.51504789479077
Sample Time (s)              22.646737348288298
Epoch Time (s)               81.4052062551491
Total Train Time (s)         3956.264512630645
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:55.247734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Epoch Duration: 81.75140523910522
2020-01-11 10:36:55.247916 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0650043
Z variance train             0.015227435
KL Divergence                25.131706
KL Loss                      2.5131707
QF Loss                      201.988
VF Loss                      112.093956
Policy Loss                  -1188.6703
Q Predictions Mean           1186.6465
Q Predictions Std            462.72107
Q Predictions Max            1783.1506
Q Predictions Min            259.26382
V Predictions Mean           1193.3657
V Predictions Std            460.66037
V Predictions Max            1764.6825
V Predictions Min            266.56958
Log Pis Mean                 1.1793385
Log Pis Std                  3.8176885
Log Pis Max                  10.959795
Log Pis Min                  -7.4058495
Policy mu Mean               0.06381178
Policy mu Std                1.0671451
Policy mu Max                2.6909554
Policy mu Min                -2.6402152
Policy log std Mean          -0.5204261
Policy log std Std           0.28479588
Policy log std Max           0.017204255
Policy log std Min           -1.9199024
Z mean eval                  2.075172
Z variance eval              0.013680605
total_rewards                [4893.11479347 5010.34609667 4911.61093698 4892.73422185 4996.41282983
 4944.84327372 4867.14475194 4871.53465599 4943.90295016 4992.48467265]
total_rewards_mean           4932.412918325712
total_rewards_std            50.57892798465066
total_rewards_max            5010.346096667866
total_rewards_min            4867.144751935819
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               31.284674047026783
(Previous) Eval Time (s)     27.860915489960462
Sample Time (s)              20.739544483833015
Epoch Time (s)               79.88513402082026
Total Train Time (s)         4035.782058820594
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:14.765088 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Epoch Duration: 79.51705527305603
2020-01-11 10:38:14.765226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0760856
Z variance train             0.013659455
KL Divergence                25.725376
KL Loss                      2.5725377
QF Loss                      191.82202
VF Loss                      81.9395
Policy Loss                  -1248.7411
Q Predictions Mean           1242.9453
Q Predictions Std            467.1571
Q Predictions Max            1797.5553
Q Predictions Min            270.30853
V Predictions Mean           1247.0927
V Predictions Std            464.44995
V Predictions Max            1778.2529
V Predictions Min            265.51788
Log Pis Mean                 1.6347833
Log Pis Std                  4.0486765
Log Pis Max                  12.66481
Log Pis Min                  -5.379085
Policy mu Mean               0.03397544
Policy mu Std                1.1157937
Policy mu Max                2.914334
Policy mu Min                -3.1011784
Policy log std Mean          -0.54698527
Policy log std Std           0.2870548
Policy log std Max           -0.010382742
Policy log std Min           -1.8966838
Z mean eval                  2.0662074
Z variance eval              0.011545819
total_rewards                [4926.83051345 4959.10013017 4927.21492366 5036.41011351 4955.34977719
 4923.58395926 5082.70110378 5229.82621307 4932.22884861 4929.96911654]
total_rewards_mean           4990.321469924843
total_rewards_std            94.71170225018832
total_rewards_max            5229.826213071207
total_rewards_min            4923.58395926469
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               31.00441701244563
(Previous) Eval Time (s)     27.49252914870158
Sample Time (s)              22.51261919364333
Epoch Time (s)               81.00956535479054
Total Train Time (s)         4117.120109434705
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:36.105547 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Epoch Duration: 81.34021234512329
2020-01-11 10:39:36.105752 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0660713
Z variance train             0.0115471985
KL Divergence                25.974792
KL Loss                      2.5974793
QF Loss                      263.41345
VF Loss                      90.20712
Policy Loss                  -1277.8147
Q Predictions Mean           1275.1204
Q Predictions Std            478.67084
Q Predictions Max            1813.9114
Q Predictions Min            270.10657
V Predictions Mean           1279.8071
V Predictions Std            476.76434
V Predictions Max            1802.772
V Predictions Min            277.02762
Log Pis Mean                 1.6285872
Log Pis Std                  4.1001515
Log Pis Max                  13.679377
Log Pis Min                  -7.8622875
Policy mu Mean               0.013217506
Policy mu Std                1.1221533
Policy mu Max                2.6683939
Policy mu Min                -2.8402045
Policy log std Mean          -0.56321406
Policy log std Std           0.2884459
Policy log std Max           -0.01610884
Policy log std Min           -1.9041153
Z mean eval                  2.0404449
Z variance eval              0.01606578
total_rewards                [4950.46837622 5037.05865745 4981.8518377  5285.61645753 5130.00151828
 5098.23970586 5071.83729075 5190.41966077 4898.55697402 5088.68436996]
total_rewards_mean           5073.2734848534155
total_rewards_std            108.70606686614127
total_rewards_max            5285.616457526616
total_rewards_min            4898.556974019945
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               31.644688901957124
(Previous) Eval Time (s)     27.82284165127203
Sample Time (s)              22.867839088197798
Epoch Time (s)               82.33536964142695
Total Train Time (s)         4199.293257548939
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:58.280987 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Epoch Duration: 82.17509627342224
2020-01-11 10:40:58.281171 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0396523
Z variance train             0.016042575
KL Divergence                24.845804
KL Loss                      2.4845805
QF Loss                      238.59036
VF Loss                      111.83638
Policy Loss                  -1287.2949
Q Predictions Mean           1282.7407
Q Predictions Std            476.90744
Q Predictions Max            1771.8518
Q Predictions Min            258.39487
V Predictions Mean           1280.8806
V Predictions Std            474.05124
V Predictions Max            1771.6102
V Predictions Min            265.36697
Log Pis Mean                 1.2912883
Log Pis Std                  3.913008
Log Pis Max                  12.745909
Log Pis Min                  -6.6440773
Policy mu Mean               0.016449139
Policy mu Std                1.0871814
Policy mu Max                3.0007837
Policy mu Min                -2.4288247
Policy log std Mean          -0.5526409
Policy log std Std           0.3004458
Policy log std Max           -0.012514636
Policy log std Min           -1.922509
Z mean eval                  2.0406127
Z variance eval              0.014806658
total_rewards                [5105.21705717 5073.49016231 5160.87880212 5016.41411928 5192.99461186
 5134.2607817  5166.64871372 4972.07921864 5127.32431611 5050.74482161]
total_rewards_mean           5100.00526045127
total_rewards_std            67.24811082696866
total_rewards_max            5192.994611859931
total_rewards_min            4972.079218638237
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               31.322198836132884
(Previous) Eval Time (s)     27.662229637615383
Sample Time (s)              22.475300974678248
Epoch Time (s)               81.45972944842651
Total Train Time (s)         4280.918583967723
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:19.908441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Epoch Duration: 81.62712335586548
2020-01-11 10:42:19.908674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0411544
Z variance train             0.014802593
KL Divergence                25.315384
KL Loss                      2.5315385
QF Loss                      261.18912
VF Loss                      120.93497
Policy Loss                  -1292.7474
Q Predictions Mean           1285.0791
Q Predictions Std            515.24615
Q Predictions Max            1907.0498
Q Predictions Min            270.95032
V Predictions Mean           1286.9615
V Predictions Std            511.87936
V Predictions Max            1894.976
V Predictions Min            275.60632
Log Pis Mean                 1.3329716
Log Pis Std                  4.1445737
Log Pis Max                  12.797676
Log Pis Min                  -7.859056
Policy mu Mean               0.001841087
Policy mu Std                1.0941694
Policy mu Max                2.7276564
Policy mu Min                -2.9146543
Policy log std Mean          -0.5373023
Policy log std Std           0.29684287
Policy log std Max           0.07881293
Policy log std Min           -1.9939736
Z mean eval                  2.0344698
Z variance eval              0.01780422
total_rewards                [5030.01659313 5325.06958331 5228.13118635 5436.11467827 5147.10392081
 5068.54602961 5129.93423741 5172.88467733 5021.26101477 5119.96132754]
total_rewards_mean           5167.9023248518515
total_rewards_std            124.4395692633454
total_rewards_max            5436.114678266391
total_rewards_min            5021.2610147694
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               31.747415489982814
(Previous) Eval Time (s)     27.829238282050937
Sample Time (s)              20.581413054373115
Epoch Time (s)               80.15806682640687
Total Train Time (s)         4361.340093057137
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:40.329691 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Epoch Duration: 80.42085266113281
2020-01-11 10:43:40.329856 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0347552
Z variance train             0.0178316
KL Divergence                24.965954
KL Loss                      2.4965954
QF Loss                      382.361
VF Loss                      121.0157
Policy Loss                  -1307.4385
Q Predictions Mean           1308.0325
Q Predictions Std            545.37
Q Predictions Max            1899.9353
Q Predictions Min            272.74936
V Predictions Mean           1312.2448
V Predictions Std            543.90265
V Predictions Max            1886.9008
V Predictions Min            273.7721
Log Pis Mean                 1.3385425
Log Pis Std                  4.156401
Log Pis Max                  13.804295
Log Pis Min                  -6.5577583
Policy mu Mean               0.002426366
Policy mu Std                1.0902941
Policy mu Max                2.8783932
Policy mu Min                -3.0471666
Policy log std Mean          -0.5329924
Policy log std Std           0.29352486
Policy log std Max           0.0009998083
Policy log std Min           -2.1698294
Z mean eval                  2.0071363
Z variance eval              0.034767695
total_rewards                [5032.86453133 5094.1245739  5240.2989436  4875.87593843 5048.13654648
 5065.41262274 4935.31949792 5007.58738189 5284.33086265 5121.31623473]
total_rewards_mean           5070.526713366178
total_rewards_std            118.2152473661397
total_rewards_max            5284.330862645135
total_rewards_min            4875.875938431835
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               31.317281652241945
(Previous) Eval Time (s)     28.091733722016215
Sample Time (s)              22.19188640639186
Epoch Time (s)               81.60090178065002
Total Train Time (s)         4441.725893240422
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:00.717209 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Epoch Duration: 80.38721990585327
2020-01-11 10:45:00.717393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0069218
Z variance train             0.034664042
KL Divergence                24.00577
KL Loss                      2.400577
QF Loss                      218.45148
VF Loss                      186.49527
Policy Loss                  -1346.9608
Q Predictions Mean           1347.7358
Q Predictions Std            534.7764
Q Predictions Max            1897.229
Q Predictions Min            261.7562
V Predictions Mean           1357.352
V Predictions Std            534.7135
V Predictions Max            1904.5417
V Predictions Min            270.70688
Log Pis Mean                 1.3796117
Log Pis Std                  3.965239
Log Pis Max                  12.558211
Log Pis Min                  -6.4389715
Policy mu Mean               -0.0325509
Policy mu Std                1.0983862
Policy mu Max                3.0105762
Policy mu Min                -2.7394373
Policy log std Mean          -0.54474133
Policy log std Std           0.30255046
Policy log std Max           0.028759003
Policy log std Min           -1.9557035
Z mean eval                  2.0049224
Z variance eval              0.034230836
total_rewards                [4898.40120382 5078.73231125 5041.34588493 5068.91629349 5101.52681303
 5076.74681937 5182.76349376 5184.48020603 4973.80141735 5008.7331068 ]
total_rewards_mean           5061.544754982662
total_rewards_std            83.36564236950754
total_rewards_max            5184.480206034946
total_rewards_min            4898.401203816653
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               31.543838298879564
(Previous) Eval Time (s)     26.877722769975662
Sample Time (s)              22.609442011918873
Epoch Time (s)               81.0310030807741
Total Train Time (s)         4525.156349443831
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:24.149257 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Epoch Duration: 83.4317262172699
2020-01-11 10:46:24.149448 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.004387
Z variance train             0.03435813
KL Divergence                24.224218
KL Loss                      2.422422
QF Loss                      213.10257
VF Loss                      97.846504
Policy Loss                  -1366.5072
Q Predictions Mean           1362.8536
Q Predictions Std            539.83307
Q Predictions Max            1921.3357
Q Predictions Min            266.73407
V Predictions Mean           1365.8851
V Predictions Std            535.81793
V Predictions Max            1914.1335
V Predictions Min            267.93124
Log Pis Mean                 1.3634953
Log Pis Std                  4.1130123
Log Pis Max                  12.610235
Log Pis Min                  -7.104994
Policy mu Mean               -0.023150042
Policy mu Std                1.0894113
Policy mu Max                2.496416
Policy mu Min                -2.6550415
Policy log std Mean          -0.5402175
Policy log std Std           0.30552065
Policy log std Max           -0.044600368
Policy log std Min           -2.1116223
Z mean eval                  2.0121858
Z variance eval              0.015406938
total_rewards                [5010.12849576 5040.45951704 5177.45293303 5167.65215622 5298.10046962
 5192.57958523 5092.32201194 5197.93823459 5128.99911329 4979.30819666]
total_rewards_mean           5128.494071338489
total_rewards_std            93.24789079232444
total_rewards_max            5298.10046962108
total_rewards_min            4979.308196663509
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.58744387002662
(Previous) Eval Time (s)     29.27814471302554
Sample Time (s)              21.90343284374103
Epoch Time (s)               82.76902142679319
Total Train Time (s)         4607.381397745572
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:46.375872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Epoch Duration: 82.22626805305481
2020-01-11 10:47:46.376067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.011755
Z variance train             0.015390444
KL Divergence                26.027256
KL Loss                      2.6027257
QF Loss                      450.10468
VF Loss                      151.62494
Policy Loss                  -1349.5355
Q Predictions Mean           1343.7957
Q Predictions Std            563.96387
Q Predictions Max            1926.0446
Q Predictions Min            259.61063
V Predictions Mean           1341.894
V Predictions Std            560.05615
V Predictions Max            1923.7134
V Predictions Min            254.48138
Log Pis Mean                 1.5490551
Log Pis Std                  4.3614893
Log Pis Max                  13.278366
Log Pis Min                  -7.9514875
Policy mu Mean               0.017815627
Policy mu Std                1.1225011
Policy mu Max                3.0243137
Policy mu Min                -2.854451
Policy log std Mean          -0.5405118
Policy log std Std           0.30331966
Policy log std Max           0.020679712
Policy log std Min           -2.1498404
Z mean eval                  2.01327
Z variance eval              0.013254347
total_rewards                [5400.50010304 5321.66965982 5050.14090435 5382.70592167 5288.79231793
 5426.97674235 5217.26021693 5104.44317521 5435.60377268 5247.11013115]
total_rewards_mean           5287.520294513384
total_rewards_std            126.80891986993436
total_rewards_max            5435.603772678169
total_rewards_min            5050.1409043499825
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.54009644081816
(Previous) Eval Time (s)     28.73512487532571
Sample Time (s)              21.59174938686192
Epoch Time (s)               81.86697070300579
Total Train Time (s)         4688.4212221177295
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:07.416750 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Epoch Duration: 81.04054355621338
2020-01-11 10:49:07.416928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013412
Z variance train             0.013257189
KL Divergence                26.304714
KL Loss                      2.6304715
QF Loss                      186.75409
VF Loss                      104.31715
Policy Loss                  -1452.2537
Q Predictions Mean           1448.1792
Q Predictions Std            521.4464
Q Predictions Max            1997.1183
Q Predictions Min            265.12915
V Predictions Mean           1448.9573
V Predictions Std            519.81
V Predictions Max            1996.0529
V Predictions Min            261.02188
Log Pis Mean                 1.8268006
Log Pis Std                  4.193028
Log Pis Max                  13.182152
Log Pis Min                  -7.1729927
Policy mu Mean               0.013410619
Policy mu Std                1.123053
Policy mu Max                3.6184366
Policy mu Min                -2.6133795
Policy log std Mean          -0.56616914
Policy log std Std           0.319007
Policy log std Max           -0.02939248
Policy log std Min           -2.0276005
Z mean eval                  2.0241408
Z variance eval              0.012960577
total_rewards                [5282.15457277 5507.87620614 5364.9493047  5364.59054877 5404.48443469
 5598.961664   5303.06108524 5457.21272559 5372.8705233  5350.54944757]
total_rewards_mean           5400.671051274322
total_rewards_std            91.35664543505837
total_rewards_max            5598.9616639961805
total_rewards_min            5282.154572767092
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               31.612659459002316
(Previous) Eval Time (s)     27.908404592890292
Sample Time (s)              22.80804098211229
Epoch Time (s)               82.3291050340049
Total Train Time (s)         4769.271528150886
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:28.269435 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Epoch Duration: 80.85235333442688
2020-01-11 10:50:28.269641 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236485
Z variance train             0.012966692
KL Divergence                26.627434
KL Loss                      2.6627433
QF Loss                      334.8048
VF Loss                      109.00946
Policy Loss                  -1461.8983
Q Predictions Mean           1456.3042
Q Predictions Std            527.4136
Q Predictions Max            2030.7473
Q Predictions Min            265.9786
V Predictions Mean           1459.749
V Predictions Std            524.68195
V Predictions Max            2026.1891
V Predictions Min            267.5097
Log Pis Mean                 2.099419
Log Pis Std                  4.135749
Log Pis Max                  12.546692
Log Pis Min                  -6.661998
Policy mu Mean               -0.04303831
Policy mu Std                1.1685997
Policy mu Max                2.973418
Policy mu Min                -2.7680788
Policy log std Mean          -0.5594494
Policy log std Std           0.30243412
Policy log std Max           -0.06474964
Policy log std Min           -2.040035
Z mean eval                  2.0247533
Z variance eval              0.01942766
total_rewards                [5394.61946297 5216.07761413 5432.47950546 5124.38710234 5359.46815593
 5577.67401839 5227.12468826 5489.88888804 5503.94964236 5374.42398628]
total_rewards_mean           5370.009306415826
total_rewards_std            135.83659236021455
total_rewards_max            5577.674018386609
total_rewards_min            5124.3871023395
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               31.638057584874332
(Previous) Eval Time (s)     26.43130757380277
Sample Time (s)              22.740424748510122
Epoch Time (s)               80.80978990718722
Total Train Time (s)         4851.194862604607
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:50.193889 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Epoch Duration: 81.92411684989929
2020-01-11 10:51:50.194081 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023825
Z variance train             0.019533407
KL Divergence                26.00922
KL Loss                      2.600922
QF Loss                      174.98682
VF Loss                      77.321365
Policy Loss                  -1447.1724
Q Predictions Mean           1444.693
Q Predictions Std            606.5482
Q Predictions Max            2055.7827
Q Predictions Min            256.9505
V Predictions Mean           1447.4823
V Predictions Std            607.18384
V Predictions Max            2050.2485
V Predictions Min            258.51175
Log Pis Mean                 1.0951242
Log Pis Std                  4.045174
Log Pis Max                  12.963133
Log Pis Min                  -8.69061
Policy mu Mean               0.021376481
Policy mu Std                1.0692366
Policy mu Max                2.9663901
Policy mu Min                -2.6079614
Policy log std Mean          -0.52501667
Policy log std Std           0.31286258
Policy log std Max           -0.02417034
Policy log std Min           -2.0927596
Z mean eval                  2.0134416
Z variance eval              0.029431995
total_rewards                [5373.31673397 5378.48335603 5300.36514387 5302.94410958 5742.83841852
 5207.93072695 5423.79489722 5153.70838257 5517.58346097 5394.00218468]
total_rewards_mean           5379.496741436111
total_rewards_std            156.79109217584238
total_rewards_max            5742.838418524939
total_rewards_min            5153.708382573983
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               30.51310090208426
(Previous) Eval Time (s)     27.545318874996156
Sample Time (s)              21.9799940045923
Epoch Time (s)               80.03841378167272
Total Train Time (s)         4932.688118043356
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:11.688861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Epoch Duration: 81.49463558197021
2020-01-11 10:53:11.689054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0132232
Z variance train             0.029720504
KL Divergence                25.07177
KL Loss                      2.507177
QF Loss                      444.69482
VF Loss                      198.72275
Policy Loss                  -1347.4083
Q Predictions Mean           1350.2262
Q Predictions Std            623.8859
Q Predictions Max            2013.3926
Q Predictions Min            257.5933
V Predictions Mean           1355.5858
V Predictions Std            626.3804
V Predictions Max            2027.051
V Predictions Min            253.84709
Log Pis Mean                 1.2123965
Log Pis Std                  4.3447614
Log Pis Max                  13.460878
Log Pis Min                  -7.5068817
Policy mu Mean               0.03332339
Policy mu Std                1.0693278
Policy mu Max                2.6895792
Policy mu Min                -2.6253655
Policy log std Mean          -0.53502965
Policy log std Std           0.32185394
Policy log std Max           0.011178106
Policy log std Min           -2.119517
Z mean eval                  2.0093799
Z variance eval              0.025849689
total_rewards                [5118.98416714 5219.7689264  5338.98221686 5216.29489641 5514.20308594
 5239.07578609 5499.96736649 5309.64430765 5289.34136087 5324.0732402 ]
total_rewards_mean           5307.033535405951
total_rewards_std            117.3043127906101
total_rewards_max            5514.20308594005
total_rewards_min            5118.9841671448385
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               31.930295537225902
(Previous) Eval Time (s)     29.001213295850903
Sample Time (s)              21.979140787851065
Epoch Time (s)               82.91064962092787
Total Train Time (s)         5014.703381260391
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:33.707058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Epoch Duration: 82.01784086227417
2020-01-11 10:54:33.707377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.008575
Z variance train             0.025867725
KL Divergence                25.040833
KL Loss                      2.5040834
QF Loss                      307.7169
VF Loss                      127.49503
Policy Loss                  -1450.769
Q Predictions Mean           1444.117
Q Predictions Std            579.5972
Q Predictions Max            2079.2097
Q Predictions Min            224.80968
V Predictions Mean           1450.2307
V Predictions Std            573.2246
V Predictions Max            2063.3933
V Predictions Min            237.03133
Log Pis Mean                 1.7236204
Log Pis Std                  4.2640586
Log Pis Max                  14.762294
Log Pis Min                  -8.528137
Policy mu Mean               -0.018282406
Policy mu Std                1.1329323
Policy mu Max                3.0073707
Policy mu Min                -2.907153
Policy log std Mean          -0.56341445
Policy log std Std           0.32291925
Policy log std Max           0.047390193
Policy log std Min           -2.1326532
Z mean eval                  2.0379953
Z variance eval              0.019211907
total_rewards                [5577.68449783 5781.47382883 5728.99980782 5576.31033472 5771.88471686
 5651.40523014 5570.29478038 5644.96415316 5705.92108074 5538.90817031]
total_rewards_mean           5654.784660078785
total_rewards_std            84.06057861095499
total_rewards_max            5781.473828827806
total_rewards_min            5538.908170309849
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               33.22074736887589
(Previous) Eval Time (s)     28.10809353319928
Sample Time (s)              22.074639656580985
Epoch Time (s)               83.40348055865616
Total Train Time (s)         5098.71564652957
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:57.719681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Epoch Duration: 84.01211190223694
2020-01-11 10:55:57.719931 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0390244
Z variance train             0.01917678
KL Divergence                26.420734
KL Loss                      2.6420734
QF Loss                      476.9852
VF Loss                      180.68924
Policy Loss                  -1485.6599
Q Predictions Mean           1479.4028
Q Predictions Std            608.9895
Q Predictions Max            2141.0403
Q Predictions Min            249.69115
V Predictions Mean           1487.6469
V Predictions Std            605.97345
V Predictions Max            2151.4517
V Predictions Min            261.11465
Log Pis Mean                 2.1727595
Log Pis Std                  4.3968334
Log Pis Max                  13.666006
Log Pis Min                  -7.9204087
Policy mu Mean               0.022429146
Policy mu Std                1.1645663
Policy mu Max                3.3534355
Policy mu Min                -2.8084035
Policy log std Mean          -0.5783078
Policy log std Std           0.3388798
Policy log std Max           0.06948975
Policy log std Min           -2.064958
Z mean eval                  2.0267282
Z variance eval              0.020318303
total_rewards                [5353.29010415 5305.78798421 5438.62155004 4996.54825495 5369.83099347
 5192.37344707 5130.50448859 5198.22218029 5233.13471645 5536.8442075 ]
total_rewards_mean           5275.515792672284
total_rewards_std            149.76344943847496
total_rewards_max            5536.84420750107
total_rewards_min            4996.548254946272
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               33.86086726281792
(Previous) Eval Time (s)     28.716258583124727
Sample Time (s)              23.406370665878057
Epoch Time (s)               85.9834965118207
Total Train Time (s)         5185.839077274781
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:24.845883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Epoch Duration: 87.12571811676025
2020-01-11 10:57:24.846238 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0254183
Z variance train             0.020229498
KL Divergence                25.799393
KL Loss                      2.5799394
QF Loss                      385.3214
VF Loss                      140.55156
Policy Loss                  -1602.4569
Q Predictions Mean           1606.8513
Q Predictions Std            552.4492
Q Predictions Max            2180.0444
Q Predictions Min            256.64227
V Predictions Mean           1609.4652
V Predictions Std            552.4448
V Predictions Max            2183.3796
V Predictions Min            224.21202
Log Pis Mean                 1.8200808
Log Pis Std                  4.1533217
Log Pis Max                  12.251984
Log Pis Min                  -7.4068375
Policy mu Mean               -0.088115536
Policy mu Std                1.1367687
Policy mu Max                2.885927
Policy mu Min                -2.9193997
Policy log std Mean          -0.5747276
Policy log std Std           0.3268146
Policy log std Max           -0.031159759
Policy log std Min           -2.0426183
Z mean eval                  2.0525863
Z variance eval              0.013073881
total_rewards                [5278.78957789 5364.42702941 5415.35154788 5298.08208453 5364.57554704
 5356.46542279 5229.76175621 5360.63285913 5382.26187734 5319.5053651 ]
total_rewards_mean           5336.985306732579
total_rewards_std            52.294195144086466
total_rewards_max            5415.351547879533
total_rewards_min            5229.761756207668
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               33.36486695101485
(Previous) Eval Time (s)     29.858100766316056
Sample Time (s)              23.793877604883164
Epoch Time (s)               87.01684532221407
Total Train Time (s)         5271.678896309808
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:50.686426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Epoch Duration: 85.83999538421631
2020-01-11 10:58:50.686647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540826
Z variance train             0.013032375
KL Divergence                27.190304
KL Loss                      2.7190304
QF Loss                      356.1452
VF Loss                      64.165886
Policy Loss                  -1592.29
Q Predictions Mean           1592.383
Q Predictions Std            559.15265
Q Predictions Max            2164.615
Q Predictions Min            245.32793
V Predictions Mean           1593.7474
V Predictions Std            555.9762
V Predictions Max            2161.7026
V Predictions Min            251.05127
Log Pis Mean                 2.0926342
Log Pis Std                  4.5518923
Log Pis Max                  14.601321
Log Pis Min                  -7.2139826
Policy mu Mean               -0.08946123
Policy mu Std                1.1585116
Policy mu Max                2.9546804
Policy mu Min                -2.8058636
Policy log std Mean          -0.564356
Policy log std Std           0.32068107
Policy log std Max           0.022530377
Policy log std Min           -2.2817595
Z mean eval                  2.054189
Z variance eval              0.01288003
total_rewards                [5720.60426659 5901.51581184 5706.79318643 5756.56278306 5790.21840744
 5496.68122363 5884.25790511 5667.71427195 5766.43540726 5769.77753422]
total_rewards_mean           5746.056079751717
total_rewards_std            108.08368356459093
total_rewards_max            5901.515811840177
total_rewards_min            5496.681223627512
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               33.91810190118849
(Previous) Eval Time (s)     28.680819565895945
Sample Time (s)              23.8484271094203
Epoch Time (s)               86.44734857650474
Total Train Time (s)         5358.433065568563
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:17.443121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Epoch Duration: 86.75624799728394
2020-01-11 11:00:17.443430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540252
Z variance train             0.012903348
KL Divergence                27.017483
KL Loss                      2.7017484
QF Loss                      205.95905
VF Loss                      76.24681
Policy Loss                  -1620.2056
Q Predictions Mean           1619.3275
Q Predictions Std            557.336
Q Predictions Max            2169.5056
Q Predictions Min            229.25378
V Predictions Mean           1620.4087
V Predictions Std            554.80383
V Predictions Max            2151.1865
V Predictions Min            244.8899
Log Pis Mean                 2.3243842
Log Pis Std                  4.2773857
Log Pis Max                  15.218156
Log Pis Min                  -5.5830703
Policy mu Mean               -0.028565481
Policy mu Std                1.1718726
Policy mu Max                2.8725832
Policy mu Min                -2.827321
Policy log std Mean          -0.59094524
Policy log std Std           0.3253409
Policy log std Max           -0.07583135
Policy log std Min           -2.092714
Z mean eval                  2.034642
Z variance eval              0.04763553
total_rewards                [5683.54255834 5704.70885809 5664.77282275 5638.66904341 5639.81553245
 5714.95162652 5735.74772724 5736.1183425  5673.72508981 5888.98080475]
total_rewards_mean           5708.103240585529
total_rewards_std            68.8992796125034
total_rewards_max            5888.980804748531
total_rewards_min            5638.669043407141
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               33.49394419416785
(Previous) Eval Time (s)     28.98928249720484
Sample Time (s)              23.83618614729494
Epoch Time (s)               86.31941283866763
Total Train Time (s)         5444.335825035814
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:43.347218 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Epoch Duration: 85.90357613563538
2020-01-11 11:01:43.347468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0345607
Z variance train             0.047717333
KL Divergence                25.569908
KL Loss                      2.5569909
QF Loss                      338.8183
VF Loss                      158.34091
Policy Loss                  -1508.8704
Q Predictions Mean           1510.5662
Q Predictions Std            598.4036
Q Predictions Max            2117.0679
Q Predictions Min            220.29977
V Predictions Mean           1502.4551
V Predictions Std            596.81024
V Predictions Max            2108.321
V Predictions Min            225.04968
Log Pis Mean                 1.8126863
Log Pis Std                  4.2458467
Log Pis Max                  13.202741
Log Pis Min                  -7.6153655
Policy mu Mean               -0.08486283
Policy mu Std                1.1093374
Policy mu Max                3.7663553
Policy mu Min                -2.8438592
Policy log std Mean          -0.5862491
Policy log std Std           0.33123106
Policy log std Max           -0.021607608
Policy log std Min           -2.3054254
Z mean eval                  2.0732608
Z variance eval              0.023040187
total_rewards                [5841.81391376 5952.22600992 5865.86436821 5915.20162249 5971.71165608
 5910.1876292  5900.82545751 5939.18818815 6048.85643433 5984.51138499]
total_rewards_mean           5933.038666464469
total_rewards_std            57.16391319870196
total_rewards_max            6048.856434325807
total_rewards_min            5841.813913758132
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               33.77890321193263
(Previous) Eval Time (s)     28.573060653172433
Sample Time (s)              21.608794504776597
Epoch Time (s)               83.96075836988166
Total Train Time (s)         5528.717976918444
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:07.730720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Epoch Duration: 84.3830943107605
2020-01-11 11:03:07.730940 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0731924
Z variance train             0.02302443
KL Divergence                26.461395
KL Loss                      2.6461396
QF Loss                      235.99539
VF Loss                      88.856834
Policy Loss                  -1562.9843
Q Predictions Mean           1561.955
Q Predictions Std            662.89453
Q Predictions Max            2196.7732
Q Predictions Min            244.54477
V Predictions Mean           1566.9236
V Predictions Std            659.78375
V Predictions Max            2199.2686
V Predictions Min            241.54808
Log Pis Mean                 1.7291133
Log Pis Std                  4.470781
Log Pis Max                  13.013176
Log Pis Min                  -5.985433
Policy mu Mean               0.004097845
Policy mu Std                1.1294845
Policy mu Max                2.9447913
Policy mu Min                -3.0819604
Policy log std Mean          -0.5454212
Policy log std Std           0.3474875
Policy log std Max           0.102757156
Policy log std Min           -2.1069102
Z mean eval                  2.0955136
Z variance eval              0.013792193
total_rewards                [5737.36634618 5898.60183577 5924.15912513 5917.62546856 5953.25917131
 5797.75080442 5830.95244718 5801.05118653 5870.72133674 5845.14717923]
total_rewards_mean           5857.663490106059
total_rewards_std            64.13900655414236
total_rewards_max            5953.259171309892
total_rewards_min            5737.36634618312
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               34.33328831382096
(Previous) Eval Time (s)     28.99503556918353
Sample Time (s)              23.671087882947177
Epoch Time (s)               86.99941176595166
Total Train Time (s)         5616.43619381031
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:35.450833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Epoch Duration: 87.71974611282349
2020-01-11 11:04:35.451031 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0970707
Z variance train             0.013803745
KL Divergence                27.715683
KL Loss                      2.7715683
QF Loss                      229.73602
VF Loss                      99.41829
Policy Loss                  -1641.2261
Q Predictions Mean           1635.1548
Q Predictions Std            579.3409
Q Predictions Max            2255.6995
Q Predictions Min            238.49467
V Predictions Mean           1638.0681
V Predictions Std            576.6452
V Predictions Max            2236.8767
V Predictions Min            243.66182
Log Pis Mean                 1.670243
Log Pis Std                  3.8188024
Log Pis Max                  13.659279
Log Pis Min                  -7.170472
Policy mu Mean               0.018325772
Policy mu Std                1.1132969
Policy mu Max                2.9587586
Policy mu Min                -2.685468
Policy log std Mean          -0.5651023
Policy log std Std           0.3221919
Policy log std Max           0.038921
Policy log std Min           -2.0961962
Z mean eval                  2.0838563
Z variance eval              0.011064863
total_rewards                [5870.04387009 5905.54532701 5968.61152172 6008.9666343  5742.9911026
 5897.89156686 5842.88642814 5860.00601628 5697.25852503 6062.20540799]
total_rewards_mean           5885.640640002779
total_rewards_std            106.0093838829731
total_rewards_max            6062.205407991227
total_rewards_min            5697.258525027953
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               33.22641342692077
(Previous) Eval Time (s)     29.715038198046386
Sample Time (s)              23.874159247614443
Epoch Time (s)               86.8156108725816
Total Train Time (s)         5702.6540380558
Epoch                        68
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:01.670529 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Epoch Duration: 86.21934723854065
2020-01-11 11:06:01.670760 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0819497
Z variance train             0.011045547
KL Divergence                28.423595
KL Loss                      2.8423595
QF Loss                      408.3325
VF Loss                      177.35391
Policy Loss                  -1598.2646
Q Predictions Mean           1595.3691
Q Predictions Std            633.54065
Q Predictions Max            2222.441
Q Predictions Min            232.79854
V Predictions Mean           1602.5865
V Predictions Std            632.82104
V Predictions Max            2236.5322
V Predictions Min            243.75876
Log Pis Mean                 2.5809503
Log Pis Std                  4.4662027
Log Pis Max                  14.429176
Log Pis Min                  -5.635748
Policy mu Mean               -0.05606849
Policy mu Std                1.208436
Policy mu Max                3.41036
Policy mu Min                -2.7092867
Policy log std Mean          -0.5744757
Policy log std Std           0.33312744
Policy log std Max           -0.010628611
Policy log std Min           -2.4634151
Z mean eval                  2.0926025
Z variance eval              0.01164424
total_rewards                [5761.49429066 5821.17837162 5915.55649189 5969.69744422 6191.73372815
 5980.96007262 5979.84565105 5818.1583395  5914.21921282 5884.38081431]
total_rewards_mean           5923.722441683605
total_rewards_std            114.0401281353854
total_rewards_max            6191.73372814644
total_rewards_min            5761.494290660418
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               33.92594486521557
(Previous) Eval Time (s)     29.118336235173047
Sample Time (s)              22.5183638012968
Epoch Time (s)               85.56264490168542
Total Train Time (s)         5788.1949321520515
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:27.212624 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Epoch Duration: 85.54172015190125
2020-01-11 11:07:27.212800 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0943716
Z variance train             0.011673568
KL Divergence                28.996618
KL Loss                      2.8996618
QF Loss                      438.46933
VF Loss                      129.57812
Policy Loss                  -1642.9235
Q Predictions Mean           1639.4998
Q Predictions Std            642.5633
Q Predictions Max            2271.9395
Q Predictions Min            237.29791
V Predictions Mean           1638.6522
V Predictions Std            636.9745
V Predictions Max            2242.5752
V Predictions Min            236.21213
Log Pis Mean                 1.8174763
Log Pis Std                  4.153148
Log Pis Max                  12.245399
Log Pis Min                  -6.0209136
Policy mu Mean               0.08255458
Policy mu Std                1.1195666
Policy mu Max                2.8909614
Policy mu Min                -2.450357
Policy log std Mean          -0.58163494
Policy log std Std           0.34637278
Policy log std Max           -0.033139795
Policy log std Min           -2.1706736
Z mean eval                  2.1016607
Z variance eval              0.011923835
total_rewards                [6001.79139899 5943.09200256 6029.5300707  6014.79996738 6067.66000125
 6042.17067271 5945.21526318 6059.05205181 5931.04291715 5883.47355335]
total_rewards_mean           5991.7827899082395
total_rewards_std            59.02187190983176
total_rewards_max            6067.660001248
total_rewards_min            5883.4735533488765
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               33.033643026370555
(Previous) Eval Time (s)     29.09702240396291
Sample Time (s)              23.398571940604597
Epoch Time (s)               85.52923737093806
Total Train Time (s)         5873.224006571807
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:52.243736 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Epoch Duration: 85.03079771995544
2020-01-11 11:08:52.243924 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.102152
Z variance train             0.011881178
KL Divergence                29.307533
KL Loss                      2.9307535
QF Loss                      242.74435
VF Loss                      130.07253
Policy Loss                  -1661.451
Q Predictions Mean           1659.6771
Q Predictions Std            637.1956
Q Predictions Max            2308.9946
Q Predictions Min            235.28268
V Predictions Mean           1655.4197
V Predictions Std            630.4683
V Predictions Max            2287.785
V Predictions Min            241.30844
Log Pis Mean                 2.4097986
Log Pis Std                  4.3220277
Log Pis Max                  13.908327
Log Pis Min                  -6.2991114
Policy mu Mean               -0.03422207
Policy mu Std                1.1656649
Policy mu Max                2.739013
Policy mu Min                -2.6938107
Policy log std Mean          -0.58906394
Policy log std Std           0.33664277
Policy log std Max           -0.047555357
Policy log std Min           -2.148845
Z mean eval                  2.099486
Z variance eval              0.014072609
total_rewards                [5896.48071562 6000.87138147 6149.75725187 5967.3044107  5692.00421338
 5910.02184673 5939.60866919 5882.39266124 6028.63633127 5727.33605352]
total_rewards_mean           5919.441353498444
total_rewards_std            128.42041158520055
total_rewards_max            6149.757251866341
total_rewards_min            5692.0042133815305
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.56630276190117
(Previous) Eval Time (s)     28.598134248983115
Sample Time (s)              22.832471795380116
Epoch Time (s)               82.9969088062644
Total Train Time (s)         5956.226402248722
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:15.247720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Epoch Duration: 83.00365734100342
2020-01-11 11:10:15.247894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0972707
Z variance train             0.014099918
KL Divergence                29.420046
KL Loss                      2.9420047
QF Loss                      461.50885
VF Loss                      271.8603
Policy Loss                  -1784.0004
Q Predictions Mean           1783.7297
Q Predictions Std            552.6394
Q Predictions Max            2333.5005
Q Predictions Min            230.09521
V Predictions Mean           1796.0752
V Predictions Std            544.9087
V Predictions Max            2347.072
V Predictions Min            245.54745
Log Pis Mean                 1.9477649
Log Pis Std                  4.199779
Log Pis Max                  14.339385
Log Pis Min                  -6.7605777
Policy mu Mean               -0.037640553
Policy mu Std                1.1457485
Policy mu Max                3.0470953
Policy mu Min                -2.753489
Policy log std Mean          -0.61021596
Policy log std Std           0.3413965
Policy log std Max           0.025689691
Policy log std Min           -2.3181841
Z mean eval                  2.0871596
Z variance eval              0.013581817
total_rewards                [5974.04276412 6191.01186975 6114.12244729 6189.82039446 6127.6343554
 6250.41691344 5948.62286841 5896.37577379 6106.6098375  6091.92340038]
total_rewards_mean           6089.058062453961
total_rewards_std            109.1301795278632
total_rewards_max            6250.416913438549
total_rewards_min            5896.37577379083
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               31.23246879922226
(Previous) Eval Time (s)     28.604533900041133
Sample Time (s)              23.01376499934122
Epoch Time (s)               82.85076769860461
Total Train Time (s)         6037.607088102493
Epoch                        72
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:36.629887 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Epoch Duration: 81.38185834884644
2020-01-11 11:11:36.630064 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.088297
Z variance train             0.013584899
KL Divergence                28.712194
KL Loss                      2.8712194
QF Loss                      287.73566
VF Loss                      144.98694
Policy Loss                  -1673.5808
Q Predictions Mean           1670.3284
Q Predictions Std            628.2927
Q Predictions Max            2254.8298
Q Predictions Min            178.31087
V Predictions Mean           1671.5623
V Predictions Std            624.9462
V Predictions Max            2256.1465
V Predictions Min            219.47527
Log Pis Mean                 2.0107691
Log Pis Std                  4.381879
Log Pis Max                  15.139852
Log Pis Min                  -6.461306
Policy mu Mean               -0.033444766
Policy mu Std                1.132883
Policy mu Max                3.4174132
Policy mu Min                -3.2109635
Policy log std Mean          -0.59144944
Policy log std Std           0.34043708
Policy log std Max           0.39829198
Policy log std Min           -2.10734
Z mean eval                  2.0855472
Z variance eval              0.015771419
total_rewards                [6056.13538551 6167.55110991 6033.90178203 6301.03925415 6251.3457514
 6335.30321597 6088.39541447 5996.39485228 6234.37438629 6131.39362046]
total_rewards_mean           6159.583477249113
total_rewards_std            111.33506788975154
total_rewards_max            6335.303215971844
total_rewards_min            5996.394852284366
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               32.028457100037485
(Previous) Eval Time (s)     27.13530923705548
Sample Time (s)              22.40794648276642
Epoch Time (s)               81.57171281985939
Total Train Time (s)         6120.496538940817
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:59.521316 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Epoch Duration: 82.89111423492432
2020-01-11 11:12:59.521507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0829456
Z variance train             0.015787052
KL Divergence                28.38974
KL Loss                      2.838974
QF Loss                      317.6906
VF Loss                      375.7648
Policy Loss                  -1620.8213
Q Predictions Mean           1623.8385
Q Predictions Std            696.7949
Q Predictions Max            2369.4626
Q Predictions Min            216.99594
V Predictions Mean           1638.0404
V Predictions Std            696.613
V Predictions Max            2362.8857
V Predictions Min            220.73717
Log Pis Mean                 1.7844996
Log Pis Std                  4.4231963
Log Pis Max                  14.945031
Log Pis Min                  -6.8453064
Policy mu Mean               -0.053721216
Policy mu Std                1.1366625
Policy mu Max                2.8887918
Policy mu Min                -2.7730458
Policy log std Mean          -0.57496405
Policy log std Std           0.34069622
Policy log std Max           -0.0013042092
Policy log std Min           -2.1682572
Z mean eval                  2.097365
Z variance eval              0.022150425
total_rewards                [6038.06150055 6193.7584051  6220.37264466 6192.43709363 6006.72631192
 6345.80159439 6213.56403154 6114.60211506 6161.20930186 6430.97391217]
total_rewards_mean           6191.7506910888505
total_rewards_std            121.2427473444249
total_rewards_max            6430.973912168036
total_rewards_min            6006.726311922985
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               31.83042331971228
(Previous) Eval Time (s)     28.45436543179676
Sample Time (s)              22.582369415089488
Epoch Time (s)               82.86715816659853
Total Train Time (s)         6203.157266685739
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:22.183696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Epoch Duration: 82.66202521324158
2020-01-11 11:14:22.183910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0953338
Z variance train             0.022086024
KL Divergence                28.051376
KL Loss                      2.8051376
QF Loss                      421.44403
VF Loss                      229.32138
Policy Loss                  -1776.8141
Q Predictions Mean           1769.3373
Q Predictions Std            620.0654
Q Predictions Max            2452.779
Q Predictions Min            211.99585
V Predictions Mean           1776.9658
V Predictions Std            614.4709
V Predictions Max            2475.5444
V Predictions Min            229.39946
Log Pis Mean                 2.5029273
Log Pis Std                  4.3813357
Log Pis Max                  14.084156
Log Pis Min                  -6.784932
Policy mu Mean               -0.074602894
Policy mu Std                1.1695241
Policy mu Max                2.9728124
Policy mu Min                -2.7080154
Policy log std Mean          -0.61930066
Policy log std Std           0.34025046
Policy log std Max           -0.07641886
Policy log std Min           -2.2160373
Z mean eval                  2.0955396
Z variance eval              0.0211276
total_rewards                [6165.01297531 6312.28054688 6341.73892246 6417.61135302 6256.36372655
 6222.39087414 6334.98757824 6399.51301628 6470.16498208 6322.76446655]
total_rewards_mean           6324.282844149853
total_rewards_std            87.5093854142323
total_rewards_max            6470.164982077686
total_rewards_min            6165.012975305183
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               31.772151921875775
(Previous) Eval Time (s)     28.248885050415993
Sample Time (s)              21.256525094620883
Epoch Time (s)               81.27756206691265
Total Train Time (s)         6284.550940855872
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:43.579727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Epoch Duration: 81.39562821388245
2020-01-11 11:15:43.580017 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0933452
Z variance train             0.021007104
KL Divergence                27.855131
KL Loss                      2.7855132
QF Loss                      301.0777
VF Loss                      175.91002
Policy Loss                  -1779.442
Q Predictions Mean           1781.8313
Q Predictions Std            647.4751
Q Predictions Max            2431.0156
Q Predictions Min            219.37886
V Predictions Mean           1787.7917
V Predictions Std            647.04486
V Predictions Max            2419.649
V Predictions Min            227.01611
Log Pis Mean                 2.3321924
Log Pis Std                  4.285305
Log Pis Max                  14.23316
Log Pis Min                  -5.962763
Policy mu Mean               -0.030345224
Policy mu Std                1.1766378
Policy mu Max                3.1160839
Policy mu Min                -2.8929005
Policy log std Mean          -0.5947221
Policy log std Std           0.3514268
Policy log std Max           -0.03581506
Policy log std Min           -2.228064
Z mean eval                  2.1001167
Z variance eval              0.018153023
total_rewards                [6396.82240901 6307.51128099 6299.97775389 6509.21459477 6399.50105621
 6093.45598631 6262.57056864 6332.32633919 6439.37777647 6477.85041857]
total_rewards_mean           6351.860818403792
total_rewards_std            115.05219720189389
total_rewards_max            6509.214594767351
total_rewards_min            6093.455986306117
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               32.28954933490604
(Previous) Eval Time (s)     28.36658034613356
Sample Time (s)              21.985120948404074
Epoch Time (s)               82.64125062944368
Total Train Time (s)         6367.242208614945
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:06.272411 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Epoch Duration: 82.69216871261597
2020-01-11 11:17:06.272635 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1020591
Z variance train             0.018251449
KL Divergence                28.486172
KL Loss                      2.8486173
QF Loss                      380.73248
VF Loss                      159.18684
Policy Loss                  -1789.928
Q Predictions Mean           1786.756
Q Predictions Std            624.2061
Q Predictions Max            2396.669
Q Predictions Min            219.85318
V Predictions Mean           1789.7229
V Predictions Std            623.6722
V Predictions Max            2400.4697
V Predictions Min            206.69519
Log Pis Mean                 2.0871572
Log Pis Std                  4.254151
Log Pis Max                  15.729063
Log Pis Min                  -6.958583
Policy mu Mean               -0.02815026
Policy mu Std                1.1589617
Policy mu Max                2.9010863
Policy mu Min                -2.958884
Policy log std Mean          -0.59529036
Policy log std Std           0.3398196
Policy log std Max           -0.06713654
Policy log std Min           -2.2132566
Z mean eval                  2.1066844
Z variance eval              0.016813211
total_rewards                [6496.52623913 6591.85177837 6569.42270709 6098.36901669 6464.48388517
 6701.31683893 6480.2497233  6434.90569056 6448.79880998 6390.03749129]
total_rewards_mean           6467.5962180509505
total_rewards_std            150.068732970856
total_rewards_max            6701.316838927655
total_rewards_min            6098.369016687215
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.142293139360845
(Previous) Eval Time (s)     28.417192582972348
Sample Time (s)              22.83404496172443
Epoch Time (s)               82.39353068405762
Total Train Time (s)         6447.94673908269
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:26.978911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Epoch Duration: 80.70609283447266
2020-01-11 11:18:26.979288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1067314
Z variance train             0.016856857
KL Divergence                28.803871
KL Loss                      2.880387
QF Loss                      389.25513
VF Loss                      176.45143
Policy Loss                  -1875.2975
Q Predictions Mean           1872.6464
Q Predictions Std            547.9376
Q Predictions Max            2413.548
Q Predictions Min            161.21803
V Predictions Mean           1871.4536
V Predictions Std            545.42053
V Predictions Max            2427.1062
V Predictions Min            214.08049
Log Pis Mean                 2.3561518
Log Pis Std                  4.365781
Log Pis Max                  15.383451
Log Pis Min                  -8.819117
Policy mu Mean               -0.046467345
Policy mu Std                1.1826154
Policy mu Max                3.1466222
Policy mu Min                -3.6537957
Policy log std Mean          -0.6178339
Policy log std Std           0.35264978
Policy log std Max           0.06282872
Policy log std Min           -2.2314305
Z mean eval                  2.0777872
Z variance eval              0.024229335
total_rewards                [6462.08451885 6486.22193854 6263.60969888 6443.50471603 6422.35798863
 6451.67359546 6474.77611572 6229.02328472 6347.49653079 6426.39904059]
total_rewards_mean           6400.71474282173
total_rewards_std            85.57256835475307
total_rewards_max            6486.22193853989
total_rewards_min            6229.023284715592
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               31.590394223108888
(Previous) Eval Time (s)     26.72938992269337
Sample Time (s)              22.737240285612643
Epoch Time (s)               81.0570244314149
Total Train Time (s)         6530.1892535244115
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:49.222828 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Epoch Duration: 82.2432861328125
2020-01-11 11:19:49.223032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0770366
Z variance train             0.02424673
KL Divergence                27.59309
KL Loss                      2.759309
QF Loss                      336.47437
VF Loss                      157.20813
Policy Loss                  -1779.4272
Q Predictions Mean           1773.571
Q Predictions Std            651.49774
Q Predictions Max            2512.0935
Q Predictions Min            222.51367
V Predictions Mean           1779.9452
V Predictions Std            647.31744
V Predictions Max            2514.0007
V Predictions Min            217.52129
Log Pis Mean                 2.40904
Log Pis Std                  4.404644
Log Pis Max                  13.6718025
Log Pis Min                  -6.7849283
Policy mu Mean               -0.07350745
Policy mu Std                1.1917588
Policy mu Max                3.254386
Policy mu Min                -2.7481205
Policy log std Mean          -0.6126142
Policy log std Std           0.34092745
Policy log std Max           0.01766634
Policy log std Min           -2.27721
Z mean eval                  2.0973535
Z variance eval              0.02116807
total_rewards                [6485.55220137 6711.74806887 6354.84641704 6560.31175036 6576.22259422
 6551.25041772 6563.85525369 6672.28597527 6444.87322902 6563.53562426]
total_rewards_mean           6548.448153181422
total_rewards_std            97.75121189992925
total_rewards_max            6711.748068870518
total_rewards_min            6354.846417039762
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               32.33784643094987
(Previous) Eval Time (s)     27.915332227014005
Sample Time (s)              22.642516432795674
Epoch Time (s)               82.89569509075955
Total Train Time (s)         6612.682141779456
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:11.717466 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Epoch Duration: 82.49427723884583
2020-01-11 11:21:11.717661 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0967438
Z variance train             0.021209795
KL Divergence                28.727974
KL Loss                      2.8727975
QF Loss                      518.7213
VF Loss                      130.17665
Policy Loss                  -1846.8888
Q Predictions Mean           1840.259
Q Predictions Std            608.31757
Q Predictions Max            2457.4092
Q Predictions Min            218.85968
V Predictions Mean           1845.5198
V Predictions Std            608.83026
V Predictions Max            2455.9893
V Predictions Min            214.42593
Log Pis Mean                 2.209661
Log Pis Std                  4.5332227
Log Pis Max                  15.467663
Log Pis Min                  -6.444452
Policy mu Mean               -0.08669285
Policy mu Std                1.1741309
Policy mu Max                2.7243667
Policy mu Min                -3.0644083
Policy log std Mean          -0.6135056
Policy log std Std           0.34137842
Policy log std Max           -0.03082177
Policy log std Min           -2.2224193
Z mean eval                  2.1182961
Z variance eval              0.017575603
total_rewards                [6584.50745257 6430.3114182  6506.28525856 6594.6324448  6535.42465627
 6454.55311118 6625.09571204 6532.69686149 6679.12758733 6481.70395329]
total_rewards_mean           6542.433845572608
total_rewards_std            74.46226246962519
total_rewards_max            6679.127587328068
total_rewards_min            6430.311418204361
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.64458189206198
(Previous) Eval Time (s)     27.51359796896577
Sample Time (s)              22.06374857062474
Epoch Time (s)               81.22192843165249
Total Train Time (s)         6694.514301301446
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:33.552764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Epoch Duration: 81.8349404335022
2020-01-11 11:22:33.553001 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1188369
Z variance train             0.017597403
KL Divergence                29.537905
KL Loss                      2.9537904
QF Loss                      401.2291
VF Loss                      179.031
Policy Loss                  -1853.7913
Q Predictions Mean           1852.9116
Q Predictions Std            668.46277
Q Predictions Max            2551.4937
Q Predictions Min            214.47496
V Predictions Mean           1852.5505
V Predictions Std            663.68567
V Predictions Max            2545.7922
V Predictions Min            219.05602
Log Pis Mean                 2.6887329
Log Pis Std                  4.493025
Log Pis Max                  15.113478
Log Pis Min                  -7.182695
Policy mu Mean               -0.052093964
Policy mu Std                1.2008934
Policy mu Max                2.7003493
Policy mu Min                -2.8021836
Policy log std Mean          -0.6244492
Policy log std Std           0.33620277
Policy log std Max           -0.007921994
Policy log std Min           -2.1131406
Z mean eval                  2.1144593
Z variance eval              0.018258236
total_rewards                [6523.77573713 6560.98857927 6468.41986991 6551.11268241 6559.73390812
 6739.11281117 6625.51859199 6325.59097589 6571.0135313  6502.80981734]
total_rewards_mean           6542.807650452154
total_rewards_std            100.76560504299825
total_rewards_max            6739.112811168114
total_rewards_min            6325.590975889167
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.75899184588343
(Previous) Eval Time (s)     28.12618798390031
Sample Time (s)              22.837701288051903
Epoch Time (s)               82.72288111783564
Total Train Time (s)         6777.165078229271
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:56.205335 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Epoch Duration: 82.65216112136841
2020-01-11 11:23:56.205542 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.113205
Z variance train             0.0182937
KL Divergence                29.402794
KL Loss                      2.9402795
QF Loss                      677.991
VF Loss                      150.39099
Policy Loss                  -1852.6014
Q Predictions Mean           1848.2668
Q Predictions Std            645.3081
Q Predictions Max            2485.9106
Q Predictions Min            194.89334
V Predictions Mean           1854.8942
V Predictions Std            637.1705
V Predictions Max            2516.4905
V Predictions Min            211.51683
Log Pis Mean                 2.3673987
Log Pis Std                  4.5556006
Log Pis Max                  15.93849
Log Pis Min                  -7.33017
Policy mu Mean               -0.09343714
Policy mu Std                1.2288659
Policy mu Max                3.5613308
Policy mu Min                -3.1131883
Policy log std Mean          -0.62361574
Policy log std Std           0.3313539
Policy log std Max           -0.00787735
Policy log std Min           -2.2958403
Z mean eval                  2.1065998
Z variance eval              0.020310437
total_rewards                [6379.90688631 6643.80982193 6462.67493711 6873.78047488 6897.02683891
 6781.95437331 6875.60188093 7167.73572092 6912.18550762 6491.93771956]
total_rewards_mean           6748.661416147399
total_rewards_std            234.93017350029933
total_rewards_max            7167.73572091989
total_rewards_min            6379.9068863074035
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               31.787185475230217
(Previous) Eval Time (s)     28.055093235801905
Sample Time (s)              23.236125783994794
Epoch Time (s)               83.07840449502692
Total Train Time (s)         6859.8750419127755
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:18.915651 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Epoch Duration: 82.70996618270874
2020-01-11 11:25:18.915823 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1092575
Z variance train             0.02032469
KL Divergence                28.854057
KL Loss                      2.8854058
QF Loss                      532.5845
VF Loss                      407.4976
Policy Loss                  -1846.4158
Q Predictions Mean           1835.4927
Q Predictions Std            725.7744
Q Predictions Max            2618.6304
Q Predictions Min            207.80984
V Predictions Mean           1829.6224
V Predictions Std            720.9508
V Predictions Max            2602.0237
V Predictions Min            214.03217
Log Pis Mean                 2.4140263
Log Pis Std                  4.3602095
Log Pis Max                  14.18362
Log Pis Min                  -6.7119536
Policy mu Mean               -0.04896359
Policy mu Std                1.1768855
Policy mu Max                3.402853
Policy mu Min                -2.7629507
Policy log std Mean          -0.6067989
Policy log std Std           0.33346012
Policy log std Max           -0.0036138296
Policy log std Min           -2.0050826
Z mean eval                  2.0886703
Z variance eval              0.031356927
total_rewards                [6798.20100136 6671.60454175 6792.0939159  6777.29104147 6715.5205953
 6910.66600738 6829.47753105 6521.86882741 6857.65240796 6633.00851318]
total_rewards_mean           6750.738438275839
total_rewards_std            110.28117892348645
total_rewards_max            6910.666007380107
total_rewards_min            6521.868827412861
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               31.3283561039716
(Previous) Eval Time (s)     27.68636200018227
Sample Time (s)              22.175486393272877
Epoch Time (s)               81.19020449742675
Total Train Time (s)         6939.923338152468
Epoch                        83
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:38.966105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Epoch Duration: 80.05014610290527
2020-01-11 11:26:38.966293 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0884247
Z variance train             0.03130274
KL Divergence                28.087553
KL Loss                      2.8087554
QF Loss                      249.94194
VF Loss                      114.77025
Policy Loss                  -1871.5049
Q Predictions Mean           1869.6436
Q Predictions Std            728.095
Q Predictions Max            2617.8857
Q Predictions Min            205.44496
V Predictions Mean           1869.1597
V Predictions Std            726.2737
V Predictions Max            2616.3254
V Predictions Min            210.04489
Log Pis Mean                 2.4130554
Log Pis Std                  4.5925326
Log Pis Max                  15.929441
Log Pis Min                  -6.2246084
Policy mu Mean               -0.080102876
Policy mu Std                1.1873438
Policy mu Max                2.8691845
Policy mu Min                -3.1432986
Policy log std Mean          -0.6100736
Policy log std Std           0.36573324
Policy log std Max           0.012500346
Policy log std Min           -2.3621314
Z mean eval                  2.099985
Z variance eval              0.028327515
total_rewards                [6630.99073372 6538.98417365 6588.57398212 6710.33546421 6432.11691934
 6603.29084294 6576.92622231 6442.99878831 6614.86910876 6377.62436887]
total_rewards_mean           6551.671060422637
total_rewards_std            98.32614657645769
total_rewards_max            6710.335464206322
total_rewards_min            6377.624368867579
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               31.678121712990105
(Previous) Eval Time (s)     26.545996421016753
Sample Time (s)              22.391425173729658
Epoch Time (s)               80.61554330773652
Total Train Time (s)         7021.8484479291365
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:00.892404 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Epoch Duration: 81.92596220970154
2020-01-11 11:28:00.892582 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1018925
Z variance train             0.028330058
KL Divergence                28.093094
KL Loss                      2.8093095
QF Loss                      1451.8175
VF Loss                      120.89322
Policy Loss                  -1945.1616
Q Predictions Mean           1954.598
Q Predictions Std            637.1124
Q Predictions Max            2620.242
Q Predictions Min            212.45891
V Predictions Mean           1950.2878
V Predictions Std            634.9307
V Predictions Max            2606.7793
V Predictions Min            208.37622
Log Pis Mean                 2.3047783
Log Pis Std                  4.57508
Log Pis Max                  17.197739
Log Pis Min                  -6.2794724
Policy mu Mean               -0.16298713
Policy mu Std                1.1618208
Policy mu Max                2.8657908
Policy mu Min                -3.015986
Policy log std Mean          -0.6190343
Policy log std Std           0.3543062
Policy log std Max           -0.021057993
Policy log std Min           -2.3900938
Z mean eval                  2.1140022
Z variance eval              0.02110885
total_rewards                [6760.27941642 6742.98074972 6707.65063711 6679.25113666 6696.190642
 6855.21397432 6731.10085851 6855.74330612 6789.23215351 6830.71572654]
total_rewards_mean           6764.835860090473
total_rewards_std            61.89605896203413
total_rewards_max            6855.743306124078
total_rewards_min            6679.251136658741
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               31.777977966703475
(Previous) Eval Time (s)     27.85612461809069
Sample Time (s)              22.522625032346696
Epoch Time (s)               82.15672761714086
Total Train Time (s)         7103.869797238149
Epoch                        85
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:22.914260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Epoch Duration: 82.02155041694641
2020-01-11 11:29:22.914406 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112228
Z variance train             0.021010736
KL Divergence                28.432049
KL Loss                      2.843205
QF Loss                      362.76715
VF Loss                      262.61792
Policy Loss                  -1937.0385
Q Predictions Mean           1936.4425
Q Predictions Std            690.8804
Q Predictions Max            2690.564
Q Predictions Min            191.97372
V Predictions Mean           1944.2379
V Predictions Std            684.3185
V Predictions Max            2680.6792
V Predictions Min            210.49422
Log Pis Mean                 2.432567
Log Pis Std                  4.0059767
Log Pis Max                  13.010123
Log Pis Min                  -6.674517
Policy mu Mean               -0.081043266
Policy mu Std                1.1618865
Policy mu Max                3.1702826
Policy mu Min                -2.7782154
Policy log std Mean          -0.6273359
Policy log std Std           0.348233
Policy log std Max           0.05909407
Policy log std Min           -2.234322
Z mean eval                  2.1126835
Z variance eval              0.018164866
total_rewards                [6839.03810333 6555.95161584 6741.67534627 6702.73312704 6481.94097652
 6802.65686198 2412.43893181 6631.2685094  6659.46165728 6629.65464334]
total_rewards_mean           6245.681977281837
total_rewards_std            1281.809701347207
total_rewards_max            6839.038103334925
total_rewards_min            2412.438931811393
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.26047171698883
(Previous) Eval Time (s)     27.720649952068925
Sample Time (s)              21.086291301529855
Epoch Time (s)               80.06741297058761
Total Train Time (s)         7183.523848954588
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:42.573019 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Epoch Duration: 79.65839886665344
2020-01-11 11:30:42.573401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122093
Z variance train             0.018192524
KL Divergence                27.948612
KL Loss                      2.7948613
QF Loss                      475.8467
VF Loss                      118.64786
Policy Loss                  -1915.0682
Q Predictions Mean           1908.3127
Q Predictions Std            684.91095
Q Predictions Max            2626.552
Q Predictions Min            194.20831
V Predictions Mean           1911.2839
V Predictions Std            677.7635
V Predictions Max            2614.6887
V Predictions Min            201.56479
Log Pis Mean                 2.7419057
Log Pis Std                  4.2740397
Log Pis Max                  13.172458
Log Pis Min                  -6.4256954
Policy mu Mean               -0.06695369
Policy mu Std                1.2126532
Policy mu Max                2.609532
Policy mu Min                -2.8924427
Policy log std Mean          -0.5986962
Policy log std Std           0.3265152
Policy log std Max           0.03910461
Policy log std Min           -2.280141
Z mean eval                  2.1120822
Z variance eval              0.017669603
total_rewards                [6767.18419889 6949.36941714 6603.08756659 6880.87454639 6818.82063983
 6861.73579043 6695.86394742 7048.37480728 6714.21383405 6784.25004562]
total_rewards_mean           6812.377479363035
total_rewards_std            123.07659902729091
total_rewards_max            7048.374807279032
total_rewards_min            6603.087566592673
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               31.77444492187351
(Previous) Eval Time (s)     27.311299308668822
Sample Time (s)              23.21236277744174
Epoch Time (s)               82.29810700798407
Total Train Time (s)         7266.471374774817
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:05.521085 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Epoch Duration: 82.94746780395508
2020-01-11 11:32:05.521285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124923
Z variance train             0.017688561
KL Divergence                28.207996
KL Loss                      2.8207996
QF Loss                      466.57025
VF Loss                      214.30792
Policy Loss                  -1963.8219
Q Predictions Mean           1958.6404
Q Predictions Std            730.1865
Q Predictions Max            2711.2788
Q Predictions Min            196.43704
V Predictions Mean           1954.2266
V Predictions Std            726.26306
V Predictions Max            2697.0273
V Predictions Min            204.41394
Log Pis Mean                 2.8433022
Log Pis Std                  4.665374
Log Pis Max                  15.240866
Log Pis Min                  -6.678838
Policy mu Mean               -0.08147884
Policy mu Std                1.2410358
Policy mu Max                3.1264265
Policy mu Min                -2.8271646
Policy log std Mean          -0.60500544
Policy log std Std           0.3651821
Policy log std Max           0.04102108
Policy log std Min           -2.2579112
Z mean eval                  2.1097808
Z variance eval              0.018948661
total_rewards                [6801.84851859 6812.16330308 6831.3982109  6889.64659081 6770.77880587
 6861.66577564 6805.52559288 6784.80240836 6722.74975077 6558.204185  ]
total_rewards_mean           6783.878314191641
total_rewards_std            87.13523771701067
total_rewards_max            6889.6465908081445
total_rewards_min            6558.204184998341
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               32.00230955518782
(Previous) Eval Time (s)     27.96031287126243
Sample Time (s)              22.048906228970736
Epoch Time (s)               82.01152865542099
Total Train Time (s)         7349.015656871721
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:28.067536 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Epoch Duration: 82.54603695869446
2020-01-11 11:33:28.067830 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.110106
Z variance train             0.018981364
KL Divergence                27.951036
KL Loss                      2.7951038
QF Loss                      506.87244
VF Loss                      153.84172
Policy Loss                  -2052.2905
Q Predictions Mean           2055.8228
Q Predictions Std            601.44
Q Predictions Max            2659.5276
Q Predictions Min            192.12689
V Predictions Mean           2056.56
V Predictions Std            596.3299
V Predictions Max            2655.185
V Predictions Min            201.69096
Log Pis Mean                 2.9147983
Log Pis Std                  3.9191172
Log Pis Max                  13.768966
Log Pis Min                  -6.5295362
Policy mu Mean               -0.007997685
Policy mu Std                1.2457504
Policy mu Max                3.5480807
Policy mu Min                -2.9732943
Policy log std Mean          -0.6226627
Policy log std Std           0.3603897
Policy log std Max           0.04567063
Policy log std Min           -2.1778457
Z mean eval                  2.1118426
Z variance eval              0.017422507
total_rewards                [6714.87013567 6884.98832926 7042.79497826 6684.55038662 6934.30109752
 6817.73004192 6931.20631787 6745.69504787 6900.6793934  6812.53539134]
total_rewards_mean           6846.93511197147
total_rewards_std            106.54943378546048
total_rewards_max            7042.7949782627975
total_rewards_min            6684.550386618351
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               31.466287653893232
(Previous) Eval Time (s)     28.494518701918423
Sample Time (s)              22.495821324177086
Epoch Time (s)               82.45662767998874
Total Train Time (s)         7431.434999479912
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:50.488458 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Epoch Duration: 82.42046403884888
2020-01-11 11:34:50.488647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112128
Z variance train             0.0174337
KL Divergence                28.180244
KL Loss                      2.8180244
QF Loss                      835.49347
VF Loss                      210.00035
Policy Loss                  -2045.658
Q Predictions Mean           2043.8903
Q Predictions Std            622.3102
Q Predictions Max            2718.1814
Q Predictions Min            197.03322
V Predictions Mean           2049.2231
V Predictions Std            617.7603
V Predictions Max            2730.426
V Predictions Min            199.60341
Log Pis Mean                 3.227231
Log Pis Std                  4.425824
Log Pis Max                  16.957983
Log Pis Min                  -6.6081724
Policy mu Mean               -0.055796485
Policy mu Std                1.2466598
Policy mu Max                4.330242
Policy mu Min                -2.9449768
Policy log std Mean          -0.6300986
Policy log std Std           0.3576951
Policy log std Max           0.03934647
Policy log std Min           -2.2321386
Z mean eval                  2.1186893
Z variance eval              0.017611785
total_rewards                [6813.48761313 6888.99163258 6868.36802793 7026.66711728 6733.32457812
 6878.95312789 6578.33334946 7078.17181731 6755.71313242 6867.10103369]
total_rewards_mean           6848.911142980379
total_rewards_std            135.6058052438946
total_rewards_max            7078.1718173113
total_rewards_min            6578.333349457154
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               32.455909995827824
(Previous) Eval Time (s)     28.45807777205482
Sample Time (s)              23.124376366380602
Epoch Time (s)               84.03836413426325
Total Train Time (s)         7513.782491726801
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:12.837426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Epoch Duration: 82.34864473342896
2020-01-11 11:36:12.837620 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1175394
Z variance train             0.01759595
KL Divergence                27.9471
KL Loss                      2.79471
QF Loss                      287.48227
VF Loss                      91.46337
Policy Loss                  -2007.4587
Q Predictions Mean           2006.3157
Q Predictions Std            735.9497
Q Predictions Max            2759.633
Q Predictions Min            193.59557
V Predictions Mean           2004.6622
V Predictions Std            732.506
V Predictions Max            2738.8313
V Predictions Min            199.29922
Log Pis Mean                 2.6386476
Log Pis Std                  4.3377843
Log Pis Max                  13.914677
Log Pis Min                  -6.6948643
Policy mu Mean               -0.107962035
Policy mu Std                1.1910582
Policy mu Max                2.5565758
Policy mu Min                -2.6055024
Policy log std Mean          -0.6202526
Policy log std Std           0.35530874
Policy log std Max           0.056209266
Policy log std Min           -2.2930908
Z mean eval                  2.1202505
Z variance eval              0.013820967
total_rewards                [6779.09597663 7175.07871727 7330.15553361 7034.34727864 7026.51673566
 7067.17853818 7008.28033393 7209.93594539 6747.74496621 7007.16710751]
total_rewards_mean           7038.550113303012
total_rewards_std            169.6508686120331
total_rewards_max            7330.155533606854
total_rewards_min            6747.744966214429
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.23511420702562
(Previous) Eval Time (s)     26.76800780603662
Sample Time (s)              22.1454661404714
Epoch Time (s)               81.14858815353364
Total Train Time (s)         7596.685723581351
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:35.742533 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Epoch Duration: 82.90476846694946
2020-01-11 11:37:35.742737 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1204176
Z variance train             0.013808973
KL Divergence                28.360386
KL Loss                      2.8360386
QF Loss                      288.9018
VF Loss                      175.24768
Policy Loss                  -2019.5417
Q Predictions Mean           2013.7673
Q Predictions Std            714.5852
Q Predictions Max            2774.7124
Q Predictions Min            197.85751
V Predictions Mean           2011.8303
V Predictions Std            711.487
V Predictions Max            2777.704
V Predictions Min            192.47272
Log Pis Mean                 2.6169648
Log Pis Std                  4.2280393
Log Pis Max                  14.41494
Log Pis Min                  -6.1153097
Policy mu Mean               -0.06642738
Policy mu Std                1.1828641
Policy mu Max                3.0285776
Policy mu Min                -3.0315902
Policy log std Mean          -0.62903917
Policy log std Std           0.35726207
Policy log std Max           0.021601051
Policy log std Min           -2.2929173
Z mean eval                  2.1172786
Z variance eval              0.011871544
total_rewards                [6983.63347062 6778.27900534 6912.16333077 6863.20215314 6803.55488877
 6912.60340925 6486.79388735 7045.45568998 6738.74531046 6868.63059816]
total_rewards_mean           6839.306174385197
total_rewards_std            146.56720314263478
total_rewards_max            7045.455689981259
total_rewards_min            6486.793887354033
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               31.687888253014535
(Previous) Eval Time (s)     28.52386320894584
Sample Time (s)              23.23496784735471
Epoch Time (s)               83.44671930931509
Total Train Time (s)         7679.566983580124
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:58.625772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Epoch Duration: 82.88286972045898
2020-01-11 11:38:58.626028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1174304
Z variance train             0.011867834
KL Divergence                28.786076
KL Loss                      2.8786075
QF Loss                      445.09286
VF Loss                      276.53772
Policy Loss                  -2063.1572
Q Predictions Mean           2056.5977
Q Predictions Std            654.83716
Q Predictions Max            2736.2563
Q Predictions Min            178.22464
V Predictions Mean           2055.3574
V Predictions Std            651.06537
V Predictions Max            2759.9446
V Predictions Min            183.11778
Log Pis Mean                 2.8057919
Log Pis Std                  4.4714513
Log Pis Max                  16.774456
Log Pis Min                  -7.1423755
Policy mu Mean               -0.13472456
Policy mu Std                1.2428132
Policy mu Max                2.738569
Policy mu Min                -2.9618506
Policy log std Mean          -0.6322445
Policy log std Std           0.3479886
Policy log std Max           0.0012553483
Policy log std Min           -2.2436156
Z mean eval                  2.1072001
Z variance eval              0.008850307
total_rewards                [6715.22586402 6805.25555951 7102.4767276  6865.50750782 4256.57998419
 6900.19411248 7139.03480449 6662.16356179 7095.34320911 6910.89199455]
total_rewards_mean           6645.267332557145
total_rewards_std            810.9295937733664
total_rewards_max            7139.034804488825
total_rewards_min            4256.579984193225
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               32.32762238429859
(Previous) Eval Time (s)     27.95968560082838
Sample Time (s)              22.991132081951946
Epoch Time (s)               83.27844006707892
Total Train Time (s)         7761.746618331876
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:20.807412 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Epoch Duration: 82.18122458457947
2020-01-11 11:40:20.807636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1078668
Z variance train             0.008865264
KL Divergence                29.469751
KL Loss                      2.9469752
QF Loss                      327.32654
VF Loss                      123.76684
Policy Loss                  -2007.035
Q Predictions Mean           2007.781
Q Predictions Std            749.353
Q Predictions Max            2741.1887
Q Predictions Min            186.55022
V Predictions Mean           2003.5571
V Predictions Std            746.2945
V Predictions Max            2705.4775
V Predictions Min            188.93533
Log Pis Mean                 2.8261132
Log Pis Std                  4.3259068
Log Pis Max                  15.593731
Log Pis Min                  -4.9157553
Policy mu Mean               -0.043644857
Policy mu Std                1.2247381
Policy mu Max                2.8771842
Policy mu Min                -3.3189218
Policy log std Mean          -0.6332294
Policy log std Std           0.36702898
Policy log std Max           -0.033600748
Policy log std Min           -2.2837336
Z mean eval                  2.1191444
Z variance eval              0.008026131
total_rewards                [6835.60011343 6733.46879938 7050.80796047 6929.79503593 6789.21743635
 6838.60736755 6934.29373986 6970.26275832 6822.22251711 6962.67082431]
total_rewards_mean           6886.69465527071
total_rewards_std            92.66723578910506
total_rewards_max            7050.807960468956
total_rewards_min            6733.468799378648
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               31.791734471917152
(Previous) Eval Time (s)     26.862084524706006
Sample Time (s)              21.60929848300293
Epoch Time (s)               80.26311747962609
Total Train Time (s)         7843.161450934596
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:42.224575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Epoch Duration: 81.41675305366516
2020-01-11 11:41:42.224886 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1192627
Z variance train             0.008038575
KL Divergence                29.807312
KL Loss                      2.9807312
QF Loss                      320.82248
VF Loss                      251.53008
Policy Loss                  -2085.5803
Q Predictions Mean           2078.0361
Q Predictions Std            716.219
Q Predictions Max            2795.3025
Q Predictions Min            188.09776
V Predictions Mean           2075.9353
V Predictions Std            711.064
V Predictions Max            2792.8374
V Predictions Min            194.62733
Log Pis Mean                 2.8077197
Log Pis Std                  4.5463023
Log Pis Max                  16.072325
Log Pis Min                  -5.6628838
Policy mu Mean               -0.05699371
Policy mu Std                1.2296203
Policy mu Max                2.7341442
Policy mu Min                -2.5883276
Policy log std Mean          -0.64061135
Policy log std Std           0.37037396
Policy log std Max           -0.038245022
Policy log std Min           -2.4186273
Z mean eval                  2.1186175
Z variance eval              0.0071749003
total_rewards                [6851.31883071 7091.39425214 7224.73847447 7278.1994485  6995.87540857
 7378.25215714 7171.23371735 6852.40175692 7170.36554699 6838.76571899]
total_rewards_mean           7085.254531176998
total_rewards_std            183.0018607944202
total_rewards_max            7378.252157136382
total_rewards_min            6838.76571898508
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               31.90249383635819
(Previous) Eval Time (s)     28.01534418016672
Sample Time (s)              22.91089844563976
Epoch Time (s)               82.82873646216467
Total Train Time (s)         7925.049193513114
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:04.113324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Epoch Duration: 81.8882155418396
2020-01-11 11:43:04.113497 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1162438
Z variance train             0.0071644313
KL Divergence                30.30085
KL Loss                      3.030085
QF Loss                      464.3106
VF Loss                      220.29218
Policy Loss                  -2092.5344
Q Predictions Mean           2091.3926
Q Predictions Std            669.70264
Q Predictions Max            2793.803
Q Predictions Min            181.58452
V Predictions Mean           2097.6978
V Predictions Std            669.6082
V Predictions Max            2777.4092
V Predictions Min            181.1402
Log Pis Mean                 2.2486963
Log Pis Std                  4.134164
Log Pis Max                  13.612854
Log Pis Min                  -5.9579945
Policy mu Mean               0.0090423245
Policy mu Std                1.1739162
Policy mu Max                2.730339
Policy mu Min                -2.6667879
Policy log std Mean          -0.6431652
Policy log std Std           0.3598806
Policy log std Max           -0.054006934
Policy log std Min           -2.2048943
Z mean eval                  2.134063
Z variance eval              0.005682435
total_rewards                [7055.40523255 7177.82566413 5143.05560085 7145.24726666 6993.00954606
 3477.99877738 7009.16716847 6717.94774776 6931.86664131 6934.35264699]
total_rewards_mean           6458.587629214582
total_rewards_std            1143.0611594456557
total_rewards_max            7177.825664131643
total_rewards_min            3477.99877737707
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               31.849084697198123
(Previous) Eval Time (s)     27.07452030479908
Sample Time (s)              22.555999418720603
Epoch Time (s)               81.4796044207178
Total Train Time (s)         8006.473046441097
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:25.539054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Epoch Duration: 81.42540836334229
2020-01-11 11:44:25.539260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1371675
Z variance train             0.00568719
KL Divergence                31.357662
KL Loss                      3.1357663
QF Loss                      280.57385
VF Loss                      356.23404
Policy Loss                  -2116.6597
Q Predictions Mean           2110.7603
Q Predictions Std            686.72235
Q Predictions Max            2871.4963
Q Predictions Min            197.71082
V Predictions Mean           2101.2236
V Predictions Std            682.7245
V Predictions Max            2860.786
V Predictions Min            195.21568
Log Pis Mean                 3.4897428
Log Pis Std                  4.1962047
Log Pis Max                  14.266742
Log Pis Min                  -5.5196714
Policy mu Mean               -0.09966087
Policy mu Std                1.268674
Policy mu Max                2.8053565
Policy mu Min                -3.0533977
Policy log std Mean          -0.65864867
Policy log std Std           0.3691005
Policy log std Max           0.033157796
Policy log std Min           -2.35281
Z mean eval                  2.1503696
Z variance eval              0.0053493693
total_rewards                [7078.17292316 7240.5019635  7238.84420118 7232.5832005  7460.92613744
 6996.14090442 7006.86617906 7327.31194015 7107.67501884 7109.62599625]
total_rewards_mean           7179.864846450076
total_rewards_std            139.58505800344452
total_rewards_max            7460.926137436067
total_rewards_min            6996.140904420887
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               31.98550223885104
(Previous) Eval Time (s)     27.020043678116053
Sample Time (s)              22.074924333952367
Epoch Time (s)               81.08047025091946
Total Train Time (s)         8088.1016197912395
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:47.169939 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Epoch Duration: 81.63052868843079
2020-01-11 11:45:47.170121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.148963
Z variance train             0.0053339778
KL Divergence                31.565243
KL Loss                      3.1565244
QF Loss                      380.07614
VF Loss                      212.30496
Policy Loss                  -2134.048
Q Predictions Mean           2134.5652
Q Predictions Std            677.5153
Q Predictions Max            2860.344
Q Predictions Min            187.1003
V Predictions Mean           2143.7783
V Predictions Std            674.9054
V Predictions Max            2829.2566
V Predictions Min            184.64319
Log Pis Mean                 3.5662358
Log Pis Std                  4.3476176
Log Pis Max                  13.570621
Log Pis Min                  -7.1309032
Policy mu Mean               -0.1348129
Policy mu Std                1.2938145
Policy mu Max                3.1469343
Policy mu Min                -3.1639054
Policy log std Mean          -0.65423644
Policy log std Std           0.35299584
Policy log std Max           -0.06714463
Policy log std Min           -2.2436695
Z mean eval                  2.1320581
Z variance eval              0.004439346
total_rewards                [6892.44296666 7117.78435908 7267.55180856 6926.61496555 7159.47947329
 7104.77421176 7233.85590234 7052.7586227  6946.87606007 7134.1111035 ]
total_rewards_mean           7083.62494735283
total_rewards_std            121.31406359957607
total_rewards_max            7267.551808563098
total_rewards_min            6892.442966662097
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               31.792365617584437
(Previous) Eval Time (s)     27.569824036676437
Sample Time (s)              23.15028202859685
Epoch Time (s)               82.51247168285772
Total Train Time (s)         8170.449477254413
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:09.520762 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Epoch Duration: 82.35050177574158
2020-01-11 11:47:09.520954 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1291676
Z variance train             0.004429465
KL Divergence                32.194828
KL Loss                      3.219483
QF Loss                      450.18982
VF Loss                      631.0471
Policy Loss                  -2177.9539
Q Predictions Mean           2184.2803
Q Predictions Std            685.8927
Q Predictions Max            2875.6655
Q Predictions Min            175.13774
V Predictions Mean           2199.931
V Predictions Std            685.0158
V Predictions Max            2887.877
V Predictions Min            186.33867
Log Pis Mean                 3.176488
Log Pis Std                  4.6382437
Log Pis Max                  17.059273
Log Pis Min                  -9.317337
Policy mu Mean               -0.13251558
Policy mu Std                1.2626597
Policy mu Max                3.1459513
Policy mu Min                -2.9884877
Policy log std Mean          -0.64590496
Policy log std Std           0.3594624
Policy log std Max           -0.0053099394
Policy log std Min           -2.370951
Z mean eval                  2.131353
Z variance eval              0.0036839545
total_rewards                [6899.71682717 7320.73298889 7199.8930073  7163.88799184 6998.40959845
 7250.86717397 7302.9521925  7171.56097303 7046.77989204 7050.13059071]
total_rewards_mean           7140.493123590006
total_rewards_std            130.84768877513184
total_rewards_max            7320.732988893716
total_rewards_min            6899.716827168728
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               31.881872869096696
(Previous) Eval Time (s)     27.407501507084817
Sample Time (s)              23.42759629059583
Epoch Time (s)               82.71697066677734
Total Train Time (s)         8253.326687164139
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:32.399009 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Epoch Duration: 82.87791419029236
2020-01-11 11:48:32.399222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.131139
Z variance train             0.0036748268
KL Divergence                32.50668
KL Loss                      3.250668
QF Loss                      574.34094
VF Loss                      239.89857
Policy Loss                  -2051.0068
Q Predictions Mean           2049.7236
Q Predictions Std            790.1528
Q Predictions Max            2877.0508
Q Predictions Min            177.79305
V Predictions Mean           2058.7808
V Predictions Std            785.891
V Predictions Max            2881.9502
V Predictions Min            181.6676
Log Pis Mean                 3.212482
Log Pis Std                  4.598144
Log Pis Max                  15.460869
Log Pis Min                  -9.032459
Policy mu Mean               -0.047839742
Policy mu Std                1.2521594
Policy mu Max                3.6966214
Policy mu Min                -5.0537553
Policy log std Mean          -0.6386722
Policy log std Std           0.35279524
Policy log std Max           0.016781896
Policy log std Min           -2.2599518
Z mean eval                  2.140799
Z variance eval              0.0036377453
total_rewards                [7227.34234386 7124.43252943 7157.90265136 7008.05203563 7132.55745653
 7211.51122127 7382.11657567 7156.16241376 7208.88108197 7139.78598931]
total_rewards_mean           7174.874429879261
total_rewards_std            90.6835696865784
total_rewards_max            7382.116575672344
total_rewards_min            7008.052035634384
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               32.35200693504885
(Previous) Eval Time (s)     27.5681062489748
Sample Time (s)              22.080661674495786
Epoch Time (s)               82.00077485851943
Total Train Time (s)         8335.207479867619
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:54.281880 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Epoch Duration: 81.88250160217285
2020-01-11 11:49:54.282112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.137263
Z variance train             0.0036380868
KL Divergence                32.16594
KL Loss                      3.216594
QF Loss                      489.71283
VF Loss                      490.662
Policy Loss                  -2134.3386
Q Predictions Mean           2138.532
Q Predictions Std            714.7278
Q Predictions Max            2896.4895
Q Predictions Min            166.85074
V Predictions Mean           2152.772
V Predictions Std            714.1172
V Predictions Max            2901.6553
V Predictions Min            176.99907
Log Pis Mean                 3.1143703
Log Pis Std                  4.2532215
Log Pis Max                  13.659947
Log Pis Min                  -7.444617
Policy mu Mean               -0.073867775
Policy mu Std                1.2631724
Policy mu Max                2.997128
Policy mu Min                -2.9464452
Policy log std Mean          -0.6527584
Policy log std Std           0.36855367
Policy log std Max           0.0048601627
Policy log std Min           -2.3027902
Z mean eval                  2.1204114
Z variance eval              0.0051975
total_rewards                [7096.07603631 7304.90372859 7211.44010684 7172.73403248 7417.0705852
 7473.29884131 7046.34190952 7204.8240059  7351.21975079 7043.59483481]
total_rewards_mean           7232.150383176342
total_rewards_std            143.21968590248912
total_rewards_max            7473.298841310296
total_rewards_min            7043.594834810469
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               33.35786796268076
(Previous) Eval Time (s)     27.449537944048643
Sample Time (s)              22.00178477121517
Epoch Time (s)               82.80919067794457
Total Train Time (s)         8419.313698085956
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:18.390385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Epoch Duration: 84.10811448097229
2020-01-11 11:51:18.390611 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1169312
Z variance train             0.0052031027
KL Divergence                31.4827
KL Loss                      3.1482701
QF Loss                      346.35223
VF Loss                      169.10416
Policy Loss                  -2219.5642
Q Predictions Mean           2219.6973
Q Predictions Std            636.3301
Q Predictions Max            2940.0
Q Predictions Min            171.89912
V Predictions Mean           2226.9697
V Predictions Std            631.1763
V Predictions Max            2926.5706
V Predictions Min            182.79803
Log Pis Mean                 3.003573
Log Pis Std                  4.415983
Log Pis Max                  15.49664
Log Pis Min                  -5.2680445
Policy mu Mean               -0.07170412
Policy mu Std                1.235413
Policy mu Max                2.7958124
Policy mu Min                -2.86961
Policy log std Mean          -0.6550223
Policy log std Std           0.36406028
Policy log std Max           0.0028227568
Policy log std Min           -2.1966865
Z mean eval                  2.1211767
Z variance eval              0.010084364
total_rewards                [7037.67945928 7430.45699401 7147.78068049 7077.46946984 7320.24929776
 7245.54356773 6999.79319027 7265.97780183 7075.99664207 7047.62483679]
total_rewards_mean           7164.857194007325
total_rewards_std            135.7990332650425
total_rewards_max            7430.456994005418
total_rewards_min            6999.79319026626
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               34.44724034098908
(Previous) Eval Time (s)     28.74812363088131
Sample Time (s)              23.831363868899643
Epoch Time (s)               87.02672784077004
Total Train Time (s)         8507.310651890468
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:46.389833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Epoch Duration: 87.99907684326172
2020-01-11 11:52:46.390024 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1185086
Z variance train             0.010065323
KL Divergence                30.537508
KL Loss                      3.0537508
QF Loss                      363.68954
VF Loss                      117.62398
Policy Loss                  -2229.6921
Q Predictions Mean           2229.7937
Q Predictions Std            675.51654
Q Predictions Max            2885.7068
Q Predictions Min            178.32274
V Predictions Mean           2228.5193
V Predictions Std            674.758
V Predictions Max            2880.8413
V Predictions Min            173.64786
Log Pis Mean                 3.4511132
Log Pis Std                  4.364775
Log Pis Max                  14.622446
Log Pis Min                  -7.099739
Policy mu Mean               -0.09909111
Policy mu Std                1.2671685
Policy mu Max                2.7829292
Policy mu Min                -2.7473803
Policy log std Mean          -0.6473047
Policy log std Std           0.34630036
Policy log std Max           -0.07612109
Policy log std Min           -2.4121976
Z mean eval                  2.106296
Z variance eval              0.009802744
total_rewards                [7113.18753162 7426.62367965 7141.4547043  7345.4977043  7170.6601782
 7537.61384165 7426.6493299  7343.14136494 7083.99668239 7193.90916856]
total_rewards_mean           7278.273418551548
total_rewards_std            149.13809646831518
total_rewards_max            7537.613841654994
total_rewards_min            7083.996682387271
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               34.00727264303714
(Previous) Eval Time (s)     29.720013650134206
Sample Time (s)              24.55756931938231
Epoch Time (s)               88.28485561255366
Total Train Time (s)         8594.27070953697
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:13.351756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Epoch Duration: 86.96158695220947
2020-01-11 11:54:13.351952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1070285
Z variance train             0.009765396
KL Divergence                29.947784
KL Loss                      2.9947784
QF Loss                      338.114
VF Loss                      286.04062
Policy Loss                  -2113.373
Q Predictions Mean           2116.8232
Q Predictions Std            822.12726
Q Predictions Max            2933.0005
Q Predictions Min            185.27792
V Predictions Mean           2100.2634
V Predictions Std            818.3948
V Predictions Max            2890.8237
V Predictions Min            172.71957
Log Pis Mean                 2.7631838
Log Pis Std                  4.3388033
Log Pis Max                  14.716442
Log Pis Min                  -5.554622
Policy mu Mean               0.0071986
Policy mu Std                1.1983473
Policy mu Max                3.0830958
Policy mu Min                -2.8514168
Policy log std Mean          -0.6178236
Policy log std Std           0.36823186
Policy log std Max           -0.033277005
Policy log std Min           -2.2644005
Z mean eval                  2.1128974
Z variance eval              0.011359483
total_rewards                [7059.20889698 7427.5308194  7397.09379276 7350.16945831 7342.9628902
 7149.64614178 7305.72909953 7141.38206092 7490.09662668 7046.60521533]
total_rewards_mean           7271.042500187781
total_rewards_std            150.92828977607954
total_rewards_max            7490.0966266828955
total_rewards_min            7046.605215329578
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               34.184664546046406
(Previous) Eval Time (s)     28.39627891406417
Sample Time (s)              23.08108240040019
Epoch Time (s)               85.66202586051077
Total Train Time (s)         8680.394489575643
Epoch                        104
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:39.476173 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Epoch Duration: 86.12408566474915
2020-01-11 11:55:39.476320 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1126962
Z variance train             0.011354087
KL Divergence                29.984858
KL Loss                      2.9984858
QF Loss                      401.4806
VF Loss                      167.92606
Policy Loss                  -2196.6252
Q Predictions Mean           2197.8784
Q Predictions Std            753.9764
Q Predictions Max            2891.858
Q Predictions Min            169.8377
V Predictions Mean           2199.7842
V Predictions Std            751.18396
V Predictions Max            2887.9424
V Predictions Min            164.96953
Log Pis Mean                 3.0556073
Log Pis Std                  4.4909596
Log Pis Max                  15.20136
Log Pis Min                  -5.9642563
Policy mu Mean               -0.077390276
Policy mu Std                1.260786
Policy mu Max                3.2304842
Policy mu Min                -3.1529126
Policy log std Mean          -0.64260054
Policy log std Std           0.3673946
Policy log std Max           0.016211003
Policy log std Min           -2.4225721
Z mean eval                  2.1097214
Z variance eval              0.0081944475
total_rewards                [7495.04495877 7485.4193152  7699.20669265 7660.93403681 7601.81081139
 7453.04068446 7411.19260523 7635.50219021 7639.55123677 7627.52508351]
total_rewards_mean           7570.922761499535
total_rewards_std            94.90798099970795
total_rewards_max            7699.206692649361
total_rewards_min            7411.192605227635
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               34.14707150636241
(Previous) Eval Time (s)     28.857904695905745
Sample Time (s)              23.630060674156994
Epoch Time (s)               86.63503687642515
Total Train Time (s)         8766.770439348184
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:05.856328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Epoch Duration: 86.37984776496887
2020-01-11 11:57:05.856644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1101084
Z variance train             0.008187551
KL Divergence                30.295332
KL Loss                      3.0295331
QF Loss                      388.31555
VF Loss                      164.54356
Policy Loss                  -2255.5042
Q Predictions Mean           2246.1108
Q Predictions Std            695.3236
Q Predictions Max            2916.2031
Q Predictions Min            172.19154
V Predictions Mean           2247.1262
V Predictions Std            694.957
V Predictions Max            2906.462
V Predictions Min            163.66127
Log Pis Mean                 3.3098376
Log Pis Std                  4.6179943
Log Pis Max                  16.971157
Log Pis Min                  -6.105455
Policy mu Mean               -0.14203691
Policy mu Std                1.245393
Policy mu Max                3.0177863
Policy mu Min                -2.7432668
Policy log std Mean          -0.63918823
Policy log std Std           0.3502886
Policy log std Max           0.008238822
Policy log std Min           -2.283938
Z mean eval                  2.095262
Z variance eval              0.04059807
total_rewards                [7266.99168518 7534.22600104 7335.08284463 7265.61446801 7158.20934963
 7239.09743025 7397.50628294 7381.47335685 7208.09847981 7203.70352608]
total_rewards_mean           7299.00034244197
total_rewards_std            107.71840185543418
total_rewards_max            7534.226001044297
total_rewards_min            7158.209349632185
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               33.779819475952536
(Previous) Eval Time (s)     28.602082048077136
Sample Time (s)              23.058954121544957
Epoch Time (s)               85.44085564557463
Total Train Time (s)         8852.270060225856
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:31.357175 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Epoch Duration: 85.50035738945007
2020-01-11 11:58:31.357383 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.096887
Z variance train             0.041200936
KL Divergence                29.510897
KL Loss                      2.9510896
QF Loss                      435.24957
VF Loss                      130.59377
Policy Loss                  -2267.9514
Q Predictions Mean           2270.836
Q Predictions Std            673.9038
Q Predictions Max            2933.276
Q Predictions Min            166.89392
V Predictions Mean           2270.0464
V Predictions Std            668.8757
V Predictions Max            2933.5588
V Predictions Min            173.94849
Log Pis Mean                 2.9219365
Log Pis Std                  4.3837347
Log Pis Max                  14.883076
Log Pis Min                  -8.072243
Policy mu Mean               -0.06263662
Policy mu Std                1.2403475
Policy mu Max                2.7912946
Policy mu Min                -2.7753944
Policy log std Mean          -0.66427964
Policy log std Std           0.3657315
Policy log std Max           -0.023473322
Policy log std Min           -2.4917445
Z mean eval                  2.110065
Z variance eval              0.03850005
total_rewards                [7042.28089531 7199.36306973 7487.29894194 7083.1903505  7061.10726149
 7106.20028341 7036.08925792 7064.27313291 7184.57379157 6957.45550965]
total_rewards_mean           7122.183249442574
total_rewards_std            138.9065593898401
total_rewards_max            7487.29894193724
total_rewards_min            6957.455509649512
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               34.783489307854325
(Previous) Eval Time (s)     28.66121829301119
Sample Time (s)              23.639052606653422
Epoch Time (s)               87.08376020751894
Total Train Time (s)         8940.213014943525
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:59.302917 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Epoch Duration: 87.94535422325134
2020-01-11 11:59:59.303284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122518
Z variance train             0.03854538
KL Divergence                29.685438
KL Loss                      2.9685438
QF Loss                      419.8003
VF Loss                      327.24115
Policy Loss                  -2178.456
Q Predictions Mean           2167.748
Q Predictions Std            699.14777
Q Predictions Max            2931.8936
Q Predictions Min            149.54788
V Predictions Mean           2165.563
V Predictions Std            691.4845
V Predictions Max            2930.138
V Predictions Min            158.81248
Log Pis Mean                 3.1352925
Log Pis Std                  4.456382
Log Pis Max                  13.170013
Log Pis Min                  -6.8989496
Policy mu Mean               -0.12077254
Policy mu Std                1.2631902
Policy mu Max                2.842502
Policy mu Min                -2.6692502
Policy log std Mean          -0.64496577
Policy log std Std           0.34558335
Policy log std Max           -0.045044303
Policy log std Min           -2.1963277
Z mean eval                  2.149693
Z variance eval              0.009720111
total_rewards                [7269.0269355  7511.68337783 7780.37946299 7560.96827885 7305.55452067
 7276.84506873 7554.11541697 7557.26837466 7306.04288581 7138.77855381]
total_rewards_mean           7426.066287582199
total_rewards_std            185.22108465979085
total_rewards_max            7780.3794629942095
total_rewards_min            7138.77855380896
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               34.006360894069076
(Previous) Eval Time (s)     29.522449960932136
Sample Time (s)              24.776930660475045
Epoch Time (s)               88.30574151547626
Total Train Time (s)         9026.360802510288
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:01:25.452563 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Epoch Duration: 86.1490683555603
2020-01-11 12:01:25.452815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1500878
Z variance train             0.009722221
KL Divergence                31.468628
KL Loss                      3.1468627
QF Loss                      542.267
VF Loss                      113.64594
Policy Loss                  -2191.5027
Q Predictions Mean           2190.2854
Q Predictions Std            824.22015
Q Predictions Max            2988.3794
Q Predictions Min            154.43639
V Predictions Mean           2191.1694
V Predictions Std            820.74585
V Predictions Max            2977.3582
V Predictions Min            160.19589
Log Pis Mean                 3.163113
Log Pis Std                  4.3687115
Log Pis Max                  12.804199
Log Pis Min                  -6.0463285
Policy mu Mean               -0.059833843
Policy mu Std                1.2605726
Policy mu Max                2.8894713
Policy mu Min                -2.8688948
Policy log std Mean          -0.62063426
Policy log std Std           0.34014478
Policy log std Max           0.01679194
Policy log std Min           -2.195249
Z mean eval                  2.1309724
Z variance eval              0.010476066
total_rewards                [7110.2740164  7188.31157362 6942.48972325 6696.87810133 7015.37067782
 7332.66010995 7481.70183404 7248.71863941 7324.07205204 7324.38506716]
total_rewards_mean           7166.486179501716
total_rewards_std            219.24425577304612
total_rewards_max            7481.701834044574
total_rewards_min            6696.878101333877
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               34.381796058733016
(Previous) Eval Time (s)     27.365319018252194
Sample Time (s)              23.458883432671428
Epoch Time (s)               85.20599850965664
Total Train Time (s)         9113.569654759485
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:52.664361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Epoch Duration: 87.21135258674622
2020-01-11 12:02:52.664716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1322606
Z variance train             0.0104754735
KL Divergence                30.337208
KL Loss                      3.0337207
QF Loss                      436.74054
VF Loss                      321.33188
Policy Loss                  -2320.1653
Q Predictions Mean           2311.6775
Q Predictions Std            680.76337
Q Predictions Max            2949.6042
Q Predictions Min            168.14175
V Predictions Mean           2317.2646
V Predictions Std            676.6763
V Predictions Max            2954.089
V Predictions Min            162.77443
Log Pis Mean                 3.1494603
Log Pis Std                  4.399215
Log Pis Max                  15.787262
Log Pis Min                  -8.497261
Policy mu Mean               -0.08499023
Policy mu Std                1.2471751
Policy mu Max                3.7374082
Policy mu Min                -3.1960382
Policy log std Mean          -0.64397174
Policy log std Std           0.3569181
Policy log std Max           0.04184243
Policy log std Min           -2.2648249
Z mean eval                  2.1494312
Z variance eval              0.009230427
total_rewards                [7410.94248404 7901.22444622 7581.64811442 7649.40208446 7391.39969899
 7486.57584616 7548.10861527 7515.72745003 7557.45377383 7329.71765727]
total_rewards_mean           7537.22001706827
total_rewards_std            151.9471734932087
total_rewards_max            7901.224446224628
total_rewards_min            7329.717657268471
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               33.58071416430175
(Previous) Eval Time (s)     29.370236618909985
Sample Time (s)              23.790479606948793
Epoch Time (s)               86.74143039016053
Total Train Time (s)         9199.382819779217
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:18.479294 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Epoch Duration: 85.81439399719238
2020-01-11 12:04:18.479504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1509123
Z variance train             0.009226255
KL Divergence                30.31403
KL Loss                      3.031403
QF Loss                      475.03714
VF Loss                      116.80836
Policy Loss                  -2306.9548
Q Predictions Mean           2305.411
Q Predictions Std            779.14246
Q Predictions Max            3042.805
Q Predictions Min            159.17107
V Predictions Mean           2307.392
V Predictions Std            778.1978
V Predictions Max            3060.7253
V Predictions Min            167.01123
Log Pis Mean                 4.106906
Log Pis Std                  4.8126283
Log Pis Max                  15.842436
Log Pis Min                  -5.982725
Policy mu Mean               -0.093729
Policy mu Std                1.3142086
Policy mu Max                2.9010594
Policy mu Min                -2.9167616
Policy log std Mean          -0.64378065
Policy log std Std           0.3620565
Policy log std Max           -0.025357336
Policy log std Min           -2.3988056
Z mean eval                  2.1385007
Z variance eval              0.018369805
total_rewards                [7338.56976998 7593.3225492  7557.56389928 7307.87774659 7256.93559413
 7641.40468065 7175.28000583 7472.94346339 7408.10199588 7366.28167047]
total_rewards_mean           7411.8281375407805
total_rewards_std            144.50853314756424
total_rewards_max            7641.404680651087
total_rewards_min            7175.280005828779
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               31.93513130908832
(Previous) Eval Time (s)     28.4428558209911
Sample Time (s)              21.790069838054478
Epoch Time (s)               82.1680569681339
Total Train Time (s)         9282.141971101053
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:41.255237 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Epoch Duration: 82.77557325363159
2020-01-11 12:05:41.255420 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1355731
Z variance train             0.01845999
KL Divergence                28.22334
KL Loss                      2.822334
QF Loss                      698.6847
VF Loss                      235.12639
Policy Loss                  -2323.7397
Q Predictions Mean           2320.0369
Q Predictions Std            701.5083
Q Predictions Max            3060.404
Q Predictions Min            156.99994
V Predictions Mean           2332.276
V Predictions Std            700.72266
V Predictions Max            3081.8171
V Predictions Min            163.65865
Log Pis Mean                 3.5314102
Log Pis Std                  4.146191
Log Pis Max                  12.478049
Log Pis Min                  -5.905792
Policy mu Mean               -0.087601684
Policy mu Std                1.2884964
Policy mu Max                3.0241313
Policy mu Min                -2.5319161
Policy log std Mean          -0.6545729
Policy log std Std           0.36815608
Policy log std Max           -0.10518041
Policy log std Min           -2.4717531
Z mean eval                  2.1263278
Z variance eval              0.07237793
total_rewards                [7508.97389381 7683.48736609 7668.00839604 7656.18637422 7702.22575994
 7610.4003947  7411.93828888 7421.20731451 7485.01578733 7839.43160801]
total_rewards_mean           7598.687518353663
total_rewards_std            130.94345598847494
total_rewards_max            7839.431608013015
total_rewards_min            7411.938288878392
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               32.07003004895523
(Previous) Eval Time (s)     29.05005435924977
Sample Time (s)              22.26452341163531
Epoch Time (s)               83.38460781984031
Total Train Time (s)         9364.94206942711
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:04.041928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Epoch Duration: 82.78637194633484
2020-01-11 12:07:04.042115 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1255012
Z variance train             0.07253233
KL Divergence                27.594051
KL Loss                      2.7594051
QF Loss                      722.95123
VF Loss                      323.3188
Policy Loss                  -2295.397
Q Predictions Mean           2288.9878
Q Predictions Std            766.8266
Q Predictions Max            3029.2751
Q Predictions Min            144.04811
V Predictions Mean           2285.996
V Predictions Std            762.952
V Predictions Max            3003.464
V Predictions Min            150.39314
Log Pis Mean                 3.8741899
Log Pis Std                  4.423392
Log Pis Max                  16.436085
Log Pis Min                  -6.2528644
Policy mu Mean               -0.19308896
Policy mu Std                1.3314401
Policy mu Max                3.2212152
Policy mu Min                -3.2202108
Policy log std Mean          -0.64146364
Policy log std Std           0.35202777
Policy log std Max           0.007009983
Policy log std Min           -2.2213311
Z mean eval                  2.1594284
Z variance eval              0.03528331
total_rewards                [7526.59799172 7420.83608399 7026.77649788 7600.56338907  784.91780135
 7516.07841832 7561.65901374 7433.14114581 7321.06056313 7565.60694412]
total_rewards_mean           6775.723784914667
total_rewards_std            2003.308525494748
total_rewards_max            7600.563389073999
total_rewards_min            784.9178013546275
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.73837530054152
(Previous) Eval Time (s)     28.45150250289589
Sample Time (s)              22.683589450083673
Epoch Time (s)               82.87346725352108
Total Train Time (s)         9446.612814343069
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:25.713277 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Epoch Duration: 81.67098832130432
2020-01-11 12:08:25.713423 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1590898
Z variance train             0.035337083
KL Divergence                28.689764
KL Loss                      2.8689764
QF Loss                      352.23053
VF Loss                      223.04655
Policy Loss                  -2406.429
Q Predictions Mean           2409.4817
Q Predictions Std            708.21387
Q Predictions Max            3114.1982
Q Predictions Min            165.5045
V Predictions Mean           2405.2268
V Predictions Std            705.40735
V Predictions Max            3107.8748
V Predictions Min            170.6744
Log Pis Mean                 3.5988455
Log Pis Std                  4.2451525
Log Pis Max                  14.981598
Log Pis Min                  -7.4913607
Policy mu Mean               -0.009034869
Policy mu Std                1.2759578
Policy mu Max                3.0347803
Policy mu Min                -2.726309
Policy log std Mean          -0.65901405
Policy log std Std           0.36898822
Policy log std Max           0.0045678318
Policy log std Min           -2.2644408
Z mean eval                  2.144406
Z variance eval              0.026352052
total_rewards                [7456.91857808 7611.25785799 7394.77075579 7704.47061088 7683.77381022
 7902.03192819 7458.48265036 7898.24934662 7520.51377    7858.62842472]
total_rewards_mean           7648.909773285304
total_rewards_std            181.6971153914399
total_rewards_max            7902.031928187303
total_rewards_min            7394.770755794435
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               32.58432270120829
(Previous) Eval Time (s)     27.248720303643495
Sample Time (s)              21.70526448637247
Epoch Time (s)               81.53830749122426
Total Train Time (s)         9529.647103800438
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:48.750664 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Epoch Duration: 83.03710699081421
2020-01-11 12:09:48.750881 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1429608
Z variance train             0.026342865
KL Divergence                28.007057
KL Loss                      2.8007057
QF Loss                      529.9026
VF Loss                      222.46034
Policy Loss                  -2315.4573
Q Predictions Mean           2317.126
Q Predictions Std            748.0376
Q Predictions Max            3078.0469
Q Predictions Min            155.15051
V Predictions Mean           2319.1604
V Predictions Std            746.3554
V Predictions Max            3033.578
V Predictions Min            156.50874
Log Pis Mean                 3.3010983
Log Pis Std                  4.543342
Log Pis Max                  14.195842
Log Pis Min                  -7.350049
Policy mu Mean               -0.1349045
Policy mu Std                1.2720443
Policy mu Max                3.7773933
Policy mu Min                -2.8201857
Policy log std Mean          -0.6450735
Policy log std Std           0.351397
Policy log std Max           -0.018994838
Policy log std Min           -2.329298
Z mean eval                  2.1672196
Z variance eval              0.030491525
total_rewards                [7389.10326874 7377.48118158 7722.08784378 7679.9598871  7735.5752469
 7947.98033704 7663.10609671 7268.07788803 7576.92504352 7545.03130575]
total_rewards_mean           7590.532809915579
total_rewards_std            192.76266376691282
total_rewards_max            7947.9803370390355
total_rewards_min            7268.0778880336775
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               32.1136109828949
(Previous) Eval Time (s)     28.747202422935516
Sample Time (s)              22.124507736880332
Epoch Time (s)               82.98532114271075
Total Train Time (s)         9610.944065124262
Epoch                        115
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:10.064147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Epoch Duration: 81.31309604644775
2020-01-11 12:11:10.064427 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166699
Z variance train             0.030564994
KL Divergence                28.413616
KL Loss                      2.8413618
QF Loss                      518.5525
VF Loss                      147.1306
Policy Loss                  -2352.0217
Q Predictions Mean           2343.3271
Q Predictions Std            747.1976
Q Predictions Max            3112.5164
Q Predictions Min            154.86742
V Predictions Mean           2345.8267
V Predictions Std            743.34296
V Predictions Max            3097.377
V Predictions Min            163.76198
Log Pis Mean                 3.3147008
Log Pis Std                  4.5653906
Log Pis Max                  15.8278055
Log Pis Min                  -5.8372893
Policy mu Mean               -0.027875898
Policy mu Std                1.2779633
Policy mu Max                2.9703162
Policy mu Min                -3.1395283
Policy log std Mean          -0.6682063
Policy log std Std           0.3874564
Policy log std Max           0.0154545605
Policy log std Min           -2.7174525
Z mean eval                  2.1401494
Z variance eval              0.023749918
total_rewards                [7373.57146268 7549.53692103 7584.10930499 7647.21837991 7725.99937749
 7490.91287627 7396.47495376 7390.76454638 7576.31709766 7516.29413311]
total_rewards_mean           7525.119905326277
total_rewards_std            109.89700808892283
total_rewards_max            7725.999377489779
total_rewards_min            7373.571462675387
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               32.49827014096081
(Previous) Eval Time (s)     27.074641888961196
Sample Time (s)              22.076462081633508
Epoch Time (s)               81.64937411155552
Total Train Time (s)         9693.638220705092
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.746686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Epoch Duration: 82.68205499649048
2020-01-11 12:12:32.746883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.140013
Z variance train             0.023713032
KL Divergence                27.795218
KL Loss                      2.7795217
QF Loss                      324.84848
VF Loss                      220.01105
Policy Loss                  -2375.778
Q Predictions Mean           2371.7883
Q Predictions Std            732.4757
Q Predictions Max            3190.255
Q Predictions Min            163.22998
V Predictions Mean           2365.7659
V Predictions Std            731.0529
V Predictions Max            3177.6418
V Predictions Min            146.25775
Log Pis Mean                 3.4242613
Log Pis Std                  4.330859
Log Pis Max                  18.024483
Log Pis Min                  -7.091023
Policy mu Mean               -0.10029149
Policy mu Std                1.2815934
Policy mu Max                3.6735494
Policy mu Min                -2.852701
Policy log std Mean          -0.636404
Policy log std Std           0.3551131
Policy log std Max           0.04967022
Policy log std Min           -2.3966842
Z mean eval                  2.1236436
Z variance eval              0.030370152
total_rewards                [7094.14086389 6956.61885004 7232.70830602 7179.98434034 7210.74068818
 7293.94971708 7298.88162312 7130.27050971 7512.41329858 7263.54324892]
total_rewards_mean           7217.325144588137
total_rewards_std            139.33086411803507
total_rewards_max            7512.41329857616
total_rewards_min            6956.6188500378
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               31.97789427312091
(Previous) Eval Time (s)     28.10699481703341
Sample Time (s)              23.36145328031853
Epoch Time (s)               83.44634237047285
Total Train Time (s)         9776.16332501173
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:55.273240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Epoch Duration: 82.5262131690979
2020-01-11 12:13:55.273449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1248085
Z variance train             0.030241128
KL Divergence                27.023613
KL Loss                      2.7023613
QF Loss                      478.9682
VF Loss                      213.45969
Policy Loss                  -2341.7983
Q Predictions Mean           2330.7517
Q Predictions Std            724.29865
Q Predictions Max            3012.2678
Q Predictions Min            152.05907
V Predictions Mean           2335.854
V Predictions Std            723.7485
V Predictions Max            3030.556
V Predictions Min            151.6353
Log Pis Mean                 3.6820002
Log Pis Std                  4.81591
Log Pis Max                  19.693758
Log Pis Min                  -6.324106
Policy mu Mean               -0.0818796
Policy mu Std                1.3036859
Policy mu Max                3.67282
Policy mu Min                -4.4581013
Policy log std Mean          -0.65584546
Policy log std Std           0.35120735
Policy log std Max           0.06569767
Policy log std Min           -2.2111728
Z mean eval                  2.1442418
Z variance eval              0.032032073
total_rewards                [7015.57949991 7584.73680885 7266.17355138 7632.92153587 7353.85207272
 7432.9831967  7528.10498244 7450.22539977 7698.85659955 7299.04190254]
total_rewards_mean           7426.2475549724595
total_rewards_std            192.05161611917384
total_rewards_max            7698.856599548134
total_rewards_min            7015.579499905669
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               31.902583480346948
(Previous) Eval Time (s)     27.186499509960413
Sample Time (s)              22.523742003832012
Epoch Time (s)               81.61282499413937
Total Train Time (s)         9859.202987961471
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:15:18.317425 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Epoch Duration: 83.04383039474487
2020-01-11 12:15:18.317602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.142915
Z variance train             0.032176126
KL Divergence                27.232662
KL Loss                      2.7232664
QF Loss                      599.9242
VF Loss                      248.53967
Policy Loss                  -2428.552
Q Predictions Mean           2426.7617
Q Predictions Std            677.93195
Q Predictions Max            3093.9102
Q Predictions Min            137.43947
V Predictions Mean           2431.7217
V Predictions Std            671.9735
V Predictions Max            3100.5488
V Predictions Min            153.88716
Log Pis Mean                 3.638464
Log Pis Std                  4.3956985
Log Pis Max                  14.92223
Log Pis Min                  -8.168527
Policy mu Mean               -0.06799839
Policy mu Std                1.3026059
Policy mu Max                2.9740832
Policy mu Min                -2.7027028
Policy log std Mean          -0.6702903
Policy log std Std           0.36021549
Policy log std Max           -0.020496786
Policy log std Min           -2.1766102
Z mean eval                  2.163973
Z variance eval              0.028902596
total_rewards                [7641.68410075 7894.56245001 7947.85026302 7728.4557448  7771.97416162
 7430.9892206  7772.72463099 8008.85295461 7655.7975318  7771.29311321]
total_rewards_mean           7762.418417142384
total_rewards_std            158.0496284247883
total_rewards_max            8008.852954614325
total_rewards_min            7430.989220600062
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.05728844227269
(Previous) Eval Time (s)     28.6171563831158
Sample Time (s)              22.346906901337206
Epoch Time (s)               83.0213517267257
Total Train Time (s)         9942.722405671142
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:41.837914 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Epoch Duration: 83.52016758918762
2020-01-11 12:16:41.838188 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1602707
Z variance train             0.028858488
KL Divergence                27.296791
KL Loss                      2.729679
QF Loss                      401.2388
VF Loss                      510.7658
Policy Loss                  -2362.0732
Q Predictions Mean           2366.3262
Q Predictions Std            804.5355
Q Predictions Max            3156.0527
Q Predictions Min            112.66487
V Predictions Mean           2380.247
V Predictions Std            807.25476
V Predictions Max            3166.221
V Predictions Min            161.13603
Log Pis Mean                 3.705635
Log Pis Std                  4.6241894
Log Pis Max                  15.8421
Log Pis Min                  -5.207158
Policy mu Mean               -0.08613255
Policy mu Std                1.3001207
Policy mu Max                3.238702
Policy mu Min                -3.1809554
Policy log std Mean          -0.6720298
Policy log std Std           0.37692523
Policy log std Max           0.07308251
Policy log std Min           -2.2911768
Z mean eval                  2.161359
Z variance eval              0.03745121
total_rewards                [1670.06486198 7887.85652497 7838.66724746 7660.85296517 7786.61000705
 7739.99749694 7577.82909044 7823.07193376 7573.41005468 7856.44628089]
total_rewards_mean           7141.480646333126
total_rewards_std            1826.9210227176288
total_rewards_max            7887.856524966769
total_rewards_min            1670.0648619832155
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               32.233737925067544
(Previous) Eval Time (s)     29.11563022620976
Sample Time (s)              22.272349659353495
Epoch Time (s)               83.6217178106308
Total Train Time (s)         10025.5637827022
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:04.678007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Epoch Duration: 82.83962345123291
2020-01-11 12:18:04.678137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1615384
Z variance train             0.037366137
KL Divergence                27.223349
KL Loss                      2.7223349
QF Loss                      493.4255
VF Loss                      116.13165
Policy Loss                  -2399.9343
Q Predictions Mean           2400.5347
Q Predictions Std            717.86743
Q Predictions Max            3130.753
Q Predictions Min            142.47969
V Predictions Mean           2403.6807
V Predictions Std            714.3444
V Predictions Max            3133.4565
V Predictions Min            147.08215
Log Pis Mean                 3.5403497
Log Pis Std                  4.5292826
Log Pis Max                  13.945557
Log Pis Min                  -7.399075
Policy mu Mean               -0.10427099
Policy mu Std                1.2915564
Policy mu Max                3.1460598
Policy mu Min                -2.8937132
Policy log std Mean          -0.6493683
Policy log std Std           0.360737
Policy log std Max           0.023186922
Policy log std Min           -2.4276505
Z mean eval                  2.166556
Z variance eval              0.028832573
total_rewards                [7768.19847141 7747.50659594 7668.43532834 7374.96079382 7875.80072032
 7588.43056421 7576.55682443 7521.63314238 7827.77809117 7818.90093491]
total_rewards_mean           7676.820146693162
total_rewards_std            151.34494536750242
total_rewards_max            7875.800720319751
total_rewards_min            7374.960793822822
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.633822922129184
(Previous) Eval Time (s)     28.333247672766447
Sample Time (s)              22.70806915126741
Epoch Time (s)               82.67513974616304
Total Train Time (s)         10108.172321683262
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:27.288362 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Epoch Duration: 82.61009097099304
2020-01-11 12:19:27.288658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669364
Z variance train             0.028765962
KL Divergence                27.72247
KL Loss                      2.772247
QF Loss                      483.68976
VF Loss                      260.29395
Policy Loss                  -2445.991
Q Predictions Mean           2449.4014
Q Predictions Std            650.5726
Q Predictions Max            3113.2083
Q Predictions Min            163.05203
V Predictions Mean           2438.819
V Predictions Std            648.2336
V Predictions Max            3088.8696
V Predictions Min            141.6081
Log Pis Mean                 3.9256926
Log Pis Std                  4.2858915
Log Pis Max                  14.054834
Log Pis Min                  -5.445697
Policy mu Mean               -0.08777684
Policy mu Std                1.3004625
Policy mu Max                3.1136425
Policy mu Min                -2.83485
Policy log std Mean          -0.6886563
Policy log std Std           0.37058768
Policy log std Max           0.026530385
Policy log std Min           -2.567794
Z mean eval                  2.1651862
Z variance eval              0.022629252
total_rewards                [7641.04870339 7881.64989157 7788.48949085 7700.76540655 7869.69252472
 7797.97736464 7750.3407883  7908.42127357 7963.95271762 7801.34298356]
total_rewards_mean           7810.368114476305
total_rewards_std            93.16752868474026
total_rewards_max            7963.952717622465
total_rewards_min            7641.048703387032
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               31.718963470775634
(Previous) Eval Time (s)     28.267850168980658
Sample Time (s)              21.725071489810944
Epoch Time (s)               81.71188512956724
Total Train Time (s)         10189.474520849064
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:48.591644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Epoch Duration: 81.30278396606445
2020-01-11 12:20:48.591789 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1675887
Z variance train             0.022673242
KL Divergence                27.969124
KL Loss                      2.7969124
QF Loss                      343.4251
VF Loss                      232.29019
Policy Loss                  -2507.861
Q Predictions Mean           2502.7715
Q Predictions Std            729.1567
Q Predictions Max            3235.6135
Q Predictions Min            144.80428
V Predictions Mean           2495.6082
V Predictions Std            721.66144
V Predictions Max            3201.9722
V Predictions Min            151.91975
Log Pis Mean                 3.9773197
Log Pis Std                  4.1661787
Log Pis Max                  14.810989
Log Pis Min                  -5.9714284
Policy mu Mean               -0.060611084
Policy mu Std                1.3432254
Policy mu Max                2.8210905
Policy mu Min                -3.023932
Policy log std Mean          -0.6700917
Policy log std Std           0.38071197
Policy log std Max           0.018575013
Policy log std Min           -2.4792962
Z mean eval                  2.158179
Z variance eval              0.022369374
total_rewards                [7569.42945748 7521.61936796 7662.41411332 7605.22178639 7673.95936073
 7539.21259328 7713.16769686 7389.85814552 7572.85418923 7618.50869766]
total_rewards_mean           7586.62454084272
total_rewards_std            87.42020960175738
total_rewards_max            7713.167696860186
total_rewards_min            7389.858145524164
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               31.900997004006058
(Previous) Eval Time (s)     27.858421981334686
Sample Time (s)              23.19695779355243
Epoch Time (s)               82.95637677889317
Total Train Time (s)         10272.593683172483
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:11.714766 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Epoch Duration: 83.12278199195862
2020-01-11 12:22:11.715079 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1583824
Z variance train             0.022367457
KL Divergence                28.011662
KL Loss                      2.8011663
QF Loss                      379.68927
VF Loss                      152.9073
Policy Loss                  -2477.808
Q Predictions Mean           2475.121
Q Predictions Std            757.524
Q Predictions Max            3194.2378
Q Predictions Min            146.45087
V Predictions Mean           2482.6062
V Predictions Std            755.21204
V Predictions Max            3197.0005
V Predictions Min            149.76118
Log Pis Mean                 3.753213
Log Pis Std                  4.49923
Log Pis Max                  14.227472
Log Pis Min                  -8.425393
Policy mu Mean               -0.08532071
Policy mu Std                1.3291787
Policy mu Max                2.9437695
Policy mu Min                -3.0960083
Policy log std Mean          -0.66863745
Policy log std Std           0.38493922
Policy log std Max           -0.019096792
Policy log std Min           -2.5060906
Z mean eval                  2.1611867
Z variance eval              0.022162767
total_rewards                [7506.01897348 7785.45865677 7848.43541352 7670.12277356 7976.60466923
 7832.07810446 7630.69376134 7733.10958317 7787.92228522 7860.19480731]
total_rewards_mean           7763.0639028051755
total_rewards_std            127.01734346316492
total_rewards_max            7976.604669227559
total_rewards_min            7506.018973476086
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.02152909198776
(Previous) Eval Time (s)     28.024450284894556
Sample Time (s)              22.444499496836215
Epoch Time (s)               82.49047887371853
Total Train Time (s)         10354.931254369672
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:34.053872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Epoch Duration: 82.33848881721497
2020-01-11 12:23:34.054080 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608572
Z variance train             0.022153946
KL Divergence                28.166801
KL Loss                      2.8166802
QF Loss                      363.5307
VF Loss                      164.76459
Policy Loss                  -2548.734
Q Predictions Mean           2549.0957
Q Predictions Std            724.4027
Q Predictions Max            3276.55
Q Predictions Min            147.92834
V Predictions Mean           2548.504
V Predictions Std            720.96655
V Predictions Max            3263.4514
V Predictions Min            155.44008
Log Pis Mean                 3.6401284
Log Pis Std                  4.2937927
Log Pis Max                  16.123154
Log Pis Min                  -5.25014
Policy mu Mean               -0.10102471
Policy mu Std                1.3115661
Policy mu Max                3.5708656
Policy mu Min                -2.7394338
Policy log std Mean          -0.6572583
Policy log std Std           0.36736044
Policy log std Max           0.07411778
Policy log std Min           -2.595261
Z mean eval                  2.1855383
Z variance eval              0.017542686
total_rewards                [7900.35309413 7638.18243217 7950.30773248 7682.0755332  7651.15239274
 7767.43930253 7836.05726565 7736.93384004 7946.70313695 7638.91278255]
total_rewards_mean           7774.811751244479
total_rewards_std            119.3205608777489
total_rewards_max            7950.307732476468
total_rewards_min            7638.182432166923
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               32.161142848897725
(Previous) Eval Time (s)     27.872199334204197
Sample Time (s)              22.375892338808626
Epoch Time (s)               82.40923452191055
Total Train Time (s)         10437.237067535985
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:24:56.362875 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Epoch Duration: 82.30854797363281
2020-01-11 12:24:56.363318 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1862042
Z variance train             0.017526515
KL Divergence                28.95858
KL Loss                      2.895858
QF Loss                      472.78363
VF Loss                      195.39989
Policy Loss                  -2495.0303
Q Predictions Mean           2497.3833
Q Predictions Std            757.35474
Q Predictions Max            3268.611
Q Predictions Min            140.42471
V Predictions Mean           2502.8516
V Predictions Std            757.9763
V Predictions Max            3247.23
V Predictions Min            141.71968
Log Pis Mean                 3.786283
Log Pis Std                  4.1812944
Log Pis Max                  15.40319
Log Pis Min                  -6.0013056
Policy mu Mean               -0.13535248
Policy mu Std                1.2990096
Policy mu Max                2.8774095
Policy mu Min                -3.786364
Policy log std Mean          -0.6798355
Policy log std Std           0.38679394
Policy log std Max           0.04966098
Policy log std Min           -2.416494
Z mean eval                  2.158931
Z variance eval              0.019582726
total_rewards                [7183.76126148 7534.87593825 7377.10301487 7974.69601064 7523.60203838
 7750.1305903  7701.22382803 7604.6092168  7563.93823029 7590.9114624 ]
total_rewards_mean           7580.485159144186
total_rewards_std            200.94628903415756
total_rewards_max            7974.696010637538
total_rewards_min            7183.761261483706
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               31.755634099710733
(Previous) Eval Time (s)     27.77115014800802
Sample Time (s)              20.634361669886857
Epoch Time (s)               80.16114591760561
Total Train Time (s)         10517.300397719722
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:16.426055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Epoch Duration: 80.0624623298645
2020-01-11 12:26:16.426191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1568856
Z variance train             0.019552493
KL Divergence                28.229713
KL Loss                      2.8229713
QF Loss                      616.3839
VF Loss                      487.9043
Policy Loss                  -2451.4524
Q Predictions Mean           2450.3145
Q Predictions Std            766.3673
Q Predictions Max            3219.5278
Q Predictions Min            139.47939
V Predictions Mean           2462.5503
V Predictions Std            760.4519
V Predictions Max            3219.7705
V Predictions Min            152.21211
Log Pis Mean                 3.4882557
Log Pis Std                  4.645358
Log Pis Max                  16.348852
Log Pis Min                  -6.896637
Policy mu Mean               -0.15351354
Policy mu Std                1.2808789
Policy mu Max                3.5147452
Policy mu Min                -3.3616762
Policy log std Mean          -0.6643668
Policy log std Std           0.3720756
Policy log std Max           -0.021333754
Policy log std Min           -2.6209126
Z mean eval                  2.1848404
Z variance eval              0.0146914525
total_rewards                [7665.51673957 7996.26428224 7917.98592376 7785.54545286 7956.04141808
 7726.39150836 7549.55906913 7840.61620286 7929.07260121 7789.35055474]
total_rewards_mean           7815.63437528122
total_rewards_std            133.8660928336053
total_rewards_max            7996.264282237264
total_rewards_min            7549.559069130345
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.06702484516427
(Previous) Eval Time (s)     27.67221516976133
Sample Time (s)              23.030520821455866
Epoch Time (s)               82.76976083638147
Total Train Time (s)         10599.788477720227
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:38.918540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Epoch Duration: 82.4921522140503
2020-01-11 12:27:38.918878 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.186056
Z variance train             0.014709538
KL Divergence                29.431313
KL Loss                      2.9431312
QF Loss                      347.77133
VF Loss                      105.075
Policy Loss                  -2509.9248
Q Predictions Mean           2510.8784
Q Predictions Std            730.0727
Q Predictions Max            3281.5493
Q Predictions Min            135.64326
V Predictions Mean           2508.6826
V Predictions Std            725.0124
V Predictions Max            3267.8672
V Predictions Min            140.59537
Log Pis Mean                 3.5548878
Log Pis Std                  4.439563
Log Pis Max                  16.564537
Log Pis Min                  -6.9519835
Policy mu Mean               -0.11658005
Policy mu Std                1.2975591
Policy mu Max                3.1982803
Policy mu Min                -2.8408027
Policy log std Mean          -0.678245
Policy log std Std           0.38412327
Policy log std Max           0.012543142
Policy log std Min           -2.3966534
Z mean eval                  2.1987805
Z variance eval              0.010929668
total_rewards                [7971.61194829 8250.10267551 7994.21648406 7941.97234983 8022.69116697
 8020.94085041 7942.53201428 8024.63327984 7943.2123199  8082.61037518]
total_rewards_mean           8019.452346427235
total_rewards_std            88.25306795480223
total_rewards_max            8250.102675513604
total_rewards_min            7941.972349832387
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               31.83170649362728
(Previous) Eval Time (s)     27.394187772180885
Sample Time (s)              22.11462298920378
Epoch Time (s)               81.34051725501195
Total Train Time (s)         10680.922513339669
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:00.055331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Epoch Duration: 81.13625645637512
2020-01-11 12:29:00.055576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1981645
Z variance train             0.0109062465
KL Divergence                30.459705
KL Loss                      3.0459707
QF Loss                      508.8352
VF Loss                      167.3658
Policy Loss                  -2480.093
Q Predictions Mean           2471.5469
Q Predictions Std            789.5917
Q Predictions Max            3215.9558
Q Predictions Min            111.80424
V Predictions Mean           2480.1736
V Predictions Std            778.1357
V Predictions Max            3210.1396
V Predictions Min            144.80128
Log Pis Mean                 3.9257646
Log Pis Std                  4.7665505
Log Pis Max                  17.98684
Log Pis Min                  -5.703204
Policy mu Mean               -0.17822695
Policy mu Std                1.3045448
Policy mu Max                3.0189474
Policy mu Min                -2.8363128
Policy log std Mean          -0.6788616
Policy log std Std           0.3771828
Policy log std Max           -0.03958553
Policy log std Min           -2.5687318
Z mean eval                  2.1800232
Z variance eval              0.012905789
total_rewards                [7435.02148792 7985.90044128 7693.62373194 7300.79498894 7911.70031642
 7621.12642823 8008.40533427 7757.86631593 3686.14073356 8016.91313735]
total_rewards_mean           7341.749291583762
total_rewards_std            1240.5209729568464
total_rewards_max            8016.913137353257
total_rewards_min            3686.1407335605672
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               31.91690224967897
(Previous) Eval Time (s)     27.189595696050674
Sample Time (s)              22.414226626977324
Epoch Time (s)               81.52072457270697
Total Train Time (s)         10763.46572679421
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:22.601328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Epoch Duration: 82.54552626609802
2020-01-11 12:30:22.601599 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1816583
Z variance train             0.012899275
KL Divergence                30.08772
KL Loss                      3.0087721
QF Loss                      563.63745
VF Loss                      255.33463
Policy Loss                  -2592.8206
Q Predictions Mean           2598.5361
Q Predictions Std            718.49274
Q Predictions Max            3345.5615
Q Predictions Min            149.24925
V Predictions Mean           2602.4749
V Predictions Std            718.4068
V Predictions Max            3330.0022
V Predictions Min            149.19011
Log Pis Mean                 4.0616083
Log Pis Std                  4.535389
Log Pis Max                  14.117641
Log Pis Min                  -6.478543
Policy mu Mean               -0.11300554
Policy mu Std                1.3381039
Policy mu Max                2.8607955
Policy mu Min                -3.3548527
Policy log std Mean          -0.66918564
Policy log std Std           0.35371384
Policy log std Max           -0.107973665
Policy log std Min           -2.4231956
Z mean eval                  2.1868505
Z variance eval              0.010797994
total_rewards                [7787.50632432 7787.63517445 8000.95543005 8014.95406301 8078.08116443
 7897.90390285 7824.36309574 7802.32746202 7925.1775027  7889.43005443]
total_rewards_mean           7900.833417399372
total_rewards_std            98.18551919732603
total_rewards_max            8078.081164428279
total_rewards_min            7787.506324324556
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               32.30447591515258
(Previous) Eval Time (s)     28.214088364038616
Sample Time (s)              21.972522630356252
Epoch Time (s)               82.49108690954745
Total Train Time (s)         10846.639206974767
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:31:45.777665 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Epoch Duration: 83.17590975761414
2020-01-11 12:31:45.777851 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1872587
Z variance train             0.010801589
KL Divergence                30.666052
KL Loss                      3.0666053
QF Loss                      368.12326
VF Loss                      166.74309
Policy Loss                  -2549.8804
Q Predictions Mean           2546.2996
Q Predictions Std            749.80695
Q Predictions Max            3337.5823
Q Predictions Min            145.52222
V Predictions Mean           2546.1174
V Predictions Std            750.222
V Predictions Max            3331.3303
V Predictions Min            139.57898
Log Pis Mean                 3.378889
Log Pis Std                  4.169176
Log Pis Max                  14.205139
Log Pis Min                  -5.038956
Policy mu Mean               -0.10830248
Policy mu Std                1.2843491
Policy mu Max                2.6152368
Policy mu Min                -2.7718062
Policy log std Mean          -0.6588785
Policy log std Std           0.37039933
Policy log std Max           -0.00889504
Policy log std Min           -2.4257443
Z mean eval                  2.1947482
Z variance eval              0.009609329
total_rewards                [7664.53587769 7756.44508608 7518.92684882 7783.85920457 7476.20986128
 7745.09483413 7918.33713711 7631.31959376 7860.38310331 7439.93364179]
total_rewards_mean           7679.504518854861
total_rewards_std            154.2478138918197
total_rewards_max            7918.337137107134
total_rewards_min            7439.933641793547
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               31.84923062985763
(Previous) Eval Time (s)     28.898611365351826
Sample Time (s)              22.945441315881908
Epoch Time (s)               83.69328331109136
Total Train Time (s)         10929.035116858315
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:08.174147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Epoch Duration: 82.39614343643188
2020-01-11 12:33:08.174333 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1953063
Z variance train             0.0096020745
KL Divergence                31.206398
KL Loss                      3.1206398
QF Loss                      764.90674
VF Loss                      264.12103
Policy Loss                  -2453.4915
Q Predictions Mean           2450.1814
Q Predictions Std            850.0971
Q Predictions Max            3249.1733
Q Predictions Min            129.88243
V Predictions Mean           2451.913
V Predictions Std            843.2255
V Predictions Max            3234.3718
V Predictions Min            135.44153
Log Pis Mean                 3.5663114
Log Pis Std                  4.3955283
Log Pis Max                  13.736706
Log Pis Min                  -6.5514946
Policy mu Mean               -0.117340714
Policy mu Std                1.3064028
Policy mu Max                4.5757027
Policy mu Min                -2.8674254
Policy log std Mean          -0.6696584
Policy log std Std           0.36769778
Policy log std Max           0.024642467
Policy log std Min           -2.4179523
Z mean eval                  2.1784477
Z variance eval              0.009002568
total_rewards                [7740.67960258 8174.96788707 7613.4121651  7793.82885911 8179.02302141
 7895.67492717 7764.59842428 7971.63741703 8064.91000879 7996.04592701]
total_rewards_mean           7919.477823953368
total_rewards_std            181.20694247679668
total_rewards_max            8179.023021407733
total_rewards_min            7613.412165099122
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               32.590766195673496
(Previous) Eval Time (s)     27.60115135787055
Sample Time (s)              23.093001856468618
Epoch Time (s)               83.28491941001266
Total Train Time (s)         11012.056824208237
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:31.198488 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Epoch Duration: 83.0240089893341
2020-01-11 12:34:31.198701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1782072
Z variance train             0.009007083
KL Divergence                30.950039
KL Loss                      3.0950038
QF Loss                      304.92255
VF Loss                      260.78442
Policy Loss                  -2475.579
Q Predictions Mean           2473.23
Q Predictions Std            842.1723
Q Predictions Max            3345.2468
Q Predictions Min            127.501785
V Predictions Mean           2479.293
V Predictions Std            841.7808
V Predictions Max            3348.9192
V Predictions Min            129.70471
Log Pis Mean                 3.9319239
Log Pis Std                  4.7513337
Log Pis Max                  14.667539
Log Pis Min                  -9.062307
Policy mu Mean               -0.07101205
Policy mu Std                1.321804
Policy mu Max                3.1458182
Policy mu Min                -3.2162943
Policy log std Mean          -0.6699941
Policy log std Std           0.3905936
Policy log std Max           -0.057042032
Policy log std Min           -2.4933712
Z mean eval                  2.1946511
Z variance eval              0.008420995
total_rewards                [7814.75901599 8259.06453777 8131.9097698  7892.20625793 7729.84299654
 7881.58627853 8047.34195834 7690.24782842 7976.16346751 7825.01462485]
total_rewards_mean           7924.813673568475
total_rewards_std            170.382171845127
total_rewards_max            8259.064537772898
total_rewards_min            7690.247828419931
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               31.581646645907313
(Previous) Eval Time (s)     27.339926719665527
Sample Time (s)              22.493171635549515
Epoch Time (s)               81.41474500112236
Total Train Time (s)         11094.26396752568
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:53.407650 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Epoch Duration: 82.20880246162415
2020-01-11 12:35:53.407844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194228
Z variance train             0.008444454
KL Divergence                31.737072
KL Loss                      3.1737072
QF Loss                      575.3832
VF Loss                      245.72696
Policy Loss                  -2461.962
Q Predictions Mean           2456.9783
Q Predictions Std            851.7289
Q Predictions Max            3322.598
Q Predictions Min            124.58693
V Predictions Mean           2460.1719
V Predictions Std            845.2321
V Predictions Max            3314.071
V Predictions Min            133.74403
Log Pis Mean                 3.8720582
Log Pis Std                  4.597559
Log Pis Max                  19.540956
Log Pis Min                  -5.172459
Policy mu Mean               -0.14549999
Policy mu Std                1.3062592
Policy mu Max                3.9423015
Policy mu Min                -3.1065602
Policy log std Mean          -0.693693
Policy log std Std           0.4019579
Policy log std Max           0.046117842
Policy log std Min           -2.5365105
Z mean eval                  2.170587
Z variance eval              0.008513495
total_rewards                [7900.81288572 7826.53268408 8180.6190086  7720.02396701 8056.56363928
 7861.60039003 7886.94731271 7989.39418172 7719.36049426 7625.51845332]
total_rewards_mean           7876.737301672389
total_rewards_std            159.13645794017913
total_rewards_max            8180.619008599673
total_rewards_min            7625.518453322919
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               32.62761056935415
(Previous) Eval Time (s)     28.133608389180154
Sample Time (s)              22.803111080545932
Epoch Time (s)               83.56433003908023
Total Train Time (s)         11178.46212478634
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:17.608549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Epoch Duration: 84.20055484771729
2020-01-11 12:37:17.608779 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1691406
Z variance train             0.008511709
KL Divergence                31.255707
KL Loss                      3.1255708
QF Loss                      356.83652
VF Loss                      227.43079
Policy Loss                  -2597.9646
Q Predictions Mean           2596.4102
Q Predictions Std            745.4515
Q Predictions Max            3326.816
Q Predictions Min            86.734665
V Predictions Mean           2604.976
V Predictions Std            745.75995
V Predictions Max            3340.791
V Predictions Min            132.43741
Log Pis Mean                 4.0929856
Log Pis Std                  4.4637647
Log Pis Max                  14.87507
Log Pis Min                  -5.2626367
Policy mu Mean               -0.121877335
Policy mu Std                1.3337426
Policy mu Max                2.689363
Policy mu Min                -2.609521
Policy log std Mean          -0.6783728
Policy log std Std           0.37448117
Policy log std Max           -0.09960866
Policy log std Min           -2.5533023
Z mean eval                  2.1662872
Z variance eval              0.009902049
total_rewards                [7734.26545797 7779.41310245 7428.82489516 7563.46061131 7589.20453299
 7675.10086838 7552.14661881 7495.63497881 7714.55281585 7716.43740051]
total_rewards_mean           7624.904128223044
total_rewards_std            109.66716194364625
total_rewards_max            7779.413102449878
total_rewards_min            7428.824895161483
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               32.46828634524718
(Previous) Eval Time (s)     28.769483662676066
Sample Time (s)              20.518734690267593
Epoch Time (s)               81.75650469819084
Total Train Time (s)         11260.075653527398
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:39.224876 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Epoch Duration: 81.61592054367065
2020-01-11 12:38:39.225214 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1645577
Z variance train             0.00991799
KL Divergence                31.33941
KL Loss                      3.1339412
QF Loss                      464.33734
VF Loss                      231.79546
Policy Loss                  -2599.4653
Q Predictions Mean           2591.939
Q Predictions Std            685.3346
Q Predictions Max            3265.1226
Q Predictions Min            129.29195
V Predictions Mean           2595.9097
V Predictions Std            679.0578
V Predictions Max            3233.5815
V Predictions Min            126.45525
Log Pis Mean                 4.0028033
Log Pis Std                  4.3124266
Log Pis Max                  15.100565
Log Pis Min                  -5.8274956
Policy mu Mean               -0.047028277
Policy mu Std                1.3377188
Policy mu Max                2.8694193
Policy mu Min                -2.84863
Policy log std Mean          -0.68946195
Policy log std Std           0.36810452
Policy log std Max           -0.1146452
Policy log std Min           -2.463295
Z mean eval                  2.1688435
Z variance eval              0.010434966
total_rewards                [7631.89988614 7783.75768456 7906.87818033 7699.05729174 7691.17588854
 8078.31481877 7744.44184311 7587.49605666 7751.56027143 7897.64156454]
total_rewards_mean           7777.222348581898
total_rewards_std            139.4174901420211
total_rewards_max            8078.314818770149
total_rewards_min            7587.496056660684
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               32.053010005969554
(Previous) Eval Time (s)     28.628570897039026
Sample Time (s)              22.618344428483397
Epoch Time (s)               83.29992533149198
Total Train Time (s)         11342.216952871531
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:01.367864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Epoch Duration: 82.14245319366455
2020-01-11 12:40:01.368073 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1700578
Z variance train             0.010450147
KL Divergence                31.384525
KL Loss                      3.1384525
QF Loss                      545.8311
VF Loss                      363.88025
Policy Loss                  -2518.2847
Q Predictions Mean           2514.3198
Q Predictions Std            824.2324
Q Predictions Max            3342.3564
Q Predictions Min            149.10762
V Predictions Mean           2510.5654
V Predictions Std            821.0022
V Predictions Max            3308.6917
V Predictions Min            125.96727
Log Pis Mean                 3.7103674
Log Pis Std                  4.316576
Log Pis Max                  12.878366
Log Pis Min                  -4.743309
Policy mu Mean               -0.15159865
Policy mu Std                1.3097025
Policy mu Max                3.0037315
Policy mu Min                -3.2773986
Policy log std Mean          -0.67722726
Policy log std Std           0.3609604
Policy log std Max           -0.0942049
Policy log std Min           -2.5852575
Z mean eval                  2.1694674
Z variance eval              0.01302254
total_rewards                [7530.97688146 7930.48783672 8120.51402197 8051.80425762 7982.69071741
 7964.84816224 7704.37279383 8211.41470652 7909.246295   7928.45900895]
total_rewards_mean           7933.481468172604
total_rewards_std            185.67606762757083
total_rewards_max            8211.414706517406
total_rewards_min            7530.976881458233
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               31.881814050022513
(Previous) Eval Time (s)     27.4707824960351
Sample Time (s)              22.23274060478434
Epoch Time (s)               81.58533715084195
Total Train Time (s)         11424.664784220047
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:23.817584 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Epoch Duration: 82.44936895370483
2020-01-11 12:41:23.817782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717608
Z variance train             0.013005422
KL Divergence                31.558426
KL Loss                      3.1558425
QF Loss                      497.1909
VF Loss                      141.47517
Policy Loss                  -2610.3813
Q Predictions Mean           2617.7014
Q Predictions Std            720.5717
Q Predictions Max            3351.514
Q Predictions Min            133.32135
V Predictions Mean           2609.4756
V Predictions Std            715.0963
V Predictions Max            3328.3123
V Predictions Min            129.00397
Log Pis Mean                 3.9014273
Log Pis Std                  4.8802414
Log Pis Max                  15.700635
Log Pis Min                  -9.054565
Policy mu Mean               -0.09679934
Policy mu Std                1.337877
Policy mu Max                3.1095595
Policy mu Min                -2.867675
Policy log std Mean          -0.6752781
Policy log std Std           0.35143888
Policy log std Max           -0.115986645
Policy log std Min           -2.5342627
Z mean eval                  2.1736605
Z variance eval              0.018814351
total_rewards                [7583.62525472 8087.00515764 7531.96793574 8145.37703754 8018.93940978
 7729.49165194 7726.7120938  7630.51892102 7775.76307073 7831.83781866]
total_rewards_mean           7806.123835156967
total_rewards_std            202.12456157828697
total_rewards_max            8145.377037540081
total_rewards_min            7531.967935738024
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               32.1892668409273
(Previous) Eval Time (s)     28.33451888570562
Sample Time (s)              21.83393588894978
Epoch Time (s)               82.3577216155827
Total Train Time (s)         11506.432054608129
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:45.587930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Epoch Duration: 81.77000689506531
2020-01-11 12:42:45.588108 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1734264
Z variance train             0.018801466
KL Divergence                30.747011
KL Loss                      3.074701
QF Loss                      357.63638
VF Loss                      175.34703
Policy Loss                  -2591.5713
Q Predictions Mean           2591.9336
Q Predictions Std            773.8418
Q Predictions Max            3330.319
Q Predictions Min            121.60279
V Predictions Mean           2597.9827
V Predictions Std            770.2079
V Predictions Max            3325.821
V Predictions Min            127.1102
Log Pis Mean                 3.804027
Log Pis Std                  4.5094495
Log Pis Max                  15.664596
Log Pis Min                  -5.623625
Policy mu Mean               -0.14805211
Policy mu Std                1.3263484
Policy mu Max                2.905786
Policy mu Min                -2.7753088
Policy log std Mean          -0.6772725
Policy log std Std           0.3831285
Policy log std Max           0.06172514
Policy log std Min           -2.6847196
Z mean eval                  2.1771522
Z variance eval              0.017222885
total_rewards                [7948.15398444 7988.2427815  8208.21735297 8153.77991273 8126.46806001
 8208.79029926 8108.12746054 7977.36512071 8288.16614913 8161.4410863 ]
total_rewards_mean           8116.875220759303
total_rewards_std            106.82939458890603
total_rewards_max            8288.166149132394
total_rewards_min            7948.1539844448625
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               33.040467496961355
(Previous) Eval Time (s)     27.746446553617716
Sample Time (s)              22.628484062850475
Epoch Time (s)               83.41539811342955
Total Train Time (s)         11590.021434172057
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:09.178769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Epoch Duration: 83.59053564071655
2020-01-11 12:44:09.178953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.179197
Z variance train             0.01725789
KL Divergence                30.884186
KL Loss                      3.0884187
QF Loss                      318.04926
VF Loss                      220.39583
Policy Loss                  -2655.1084
Q Predictions Mean           2649.4658
Q Predictions Std            703.5291
Q Predictions Max            3429.0725
Q Predictions Min            122.69882
V Predictions Mean           2647.2856
V Predictions Std            701.20966
V Predictions Max            3400.4062
V Predictions Min            125.45416
Log Pis Mean                 3.889709
Log Pis Std                  4.0291147
Log Pis Max                  13.977915
Log Pis Min                  -5.899637
Policy mu Mean               -0.14719062
Policy mu Std                1.3344375
Policy mu Max                3.190541
Policy mu Min                -2.9124854
Policy log std Mean          -0.6896093
Policy log std Std           0.35330197
Policy log std Max           -0.12744164
Policy log std Min           -2.495167
Z mean eval                  2.1696541
Z variance eval              0.01736121
total_rewards                [7242.57301035 7647.56048482 7436.55393542 7432.65070625 7832.84630897
 7723.54543414 7689.47545919 7963.73261145 7704.43797415 7655.2221715 ]
total_rewards_mean           7632.859809625103
total_rewards_std            199.4200869767306
total_rewards_max            7963.732611446228
total_rewards_min            7242.573010354453
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               31.62743871100247
(Previous) Eval Time (s)     27.921318877954036
Sample Time (s)              20.935219258069992
Epoch Time (s)               80.4839768470265
Total Train Time (s)         11670.938934384845
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:30.099178 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Epoch Duration: 80.92007946968079
2020-01-11 12:45:30.099440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1721935
Z variance train             0.017292937
KL Divergence                30.738293
KL Loss                      3.0738294
QF Loss                      344.6336
VF Loss                      266.31494
Policy Loss                  -2577.519
Q Predictions Mean           2575.3867
Q Predictions Std            696.39294
Q Predictions Max            3326.9248
Q Predictions Min            131.18968
V Predictions Mean           2573.9587
V Predictions Std            691.5307
V Predictions Max            3290.102
V Predictions Min            128.30995
Log Pis Mean                 4.476345
Log Pis Std                  4.6452665
Log Pis Max                  15.229158
Log Pis Min                  -6.2366066
Policy mu Mean               -0.12382728
Policy mu Std                1.366121
Policy mu Max                3.094192
Policy mu Min                -2.8068967
Policy log std Mean          -0.69165134
Policy log std Std           0.35674566
Policy log std Max           0.048240602
Policy log std Min           -2.4141808
Z mean eval                  2.186639
Z variance eval              0.016912075
total_rewards                [7909.08287681 7728.80028692 7993.70263423 8189.40397069 7854.07741244
 8184.13862291 7954.08298718 7900.05607335 7934.25290456 8067.4427184 ]
total_rewards_mean           7971.504048750644
total_rewards_std            136.30015832211308
total_rewards_max            8189.403970690679
total_rewards_min            7728.800286924179
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               33.996261787135154
(Previous) Eval Time (s)     28.357096292078495
Sample Time (s)              22.524886657949537
Epoch Time (s)               84.87824473716319
Total Train Time (s)         11756.10625736788
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.268509 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Epoch Duration: 85.16890907287598
2020-01-11 12:46:55.268730 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1857333
Z variance train             0.016904306
KL Divergence                30.963089
KL Loss                      3.096309
QF Loss                      930.1045
VF Loss                      295.70374
Policy Loss                  -2606.9036
Q Predictions Mean           2606.8584
Q Predictions Std            717.6201
Q Predictions Max            3346.1487
Q Predictions Min            117.75682
V Predictions Mean           2619.331
V Predictions Std            715.3399
V Predictions Max            3372.2458
V Predictions Min            120.90672
Log Pis Mean                 3.4072404
Log Pis Std                  4.3985085
Log Pis Max                  13.635675
Log Pis Min                  -6.324918
Policy mu Mean               -0.11801449
Policy mu Std                1.286422
Policy mu Max                3.292681
Policy mu Min                -2.820134
Policy log std Mean          -0.6730531
Policy log std Std           0.359619
Policy log std Max           -0.011057854
Policy log std Min           -2.5227983
Z mean eval                  2.1801398
Z variance eval              0.016105149
total_rewards                [8033.81073301 7964.38257423 8201.90262438 8112.31099287 8310.37864266
 8165.95527967 7848.13128244 8158.99906105 8020.12560538 7962.91015347]
total_rewards_mean           8077.890694915724
total_rewards_std            130.04697388189726
total_rewards_max            8310.378642661153
total_rewards_min            7848.1312824400875
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               35.16356502985582
(Previous) Eval Time (s)     28.647387025877833
Sample Time (s)              23.160227664746344
Epoch Time (s)               86.97117972048
Total Train Time (s)         11842.536763054319
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:21.701083 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Epoch Duration: 86.43218851089478
2020-01-11 12:48:21.701297 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1836553
Z variance train             0.0160135
KL Divergence                31.08053
KL Loss                      3.108053
QF Loss                      317.73132
VF Loss                      292.46588
Policy Loss                  -2680.1714
Q Predictions Mean           2679.3403
Q Predictions Std            755.68567
Q Predictions Max            3416.0098
Q Predictions Min            131.14708
V Predictions Mean           2666.5222
V Predictions Std            751.3525
V Predictions Max            3361.236
V Predictions Min            132.65543
Log Pis Mean                 4.181818
Log Pis Std                  4.624046
Log Pis Max                  15.526642
Log Pis Min                  -6.7618465
Policy mu Mean               -0.15324421
Policy mu Std                1.3386686
Policy mu Max                2.8726826
Policy mu Min                -2.7971344
Policy log std Mean          -0.67837715
Policy log std Std           0.36563018
Policy log std Max           -0.036978126
Policy log std Min           -2.5403833
Z mean eval                  2.1807866
Z variance eval              0.017010735
total_rewards                [5127.01521167 3293.08600206 3299.60015781 7883.69967112 7736.4225393
 7796.21186622 8084.58621526 7653.32259114 8299.13702327 7886.71832898]
total_rewards_mean           6705.979960682655
total_rewards_std            1900.3195844377187
total_rewards_max            8299.137023269337
total_rewards_min            3293.086002055934
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               34.73040391411632
(Previous) Eval Time (s)     28.108037685975432
Sample Time (s)              23.37034860998392
Epoch Time (s)               86.20879021007568
Total Train Time (s)         11929.39017646201
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:48.556513 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Epoch Duration: 86.85507416725159
2020-01-11 12:49:48.556696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.17959
Z variance train             0.017060356
KL Divergence                30.284977
KL Loss                      3.0284977
QF Loss                      642.35925
VF Loss                      162.909
Policy Loss                  -2703.3018
Q Predictions Mean           2697.425
Q Predictions Std            748.1061
Q Predictions Max            3415.1638
Q Predictions Min            128.95009
V Predictions Mean           2704.9482
V Predictions Std            746.3405
V Predictions Max            3412.483
V Predictions Min            129.41751
Log Pis Mean                 4.3424025
Log Pis Std                  4.4791617
Log Pis Max                  17.391302
Log Pis Min                  -5.875
Policy mu Mean               -0.13399671
Policy mu Std                1.3571267
Policy mu Max                3.2493262
Policy mu Min                -3.1954772
Policy log std Mean          -0.6900994
Policy log std Std           0.37775344
Policy log std Max           -0.02314198
Policy log std Min           -2.587591
Z mean eval                  2.1846442
Z variance eval              0.015598996
total_rewards                [7685.51772389 8275.19315731 7988.67088554 8050.90535399 8056.87854443
 8076.49097113 7848.18197943 7804.51505356 8121.40137335 8161.21998545]
total_rewards_mean           8006.8975028084005
total_rewards_std            169.69196049372056
total_rewards_max            8275.193157313277
total_rewards_min            7685.517723889621
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               34.528948449064046
(Previous) Eval Time (s)     28.753930575214326
Sample Time (s)              23.264798528980464
Epoch Time (s)               86.54767755325884
Total Train Time (s)         12015.596650345717
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:14.769681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Epoch Duration: 86.21283221244812
2020-01-11 12:51:14.769919 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1853175
Z variance train             0.015634859
KL Divergence                30.286522
KL Loss                      3.0286522
QF Loss                      449.727
VF Loss                      299.0274
Policy Loss                  -2595.171
Q Predictions Mean           2599.7405
Q Predictions Std            808.89655
Q Predictions Max            3334.3555
Q Predictions Min            121.14121
V Predictions Mean           2593.8706
V Predictions Std            801.99554
V Predictions Max            3319.1917
V Predictions Min            125.518456
Log Pis Mean                 3.90182
Log Pis Std                  4.8812914
Log Pis Max                  22.247377
Log Pis Min                  -8.107687
Policy mu Mean               -0.10241414
Policy mu Std                1.3309243
Policy mu Max                3.750727
Policy mu Min                -3.9114876
Policy log std Mean          -0.67686707
Policy log std Std           0.37682548
Policy log std Max           0.036878407
Policy log std Min           -2.6026204
Z mean eval                  2.1740806
Z variance eval              0.016438363
total_rewards                [7712.14947511 8181.83242656 8130.48160333 8066.40997955 8216.40211491
 7977.84527479 8219.38489484 8177.84966531 8333.89454116 7864.0805901 ]
total_rewards_mean           8088.0330565667855
total_rewards_std            178.0165983998801
total_rewards_max            8333.894541157872
total_rewards_min            7712.149475109668
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               34.99804446985945
(Previous) Eval Time (s)     28.418695447966456
Sample Time (s)              23.615481947548687
Epoch Time (s)               87.0322218653746
Total Train Time (s)         12101.873331838753
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:41.044777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Epoch Duration: 86.27470970153809
2020-01-11 12:52:41.044982 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1735835
Z variance train             0.016437728
KL Divergence                29.721806
KL Loss                      2.9721806
QF Loss                      1034.8977
VF Loss                      182.78183
Policy Loss                  -2619.8757
Q Predictions Mean           2619.969
Q Predictions Std            763.30774
Q Predictions Max            3350.7356
Q Predictions Min            118.724556
V Predictions Mean           2620.9067
V Predictions Std            759.81506
V Predictions Max            3337.7368
V Predictions Min            119.12189
Log Pis Mean                 3.963673
Log Pis Std                  4.4745493
Log Pis Max                  16.105885
Log Pis Min                  -5.3274183
Policy mu Mean               -0.10852497
Policy mu Std                1.3160682
Policy mu Max                3.2577121
Policy mu Min                -3.0110087
Policy log std Mean          -0.6866922
Policy log std Std           0.35968587
Policy log std Max           -0.067824304
Policy log std Min           -2.4720795
Z mean eval                  2.1812978
Z variance eval              0.022588765
total_rewards                [7980.81079794 8193.6396807  8076.71733921 7982.66283382 8068.2812653
 8113.7116349  8252.75263329 8170.15344308 7871.15815388 8128.67557722]
total_rewards_mean           8083.856335933054
total_rewards_std            108.31353033417643
total_rewards_max            8252.752633288334
total_rewards_min            7871.158153882301
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               33.70450932113454
(Previous) Eval Time (s)     27.660793066956103
Sample Time (s)              22.86515737976879
Epoch Time (s)               84.23045976785943
Total Train Time (s)         12187.383306235075
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:06.556877 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Epoch Duration: 85.51174211502075
2020-01-11 12:54:06.557076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1807172
Z variance train             0.022455912
KL Divergence                29.49115
KL Loss                      2.949115
QF Loss                      291.25793
VF Loss                      208.53003
Policy Loss                  -2717.308
Q Predictions Mean           2725.7637
Q Predictions Std            721.9104
Q Predictions Max            3425.8545
Q Predictions Min            123.27343
V Predictions Mean           2727.772
V Predictions Std            719.3412
V Predictions Max            3418.2422
V Predictions Min            126.74532
Log Pis Mean                 4.4831676
Log Pis Std                  4.7297
Log Pis Max                  14.873716
Log Pis Min                  -5.2306604
Policy mu Mean               -0.14083825
Policy mu Std                1.3717936
Policy mu Max                3.0902903
Policy mu Min                -2.7745898
Policy log std Mean          -0.6773295
Policy log std Std           0.37763205
Policy log std Max           -0.033352077
Policy log std Min           -2.6110125
Z mean eval                  2.1739573
Z variance eval              0.017666081
total_rewards                [8394.79184065 8358.00932333 8061.50860468 8057.27440619 8317.16755266
 8288.77152348 3193.82498633 8372.93169551 8029.84168581 8226.63076156]
total_rewards_mean           7730.075238019733
total_rewards_std            1517.7988587692978
total_rewards_max            8394.791840650349
total_rewards_min            3193.8249863346878
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               34.97083742078394
(Previous) Eval Time (s)     28.941618971992284
Sample Time (s)              23.519856427330524
Epoch Time (s)               87.43231282010674
Total Train Time (s)         12275.292817876674
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:34.468686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Epoch Duration: 87.91145873069763
2020-01-11 12:55:34.468893 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1750267
Z variance train             0.017659504
KL Divergence                29.713604
KL Loss                      2.9713604
QF Loss                      413.0855
VF Loss                      145.6702
Policy Loss                  -2620.3179
Q Predictions Mean           2622.8274
Q Predictions Std            799.8625
Q Predictions Max            3436.7678
Q Predictions Min            121.347305
V Predictions Mean           2616.065
V Predictions Std            799.17957
V Predictions Max            3416.8428
V Predictions Min            109.27268
Log Pis Mean                 4.2571335
Log Pis Std                  4.6509295
Log Pis Max                  15.542897
Log Pis Min                  -6.7210274
Policy mu Mean               -0.09779634
Policy mu Std                1.3570921
Policy mu Max                3.2355702
Policy mu Min                -3.032516
Policy log std Mean          -0.6882505
Policy log std Std           0.38621438
Policy log std Max           -0.06733291
Policy log std Min           -2.6815994
Z mean eval                  2.1841197
Z variance eval              0.015552203
total_rewards                [8222.6328539  8018.87966435 8021.27024279 8278.94598326 8257.77411458
 8558.47921906 7901.6260407  8191.04965231 8543.33674246 8318.70878135]
total_rewards_mean           8231.270329476069
total_rewards_std            203.62698790077326
total_rewards_max            8558.479219061168
total_rewards_min            7901.626040698002
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               34.14721919596195
(Previous) Eval Time (s)     29.420342409051955
Sample Time (s)              24.362708696629852
Epoch Time (s)               87.93027030164376
Total Train Time (s)         12362.16829444142
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:01.346354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Epoch Duration: 86.87731623649597
2020-01-11 12:57:01.346544 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1828792
Z variance train             0.015567553
KL Divergence                29.988707
KL Loss                      2.9988706
QF Loss                      573.16455
VF Loss                      253.85223
Policy Loss                  -2721.856
Q Predictions Mean           2729.6812
Q Predictions Std            855.5803
Q Predictions Max            3466.3062
Q Predictions Min            120.05811
V Predictions Mean           2732.308
V Predictions Std            852.2054
V Predictions Max            3463.9976
V Predictions Min            125.69478
Log Pis Mean                 3.9435625
Log Pis Std                  4.4639707
Log Pis Max                  14.112034
Log Pis Min                  -6.8253584
Policy mu Mean               -0.07139673
Policy mu Std                1.3211466
Policy mu Max                2.85628
Policy mu Min                -3.0030997
Policy log std Mean          -0.68580467
Policy log std Std           0.3820334
Policy log std Max           0.3560654
Policy log std Min           -2.5760899
Z mean eval                  2.1996827
Z variance eval              0.015123211
total_rewards                [8032.85102045 8067.88808157 8138.11705652 8040.87570091 4945.60939462
 8251.79756987 8294.31315824 8261.84623656 8105.66090459 7986.16986662]
total_rewards_mean           7812.512898996198
total_rewards_std            960.9455846948803
total_rewards_max            8294.313158236917
total_rewards_min            4945.609394621281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               34.255717772990465
(Previous) Eval Time (s)     28.366993669886142
Sample Time (s)              23.12407329166308
Epoch Time (s)               85.74678473453969
Total Train Time (s)         12447.836281966884
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:27.016953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Epoch Duration: 85.6702573299408
2020-01-11 12:58:27.017206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2008262
Z variance train             0.015152323
KL Divergence                30.459185
KL Loss                      3.0459185
QF Loss                      648.2738
VF Loss                      226.78369
Policy Loss                  -2753.8606
Q Predictions Mean           2746.866
Q Predictions Std            732.07446
Q Predictions Max            3473.1675
Q Predictions Min            108.01375
V Predictions Mean           2748.4917
V Predictions Std            729.0113
V Predictions Max            3466.8237
V Predictions Min            108.59829
Log Pis Mean                 4.319524
Log Pis Std                  4.410352
Log Pis Max                  18.854507
Log Pis Min                  -4.972476
Policy mu Mean               -0.15832445
Policy mu Std                1.3493961
Policy mu Max                3.336906
Policy mu Min                -3.5219538
Policy log std Mean          -0.6980637
Policy log std Std           0.37110224
Policy log std Max           -0.0024894178
Policy log std Min           -2.4434958
Z mean eval                  2.1964366
Z variance eval              0.012359759
total_rewards                [8107.79827767 8174.99926671 8104.74283201 8307.2220705  7963.7253753
 8076.08363864 8158.69306914 3722.51059333 7800.00738274 7893.78239253]
total_rewards_mean           7630.956489857871
total_rewards_std            1310.1966821664262
total_rewards_max            8307.222070501075
total_rewards_min            3722.510593332787
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.64345977129415
(Previous) Eval Time (s)     28.290116680320352
Sample Time (s)              23.027602296322584
Epoch Time (s)               85.96117874793708
Total Train Time (s)         12533.656794335693
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:52.838898 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Epoch Duration: 85.82153677940369
2020-01-11 12:59:52.839060 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194336
Z variance train             0.012364132
KL Divergence                31.15099
KL Loss                      3.115099
QF Loss                      483.41174
VF Loss                      232.22438
Policy Loss                  -2661.7856
Q Predictions Mean           2672.4243
Q Predictions Std            829.24634
Q Predictions Max            3479.3608
Q Predictions Min            124.254745
V Predictions Mean           2669.0884
V Predictions Std            830.9873
V Predictions Max            3468.9172
V Predictions Min            117.09113
Log Pis Mean                 3.9629035
Log Pis Std                  4.8691263
Log Pis Max                  18.926704
Log Pis Min                  -7.02364
Policy mu Mean               -0.068377644
Policy mu Std                1.3277528
Policy mu Max                2.835916
Policy mu Min                -3.0173485
Policy log std Mean          -0.6776502
Policy log std Std           0.38649938
Policy log std Max           -0.01805988
Policy log std Min           -2.725581
Z mean eval                  2.1913269
Z variance eval              0.012306685
total_rewards                [8055.88837829 8134.17530672 8328.58114563 8032.46381218 7961.75675681
 8237.8845128  8118.17592875 8205.17021746 7993.80224986 8162.36254457]
total_rewards_mean           8123.026085307305
total_rewards_std            109.2262691869434
total_rewards_max            8328.58114563489
total_rewards_min            7961.756756807744
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               32.203697175718844
(Previous) Eval Time (s)     28.150103885680437
Sample Time (s)              21.049227268900722
Epoch Time (s)               81.4030283303
Total Train Time (s)         12614.784143243916
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:13.968694 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Epoch Duration: 81.12951445579529
2020-01-11 13:01:13.968868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.190844
Z variance train             0.012286754
KL Divergence                31.179657
KL Loss                      3.1179657
QF Loss                      503.67444
VF Loss                      238.56946
Policy Loss                  -2651.4604
Q Predictions Mean           2646.427
Q Predictions Std            856.5455
Q Predictions Max            3398.7092
Q Predictions Min            103.810715
V Predictions Mean           2654.853
V Predictions Std            856.7348
V Predictions Max            3401.4172
V Predictions Min            110.66564
Log Pis Mean                 3.8171098
Log Pis Std                  4.448261
Log Pis Max                  16.70994
Log Pis Min                  -5.0599794
Policy mu Mean               -0.101178326
Policy mu Std                1.3052834
Policy mu Max                2.9918728
Policy mu Min                -2.8971944
Policy log std Mean          -0.67693776
Policy log std Std           0.35865656
Policy log std Max           -0.06218344
Policy log std Min           -2.5735424
Z mean eval                  2.1782012
Z variance eval              0.015002829
total_rewards                [7106.10241674 8395.75549472 8335.61862581 8294.1673385  8258.29546361
 8330.44749481 8350.11028251 8251.23925161 8372.49300861 8382.056169  ]
total_rewards_mean           8207.628554592182
total_rewards_std            370.14616595589683
total_rewards_max            8395.755494715408
total_rewards_min            7106.102416741076
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               32.59887999901548
(Previous) Eval Time (s)     27.876289496663958
Sample Time (s)              21.899822616018355
Epoch Time (s)               82.3749921116978
Total Train Time (s)         12697.619671269786
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:36.807329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Epoch Duration: 82.83830714225769
2020-01-11 13:02:36.807637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.177626
Z variance train             0.014954132
KL Divergence                30.536848
KL Loss                      3.053685
QF Loss                      455.80273
VF Loss                      738.08167
Policy Loss                  -2645.9907
Q Predictions Mean           2653.5332
Q Predictions Std            812.8927
Q Predictions Max            3439.4792
Q Predictions Min            96.710434
V Predictions Mean           2664.6445
V Predictions Std            808.546
V Predictions Max            3432.751
V Predictions Min            101.68033
Log Pis Mean                 4.3382387
Log Pis Std                  4.6633787
Log Pis Max                  15.353985
Log Pis Min                  -4.4617596
Policy mu Mean               -0.17368758
Policy mu Std                1.3622711
Policy mu Max                4.3207726
Policy mu Min                -3.463114
Policy log std Mean          -0.6966862
Policy log std Std           0.37037534
Policy log std Max           0.000228405
Policy log std Min           -2.5500858
Z mean eval                  2.1709118
Z variance eval              0.011536563
total_rewards                [8163.43378296 8168.49902448 8336.31668977 8362.42540092 8231.52786885
 8321.64787705 8292.29924114 8307.82509966 8056.59220911 8242.03378643]
total_rewards_mean           8248.260098036659
total_rewards_std            90.7047562483921
total_rewards_max            8362.425400918017
total_rewards_min            8056.592209113478
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               32.66214693989605
(Previous) Eval Time (s)     28.339242266025394
Sample Time (s)              21.866661607753485
Epoch Time (s)               82.86805081367493
Total Train Time (s)         12779.527209723834
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:58.717091 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Epoch Duration: 81.90924620628357
2020-01-11 13:03:58.717281 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1705556
Z variance train             0.011510333
KL Divergence                31.016249
KL Loss                      3.101625
QF Loss                      1170.7958
VF Loss                      287.6662
Policy Loss                  -2654.2622
Q Predictions Mean           2649.7964
Q Predictions Std            778.9335
Q Predictions Max            3390.7097
Q Predictions Min            93.25692
V Predictions Mean           2658.3733
V Predictions Std            773.1238
V Predictions Max            3398.9512
V Predictions Min            107.267426
Log Pis Mean                 3.7786884
Log Pis Std                  4.5174794
Log Pis Max                  17.774292
Log Pis Min                  -9.257866
Policy mu Mean               -0.1434378
Policy mu Std                1.3272784
Policy mu Max                4.925196
Policy mu Min                -3.50671
Policy log std Mean          -0.671478
Policy log std Std           0.3794885
Policy log std Max           0.096235275
Policy log std Min           -2.6341438
Z mean eval                  2.161058
Z variance eval              0.014749801
total_rewards                [8215.01055933 8330.75159695 7745.54277876 8080.68800786 8082.39573593
 8410.17716879 8398.83377979 7816.26723659 8031.50441315 7846.26812753]
total_rewards_mean           8095.743940467682
total_rewards_std            229.71779778780964
total_rewards_max            8410.177168792185
total_rewards_min            7745.542778761427
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               32.28870747704059
(Previous) Eval Time (s)     27.380124324001372
Sample Time (s)              22.83941999077797
Epoch Time (s)               82.50825179181993
Total Train Time (s)         12861.902644032147
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:21.094753 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Epoch Duration: 82.3773398399353
2020-01-11 13:05:21.094929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608405
Z variance train             0.01472949
KL Divergence                30.228409
KL Loss                      3.022841
QF Loss                      767.4296
VF Loss                      260.09085
Policy Loss                  -2772.9883
Q Predictions Mean           2761.1082
Q Predictions Std            766.8192
Q Predictions Max            3497.7207
Q Predictions Min            121.39891
V Predictions Mean           2763.059
V Predictions Std            766.21356
V Predictions Max            3495.3843
V Predictions Min            116.19682
Log Pis Mean                 4.207266
Log Pis Std                  4.755133
Log Pis Max                  17.509733
Log Pis Min                  -7.431881
Policy mu Mean               -0.1649101
Policy mu Std                1.3376147
Policy mu Max                2.8905327
Policy mu Min                -2.811872
Policy log std Mean          -0.7073922
Policy log std Std           0.3705382
Policy log std Max           -0.0059678555
Policy log std Min           -2.6800046
Z mean eval                  2.1682675
Z variance eval              0.016317654
total_rewards                [8338.93478303 8203.07022355 8495.69068551 8431.92074674 8250.21987105
 8231.88062433 8207.3651958  8436.64316631 8536.3160995  8416.22993162]
total_rewards_mean           8354.827132744622
total_rewards_std            118.43759967844558
total_rewards_max            8536.316099497728
total_rewards_min            8203.07022354993
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               32.21453553903848
(Previous) Eval Time (s)     27.248861314263195
Sample Time (s)              22.44150106003508
Epoch Time (s)               81.90489791333675
Total Train Time (s)         12944.035590780899
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:43.228786 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Epoch Duration: 82.13373041152954
2020-01-11 13:06:43.228930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1670048
Z variance train             0.016318586
KL Divergence                30.233809
KL Loss                      3.023381
QF Loss                      308.20233
VF Loss                      278.70557
Policy Loss                  -2789.9438
Q Predictions Mean           2789.7783
Q Predictions Std            584.7291
Q Predictions Max            3480.3813
Q Predictions Min            110.83753
V Predictions Mean           2777.259
V Predictions Std            579.1333
V Predictions Max            3456.7659
V Predictions Min            109.43785
Log Pis Mean                 4.4722176
Log Pis Std                  4.191602
Log Pis Max                  16.762405
Log Pis Min                  -5.4968224
Policy mu Mean               -0.08120951
Policy mu Std                1.3496226
Policy mu Max                3.0048628
Policy mu Min                -3.1860738
Policy log std Mean          -0.7209366
Policy log std Std           0.39630088
Policy log std Max           -0.025103152
Policy log std Min           -2.6640217
Z mean eval                  2.1600013
Z variance eval              0.018863175
total_rewards                [8175.03825279 8228.27016256 8110.70689738 8580.78345492 8145.94168623
 7906.9830663  8498.81926087 8025.16689448 5754.96525512 8309.44694516]
total_rewards_mean           7973.612187581084
total_rewards_std            764.2441691084034
total_rewards_max            8580.783454918585
total_rewards_min            5754.965255118916
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               32.166706276126206
(Previous) Eval Time (s)     27.477429253980517
Sample Time (s)              21.959417109843343
Epoch Time (s)               81.60355263995007
Total Train Time (s)         13025.608002073597
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:04.804701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Epoch Duration: 81.57559752464294
2020-01-11 13:08:04.804971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603985
Z variance train             0.018761765
KL Divergence                29.376331
KL Loss                      2.9376333
QF Loss                      748.91034
VF Loss                      405.7658
Policy Loss                  -2666.9695
Q Predictions Mean           2673.156
Q Predictions Std            849.9787
Q Predictions Max            3464.2207
Q Predictions Min            104.91224
V Predictions Mean           2666.674
V Predictions Std            838.42084
V Predictions Max            3455.7625
V Predictions Min            104.79795
Log Pis Mean                 3.990968
Log Pis Std                  4.812022
Log Pis Max                  16.991848
Log Pis Min                  -7.0292025
Policy mu Mean               -0.051224858
Policy mu Std                1.3403344
Policy mu Max                3.0802205
Policy mu Min                -3.431369
Policy log std Mean          -0.71091604
Policy log std Std           0.3801864
Policy log std Max           -0.08791202
Policy log std Min           -2.4887362
Z mean eval                  2.183313
Z variance eval              0.01875658
total_rewards                [8138.68112638 8196.13400562 8213.06151692 8237.17980699 8454.8290708
 8534.52496643 8380.31321311 8294.39988887 8179.81607736 8314.77694257]
total_rewards_mean           8294.371661504787
total_rewards_std            121.70370828532121
total_rewards_max            8534.524966427543
total_rewards_min            8138.681126384749
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               32.091468083206564
(Previous) Eval Time (s)     27.449103095103055
Sample Time (s)              22.977306901477277
Epoch Time (s)               82.5178780797869
Total Train Time (s)         13108.380205229856
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:27.578169 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Epoch Duration: 82.7729697227478
2020-01-11 13:09:27.578561 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1843288
Z variance train             0.018695083
KL Divergence                30.225536
KL Loss                      3.0225537
QF Loss                      367.27243
VF Loss                      351.9325
Policy Loss                  -2822.964
Q Predictions Mean           2816.8745
Q Predictions Std            642.86456
Q Predictions Max            3483.8079
Q Predictions Min            102.616066
V Predictions Mean           2812.8052
V Predictions Std            635.41565
V Predictions Max            3483.7883
V Predictions Min            111.241615
Log Pis Mean                 4.645456
Log Pis Std                  4.122541
Log Pis Max                  16.314152
Log Pis Min                  -5.810479
Policy mu Mean               -0.18458688
Policy mu Std                1.3911924
Policy mu Max                2.7579005
Policy mu Min                -2.8049376
Policy log std Mean          -0.6953148
Policy log std Std           0.3670618
Policy log std Max           0.06722808
Policy log std Min           -2.5413923
Z mean eval                  2.1707952
Z variance eval              0.019570205
total_rewards                [8394.50978013 8120.94966761 8669.24955646 8390.04871691 8453.33751742
 8504.02741007 8410.53904979 8550.78493647 8614.40231324 8380.45046641]
total_rewards_mean           8448.829941449583
total_rewards_std            144.74607007570927
total_rewards_max            8669.24955646147
total_rewards_min            8120.949667608857
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               32.64221241977066
(Previous) Eval Time (s)     27.70375945419073
Sample Time (s)              21.9531758450903
Epoch Time (s)               82.29914771905169
Total Train Time (s)         13191.177050733007
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:50.377829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Epoch Duration: 82.79907631874084
2020-01-11 13:10:50.378028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1709785
Z variance train             0.019532867
KL Divergence                30.5111
KL Loss                      3.05111
QF Loss                      367.93744
VF Loss                      123.40687
Policy Loss                  -2731.0935
Q Predictions Mean           2728.9363
Q Predictions Std            767.4172
Q Predictions Max            3515.9114
Q Predictions Min            111.92651
V Predictions Mean           2728.6538
V Predictions Std            757.54144
V Predictions Max            3508.8982
V Predictions Min            115.1222
Log Pis Mean                 3.9842062
Log Pis Std                  4.6791973
Log Pis Max                  23.34141
Log Pis Min                  -6.2911525
Policy mu Mean               -0.09305751
Policy mu Std                1.3617815
Policy mu Max                3.7388265
Policy mu Min                -4.3848176
Policy log std Mean          -0.6909594
Policy log std Std           0.37988663
Policy log std Max           -0.07103239
Policy log std Min           -2.6738527
Z mean eval                  2.179823
Z variance eval              0.021304952
total_rewards                [8040.88230212 8000.54138174 7739.20669464 7983.2984479  7891.42486316
 7870.22842351 7491.67943965 7717.56880705 8082.19005766 7622.84153616]
total_rewards_mean           7843.986195359427
total_rewards_std            185.02723554931686
total_rewards_max            8082.190057659273
total_rewards_min            7491.67943965178
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               32.54895751923323
(Previous) Eval Time (s)     28.203358255326748
Sample Time (s)              21.93366146320477
Epoch Time (s)               82.68597723776475
Total Train Time (s)         13273.291741450317
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:12.496401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Epoch Duration: 82.11813831329346
2020-01-11 13:12:12.496714 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.178524
Z variance train             0.02129187
KL Divergence                29.961823
KL Loss                      2.9961822
QF Loss                      361.32373
VF Loss                      339.13947
Policy Loss                  -2718.0022
Q Predictions Mean           2723.6282
Q Predictions Std            785.4607
Q Predictions Max            3500.926
Q Predictions Min            94.73536
V Predictions Mean           2733.1675
V Predictions Std            781.8608
V Predictions Max            3499.9858
V Predictions Min            114.96151
Log Pis Mean                 4.367237
Log Pis Std                  4.5824003
Log Pis Max                  14.5554085
Log Pis Min                  -5.6210938
Policy mu Mean               -0.10741816
Policy mu Std                1.3480103
Policy mu Max                2.8335993
Policy mu Min                -2.894303
Policy log std Mean          -0.70940137
Policy log std Std           0.41077542
Policy log std Max           -0.006300628
Policy log std Min           -2.6367137
Z mean eval                  2.1694179
Z variance eval              0.013005981
total_rewards                [8202.60558273 8158.5091134  8544.70470801 8257.17946169 8325.70968888
 8605.8972472  8344.57999227 8370.27727219 8254.70665527 8340.48546391]
total_rewards_mean           8340.4655185557
total_rewards_std            134.05062428784456
total_rewards_max            8605.897247204748
total_rewards_min            8158.5091133999595
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               32.4697908628732
(Previous) Eval Time (s)     27.63518008682877
Sample Time (s)              21.437140248250216
Epoch Time (s)               81.54211119795218
Total Train Time (s)         13355.745125736576
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:34.951727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Epoch Duration: 82.45482444763184
2020-01-11 13:13:34.951957 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1710582
Z variance train             0.012960616
KL Divergence                30.515244
KL Loss                      3.0515244
QF Loss                      541.72076
VF Loss                      391.02557
Policy Loss                  -2659.5867
Q Predictions Mean           2664.122
Q Predictions Std            880.4134
Q Predictions Max            3469.4194
Q Predictions Min            121.6832
V Predictions Mean           2644.1023
V Predictions Std            876.82654
V Predictions Max            3442.1982
V Predictions Min            105.4444
Log Pis Mean                 3.4008212
Log Pis Std                  4.78595
Log Pis Max                  16.434406
Log Pis Min                  -6.613274
Policy mu Mean               -0.13765144
Policy mu Std                1.2866412
Policy mu Max                3.2824528
Policy mu Min                -2.7179706
Policy log std Mean          -0.6652009
Policy log std Std           0.3941817
Policy log std Max           -0.05624205
Policy log std Min           -2.7297373
Z mean eval                  2.1655755
Z variance eval              0.014214613
total_rewards                [8099.94006133 8167.32459464 8257.26241321 8303.75253973 8254.84442949
 8046.39010227 8099.02356375 8160.19886168 8092.15345837 8211.39967521]
total_rewards_mean           8169.228969966609
total_rewards_std            81.11707377019452
total_rewards_max            8303.75253972667
total_rewards_min            8046.390102265963
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               31.936776144895703
(Previous) Eval Time (s)     28.54758922290057
Sample Time (s)              22.604899014811963
Epoch Time (s)               83.08926438260823
Total Train Time (s)         13438.980610733852
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:58.191410 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Epoch Duration: 83.2392737865448
2020-01-11 13:14:58.191658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669714
Z variance train             0.014210914
KL Divergence                30.007301
KL Loss                      3.0007303
QF Loss                      3509.3289
VF Loss                      518.5312
Policy Loss                  -2796.788
Q Predictions Mean           2806.7036
Q Predictions Std            711.47784
Q Predictions Max            3504.0176
Q Predictions Min            97.70087
V Predictions Mean           2812.1353
V Predictions Std            709.28094
V Predictions Max            3527.7708
V Predictions Min            115.684845
Log Pis Mean                 4.4185305
Log Pis Std                  4.6406803
Log Pis Max                  17.608948
Log Pis Min                  -5.0928106
Policy mu Mean               -0.16481362
Policy mu Std                1.343435
Policy mu Max                2.6524968
Policy mu Min                -3.396403
Policy log std Mean          -0.7074659
Policy log std Std           0.39325824
Policy log std Max           0.03947586
Policy log std Min           -2.5490289
Z mean eval                  2.1748815
Z variance eval              0.010858184
total_rewards                [8476.36278425 8253.97637014 8284.96491802 8442.04014319 8239.25395211
 8248.08684507 3271.24051223 8147.87642314 8439.1778131  8654.72169791]
total_rewards_mean           7845.770145915629
total_rewards_std            1531.4542902685248
total_rewards_max            8654.72169791136
total_rewards_min            3271.240512230066
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               32.199974542018026
(Previous) Eval Time (s)     28.697162138298154
Sample Time (s)              21.68065315578133
Epoch Time (s)               82.57778983609751
Total Train Time (s)         13520.847769537475
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:20.059058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Epoch Duration: 81.86723279953003
2020-01-11 13:16:20.059304 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.174609
Z variance train             0.010878979
KL Divergence                30.90638
KL Loss                      3.090638
QF Loss                      419.08328
VF Loss                      159.76161
Policy Loss                  -2783.644
Q Predictions Mean           2779.6377
Q Predictions Std            804.0906
Q Predictions Max            3529.5251
Q Predictions Min            78.02862
V Predictions Mean           2783.2769
V Predictions Std            798.8961
V Predictions Max            3514.6987
V Predictions Min            110.62862
Log Pis Mean                 4.13972
Log Pis Std                  4.448639
Log Pis Max                  17.953396
Log Pis Min                  -6.615619
Policy mu Mean               -0.09892393
Policy mu Std                1.3380995
Policy mu Max                3.1350775
Policy mu Min                -2.9906292
Policy log std Mean          -0.71696645
Policy log std Std           0.3966439
Policy log std Max           -0.05039394
Policy log std Min           -2.65165
Z mean eval                  2.16568
Z variance eval              0.022873867
total_rewards                [8229.81716236 8244.07644588 8257.51512198 8269.64558066 8361.15359317
 8201.39307414 8364.60204365 8539.99478251 8293.10329527 8648.9653141 ]
total_rewards_mean           8341.026641371334
total_rewards_std            138.20489848700578
total_rewards_max            8648.96531409905
total_rewards_min            8201.393074135114
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               32.98062768206
(Previous) Eval Time (s)     27.986317292321473
Sample Time (s)              22.74931017216295
Epoch Time (s)               83.71625514654443
Total Train Time (s)         13605.065778617747
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:44.279285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Epoch Duration: 84.21983814239502
2020-01-11 13:17:44.279473 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166281
Z variance train             0.022862151
KL Divergence                29.473824
KL Loss                      2.9473825
QF Loss                      629.7709
VF Loss                      130.5994
Policy Loss                  -2846.6323
Q Predictions Mean           2842.9453
Q Predictions Std            700.7001
Q Predictions Max            3543.0557
Q Predictions Min            94.47828
V Predictions Mean           2844.417
V Predictions Std            694.47406
V Predictions Max            3554.136
V Predictions Min            108.022484
Log Pis Mean                 4.157975
Log Pis Std                  4.6733356
Log Pis Max                  16.821898
Log Pis Min                  -6.384578
Policy mu Mean               -0.15417977
Policy mu Std                1.331062
Policy mu Max                2.7439165
Policy mu Min                -2.7177057
Policy log std Mean          -0.7120936
Policy log std Std           0.38676226
Policy log std Max           0.0086301565
Policy log std Min           -2.576136
Z mean eval                  2.1748798
Z variance eval              0.018965434
total_rewards                [8219.58300013 8420.37895809 8320.75910237 8303.12013761 7954.93734154
 8173.32211931 8153.44788183 8310.52779949 7908.68044639 8359.98127498]
total_rewards_mean           8212.473806174095
total_rewards_std            160.69316879055128
total_rewards_max            8420.378958091467
total_rewards_min            7908.68044639193
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               32.18664012989029
(Previous) Eval Time (s)     28.489611845929176
Sample Time (s)              22.754182788543403
Epoch Time (s)               83.43043476436287
Total Train Time (s)         13687.096014835406
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:19:06.312846 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Epoch Duration: 82.0332293510437
2020-01-11 13:19:06.313032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.175464
Z variance train             0.019055964
KL Divergence                29.775196
KL Loss                      2.9775198
QF Loss                      601.7307
VF Loss                      303.30115
Policy Loss                  -2773.6519
Q Predictions Mean           2775.8154
Q Predictions Std            713.75635
Q Predictions Max            3498.1023
Q Predictions Min            98.72823
V Predictions Mean           2766.0005
V Predictions Std            709.13
V Predictions Max            3512.482
V Predictions Min            99.84457
Log Pis Mean                 4.1663322
Log Pis Std                  4.0161157
Log Pis Max                  14.012211
Log Pis Min                  -5.0645766
Policy mu Mean               -0.12358788
Policy mu Std                1.3212898
Policy mu Max                2.8414638
Policy mu Min                -3.0020294
Policy log std Mean          -0.70111674
Policy log std Std           0.38520968
Policy log std Max           0.14287704
Policy log std Min           -2.4891844
Z mean eval                  2.151649
Z variance eval              0.015551589
total_rewards                [8039.96656793 8464.42623389 8406.18784284 8472.74279395 8259.00237781
 8638.71358436 8424.51548038 8422.75466618 8441.11466642 8637.81456213]
total_rewards_mean           8420.72387758888
total_rewards_std            164.63271074116298
total_rewards_max            8638.713584356521
total_rewards_min            8039.966567929045
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               32.4438710231334
(Previous) Eval Time (s)     27.092116343788803
Sample Time (s)              22.196449742652476
Epoch Time (s)               81.73243710957468
Total Train Time (s)         13768.84188422421
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:20:28.060929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Epoch Duration: 81.7477376461029
2020-01-11 13:20:28.061255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1522832
Z variance train             0.015551744
KL Divergence                29.543638
KL Loss                      2.9543638
QF Loss                      861.64166
VF Loss                      415.15454
Policy Loss                  -2632.791
Q Predictions Mean           2632.8745
Q Predictions Std            800.7468
Q Predictions Max            3398.1582
Q Predictions Min            91.48517
V Predictions Mean           2640.9004
V Predictions Std            796.5296
V Predictions Max            3406.344
V Predictions Min            93.33141
Log Pis Mean                 4.0421505
Log Pis Std                  4.9423714
Log Pis Max                  36.666397
Log Pis Min                  -5.789901
Policy mu Mean               -0.08218036
Policy mu Std                1.3369756
Policy mu Max                6.289949
Policy mu Min                -5.6987963
Policy log std Mean          -0.7073717
Policy log std Std           0.38669866
Policy log std Max           0.65917134
Policy log std Min           -2.4734476
Z mean eval                  2.1688173
Z variance eval              0.016570847
total_rewards                [8259.4340206  8629.87727786 8579.09681932 8556.82068386 8395.30840031
 8548.68858561 8906.00811868 8399.48046464 8720.79725734 8439.29390349]
total_rewards_mean           8543.480553170908
total_rewards_std            174.93820265544375
total_rewards_max            8906.008118675029
total_rewards_min            8259.434020604913
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               32.31722186226398
(Previous) Eval Time (s)     27.107090051751584
Sample Time (s)              22.316013004630804
Epoch Time (s)               81.74032491864637
Total Train Time (s)         13851.967588198837
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:51.188908 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Epoch Duration: 83.12745714187622
2020-01-11 13:21:51.189113 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.169198
Z variance train             0.01651583
KL Divergence                30.049644
KL Loss                      3.0049646
QF Loss                      302.8443
VF Loss                      136.39145
Policy Loss                  -2713.68
Q Predictions Mean           2711.9937
Q Predictions Std            842.2739
Q Predictions Max            3482.4666
Q Predictions Min            99.43801
V Predictions Mean           2708.212
V Predictions Std            838.00885
V Predictions Max            3464.1143
V Predictions Min            98.93197
Log Pis Mean                 4.215662
Log Pis Std                  4.1973977
Log Pis Max                  13.698294
Log Pis Min                  -4.776114
Policy mu Mean               -0.11331111
Policy mu Std                1.3591719
Policy mu Max                2.8281724
Policy mu Min                -2.8064005
Policy log std Mean          -0.6884372
Policy log std Std           0.38625476
Policy log std Max           0.07525736
Policy log std Min           -2.6204925
Z mean eval                  2.1605563
Z variance eval              0.011455504
total_rewards                [8382.97185551 8195.44935824 8339.59833157 8324.23237442 8262.85107056
 8352.30952772 8333.13939758 8271.54119936 8123.42673695 8240.80464055]
total_rewards_mean           8282.632449246874
total_rewards_std            75.93467165878499
total_rewards_max            8382.971855505491
total_rewards_min            8123.4267369468
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.253836817108095
(Previous) Eval Time (s)     28.49390060873702
Sample Time (s)              22.184308847412467
Epoch Time (s)               82.93204627325758
Total Train Time (s)         13933.113986016251
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:12.336385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Epoch Duration: 81.14712333679199
2020-01-11 13:23:12.336591 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1631608
Z variance train             0.011473628
KL Divergence                30.803967
KL Loss                      3.0803967
QF Loss                      579.1387
VF Loss                      166.38017
Policy Loss                  -2803.6963
Q Predictions Mean           2802.982
Q Predictions Std            724.9704
Q Predictions Max            3490.7314
Q Predictions Min            120.048256
V Predictions Mean           2802.4062
V Predictions Std            725.3629
V Predictions Max            3466.6233
V Predictions Min            108.59888
Log Pis Mean                 4.529895
Log Pis Std                  4.411736
Log Pis Max                  16.078285
Log Pis Min                  -5.445009
Policy mu Mean               -0.15306813
Policy mu Std                1.3663051
Policy mu Max                2.6738825
Policy mu Min                -3.2899528
Policy log std Mean          -0.70974034
Policy log std Std           0.38388225
Policy log std Max           -0.03130266
Policy log std Min           -2.7281032
Z mean eval                  2.1685703
Z variance eval              0.007972
total_rewards                [8406.69938312 8582.78047879 8339.85780719 8681.12512202 8639.57270943
 8774.80129471 8526.57793607 8653.86389717 8495.99998097 8739.25267889]
total_rewards_mean           8584.053128834974
total_rewards_std            134.16213425986922
total_rewards_max            8774.80129470524
total_rewards_min            8339.857807186525
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               32.5951568428427
(Previous) Eval Time (s)     26.708627664018422
Sample Time (s)              22.599341060500592
Epoch Time (s)               81.90312556736171
Total Train Time (s)         14016.030942118261
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:24:35.254572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Epoch Duration: 82.9178307056427
2020-01-11 13:24:35.254718 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1667483
Z variance train             0.007983036
KL Divergence                31.342255
KL Loss                      3.1342256
QF Loss                      882.99713
VF Loss                      459.3475
Policy Loss                  -2766.6726
Q Predictions Mean           2763.5461
Q Predictions Std            794.5885
Q Predictions Max            3512.4114
Q Predictions Min            104.48339
V Predictions Mean           2768.1936
V Predictions Std            792.9538
V Predictions Max            3483.6084
V Predictions Min            105.471085
Log Pis Mean                 4.704301
Log Pis Std                  4.863737
Log Pis Max                  15.959921
Log Pis Min                  -4.7189775
Policy mu Mean               -0.14056568
Policy mu Std                1.3779981
Policy mu Max                4.727532
Policy mu Min                -2.7378557
Policy log std Mean          -0.7103374
Policy log std Std           0.39875862
Policy log std Max           -0.052495778
Policy log std Min           -2.851142
Z mean eval                  2.2038207
Z variance eval              0.009045398
total_rewards                [8413.73125389 8070.50420539 4568.65701964 8314.92877818 8051.53928728
 8029.45772827 8512.82419425 8199.88311927 7978.88521857 1267.89955853]
total_rewards_mean           7140.8310363274095
total_rewards_std            2242.6728307029566
total_rewards_max            8512.824194245835
total_rewards_min            1267.8995585296811
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               32.320627447683364
(Previous) Eval Time (s)     27.722990276291966
Sample Time (s)              21.704000238329172
Epoch Time (s)               81.7476179623045
Total Train Time (s)         14097.59427313134
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:25:56.821142 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Epoch Duration: 81.56631064414978
2020-01-11 13:25:56.821322 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2026305
Z variance train             0.009038573
KL Divergence                31.4452
KL Loss                      3.14452
QF Loss                      534.20526
VF Loss                      258.1293
Policy Loss                  -2828.897
Q Predictions Mean           2831.3408
Q Predictions Std            679.627
Q Predictions Max            3493.1575
Q Predictions Min            88.73053
V Predictions Mean           2830.5688
V Predictions Std            676.93195
V Predictions Max            3499.0598
V Predictions Min            102.54018
Log Pis Mean                 4.383283
Log Pis Std                  4.4419017
Log Pis Max                  16.450771
Log Pis Min                  -7.1141253
Policy mu Mean               -0.08657404
Policy mu Std                1.3680065
Policy mu Max                3.9902823
Policy mu Min                -2.8494825
Policy log std Mean          -0.699058
Policy log std Std           0.36272112
Policy log std Max           0.031098366
Policy log std Min           -2.6377742
Z mean eval                  2.1612115
Z variance eval              0.00840072
total_rewards                [8290.14506568 8630.34966887 8508.26635439 8453.53908703 8557.12844672
 8613.60960602 8537.36778551 8303.8388728  8441.50181925 8255.97944083]
total_rewards_mean           8459.17261470964
total_rewards_std            128.68672676502723
total_rewards_max            8630.349668870773
total_rewards_min            8255.979440834235
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               32.161389937624335
(Previous) Eval Time (s)     27.541303574107587
Sample Time (s)              22.56612768024206
Epoch Time (s)               82.26882119197398
Total Train Time (s)         14180.810064418707
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:27:20.040601 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Epoch Duration: 83.21915698051453
2020-01-11 13:27:20.040802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1610477
Z variance train             0.008403895
KL Divergence                31.234488
KL Loss                      3.1234488
QF Loss                      558.047
VF Loss                      285.93826
Policy Loss                  -2784.5137
Q Predictions Mean           2795.9312
Q Predictions Std            797.0648
Q Predictions Max            3580.4355
Q Predictions Min            102.12215
V Predictions Mean           2797.5898
V Predictions Std            793.1001
V Predictions Max            3567.28
V Predictions Min            105.9998
Log Pis Mean                 3.9836402
Log Pis Std                  4.316862
Log Pis Max                  13.378947
Log Pis Min                  -5.7061806
Policy mu Mean               -0.072469026
Policy mu Std                1.3339747
Policy mu Max                2.8003051
Policy mu Min                -2.863253
Policy log std Mean          -0.68844557
Policy log std Std           0.3778439
Policy log std Max           0.14966619
Policy log std Min           -2.4936337
Z mean eval                  2.1902947
Z variance eval              0.0108958855
total_rewards                [8264.20879001 8288.82005058 8459.09039862 8387.04577643 8370.18232368
 8566.39719559 8231.9561798  8263.19556451 8372.29962103 8142.08023893]
total_rewards_mean           8334.527613917437
total_rewards_std            115.9373112219732
total_rewards_max            8566.39719559325
total_rewards_min            8142.080238930463
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               32.19271402899176
(Previous) Eval Time (s)     28.491293444298208
Sample Time (s)              22.75798770133406
Epoch Time (s)               83.44199517462403
Total Train Time (s)         14263.511980766896
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:28:42.744769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Epoch Duration: 82.70381116867065
2020-01-11 13:28:42.744977 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.192122
Z variance train             0.010868586
KL Divergence                31.347183
KL Loss                      3.1347184
QF Loss                      868.23676
VF Loss                      161.67984
Policy Loss                  -2865.65
Q Predictions Mean           2866.3337
Q Predictions Std            661.33044
Q Predictions Max            3537.289
Q Predictions Min            94.92277
V Predictions Mean           2862.4402
V Predictions Std            651.7874
V Predictions Max            3522.557
V Predictions Min            98.013504
Log Pis Mean                 4.538002
Log Pis Std                  4.4060307
Log Pis Max                  14.86231
Log Pis Min                  -6.5945315
Policy mu Mean               -0.026469626
Policy mu Std                1.3883978
Policy mu Max                3.7622716
Policy mu Min                -3.2624235
Policy log std Mean          -0.68867683
Policy log std Std           0.35682368
Policy log std Max           0.08361256
Policy log std Min           -2.8073144
Z mean eval                  2.1598158
Z variance eval              0.010527335
total_rewards                [8535.07867381 8708.7372515  8596.75905993 8553.08074658 8735.29591357
 8451.72357209 8675.34937832 8496.20711341 8645.41239634 8761.59180427]
total_rewards_mean           8615.923590982367
total_rewards_std            100.31473140288021
total_rewards_max            8761.591804266818
total_rewards_min            8451.723572087574
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               32.202936307061464
(Previous) Eval Time (s)     27.752759610768408
Sample Time (s)              22.724454111419618
Epoch Time (s)               82.68015002924949
Total Train Time (s)         14347.33307537809
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:30:06.567909 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Epoch Duration: 83.8227813243866
2020-01-11 13:30:06.568117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1600502
Z variance train             0.010540567
KL Divergence                31.090147
KL Loss                      3.1090147
QF Loss                      594.60254
VF Loss                      164.14493
Policy Loss                  -2892.645
Q Predictions Mean           2891.8071
Q Predictions Std            668.01166
Q Predictions Max            3515.6978
Q Predictions Min            99.55593
V Predictions Mean           2896.0654
V Predictions Std            664.8419
V Predictions Max            3502.2524
V Predictions Min            96.603455
Log Pis Mean                 4.936455
Log Pis Std                  5.019488
Log Pis Max                  20.221407
Log Pis Min                  -6.756613
Policy mu Mean               -0.16185905
Policy mu Std                1.4103508
Policy mu Max                3.297838
Policy mu Min                -2.754206
Policy log std Mean          -0.71321255
Policy log std Std           0.38029778
Policy log std Max           -0.03395334
Policy log std Min           -2.5858603
Z mean eval                  2.1648152
Z variance eval              0.008551662
total_rewards                [8253.70767244 8351.71341665 8230.09456064 8234.58328714 8350.06397107
 8135.84320851 8214.77210547 8273.71028071 8144.26533834 8315.63639373]
total_rewards_mean           8250.43902347096
total_rewards_std            71.64289795135831
total_rewards_max            8351.71341665464
total_rewards_min            8135.8432085146915
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               32.477429947815835
(Previous) Eval Time (s)     28.895091965794563
Sample Time (s)              22.85416153864935
Epoch Time (s)               84.22668345225975
Total Train Time (s)         14430.384973485488
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:31:29.622122 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Epoch Duration: 83.05386662483215
2020-01-11 13:31:29.622310 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Started Training: True
