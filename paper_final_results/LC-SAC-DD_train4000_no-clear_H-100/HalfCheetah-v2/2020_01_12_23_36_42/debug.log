---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018217813
Z variance train             0.69422555
KL Divergence                0.14797209
KL Loss                      0.01479721
QF Loss                      46.70729
VF Loss                      16.16856
Policy Loss                  -3.9819906
Q Predictions Mean           -0.0022512947
Q Predictions Std            0.0025138475
Q Predictions Max            0.004002746
Q Predictions Min            -0.01302879
V Predictions Mean           -0.0015676554
V Predictions Std            0.0012872805
V Predictions Max            0.002257069
V Predictions Min            -0.0043354146
Log Pis Mean                 -4.0087533
Log Pis Std                  0.5476844
Log Pis Max                  -2.222971
Log Pis Min                  -5.732667
Policy mu Mean               -0.000108715765
Policy mu Std                0.0013636658
Policy mu Max                0.004181002
Policy mu Min                -0.0046730456
Policy log std Mean          -0.0005662386
Policy log std Std           0.0011472128
Policy log std Max           0.0024465274
Policy log std Min           -0.005169934
Z mean eval                  1.116185
Z variance eval              0.0277536
total_rewards                [-176.68147304 -162.82313212 -131.92605433 -134.69176998 -145.40821626
 -166.60860951 -144.72816838 -159.0413528  -162.65548998 -163.03671473]
total_rewards_mean           -154.76009811369642
total_rewards_std            13.954726129258347
total_rewards_max            -131.9260543302745
total_rewards_min            -176.68147303840618
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               186.53654375625774
(Previous) Eval Time (s)     0
Sample Time (s)              12.13370274938643
Epoch Time (s)               198.67024650564417
Total Train Time (s)         224.2318981741555
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:40:26.898523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #0 | Epoch Duration: 224.23730158805847
2020-01-12 23:40:26.898933 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1214924
Z variance train             0.027339641
KL Divergence                10.77993
KL Loss                      1.077993
QF Loss                      66.98274
VF Loss                      11.140207
Policy Loss                  -45.446598
Q Predictions Mean           40.777805
Q Predictions Std            17.961557
Q Predictions Max            102.1574
Q Predictions Min            -15.156419
V Predictions Mean           46.68647
V Predictions Std            18.072783
V Predictions Max            106.22539
V Predictions Min            -10.304118
Log Pis Mean                 -3.4148583
Log Pis Std                  1.1387757
Log Pis Max                  0.4574468
Log Pis Min                  -6.0104647
Policy mu Mean               0.0055068075
Policy mu Std                0.3501075
Policy mu Max                1.7192687
Policy mu Min                -1.1769842
Policy log std Mean          -0.29517165
Policy log std Std           0.07782974
Policy log std Max           -0.15623376
Policy log std Min           -0.65803015
Z mean eval                  1.2590775
Z variance eval              0.03814055
total_rewards                [-107.53743752  -80.08427627 -109.28842128  -75.67491544  -69.15325952
 -146.80039312 -118.89520327  -99.35622364 -107.56259512 -107.76168299]
total_rewards_mean           -102.21144081826144
total_rewards_std            21.67765378570854
total_rewards_max            -69.15325951912568
total_rewards_min            -146.8003931184388
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               187.03156457981095
(Previous) Eval Time (s)     30.042155583389103
Sample Time (s)              6.247888636775315
Epoch Time (s)               223.32160879997537
Total Train Time (s)         447.6399909341708
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:10.306265 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #1 | Epoch Duration: 223.40710163116455
2020-01-12 23:44:10.306489 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.277373
Z variance train             0.032901075
KL Divergence                11.767029
KL Loss                      1.1767029
QF Loss                      67.1552
VF Loss                      14.082468
Policy Loss                  -99.247925
Q Predictions Mean           94.26979
Q Predictions Std            31.237263
Q Predictions Max            183.1977
Q Predictions Min            36.05584
V Predictions Mean           100.23398
V Predictions Std            31.542786
V Predictions Max            189.27489
V Predictions Min            44.259483
Log Pis Mean                 -3.0476556
Log Pis Std                  1.5417147
Log Pis Max                  2.564364
Log Pis Min                  -6.804138
Policy mu Mean               -0.029190028
Policy mu Std                0.4472133
Policy mu Max                1.6589332
Policy mu Min                -1.6432871
Policy log std Mean          -0.33671793
Policy log std Std           0.08637738
Policy log std Max           -0.08763477
Policy log std Min           -0.716629
Z mean eval                  1.4096673
Z variance eval              0.02574269
total_rewards                [-33.76866321 -16.98020005 -77.1960117  -54.66192864 -20.25635187
 -81.87233324 -44.45306427 -25.35346134 -23.96772246 -24.38064153]
total_rewards_mean           -40.28903783060967
total_rewards_std            22.460796620418655
total_rewards_max            -16.980200047569635
total_rewards_min            -81.8723332425624
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               186.47235961584374
(Previous) Eval Time (s)     30.114270615857095
Sample Time (s)              6.181578679941595
Epoch Time (s)               222.76820891164243
Total Train Time (s)         670.4931228985079
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:53.158674 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #2 | Epoch Duration: 222.85204982757568
2020-01-12 23:47:53.158805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4093043
Z variance train             0.025942218
KL Divergence                13.281265
KL Loss                      1.3281265
QF Loss                      62.632263
VF Loss                      17.808714
Policy Loss                  -133.93066
Q Predictions Mean           129.27301
Q Predictions Std            42.240784
Q Predictions Max            271.20953
Q Predictions Min            46.216522
V Predictions Mean           135.80557
V Predictions Std            43.28236
V Predictions Max            266.66885
V Predictions Min            67.841064
Log Pis Mean                 -3.2598743
Log Pis Std                  1.3449094
Log Pis Max                  1.7769213
Log Pis Min                  -7.628059
Policy mu Mean               -0.07194036
Policy mu Std                0.40809822
Policy mu Max                1.6317571
Policy mu Min                -1.7478905
Policy log std Mean          -0.34424224
Policy log std Std           0.08867723
Policy log std Max           -0.14676315
Policy log std Min           -0.73211396
Z mean eval                  1.4753469
Z variance eval              0.023215115
total_rewards                [ 10.54584085  37.27142214 200.56970817  19.33331714  36.11372866
  35.56601372  13.04012965 -39.66171746  40.32447268 104.09874044]
total_rewards_mean           45.720165599299854
total_rewards_std            61.62294510274914
total_rewards_max            200.56970816923382
total_rewards_min            -39.66171746003335
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               187.00732743926346
(Previous) Eval Time (s)     29.70598462410271
Sample Time (s)              6.11197341280058
Epoch Time (s)               222.82528547616675
Total Train Time (s)         893.4041896606795
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:36.072915 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #3 | Epoch Duration: 222.91401386260986
2020-01-12 23:51:36.073049 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4669424
Z variance train             0.02384245
KL Divergence                14.946822
KL Loss                      1.4946822
QF Loss                      127.47774
VF Loss                      12.95183
Policy Loss                  -162.3078
Q Predictions Mean           156.99051
Q Predictions Std            48.539085
Q Predictions Max            283.41388
Q Predictions Min            85.95802
V Predictions Mean           162.06754
V Predictions Std            49.139782
V Predictions Max            298.8394
V Predictions Min            91.71025
Log Pis Mean                 -3.2184267
Log Pis Std                  1.3948534
Log Pis Max                  1.9477053
Log Pis Min                  -6.8302593
Policy mu Mean               0.046453606
Policy mu Std                0.39981836
Policy mu Max                1.758706
Policy mu Min                -1.2574633
Policy log std Mean          -0.33202043
Policy log std Std           0.09875174
Policy log std Max           -0.15120758
Policy log std Min           -0.7950415
Z mean eval                  1.5570865
Z variance eval              0.021421911
total_rewards                [140.07979102 240.58030136 168.53211327 108.01399601 146.93479265
  91.1531475  361.85942735  -4.80900143 154.47942644 502.0021912 ]
total_rewards_mean           190.88261853666575
total_rewards_std            137.82009273189257
total_rewards_max            502.00219120208794
total_rewards_min            -4.8090014258084315
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               187.89768052566797
(Previous) Eval Time (s)     29.900995818898082
Sample Time (s)              6.131760641001165
Epoch Time (s)               223.9304369855672
Total Train Time (s)         1117.4176962003112
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:55:20.086338 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #4 | Epoch Duration: 224.01317739486694
2020-01-12 23:55:20.086531 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5505717
Z variance train             0.021375576
KL Divergence                16.483246
KL Loss                      1.6483246
QF Loss                      181.74393
VF Loss                      14.498477
Policy Loss                  -194.50089
Q Predictions Mean           190.82387
Q Predictions Std            54.94892
Q Predictions Max            327.63672
Q Predictions Min            97.83941
V Predictions Mean           196.74324
V Predictions Std            54.995605
V Predictions Max            326.5769
V Predictions Min            112.95401
Log Pis Mean                 -3.1192887
Log Pis Std                  1.2693834
Log Pis Max                  2.7853668
Log Pis Min                  -7.658803
Policy mu Mean               0.024820572
Policy mu Std                0.42808315
Policy mu Max                1.7239971
Policy mu Min                -1.3266675
Policy log std Mean          -0.34526873
Policy log std Std           0.10341434
Policy log std Max           -0.05072297
Policy log std Min           -0.87378
Z mean eval                  1.5336038
Z variance eval              0.03014021
total_rewards                [1125.81580222 1057.41400578 1009.91205917 1029.08728079 1120.49020476
 1217.52115024 1088.9481573  1035.32626134   18.09231069  956.59804938]
total_rewards_mean           965.9205281664656
total_rewards_std            323.33816636329624
total_rewards_max            1217.5211502440886
total_rewards_min            18.09231069439796
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               187.03594610933214
(Previous) Eval Time (s)     29.98667796002701
Sample Time (s)              6.215880207251757
Epoch Time (s)               223.2385042766109
Total Train Time (s)         1340.7547774175182
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:59:03.423487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #5 | Epoch Duration: 223.33680272102356
2020-01-12 23:59:03.423621 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5315522
Z variance train             0.030231914
KL Divergence                14.619421
KL Loss                      1.4619421
QF Loss                      53.48102
VF Loss                      12.250276
Policy Loss                  -209.51338
Q Predictions Mean           203.33054
Q Predictions Std            60.78292
Q Predictions Max            362.1008
Q Predictions Min            110.38847
V Predictions Mean           208.46619
V Predictions Std            61.18456
V Predictions Max            358.91928
V Predictions Min            117.53277
Log Pis Mean                 -3.1357718
Log Pis Std                  1.3853381
Log Pis Max                  1.5750802
Log Pis Min                  -7.57645
Policy mu Mean               -0.021327076
Policy mu Std                0.4213952
Policy mu Max                2.038096
Policy mu Min                -1.5391566
Policy log std Mean          -0.33819246
Policy log std Std           0.09634786
Policy log std Max           -0.13392954
Policy log std Min           -0.87926114
Z mean eval                  1.5770445
Z variance eval              0.03206729
total_rewards                [ 345.42046229 1477.05803139 1564.00451053 1404.98583175 1488.64931956
 1544.67485028 1424.39850163 1424.8591545  1595.52064989  264.6393122 ]
total_rewards_mean           1253.4210624009754
total_rewards_std            478.26973818349325
total_rewards_max            1595.5206498943685
total_rewards_min            264.63931219771666
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               186.6105377781205
(Previous) Eval Time (s)     30.22968444507569
Sample Time (s)              6.121593052987009
Epoch Time (s)               222.9618152761832
Total Train Time (s)         1563.8031677026302
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:02:46.473205 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #6 | Epoch Duration: 223.049485206604
2020-01-13 00:02:46.473334 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7119061
Z variance train             0.028880779
KL Divergence                17.330532
KL Loss                      1.7330532
QF Loss                      75.96162
VF Loss                      16.831284
Policy Loss                  -250.59352
Q Predictions Mean           243.78476
Q Predictions Std            78.02409
Q Predictions Max            488.13678
Q Predictions Min            139.87979
V Predictions Mean           248.8775
V Predictions Std            77.33309
V Predictions Max            481.83664
V Predictions Min            146.5045
Log Pis Mean                 -2.931977
Log Pis Std                  1.8771968
Log Pis Max                  4.560878
Log Pis Min                  -7.9214497
Policy mu Mean               0.013531075
Policy mu Std                0.48068175
Policy mu Max                1.8789439
Policy mu Min                -1.817888
Policy log std Mean          -0.3477986
Policy log std Std           0.10738941
Policy log std Max           -0.106454074
Policy log std Min           -0.8842462
Z mean eval                  1.6044209
Z variance eval              0.032340888
total_rewards                [1970.5148904  1372.75320807 2215.78543196 1963.63863784 2058.69719251
 1063.31804796 1895.21395774 1995.04105522 2051.12480895 2057.45835971]
total_rewards_mean           1864.3545590351994
total_rewards_std            339.990427674023
total_rewards_max            2215.7854319637536
total_rewards_min            1063.3180479597474
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               187.76601395895705
(Previous) Eval Time (s)     29.743452484253794
Sample Time (s)              6.424291969276965
Epoch Time (s)               223.9337584124878
Total Train Time (s)         1787.8204043027945
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:30.493668 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #7 | Epoch Duration: 224.02020740509033
2020-01-13 00:06:30.493878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.589783
Z variance train             0.03279521
KL Divergence                15.835573
KL Loss                      1.5835574
QF Loss                      218.69362
VF Loss                      32.113552
Policy Loss                  -263.87924
Q Predictions Mean           257.44363
Q Predictions Std            89.77086
Q Predictions Max            520.4503
Q Predictions Min            119.80067
V Predictions Mean           265.21332
V Predictions Std            90.05559
V Predictions Max            512.62756
V Predictions Min            156.82222
Log Pis Mean                 -2.5035925
Log Pis Std                  1.9016542
Log Pis Max                  4.918833
Log Pis Min                  -6.6424823
Policy mu Mean               -0.018255034
Policy mu Std                0.5411281
Policy mu Max                2.111793
Policy mu Min                -1.7452115
Policy log std Mean          -0.37741408
Policy log std Std           0.12737581
Policy log std Max           -0.11921927
Policy log std Min           -0.9974625
Z mean eval                  1.7442287
Z variance eval              0.015829071
total_rewards                [2646.95519982 2754.29749052 2623.06783296 2433.71559212 2774.78783467
 2680.9185814  2615.13462743 2639.81544799 2620.69247865 2594.9336539 ]
total_rewards_mean           2638.4318739465734
total_rewards_std            88.76475854145443
total_rewards_max            2774.7878346698167
total_rewards_min            2433.715592118263
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               186.6866666013375
(Previous) Eval Time (s)     25.83375793788582
Sample Time (s)              6.29637974081561
Epoch Time (s)               218.81680428003892
Total Train Time (s)         2006.7256689369678
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:10:09.401821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #8 | Epoch Duration: 218.90774655342102
2020-01-13 00:10:09.402163 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7438787
Z variance train             0.015827738
KL Divergence                19.349184
KL Loss                      1.9349184
QF Loss                      111.800705
VF Loss                      28.382107
Policy Loss                  -309.6039
Q Predictions Mean           303.37518
Q Predictions Std            122.33781
Q Predictions Max            668.27966
Q Predictions Min            164.52547
V Predictions Mean           311.71466
V Predictions Std            121.580025
V Predictions Max            662.92017
V Predictions Min            178.52582
Log Pis Mean                 -2.1862736
Log Pis Std                  2.3340807
Log Pis Max                  7.8983955
Log Pis Min                  -10.536825
Policy mu Mean               -0.055970844
Policy mu Std                0.61097825
Policy mu Max                2.001724
Policy mu Min                -2.1186988
Policy log std Mean          -0.4013512
Policy log std Std           0.14681602
Policy log std Max           -0.15798664
Policy log std Min           -1.1409681
Z mean eval                  1.7837355
Z variance eval              0.01542698
total_rewards                [1276.97403439  367.35047825 1772.36154443 2813.16835161 3053.24239124
 2760.184908   3039.91557931 2616.18406667 1177.46491639 2531.74304968]
total_rewards_mean           2140.8589319969483
total_rewards_std            883.7750355690176
total_rewards_max            3053.2423912401996
total_rewards_min            367.3504782461374
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               185.49465434718877
(Previous) Eval Time (s)     30.160845027770847
Sample Time (s)              6.231713667977601
Epoch Time (s)               221.88721304293722
Total Train Time (s)         2228.6971222078428
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:13:51.370805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #9 | Epoch Duration: 221.96841263771057
2020-01-13 00:13:51.370934 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #9 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7859663
Z variance train             0.014814961
KL Divergence                19.979666
KL Loss                      1.9979666
QF Loss                      120.06738
VF Loss                      53.428066
Policy Loss                  -347.4014
Q Predictions Mean           337.53662
Q Predictions Std            152.54999
Q Predictions Max            769.77405
Q Predictions Min            151.52318
V Predictions Mean           342.24234
V Predictions Std            152.05516
V Predictions Max            773.64294
V Predictions Min            180.33894
Log Pis Mean                 -2.0268993
Log Pis Std                  2.4630027
Log Pis Max                  9.491957
Log Pis Min                  -7.661101
Policy mu Mean               0.043916147
Policy mu Std                0.6222217
Policy mu Max                2.2540858
Policy mu Min                -2.0819285
Policy log std Mean          -0.41828707
Policy log std Std           0.16492899
Policy log std Max           -0.16385925
Policy log std Min           -1.6652082
Z mean eval                  1.8893547
Z variance eval              0.016804403
total_rewards                [3068.09985618 3049.59900571 3180.42414713 3094.60470583 3146.76408737
  600.97132866 3111.64923698 3163.91059613 2852.58824421 3098.42609561]
total_rewards_mean           2836.7037303800803
total_rewards_std            750.3047566991081
total_rewards_max            3180.424147126171
total_rewards_min            600.9713286554063
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               186.7728245612234
(Previous) Eval Time (s)     26.895107528194785
Sample Time (s)              6.095901035703719
Epoch Time (s)               219.7638331251219
Total Train Time (s)         2448.54417149676
Epoch                        10
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:17:31.222632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #10 | Epoch Duration: 219.85155034065247
2020-01-13 00:17:31.222946 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.891436
Z variance train             0.016796809
KL Divergence                21.023157
KL Loss                      2.1023157
QF Loss                      180.0159
VF Loss                      39.736877
Policy Loss                  -382.6513
Q Predictions Mean           374.97528
Q Predictions Std            190.58624
Q Predictions Max            938.9675
Q Predictions Min            175.8277
V Predictions Mean           381.53558
V Predictions Std            192.32536
V Predictions Max            942.4062
V Predictions Min            189.90099
Log Pis Mean                 -1.7657788
Log Pis Std                  2.5921702
Log Pis Max                  8.858339
Log Pis Min                  -6.0932655
Policy mu Mean               -0.024738736
Policy mu Std                0.6804228
Policy mu Max                2.9768522
Policy mu Min                -2.2770364
Policy log std Mean          -0.4335903
Policy log std Std           0.17940935
Policy log std Max           -0.11497718
Policy log std Min           -1.5650802
Z mean eval                  2.0247645
Z variance eval              0.015901688
total_rewards                [3160.53150922 3003.27225475 3167.41556881 3322.43987268 2718.69844918
 3071.41050664 3088.17472558 3139.5209638  3266.31342574 1141.10959544]
total_rewards_mean           2907.8886871847435
total_rewards_std            609.1632670466593
total_rewards_max            3322.4398726765103
total_rewards_min            1141.1095954446848
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               181.0774380369112
(Previous) Eval Time (s)     29.73015234619379
Sample Time (s)              6.354548334144056
Epoch Time (s)               217.16213871724904
Total Train Time (s)         2665.8011199748144
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:21:08.481369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #11 | Epoch Duration: 217.25814771652222
2020-01-13 00:21:08.481699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0246956
Z variance train             0.015901621
KL Divergence                22.988487
KL Loss                      2.2988489
QF Loss                      480.6017
VF Loss                      35.59488
Policy Loss                  -432.46765
Q Predictions Mean           428.03546
Q Predictions Std            235.05957
Q Predictions Max            1093.5465
Q Predictions Min            184.93785
V Predictions Mean           434.73413
V Predictions Std            235.142
V Predictions Max            1078.0251
V Predictions Min            192.9292
Log Pis Mean                 -1.9976823
Log Pis Std                  2.5082452
Log Pis Max                  8.574451
Log Pis Min                  -7.493491
Policy mu Mean               -0.06352374
Policy mu Std                0.64334637
Policy mu Max                2.5146782
Policy mu Min                -2.2544422
Policy log std Mean          -0.41897556
Policy log std Std           0.16602577
Policy log std Max           -0.14639097
Policy log std Min           -1.622341
Z mean eval                  2.1087298
Z variance eval              0.0116963405
total_rewards                [1019.1783857  3347.7468043  3506.69591821 3460.71163905 3375.64391368
 3417.51155772 3414.77353964 3166.85200656 3597.33476437 3275.09425769]
total_rewards_mean           3158.154278692132
total_rewards_std            721.8889748502587
total_rewards_max            3597.3347643698244
total_rewards_min            1019.1783857016727
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               188.10277517605573
(Previous) Eval Time (s)     30.36489338707179
Sample Time (s)              6.14567069336772
Epoch Time (s)               224.61333925649524
Total Train Time (s)         2890.5043285316788
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:24:53.182419 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #12 | Epoch Duration: 224.70049381256104
2020-01-13 00:24:53.182560 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1094308
Z variance train             0.011721242
KL Divergence                23.507256
KL Loss                      2.3507257
QF Loss                      150.19496
VF Loss                      60.16285
Policy Loss                  -486.8051
Q Predictions Mean           476.276
Q Predictions Std            273.098
Q Predictions Max            1112.9072
Q Predictions Min            204.20078
V Predictions Mean           484.13757
V Predictions Std            276.6998
V Predictions Max            1094.7489
V Predictions Min            204.03912
Log Pis Mean                 -1.5187105
Log Pis Std                  2.7121627
Log Pis Max                  8.633623
Log Pis Min                  -6.066738
Policy mu Mean               -0.01230276
Policy mu Std                0.7073393
Policy mu Max                2.450392
Policy mu Min                -2.921397
Policy log std Mean          -0.4382129
Policy log std Std           0.18554692
Policy log std Max           -0.17161568
Policy log std Min           -1.5247829
Z mean eval                  2.1768234
Z variance eval              0.025125396
total_rewards                [3269.60409341 3267.86187593 3700.81070812 3347.35163308 3261.25738771
 3322.92876695 1786.0913654  3395.8835569  3283.19835793 3125.58990528]
total_rewards_mean           3176.057765071547
total_rewards_std            484.25946559135747
total_rewards_max            3700.8107081224634
total_rewards_min            1786.0913653988653
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               187.567043278832
(Previous) Eval Time (s)     30.137128888163716
Sample Time (s)              6.27261994080618
Epoch Time (s)               223.97679210780188
Total Train Time (s)         3114.573692628648
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:28:37.253461 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #13 | Epoch Duration: 224.07080149650574
2020-01-13 00:28:37.253596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.176237
Z variance train             0.025049541
KL Divergence                22.087545
KL Loss                      2.2087545
QF Loss                      259.75006
VF Loss                      88.34802
Policy Loss                  -534.9407
Q Predictions Mean           527.81274
Q Predictions Std            318.22385
Q Predictions Max            1213.525
Q Predictions Min            171.7709
V Predictions Mean           540.0761
V Predictions Std            319.4243
V Predictions Max            1208.6572
V Predictions Min            212.47977
Log Pis Mean                 -1.536995
Log Pis Std                  2.9946065
Log Pis Max                  9.443102
Log Pis Min                  -7.33166
Policy mu Mean               0.0038221169
Policy mu Std                0.7270519
Policy mu Max                2.585394
Policy mu Min                -2.663643
Policy log std Mean          -0.4403347
Policy log std Std           0.18258862
Policy log std Max           -0.16253981
Policy log std Min           -1.6651633
Z mean eval                  2.211615
Z variance eval              0.020401081
total_rewards                [3723.03073849 3603.66449613 3764.20571669 3618.05663487 3667.59985553
 3717.78943052 3701.44305275 3601.13564836 3710.99177891 3691.3517524 ]
total_rewards_mean           3679.926910466681
total_rewards_std            52.8742197563692
total_rewards_max            3764.205716692099
total_rewards_min            3601.135648359524
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               187.87872691685334
(Previous) Eval Time (s)     29.843519946094602
Sample Time (s)              6.278170013800263
Epoch Time (s)               224.0004168767482
Total Train Time (s)         3338.6618537814356
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:21.342213 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #14 | Epoch Duration: 224.08852195739746
2020-01-13 00:32:21.342347 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2120032
Z variance train             0.020392409
KL Divergence                22.747505
KL Loss                      2.2747505
QF Loss                      633.9502
VF Loss                      55.496944
Policy Loss                  -574.5079
Q Predictions Mean           566.9468
Q Predictions Std            352.69473
Q Predictions Max            1302.4519
Q Predictions Min            174.30328
V Predictions Mean           573.47095
V Predictions Std            353.21124
V Predictions Max            1281.8687
V Predictions Min            184.46327
Log Pis Mean                 -1.374733
Log Pis Std                  2.9607677
Log Pis Max                  8.685177
Log Pis Min                  -6.1761203
Policy mu Mean               -0.062980905
Policy mu Std                0.73179746
Policy mu Max                2.053347
Policy mu Min                -2.4549959
Policy log std Mean          -0.4637089
Policy log std Std           0.21578759
Policy log std Max           -0.16246958
Policy log std Min           -2.0182223
Z mean eval                  2.2524695
Z variance eval              0.025954206
total_rewards                [3599.46511177 3495.65297287 3506.29352231 3568.78448325 3573.08857242
 3480.97652285 3458.91412585 3580.29543605 3310.31792946 3491.64596235]
total_rewards_mean           3506.5434639186833
total_rewards_std            80.08949088347336
total_rewards_max            3599.465111770938
total_rewards_min            3310.3179294592533
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               186.49432657612488
(Previous) Eval Time (s)     25.16356263216585
Sample Time (s)              6.202448897995055
Epoch Time (s)               217.86033810628578
Total Train Time (s)         3556.6045449827798
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:59.286878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #15 | Epoch Duration: 217.94442057609558
2020-01-13 00:35:59.287064 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2449193
Z variance train             0.02606223
KL Divergence                22.704262
KL Loss                      2.2704263
QF Loss                      321.19604
VF Loss                      130.42993
Policy Loss                  -620.48065
Q Predictions Mean           619.6658
Q Predictions Std            371.2636
Q Predictions Max            1319.6528
Q Predictions Min            189.48015
V Predictions Mean           626.31445
V Predictions Std            373.13342
V Predictions Max            1323.444
V Predictions Min            198.1707
Log Pis Mean                 -1.3852212
Log Pis Std                  2.8412874
Log Pis Max                  8.169683
Log Pis Min                  -7.1011944
Policy mu Mean               -0.07810334
Policy mu Std                0.7424491
Policy mu Max                2.3256822
Policy mu Min                -2.9819806
Policy log std Mean          -0.4581561
Policy log std Std           0.19999918
Policy log std Max           -0.16172321
Policy log std Min           -1.7762144
Z mean eval                  2.261516
Z variance eval              0.015488988
total_rewards                [4183.23786865 3941.1741746  3610.30698055 4083.71603214 3872.43085499
 3536.99661784 3816.26316335 3768.14363093 3542.8688872  3471.65483963]
total_rewards_mean           3782.679304985538
total_rewards_std            230.19618922266517
total_rewards_max            4183.237868645795
total_rewards_min            3471.6548396307676
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               186.67199097806588
(Previous) Eval Time (s)     30.24549579806626
Sample Time (s)              6.1165554746985435
Epoch Time (s)               223.03404225083068
Total Train Time (s)         3779.720407000277
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:39:42.406253 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #16 | Epoch Duration: 223.11901926994324
2020-01-13 00:39:42.406510 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.263801
Z variance train             0.0154396845
KL Divergence                24.949615
KL Loss                      2.4949615
QF Loss                      264.20636
VF Loss                      79.59962
Policy Loss                  -638.6625
Q Predictions Mean           628.7418
Q Predictions Std            397.19168
Q Predictions Max            1389.3214
Q Predictions Min            164.77641
V Predictions Mean           639.2584
V Predictions Std            398.33002
V Predictions Max            1388.1776
V Predictions Min            165.8346
Log Pis Mean                 -1.02048
Log Pis Std                  2.9857101
Log Pis Max                  7.908613
Log Pis Min                  -6.353056
Policy mu Mean               -0.10867701
Policy mu Std                0.75677997
Policy mu Max                2.658464
Policy mu Min                -2.3880491
Policy log std Mean          -0.46155748
Policy log std Std           0.18664218
Policy log std Max           -0.18469605
Policy log std Min           -1.8360735
Z mean eval                  2.288576
Z variance eval              0.0174272
total_rewards                [3587.72322897 3935.7429478  3891.82583655 3578.29827853 3664.70206816
 3766.40348016 3738.36572434 3844.12638014 4002.49639562 3648.1150465 ]
total_rewards_mean           3765.7799386774905
total_rewards_std            140.93086751815196
total_rewards_max            4002.4963956241522
total_rewards_min            3578.2982785270947
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               189.30844140192494
(Previous) Eval Time (s)     29.913965615909547
Sample Time (s)              6.206548125017434
Epoch Time (s)               225.42895514285192
Total Train Time (s)         4005.239073525183
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:43:27.924554 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #17 | Epoch Duration: 225.517835855484
2020-01-13 00:43:27.924742 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2886565
Z variance train             0.017387219
KL Divergence                25.591887
KL Loss                      2.5591886
QF Loss                      530.316
VF Loss                      78.51382
Policy Loss                  -609.876
Q Predictions Mean           598.0649
Q Predictions Std            407.74643
Q Predictions Max            1386.2427
Q Predictions Min            157.39949
V Predictions Mean           606.092
V Predictions Std            409.9614
V Predictions Max            1377.4961
V Predictions Min            172.20157
Log Pis Mean                 -1.556395
Log Pis Std                  3.0015988
Log Pis Max                  8.716555
Log Pis Min                  -6.95507
Policy mu Mean               -0.068068035
Policy mu Std                0.70571715
Policy mu Max                2.5368295
Policy mu Min                -2.466396
Policy log std Mean          -0.43164238
Policy log std Std           0.18899567
Policy log std Max           -0.17674501
Policy log std Min           -1.5848029
Z mean eval                  2.3105023
Z variance eval              0.010757058
total_rewards                [4226.01843403 3764.97218208 3993.01697507 4196.76704704 4074.25407067
 3890.86997122  805.47941214 3994.4598708  4017.23666302 4277.70362098]
total_rewards_mean           3724.0778247049902
total_rewards_std            984.0523302194757
total_rewards_max            4277.7036209759335
total_rewards_min            805.4794121395455
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               186.94253124576062
(Previous) Eval Time (s)     25.0320803867653
Sample Time (s)              5.707792361266911
Epoch Time (s)               217.68240399379283
Total Train Time (s)         4223.010848558042
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:47:05.697256 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #18 | Epoch Duration: 217.772367477417
2020-01-13 00:47:05.697439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3100994
Z variance train             0.0107383635
KL Divergence                26.958645
KL Loss                      2.6958644
QF Loss                      571.3604
VF Loss                      117.107
Policy Loss                  -606.83496
Q Predictions Mean           596.9114
Q Predictions Std            435.22836
Q Predictions Max            1509.9663
Q Predictions Min            165.03804
V Predictions Mean           602.5526
V Predictions Std            435.4951
V Predictions Max            1493.4252
V Predictions Min            138.9097
Log Pis Mean                 -1.5195312
Log Pis Std                  3.0494
Log Pis Max                  8.867
Log Pis Min                  -6.6088767
Policy mu Mean               -0.07922266
Policy mu Std                0.7014404
Policy mu Max                2.924916
Policy mu Min                -2.467827
Policy log std Mean          -0.45660266
Policy log std Std           0.20826872
Policy log std Max           -0.18040217
Policy log std Min           -1.8927178
Z mean eval                  2.3214297
Z variance eval              0.005295939
total_rewards                [3732.04063315 4042.83622372 3973.07808004 3867.91139309 3837.59913227
 3797.16437855 3967.28132165 3838.82212135 3955.12069293 3922.73527263]
total_rewards_mean           3893.4589249400146
total_rewards_std            89.915788039988
total_rewards_max            4042.8362237233164
total_rewards_min            3732.0406331531644
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               186.82468362292275
(Previous) Eval Time (s)     24.907658644020557
Sample Time (s)              6.148829197045416
Epoch Time (s)               217.88117146398872
Total Train Time (s)         4440.978407247923
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:50:43.666141 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #19 | Epoch Duration: 217.9685685634613
2020-01-13 00:50:43.666301 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3191516
Z variance train             0.0053063594
KL Divergence                29.117947
KL Loss                      2.9117947
QF Loss                      489.07672
VF Loss                      56.891838
Policy Loss                  -640.7434
Q Predictions Mean           634.59106
Q Predictions Std            435.94543
Q Predictions Max            1452.5421
Q Predictions Min            131.45174
V Predictions Mean           641.65656
V Predictions Std            436.95038
V Predictions Max            1443.6765
V Predictions Min            147.40692
Log Pis Mean                 -1.6666484
Log Pis Std                  2.7677267
Log Pis Max                  6.8426704
Log Pis Min                  -8.418087
Policy mu Mean               -0.05384789
Policy mu Std                0.6949866
Policy mu Max                2.407179
Policy mu Min                -2.2716298
Policy log std Mean          -0.46303257
Policy log std Std           0.20818408
Policy log std Max           -0.18124741
Policy log std Min           -1.78318
Z mean eval                  2.3277297
Z variance eval              0.0149137275
total_rewards                [3993.26864031 3944.34701195 4021.44033132 3875.07091588 3814.82408355
 4047.78482285 4014.22635278 3933.39180902 3981.8534912  3944.96542943]
total_rewards_mean           3957.1172888306
total_rewards_std            67.37277659523573
total_rewards_max            4047.784822852857
total_rewards_min            3814.824083551536
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               187.65797957405448
(Previous) Eval Time (s)     24.9993724450469
Sample Time (s)              6.251295767724514
Epoch Time (s)               218.9086477868259
Total Train Time (s)         4659.96800582204
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:54:22.656830 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #20 | Epoch Duration: 218.99039316177368
2020-01-13 00:54:22.657024 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3264294
Z variance train             0.014927971
KL Divergence                27.34947
KL Loss                      2.734947
QF Loss                      289.753
VF Loss                      94.99451
Policy Loss                  -614.63763
Q Predictions Mean           605.6223
Q Predictions Std            484.44156
Q Predictions Max            1573.2803
Q Predictions Min            127.767075
V Predictions Mean           619.0281
V Predictions Std            488.72177
V Predictions Max            1589.7064
V Predictions Min            135.85036
Log Pis Mean                 -1.5285537
Log Pis Std                  3.1283247
Log Pis Max                  8.49852
Log Pis Min                  -6.866958
Policy mu Mean               -0.055716615
Policy mu Std                0.7067929
Policy mu Max                2.462692
Policy mu Min                -2.5983481
Policy log std Mean          -0.45136622
Policy log std Std           0.19398353
Policy log std Max           -0.14673728
Policy log std Min           -1.6784351
Z mean eval                  2.3162942
Z variance eval              0.005999145
total_rewards                [4139.27787273 4273.61350732 4073.00992073 4144.84936946 4291.86685504
 4277.3926231  4096.05565419 4099.71171015 4329.60084847 4142.7624769 ]
total_rewards_mean           4186.814083809094
total_rewards_std            90.49825018752351
total_rewards_max            4329.6008484663125
total_rewards_min            4073.009920734343
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               186.42733592027798
(Previous) Eval Time (s)     30.15746512217447
Sample Time (s)              5.373653799761087
Epoch Time (s)               221.95845484221354
Total Train Time (s)         4882.009542124346
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:04.699212 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #21 | Epoch Duration: 222.04204082489014
2020-01-13 00:58:04.699391 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3164
Z variance train             0.0060035205
KL Divergence                28.208942
KL Loss                      2.8208942
QF Loss                      276.72644
VF Loss                      47.434357
Policy Loss                  -630.17786
Q Predictions Mean           624.7716
Q Predictions Std            481.44864
Q Predictions Max            1566.7751
Q Predictions Min            120.09857
V Predictions Mean           627.7665
V Predictions Std            482.4407
V Predictions Max            1546.0876
V Predictions Min            121.17372
Log Pis Mean                 -1.3333086
Log Pis Std                  3.2297473
Log Pis Max                  11.456031
Log Pis Min                  -6.1094756
Policy mu Mean               -0.02914352
Policy mu Std                0.7192949
Policy mu Max                2.7500486
Policy mu Min                -2.5695138
Policy log std Mean          -0.44085327
Policy log std Std           0.20478645
Policy log std Max           -0.18517657
Policy log std Min           -1.796461
Z mean eval                  2.3043346
Z variance eval              0.0049277926
total_rewards                [3997.02778602 4210.81239736 4186.95632417 4205.42266936 4158.70007702
 4182.94776908 4073.80362034 4076.48026889 4180.01934211 4094.22261095]
total_rewards_mean           4136.639286529485
total_rewards_std            67.92316648109443
total_rewards_max            4210.8123973645725
total_rewards_min            3997.0277860190004
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               187.95090110227466
(Previous) Eval Time (s)     29.94375248020515
Sample Time (s)              6.120700127445161
Epoch Time (s)               224.01535370992497
Total Train Time (s)         5106.105995318387
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:48.795949 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #22 | Epoch Duration: 224.09643411636353
2020-01-13 01:01:48.796088 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.305245
Z variance train             0.0049202703
KL Divergence                28.735903
KL Loss                      2.8735902
QF Loss                      436.59326
VF Loss                      99.59502
Policy Loss                  -679.84576
Q Predictions Mean           670.43286
Q Predictions Std            496.41782
Q Predictions Max            1577.5027
Q Predictions Min            96.47561
V Predictions Mean           674.77795
V Predictions Std            497.34665
V Predictions Max            1569.4574
V Predictions Min            108.01477
Log Pis Mean                 -1.4531237
Log Pis Std                  2.942501
Log Pis Max                  8.869861
Log Pis Min                  -5.70525
Policy mu Mean               -0.0751229
Policy mu Std                0.71413004
Policy mu Max                2.8821368
Policy mu Min                -2.6274374
Policy log std Mean          -0.45087016
Policy log std Std           0.20952474
Policy log std Max           -0.13065869
Policy log std Min           -1.8851628
Z mean eval                  2.315546
Z variance eval              0.013189207
total_rewards                [4083.97078388 4304.99553856 3903.8149814  4087.94726519 4081.0484921
 4033.77922189 4010.40728439 4297.036935   4105.34366905 3771.19263945]
total_rewards_mean           4067.9536810884756
total_rewards_std            151.7833540557973
total_rewards_max            4304.995538558535
total_rewards_min            3771.192639449912
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               185.56851681694388
(Previous) Eval Time (s)     24.87897790502757
Sample Time (s)              6.1629876885563135
Epoch Time (s)               216.61048241052777
Total Train Time (s)         5322.798249765299
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:05:25.489794 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #23 | Epoch Duration: 216.69359374046326
2020-01-13 01:05:25.489983 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3142838
Z variance train             0.013170253
KL Divergence                27.193293
KL Loss                      2.7193294
QF Loss                      585.23834
VF Loss                      100.74838
Policy Loss                  -650.06757
Q Predictions Mean           642.3779
Q Predictions Std            502.4591
Q Predictions Max            1627.6528
Q Predictions Min            81.06851
V Predictions Mean           645.9719
V Predictions Std            503.12927
V Predictions Max            1594.9814
V Predictions Min            91.03906
Log Pis Mean                 -1.7477769
Log Pis Std                  3.1237414
Log Pis Max                  10.180765
Log Pis Min                  -6.878917
Policy mu Mean               -0.020679621
Policy mu Std                0.69261795
Policy mu Max                2.709046
Policy mu Min                -2.3528333
Policy log std Mean          -0.4355676
Policy log std Std           0.19218686
Policy log std Max           -0.16579375
Policy log std Min           -1.73683
Z mean eval                  2.3194337
Z variance eval              0.00823963
total_rewards                [4153.29011193 4403.39512872 4456.19643842 4332.49338886 4393.99365619
 4262.78559652 4299.66927174 4207.26656603 4308.7260779  4472.5938192 ]
total_rewards_mean           4329.041005552007
total_rewards_std            98.95341369040558
total_rewards_max            4472.593819201539
total_rewards_min            4153.290111933738
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               187.08238202612847
(Previous) Eval Time (s)     30.04587208572775
Sample Time (s)              6.497146645095199
Epoch Time (s)               223.62540075695142
Total Train Time (s)         5546.506484525278
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:09:09.198168 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #24 | Epoch Duration: 223.70805382728577
2020-01-13 01:09:09.198304 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3184438
Z variance train             0.008213124
KL Divergence                28.533037
KL Loss                      2.8533037
QF Loss                      564.8596
VF Loss                      126.466324
Policy Loss                  -642.5711
Q Predictions Mean           638.8376
Q Predictions Std            532.31885
Q Predictions Max            1718.728
Q Predictions Min            62.376743
V Predictions Mean           644.5123
V Predictions Std            532.78986
V Predictions Max            1737.1183
V Predictions Min            70.85693
Log Pis Mean                 -1.5995727
Log Pis Std                  3.1531978
Log Pis Max                  14.670595
Log Pis Min                  -6.885838
Policy mu Mean               -0.07969507
Policy mu Std                0.68582773
Policy mu Max                2.9096346
Policy mu Min                -3.6570435
Policy log std Mean          -0.43911204
Policy log std Std           0.20627983
Policy log std Max           -0.10463607
Policy log std Min           -1.6892155
Z mean eval                  2.330049
Z variance eval              0.0061633587
total_rewards                [4509.12848326 4576.40772385 4393.02316762 4557.9297     4571.29280349
 4407.25930958 4754.62208135 3481.37137649 4526.75913341 4244.69372211]
total_rewards_mean           4402.2487501165915
total_rewards_std            332.74401826705054
total_rewards_max            4754.622081354163
total_rewards_min            3481.3713764920853
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               186.8241559569724
(Previous) Eval Time (s)     30.140699800103903
Sample Time (s)              6.138523204252124
Epoch Time (s)               223.10337896132842
Total Train Time (s)         5769.695867217146
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:12:52.388721 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #25 | Epoch Duration: 223.1903178691864
2020-01-13 01:12:52.388854 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #25 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.330504
Z variance train             0.0061747106
KL Divergence                28.213871
KL Loss                      2.821387
QF Loss                      262.80353
VF Loss                      66.44122
Policy Loss                  -651.41254
Q Predictions Mean           642.7795
Q Predictions Std            524.6292
Q Predictions Max            1683.4128
Q Predictions Min            58.501682
V Predictions Mean           648.7357
V Predictions Std            526.6549
V Predictions Max            1700.7849
V Predictions Min            72.66127
Log Pis Mean                 -1.4557703
Log Pis Std                  3.0919495
Log Pis Max                  8.744531
Log Pis Min                  -6.481897
Policy mu Mean               -0.026587805
Policy mu Std                0.714499
Policy mu Max                2.4621568
Policy mu Min                -2.220748
Policy log std Mean          -0.4411539
Policy log std Std           0.20593071
Policy log std Max           -0.13197672
Policy log std Min           -1.788646
Z mean eval                  2.3216047
Z variance eval              0.0071570603
total_rewards                [4879.90109853 2464.85464299 4731.57374161 4906.74033148 4967.3561752
 4660.75830541 4585.11550567 4691.73864123 4771.7757351  4753.5320949 ]
total_rewards_mean           4541.334627211941
total_rewards_std            701.0373746263828
total_rewards_max            4967.356175195747
total_rewards_min            2464.8546429937546
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               187.01149049773812
(Previous) Eval Time (s)     30.14511080412194
Sample Time (s)              6.218156006652862
Epoch Time (s)               223.37475730851293
Total Train Time (s)         5993.160859564319
Epoch                        26
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:16:35.856850 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #26 | Epoch Duration: 223.46789383888245
2020-01-13 01:16:35.856991 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #26 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3173606
Z variance train             0.0071580643
KL Divergence                27.510548
KL Loss                      2.7510548
QF Loss                      387.6197
VF Loss                      143.2634
Policy Loss                  -697.31116
Q Predictions Mean           689.0975
Q Predictions Std            557.8832
Q Predictions Max            1724.3652
Q Predictions Min            41.05411
V Predictions Mean           703.2322
V Predictions Std            561.965
V Predictions Max            1744.769
V Predictions Min            70.959656
Log Pis Mean                 -1.3588502
Log Pis Std                  3.1929367
Log Pis Max                  11.402835
Log Pis Min                  -5.949246
Policy mu Mean               -0.10711238
Policy mu Std                0.7602245
Policy mu Max                2.7025316
Policy mu Min                -2.7145007
Policy log std Mean          -0.44289777
Policy log std Std           0.2136182
Policy log std Max           -0.1316817
Policy log std Min           -2.0961628
Z mean eval                  2.3126376
Z variance eval              0.006795822
total_rewards                [4331.11138113 4637.55258539 4551.371881   4466.37229792 4640.2982273
 4588.84953939 4331.96892517 4505.16752374 4597.45730491 4528.58445419]
total_rewards_mean           4517.873412012124
total_rewards_std            106.85193456764048
total_rewards_max            4640.298227295942
total_rewards_min            4331.111381133988
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               185.89875526493415
(Previous) Eval Time (s)     30.18023105384782
Sample Time (s)              6.126893553882837
Epoch Time (s)               222.2058798726648
Total Train Time (s)         6215.448753379285
Epoch                        27
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:20:18.147870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #27 | Epoch Duration: 222.29073667526245
2020-01-13 01:20:18.148212 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3122964
Z variance train             0.0067739426
KL Divergence                28.202017
KL Loss                      2.8202016
QF Loss                      187.64554
VF Loss                      66.25015
Policy Loss                  -644.45264
Q Predictions Mean           634.1639
Q Predictions Std            547.639
Q Predictions Max            1733.746
Q Predictions Min            42.16256
V Predictions Mean           642.4997
V Predictions Std            548.8915
V Predictions Max            1731.6792
V Predictions Min            45.083725
Log Pis Mean                 -1.9114116
Log Pis Std                  2.851612
Log Pis Max                  10.692981
Log Pis Min                  -6.3030787
Policy mu Mean               0.04013412
Policy mu Std                0.6544269
Policy mu Max                2.3784354
Policy mu Min                -2.239336
Policy log std Mean          -0.41836438
Policy log std Std           0.21093018
Policy log std Max           -0.052181453
Policy log std Min           -1.9986122
Z mean eval                  2.329613
Z variance eval              0.012489265
total_rewards                [4879.29789344 4679.6394709  4733.15168829 4536.39849542 4725.81094665
 4690.8413323  4805.77859494 4845.92448287 4574.7601608  4433.64359372]
total_rewards_mean           4690.524665933156
total_rewards_std            133.93761884229548
total_rewards_max            4879.297893437456
total_rewards_min            4433.643593724557
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               187.47356081241742
(Previous) Eval Time (s)     24.92675506696105
Sample Time (s)              6.183142495341599
Epoch Time (s)               218.58345837472007
Total Train Time (s)         6434.117592837196
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:23:56.815822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #28 | Epoch Duration: 218.66738724708557
2020-01-13 01:23:56.816020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3300292
Z variance train             0.012573646
KL Divergence                26.975061
KL Loss                      2.6975062
QF Loss                      718.88354
VF Loss                      121.78664
Policy Loss                  -664.93646
Q Predictions Mean           657.0244
Q Predictions Std            556.4698
Q Predictions Max            1780.8668
Q Predictions Min            6.621465
V Predictions Mean           670.9398
V Predictions Std            556.42316
V Predictions Max            1805.3578
V Predictions Min            50.17897
Log Pis Mean                 -1.7280895
Log Pis Std                  2.830935
Log Pis Max                  7.2222033
Log Pis Min                  -7.1920924
Policy mu Mean               -0.059956204
Policy mu Std                0.6583313
Policy mu Max                2.5414426
Policy mu Min                -2.276971
Policy log std Mean          -0.4485413
Policy log std Std           0.22364527
Policy log std Max           -0.1507526
Policy log std Min           -1.9537852
Z mean eval                  2.3427641
Z variance eval              0.007835761
total_rewards                [4895.85020005 5019.48212621 4769.90472431 4653.82933058 4694.49296335
 4866.3468425  4941.32807649 4901.11472869 4757.87261829 4755.23891756]
total_rewards_mean           4825.546052804496
total_rewards_std            110.73164376107488
total_rewards_max            5019.482126214742
total_rewards_min            4653.829330580395
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               187.26852755900472
(Previous) Eval Time (s)     25.436344997026026
Sample Time (s)              6.154297543223947
Epoch Time (s)               218.8591700992547
Total Train Time (s)         6653.063456165604
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:35.765044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #29 | Epoch Duration: 218.94885277748108
2020-01-13 01:27:35.765314 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #29 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3426569
Z variance train             0.007836952
KL Divergence                27.993116
KL Loss                      2.7993116
QF Loss                      281.51324
VF Loss                      117.535164
Policy Loss                  -688.4225
Q Predictions Mean           680.83527
Q Predictions Std            579.2952
Q Predictions Max            1807.273
Q Predictions Min            20.66165
V Predictions Mean           688.93054
V Predictions Std            580.4161
V Predictions Max            1800.971
V Predictions Min            38.20938
Log Pis Mean                 -1.6919024
Log Pis Std                  2.941293
Log Pis Max                  10.095071
Log Pis Min                  -6.533963
Policy mu Mean               0.030880474
Policy mu Std                0.6854854
Policy mu Max                2.1951728
Policy mu Min                -2.4901652
Policy log std Mean          -0.43843198
Policy log std Std           0.21352407
Policy log std Max           -0.16088086
Policy log std Min           -1.9750581
Z mean eval                  2.3132346
Z variance eval              0.020698402
total_rewards                [4789.19348481 4749.39278349 4380.56875027 4560.89215787 4727.7758475
 4993.78874059 4547.27654476 4751.25006433 4472.9353313  4580.29652978]
total_rewards_mean           4655.337023469126
total_rewards_std            170.5157630085754
total_rewards_max            4993.788740588783
total_rewards_min            4380.568750269931
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               183.3120746887289
(Previous) Eval Time (s)     29.075818239711225
Sample Time (s)              6.283630318008363
Epoch Time (s)               218.6715232464485
Total Train Time (s)         6871.831360136624
Epoch                        30
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:31:14.533055 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #30 | Epoch Duration: 218.76754474639893
2020-01-13 01:31:14.533234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3171222
Z variance train             0.02061833
KL Divergence                25.600906
KL Loss                      2.5600908
QF Loss                      582.8331
VF Loss                      113.656746
Policy Loss                  -702.6074
Q Predictions Mean           694.8131
Q Predictions Std            585.4956
Q Predictions Max            1842.825
Q Predictions Min            7.9172697
V Predictions Mean           698.4264
V Predictions Std            586.9429
V Predictions Max            1815.3865
V Predictions Min            25.055412
Log Pis Mean                 -1.4997058
Log Pis Std                  3.2585316
Log Pis Max                  12.715376
Log Pis Min                  -7.489197
Policy mu Mean               -0.048964426
Policy mu Std                0.70062125
Policy mu Max                2.2993186
Policy mu Min                -2.7932374
Policy log std Mean          -0.45395932
Policy log std Std           0.22768855
Policy log std Max           -0.08278164
Policy log std Min           -1.802273
Z mean eval                  2.3369956
Z variance eval              0.015816316
total_rewards                [3982.93051937 4763.31869222 4735.15573606 4838.83478269 4663.75104404
 4607.58384216 4832.51325266 4957.02845654 4820.99972947 4733.64550882]
total_rewards_mean           4693.576156402562
total_rewards_std            254.4695147304463
total_rewards_max            4957.028456541642
total_rewards_min            3982.9305193681816
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               187.16768873576075
(Previous) Eval Time (s)     29.737560973968357
Sample Time (s)              6.081514759454876
Epoch Time (s)               222.98676446918398
Total Train Time (s)         7094.903266110923
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:34:57.604820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #31 | Epoch Duration: 223.07144570350647
2020-01-13 01:34:57.604952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3347492
Z variance train             0.01587791
KL Divergence                26.517792
KL Loss                      2.6517792
QF Loss                      187.72403
VF Loss                      49.03009
Policy Loss                  -702.4566
Q Predictions Mean           695.73676
Q Predictions Std            590.8636
Q Predictions Max            1897.7203
Q Predictions Min            16.83227
V Predictions Mean           703.71155
V Predictions Std            592.2119
V Predictions Max            1889.2379
V Predictions Min            20.433128
Log Pis Mean                 -1.3930576
Log Pis Std                  3.2353072
Log Pis Max                  8.643176
Log Pis Min                  -7.065298
Policy mu Mean               -0.09651235
Policy mu Std                0.72297233
Policy mu Max                2.5366404
Policy mu Min                -2.5932775
Policy log std Mean          -0.4388311
Policy log std Std           0.22131898
Policy log std Max           -0.16971855
Policy log std Min           -1.8646345
Z mean eval                  2.338468
Z variance eval              0.020055538
total_rewards                [4936.91390974 5051.57021611 5032.11536225 4893.4240536  4792.14027906
 5018.40207157 4868.94856339 5174.52962576 5086.98220947 4974.32882208]
total_rewards_mean           4982.935511304217
total_rewards_std            107.48092218945354
total_rewards_max            5174.529625762707
total_rewards_min            4792.140279060133
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               186.32978921895847
(Previous) Eval Time (s)     30.02685507107526
Sample Time (s)              6.097308437805623
Epoch Time (s)               222.45395272783935
Total Train Time (s)         7317.4438992901705
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:40.147996 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #32 | Epoch Duration: 222.54291105270386
2020-01-13 01:38:40.148221 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3391907
Z variance train             0.02006136
KL Divergence                25.483387
KL Loss                      2.5483387
QF Loss                      185.87115
VF Loss                      81.43358
Policy Loss                  -670.9217
Q Predictions Mean           662.0318
Q Predictions Std            603.5328
Q Predictions Max            1971.8575
Q Predictions Min            12.264779
V Predictions Mean           670.6202
V Predictions Std            604.7636
V Predictions Max            1974.203
V Predictions Min            14.023031
Log Pis Mean                 -1.8478699
Log Pis Std                  2.891262
Log Pis Max                  11.158294
Log Pis Min                  -7.3678703
Policy mu Mean               -0.09721344
Policy mu Std                0.6448879
Policy mu Max                2.4899616
Policy mu Min                -2.6294246
Policy log std Mean          -0.44090104
Policy log std Std           0.21214953
Policy log std Max           -0.17215446
Policy log std Min           -1.9087644
Z mean eval                  2.3459783
Z variance eval              0.008068812
total_rewards                [5083.82826427 4909.12466546 5083.4100348  4863.03159672 4908.84202665
 5032.99868764 4653.38679722 4865.21922883 5056.90369512 5162.72916153]
total_rewards_mean           4961.947415823532
total_rewards_std            142.81006923207315
total_rewards_max            5162.729161532076
total_rewards_min            4653.386797216218
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               187.49626199807972
(Previous) Eval Time (s)     30.226757966913283
Sample Time (s)              6.18790445337072
Epoch Time (s)               223.91092441836372
Total Train Time (s)         7541.4429838988
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:42:24.146886 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #33 | Epoch Duration: 223.99851250648499
2020-01-13 01:42:24.147034 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3464637
Z variance train             0.008091072
KL Divergence                27.94888
KL Loss                      2.794888
QF Loss                      599.40686
VF Loss                      120.0859
Policy Loss                  -740.4086
Q Predictions Mean           734.5757
Q Predictions Std            613.80597
Q Predictions Max            1933.6918
Q Predictions Min            2.0934012
V Predictions Mean           744.87506
V Predictions Std            615.8289
V Predictions Max            1974.7507
V Predictions Min            6.5645022
Log Pis Mean                 -1.5697724
Log Pis Std                  3.075431
Log Pis Max                  13.732288
Log Pis Min                  -7.181999
Policy mu Mean               -0.04293451
Policy mu Std                0.7206104
Policy mu Max                2.8725667
Policy mu Min                -2.385202
Policy log std Mean          -0.45940104
Policy log std Std           0.23571487
Policy log std Max           -0.1503782
Policy log std Min           -1.9708989
Z mean eval                  2.36405
Z variance eval              0.0073919417
total_rewards                [5258.54103639 5130.02787987 5247.28464297 5259.65850398 5113.17470315
 5139.90322872 5094.10303476 5030.61547756 4969.17648678 5100.72709493]
total_rewards_mean           5134.321208910935
total_rewards_std            92.28826080377434
total_rewards_max            5259.658503976155
total_rewards_min            4969.176486779153
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               187.69980221800506
(Previous) Eval Time (s)     29.973763442132622
Sample Time (s)              6.186746422201395
Epoch Time (s)               223.86031208233908
Total Train Time (s)         7765.3922274122015
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:46:08.098127 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #34 | Epoch Duration: 223.95099425315857
2020-01-13 01:46:08.098252 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3634734
Z variance train             0.0073644714
KL Divergence                29.044054
KL Loss                      2.9044054
QF Loss                      275.70905
VF Loss                      83.3893
Policy Loss                  -637.4176
Q Predictions Mean           636.4957
Q Predictions Std            608.2523
Q Predictions Max            2020.6548
Q Predictions Min            -1.7746849
V Predictions Mean           640.6804
V Predictions Std            606.5931
V Predictions Max            1996.138
V Predictions Min            -3.5636826
Log Pis Mean                 -2.0169568
Log Pis Std                  2.8388083
Log Pis Max                  8.716924
Log Pis Min                  -7.043212
Policy mu Mean               -0.04487887
Policy mu Std                0.6539405
Policy mu Max                2.8050547
Policy mu Min                -2.3702679
Policy log std Mean          -0.42507228
Policy log std Std           0.20880415
Policy log std Max           -0.16477898
Policy log std Min           -2.1978662
Z mean eval                  2.3751564
Z variance eval              0.0051404512
total_rewards                [5085.45915173 4778.87132882 5163.09908113 5110.47851012 4962.55282942
 5191.85872595 5027.24316654 4991.60882336 4925.56073001 5103.29749399]
total_rewards_mean           5034.002984108074
total_rewards_std            117.7633977404768
total_rewards_max            5191.8587259529595
total_rewards_min            4778.871328819641
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               187.28343902667984
(Previous) Eval Time (s)     30.23688960680738
Sample Time (s)              5.496251503471285
Epoch Time (s)               223.0165801369585
Total Train Time (s)         7988.493226320483
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:49:51.199815 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #35 | Epoch Duration: 223.10146975517273
2020-01-13 01:49:51.199942 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.37167
Z variance train             0.005128695
KL Divergence                30.556913
KL Loss                      3.0556915
QF Loss                      264.30374
VF Loss                      77.42591
Policy Loss                  -721.1884
Q Predictions Mean           712.20483
Q Predictions Std            612.4665
Q Predictions Max            1975.2062
Q Predictions Min            -24.62529
V Predictions Mean           722.0718
V Predictions Std            616.64343
V Predictions Max            2008.0333
V Predictions Min            -14.772296
Log Pis Mean                 -1.4067945
Log Pis Std                  3.3761795
Log Pis Max                  14.118653
Log Pis Min                  -5.840829
Policy mu Mean               -0.02733124
Policy mu Std                0.747882
Policy mu Max                2.77735
Policy mu Min                -2.861706
Policy log std Mean          -0.4483637
Policy log std Std           0.2232943
Policy log std Max           -0.122823775
Policy log std Min           -1.9150996
Z mean eval                  2.351812
Z variance eval              0.0077859843
total_rewards                [5394.22680331 5002.13728627 5138.36341304 5162.4120592  5333.39291634
 5082.48991764 5202.78549353 5350.77919776 5095.11861923 5237.3422392 ]
total_rewards_mean           5199.904794552888
total_rewards_std            121.99364656151877
total_rewards_max            5394.226803313408
total_rewards_min            5002.137286270244
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               187.80885988287628
(Previous) Eval Time (s)     25.092445333022624
Sample Time (s)              6.261330905370414
Epoch Time (s)               219.16263612126932
Total Train Time (s)         8207.738460185006
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:30.448841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #36 | Epoch Duration: 219.24878597259521
2020-01-13 01:53:30.449015 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3497493
Z variance train             0.0076900846
KL Divergence                30.745499
KL Loss                      3.07455
QF Loss                      221.7937
VF Loss                      39.922184
Policy Loss                  -677.49005
Q Predictions Mean           669.8917
Q Predictions Std            635.98346
Q Predictions Max            2016.0519
Q Predictions Min            -35.785034
V Predictions Mean           676.38367
V Predictions Std            638.5241
V Predictions Max            2030.0347
V Predictions Min            -13.127423
Log Pis Mean                 -1.9140017
Log Pis Std                  3.0650356
Log Pis Max                  10.992925
Log Pis Min                  -8.7159605
Policy mu Mean               -0.039244533
Policy mu Std                0.6653469
Policy mu Max                2.9484842
Policy mu Min                -3.2016077
Policy log std Mean          -0.43083477
Policy log std Std           0.2150667
Policy log std Max           -0.1473774
Policy log std Min           -1.8662146
Z mean eval                  2.355947
Z variance eval              0.006538826
total_rewards                [5063.26564059 5284.74346358 5041.44982917 5240.66591778 5096.92954168
 5148.73219477 5335.58753538 5055.57838299 5245.00459007 5151.69133057]
total_rewards_mean           5166.364842657147
total_rewards_std            99.10045722236464
total_rewards_max            5335.58753538016
total_rewards_min            5041.449829171061
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               187.6026408718899
(Previous) Eval Time (s)     30.10955789592117
Sample Time (s)              6.180371064692736
Epoch Time (s)               223.8925698325038
Total Train Time (s)         8431.722772260662
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:57:14.433495 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #37 | Epoch Duration: 223.98435735702515
2020-01-13 01:57:14.433629 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3589053
Z variance train             0.0065583056
KL Divergence                30.747536
KL Loss                      3.0747535
QF Loss                      285.38916
VF Loss                      169.21497
Policy Loss                  -718.3474
Q Predictions Mean           709.5893
Q Predictions Std            651.55365
Q Predictions Max            2051.1838
Q Predictions Min            -19.941395
V Predictions Mean           709.81433
V Predictions Std            652.7802
V Predictions Max            2029.8353
V Predictions Min            -20.760965
Log Pis Mean                 -1.5681865
Log Pis Std                  3.0643296
Log Pis Max                  11.942179
Log Pis Min                  -6.1460824
Policy mu Mean               -0.11640236
Policy mu Std                0.7039405
Policy mu Max                2.705859
Policy mu Min                -2.35048
Policy log std Mean          -0.43285346
Policy log std Std           0.20993826
Policy log std Max           -0.14159463
Policy log std Min           -2.0136814
Z mean eval                  2.362326
Z variance eval              0.0066272514
total_rewards                [5061.64914204 5034.93074564 5201.43937984 5150.65746934 5051.78564064
 5203.67624286 5121.21770366 5089.80824071 5200.5189584  5023.25675526]
total_rewards_mean           5113.8940278402315
total_rewards_std            68.0084703223034
total_rewards_max            5203.676242863217
total_rewards_min            5023.256755255725
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               186.03238970180973
(Previous) Eval Time (s)     29.755556287709624
Sample Time (s)              6.309569858480245
Epoch Time (s)               222.0975158479996
Total Train Time (s)         8653.91114527965
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:00:56.622509 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #38 | Epoch Duration: 222.1887800693512
2020-01-13 02:00:56.622654 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3614924
Z variance train             0.0066348263
KL Divergence                29.657108
KL Loss                      2.9657109
QF Loss                      270.9249
VF Loss                      101.17924
Policy Loss                  -712.41046
Q Predictions Mean           704.51697
Q Predictions Std            653.6545
Q Predictions Max            2039.1741
Q Predictions Min            -44.137974
V Predictions Mean           713.69366
V Predictions Std            660.0907
V Predictions Max            2054.9377
V Predictions Min            -31.023829
Log Pis Mean                 -1.7057719
Log Pis Std                  3.1638482
Log Pis Max                  13.94822
Log Pis Min                  -6.475436
Policy mu Mean               -0.04601699
Policy mu Std                0.71736574
Policy mu Max                2.529251
Policy mu Min                -2.5844107
Policy log std Mean          -0.43965778
Policy log std Std           0.23647435
Policy log std Max           -0.14813411
Policy log std Min           -2.080164
Z mean eval                  2.3609142
Z variance eval              0.0075599076
total_rewards                [5150.8934109  5212.51957026 5325.73019732 5122.92887898 5199.20623068
 1271.55164716 5409.42298559 5266.0592481  5445.85356167 5246.44554692]
total_rewards_mean           4865.061127757658
total_rewards_std            1201.9153805632382
total_rewards_max            5445.853561666168
total_rewards_min            1271.5516471573972
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               187.26287537394091
(Previous) Eval Time (s)     29.919473734218627
Sample Time (s)              6.101108793634921
Epoch Time (s)               223.28345790179446
Total Train Time (s)         8877.281923444942
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:04:39.994803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #39 | Epoch Duration: 223.37205266952515
2020-01-13 02:04:39.994939 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3584332
Z variance train             0.0075560054
KL Divergence                29.040283
KL Loss                      2.9040284
QF Loss                      243.08179
VF Loss                      124.79726
Policy Loss                  -787.9191
Q Predictions Mean           777.5768
Q Predictions Std            680.0288
Q Predictions Max            2052.6404
Q Predictions Min            179.94734
V Predictions Mean           782.23315
V Predictions Std            682.6645
V Predictions Max            2059.7122
V Predictions Min            180.437
Log Pis Mean                 -1.3805761
Log Pis Std                  3.2801957
Log Pis Max                  10.020891
Log Pis Min                  -7.345269
Policy mu Mean               -0.061813787
Policy mu Std                0.7418588
Policy mu Max                2.2255409
Policy mu Min                -2.5994189
Policy log std Mean          -0.45273992
Policy log std Std           0.22853363
Policy log std Max           -0.1534728
Policy log std Min           -1.9543458
Z mean eval                  2.3614738
Z variance eval              0.009289267
total_rewards                [5183.59159834 5173.21116115 5150.97853248 5078.01209606 5144.06040629
 5107.89051406 5228.03267184 5196.63783919 5125.66987071 5208.76964735]
total_rewards_mean           5159.6854337468385
total_rewards_std            44.75577414334385
total_rewards_max            5228.032671841797
total_rewards_min            5078.01209605682
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               187.43691158667207
(Previous) Eval Time (s)     25.745965865906328
Sample Time (s)              9.35299962386489
Epoch Time (s)               222.53587707644328
Total Train Time (s)         9099.906909294892
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:08:22.625924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #40 | Epoch Duration: 222.63086771965027
2020-01-13 02:08:22.626130 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3616543
Z variance train             0.0092370305
KL Divergence                30.185707
KL Loss                      3.0185707
QF Loss                      254.75703
VF Loss                      181.35594
Policy Loss                  -710.9673
Q Predictions Mean           707.72974
Q Predictions Std            680.5433
Q Predictions Max            2067.04
Q Predictions Min            -32.84908
V Predictions Mean           720.2508
V Predictions Std            686.83923
V Predictions Max            2081.6824
V Predictions Min            -21.194248
Log Pis Mean                 -1.5130305
Log Pis Std                  3.4708452
Log Pis Max                  18.01634
Log Pis Min                  -5.50316
Policy mu Mean               -0.06095312
Policy mu Std                0.70422345
Policy mu Max                3.6581645
Policy mu Min                -2.9677498
Policy log std Mean          -0.43296456
Policy log std Std           0.23787466
Policy log std Max           -0.10976985
Policy log std Min           -2.0640688
Z mean eval                  2.3688579
Z variance eval              0.0096537685
total_rewards                [5476.80359246 5468.63908429 4216.7495802  5455.84050507 5717.08142162
 5339.6669654  5373.30070276 5385.12968222 5427.45285238 5225.71630499]
total_rewards_mean           5308.638069141059
total_rewards_std            382.9599139377829
total_rewards_max            5717.081421621387
total_rewards_min            4216.749580204429
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               188.13359254179522
(Previous) Eval Time (s)     25.380558740813285
Sample Time (s)              6.260247926227748
Epoch Time (s)               219.77439920883626
Total Train Time (s)         9319.798933295067
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:12:02.515098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #41 | Epoch Duration: 219.88881969451904
2020-01-13 02:12:02.515297 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3668494
Z variance train             0.009619373
KL Divergence                29.654888
KL Loss                      2.965489
QF Loss                      728.6374
VF Loss                      96.790985
Policy Loss                  -749.4183
Q Predictions Mean           741.1487
Q Predictions Std            706.76984
Q Predictions Max            2126.7317
Q Predictions Min            -39.323013
V Predictions Mean           750.10474
V Predictions Std            709.538
V Predictions Max            2138.0894
V Predictions Min            -31.119305
Log Pis Mean                 -1.489522
Log Pis Std                  3.3590004
Log Pis Max                  11.610472
Log Pis Min                  -6.4218206
Policy mu Mean               -0.08293486
Policy mu Std                0.70937765
Policy mu Max                2.6021912
Policy mu Min                -2.834172
Policy log std Mean          -0.44863495
Policy log std Std           0.23534204
Policy log std Max           -0.13685474
Policy log std Min           -2.1676292
Z mean eval                  2.3692708
Z variance eval              0.009304547
total_rewards                [5313.01701401 5357.75658983 5285.18921886 5247.99600818 5344.40396325
 5241.1343022  5390.82799345 5221.21004701 5050.4623938  5099.26686901]
total_rewards_mean           5255.126439958842
total_rewards_std            104.2832426698034
total_rewards_max            5390.82799344711
total_rewards_min            5050.462393802077
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               187.41065345471725
(Previous) Eval Time (s)     29.822080318350345
Sample Time (s)              6.129695099778473
Epoch Time (s)               223.36242887284607
Total Train Time (s)         9543.249841254205
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:15:45.966114 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #42 | Epoch Duration: 223.45068097114563
2020-01-13 02:15:45.966244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3640056
Z variance train             0.00934312
KL Divergence                28.912216
KL Loss                      2.8912218
QF Loss                      454.80273
VF Loss                      303.97406
Policy Loss                  -846.66736
Q Predictions Mean           835.37335
Q Predictions Std            706.31506
Q Predictions Max            2145.0984
Q Predictions Min            -57.83733
V Predictions Mean           854.8692
V Predictions Std            713.3689
V Predictions Max            2156.912
V Predictions Min            -29.084175
Log Pis Mean                 -1.1577747
Log Pis Std                  3.617947
Log Pis Max                  20.17926
Log Pis Min                  -6.443304
Policy mu Mean               -0.038590882
Policy mu Std                0.76156914
Policy mu Max                2.6811428
Policy mu Min                -3.0567656
Policy log std Mean          -0.4684956
Policy log std Std           0.22341982
Policy log std Max           -0.09503573
Policy log std Min           -2.1153886
Z mean eval                  2.4190316
Z variance eval              0.0060305935
total_rewards                [5446.35712219 5442.67705062 5512.76479938 5530.58118766 5320.46491814
 5393.03311896 5729.78689183 5343.63595555 5712.256212   5548.96558781]
total_rewards_mean           5498.052284413179
total_rewards_std            132.5143425000901
total_rewards_max            5729.78689183084
total_rewards_min            5320.46491814486
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               185.82769717881456
(Previous) Eval Time (s)     29.63274941779673
Sample Time (s)              6.108668661676347
Epoch Time (s)               221.56911525828764
Total Train Time (s)         9764.959478844889
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:27.677292 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #43 | Epoch Duration: 221.71093344688416
2020-01-13 02:19:27.677487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4174528
Z variance train             0.006037337
KL Divergence                31.881355
KL Loss                      3.1881356
QF Loss                      397.1281
VF Loss                      95.25561
Policy Loss                  -788.4522
Q Predictions Mean           778.66315
Q Predictions Std            699.39545
Q Predictions Max            2161.8882
Q Predictions Min            -71.66083
V Predictions Mean           788.6885
V Predictions Std            703.6272
V Predictions Max            2163.9878
V Predictions Min            -61.477367
Log Pis Mean                 -1.3472238
Log Pis Std                  3.2004662
Log Pis Max                  8.157423
Log Pis Min                  -5.828005
Policy mu Mean               -0.03359602
Policy mu Std                0.72512156
Policy mu Max                2.6467614
Policy mu Min                -2.4927764
Policy log std Mean          -0.44833735
Policy log std Std           0.22547333
Policy log std Max           -0.12073308
Policy log std Min           -1.9132137
Z mean eval                  2.3710697
Z variance eval              0.0039550294
total_rewards                [5252.70477873 5360.16165982 5354.78379076 5465.48633095 5563.29355473
 5490.23399232 5322.3884207  5543.10612448 5366.52232952 5466.83364736]
total_rewards_mean           5418.551462937533
total_rewards_std            96.4736970581384
total_rewards_max            5563.293554734538
total_rewards_min            5252.704778726285
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               187.84508305089548
(Previous) Eval Time (s)     29.82595001719892
Sample Time (s)              6.308025212492794
Epoch Time (s)               223.9790582805872
Total Train Time (s)         9989.021726958454
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:23:11.741285 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #44 | Epoch Duration: 224.06366419792175
2020-01-13 02:23:11.741430 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4239824
Z variance train             0.003744693
KL Divergence                32.034245
KL Loss                      3.2034245
QF Loss                      315.80847
VF Loss                      78.230286
Policy Loss                  -724.29614
Q Predictions Mean           714.53906
Q Predictions Std            719.5357
Q Predictions Max            2191.6653
Q Predictions Min            -58.56738
V Predictions Mean           718.9481
V Predictions Std            720.3429
V Predictions Max            2184.8896
V Predictions Min            -58.60312
Log Pis Mean                 -1.5470811
Log Pis Std                  3.343618
Log Pis Max                  9.26613
Log Pis Min                  -6.7944727
Policy mu Mean               -0.038163476
Policy mu Std                0.70936304
Policy mu Max                2.4173522
Policy mu Min                -3.4935577
Policy log std Mean          -0.43227646
Policy log std Std           0.22288401
Policy log std Max           -0.1015341
Policy log std Min           -1.9387414
Z mean eval                  2.4376724
Z variance eval              0.0023813762
total_rewards                [5604.68745265 5616.33670972 5543.62715372 5667.48876636 5322.84915259
 5687.79290754 5339.70907672 5686.73235544 5557.85593163 5506.92872027]
total_rewards_mean           5553.400822664511
total_rewards_std            125.11558538438177
total_rewards_max            5687.792907539727
total_rewards_min            5322.849152589541
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               186.27469555614516
(Previous) Eval Time (s)     30.010172876995057
Sample Time (s)              6.164170057978481
Epoch Time (s)               222.4490384911187
Total Train Time (s)         10211.553189969156
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:26:54.274498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #45 | Epoch Duration: 222.53296566009521
2020-01-13 02:26:54.274632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3707442
Z variance train             0.0025392706
KL Divergence                32.80424
KL Loss                      3.280424
QF Loss                      218.80316
VF Loss                      158.72804
Policy Loss                  -776.4017
Q Predictions Mean           763.90027
Q Predictions Std            707.8289
Q Predictions Max            2195.3713
Q Predictions Min            -62.244125
V Predictions Mean           775.0311
V Predictions Std            709.8807
V Predictions Max            2192.7153
V Predictions Min            -55.456547
Log Pis Mean                 -1.3459849
Log Pis Std                  3.4292464
Log Pis Max                  13.870514
Log Pis Min                  -6.4399204
Policy mu Mean               -0.09310526
Policy mu Std                0.73553663
Policy mu Max                3.3553903
Policy mu Min                -3.2963946
Policy log std Mean          -0.44744024
Policy log std Std           0.22392221
Policy log std Max           -0.15496275
Policy log std Min           -2.1442668
Z mean eval                  2.3824496
Z variance eval              0.008315819
total_rewards                [5776.36003197 5496.44263323 5479.61099669 4408.32545886 5547.14095731
 5357.59575284 5515.68896344 5537.43267016 3473.88793282 4185.78609126]
total_rewards_mean           5077.827148857476
total_rewards_std            730.9373618487468
total_rewards_max            5776.360031967753
total_rewards_min            3473.8879328224557
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               187.4213638510555
(Previous) Eval Time (s)     29.86919728992507
Sample Time (s)              6.253788835834712
Epoch Time (s)               223.54434997681528
Total Train Time (s)         10435.175599944778
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:37.898372 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #46 | Epoch Duration: 223.62362480163574
2020-01-13 02:30:37.898571 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3822732
Z variance train             0.008272995
KL Divergence                33.139206
KL Loss                      3.3139207
QF Loss                      237.86632
VF Loss                      65.518974
Policy Loss                  -767.9112
Q Predictions Mean           756.9458
Q Predictions Std            724.54034
Q Predictions Max            2263.134
Q Predictions Min            -75.85742
V Predictions Mean           769.06055
V Predictions Std            726.93
V Predictions Max            2245.8254
V Predictions Min            -65.195206
Log Pis Mean                 -1.5511365
Log Pis Std                  3.345251
Log Pis Max                  19.585936
Log Pis Min                  -6.955123
Policy mu Mean               -0.0014785659
Policy mu Std                0.6955076
Policy mu Max                3.7488348
Policy mu Min                -3.1610377
Policy log std Mean          -0.46611166
Policy log std Std           0.25068644
Policy log std Max           -0.15089905
Policy log std Min           -2.1429658
Z mean eval                  2.3952305
Z variance eval              0.021143887
total_rewards                [5811.63408185 5629.96645669 5673.87775889 5701.63246019 5316.65634387
 5454.39836084 5466.52699234 5655.96473918 5610.59103921 5772.916265  ]
total_rewards_mean           5609.4164498065265
total_rewards_std            145.95551496690265
total_rewards_max            5811.634081854503
total_rewards_min            5316.656343873898
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               184.9775400799699
(Previous) Eval Time (s)     25.4176829890348
Sample Time (s)              6.254399398807436
Epoch Time (s)               216.64962246781215
Total Train Time (s)         10651.910857778043
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:34:14.637160 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #47 | Epoch Duration: 216.7384181022644
2020-01-13 02:34:14.637438 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3891132
Z variance train             0.020983655
KL Divergence                30.345417
KL Loss                      3.0345418
QF Loss                      985.9297
VF Loss                      347.98706
Policy Loss                  -703.6261
Q Predictions Mean           694.5601
Q Predictions Std            705.77594
Q Predictions Max            2162.5452
Q Predictions Min            -83.197845
V Predictions Mean           707.8051
V Predictions Std            709.2615
V Predictions Max            2174.227
V Predictions Min            -73.05306
Log Pis Mean                 -1.5754405
Log Pis Std                  3.1798344
Log Pis Max                  13.511213
Log Pis Min                  -6.412565
Policy mu Mean               -0.06522762
Policy mu Std                0.70701987
Policy mu Max                3.0875208
Policy mu Min                -2.6817691
Policy log std Mean          -0.4441743
Policy log std Std           0.22624432
Policy log std Max           -0.15550548
Policy log std Min           -1.8382909
Z mean eval                  2.400104
Z variance eval              0.017684087
total_rewards                [5633.0727579  5547.64150276 5387.17167553 5685.00104423 5654.22512444
 5740.98795463 5666.54842195 5696.0034432  5669.67599641 5708.11088094]
total_rewards_mean           5638.843880198393
total_rewards_std            97.09472208770134
total_rewards_max            5740.987954625214
total_rewards_min            5387.171675525068
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               186.2389863235876
(Previous) Eval Time (s)     29.889542726799846
Sample Time (s)              6.171431785915047
Epoch Time (s)               222.2999608363025
Total Train Time (s)         10874.595788502134
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:37:57.321374 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #48 | Epoch Duration: 222.68374252319336
2020-01-13 02:37:57.321528 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4033253
Z variance train             0.017709818
KL Divergence                30.8609
KL Loss                      3.08609
QF Loss                      791.4275
VF Loss                      127.09065
Policy Loss                  -725.4306
Q Predictions Mean           719.43994
Q Predictions Std            707.8625
Q Predictions Max            2236.7498
Q Predictions Min            -69.37448
V Predictions Mean           728.81067
V Predictions Std            709.3252
V Predictions Max            2225.1711
V Predictions Min            -64.68082
Log Pis Mean                 -1.605813
Log Pis Std                  3.2643402
Log Pis Max                  14.297088
Log Pis Min                  -9.263687
Policy mu Mean               -0.051000763
Policy mu Std                0.7403378
Policy mu Max                3.8343883
Policy mu Min                -2.9764898
Policy log std Mean          -0.45969474
Policy log std Std           0.23508367
Policy log std Max           -0.14691462
Policy log std Min           -2.051124
Z mean eval                  2.4149373
Z variance eval              0.009930139
total_rewards                [5574.96773318 5595.77060143 5634.15674    5831.4692461  5665.65323501
 5833.32319959 5453.95280721 5412.63637113 5752.88211705 4595.82514978]
total_rewards_mean           5535.06372004949
total_rewards_std            340.60931265042643
total_rewards_max            5833.323199594375
total_rewards_min            4595.825149780579
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               187.68239828478545
(Previous) Eval Time (s)     25.091157615184784
Sample Time (s)              6.120279508177191
Epoch Time (s)               218.89383540814742
Total Train Time (s)         11093.577175447252
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:36.304795 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #49 | Epoch Duration: 218.98314690589905
2020-01-13 02:41:36.304990 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4162889
Z variance train             0.0099574905
KL Divergence                30.261993
KL Loss                      3.0261993
QF Loss                      285.3009
VF Loss                      84.069435
Policy Loss                  -780.5323
Q Predictions Mean           772.4857
Q Predictions Std            756.4514
Q Predictions Max            2313.1672
Q Predictions Min            -68.39605
V Predictions Mean           776.7488
V Predictions Std            754.3113
V Predictions Max            2287.3123
V Predictions Min            -71.143
Log Pis Mean                 -1.4025378
Log Pis Std                  3.3443189
Log Pis Max                  10.315491
Log Pis Min                  -7.106841
Policy mu Mean               -0.01922196
Policy mu Std                0.7407352
Policy mu Max                2.79578
Policy mu Min                -2.5082207
Policy log std Mean          -0.45403942
Policy log std Std           0.21974629
Policy log std Max           -0.1835373
Policy log std Min           -1.7632263
Z mean eval                  2.4098716
Z variance eval              0.012762261
total_rewards                [5765.6148071  5877.08904629 5837.65709814 5698.21833882 5909.76640606
 6051.0459743  6105.82068099 5938.47559349 5863.63563618 5896.45231148]
total_rewards_mean           5894.377589284916
total_rewards_std            114.43705656685762
total_rewards_max            6105.820680993063
total_rewards_min            5698.218338824145
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               186.43790297675878
(Previous) Eval Time (s)     30.254214324988425
Sample Time (s)              6.14051748579368
Epoch Time (s)               222.83263478754088
Total Train Time (s)         11316.500898300204
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:45:19.230200 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #50 | Epoch Duration: 222.92500042915344
2020-01-13 02:45:19.230504 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #50 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4132237
Z variance train             0.012806797
KL Divergence                28.246328
KL Loss                      2.824633
QF Loss                      392.67755
VF Loss                      213.91095
Policy Loss                  -826.67096
Q Predictions Mean           815.3597
Q Predictions Std            753.7222
Q Predictions Max            2281.3235
Q Predictions Min            -67.1555
V Predictions Mean           821.41614
V Predictions Std            751.3567
V Predictions Max            2271.9094
V Predictions Min            -72.72993
Log Pis Mean                 -1.5005624
Log Pis Std                  3.1420014
Log Pis Max                  9.49777
Log Pis Min                  -5.7915087
Policy mu Mean               -0.09238615
Policy mu Std                0.7402435
Policy mu Max                2.418401
Policy mu Min                -2.786629
Policy log std Mean          -0.46180534
Policy log std Std           0.23953268
Policy log std Max           -0.10065186
Policy log std Min           -1.9378566
Z mean eval                  2.4063053
Z variance eval              0.017880313
total_rewards                [5071.08110075 5538.95343491 5459.79510716 5611.47835621 5475.2292243
 5238.88584135 3286.51143843 5532.87989491 4340.01866582 5632.28347609]
total_rewards_mean           5118.711653993638
total_rewards_std            712.6140000094011
total_rewards_max            5632.283476085522
total_rewards_min            3286.511438427471
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               188.07947316300124
(Previous) Eval Time (s)     25.099488477688283
Sample Time (s)              6.398998690303415
Epoch Time (s)               219.57796033099294
Total Train Time (s)         11536.169902853668
Epoch                        51
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:58.899918 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #51 | Epoch Duration: 219.66922187805176
2020-01-13 02:48:58.900140 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.407617
Z variance train             0.01792757
KL Divergence                28.600338
KL Loss                      2.8600338
QF Loss                      230.44044
VF Loss                      44.49787
Policy Loss                  -804.64575
Q Predictions Mean           800.0997
Q Predictions Std            768.87463
Q Predictions Max            2299.8223
Q Predictions Min            -63.562927
V Predictions Mean           802.4674
V Predictions Std            768.8571
V Predictions Max            2277.0493
V Predictions Min            -72.16001
Log Pis Mean                 -1.6324639
Log Pis Std                  3.100915
Log Pis Max                  9.827938
Log Pis Min                  -6.879979
Policy mu Mean               -0.044882517
Policy mu Std                0.7173642
Policy mu Max                2.5078826
Policy mu Min                -2.6357632
Policy log std Mean          -0.4446074
Policy log std Std           0.21584314
Policy log std Max           -0.14540258
Policy log std Min           -2.1008115
Z mean eval                  2.4158103
Z variance eval              0.0204042
total_rewards                [5541.24712474 6021.18881863 5922.58595873 5651.45867005 5801.04747216
 5755.95284072 5883.51891267 5795.55451458 5780.40219042 5896.84491101]
total_rewards_mean           5804.980141369399
total_rewards_std            130.92776684927827
total_rewards_max            6021.188818625098
total_rewards_min            5541.247124742611
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               185.98303209617734
(Previous) Eval Time (s)     25.048811009153724
Sample Time (s)              6.56935424124822
Epoch Time (s)               217.60119734657928
Total Train Time (s)         11753.854759290814
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:52:36.589757 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #52 | Epoch Duration: 217.68938446044922
2020-01-13 02:52:36.590152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4172795
Z variance train             0.020343397
KL Divergence                29.92098
KL Loss                      2.992098
QF Loss                      823.2987
VF Loss                      107.86604
Policy Loss                  -830.2411
Q Predictions Mean           820.7412
Q Predictions Std            766.1321
Q Predictions Max            2297.1562
Q Predictions Min            -98.742226
V Predictions Mean           831.91
V Predictions Std            766.9009
V Predictions Max            2283.5576
V Predictions Min            -89.97578
Log Pis Mean                 -1.180562
Log Pis Std                  3.4359107
Log Pis Max                  14.085802
Log Pis Min                  -8.393363
Policy mu Mean               -0.055846293
Policy mu Std                0.75830096
Policy mu Max                2.721046
Policy mu Min                -2.768252
Policy log std Mean          -0.4683756
Policy log std Std           0.23229782
Policy log std Max           -0.13658595
Policy log std Min           -2.2511196
Z mean eval                  2.4329562
Z variance eval              0.017811544
total_rewards                [5788.04678046 5738.36865062 6033.08609358 6049.39101195 5851.53975442
 2570.34193043 5880.08815175 6003.13894673 5834.68897167 6085.47464055]
total_rewards_mean           5583.41649321556
total_rewards_std            1010.6981935233288
total_rewards_max            6085.474640545198
total_rewards_min            2570.3419304338536
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               187.6082933647558
(Previous) Eval Time (s)     29.918249714188278
Sample Time (s)              6.239514440763742
Epoch Time (s)               223.76605751970783
Total Train Time (s)         11977.93731464399
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:56:20.671500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #53 | Epoch Duration: 224.0810685157776
2020-01-13 02:56:20.671726 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4345744
Z variance train             0.017822567
KL Divergence                30.587145
KL Loss                      3.0587146
QF Loss                      691.7591
VF Loss                      49.52264
Policy Loss                  -748.4092
Q Predictions Mean           739.7345
Q Predictions Std            749.82544
Q Predictions Max            2377.5457
Q Predictions Min            -77.49824
V Predictions Mean           747.3501
V Predictions Std            753.36066
V Predictions Max            2377.5352
V Predictions Min            -77.81072
Log Pis Mean                 -1.6909995
Log Pis Std                  3.3890202
Log Pis Max                  15.760572
Log Pis Min                  -6.4056926
Policy mu Mean               -0.010802709
Policy mu Std                0.7133555
Policy mu Max                2.8147779
Policy mu Min                -2.673869
Policy log std Mean          -0.44819656
Policy log std Std           0.21460296
Policy log std Max           -0.1516096
Policy log std Min           -2.108212
Z mean eval                  2.4219162
Z variance eval              0.018000547
total_rewards                [5844.55686864 5781.23829157 5770.32512156 5767.3241933  5825.61994519
 5677.3705698  5752.9686167  5609.61544777 5889.38604022 5785.16043966]
total_rewards_mean           5770.356553441033
total_rewards_std            76.06638415254804
total_rewards_max            5889.386040215507
total_rewards_min            5609.615447774476
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               187.7026898758486
(Previous) Eval Time (s)     29.810591076035053
Sample Time (s)              6.284710684791207
Epoch Time (s)               223.79799163667485
Total Train Time (s)         12201.817136217374
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:00:04.554003 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #54 | Epoch Duration: 223.8821063041687
2020-01-13 03:00:04.554263 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #54 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4185386
Z variance train             0.01798318
KL Divergence                29.980762
KL Loss                      2.9980762
QF Loss                      230.69289
VF Loss                      70.60527
Policy Loss                  -760.65155
Q Predictions Mean           752.9823
Q Predictions Std            745.6717
Q Predictions Max            2346.6917
Q Predictions Min            -87.63566
V Predictions Mean           765.49664
V Predictions Std            743.9023
V Predictions Max            2354.3625
V Predictions Min            -95.91559
Log Pis Mean                 -1.7221103
Log Pis Std                  2.7803776
Log Pis Max                  7.611027
Log Pis Min                  -6.420254
Policy mu Mean               -0.06492108
Policy mu Std                0.66961384
Policy mu Max                2.2860217
Policy mu Min                -2.1397767
Policy log std Mean          -0.45217457
Policy log std Std           0.22989108
Policy log std Max           -0.120602444
Policy log std Min           -2.0656178
Z mean eval                  2.3752666
Z variance eval              0.0045114737
total_rewards                [6021.24156528 6073.45284334 6161.63487915 6123.56979356 6067.8540557
 6078.70257209 6259.4608765  6051.724177   6097.60021638 3698.29977539]
total_rewards_mean           5863.354075438229
total_rewards_std            724.4766453240242
total_rewards_max            6259.46087649743
total_rewards_min            3698.299775388022
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               186.9413216789253
(Previous) Eval Time (s)     30.015761643182486
Sample Time (s)              5.184444929007441
Epoch Time (s)               222.14152825111523
Total Train Time (s)         12424.041295584291
Epoch                        55
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:03:46.779782 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #55 | Epoch Duration: 222.22532200813293
2020-01-13 03:03:46.780055 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #55 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3823981
Z variance train             0.004483
KL Divergence                31.857677
KL Loss                      3.185768
QF Loss                      369.6329
VF Loss                      74.01573
Policy Loss                  -719.674
Q Predictions Mean           712.898
Q Predictions Std            741.27673
Q Predictions Max            2395.396
Q Predictions Min            -64.411606
V Predictions Mean           722.4626
V Predictions Std            741.68134
V Predictions Max            2395.5955
V Predictions Min            -81.49657
Log Pis Mean                 -1.3440955
Log Pis Std                  3.3619215
Log Pis Max                  12.041818
Log Pis Min                  -7.070809
Policy mu Mean               -0.041795563
Policy mu Std                0.73741055
Policy mu Max                2.733506
Policy mu Min                -2.940049
Policy log std Mean          -0.43204215
Policy log std Std           0.21448088
Policy log std Max           -0.12023057
Policy log std Min           -2.159181
Z mean eval                  2.4222453
Z variance eval              0.002684382
total_rewards                [5837.96147503 5958.44053963 5963.94546036 5865.14207281 5999.9704002
 6019.90667447 5831.02206694 5833.17985781 5909.66622993 5955.29298409]
total_rewards_mean           5917.452776127009
total_rewards_std            68.02022238639186
total_rewards_max            6019.906674469551
total_rewards_min            5831.022066939676
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               187.82332108682021
(Previous) Eval Time (s)     29.714234991930425
Sample Time (s)              6.178860838059336
Epoch Time (s)               223.71641691680998
Total Train Time (s)         12647.850048990455
Epoch                        56
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:07:30.588168 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #56 | Epoch Duration: 223.80794548988342
2020-01-13 03:07:30.588309 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4680152
Z variance train             0.0026188942
KL Divergence                34.438614
KL Loss                      3.4438615
QF Loss                      214.84642
VF Loss                      58.356316
Policy Loss                  -730.6177
Q Predictions Mean           723.71564
Q Predictions Std            709.34576
Q Predictions Max            2387.1204
Q Predictions Min            -97.41751
V Predictions Mean           730.57214
V Predictions Std            713.1427
V Predictions Max            2360.2334
V Predictions Min            -88.82741
Log Pis Mean                 -1.6511474
Log Pis Std                  3.1292806
Log Pis Max                  9.356824
Log Pis Min                  -6.65555
Policy mu Mean               -0.01967318
Policy mu Std                0.6968759
Policy mu Max                2.4349372
Policy mu Min                -2.5521388
Policy log std Mean          -0.44301084
Policy log std Std           0.23214185
Policy log std Max           -0.13459331
Policy log std Min           -2.137845
Z mean eval                  2.3993518
Z variance eval              0.011217145
total_rewards                [5702.41097301 5621.56648999 5522.87846523 5395.35298196 5659.08180754
 5698.63056891 5555.51899965 5688.20885325 5563.84785369 5736.61402409]
total_rewards_mean           5614.411101730696
total_rewards_std            99.82626659315146
total_rewards_max            5736.614024090868
total_rewards_min            5395.352981961576
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               188.17416345281526
(Previous) Eval Time (s)     30.052103001624346
Sample Time (s)              6.2276957565918565
Epoch Time (s)               224.45396221103147
Total Train Time (s)         12872.389014812652
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:15.128868 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #57 | Epoch Duration: 224.54040813446045
2020-01-13 03:11:15.129108 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #57 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.394729
Z variance train             0.011229368
KL Divergence                29.292364
KL Loss                      2.9292364
QF Loss                      796.96515
VF Loss                      232.04993
Policy Loss                  -773.5665
Q Predictions Mean           765.68286
Q Predictions Std            791.86176
Q Predictions Max            2356.1155
Q Predictions Min            -114.10052
V Predictions Mean           780.9175
V Predictions Std            794.65515
V Predictions Max            2372.1914
V Predictions Min            -94.585724
Log Pis Mean                 -1.5748606
Log Pis Std                  3.5144866
Log Pis Max                  16.594885
Log Pis Min                  -7.4844112
Policy mu Mean               -0.053701133
Policy mu Std                0.7473339
Policy mu Max                2.5522528
Policy mu Min                -2.8658338
Policy log std Mean          -0.45589685
Policy log std Std           0.24414164
Policy log std Max           -0.15025455
Policy log std Min           -2.151228
Z mean eval                  2.4559357
Z variance eval              0.02524751
total_rewards                [6377.22944469 6212.59822463 6085.95251577 6378.21370426 6085.4910081
 6174.59336936 5914.57932569 5840.7229261  6168.55943057 6129.9880424 ]
total_rewards_mean           6136.792799157358
total_rewards_std            163.271984388458
total_rewards_max            6378.213704256258
total_rewards_min            5840.7229260997
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               188.3026502407156
(Previous) Eval Time (s)     24.70129062514752
Sample Time (s)              6.162199261598289
Epoch Time (s)               219.1661401274614
Total Train Time (s)         13091.637116295286
Epoch                        58
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:54.380314 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #58 | Epoch Duration: 219.25102758407593
2020-01-13 03:14:54.380600 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #58 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4408898
Z variance train             0.024933737
KL Divergence                29.48146
KL Loss                      2.948146
QF Loss                      199.6922
VF Loss                      51.874435
Policy Loss                  -800.68805
Q Predictions Mean           791.8583
Q Predictions Std            820.0874
Q Predictions Max            2447.536
Q Predictions Min            -101.70539
V Predictions Mean           796.3973
V Predictions Std            817.67834
V Predictions Max            2445.8657
V Predictions Min            -94.43703
Log Pis Mean                 -1.4783727
Log Pis Std                  3.3681705
Log Pis Max                  10.880018
Log Pis Min                  -7.395627
Policy mu Mean               -0.07149107
Policy mu Std                0.7297866
Policy mu Max                2.5769818
Policy mu Min                -2.4165413
Policy log std Mean          -0.45966554
Policy log std Std           0.23371007
Policy log std Max           -0.15312603
Policy log std Min           -2.2977226
Z mean eval                  2.3764367
Z variance eval              0.013419652
total_rewards                [5750.59561328 5693.96201894 5718.84775894 5737.51942807 5780.226284
 5868.2932524  5635.78680244 5677.66343033 5664.2216719  5736.19925325]
total_rewards_mean           5726.331551356149
total_rewards_std            62.76736417801166
total_rewards_max            5868.2932523957525
total_rewards_min            5635.786802441267
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               188.59358926583081
(Previous) Eval Time (s)     30.567091414239258
Sample Time (s)              6.299307469744235
Epoch Time (s)               225.4599881498143
Total Train Time (s)         13317.193011524621
Epoch                        59
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:18:39.935369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #59 | Epoch Duration: 225.55457615852356
2020-01-13 03:18:39.935509 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3777962
Z variance train             0.013402419
KL Divergence                28.978098
KL Loss                      2.8978097
QF Loss                      225.28296
VF Loss                      37.506363
Policy Loss                  -706.53656
Q Predictions Mean           698.5772
Q Predictions Std            727.9814
Q Predictions Max            2405.426
Q Predictions Min            -95.00376
V Predictions Mean           706.5227
V Predictions Std            731.0507
V Predictions Max            2409.7207
V Predictions Min            -104.6995
Log Pis Mean                 -1.6892135
Log Pis Std                  2.877324
Log Pis Max                  9.584259
Log Pis Min                  -6.675419
Policy mu Mean               -0.002542463
Policy mu Std                0.67550516
Policy mu Max                2.4831126
Policy mu Min                -2.5414176
Policy log std Mean          -0.44050714
Policy log std Std           0.21526296
Policy log std Max           -0.14759234
Policy log std Min           -2.1111445
Z mean eval                  2.4170582
Z variance eval              0.0061714374
total_rewards                [6070.47205246 6012.9522242  6101.98083896 6136.98202105 2240.06976851
 5744.71547875 5972.63249619 6103.59416063 6074.67126279 6150.36302761]
total_rewards_mean           5660.843333115198
total_rewards_std            1145.6848122141312
total_rewards_max            6150.363027605096
total_rewards_min            2240.0697685092673
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               186.64848724612966
(Previous) Eval Time (s)     29.855086382944137
Sample Time (s)              7.514069646131247
Epoch Time (s)               224.01764327520505
Total Train Time (s)         13541.299193346407
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:24.042696 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #60 | Epoch Duration: 224.10708618164062
2020-01-13 03:22:24.042820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4186044
Z variance train             0.0060142665
KL Divergence                31.286446
KL Loss                      3.1286447
QF Loss                      361.5055
VF Loss                      97.50837
Policy Loss                  -846.4148
Q Predictions Mean           836.44434
Q Predictions Std            798.33057
Q Predictions Max            2457.94
Q Predictions Min            -115.63688
V Predictions Mean           843.299
V Predictions Std            799.5073
V Predictions Max            2439.5713
V Predictions Min            -134.94722
Log Pis Mean                 -1.2145281
Log Pis Std                  3.5824015
Log Pis Max                  14.437563
Log Pis Min                  -8.233348
Policy mu Mean               -0.12624179
Policy mu Std                0.7707158
Policy mu Max                3.0216608
Policy mu Min                -3.195116
Policy log std Mean          -0.44568813
Policy log std Std           0.22377536
Policy log std Max           -0.035897553
Policy log std Min           -2.1042163
Z mean eval                  2.3872137
Z variance eval              0.0068397536
total_rewards                [5709.55215659 5727.83927559 5513.26093451 5572.65780786 5634.15251296
 5717.42876185 5611.66816672 5502.92566719 5718.97430213 5562.52422003]
total_rewards_mean           5627.098380543185
total_rewards_std            83.27508221345062
total_rewards_max            5727.83927558907
total_rewards_min            5502.925667194192
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               187.9925628551282
(Previous) Eval Time (s)     30.148482660762966
Sample Time (s)              6.137740980368108
Epoch Time (s)               224.27878649625927
Total Train Time (s)         13765.668768367264
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:26:08.416322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #61 | Epoch Duration: 224.3733742237091
2020-01-13 03:26:08.416577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3858867
Z variance train             0.0068444414
KL Divergence                32.805763
KL Loss                      3.2805765
QF Loss                      209.72528
VF Loss                      105.94847
Policy Loss                  -764.51587
Q Predictions Mean           755.84753
Q Predictions Std            772.1166
Q Predictions Max            2443.795
Q Predictions Min            -110.25078
V Predictions Mean           761.7869
V Predictions Std            767.99725
V Predictions Max            2400.9292
V Predictions Min            -110.772446
Log Pis Mean                 -1.4946594
Log Pis Std                  3.1974585
Log Pis Max                  10.268626
Log Pis Min                  -6.929656
Policy mu Mean               -0.05547144
Policy mu Std                0.716625
Policy mu Max                2.2603452
Policy mu Min                -2.582688
Policy log std Mean          -0.44167376
Policy log std Std           0.21908772
Policy log std Max           -0.12808758
Policy log std Min           -2.290547
Z mean eval                  2.3897653
Z variance eval              0.008569826
total_rewards                [6160.24325809 6171.41421641 6151.44957153 6054.60819564 6032.30289266
 6115.4645797  5987.49069728 5790.41308063 6043.64163595 5894.50073039]
total_rewards_mean           6040.152885827346
total_rewards_std            116.76926583359503
total_rewards_max            6171.414216407587
total_rewards_min            5790.41308063217
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               186.730641042348
(Previous) Eval Time (s)     29.91351104201749
Sample Time (s)              6.076122652273625
Epoch Time (s)               222.7202747366391
Total Train Time (s)         13988.471289599314
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:29:51.219189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #62 | Epoch Duration: 222.80241870880127
2020-01-13 03:29:51.219370 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3890877
Z variance train             0.008639792
KL Divergence                33.08727
KL Loss                      3.308727
QF Loss                      269.77203
VF Loss                      199.41914
Policy Loss                  -807.3063
Q Predictions Mean           803.4875
Q Predictions Std            809.42065
Q Predictions Max            2502.2432
Q Predictions Min            -113.89395
V Predictions Mean           818.3779
V Predictions Std            815.795
V Predictions Max            2520.215
V Predictions Min            -111.673836
Log Pis Mean                 -1.222328
Log Pis Std                  3.2606483
Log Pis Max                  11.806016
Log Pis Min                  -6.593865
Policy mu Mean               0.0059359595
Policy mu Std                0.7690601
Policy mu Max                2.6348867
Policy mu Min                -3.3578389
Policy log std Mean          -0.46734187
Policy log std Std           0.2454035
Policy log std Max           -0.037298977
Policy log std Min           -2.0184257
Z mean eval                  2.423922
Z variance eval              0.017593164
total_rewards                [5381.63581114 6297.29328948 6110.84029227 6105.40027958 5092.75556348
 4609.89595557 6378.41618638 6132.52439837 5929.97142515 5923.92038866]
total_rewards_mean           5796.265359007499
total_rewards_std            548.2708889531251
total_rewards_max            6378.416186375862
total_rewards_min            4609.895955565042
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               184.78909204388037
(Previous) Eval Time (s)     30.11633804719895
Sample Time (s)              6.293021673336625
Epoch Time (s)               221.19845176441595
Total Train Time (s)         14209.74754405301
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:33:32.496744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #63 | Epoch Duration: 221.27724409103394
2020-01-13 03:33:32.496877 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4248402
Z variance train             0.017598173
KL Divergence                29.35921
KL Loss                      2.935921
QF Loss                      693.9475
VF Loss                      132.6536
Policy Loss                  -813.1869
Q Predictions Mean           804.7069
Q Predictions Std            793.9799
Q Predictions Max            2459.782
Q Predictions Min            -115.42399
V Predictions Mean           811.1515
V Predictions Std            794.03827
V Predictions Max            2445.9133
V Predictions Min            -103.94168
Log Pis Mean                 -1.3539191
Log Pis Std                  3.3639278
Log Pis Max                  14.547317
Log Pis Min                  -6.901544
Policy mu Mean               -0.031777803
Policy mu Std                0.7626281
Policy mu Max                3.8937304
Policy mu Min                -3.100086
Policy log std Mean          -0.4694045
Policy log std Std           0.2300873
Policy log std Max           -0.15268262
Policy log std Min           -2.0503042
Z mean eval                  2.3712795
Z variance eval              0.019231234
total_rewards                [6071.34454816 6271.51235163 6210.94956856 6331.18718357 6625.94868852
 6361.80251647 6441.67447148 6329.46288898 6410.50039181 6383.71576586]
total_rewards_mean           6343.809837505704
total_rewards_std            138.93341759151417
total_rewards_max            6625.948688524013
total_rewards_min            6071.344548159205
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               186.28503796597943
(Previous) Eval Time (s)     29.810289926826954
Sample Time (s)              6.317941215354949
Epoch Time (s)               222.41326910816133
Total Train Time (s)         14432.246422992554
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:37:14.999121 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #64 | Epoch Duration: 222.50211787223816
2020-01-13 03:37:14.999356 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.359745
Z variance train             0.019650247
KL Divergence                30.138496
KL Loss                      3.0138497
QF Loss                      502.02545
VF Loss                      337.1417
Policy Loss                  -877.4549
Q Predictions Mean           871.87805
Q Predictions Std            827.642
Q Predictions Max            2441.7034
Q Predictions Min            -109.69705
V Predictions Mean           889.2473
V Predictions Std            834.77747
V Predictions Max            2456.3506
V Predictions Min            -102.8182
Log Pis Mean                 -1.2732406
Log Pis Std                  3.3807056
Log Pis Max                  11.678955
Log Pis Min                  -10.730068
Policy mu Mean               -0.050059874
Policy mu Std                0.7726734
Policy mu Max                3.046837
Policy mu Min                -2.8757114
Policy log std Mean          -0.4674554
Policy log std Std           0.23380652
Policy log std Max           -0.118224055
Policy log std Min           -2.1714919
Z mean eval                  2.358163
Z variance eval              0.006485434
total_rewards                [5953.64692014 5893.01275951 5607.60296982 5950.3491492  5980.90487892
 5901.20521941 5931.09691229 6005.54124577 6097.42879696 5874.91276393]
total_rewards_mean           5919.570161593418
total_rewards_std            120.57714758050122
total_rewards_max            6097.428796955432
total_rewards_min            5607.602969816702
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               187.83497433410957
(Previous) Eval Time (s)     24.9456902788952
Sample Time (s)              6.10947335138917
Epoch Time (s)               218.89013796439394
Total Train Time (s)         14651.225688688923
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:40:53.981733 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #65 | Epoch Duration: 218.98219513893127
2020-01-13 03:40:53.981937 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3474975
Z variance train             0.006657602
KL Divergence                31.815937
KL Loss                      3.1815937
QF Loss                      193.41861
VF Loss                      66.30578
Policy Loss                  -756.3035
Q Predictions Mean           749.3548
Q Predictions Std            776.6974
Q Predictions Max            2455.4968
Q Predictions Min            -140.79414
V Predictions Mean           755.3783
V Predictions Std            778.27893
V Predictions Max            2430.6038
V Predictions Min            -120.94453
Log Pis Mean                 -1.5276365
Log Pis Std                  3.1590214
Log Pis Max                  9.344141
Log Pis Min                  -6.3552027
Policy mu Mean               -0.08263319
Policy mu Std                0.6996278
Policy mu Max                2.3763134
Policy mu Min                -2.6267061
Policy log std Mean          -0.4513552
Policy log std Std           0.23325387
Policy log std Max           -0.08411935
Policy log std Min           -2.2423096
Z mean eval                  2.3638089
Z variance eval              0.01374543
total_rewards                [5870.7773472  5862.14248766 5929.32884651 5884.86198266 6057.48404387
 5911.39730999 5837.21117545 5656.59505225 6027.97099544 5954.71017645]
total_rewards_mean           5899.247941747322
total_rewards_std            105.29014506306054
total_rewards_max            6057.484043870576
total_rewards_min            5656.595052249281
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               188.0287812212482
(Previous) Eval Time (s)     25.319307531695813
Sample Time (s)              6.212527679279447
Epoch Time (s)               219.56061643222347
Total Train Time (s)         14870.873629646376
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:44:33.633613 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #66 | Epoch Duration: 219.65149760246277
2020-01-13 03:44:33.633947 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3589544
Z variance train             0.013750893
KL Divergence                32.303722
KL Loss                      3.2303722
QF Loss                      255.79582
VF Loss                      174.76811
Policy Loss                  -822.80005
Q Predictions Mean           817.1772
Q Predictions Std            794.24786
Q Predictions Max            2474.4214
Q Predictions Min            -130.80072
V Predictions Mean           831.1282
V Predictions Std            799.8485
V Predictions Max            2461.6987
V Predictions Min            -116.563866
Log Pis Mean                 -1.208628
Log Pis Std                  3.493672
Log Pis Max                  10.598558
Log Pis Min                  -7.842445
Policy mu Mean               -0.057117973
Policy mu Std                0.7567594
Policy mu Max                2.5699635
Policy mu Min                -2.6594007
Policy log std Mean          -0.48897243
Policy log std Std           0.2434632
Policy log std Max           -0.13783087
Policy log std Min           -2.1528716
Z mean eval                  2.3480186
Z variance eval              0.018309932
total_rewards                [2528.06670893 6243.57931495 6378.41913935 6210.16551937 6220.50905382
 6310.38119174 6147.87511108 6202.53654786 6224.39303699 6186.94811168]
total_rewards_mean           5865.287373578007
total_rewards_std            1114.1228834324465
total_rewards_max            6378.419139348064
total_rewards_min            2528.066708933844
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               188.1673838668503
(Previous) Eval Time (s)     29.75428160605952
Sample Time (s)              6.1528732613660395
Epoch Time (s)               224.07453873427585
Total Train Time (s)         15095.03897343669
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:17.798910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #67 | Epoch Duration: 224.16473960876465
2020-01-13 03:48:17.799044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.347347
Z variance train             0.0182846
KL Divergence                30.62833
KL Loss                      3.062833
QF Loss                      324.07568
VF Loss                      123.35798
Policy Loss                  -764.12036
Q Predictions Mean           752.8854
Q Predictions Std            782.7439
Q Predictions Max            2527.969
Q Predictions Min            -113.03267
V Predictions Mean           758.2476
V Predictions Std            780.53204
V Predictions Max            2543.5754
V Predictions Min            -125.067375
Log Pis Mean                 -1.1401472
Log Pis Std                  3.812455
Log Pis Max                  20.234825
Log Pis Min                  -7.6890106
Policy mu Mean               8.77101e-05
Policy mu Std                0.7951635
Policy mu Max                3.6261878
Policy mu Min                -3.6706023
Policy log std Mean          -0.46469846
Policy log std Std           0.24061549
Policy log std Max           -0.10185714
Policy log std Min           -2.2670624
Z mean eval                  2.372252
Z variance eval              0.019833742
total_rewards                [6267.78025057 6430.50701373 6414.21235906 6512.63634964 6170.79767208
 6274.18646347 6321.9283168  6379.09155925 6356.8619876  6406.8009951 ]
total_rewards_mean           6353.480296729422
total_rewards_std            92.98553429159536
total_rewards_max            6512.6363496423355
total_rewards_min            6170.797672075066
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               186.75817075604573
(Previous) Eval Time (s)     30.17160046612844
Sample Time (s)              6.224948122166097
Epoch Time (s)               223.15471934434026
Total Train Time (s)         15318.289904132951
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:52:01.051243 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #68 | Epoch Duration: 223.25208258628845
2020-01-13 03:52:01.051442 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3710232
Z variance train             0.019907514
KL Divergence                29.780386
KL Loss                      2.9780385
QF Loss                      173.9462
VF Loss                      36.677547
Policy Loss                  -819.9799
Q Predictions Mean           811.0487
Q Predictions Std            832.507
Q Predictions Max            2602.7378
Q Predictions Min            -130.29144
V Predictions Mean           819.2676
V Predictions Std            835.41235
V Predictions Max            2582.1504
V Predictions Min            -124.48591
Log Pis Mean                 -1.0182364
Log Pis Std                  3.6155934
Log Pis Max                  21.739529
Log Pis Min                  -7.333329
Policy mu Mean               -0.094935
Policy mu Std                0.7854345
Policy mu Max                2.7563736
Policy mu Min                -3.481133
Policy log std Mean          -0.46576533
Policy log std Std           0.2210289
Policy log std Max           -0.06901276
Policy log std Min           -2.335439
Z mean eval                  2.3554006
Z variance eval              0.01686182
total_rewards                [6180.02087311 6159.74505673 6183.39201641 6270.32557261 6378.72280081
 6108.92562228 6096.44845029 5914.65077107 6143.10092139 6029.80835064]
total_rewards_mean           6146.514043532895
total_rewards_std            119.67449695934178
total_rewards_max            6378.722800812186
total_rewards_min            5914.650771066295
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               186.99435090692714
(Previous) Eval Time (s)     30.14867762522772
Sample Time (s)              6.414986478164792
Epoch Time (s)               223.55801501031965
Total Train Time (s)         15541.94618464727
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:55:44.707873 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #69 | Epoch Duration: 223.65629172325134
2020-01-13 03:55:44.708025 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3574796
Z variance train             0.01685493
KL Divergence                31.981262
KL Loss                      3.1981263
QF Loss                      436.30237
VF Loss                      75.66874
Policy Loss                  -795.2056
Q Predictions Mean           787.1103
Q Predictions Std            810.22906
Q Predictions Max            2570.332
Q Predictions Min            -117.868866
V Predictions Mean           794.7187
V Predictions Std            813.75543
V Predictions Max            2577.0261
V Predictions Min            -117.465126
Log Pis Mean                 -1.2509468
Log Pis Std                  3.2248554
Log Pis Max                  12.712981
Log Pis Min                  -7.7459927
Policy mu Mean               0.027641967
Policy mu Std                0.75884396
Policy mu Max                2.6628919
Policy mu Min                -2.8339252
Policy log std Mean          -0.47239783
Policy log std Std           0.24126779
Policy log std Max           -0.13287985
Policy log std Min           -2.3453705
Z mean eval                  2.3468366
Z variance eval              0.014217136
total_rewards                [6096.51893407 6168.65722274 6143.30946568 6082.57267142 6325.17076502
 6198.63458537 6136.44968103 6128.3305535  6121.44110893 6105.50953492]
total_rewards_mean           6150.659452267762
total_rewards_std            66.55334935062358
total_rewards_max            6325.170765016041
total_rewards_min            6082.572671416414
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               187.91823762236163
(Previous) Eval Time (s)     29.701641481835395
Sample Time (s)              6.258788112550974
Epoch Time (s)               223.878667216748
Total Train Time (s)         15765.907869180199
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:59:28.670734 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #70 | Epoch Duration: 223.96260809898376
2020-01-13 03:59:28.670870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3467724
Z variance train             0.014160773
KL Divergence                31.097965
KL Loss                      3.1097965
QF Loss                      508.61124
VF Loss                      99.038956
Policy Loss                  -869.2666
Q Predictions Mean           857.90906
Q Predictions Std            838.8051
Q Predictions Max            2564.3342
Q Predictions Min            -132.35233
V Predictions Mean           873.9904
V Predictions Std            840.29205
V Predictions Max            2578.5896
V Predictions Min            -130.1423
Log Pis Mean                 -0.8830212
Log Pis Std                  3.660553
Log Pis Max                  13.926894
Log Pis Min                  -7.457249
Policy mu Mean               -0.025361678
Policy mu Std                0.8169325
Policy mu Max                3.153495
Policy mu Min                -3.4993956
Policy log std Mean          -0.47904643
Policy log std Std           0.22478168
Policy log std Max           -0.1540376
Policy log std Min           -1.9000876
Z mean eval                  2.3175232
Z variance eval              0.03364452
total_rewards                [6524.02243463 6317.74357721 6286.84223727 6356.82136701 6207.69696605
 6334.67978581 6366.01137728 6245.80068577 6227.4907569  6255.0870162 ]
total_rewards_mean           6312.219620412247
total_rewards_std            87.57959845212527
total_rewards_max            6524.022434628004
total_rewards_min            6207.696966050486
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               186.6636098367162
(Previous) Eval Time (s)     25.242909736
Sample Time (s)              5.9698840086348355
Epoch Time (s)               217.87640358135104
Total Train Time (s)         15983.872641241644
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:06.639021 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #71 | Epoch Duration: 217.96802878379822
2020-01-13 04:03:06.639245 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3148694
Z variance train             0.03360928
KL Divergence                29.314878
KL Loss                      2.9314878
QF Loss                      936.5145
VF Loss                      318.80933
Policy Loss                  -877.0834
Q Predictions Mean           862.963
Q Predictions Std            871.062
Q Predictions Max            2628.4817
Q Predictions Min            -127.735664
V Predictions Mean           871.24567
V Predictions Std            871.4121
V Predictions Max            2619.0913
V Predictions Min            -123.6258
Log Pis Mean                 -0.85039294
Log Pis Std                  4.1410136
Log Pis Max                  22.247116
Log Pis Min                  -7.4592257
Policy mu Mean               -0.04091577
Policy mu Std                0.825434
Policy mu Max                4.2792835
Policy mu Min                -3.6096597
Policy log std Mean          -0.48424622
Policy log std Std           0.25045267
Policy log std Max           -0.1302652
Policy log std Min           -2.2602856
Z mean eval                  2.3305237
Z variance eval              0.024451135
total_rewards                [6448.27104524 6477.03518544 6412.82985787 6431.69152085 6479.98192202
 6405.87592937 6489.12435416 6498.44912311 6840.68720324 6370.31804701]
total_rewards_mean           6485.426418830696
total_rewards_std            124.7437313800075
total_rewards_max            6840.6872032424235
total_rewards_min            6370.318047005435
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               188.00310559617355
(Previous) Eval Time (s)     24.562292706221342
Sample Time (s)              6.167634325101972
Epoch Time (s)               218.73303262749687
Total Train Time (s)         16202.685830384027
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:45.454256 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #72 | Epoch Duration: 218.8147747516632
2020-01-13 04:06:45.454565 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3302615
Z variance train             0.024387382
KL Divergence                30.045906
KL Loss                      3.0045907
QF Loss                      198.09451
VF Loss                      96.61368
Policy Loss                  -852.64374
Q Predictions Mean           842.7521
Q Predictions Std            851.6439
Q Predictions Max            2645.5398
Q Predictions Min            -138.99606
V Predictions Mean           846.91394
V Predictions Std            852.1459
V Predictions Max            2653.1511
V Predictions Min            -124.273605
Log Pis Mean                 -1.1481243
Log Pis Std                  3.2427814
Log Pis Max                  17.298122
Log Pis Min                  -8.752647
Policy mu Mean               -0.044123497
Policy mu Std                0.7618923
Policy mu Max                3.1236758
Policy mu Min                -2.4736793
Policy log std Mean          -0.47333083
Policy log std Std           0.24979326
Policy log std Max           -0.046910763
Policy log std Min           -2.2464192
Z mean eval                  2.3149173
Z variance eval              0.009175141
total_rewards                [6242.30623179 6390.35332659 6410.47346258 6464.46247534 6478.67157243
 6474.01302441 6646.48820927 6558.7655532  6458.83572876 6643.54156403]
total_rewards_mean           6476.791114837759
total_rewards_std            114.30702186360993
total_rewards_max            6646.48820926691
total_rewards_min            6242.30623178509
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               187.36251603392884
(Previous) Eval Time (s)     25.885234151035547
Sample Time (s)              6.223514537326992
Epoch Time (s)               219.47126472229138
Total Train Time (s)         16422.2424745257
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:10:25.015407 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #73 | Epoch Duration: 219.5606210231781
2020-01-13 04:10:25.015741 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3145413
Z variance train             0.009225064
KL Divergence                32.066635
KL Loss                      3.2066636
QF Loss                      195.84853
VF Loss                      61.973595
Policy Loss                  -803.36285
Q Predictions Mean           792.35913
Q Predictions Std            808.0722
Q Predictions Max            2569.9539
Q Predictions Min            -143.96129
V Predictions Mean           799.094
V Predictions Std            808.56024
V Predictions Max            2545.4214
V Predictions Min            -121.23529
Log Pis Mean                 -0.7989782
Log Pis Std                  3.3736653
Log Pis Max                  22.786783
Log Pis Min                  -5.7989244
Policy mu Mean               -0.024643742
Policy mu Std                0.7912162
Policy mu Max                3.2584932
Policy mu Min                -3.3031466
Policy log std Mean          -0.46805152
Policy log std Std           0.207691
Policy log std Max           -0.11826259
Policy log std Min           -2.1020055
Z mean eval                  2.3211906
Z variance eval              0.009191343
total_rewards                [6186.49627071 6195.66173632 6176.9572376  5978.60601148 6133.39366539
 6299.77961765 6261.58721831 6192.62315424 6062.46447119 6225.51737266]
total_rewards_mean           6171.308675556176
total_rewards_std            89.0631542881807
total_rewards_max            6299.779617653021
total_rewards_min            5978.606011482679
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               187.91640697000548
(Previous) Eval Time (s)     30.21908902609721
Sample Time (s)              6.177818384021521
Epoch Time (s)               224.3133143801242
Total Train Time (s)         16646.64289480215
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:14:09.415282 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #74 | Epoch Duration: 224.39929842948914
2020-01-13 04:14:09.415478 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.320126
Z variance train             0.009201612
KL Divergence                33.85476
KL Loss                      3.3854759
QF Loss                      344.01086
VF Loss                      108.347046
Policy Loss                  -834.32874
Q Predictions Mean           828.266
Q Predictions Std            865.65314
Q Predictions Max            2593.3071
Q Predictions Min            -175.36786
V Predictions Mean           835.8054
V Predictions Std            866.03564
V Predictions Max            2575.0327
V Predictions Min            -145.48077
Log Pis Mean                 -0.8439014
Log Pis Std                  3.7916675
Log Pis Max                  12.527181
Log Pis Min                  -7.657691
Policy mu Mean               -0.018107133
Policy mu Std                0.8224649
Policy mu Max                3.7209418
Policy mu Min                -2.672105
Policy log std Mean          -0.46968606
Policy log std Std           0.23877181
Policy log std Max           -0.10371685
Policy log std Min           -2.2833257
Z mean eval                  2.3068848
Z variance eval              0.017468853
total_rewards                [5899.01456406 5771.69370131 5838.62331901 5915.45834181 5993.76221538
 6057.27542938 6021.17454882 5917.2314199  5877.30179505 5962.78833455]
total_rewards_mean           5925.432366926352
total_rewards_std            81.83286142596664
total_rewards_max            6057.275429383566
total_rewards_min            5771.693701309531
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               186.54150621592999
(Previous) Eval Time (s)     29.66691958811134
Sample Time (s)              5.296154275536537
Epoch Time (s)               221.50458007957786
Total Train Time (s)         16868.232646904886
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:51.009514 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #75 | Epoch Duration: 221.59385561943054
2020-01-13 04:17:51.009837 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3083467
Z variance train             0.017477468
KL Divergence                33.040756
KL Loss                      3.3040757
QF Loss                      963.52625
VF Loss                      101.68433
Policy Loss                  -908.1293
Q Predictions Mean           902.04846
Q Predictions Std            858.151
Q Predictions Max            2657.494
Q Predictions Min            -129.98488
V Predictions Mean           905.6851
V Predictions Std            854.5807
V Predictions Max            2607.8938
V Predictions Min            -124.76458
Log Pis Mean                 -0.8649101
Log Pis Std                  3.6288497
Log Pis Max                  12.24091
Log Pis Min                  -7.780403
Policy mu Mean               -0.028320992
Policy mu Std                0.8144808
Policy mu Max                3.1976714
Policy mu Min                -2.6893885
Policy log std Mean          -0.48916575
Policy log std Std           0.24291867
Policy log std Max           -0.103580594
Policy log std Min           -1.9538101
Z mean eval                  2.2968848
Z variance eval              0.020519938
total_rewards                [6188.06331216 6285.75475257 5923.42142014 6335.43791203 6109.96600479
 6668.10987157 6245.30885446 6091.00432383 5959.42528998 5812.57340341]
total_rewards_mean           6161.906514496357
total_rewards_std            231.7252349854874
total_rewards_max            6668.109871569147
total_rewards_min            5812.573403412262
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               186.94992478191853
(Previous) Eval Time (s)     30.21073160227388
Sample Time (s)              6.179829629138112
Epoch Time (s)               223.34048601333052
Total Train Time (s)         17091.67013027752
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:34.447283 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #76 | Epoch Duration: 223.437171459198
2020-01-13 04:21:34.447538 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2980907
Z variance train             0.020675037
KL Divergence                31.863327
KL Loss                      3.1863327
QF Loss                      482.0022
VF Loss                      140.97357
Policy Loss                  -839.79913
Q Predictions Mean           834.33154
Q Predictions Std            862.9886
Q Predictions Max            2603.5344
Q Predictions Min            -139.32217
V Predictions Mean           834.5583
V Predictions Std            859.01605
V Predictions Max            2599.4316
V Predictions Min            -132.69312
Log Pis Mean                 -0.9648772
Log Pis Std                  3.3515282
Log Pis Max                  9.666773
Log Pis Min                  -7.123507
Policy mu Mean               -0.019650174
Policy mu Std                0.7890567
Policy mu Max                2.7198925
Policy mu Min                -2.3181617
Policy log std Mean          -0.47309998
Policy log std Std           0.23562622
Policy log std Max           -0.13621974
Policy log std Min           -1.9443295
Z mean eval                  2.3319159
Z variance eval              0.011418047
total_rewards                [6710.80642732 6474.47760675 6317.2546995  6453.68808377 6622.13918514
 6531.55734673 6639.5067453  5474.745193   6476.80350718 6433.98886427]
total_rewards_mean           6413.496765896212
total_rewards_std            331.2434498915697
total_rewards_max            6710.806427321111
total_rewards_min            5474.74519299642
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               187.61130295461044
(Previous) Eval Time (s)     29.69713157368824
Sample Time (s)              6.229361119214445
Epoch Time (s)               223.53779564751312
Total Train Time (s)         17315.303539927118
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:25:18.085038 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #77 | Epoch Duration: 223.63734889030457
2020-01-13 04:25:18.085234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3296292
Z variance train             0.011476527
KL Divergence                33.39257
KL Loss                      3.339257
QF Loss                      175.44933
VF Loss                      203.09462
Policy Loss                  -848.5214
Q Predictions Mean           846.088
Q Predictions Std            833.7375
Q Predictions Max            2603.375
Q Predictions Min            -146.42192
V Predictions Mean           859.0996
V Predictions Std            839.548
V Predictions Max            2623.292
V Predictions Min            -133.81804
Log Pis Mean                 -0.8667901
Log Pis Std                  3.3441424
Log Pis Max                  12.005741
Log Pis Min                  -6.1380553
Policy mu Mean               -0.019803248
Policy mu Std                0.7858943
Policy mu Max                2.5676227
Policy mu Min                -2.6285186
Policy log std Mean          -0.4860693
Policy log std Std           0.24165413
Policy log std Max           -0.07737237
Policy log std Min           -2.3280113
Z mean eval                  2.348563
Z variance eval              0.009749065
total_rewards                [6306.58761063 6244.77408861 6232.64026819 6336.2872617  3980.29828423
 6415.06518617 6428.48781995 2335.28353703 6116.32169391 6105.45766876]
total_rewards_mean           5650.12034192037
total_rewards_std            1303.3356411316217
total_rewards_max            6428.487819946768
total_rewards_min            2335.283537034675
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               187.753035150934
(Previous) Eval Time (s)     25.292109600268304
Sample Time (s)              6.153411553706974
Epoch Time (s)               219.1985563049093
Total Train Time (s)         17534.597525184043
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:28:57.379765 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #78 | Epoch Duration: 219.29438591003418
2020-01-13 04:28:57.379956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.348301
Z variance train             0.009758553
KL Divergence                35.11766
KL Loss                      3.5117662
QF Loss                      807.72314
VF Loss                      157.86668
Policy Loss                  -730.25977
Q Predictions Mean           726.294
Q Predictions Std            805.37854
Q Predictions Max            2599.7397
Q Predictions Min            -134.74936
V Predictions Mean           740.1377
V Predictions Std            810.1362
V Predictions Max            2610.8562
V Predictions Min            -149.75743
Log Pis Mean                 -1.189068
Log Pis Std                  3.339233
Log Pis Max                  15.4629
Log Pis Min                  -5.8122077
Policy mu Mean               -0.0026043227
Policy mu Std                0.758264
Policy mu Max                2.8484251
Policy mu Min                -3.2117941
Policy log std Mean          -0.47136632
Policy log std Std           0.23852056
Policy log std Max           -0.073294416
Policy log std Min           -2.2548232
Z mean eval                  2.3616357
Z variance eval              0.014461666
total_rewards                [6384.48947218 1570.86292111 6534.26320546 6430.08691265 6450.57675825
 6570.27495518 6606.48670029 6499.39096563 6258.16102486 6631.00958132]
total_rewards_mean           5993.560249692189
total_rewards_std            1478.0174301866882
total_rewards_max            6631.0095813208145
total_rewards_min            1570.8629211088385
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               183.07885195314884
(Previous) Eval Time (s)     31.542519560549408
Sample Time (s)              6.110026977956295
Epoch Time (s)               220.73139849165455
Total Train Time (s)         17755.422124903183
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:32:38.206105 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #79 | Epoch Duration: 220.82598233222961
2020-01-13 04:32:38.206312 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3615487
Z variance train             0.014446586
KL Divergence                34.247868
KL Loss                      3.4247868
QF Loss                      784.51685
VF Loss                      130.85277
Policy Loss                  -807.2466
Q Predictions Mean           801.0978
Q Predictions Std            847.08734
Q Predictions Max            2640.2656
Q Predictions Min            -148.8181
V Predictions Mean           800.96704
V Predictions Std            842.70715
V Predictions Max            2634.8174
V Predictions Min            -137.2716
Log Pis Mean                 -1.3312734
Log Pis Std                  3.1893349
Log Pis Max                  11.274904
Log Pis Min                  -6.368061
Policy mu Mean               -0.054482255
Policy mu Std                0.7466958
Policy mu Max                2.5705614
Policy mu Min                -2.5462592
Policy log std Mean          -0.46443033
Policy log std Std           0.23180914
Policy log std Max           -0.13742694
Policy log std Min           -2.3264027
Z mean eval                  2.3553576
Z variance eval              0.010489114
total_rewards                [6683.82125374 6558.58938088 6777.06037604 6518.69489052 6626.83915435
 6668.22502323 6638.79366212 6852.11990266 6621.75779362 6807.47333149]
total_rewards_mean           6675.337476863727
total_rewards_std            101.93495854834326
total_rewards_max            6852.119902660945
total_rewards_min            6518.694890516369
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               200.7156035369262
(Previous) Eval Time (s)     31.448364545125514
Sample Time (s)              10.477529996540397
Epoch Time (s)               242.64149807859212
Total Train Time (s)         17998.141931990627
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:36:40.927862 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #80 | Epoch Duration: 242.72133040428162
2020-01-13 04:36:40.928190 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3533509
Z variance train             0.010489372
KL Divergence                34.648552
KL Loss                      3.4648552
QF Loss                      222.77513
VF Loss                      91.09363
Policy Loss                  -872.0332
Q Predictions Mean           861.30237
Q Predictions Std            865.9509
Q Predictions Max            2707.5852
Q Predictions Min            242.95177
V Predictions Mean           865.2023
V Predictions Std            867.1558
V Predictions Max            2686.4365
V Predictions Min            247.08351
Log Pis Mean                 -0.852456
Log Pis Std                  3.572194
Log Pis Max                  19.207779
Log Pis Min                  -7.8121777
Policy mu Mean               -0.07282914
Policy mu Std                0.8185904
Policy mu Max                3.182598
Policy mu Min                -2.64822
Policy log std Mean          -0.4821354
Policy log std Std           0.25234863
Policy log std Max           -0.1267047
Policy log std Min           -2.3645098
Z mean eval                  2.3129559
Z variance eval              0.008772245
total_rewards                [6660.07538576 6458.67581128 6593.68945261 6777.61767034 6632.65331835
 6547.13777954 6449.47074699 6860.55734363 6787.58871481 6692.74675574]
total_rewards_mean           6646.0212979047255
total_rewards_std            131.22163122770328
total_rewards_max            6860.557343631944
total_rewards_min            6449.470746985328
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               198.4758815416135
(Previous) Eval Time (s)     31.971007734071463
Sample Time (s)              6.500837113242596
Epoch Time (s)               236.94772638892755
Total Train Time (s)         18235.17316064099
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:37.960060 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #81 | Epoch Duration: 237.03167486190796
2020-01-13 04:40:37.960263 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3112931
Z variance train             0.008735628
KL Divergence                33.106663
KL Loss                      3.3106663
QF Loss                      264.67438
VF Loss                      74.39027
Policy Loss                  -860.8088
Q Predictions Mean           852.5184
Q Predictions Std            880.76587
Q Predictions Max            2681.151
Q Predictions Min            -150.01291
V Predictions Mean           859.94836
V Predictions Std            880.5763
V Predictions Max            2669.7341
V Predictions Min            -137.3824
Log Pis Mean                 -0.97026896
Log Pis Std                  3.1730576
Log Pis Max                  8.960858
Log Pis Min                  -6.735859
Policy mu Mean               0.012121402
Policy mu Std                0.79164827
Policy mu Max                2.4792817
Policy mu Min                -2.6431954
Policy log std Mean          -0.47166857
Policy log std Std           0.21886879
Policy log std Max           -0.15527897
Policy log std Min           -2.2021158
Z mean eval                  2.3683963
Z variance eval              0.007167949
total_rewards                [6408.77287455 6711.35238334 6656.62264612 6629.96363267 6977.21829592
 6818.53487634 7019.80273653 6573.72468659 6453.67749179 6869.79675537]
total_rewards_mean           6711.946637921719
total_rewards_std            197.21233302379
total_rewards_max            7019.802736530285
total_rewards_min            6408.772874547014
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               202.84032157901675
(Previous) Eval Time (s)     34.791180999949574
Sample Time (s)              8.200882754754275
Epoch Time (s)               245.8323853337206
Total Train Time (s)         18481.099270169158
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:44:43.887885 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #82 | Epoch Duration: 245.92746138572693
2020-01-13 04:44:43.888104 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3733568
Z variance train             0.007215789
KL Divergence                34.62836
KL Loss                      3.462836
QF Loss                      413.83508
VF Loss                      133.93056
Policy Loss                  -876.4042
Q Predictions Mean           876.9203
Q Predictions Std            872.2022
Q Predictions Max            2705.126
Q Predictions Min            -143.8182
V Predictions Mean           882.55707
V Predictions Std            875.51733
V Predictions Max            2695.1335
V Predictions Min            -139.00107
Log Pis Mean                 -0.6754694
Log Pis Std                  3.457252
Log Pis Max                  16.337368
Log Pis Min                  -6.938815
Policy mu Mean               -0.07311972
Policy mu Std                0.80532825
Policy mu Max                2.7363665
Policy mu Min                -2.5974333
Policy log std Mean          -0.48919332
Policy log std Std           0.23858532
Policy log std Max           -0.1438463
Policy log std Min           -2.3101337
Z mean eval                  2.325477
Z variance eval              0.026475415
total_rewards                [6637.25738002 6445.44020475 6440.37496544 4225.4775035  6358.31955017
 6884.23957679 6385.219956   5376.0455547  6459.83464101 6863.81437163]
total_rewards_mean           6207.602370402561
total_rewards_std            769.5450579682009
total_rewards_max            6884.23957679107
total_rewards_min            4225.477503497674
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               201.73859556997195
(Previous) Eval Time (s)     30.79800917999819
Sample Time (s)              7.179852378554642
Epoch Time (s)               239.71645712852478
Total Train Time (s)         18720.939781317487
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:43.730609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #83 | Epoch Duration: 239.842355966568
2020-01-13 04:48:43.730802 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.323978
Z variance train             0.026389971
KL Divergence                32.406635
KL Loss                      3.2406635
QF Loss                      957.07007
VF Loss                      99.77453
Policy Loss                  -867.6194
Q Predictions Mean           859.123
Q Predictions Std            867.15924
Q Predictions Max            2628.4863
Q Predictions Min            -148.22925
V Predictions Mean           867.99536
V Predictions Std            867.9048
V Predictions Max            2600.4187
V Predictions Min            -130.83382
Log Pis Mean                 -0.6827365
Log Pis Std                  3.8744302
Log Pis Max                  18.959948
Log Pis Min                  -6.604789
Policy mu Mean               -0.041131925
Policy mu Std                0.8313554
Policy mu Max                3.7795773
Policy mu Min                -2.9963682
Policy log std Mean          -0.48615947
Policy log std Std           0.24695367
Policy log std Max           -0.0887599
Policy log std Min           -2.0311153
Z mean eval                  2.3550925
Z variance eval              0.012958184
total_rewards                [6330.55569254 6609.0994838  6758.95646679 6622.80402016 6523.40541328
 6487.92624996 6623.14951159 6393.2667346  6539.311564   6732.48413796]
total_rewards_mean           6562.095927468535
total_rewards_std            129.24394071012566
total_rewards_max            6758.956466793455
total_rewards_min            6330.555692537803
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               200.42171562090516
(Previous) Eval Time (s)     30.52643159357831
Sample Time (s)              6.649308313149959
Epoch Time (s)               237.59745552763343
Total Train Time (s)         18958.6211718102
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:41.413918 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #84 | Epoch Duration: 237.68296074867249
2020-01-13 04:52:41.414130 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3565927
Z variance train             0.012952313
KL Divergence                32.53212
KL Loss                      3.253212
QF Loss                      248.24298
VF Loss                      44.82451
Policy Loss                  -879.91473
Q Predictions Mean           871.31885
Q Predictions Std            885.0069
Q Predictions Max            2728.7
Q Predictions Min            -164.73035
V Predictions Mean           878.4268
V Predictions Std            884.81
V Predictions Max            2735.9822
V Predictions Min            -151.25217
Log Pis Mean                 -0.9814535
Log Pis Std                  3.0167892
Log Pis Max                  11.224752
Log Pis Min                  -5.881946
Policy mu Mean               -0.02297806
Policy mu Std                0.79430693
Policy mu Max                2.6219642
Policy mu Min                -2.9624581
Policy log std Mean          -0.48151124
Policy log std Std           0.22320172
Policy log std Max           -0.0546782
Policy log std Min           -1.8904176
Z mean eval                  2.3647544
Z variance eval              0.007866129
total_rewards                [6591.73118519 6534.91474443 6656.90251447 6587.52939043 6754.60645545
 6813.29762194 3458.38326632 3126.56598804 6656.66486275 6963.34317267]
total_rewards_mean           6014.393920169465
total_rewards_std            1368.1184453424505
total_rewards_max            6963.343172670856
total_rewards_min            3126.5659880375497
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               201.26589742908254
(Previous) Eval Time (s)     33.26621924014762
Sample Time (s)              7.222366330679506
Epoch Time (s)               241.75448299990967
Total Train Time (s)         19200.455833804794
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:56:43.250492 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #85 | Epoch Duration: 241.8361999988556
2020-01-13 04:56:43.250672 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364522
Z variance train             0.007862948
KL Divergence                34.28977
KL Loss                      3.4289768
QF Loss                      157.33578
VF Loss                      45.353703
Policy Loss                  -738.547
Q Predictions Mean           730.4009
Q Predictions Std            803.0427
Q Predictions Max            2755.332
Q Predictions Min            -159.36592
V Predictions Mean           734.46436
V Predictions Std            804.518
V Predictions Max            2732.5964
V Predictions Min            -131.85593
Log Pis Mean                 -1.0641458
Log Pis Std                  2.9348757
Log Pis Max                  9.501788
Log Pis Min                  -6.02244
Policy mu Mean               -0.04915452
Policy mu Std                0.7463765
Policy mu Max                2.8948781
Policy mu Min                -2.3147488
Policy log std Mean          -0.4658698
Policy log std Std           0.23472808
Policy log std Max           -0.14119044
Policy log std Min           -2.387084
Z mean eval                  2.369685
Z variance eval              0.01612093
total_rewards                [6872.34001238 6808.73475924 6777.72570365 6446.16685667 6443.50931445
 6820.93657636 6909.55146403 6542.42823566 6597.53817192 6833.51102567]
total_rewards_mean           6705.244212002415
total_rewards_std            170.05860291581405
total_rewards_max            6909.551464030929
total_rewards_min            6443.509314451054
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               204.18677414907143
(Previous) Eval Time (s)     35.66582896793261
Sample Time (s)              7.52831033943221
Epoch Time (s)               247.38091345643625
Total Train Time (s)         19447.941985568497
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:00:50.742133 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #86 | Epoch Duration: 247.49126839637756
2020-01-13 05:00:50.742392 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3674388
Z variance train             0.016162552
KL Divergence                33.257698
KL Loss                      3.32577
QF Loss                      192.98482
VF Loss                      76.59275
Policy Loss                  -837.46765
Q Predictions Mean           830.8843
Q Predictions Std            828.88654
Q Predictions Max            2635.635
Q Predictions Min            249.00005
V Predictions Mean           843.13574
V Predictions Std            833.1979
V Predictions Max            2643.9905
V Predictions Min            256.6544
Log Pis Mean                 -0.9327228
Log Pis Std                  3.0593798
Log Pis Max                  12.216226
Log Pis Min                  -6.8364344
Policy mu Mean               -0.06831687
Policy mu Std                0.7943538
Policy mu Max                2.4663858
Policy mu Min                -2.378608
Policy log std Mean          -0.47337136
Policy log std Std           0.22782686
Policy log std Max           -0.14141855
Policy log std Min           -1.9650924
Z mean eval                  2.3983932
Z variance eval              0.01679206
total_rewards                [6527.62890806 6627.92895534 6268.39843934 6323.91086977 4056.85797122
 6633.98269761 6365.35980408 6198.37017206  555.44864113 6413.38035617]
total_rewards_mean           5597.126681477943
total_rewards_std            1827.3251007505728
total_rewards_max            6633.98269760976
total_rewards_min            555.4486411292056
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               203.33887098310515
(Previous) Eval Time (s)     32.18195858504623
Sample Time (s)              6.752130837645382
Epoch Time (s)               242.27296040579677
Total Train Time (s)         19690.32599128317
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:53.126560 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #87 | Epoch Duration: 242.38400173187256
2020-01-13 05:04:53.126739 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3955243
Z variance train             0.016769053
KL Divergence                33.066353
KL Loss                      3.3066354
QF Loss                      1173.8623
VF Loss                      44.677395
Policy Loss                  -771.57983
Q Predictions Mean           761.8165
Q Predictions Std            817.64526
Q Predictions Max            2673.1672
Q Predictions Min            -119.01561
V Predictions Mean           771.713
V Predictions Std            821.5773
V Predictions Max            2662.3608
V Predictions Min            -140.55602
Log Pis Mean                 -0.72785366
Log Pis Std                  3.6718338
Log Pis Max                  14.633949
Log Pis Min                  -6.786699
Policy mu Mean               -0.014661147
Policy mu Std                0.8228223
Policy mu Max                2.7830482
Policy mu Min                -2.814448
Policy log std Mean          -0.4764392
Policy log std Std           0.22012262
Policy log std Max           -0.1580219
Policy log std Min           -1.7998827
Z mean eval                  2.3470118
Z variance eval              0.010960404
total_rewards                [6659.00258243 6767.44856753 6829.53756904 6613.68914239 6729.50436765
 6542.06789578 6788.57848763 6691.16782189 6757.50168085 6772.84627615]
total_rewards_mean           6715.134439133855
total_rewards_std            83.97581038999745
total_rewards_max            6829.537569037407
total_rewards_min            6542.067895783752
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               204.95688334992155
(Previous) Eval Time (s)     31.86853663995862
Sample Time (s)              8.00919144321233
Epoch Time (s)               244.8346114330925
Total Train Time (s)         19935.240214903373
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:08:58.042792 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #88 | Epoch Duration: 244.9158365726471
2020-01-13 05:08:58.043103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3494518
Z variance train             0.010983435
KL Divergence                33.58957
KL Loss                      3.358957
QF Loss                      166.32773
VF Loss                      63.965916
Policy Loss                  -904.52014
Q Predictions Mean           896.8652
Q Predictions Std            924.4244
Q Predictions Max            2792.0918
Q Predictions Min            -140.49463
V Predictions Mean           903.1787
V Predictions Std            923.6712
V Predictions Max            2784.2585
V Predictions Min            -134.0725
Log Pis Mean                 -0.73609143
Log Pis Std                  3.742187
Log Pis Max                  19.662498
Log Pis Min                  -9.020263
Policy mu Mean               -0.055629443
Policy mu Std                0.81691116
Policy mu Max                3.6645586
Policy mu Min                -2.9501295
Policy log std Mean          -0.51087874
Policy log std Std           0.23968273
Policy log std Max           -0.18596146
Policy log std Min           -2.2585382
Z mean eval                  2.3671784
Z variance eval              0.012610148
total_rewards                [6967.73384505 6902.47905046 6707.6785338  6921.55607106 6773.50179045
 6797.32671373 6846.98339838 7092.96854547 6641.11798708 6957.00962872]
total_rewards_mean           6860.835556420806
total_rewards_std            127.89406097006798
total_rewards_max            7092.968545473493
total_rewards_min            6641.117987078796
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               204.02642784407362
(Previous) Eval Time (s)     31.700698437169194
Sample Time (s)              7.57142372475937
Epoch Time (s)               243.2985500060022
Total Train Time (s)         20178.641228915658
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:01.444812 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #89 | Epoch Duration: 243.40151405334473
2020-01-13 05:13:01.445013 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3719134
Z variance train             0.012652022
KL Divergence                33.730976
KL Loss                      3.3730977
QF Loss                      283.6479
VF Loss                      67.50827
Policy Loss                  -893.6465
Q Predictions Mean           882.963
Q Predictions Std            899.2093
Q Predictions Max            2753.6284
Q Predictions Min            -148.53154
V Predictions Mean           895.057
V Predictions Std            902.5732
V Predictions Max            2745.4524
V Predictions Min            -130.8657
Log Pis Mean                 -0.8655071
Log Pis Std                  3.360842
Log Pis Max                  13.683126
Log Pis Min                  -7.3961773
Policy mu Mean               -0.023482338
Policy mu Std                0.8128081
Policy mu Max                2.459829
Policy mu Min                -3.1158624
Policy log std Mean          -0.4921647
Policy log std Std           0.23718745
Policy log std Max           -0.11847465
Policy log std Min           -2.168447
Z mean eval                  2.379026
Z variance eval              0.028692905
total_rewards                [6737.03481152 6727.22169904 6933.07759547 6755.74680936 6797.55036269
 6784.25243511 6930.79896822 6839.77449676 6959.37442434 6818.0321296 ]
total_rewards_mean           6828.286373210246
total_rewards_std            80.99248748181842
total_rewards_max            6959.374424335007
total_rewards_min            6727.2216990447705
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               205.04304860392585
(Previous) Eval Time (s)     32.42285351967439
Sample Time (s)              7.234269161242992
Epoch Time (s)               244.70017128484324
Total Train Time (s)         20423.426514148246
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:17:06.235428 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #90 | Epoch Duration: 244.79022240638733
2020-01-13 05:17:06.235760 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.375523
Z variance train             0.0283718
KL Divergence                33.548077
KL Loss                      3.3548076
QF Loss                      1069.4583
VF Loss                      60.05433
Policy Loss                  -768.0455
Q Predictions Mean           761.3895
Q Predictions Std            821.34265
Q Predictions Max            2724.1853
Q Predictions Min            263.85696
V Predictions Mean           764.4943
V Predictions Std            826.7352
V Predictions Max            2724.7217
V Predictions Min            270.6095
Log Pis Mean                 -0.9534801
Log Pis Std                  3.549314
Log Pis Max                  19.618587
Log Pis Min                  -8.283438
Policy mu Mean               -0.02622895
Policy mu Std                0.7850082
Policy mu Max                3.2724805
Policy mu Min                -2.8410215
Policy log std Mean          -0.46793976
Policy log std Std           0.2320136
Policy log std Max           -0.124568224
Policy log std Min           -2.0670805
Z mean eval                  2.4350648
Z variance eval              0.012663426
total_rewards                [6695.92542089 6586.60080677 6592.21114096 6562.35608694 6740.77280512
 6538.03715136 6502.73545595 6743.35315907 6579.02061923 6637.10407895]
total_rewards_mean           6617.8116725253185
total_rewards_std            79.4796468261482
total_rewards_max            6743.353159074975
total_rewards_min            6502.735455954529
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               203.8174838279374
(Previous) Eval Time (s)     33.026006660889834
Sample Time (s)              6.473623080179095
Epoch Time (s)               243.31711356900632
Total Train Time (s)         20666.83382451441
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:09.643956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #91 | Epoch Duration: 243.40793871879578
2020-01-13 05:21:09.644199 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4320912
Z variance train             0.012693768
KL Divergence                35.19599
KL Loss                      3.5195992
QF Loss                      1782.2726
VF Loss                      187.0058
Policy Loss                  -763.8334
Q Predictions Mean           762.9214
Q Predictions Std            851.99927
Q Predictions Max            2844.0142
Q Predictions Min            -143.3552
V Predictions Mean           774.1498
V Predictions Std            852.87103
V Predictions Max            2847.286
V Predictions Min            -132.64839
Log Pis Mean                 -1.1840848
Log Pis Std                  3.3436208
Log Pis Max                  20.167492
Log Pis Min                  -6.610156
Policy mu Mean               0.003100127
Policy mu Std                0.7819725
Policy mu Max                3.7193415
Policy mu Min                -3.3758895
Policy log std Mean          -0.49204603
Policy log std Std           0.22426318
Policy log std Max           -0.060394466
Policy log std Min           -2.1047611
Z mean eval                  2.3857055
Z variance eval              0.0069057085
total_rewards                [5724.93571092 6198.62941066 6533.98442417 6644.25296423 6092.29519716
 6274.25497179 5388.71184675 6436.59859918 2235.66962894 6270.26154976]
total_rewards_mean           5779.959430355756
total_rewards_std            1233.7903757956553
total_rewards_max            6644.252964227555
total_rewards_min            2235.669628935201
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               206.42531239287928
(Previous) Eval Time (s)     31.03212659107521
Sample Time (s)              6.4456794881261885
Epoch Time (s)               243.90311847208068
Total Train Time (s)         20910.814759533852
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:25:13.624957 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #92 | Epoch Duration: 243.9805874824524
2020-01-13 05:25:13.625098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.384962
Z variance train             0.006913723
KL Divergence                36.57022
KL Loss                      3.6570222
QF Loss                      249.95111
VF Loss                      149.4236
Policy Loss                  -844.3343
Q Predictions Mean           835.97156
Q Predictions Std            874.56067
Q Predictions Max            2781.3718
Q Predictions Min            -192.96011
V Predictions Mean           836.07056
V Predictions Std            873.6846
V Predictions Max            2754.295
V Predictions Min            -136.9001
Log Pis Mean                 -0.62106097
Log Pis Std                  3.2670605
Log Pis Max                  14.598035
Log Pis Min                  -7.7227087
Policy mu Mean               -0.02442577
Policy mu Std                0.8219035
Policy mu Max                2.5885
Policy mu Min                -2.6800516
Policy log std Mean          -0.49260005
Policy log std Std           0.22274731
Policy log std Max           -0.09149191
Policy log std Min           -1.8265103
Z mean eval                  2.361319
Z variance eval              0.009872237
total_rewards                [6586.91751415 6719.39676132 6679.82144815 6535.52583252 6584.78310521
 6848.07994857 6571.64299125 6207.45879256 6495.34568877 6661.79671871]
total_rewards_mean           6589.076880120059
total_rewards_std            159.75020124648245
total_rewards_max            6848.079948571606
total_rewards_min            6207.458792560799
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               202.64757318189368
(Previous) Eval Time (s)     34.254506001248956
Sample Time (s)              5.968918161001056
Epoch Time (s)               242.8709973441437
Total Train Time (s)         21153.772460835055
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:16.585162 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #93 | Epoch Duration: 242.95989966392517
2020-01-13 05:29:16.585406 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3580136
Z variance train             0.009899354
KL Divergence                35.389717
KL Loss                      3.5389717
QF Loss                      203.95111
VF Loss                      180.65181
Policy Loss                  -843.6977
Q Predictions Mean           841.18164
Q Predictions Std            884.3919
Q Predictions Max            2784.806
Q Predictions Min            270.3841
V Predictions Mean           851.0521
V Predictions Std            888.96686
V Predictions Max            2801.8635
V Predictions Min            282.26086
Log Pis Mean                 -0.8371486
Log Pis Std                  3.3231714
Log Pis Max                  13.317524
Log Pis Min                  -8.236119
Policy mu Mean               -0.009895221
Policy mu Std                0.7852466
Policy mu Max                2.439017
Policy mu Min                -2.6961455
Policy log std Mean          -0.49742606
Policy log std Std           0.24760167
Policy log std Max           -0.15302593
Policy log std Min           -2.282616
Z mean eval                  2.425017
Z variance eval              0.028974097
total_rewards                [6511.01279148 6656.31097701 6601.13743337 6558.97998629 6530.66951669
 6212.25852402 6693.49966666 6358.65300993 6660.57956592 6619.99164065]
total_rewards_mean           6540.309311202722
total_rewards_std            142.60227077178854
total_rewards_max            6693.499666659604
total_rewards_min            6212.2585240223925
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               202.388077233918
(Previous) Eval Time (s)     31.941479715984315
Sample Time (s)              8.397796029690653
Epoch Time (s)               242.72735297959298
Total Train Time (s)         21396.58412717143
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:33:19.399069 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #94 | Epoch Duration: 242.81353116035461
2020-01-13 05:33:19.399244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4230518
Z variance train             0.02888174
KL Divergence                31.789898
KL Loss                      3.17899
QF Loss                      274.36823
VF Loss                      43.048424
Policy Loss                  -795.6621
Q Predictions Mean           791.60974
Q Predictions Std            832.17365
Q Predictions Max            2723.8047
Q Predictions Min            276.78894
V Predictions Mean           794.0979
V Predictions Std            836.74084
V Predictions Max            2724.9705
V Predictions Min            279.1059
Log Pis Mean                 -0.62367713
Log Pis Std                  3.639028
Log Pis Max                  12.342768
Log Pis Min                  -9.304031
Policy mu Mean               0.022327498
Policy mu Std                0.8315546
Policy mu Max                2.7438254
Policy mu Min                -2.54195
Policy log std Mean          -0.48986495
Policy log std Std           0.22263567
Policy log std Max           -0.15073748
Policy log std Min           -2.2165322
Z mean eval                  2.3665853
Z variance eval              0.026343197
total_rewards                [6874.55363979 6802.67713437 6698.22953567 6892.11307323 6834.64585916
 6912.90630302 6848.50283901 6587.94753985 6745.60809541 6835.53375652]
total_rewards_mean           6803.271777602774
total_rewards_std            94.75678331324427
total_rewards_max            6912.906303016389
total_rewards_min            6587.9475398526465
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               201.35341135086492
(Previous) Eval Time (s)     32.141588957980275
Sample Time (s)              6.780369719490409
Epoch Time (s)               240.2753700283356
Total Train Time (s)         21636.951351107098
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:19.768284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #95 | Epoch Duration: 240.36890959739685
2020-01-13 05:37:19.768450 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3662536
Z variance train             0.02638262
KL Divergence                31.602198
KL Loss                      3.16022
QF Loss                      240.80794
VF Loss                      81.27557
Policy Loss                  -836.8326
Q Predictions Mean           831.5445
Q Predictions Std            885.1375
Q Predictions Max            2817.8728
Q Predictions Min            280.044
V Predictions Mean           836.06165
V Predictions Std            887.4904
V Predictions Max            2827.5413
V Predictions Min            275.66803
Log Pis Mean                 -0.6739047
Log Pis Std                  3.4296062
Log Pis Max                  15.225002
Log Pis Min                  -6.939065
Policy mu Mean               -0.0004470572
Policy mu Std                0.818613
Policy mu Max                2.6885583
Policy mu Min                -3.3772502
Policy log std Mean          -0.48697332
Policy log std Std           0.2446726
Policy log std Max           -0.07919744
Policy log std Min           -2.3412964
Z mean eval                  2.3628273
Z variance eval              0.041732103
total_rewards                [6798.11291202 6524.53044405 6690.65362546 6766.3342921  6929.58979018
 6799.47830762 6686.64201742 6827.01569123 6655.28907364 6680.55270054]
total_rewards_mean           6735.819885425686
total_rewards_std            106.47476275032028
total_rewards_max            6929.589790178311
total_rewards_min            6524.530444047049
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               203.15459493082017
(Previous) Eval Time (s)     31.63638826692477
Sample Time (s)              6.672255116514862
Epoch Time (s)               241.4632383142598
Total Train Time (s)         21878.507663437165
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:21.326485 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #96 | Epoch Duration: 241.55788826942444
2020-01-13 05:41:21.326694 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.363662
Z variance train             0.041621502
KL Divergence                30.498762
KL Loss                      3.0498762
QF Loss                      247.2196
VF Loss                      163.76462
Policy Loss                  -848.5394
Q Predictions Mean           850.4668
Q Predictions Std            921.7949
Q Predictions Max            2906.6287
Q Predictions Min            -148.27243
V Predictions Mean           853.01086
V Predictions Std            921.60876
V Predictions Max            2893.912
V Predictions Min            -147.77628
Log Pis Mean                 -0.8794662
Log Pis Std                  3.4390848
Log Pis Max                  13.941726
Log Pis Min                  -7.0264487
Policy mu Mean               0.02647891
Policy mu Std                0.8106562
Policy mu Max                2.7293775
Policy mu Min                -2.568254
Policy log std Mean          -0.49286905
Policy log std Std           0.24602859
Policy log std Max           -0.13581958
Policy log std Min           -2.220014
Z mean eval                  2.3832974
Z variance eval              0.024201635
total_rewards                [6841.28361745 6473.51916317 6464.88438056 6385.9075101  6920.75372322
 6943.81582821 6675.59100055 6284.20082613 6584.648418   6796.61256388]
total_rewards_mean           6637.121703127897
total_rewards_std            221.3491283408484
total_rewards_max            6943.815828213668
total_rewards_min            6284.200826131823
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               203.97605715040118
(Previous) Eval Time (s)     31.942157605662942
Sample Time (s)              7.34215563070029
Epoch Time (s)               243.2603703867644
Total Train Time (s)         22121.852327222936
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:45:24.677320 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #97 | Epoch Duration: 243.35043501853943
2020-01-13 05:45:24.677647 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3844173
Z variance train             0.024086837
KL Divergence                32.27231
KL Loss                      3.2272308
QF Loss                      443.00397
VF Loss                      47.76012
Policy Loss                  -737.3822
Q Predictions Mean           737.4891
Q Predictions Std            839.9886
Q Predictions Max            2822.2273
Q Predictions Min            -175.37024
V Predictions Mean           739.8911
V Predictions Std            841.0503
V Predictions Max            2824.6265
V Predictions Min            -159.17097
Log Pis Mean                 -1.1216062
Log Pis Std                  3.0678582
Log Pis Max                  14.840046
Log Pis Min                  -5.808484
Policy mu Mean               -0.045261934
Policy mu Std                0.75181454
Policy mu Max                2.2229536
Policy mu Min                -3.2123919
Policy log std Mean          -0.48743138
Policy log std Std           0.2209498
Policy log std Max           -0.15445682
Policy log std Min           -2.3627424
Z mean eval                  2.4132202
Z variance eval              0.018739639
total_rewards                [3705.19431348 4248.69864727 6688.77268075 6829.4518855  6428.98414818
 6167.62468464 6545.27204214 6508.0492702  6472.74719017 6569.89510438]
total_rewards_mean           6016.468996670485
total_rewards_std            1039.6493137383684
total_rewards_max            6829.4518855003425
total_rewards_min            3705.1943134782605
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               206.71996050467715
(Previous) Eval Time (s)     29.885251682251692
Sample Time (s)              6.587447431404144
Epoch Time (s)               243.19265961833298
Total Train Time (s)         22365.13003765326
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:27.953745 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #98 | Epoch Duration: 243.2758469581604
2020-01-13 05:49:27.953936 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4137986
Z variance train             0.018699652
KL Divergence                33.972275
KL Loss                      3.3972275
QF Loss                      1203.5117
VF Loss                      112.80144
Policy Loss                  -802.4972
Q Predictions Mean           798.7526
Q Predictions Std            855.7807
Q Predictions Max            2855.9236
Q Predictions Min            277.47134
V Predictions Mean           806.28674
V Predictions Std            857.1411
V Predictions Max            2862.6772
V Predictions Min            284.45938
Log Pis Mean                 -0.98594284
Log Pis Std                  3.3361793
Log Pis Max                  14.653837
Log Pis Min                  -5.828022
Policy mu Mean               0.0046478533
Policy mu Std                0.8108913
Policy mu Max                3.270932
Policy mu Min                -2.8124857
Policy log std Mean          -0.48263136
Policy log std Std           0.23311946
Policy log std Max           -0.14046508
Policy log std Min           -2.0177977
Z mean eval                  2.389764
Z variance eval              0.0115949465
total_rewards                [6560.13498455 6471.35487187 6718.89096056 6582.54605146 6883.11690237
 6643.48231123 6825.96262733 6594.74056097 6539.73473651 6423.50182213]
total_rewards_mean           6624.346582897089
total_rewards_std            139.48731107322786
total_rewards_max            6883.116902372615
total_rewards_min            6423.501822129562
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               204.5148045560345
(Previous) Eval Time (s)     31.344727660994977
Sample Time (s)              6.3814738327637315
Epoch Time (s)               242.2410060497932
Total Train Time (s)         22607.457964670844
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:30.284590 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #99 | Epoch Duration: 242.33049964904785
2020-01-13 05:53:30.284799 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.387817
Z variance train             0.011644918
KL Divergence                35.019302
KL Loss                      3.5019302
QF Loss                      351.14816
VF Loss                      118.258705
Policy Loss                  -797.3743
Q Predictions Mean           791.1144
Q Predictions Std            874.5187
Q Predictions Max            2839.2654
Q Predictions Min            -180.9697
V Predictions Mean           794.49457
V Predictions Std            874.5572
V Predictions Max            2824.479
V Predictions Min            -161.7268
Log Pis Mean                 -0.7183402
Log Pis Std                  3.6747825
Log Pis Max                  20.970806
Log Pis Min                  -6.704914
Policy mu Mean               -0.0024137888
Policy mu Std                0.82477295
Policy mu Max                3.2898653
Policy mu Min                -3.7733629
Policy log std Mean          -0.48549235
Policy log std Std           0.2436331
Policy log std Max           -0.014108419
Policy log std Min           -2.3379164
Z mean eval                  2.3863149
Z variance eval              0.01161121
total_rewards                [6901.64113113 6933.75361306 6870.49556031 6827.23125272 6667.98149373
 7070.15209861 6925.40101306 7083.91541612 6896.19596109 6952.85406898]
total_rewards_mean           6912.962160880161
total_rewards_std            112.11158061712008
total_rewards_max            7083.915416117974
total_rewards_min            6667.981493727656
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               201.35358797432855
(Previous) Eval Time (s)     33.81339654605836
Sample Time (s)              10.474116881377995
Epoch Time (s)               245.6411014017649
Total Train Time (s)         22853.18851219397
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:57:36.016395 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #100 | Epoch Duration: 245.73143219947815
2020-01-13 05:57:36.016576 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.388354
Z variance train             0.011595137
KL Divergence                35.418995
KL Loss                      3.5418994
QF Loss                      179.11923
VF Loss                      40.055264
Policy Loss                  -753.4954
Q Predictions Mean           753.0633
Q Predictions Std            860.145
Q Predictions Max            2884.3105
Q Predictions Min            -146.24277
V Predictions Mean           756.219
V Predictions Std            861.5544
V Predictions Max            2899.2278
V Predictions Min            -169.83629
Log Pis Mean                 -0.923892
Log Pis Std                  3.0548482
Log Pis Max                  10.833756
Log Pis Min                  -7.2876415
Policy mu Mean               -0.060387403
Policy mu Std                0.791221
Policy mu Max                2.842186
Policy mu Min                -2.8637357
Policy log std Mean          -0.48383474
Policy log std Std           0.20363136
Policy log std Max           -0.10869944
Policy log std Min           -2.0265505
Z mean eval                  2.3922436
Z variance eval              0.030791009
total_rewards                [6759.97782609 6905.63504083 6441.41733696 7070.74883323 6422.56436922
 6841.38400977 6045.71087197 6622.08279239 6532.33317264 6428.71499029]
total_rewards_mean           6607.056924341379
total_rewards_std            282.25018878878006
total_rewards_max            7070.748833234144
total_rewards_min            6045.710871971817
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               196.44738067081198
(Previous) Eval Time (s)     32.26851587416604
Sample Time (s)              7.951601675245911
Epoch Time (s)               236.66749822022393
Total Train Time (s)         23089.94290129654
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:32.772611 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #101 | Epoch Duration: 236.75583267211914
2020-01-13 06:01:32.772799 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3932629
Z variance train             0.03068992
KL Divergence                35.4974
KL Loss                      3.5497398
QF Loss                      106.31552
VF Loss                      89.892654
Policy Loss                  -794.31433
Q Predictions Mean           787.8451
Q Predictions Std            883.59247
Q Predictions Max            2945.4492
Q Predictions Min            306.38617
V Predictions Mean           790.1347
V Predictions Std            883.17316
V Predictions Max            2933.873
V Predictions Min            310.1211
Log Pis Mean                 -0.8460406
Log Pis Std                  3.3387902
Log Pis Max                  12.110802
Log Pis Min                  -6.9130297
Policy mu Mean               0.008616771
Policy mu Std                0.7991277
Policy mu Max                2.4644036
Policy mu Min                -2.661543
Policy log std Mean          -0.48690844
Policy log std Std           0.2277359
Policy log std Max           -0.1153692
Policy log std Min           -2.1493495
Z mean eval                  2.414444
Z variance eval              0.011531283
total_rewards                [7070.2713204  7216.40399785 7004.68165565 7067.8990637  7312.78870075
 7112.24850029 6898.96994815 7058.97120573 6778.9809096  6982.33241248]
total_rewards_mean           7050.354771461369
total_rewards_std            142.94323104271294
total_rewards_max            7312.78870075349
total_rewards_min            6778.980909596796
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               192.16465406306088
(Previous) Eval Time (s)     33.888792499899864
Sample Time (s)              7.294973976910114
Epoch Time (s)               233.34842053987086
Total Train Time (s)         23323.372631798964
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:05:26.204718 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #102 | Epoch Duration: 233.4317820072174
2020-01-13 06:05:26.204884 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.418464
Z variance train             0.011551134
KL Divergence                36.36499
KL Loss                      3.6364992
QF Loss                      105.68399
VF Loss                      126.23605
Policy Loss                  -715.61505
Q Predictions Mean           712.05756
Q Predictions Std            817.0381
Q Predictions Max            2971.6345
Q Predictions Min            -184.13545
V Predictions Mean           708.8699
V Predictions Std            813.79047
V Predictions Max            2950.038
V Predictions Min            -183.51294
Log Pis Mean                 -1.3684905
Log Pis Std                  2.7545745
Log Pis Max                  8.540494
Log Pis Min                  -6.638674
Policy mu Mean               0.02443637
Policy mu Std                0.7228085
Policy mu Max                2.7999775
Policy mu Min                -2.0711179
Policy log std Mean          -0.47181022
Policy log std Std           0.22088917
Policy log std Max           -0.033525348
Policy log std Min           -2.090894
Z mean eval                  2.378338
Z variance eval              0.013070807
total_rewards                [7051.96271376 6873.65602867 6987.73987131 7027.10622137 7036.4218181
 6919.19002065 6811.82497712 6805.88571266 6968.77685787 6455.33905402]
total_rewards_mean           6893.790327552563
total_rewards_std            168.91431660831591
total_rewards_max            7051.962713757463
total_rewards_min            6455.3390540210585
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               190.02535403333604
(Previous) Eval Time (s)     33.95617962675169
Sample Time (s)              7.7773574171587825
Epoch Time (s)               231.75889107724652
Total Train Time (s)         23555.20930683613
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:09:18.041714 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #103 | Epoch Duration: 231.8367063999176
2020-01-13 06:09:18.041835 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3784494
Z variance train             0.01309256
KL Divergence                35.71952
KL Loss                      3.571952
QF Loss                      868.44836
VF Loss                      76.86656
Policy Loss                  -805.3964
Q Predictions Mean           801.4947
Q Predictions Std            890.4968
Q Predictions Max            2958.115
Q Predictions Min            306.38977
V Predictions Mean           807.2226
V Predictions Std            893.38104
V Predictions Max            2938.694
V Predictions Min            309.61658
Log Pis Mean                 -0.8566755
Log Pis Std                  3.225834
Log Pis Max                  11.947108
Log Pis Min                  -7.188681
Policy mu Mean               -0.04219689
Policy mu Std                0.80588883
Policy mu Max                3.3510723
Policy mu Min                -2.8099263
Policy log std Mean          -0.49232808
Policy log std Std           0.23690887
Policy log std Max           -0.13239133
Policy log std Min           -2.1525943
Z mean eval                  2.358934
Z variance eval              0.020671627
total_rewards                [7273.29633519 7454.33154305 7262.59374868 7367.45800395 7257.90584434
 7354.36216906 6940.2548896  7223.68686797 7039.46163959 7367.80148475]
total_rewards_mean           7254.115252618132
total_rewards_std            148.95358368610513
total_rewards_max            7454.331543051222
total_rewards_min            6940.254889599223
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               191.72671205783263
(Previous) Eval Time (s)     32.700087409000844
Sample Time (s)              7.198141371365637
Epoch Time (s)               231.6249408381991
Total Train Time (s)         23786.914208399132
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:09.748223 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #104 | Epoch Duration: 231.70628356933594
2020-01-13 06:13:09.748386 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.361504
Z variance train             0.020725274
KL Divergence                33.161633
KL Loss                      3.3161633
QF Loss                      221.46973
VF Loss                      87.74388
Policy Loss                  -796.5973
Q Predictions Mean           792.97485
Q Predictions Std            864.8543
Q Predictions Max            2903.9338
Q Predictions Min            161.41087
V Predictions Mean           794.5958
V Predictions Std            861.46747
V Predictions Max            2904.4016
V Predictions Min            269.36768
Log Pis Mean                 -0.9323631
Log Pis Std                  3.1601436
Log Pis Max                  11.047701
Log Pis Min                  -7.504847
Policy mu Mean               -0.032931443
Policy mu Std                0.817764
Policy mu Max                2.7110815
Policy mu Min                -2.7429137
Policy log std Mean          -0.48864472
Policy log std Std           0.23489806
Policy log std Max           -0.14632381
Policy log std Min           -2.2949617
Z mean eval                  2.3826942
Z variance eval              0.015521385
total_rewards                [7182.34823347 7320.99949192 7265.35790874 7297.81669905 7029.46871988
 7380.97958039 7536.12114104 7141.0462106  6992.74761527 7211.23226329]
total_rewards_mean           7235.8117863654825
total_rewards_std            154.05667651771483
total_rewards_max            7536.121141041676
total_rewards_min            6992.747615273648
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               189.67490923590958
(Previous) Eval Time (s)     35.32636819873005
Sample Time (s)              8.886279276106507
Epoch Time (s)               233.88755671074614
Total Train Time (s)         24020.895813302603
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:17:03.734439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #105 | Epoch Duration: 233.98592019081116
2020-01-13 06:17:03.734609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3815804
Z variance train             0.015637513
KL Divergence                32.754326
KL Loss                      3.2754326
QF Loss                      132.00208
VF Loss                      76.55717
Policy Loss                  -707.21277
Q Predictions Mean           702.3894
Q Predictions Std            785.5563
Q Predictions Max            2931.8928
Q Predictions Min            312.79013
V Predictions Mean           700.52747
V Predictions Std            783.1085
V Predictions Max            2921.6143
V Predictions Min            316.78177
Log Pis Mean                 -0.6584857
Log Pis Std                  3.2991357
Log Pis Max                  18.47282
Log Pis Min                  -7.6448145
Policy mu Mean               -0.026562853
Policy mu Std                0.82893264
Policy mu Max                3.341986
Policy mu Min                -3.5332196
Policy log std Mean          -0.4846878
Policy log std Std           0.21796627
Policy log std Max           -0.13645774
Policy log std Min           -1.9300215
Z mean eval                  2.3694859
Z variance eval              0.017617473
total_rewards                [7034.38937559 6906.82559093 7031.77284158 7057.47705346 6995.67698588
 6706.24943007 7104.09594208 6640.4688662  7241.81472091 6990.40256166]
total_rewards_mean           6970.91733683685
total_rewards_std            170.49702901076452
total_rewards_max            7241.814720911
total_rewards_min            6640.4688661956325
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               191.13372090877965
(Previous) Eval Time (s)     32.508604214992374
Sample Time (s)              7.621427648235112
Epoch Time (s)               231.26375277200714
Total Train Time (s)         24252.245819556993
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:20:55.084539 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #106 | Epoch Duration: 231.34979438781738
2020-01-13 06:20:55.084724 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.370705
Z variance train             0.017603427
KL Divergence                32.534077
KL Loss                      3.2534077
QF Loss                      1331.4939
VF Loss                      201.6685
Policy Loss                  -771.21857
Q Predictions Mean           766.5398
Q Predictions Std            854.3406
Q Predictions Max            3037.5989
Q Predictions Min            290.53415
V Predictions Mean           769.949
V Predictions Std            851.935
V Predictions Max            3011.3418
V Predictions Min            300.00723
Log Pis Mean                 -0.87039155
Log Pis Std                  3.535173
Log Pis Max                  17.080967
Log Pis Min                  -6.906127
Policy mu Mean               -0.03617994
Policy mu Std                0.7898009
Policy mu Max                4.5647993
Policy mu Min                -3.4456816
Policy log std Mean          -0.48417893
Policy log std Std           0.22091027
Policy log std Max           -0.039164364
Policy log std Min           -1.9312203
Z mean eval                  2.3540754
Z variance eval              0.018892206
total_rewards                [6889.47387523 6711.81750841 6781.31321618 7083.3560212  7025.57596806
 7248.3238509  6909.95380295 7023.45959058 7182.75623854 6899.20689314]
total_rewards_mean           6975.523696518307
total_rewards_std            160.80517474983446
total_rewards_max            7248.323850897556
total_rewards_min            6711.817508407623
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               191.20607724273577
(Previous) Eval Time (s)     32.01565364887938
Sample Time (s)              6.622633465565741
Epoch Time (s)               229.8443643571809
Total Train Time (s)         24482.175286583602
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:45.016793 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #107 | Epoch Duration: 229.93186259269714
2020-01-13 06:24:45.017081 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3541234
Z variance train             0.01890589
KL Divergence                32.636955
KL Loss                      3.2636955
QF Loss                      390.0594
VF Loss                      177.33688
Policy Loss                  -755.0678
Q Predictions Mean           749.35675
Q Predictions Std            817.67206
Q Predictions Max            2964.769
Q Predictions Min            295.95847
V Predictions Mean           755.17834
V Predictions Std            818.73334
V Predictions Max            2960.4053
V Predictions Min            303.01538
Log Pis Mean                 -1.2748742
Log Pis Std                  2.7262783
Log Pis Max                  10.891305
Log Pis Min                  -6.732515
Policy mu Mean               0.013607343
Policy mu Std                0.72658527
Policy mu Max                2.9442992
Policy mu Min                -2.4171
Policy log std Mean          -0.49372652
Policy log std Std           0.22336586
Policy log std Max           0.2742077
Policy log std Min           -2.1077695
Z mean eval                  2.367269
Z variance eval              0.027645368
total_rewards                [6927.65014712 6670.27171216 6907.16928837 6749.72366947 6828.52303873
 6813.91260302 6574.75080859 6621.48071738 6569.14286688 6885.21586222]
total_rewards_mean           6754.784071395043
total_rewards_std            130.71433293911306
total_rewards_max            6927.65014712208
total_rewards_min            6569.142866880143
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               192.8684380291961
(Previous) Eval Time (s)     33.918316673953086
Sample Time (s)              7.588387432042509
Epoch Time (s)               234.3751421351917
Total Train Time (s)         24716.62931264192
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:39.472196 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #108 | Epoch Duration: 234.45493078231812
2020-01-13 06:28:39.472389 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3669689
Z variance train             0.027669784
KL Divergence                31.717817
KL Loss                      3.1717818
QF Loss                      278.96848
VF Loss                      95.796936
Policy Loss                  -890.78577
Q Predictions Mean           888.24915
Q Predictions Std            948.17236
Q Predictions Max            3027.3835
Q Predictions Min            -278.43814
V Predictions Mean           886.06506
V Predictions Std            943.2837
V Predictions Max            3007.9446
V Predictions Min            -258.09055
Log Pis Mean                 -0.61698806
Log Pis Std                  3.643743
Log Pis Max                  17.690384
Log Pis Min                  -6.048314
Policy mu Mean               -0.02026139
Policy mu Std                0.83752716
Policy mu Max                3.0834017
Policy mu Min                -2.8996773
Policy log std Mean          -0.49108052
Policy log std Std           0.24731086
Policy log std Max           0.060806513
Policy log std Min           -2.2407994
Z mean eval                  2.378159
Z variance eval              0.030442495
total_rewards                [7534.45706247 7337.83591459 7124.58567951 7060.72599026 7330.63666721
 7019.79323161 7166.54099209 7273.37952128 7346.67681532 7225.0818179 ]
total_rewards_mean           7241.971369225027
total_rewards_std            147.1450102629547
total_rewards_max            7534.457062474099
total_rewards_min            7019.79323161285
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               194.73271376406774
(Previous) Eval Time (s)     35.37994905281812
Sample Time (s)              8.465059744659811
Epoch Time (s)               238.57772256154567
Total Train Time (s)         24955.444329527672
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:32:38.288957 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #109 | Epoch Duration: 238.81641364097595
2020-01-13 06:32:38.289169 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3781993
Z variance train             0.03056768
KL Divergence                32.524994
KL Loss                      3.2524993
QF Loss                      1407.2146
VF Loss                      81.31914
Policy Loss                  -913.54913
Q Predictions Mean           914.15845
Q Predictions Std            964.8417
Q Predictions Max            3114.6812
Q Predictions Min            -238.6327
V Predictions Mean           919.76636
V Predictions Std            967.5894
V Predictions Max            3116.7458
V Predictions Min            -246.78432
Log Pis Mean                 -0.7852782
Log Pis Std                  3.485668
Log Pis Max                  10.85703
Log Pis Min                  -8.014543
Policy mu Mean               -0.056499377
Policy mu Std                0.8470789
Policy mu Max                3.0653214
Policy mu Min                -2.965252
Policy log std Mean          -0.49739084
Policy log std Std           0.22863056
Policy log std Max           -0.14284486
Policy log std Min           -2.2083967
Z mean eval                  2.4433422
Z variance eval              0.041374773
total_rewards                [7355.97429283 7052.65765995 7015.35640316 7122.14362177 7273.52333541
 7371.48935702 7065.39913262 7136.2350221  7244.12487037 7203.27511335]
total_rewards_mean           7184.017880858788
total_rewards_std            119.4126099861237
total_rewards_max            7371.489357022442
total_rewards_min            7015.356403158984
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               188.28392108203843
(Previous) Eval Time (s)     34.6724556889385
Sample Time (s)              7.185761785600334
Epoch Time (s)               230.14213855657727
Total Train Time (s)         25185.677163151093
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:36:28.524604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #110 | Epoch Duration: 230.23527336120605
2020-01-13 06:36:28.524822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.443294
Z variance train             0.04116947
KL Divergence                34.679256
KL Loss                      3.4679258
QF Loss                      291.22113
VF Loss                      115.878204
Policy Loss                  -780.46356
Q Predictions Mean           774.3237
Q Predictions Std            868.28253
Q Predictions Max            3023.226
Q Predictions Min            -293.1857
V Predictions Mean           775.91895
V Predictions Std            867.0656
V Predictions Max            3012.9924
V Predictions Min            -278.30783
Log Pis Mean                 -0.98798287
Log Pis Std                  2.9642038
Log Pis Max                  9.402335
Log Pis Min                  -8.635218
Policy mu Mean               -0.012122206
Policy mu Std                0.7803394
Policy mu Max                2.6410635
Policy mu Min                -2.337457
Policy log std Mean          -0.48807955
Policy log std Std           0.24442835
Policy log std Max           -0.09819105
Policy log std Min           -2.2578611
Z mean eval                  2.4192326
Z variance eval              0.028861891
total_rewards                [7068.33436456 7159.20927192 7112.55936145 7113.77438731 7058.30421565
 6951.41346364 6981.02652941 7043.38931766 6992.96605261 6849.03103708]
total_rewards_mean           7033.00080012868
total_rewards_std            86.93942336011588
total_rewards_max            7159.209271921316
total_rewards_min            6849.031037082559
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               193.8409417490475
(Previous) Eval Time (s)     35.30200512893498
Sample Time (s)              7.417535507585853
Epoch Time (s)               236.56048238556832
Total Train Time (s)         25422.321258524433
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:25.169291 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #111 | Epoch Duration: 236.6443088054657
2020-01-13 06:40:25.169491 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4209316
Z variance train             0.028787836
KL Divergence                34.627586
KL Loss                      3.4627588
QF Loss                      207.79854
VF Loss                      86.50105
Policy Loss                  -982.4785
Q Predictions Mean           979.9088
Q Predictions Std            1010.82666
Q Predictions Max            3095.1865
Q Predictions Min            -275.95193
V Predictions Mean           981.5476
V Predictions Std            1012.6515
V Predictions Max            3103.13
V Predictions Min            -267.7409
Log Pis Mean                 -0.20073465
Log Pis Std                  3.6470885
Log Pis Max                  12.243752
Log Pis Min                  -6.120733
Policy mu Mean               -0.05497692
Policy mu Std                0.8741391
Policy mu Max                2.5170817
Policy mu Min                -2.4823592
Policy log std Mean          -0.5028198
Policy log std Std           0.24419916
Policy log std Max           -0.06372966
Policy log std Min           -2.2856388
Z mean eval                  2.4121456
Z variance eval              0.009360919
total_rewards                [7265.83010177 7091.35374225 7448.15332663 7057.9389155  7663.94138247
 7094.6613302  7106.53718262 7323.8075213  7191.91478832 7141.00049692]
total_rewards_mean           7238.513878795611
total_rewards_std            183.57930236503296
total_rewards_max            7663.941382466083
total_rewards_min            7057.938915496997
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               190.7003251328133
(Previous) Eval Time (s)     35.69212589971721
Sample Time (s)              8.329258158802986
Epoch Time (s)               234.7217091913335
Total Train Time (s)         25657.13911930658
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:44:19.993517 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #112 | Epoch Duration: 234.82383036613464
2020-01-13 06:44:19.993851 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.413935
Z variance train             0.009356315
KL Divergence                36.27749
KL Loss                      3.627749
QF Loss                      162.16724
VF Loss                      235.72177
Policy Loss                  -856.9343
Q Predictions Mean           847.19604
Q Predictions Std            944.8027
Q Predictions Max            3046.371
Q Predictions Min            -298.50327
V Predictions Mean           844.31177
V Predictions Std            940.7422
V Predictions Max            3034.8696
V Predictions Min            -276.46323
Log Pis Mean                 -0.79422057
Log Pis Std                  3.2855537
Log Pis Max                  11.674738
Log Pis Min                  -6.6747
Policy mu Mean               0.0125026405
Policy mu Std                0.8179594
Policy mu Max                2.5601666
Policy mu Min                -2.7900164
Policy log std Mean          -0.49602243
Policy log std Std           0.23585992
Policy log std Max           -0.13856037
Policy log std Min           -2.301085
Z mean eval                  2.3965256
Z variance eval              0.020117419
total_rewards                [6756.18448181 6503.17616711 6782.60520333 6982.11950792 6867.16512866
 6775.237981   6772.46100648 6686.69642359 6772.67254572 7005.95876207]
total_rewards_mean           6790.427720768969
total_rewards_std            135.81760060418696
total_rewards_max            7005.958762068265
total_rewards_min            6503.176167106339
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               193.12521798396483
(Previous) Eval Time (s)     35.604141862131655
Sample Time (s)              6.842854545451701
Epoch Time (s)               235.5722143915482
Total Train Time (s)         25892.793375784997
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:48:15.646518 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #113 | Epoch Duration: 235.65240359306335
2020-01-13 06:48:15.646719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3971345
Z variance train             0.020160925
KL Divergence                34.52762
KL Loss                      3.452762
QF Loss                      117.26252
VF Loss                      41.92177
Policy Loss                  -784.6341
Q Predictions Mean           779.56165
Q Predictions Std            875.6504
Q Predictions Max            3026.2507
Q Predictions Min            -275.08417
V Predictions Mean           783.7565
V Predictions Std            876.65106
V Predictions Max            3037.6035
V Predictions Min            -263.03946
Log Pis Mean                 -0.9905231
Log Pis Std                  2.9734793
Log Pis Max                  16.961308
Log Pis Min                  -7.1211233
Policy mu Mean               -0.024763698
Policy mu Std                0.80313
Policy mu Max                3.6572993
Policy mu Min                -3.3668737
Policy log std Mean          -0.4810531
Policy log std Std           0.22551511
Policy log std Max           -0.08403307
Policy log std Min           -2.2513313
Z mean eval                  2.3850007
Z variance eval              0.044242334
total_rewards                [6904.73868365 7181.53573159 6922.51075075 6859.12408182 7163.20331116
 7023.77955628 7077.15901523 6824.91679822 6749.76557553 6681.75223083]
total_rewards_mean           6938.848573506516
total_rewards_std            160.68382547753134
total_rewards_max            7181.535731587146
total_rewards_min            6681.752230834412
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               194.137844319921
(Previous) Eval Time (s)     33.06217734888196
Sample Time (s)              6.376210088375956
Epoch Time (s)               233.5762317571789
Total Train Time (s)         26126.449211459607
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:09.304586 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #114 | Epoch Duration: 233.6577124595642
2020-01-13 06:52:09.304785 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.381967
Z variance train             0.04426367
KL Divergence                32.2134
KL Loss                      3.2213402
QF Loss                      111.18854
VF Loss                      108.68267
Policy Loss                  -778.9085
Q Predictions Mean           775.4499
Q Predictions Std            873.9197
Q Predictions Max            3071.524
Q Predictions Min            -256.7075
V Predictions Mean           772.5237
V Predictions Std            871.07104
V Predictions Max            3035.2168
V Predictions Min            -255.20293
Log Pis Mean                 -0.6367619
Log Pis Std                  3.277388
Log Pis Max                  14.957436
Log Pis Min                  -6.823497
Policy mu Mean               -0.012257658
Policy mu Std                0.8357858
Policy mu Max                3.2809157
Policy mu Min                -2.7691698
Policy log std Mean          -0.48935232
Policy log std Std           0.23605226
Policy log std Max           -0.13481084
Policy log std Min           -2.3111713
Z mean eval                  2.4261234
Z variance eval              0.04033663
total_rewards                [7120.02177511 7297.4905346  7115.98915807 6996.00010022 7147.56156851
 6866.0815257  7115.78782622 7032.68751309 7344.09000369 7104.96838497]
total_rewards_mean           7114.067839016747
total_rewards_std            130.33064514518398
total_rewards_max            7344.090003692769
total_rewards_min            6866.081525698259
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               191.18915978260338
(Previous) Eval Time (s)     35.37314118631184
Sample Time (s)              7.900508771184832
Epoch Time (s)               234.46280974010006
Total Train Time (s)         26361.007478269283
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:03.865494 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #115 | Epoch Duration: 234.56054639816284
2020-01-13 06:56:03.865739 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4248593
Z variance train             0.040337563
KL Divergence                32.51196
KL Loss                      3.251196
QF Loss                      631.2743
VF Loss                      234.13187
Policy Loss                  -802.7943
Q Predictions Mean           799.3718
Q Predictions Std            904.5726
Q Predictions Max            2981.9612
Q Predictions Min            139.30292
V Predictions Mean           802.86145
V Predictions Std            900.5644
V Predictions Max            2976.9521
V Predictions Min            312.5637
Log Pis Mean                 -0.73243415
Log Pis Std                  3.2061098
Log Pis Max                  16.677006
Log Pis Min                  -7.0559683
Policy mu Mean               0.03655225
Policy mu Std                0.8175828
Policy mu Max                2.8702884
Policy mu Min                -2.870557
Policy log std Mean          -0.49237204
Policy log std Std           0.23172052
Policy log std Max           -0.11878353
Policy log std Min           -2.271602
Z mean eval                  2.4535842
Z variance eval              0.012866093
total_rewards                [7120.34985805 6759.56413111 7130.90395561 6914.59161499 6944.84791925
 6559.9851037  6939.59287714 7252.53981264 6952.60328124 6857.81667358]
total_rewards_mean           6943.279522731349
total_rewards_std            187.37518338604147
total_rewards_max            7252.539812639309
total_rewards_min            6559.985103698569
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               197.2910282718949
(Previous) Eval Time (s)     32.39110016962513
Sample Time (s)              6.735159168019891
Epoch Time (s)               236.41728760953993
Total Train Time (s)         26597.504297574982
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:00:00.364383 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #116 | Epoch Duration: 236.49846267700195
2020-01-13 07:00:00.364585 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4512992
Z variance train             0.012826955
KL Divergence                36.53527
KL Loss                      3.653527
QF Loss                      160.30984
VF Loss                      72.768906
Policy Loss                  -1003.4687
Q Predictions Mean           997.23914
Q Predictions Std            1051.4114
Q Predictions Max            3046.5815
Q Predictions Min            339.49005
V Predictions Mean           1007.3169
V Predictions Std            1052.3134
V Predictions Max            3051.7224
V Predictions Min            351.2664
Log Pis Mean                 -0.6720926
Log Pis Std                  3.5570939
Log Pis Max                  15.118576
Log Pis Min                  -7.6116924
Policy mu Mean               -0.04812457
Policy mu Std                0.8563458
Policy mu Max                2.9112308
Policy mu Min                -2.8727508
Policy log std Mean          -0.5030327
Policy log std Std           0.22656447
Policy log std Max           -0.11188197
Policy log std Min           -2.3697202
Z mean eval                  2.4661376
Z variance eval              0.013591366
total_rewards                [6733.78653123 7230.10231084 6923.36697462 7259.02285627 6874.42653217
 6944.96106915 6914.07302752 7232.72421827 7476.28739697 7365.73404315]
total_rewards_mean           7095.4484960178725
total_rewards_std            233.8014225925144
total_rewards_max            7476.28739696544
total_rewards_min            6733.786531228109
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               197.06571602402255
(Previous) Eval Time (s)     31.722718778066337
Sample Time (s)              7.939997537527233
Epoch Time (s)               236.72843233961612
Total Train Time (s)         26834.332154254895
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:03:57.193499 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #117 | Epoch Duration: 236.8287525177002
2020-01-13 07:03:57.193709 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5470912
Z variance train             0.013230838
KL Divergence                38.238754
KL Loss                      3.8238754
QF Loss                      220.24188
VF Loss                      89.56567
Policy Loss                  -842.2801
Q Predictions Mean           840.4824
Q Predictions Std            928.1642
Q Predictions Max            3160.676
Q Predictions Min            -261.78152
V Predictions Mean           847.7411
V Predictions Std            931.4107
V Predictions Max            3188.6458
V Predictions Min            -278.0122
Log Pis Mean                 -0.7795371
Log Pis Std                  2.9611828
Log Pis Max                  10.0101795
Log Pis Min                  -7.190307
Policy mu Mean               -0.08420965
Policy mu Std                0.79333454
Policy mu Max                2.5771384
Policy mu Min                -2.8210459
Policy log std Mean          -0.4956653
Policy log std Std           0.23992583
Policy log std Max           -0.10236251
Policy log std Min           -2.3547637
Z mean eval                  2.451123
Z variance eval              0.017584525
total_rewards                [6980.31103562 7093.46546203 6899.4092605  7005.77952482 7052.19456334
 7132.29849194 7142.62301285 7366.12688912 6907.17213658 7131.77606566]
total_rewards_mean           7071.115644247619
total_rewards_std            130.11545987295887
total_rewards_max            7366.12688912411
total_rewards_min            6899.409260502795
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               194.5534824617207
(Previous) Eval Time (s)     33.53108900692314
Sample Time (s)              7.918449178803712
Epoch Time (s)               236.00302064744756
Total Train Time (s)         27070.414185508154
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:07:53.278270 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #118 | Epoch Duration: 236.08440494537354
2020-01-13 07:07:53.278458 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.446478
Z variance train             0.017608121
KL Divergence                37.456924
KL Loss                      3.7456925
QF Loss                      168.94112
VF Loss                      86.06381
Policy Loss                  -920.89276
Q Predictions Mean           916.50757
Q Predictions Std            992.26465
Q Predictions Max            3184.4668
Q Predictions Min            323.6163
V Predictions Mean           923.2513
V Predictions Std            995.2878
V Predictions Max            3158.7498
V Predictions Min            338.1707
Log Pis Mean                 -0.53434384
Log Pis Std                  3.3653452
Log Pis Max                  12.235519
Log Pis Min                  -6.8263674
Policy mu Mean               -0.0088265585
Policy mu Std                0.83797115
Policy mu Max                2.3474405
Policy mu Min                -2.4327996
Policy log std Mean          -0.50317955
Policy log std Std           0.23592989
Policy log std Max           -0.07045491
Policy log std Min           -2.1554966
Z mean eval                  2.5039933
Z variance eval              0.0225075
total_rewards                [7619.61975311 7490.91251699 7345.4825999  7298.54141663 7456.68544172
 7680.44432005 7623.58045154 7175.78710287 7419.49469339 7331.8897375 ]
total_rewards_mean           7444.243803369539
total_rewards_std            154.05509398217467
total_rewards_max            7680.444320047855
total_rewards_min            7175.7871028693835
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               190.27488333033398
(Previous) Eval Time (s)     32.040421115234494
Sample Time (s)              6.743371340911835
Epoch Time (s)               229.0586757864803
Total Train Time (s)         27299.55584243452
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:11:42.421665 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #119 | Epoch Duration: 229.1430003643036
2020-01-13 07:11:42.421960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.502811
Z variance train             0.022553295
KL Divergence                37.725533
KL Loss                      3.7725532
QF Loss                      130.76013
VF Loss                      50.44587
Policy Loss                  -853.3321
Q Predictions Mean           852.14886
Q Predictions Std            923.2249
Q Predictions Max            3090.6929
Q Predictions Min            345.47528
V Predictions Mean           850.7677
V Predictions Std            920.1241
V Predictions Max            3069.1072
V Predictions Min            352.12756
Log Pis Mean                 -0.63186353
Log Pis Std                  3.096471
Log Pis Max                  11.231658
Log Pis Min                  -6.635481
Policy mu Mean               0.0052467114
Policy mu Std                0.8275258
Policy mu Max                2.2901185
Policy mu Min                -3.3014033
Policy log std Mean          -0.5096056
Policy log std Std           0.24082276
Policy log std Max           -0.043775335
Policy log std Min           -2.1969786
Z mean eval                  2.4625854
Z variance eval              0.025190407
total_rewards                [7038.06986599 6943.96848463 6927.54899793 6932.76305822 6951.72333427
 6922.05587071 7028.12682957 7002.83782588 7188.05071438 7445.30463603]
total_rewards_mean           7038.044961762311
total_rewards_std            155.80404163202775
total_rewards_max            7445.304636029082
total_rewards_min            6922.055870712341
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               189.70620628912002
(Previous) Eval Time (s)     34.44886833708733
Sample Time (s)              10.309682470280677
Epoch Time (s)               234.46475709648803
Total Train Time (s)         27534.105234036688
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:15:36.975466 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #120 | Epoch Duration: 234.55331993103027
2020-01-13 07:15:36.975673 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4641755
Z variance train             0.025230538
KL Divergence                37.120888
KL Loss                      3.7120888
QF Loss                      1448.3958
VF Loss                      141.01942
Policy Loss                  -894.6742
Q Predictions Mean           888.01733
Q Predictions Std            970.3733
Q Predictions Max            3192.2834
Q Predictions Min            350.69525
V Predictions Mean           886.70154
V Predictions Std            967.2319
V Predictions Max            3186.5967
V Predictions Min            357.69086
Log Pis Mean                 -0.5810605
Log Pis Std                  3.126819
Log Pis Max                  9.841087
Log Pis Min                  -5.9886637
Policy mu Mean               -0.02489233
Policy mu Std                0.83094823
Policy mu Max                2.462107
Policy mu Min                -2.8846338
Policy log std Mean          -0.50090235
Policy log std Std           0.23703615
Policy log std Max           -0.107239366
Policy log std Min           -2.2466424
Z mean eval                  2.457745
Z variance eval              0.013334738
total_rewards                [7143.51102058 7047.99239209 6946.26885371 7023.90652994 7132.34936068
 6886.9491902  6740.16918891 6980.59403902 6637.6479837  6470.47586318]
total_rewards_mean           6900.986442202612
total_rewards_std            209.33243190491532
total_rewards_max            7143.511020584448
total_rewards_min            6470.475863184947
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               191.92024299874902
(Previous) Eval Time (s)     35.4315516250208
Sample Time (s)              7.1857058010064065
Epoch Time (s)               234.53750042477623
Total Train Time (s)         27768.72876377264
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:31.600537 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #121 | Epoch Duration: 234.62465953826904
2020-01-13 07:19:31.600813 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4591484
Z variance train             0.013335099
KL Divergence                37.6566
KL Loss                      3.76566
QF Loss                      109.7713
VF Loss                      38.01153
Policy Loss                  -898.6013
Q Predictions Mean           891.8047
Q Predictions Std            951.05774
Q Predictions Max            3145.3374
Q Predictions Min            358.83734
V Predictions Mean           896.0027
V Predictions Std            950.9467
V Predictions Max            3164.9192
V Predictions Min            369.30896
Log Pis Mean                 -0.82444566
Log Pis Std                  3.0924194
Log Pis Max                  11.866415
Log Pis Min                  -7.4264226
Policy mu Mean               0.02357936
Policy mu Std                0.798696
Policy mu Max                2.8069038
Policy mu Min                -2.479508
Policy log std Mean          -0.5032208
Policy log std Std           0.23425971
Policy log std Max           -0.1512093
Policy log std Min           -2.1961017
Z mean eval                  2.417719
Z variance eval              0.014644456
total_rewards                [7190.76855561 7329.66585562 7216.03298548 7439.29125205 7258.27408259
 7274.83580798 7053.38415541 7317.87832327 7224.242508   7135.83288491]
total_rewards_mean           7244.020641092667
total_rewards_std            102.04437019315789
total_rewards_max            7439.291252052277
total_rewards_min            7053.38415541308
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               187.76156838284805
(Previous) Eval Time (s)     35.610060011036694
Sample Time (s)              7.015000315848738
Epoch Time (s)               230.3866287097335
Total Train Time (s)         27999.212290767115
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:23:22.085327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #122 | Epoch Duration: 230.48433637619019
2020-01-13 07:23:22.085523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4210868
Z variance train             0.014740078
KL Divergence                36.893402
KL Loss                      3.6893404
QF Loss                      242.87186
VF Loss                      116.67157
Policy Loss                  -833.7343
Q Predictions Mean           825.1681
Q Predictions Std            905.9327
Q Predictions Max            3161.4004
Q Predictions Min            357.5486
V Predictions Mean           829.15405
V Predictions Std            904.4042
V Predictions Max            3154.8904
V Predictions Min            364.16904
Log Pis Mean                 -0.8687284
Log Pis Std                  3.0787735
Log Pis Max                  13.4268
Log Pis Min                  -9.04739
Policy mu Mean               -0.01842077
Policy mu Std                0.8045889
Policy mu Max                2.360936
Policy mu Min                -2.4812202
Policy log std Mean          -0.4929787
Policy log std Std           0.23718998
Policy log std Max           -0.14313978
Policy log std Min           -2.3694804
Z mean eval                  2.4740384
Z variance eval              0.02143723
total_rewards                [6574.15490649 6368.25581443 6740.08936574 6785.2073048  6682.62855122
 6717.5083777  6626.07436649 6726.58672689 7203.11780636 6904.83510344]
total_rewards_mean           6732.845832355958
total_rewards_std            206.35776160871498
total_rewards_max            7203.117806359173
total_rewards_min            6368.255814431361
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               193.53449158603325
(Previous) Eval Time (s)     33.07755645830184
Sample Time (s)              8.245606448501348
Epoch Time (s)               234.85765449283645
Total Train Time (s)         28234.151601534802
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:27:17.030278 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #123 | Epoch Duration: 234.94459700584412
2020-01-13 07:27:17.030497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4762387
Z variance train             0.02148075
KL Divergence                35.25986
KL Loss                      3.5259862
QF Loss                      261.03583
VF Loss                      44.647213
Policy Loss                  -870.393
Q Predictions Mean           863.74347
Q Predictions Std            947.9611
Q Predictions Max            3169.6643
Q Predictions Min            351.0817
V Predictions Mean           869.2042
V Predictions Std            945.70844
V Predictions Max            3129.4685
V Predictions Min            360.53778
Log Pis Mean                 -0.7258871
Log Pis Std                  3.0551257
Log Pis Max                  10.926655
Log Pis Min                  -6.833131
Policy mu Mean               -0.06284975
Policy mu Std                0.7986264
Policy mu Max                3.0591025
Policy mu Min                -2.476301
Policy log std Mean          -0.51398164
Policy log std Std           0.22930689
Policy log std Max           -0.053965554
Policy log std Min           -2.2157884
Z mean eval                  2.4474645
Z variance eval              0.01925805
total_rewards                [7235.35682105 7459.21198166 7523.33621058 7453.29098875 7385.75217018
 7344.06816721 7354.26937916 7256.69944434 7396.04819658 7199.93752482]
total_rewards_mean           7360.797088431978
total_rewards_std            99.6467876817751
total_rewards_max            7523.3362105825145
total_rewards_min            7199.9375248201
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               188.88691015029326
(Previous) Eval Time (s)     35.08550047222525
Sample Time (s)              6.887063923291862
Epoch Time (s)               230.85947454581037
Total Train Time (s)         28465.19680999685
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:08.091058 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #124 | Epoch Duration: 231.0603382587433
2020-01-13 07:31:08.091344 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4461942
Z variance train             0.019272555
KL Divergence                35.810673
KL Loss                      3.5810673
QF Loss                      219.4707
VF Loss                      64.52697
Policy Loss                  -867.90985
Q Predictions Mean           863.5167
Q Predictions Std            941.94446
Q Predictions Max            3186.6865
Q Predictions Min            332.20648
V Predictions Mean           865.77765
V Predictions Std            940.7089
V Predictions Max            3154.154
V Predictions Min            344.3431
Log Pis Mean                 -0.7331747
Log Pis Std                  3.3181336
Log Pis Max                  16.170578
Log Pis Min                  -7.798026
Policy mu Mean               -0.044524636
Policy mu Std                0.8374811
Policy mu Max                3.3222663
Policy mu Min                -3.308507
Policy log std Mean          -0.5011994
Policy log std Std           0.24728324
Policy log std Max           -0.11119887
Policy log std Min           -2.4763885
Z mean eval                  2.4045615
Z variance eval              0.021993678
total_rewards                [7464.7494534  7374.29867784 7435.97970593 7089.61486213 7382.67233538
 7369.54763311 7142.54129608 7421.20872734 7513.55004637 7491.37284817]
total_rewards_mean           7368.55355857513
total_rewards_std            134.83424464946228
total_rewards_max            7513.550046368148
total_rewards_min            7089.614862134812
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               190.77930505992845
(Previous) Eval Time (s)     33.19064713874832
Sample Time (s)              7.473704228643328
Epoch Time (s)               231.4436564273201
Total Train Time (s)         28696.74836745998
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:34:59.630327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #125 | Epoch Duration: 231.5387921333313
2020-01-13 07:34:59.630551 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4030807
Z variance train             0.021952173
KL Divergence                34.489845
KL Loss                      3.4489846
QF Loss                      216.41927
VF Loss                      45.129993
Policy Loss                  -724.059
Q Predictions Mean           722.17395
Q Predictions Std            793.4808
Q Predictions Max            3048.9194
Q Predictions Min            364.76337
V Predictions Mean           728.32324
V Predictions Std            794.42413
V Predictions Max            3041.5505
V Predictions Min            370.39633
Log Pis Mean                 -0.93715
Log Pis Std                  2.9993885
Log Pis Max                  10.717724
Log Pis Min                  -8.140587
Policy mu Mean               -0.024168344
Policy mu Std                0.77527267
Policy mu Max                2.6761494
Policy mu Min                -2.6305413
Policy log std Mean          -0.5033559
Policy log std Std           0.2313647
Policy log std Max           -0.019349188
Policy log std Min           -2.4357204
Z mean eval                  2.4232469
Z variance eval              0.02758593
total_rewards                [7643.25111735 7280.11109397 7416.88805517 7470.29513278 7528.90348408
 7505.35035565 7751.53223447 7438.47573367 7208.29104044 7558.16043918]
total_rewards_mean           7480.125868677564
total_rewards_std            151.3626998183603
total_rewards_max            7751.5322344710985
total_rewards_min            7208.291040441649
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               192.960303963162
(Previous) Eval Time (s)     30.55027084099129
Sample Time (s)              6.837589093018323
Epoch Time (s)               230.34816389717162
Total Train Time (s)         28927.181998297106
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:50.068920 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #126 | Epoch Duration: 230.4381947517395
2020-01-13 07:38:50.069181 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4255905
Z variance train             0.027630214
KL Divergence                33.658546
KL Loss                      3.3658547
QF Loss                      1410.0148
VF Loss                      34.421013
Policy Loss                  -766.585
Q Predictions Mean           764.8273
Q Predictions Std            859.55884
Q Predictions Max            3197.2134
Q Predictions Min            362.27512
V Predictions Mean           767.0297
V Predictions Std            855.79126
V Predictions Max            3176.2502
V Predictions Min            365.02847
Log Pis Mean                 -0.71227527
Log Pis Std                  3.3979764
Log Pis Max                  17.40755
Log Pis Min                  -6.133987
Policy mu Mean               -0.027078174
Policy mu Std                0.81527615
Policy mu Max                3.2794163
Policy mu Min                -3.005434
Policy log std Mean          -0.48613906
Policy log std Std           0.23574962
Policy log std Max           -0.09327668
Policy log std Min           -2.3513727
Z mean eval                  2.4754734
Z variance eval              0.018523816
total_rewards                [7276.96163296 7257.0238101  7304.2528697  7435.322195   7357.94242729
 7110.94044633 7735.27755325 7217.2209633  7526.77220978 7463.84989358]
total_rewards_mean           7368.5564001294815
total_rewards_std            169.52884190516423
total_rewards_max            7735.277553250771
total_rewards_min            7110.940446333561
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               194.303839283064
(Previous) Eval Time (s)     35.030622026883066
Sample Time (s)              6.595488550607115
Epoch Time (s)               235.9299498605542
Total Train Time (s)         29163.196554731112
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:46.084100 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #127 | Epoch Duration: 236.01472520828247
2020-01-13 07:42:46.084304 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4776998
Z variance train             0.01850706
KL Divergence                35.640053
KL Loss                      3.5640054
QF Loss                      148.5813
VF Loss                      205.0873
Policy Loss                  -735.649
Q Predictions Mean           735.42456
Q Predictions Std            817.0636
Q Predictions Max            3168.4587
Q Predictions Min            376.1633
V Predictions Mean           733.4231
V Predictions Std            816.6545
V Predictions Max            3165.8518
V Predictions Min            375.51053
Log Pis Mean                 -0.89564157
Log Pis Std                  3.4575205
Log Pis Max                  17.958845
Log Pis Min                  -7.5867305
Policy mu Mean               0.050168287
Policy mu Std                0.78528315
Policy mu Max                3.1833475
Policy mu Min                -3.03195
Policy log std Mean          -0.48041978
Policy log std Std           0.23481864
Policy log std Max           -0.03936343
Policy log std Min           -2.3092434
Z mean eval                  2.4371362
Z variance eval              0.026284471
total_rewards                [7177.41420757 7349.84074038 7312.50818994 7292.19317463 6908.24532416
 7068.01135248 7203.67087312 7290.72899985 7350.97630586 7271.71432189]
total_rewards_mean           7222.530348986923
total_rewards_std            133.32954776261553
total_rewards_max            7350.976305856888
total_rewards_min            6908.245324156087
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               193.06879666028544
(Previous) Eval Time (s)     29.757026112172753
Sample Time (s)              7.884273801930249
Epoch Time (s)               230.71009657438844
Total Train Time (s)         29393.986422378104
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:36.875878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #128 | Epoch Duration: 230.79141187667847
2020-01-13 07:46:36.876126 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4372897
Z variance train             0.026292956
KL Divergence                34.9248
KL Loss                      3.49248
QF Loss                      149.7567
VF Loss                      93.63142
Policy Loss                  -962.9175
Q Predictions Mean           960.8802
Q Predictions Std            1015.7506
Q Predictions Max            3171.3281
Q Predictions Min            377.18732
V Predictions Mean           957.91956
V Predictions Std            1009.90607
V Predictions Max            3158.1516
V Predictions Min            381.39813
Log Pis Mean                 -0.7789993
Log Pis Std                  3.3093607
Log Pis Max                  12.328398
Log Pis Min                  -7.4859962
Policy mu Mean               -0.048295934
Policy mu Std                0.81616193
Policy mu Max                2.8668725
Policy mu Min                -2.5024474
Policy log std Mean          -0.50264174
Policy log std Std           0.23551688
Policy log std Max           -0.098140344
Policy log std Min           -2.3461149
Z mean eval                  2.477528
Z variance eval              0.027736124
total_rewards                [7181.09400046 7830.71829477 7556.50873283 7665.30515666 7469.62322919
 7584.34301613 7578.7155426  7788.94401191 7342.96882528 7562.46805666]
total_rewards_mean           7556.06888664866
total_rewards_std            183.422947697311
total_rewards_max            7830.718294767605
total_rewards_min            7181.094000462379
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               190.57355182804167
(Previous) Eval Time (s)     31.653969989623874
Sample Time (s)              7.858579942025244
Epoch Time (s)               230.0861017596908
Total Train Time (s)         29624.15429467708
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:50:27.045796 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #129 | Epoch Duration: 230.16944551467896
2020-01-13 07:50:27.046103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4767082
Z variance train             0.027664278
KL Divergence                34.750652
KL Loss                      3.4750652
QF Loss                      141.20514
VF Loss                      64.75785
Policy Loss                  -845.4765
Q Predictions Mean           842.64197
Q Predictions Std            926.4444
Q Predictions Max            3303.8218
Q Predictions Min            366.29898
V Predictions Mean           850.2631
V Predictions Std            927.0852
V Predictions Max            3300.7485
V Predictions Min            380.8138
Log Pis Mean                 -0.7806845
Log Pis Std                  2.9306226
Log Pis Max                  10.161748
Log Pis Min                  -6.720813
Policy mu Mean               0.014839809
Policy mu Std                0.81302214
Policy mu Max                2.4697895
Policy mu Min                -2.777885
Policy log std Mean          -0.4979647
Policy log std Std           0.22252026
Policy log std Max           -0.028190136
Policy log std Min           -2.219459
Z mean eval                  2.4484143
Z variance eval              0.023233961
total_rewards                [7491.52183121 8072.41766306 7650.42361142 7865.08094655 7845.90900259
 7849.72686729 7499.26861198 7599.9950294  7817.77481646 7665.36127823]
total_rewards_mean           7735.7479658177035
total_rewards_std            175.54510354326584
total_rewards_max            8072.417663057286
total_rewards_min            7491.521831206622
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               188.6964161451906
(Previous) Eval Time (s)     32.178974559064955
Sample Time (s)              6.281613556668162
Epoch Time (s)               227.1570042609237
Total Train Time (s)         29851.40135108307
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:54:14.294472 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #130 | Epoch Duration: 227.24817872047424
2020-01-13 07:54:14.294653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.450655
Z variance train             0.023228213
KL Divergence                35.260006
KL Loss                      3.5260007
QF Loss                      1432.2106
VF Loss                      39.696934
Policy Loss                  -823.4955
Q Predictions Mean           823.42334
Q Predictions Std            897.30896
Q Predictions Max            3258.434
Q Predictions Min            379.13675
V Predictions Mean           823.13916
V Predictions Std            899.3799
V Predictions Max            3258.5564
V Predictions Min            385.7205
Log Pis Mean                 -0.84372807
Log Pis Std                  3.170863
Log Pis Max                  15.094231
Log Pis Min                  -8.510298
Policy mu Mean               -0.0028061469
Policy mu Std                0.80029017
Policy mu Max                2.5664272
Policy mu Min                -2.4473035
Policy log std Mean          -0.51014775
Policy log std Std           0.23785482
Policy log std Max           0.049128413
Policy log std Min           -2.2977107
Z mean eval                  2.4555252
Z variance eval              0.022890832
total_rewards                [6921.63743092 6771.93132432 7412.11614907 6986.20896487 7170.22889979
 6864.21723387 7220.13452331 7037.2438952  6458.78983841 6988.14867438]
total_rewards_mean           6983.065693413252
total_rewards_std            248.11857357776879
total_rewards_max            7412.116149067102
total_rewards_min            6458.789838414956
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               189.30306193511933
(Previous) Eval Time (s)     38.06319053284824
Sample Time (s)              7.987594302743673
Epoch Time (s)               235.35384677071124
Total Train Time (s)         30086.888803570066
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:58:09.786826 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #131 | Epoch Duration: 235.491952419281
2020-01-13 07:58:09.787147 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4562953
Z variance train             0.02290542
KL Divergence                36.754208
KL Loss                      3.6754208
QF Loss                      144.95868
VF Loss                      57.039764
Policy Loss                  -908.5803
Q Predictions Mean           905.9636
Q Predictions Std            973.1926
Q Predictions Max            3229.6501
Q Predictions Min            371.79172
V Predictions Mean           907.05005
V Predictions Std            972.17664
V Predictions Max            3209.3108
V Predictions Min            379.6445
Log Pis Mean                 -0.51649535
Log Pis Std                  3.4321113
Log Pis Max                  11.916042
Log Pis Min                  -7.0673046
Policy mu Mean               0.005678946
Policy mu Std                0.8512118
Policy mu Max                3.4510798
Policy mu Min                -2.3994315
Policy log std Mean          -0.5002398
Policy log std Std           0.25500613
Policy log std Max           -0.08002818
Policy log std Min           -2.341215
Z mean eval                  2.4465814
Z variance eval              0.019378057
total_rewards                [7721.09108706 7904.66814807 7909.27249817 7644.30621306 7831.49840246
 7708.09181348 7952.94148244 7733.69075476 7627.42520222 7642.76305731]
total_rewards_mean           7767.57486590397
total_rewards_std            116.00947066240556
total_rewards_max            7952.941482437968
total_rewards_min            7627.425202222777
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               189.11666351370513
(Previous) Eval Time (s)     31.971911906264722
Sample Time (s)              7.9062557383440435
Epoch Time (s)               228.9948311583139
Total Train Time (s)         30315.968470343854
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:01:58.868042 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #132 | Epoch Duration: 229.08071184158325
2020-01-13 08:01:58.868213 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4474494
Z variance train             0.019371036
KL Divergence                35.342236
KL Loss                      3.5342236
QF Loss                      140.04102
VF Loss                      233.89517
Policy Loss                  -931.2677
Q Predictions Mean           928.26117
Q Predictions Std            996.4317
Q Predictions Max            3230.367
Q Predictions Min            378.14444
V Predictions Mean           934.02386
V Predictions Std            995.24554
V Predictions Max            3226.0344
V Predictions Min            387.00104
Log Pis Mean                 -0.64281577
Log Pis Std                  3.7668803
Log Pis Max                  20.586906
Log Pis Min                  -9.431591
Policy mu Mean               -0.06869237
Policy mu Std                0.85560215
Policy mu Max                4.322344
Policy mu Min                -2.6249797
Policy log std Mean          -0.50483745
Policy log std Std           0.23560962
Policy log std Max           -0.103358656
Policy log std Min           -2.4018009
Z mean eval                  2.4328003
Z variance eval              0.026255766
total_rewards                [7903.76431678 7911.01965076 7877.05450948 7817.00499963 7724.75351238
 7896.28189337 7511.24350813 7998.79925952 7820.03017425 7727.16675936]
total_rewards_mean           7818.711858367475
total_rewards_std            130.13731601471545
total_rewards_max            7998.799259515201
total_rewards_min            7511.243508129725
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               189.55462410021573
(Previous) Eval Time (s)     36.454414926003665
Sample Time (s)              6.686941240914166
Epoch Time (s)               232.69598026713356
Total Train Time (s)         30548.747103607748
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:05:51.650400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #133 | Epoch Duration: 232.78204989433289
2020-01-13 08:05:51.650578 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.431623
Z variance train             0.026194971
KL Divergence                35.237278
KL Loss                      3.523728
QF Loss                      125.67196
VF Loss                      67.03149
Policy Loss                  -822.3804
Q Predictions Mean           819.624
Q Predictions Std            879.54767
Q Predictions Max            3265.5037
Q Predictions Min            388.7754
V Predictions Mean           825.1521
V Predictions Std            883.0724
V Predictions Max            3275.0405
V Predictions Min            399.10233
Log Pis Mean                 -0.97450364
Log Pis Std                  3.0215118
Log Pis Max                  10.9647045
Log Pis Min                  -8.376728
Policy mu Mean               -0.041651078
Policy mu Std                0.795867
Policy mu Max                2.8953733
Policy mu Min                -3.0237324
Policy log std Mean          -0.49717033
Policy log std Std           0.22705382
Policy log std Max           -0.11983664
Policy log std Min           -1.7565595
Z mean eval                  2.4256644
Z variance eval              0.020035971
total_rewards                [7954.04193616 7663.93882188 7777.41000498 7932.68090471 7775.93755671
 7823.62739109 8012.8995662  7927.23449033 7581.0225834  7926.91727698]
total_rewards_mean           7837.5710532435405
total_rewards_std            131.51100790283036
total_rewards_max            8012.899566195437
total_rewards_min            7581.022583398252
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               190.0154283400625
(Previous) Eval Time (s)     31.881938779260963
Sample Time (s)              6.725245937239379
Epoch Time (s)               228.62261305656284
Total Train Time (s)         30777.47495298274
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:09:40.382342 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #134 | Epoch Duration: 228.73156237602234
2020-01-13 08:09:40.382661 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4221902
Z variance train             0.02002517
KL Divergence                35.38349
KL Loss                      3.5383492
QF Loss                      107.16957
VF Loss                      80.483765
Policy Loss                  -869.18665
Q Predictions Mean           866.7479
Q Predictions Std            943.27765
Q Predictions Max            3254.3313
Q Predictions Min            367.3563
V Predictions Mean           862.7296
V Predictions Std            941.9106
V Predictions Max            3233.729
V Predictions Min            350.5362
Log Pis Mean                 -0.57971156
Log Pis Std                  2.930399
Log Pis Max                  9.2863655
Log Pis Min                  -6.946933
Policy mu Mean               -0.00019873276
Policy mu Std                0.83694357
Policy mu Max                2.5726922
Policy mu Min                -2.5350008
Policy log std Mean          -0.5072461
Policy log std Std           0.21986483
Policy log std Max           0.0049846172
Policy log std Min           -1.9898134
Z mean eval                  2.466182
Z variance eval              0.023430552
total_rewards                [7244.2488405  7279.82108385 7354.67293188 7278.20000269 7109.80825757
 7142.46862247 7326.67375881 7223.28789289 7234.63832137 7074.13026871]
total_rewards_mean           7226.794998074988
total_rewards_std            87.32959513345394
total_rewards_max            7354.672931879524
total_rewards_min            7074.130268710139
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               193.0228235339746
(Previous) Eval Time (s)     35.253034298773855
Sample Time (s)              6.683221708983183
Epoch Time (s)               234.95907954173163
Total Train Time (s)         31012.516765431035
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:13:35.425174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #135 | Epoch Duration: 235.0422558784485
2020-01-13 08:13:35.425400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4662967
Z variance train             0.023424279
KL Divergence                36.942844
KL Loss                      3.6942844
QF Loss                      269.49786
VF Loss                      92.18722
Policy Loss                  -984.8265
Q Predictions Mean           983.8144
Q Predictions Std            1036.3064
Q Predictions Max            3300.3352
Q Predictions Min            388.84915
V Predictions Mean           981.02423
V Predictions Std            1028.7145
V Predictions Max            3266.3438
V Predictions Min            390.92328
Log Pis Mean                 -0.51775813
Log Pis Std                  3.5239716
Log Pis Max                  19.464539
Log Pis Min                  -7.684331
Policy mu Mean               -0.08515817
Policy mu Std                0.8599556
Policy mu Max                4.0368114
Policy mu Min                -3.580235
Policy log std Mean          -0.5069782
Policy log std Std           0.24938972
Policy log std Max           0.08385277
Policy log std Min           -2.3750927
Z mean eval                  2.4320889
Z variance eval              0.02129041
total_rewards                [7512.2061653  7667.73493915 8204.1839676  7853.8447456  7862.04412237
 7839.38920337 7752.81750618 7863.79191728 7902.50959573 7896.16165523]
total_rewards_mean           7835.468381783348
total_rewards_std            168.9541573602017
total_rewards_max            8204.183967603107
total_rewards_min            7512.206165304212
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               189.44145905273035
(Previous) Eval Time (s)     33.42576832603663
Sample Time (s)              7.106218527536839
Epoch Time (s)               229.97344590630382
Total Train Time (s)         31242.861330807675
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:17:25.771998 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #136 | Epoch Duration: 230.34640526771545
2020-01-13 08:17:25.772232 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4335542
Z variance train             0.021385022
KL Divergence                37.801205
KL Loss                      3.7801206
QF Loss                      82.99725
VF Loss                      59.36881
Policy Loss                  -929.6671
Q Predictions Mean           926.0463
Q Predictions Std            971.38165
Q Predictions Max            3336.7021
Q Predictions Min            384.78812
V Predictions Mean           928.18677
V Predictions Std            969.5138
V Predictions Max            3332.8232
V Predictions Min            389.5609
Log Pis Mean                 -0.43788916
Log Pis Std                  3.1867318
Log Pis Max                  9.983719
Log Pis Min                  -6.3121934
Policy mu Mean               -0.01704075
Policy mu Std                0.8673193
Policy mu Max                2.4992304
Policy mu Min                -2.6740441
Policy log std Mean          -0.50610906
Policy log std Std           0.24066505
Policy log std Max           -0.09979309
Policy log std Min           -2.5353322
Z mean eval                  2.4565077
Z variance eval              0.034558736
total_rewards                [7602.54236237 7793.89610619 7501.1264053  7827.50089521 7331.55685168
 7393.75886701 7166.00950398 7228.01105857 7806.61495705 7536.49323906]
total_rewards_mean           7518.751024640592
total_rewards_std            228.29024285790751
total_rewards_max            7827.500895207607
total_rewards_min            7166.0095039820435
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               189.2565226070583
(Previous) Eval Time (s)     36.0262319650501
Sample Time (s)              7.485669102985412
Epoch Time (s)               232.7684236750938
Total Train Time (s)         31476.01911923196
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:18.933614 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #137 | Epoch Duration: 233.16120290756226
2020-01-13 08:21:18.933816 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4617565
Z variance train             0.03458554
KL Divergence                36.12047
KL Loss                      3.612047
QF Loss                      124.19447
VF Loss                      142.68533
Policy Loss                  -882.2224
Q Predictions Mean           880.3359
Q Predictions Std            933.4264
Q Predictions Max            3314.1235
Q Predictions Min            378.59253
V Predictions Mean           883.70996
V Predictions Std            938.9664
V Predictions Max            3315.6516
V Predictions Min            388.24362
Log Pis Mean                 -0.7481433
Log Pis Std                  3.20961
Log Pis Max                  11.926431
Log Pis Min                  -7.0103416
Policy mu Mean               0.03915384
Policy mu Std                0.81581557
Policy mu Max                2.486092
Policy mu Min                -2.6313822
Policy log std Mean          -0.5131919
Policy log std Std           0.2321751
Policy log std Max           -0.16179207
Policy log std Min           -2.598116
Z mean eval                  2.4392478
Z variance eval              0.020503895
total_rewards                [7604.14928229 7769.66437874 7975.94798392 7763.2963247  7728.80765351
 7594.65702458 7379.90570538 7686.30679997 8144.24992978 7573.89394741]
total_rewards_mean           7722.087903028287
total_rewards_std            204.24276409574364
total_rewards_max            8144.249929783005
total_rewards_min            7379.905705384697
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               189.43001968832687
(Previous) Eval Time (s)     33.18735185125843
Sample Time (s)              7.756384338252246
Epoch Time (s)               230.37375587783754
Total Train Time (s)         31706.489751793444
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:25:09.406577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #138 | Epoch Duration: 230.4726104736328
2020-01-13 08:25:09.406766 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.438496
Z variance train             0.020534988
KL Divergence                36.425552
KL Loss                      3.6425552
QF Loss                      161.83325
VF Loss                      33.84757
Policy Loss                  -865.9298
Q Predictions Mean           859.0038
Q Predictions Std            905.93604
Q Predictions Max            3325.0935
Q Predictions Min            398.91727
V Predictions Mean           868.3714
V Predictions Std            909.4867
V Predictions Max            3318.9927
V Predictions Min            397.6663
Log Pis Mean                 -0.5559671
Log Pis Std                  3.4494925
Log Pis Max                  16.035597
Log Pis Min                  -7.135111
Policy mu Mean               0.025845012
Policy mu Std                0.80608386
Policy mu Max                3.316081
Policy mu Min                -3.0123026
Policy log std Mean          -0.5184739
Policy log std Std           0.24393946
Policy log std Max           -0.07308194
Policy log std Min           -2.4605505
Z mean eval                  2.460364
Z variance eval              0.018056598
total_rewards                [8110.50435416 8198.40613089 7811.57293849 8046.178153   8022.59043619
 7909.73388213 8033.2435753  7825.2804999  7960.47457992 7970.39089214]
total_rewards_mean           7988.837544213011
total_rewards_std            114.32264742961827
total_rewards_max            8198.406130894346
total_rewards_min            7811.572938489722
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               188.97370677767321
(Previous) Eval Time (s)     32.69222002290189
Sample Time (s)              6.975355749949813
Epoch Time (s)               228.64128255052492
Total Train Time (s)         31935.21349175414
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:28:58.135804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #139 | Epoch Duration: 228.72885584831238
2020-01-13 08:28:58.136145 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4574103
Z variance train             0.018050782
KL Divergence                37.485855
KL Loss                      3.7485855
QF Loss                      170.8916
VF Loss                      27.772957
Policy Loss                  -910.01013
Q Predictions Mean           909.45874
Q Predictions Std            965.26385
Q Predictions Max            3397.035
Q Predictions Min            407.82214
V Predictions Mean           909.1755
V Predictions Std            965.88275
V Predictions Max            3393.5674
V Predictions Min            409.93094
Log Pis Mean                 -0.8289524
Log Pis Std                  3.262939
Log Pis Max                  10.08011
Log Pis Min                  -7.895606
Policy mu Mean               0.02527651
Policy mu Std                0.8047192
Policy mu Max                2.3351636
Policy mu Min                -2.3687425
Policy log std Mean          -0.50888485
Policy log std Std           0.25027916
Policy log std Max           -0.058358535
Policy log std Min           -2.2670329
Z mean eval                  2.4420943
Z variance eval              0.042781565
total_rewards                [7326.86868833 7904.25261942 7238.24047055 7192.41373939 7670.46644805
 8015.03215464 7707.09260857 7752.03810904 7801.69277102 7935.66266472]
total_rewards_mean           7654.376027371558
total_rewards_std            282.79858287512536
total_rewards_max            8015.032154639624
total_rewards_min            7192.4137393850515
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               192.4433170990087
(Previous) Eval Time (s)     33.42434324789792
Sample Time (s)              12.456587087828666
Epoch Time (s)               238.3242474347353
Total Train Time (s)         32173.61901639169
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:32:56.541758 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #140 | Epoch Duration: 238.40536761283875
2020-01-13 08:32:56.541946 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.443235
Z variance train             0.042679798
KL Divergence                36.962013
KL Loss                      3.6962013
QF Loss                      2250.8833
VF Loss                      98.22241
Policy Loss                  -1018.2259
Q Predictions Mean           1016.6842
Q Predictions Std            1067.6129
Q Predictions Max            3424.75
Q Predictions Min            407.1838
V Predictions Mean           1019.1126
V Predictions Std            1067.016
V Predictions Max            3415.0557
V Predictions Min            411.83786
Log Pis Mean                 -0.41632098
Log Pis Std                  3.6328635
Log Pis Max                  14.661454
Log Pis Min                  -6.718545
Policy mu Mean               -0.040629182
Policy mu Std                0.8511532
Policy mu Max                3.3413663
Policy mu Min                -2.7644846
Policy log std Mean          -0.5097678
Policy log std Std           0.24557161
Policy log std Max           -0.1262691
Policy log std Min           -2.5021577
Z mean eval                  2.450964
Z variance eval              0.020245757
total_rewards                [7610.16400264 8167.85715014 8034.43545976 7973.06420345 8079.10232722
 7668.3936797  8287.01715892 8142.57249517 8224.32171959 7755.98394437]
total_rewards_mean           7994.29121409643
total_rewards_std            225.94763295242015
total_rewards_max            8287.017158923045
total_rewards_min            7610.164002639821
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               189.51768141891807
(Previous) Eval Time (s)     34.67302854685113
Sample Time (s)              7.918000520672649
Epoch Time (s)               232.10871048644185
Total Train Time (s)         32405.80845826678
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:48.733769 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #141 | Epoch Duration: 232.19162130355835
2020-01-13 08:36:48.734071 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.453533
Z variance train             0.020252999
KL Divergence                38.274616
KL Loss                      3.8274617
QF Loss                      1760.5719
VF Loss                      44.706528
Policy Loss                  -938.49005
Q Predictions Mean           938.78796
Q Predictions Std            992.0003
Q Predictions Max            3400.3496
Q Predictions Min            406.25668
V Predictions Mean           935.177
V Predictions Std            991.7609
V Predictions Max            3403.9744
V Predictions Min            406.4542
Log Pis Mean                 -0.8421882
Log Pis Std                  3.111061
Log Pis Max                  14.715842
Log Pis Min                  -6.1397905
Policy mu Mean               0.0029104936
Policy mu Std                0.8215266
Policy mu Max                2.753829
Policy mu Min                -2.6995716
Policy log std Mean          -0.502732
Policy log std Std           0.2382841
Policy log std Max           0.051635206
Policy log std Min           -2.2169936
Z mean eval                  2.434545
Z variance eval              0.040427107
total_rewards                [7790.91079799 8042.89089209 8214.28243082 8017.16301193 7877.70984398
 7834.79202495 8047.1823645  7796.98632955 8214.24350261 7520.74103466]
total_rewards_mean           7935.690223307813
total_rewards_std            202.90162538690484
total_rewards_max            8214.282430823994
total_rewards_min            7520.741034655006
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               185.78949133306742
(Previous) Eval Time (s)     33.94437266467139
Sample Time (s)              7.203561139293015
Epoch Time (s)               226.93742513703182
Total Train Time (s)         32632.86572125554
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:40:35.793416 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #142 | Epoch Duration: 227.0591516494751
2020-01-13 08:40:35.793637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4347901
Z variance train             0.040363967
KL Divergence                37.73094
KL Loss                      3.7730942
QF Loss                      148.65163
VF Loss                      99.083176
Policy Loss                  -945.47943
Q Predictions Mean           940.76715
Q Predictions Std            990.2711
Q Predictions Max            3418.6802
Q Predictions Min            414.7929
V Predictions Mean           945.3793
V Predictions Std            990.7983
V Predictions Max            3423.4075
V Predictions Min            419.57837
Log Pis Mean                 -0.44598737
Log Pis Std                  3.7620082
Log Pis Max                  18.813274
Log Pis Min                  -7.0585403
Policy mu Mean               -0.005984714
Policy mu Std                0.84403205
Policy mu Max                3.233542
Policy mu Min                -3.4572248
Policy log std Mean          -0.49363685
Policy log std Std           0.23793834
Policy log std Max           -0.0809108
Policy log std Min           -1.925804
Z mean eval                  2.4549763
Z variance eval              0.017129304
total_rewards                [7737.09118946 7583.49023642 7650.84979556 7302.64672881 7491.7471492
 7541.79455348 7560.37120202 7213.37205078 7531.92797035 7654.91718625]
total_rewards_mean           7526.820806233556
total_rewards_std            151.76533106681867
total_rewards_max            7737.091189459248
total_rewards_min            7213.37205078124
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               188.75108023919165
(Previous) Eval Time (s)     35.66905409377068
Sample Time (s)              7.871927188709378
Epoch Time (s)               232.2920615216717
Total Train Time (s)         32865.56003696658
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:44:28.489667 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #143 | Epoch Duration: 232.6958508491516
2020-01-13 08:44:28.489895 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.451989
Z variance train             0.01711126
KL Divergence                39.821247
KL Loss                      3.9821248
QF Loss                      240.22223
VF Loss                      65.36259
Policy Loss                  -955.2248
Q Predictions Mean           950.4901
Q Predictions Std            996.91473
Q Predictions Max            3432.1245
Q Predictions Min            402.91113
V Predictions Mean           960.33856
V Predictions Std            999.9071
V Predictions Max            3452.8645
V Predictions Min            419.00024
Log Pis Mean                 -0.8537336
Log Pis Std                  3.3091247
Log Pis Max                  13.799517
Log Pis Min                  -6.630972
Policy mu Mean               -0.015833778
Policy mu Std                0.8154041
Policy mu Max                2.8509712
Policy mu Min                -2.6844065
Policy log std Mean          -0.49694407
Policy log std Std           0.25097498
Policy log std Max           -0.06532925
Policy log std Min           -2.313974
Z mean eval                  2.3969705
Z variance eval              0.019061312
total_rewards                [8568.9938069  7670.36866068 7906.98265771 8013.59059721 8041.69852393
 8239.03319678 7855.79988142 8321.37216784 8280.70745707 8003.72521667]
total_rewards_mean           8090.227216621459
total_rewards_std            249.3186977483785
total_rewards_max            8568.993806896346
total_rewards_min            7670.368660684604
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               190.45833809580654
(Previous) Eval Time (s)     32.91480550682172
Sample Time (s)              7.236598138231784
Epoch Time (s)               230.60974174086004
Total Train Time (s)         33096.2489828337
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:48:19.180681 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #144 | Epoch Duration: 230.69063353538513
2020-01-13 08:48:19.180861 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.397958
Z variance train             0.019052982
KL Divergence                37.735416
KL Loss                      3.7735417
QF Loss                      416.45023
VF Loss                      170.37645
Policy Loss                  -873.056
Q Predictions Mean           869.2311
Q Predictions Std            929.8266
Q Predictions Max            3327.671
Q Predictions Min            387.02536
V Predictions Mean           880.9005
V Predictions Std            932.17334
V Predictions Max            3376.3616
V Predictions Min            406.09457
Log Pis Mean                 -1.0316837
Log Pis Std                  2.9424853
Log Pis Max                  16.590715
Log Pis Min                  -7.343934
Policy mu Mean               0.013464904
Policy mu Std                0.79654145
Policy mu Max                3.2063694
Policy mu Min                -2.4172504
Policy log std Mean          -0.50581557
Policy log std Std           0.24459854
Policy log std Max           -0.10103984
Policy log std Min           -2.7340689
Z mean eval                  2.3820121
Z variance eval              0.059666127
total_rewards                [8072.96970911 8313.27596896 7908.51073152 7899.99938429 8274.93323358
 7828.5869357  8027.39210784 8340.92667529 8107.51634279 8019.0415114 ]
total_rewards_mean           8079.315260047753
total_rewards_std            171.11461245557987
total_rewards_max            8340.926675289884
total_rewards_min            7828.586935697267
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               186.23980388743803
(Previous) Eval Time (s)     32.78355517424643
Sample Time (s)              6.790265255142003
Epoch Time (s)               225.81362431682646
Total Train Time (s)         33322.15053420514
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:52:05.083992 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #145 | Epoch Duration: 225.9029791355133
2020-01-13 08:52:05.084194 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.381345
Z variance train             0.05970981
KL Divergence                35.502483
KL Loss                      3.5502484
QF Loss                      110.070786
VF Loss                      31.60647
Policy Loss                  -931.32355
Q Predictions Mean           926.9535
Q Predictions Std            989.7077
Q Predictions Max            3352.3958
Q Predictions Min            417.36783
V Predictions Mean           931.5297
V Predictions Std            990.55255
V Predictions Max            3364.5774
V Predictions Min            425.23624
Log Pis Mean                 -0.54084647
Log Pis Std                  3.2436376
Log Pis Max                  11.507826
Log Pis Min                  -7.3960524
Policy mu Mean               0.013650741
Policy mu Std                0.82934767
Policy mu Max                2.5116994
Policy mu Min                -2.6647336
Policy log std Mean          -0.5124822
Policy log std Std           0.23803727
Policy log std Max           -0.12310234
Policy log std Min           -2.226531
Z mean eval                  2.455525
Z variance eval              0.028949032
total_rewards                [8041.6611443  8256.68601524 8217.67818411 8347.32058597 8402.46381841
 8573.36348262 8453.13539869 8235.67459436 8250.80846909 8229.26026431]
total_rewards_mean           8300.805195710282
total_rewards_std            140.6638739119889
total_rewards_max            8573.36348261686
total_rewards_min            8041.661144303913
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               187.87249122187495
(Previous) Eval Time (s)     32.77034089015797
Sample Time (s)              8.95713967224583
Epoch Time (s)               229.59997178427875
Total Train Time (s)         33551.848078162875
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:55:54.783715 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #146 | Epoch Duration: 229.69936656951904
2020-01-13 08:55:54.783911 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4549236
Z variance train             0.028992202
KL Divergence                38.878845
KL Loss                      3.8878846
QF Loss                      217.43782
VF Loss                      207.55768
Policy Loss                  -1069.8531
Q Predictions Mean           1065.5911
Q Predictions Std            1081.9735
Q Predictions Max            3373.544
Q Predictions Min            431.80606
V Predictions Mean           1073.9252
V Predictions Std            1082.7177
V Predictions Max            3376.5896
V Predictions Min            434.49365
Log Pis Mean                 -0.25295907
Log Pis Std                  3.8075497
Log Pis Max                  17.167421
Log Pis Min                  -6.754788
Policy mu Mean               -0.028548831
Policy mu Std                0.8840449
Policy mu Max                2.6410277
Policy mu Min                -2.675428
Policy log std Mean          -0.5257455
Policy log std Std           0.26357454
Policy log std Max           -0.08410376
Policy log std Min           -2.647852
Z mean eval                  2.43463
Z variance eval              0.04611974
total_rewards                [8088.65154537 8477.31308694 8291.42955463 8265.65274929 8103.65677057
 8244.83042986 8050.8538815  8393.78054313 8044.82815809 8266.34847725]
total_rewards_mean           8222.734519663049
total_rewards_std            140.13199472354734
total_rewards_max            8477.313086935903
total_rewards_min            8044.8281580934245
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               187.70842300308868
(Previous) Eval Time (s)     32.99558160593733
Sample Time (s)              7.324870076030493
Epoch Time (s)               228.0288746850565
Total Train Time (s)         33779.958659215365
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:59:42.896428 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #147 | Epoch Duration: 228.11234664916992
2020-01-13 08:59:42.896656 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4343686
Z variance train             0.0460349
KL Divergence                37.58741
KL Loss                      3.7587411
QF Loss                      1631.6514
VF Loss                      34.817684
Policy Loss                  -847.2244
Q Predictions Mean           846.75415
Q Predictions Std            902.2144
Q Predictions Max            3402.5667
Q Predictions Min            429.11472
V Predictions Mean           845.21643
V Predictions Std            902.64325
V Predictions Max            3411.0537
V Predictions Min            433.6635
Log Pis Mean                 -0.77142334
Log Pis Std                  3.1848004
Log Pis Max                  11.495791
Log Pis Min                  -6.208587
Policy mu Mean               0.01816806
Policy mu Std                0.8013299
Policy mu Max                2.6846983
Policy mu Min                -2.5337532
Policy log std Mean          -0.48598364
Policy log std Std           0.23951514
Policy log std Max           -0.09510419
Policy log std Min           -2.5827498
Z mean eval                  2.4011712
Z variance eval              0.066891775
total_rewards                [7591.44820583 7873.88138835 7892.00863662 8019.31542717 7669.80907053
 8002.387592   7976.39889044 7821.13713216 8141.68812838 7819.65352762]
total_rewards_mean           7880.772799909294
total_rewards_std            157.1259064532741
total_rewards_max            8141.688128376465
total_rewards_min            7591.448205827566
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               188.2878153352067
(Previous) Eval Time (s)     32.323953073937446
Sample Time (s)              6.726804852485657
Epoch Time (s)               227.3385732616298
Total Train Time (s)         34007.3859658842
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:03:30.327005 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #148 | Epoch Duration: 227.43017482757568
2020-01-13 09:03:30.327248 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4021747
Z variance train             0.06688098
KL Divergence                34.427364
KL Loss                      3.4427364
QF Loss                      195.75233
VF Loss                      54.435364
Policy Loss                  -1023.6353
Q Predictions Mean           1023.0609
Q Predictions Std            1055.9033
Q Predictions Max            3417.2322
Q Predictions Min            423.89938
V Predictions Mean           1020.86005
V Predictions Std            1053.4274
V Predictions Max            3416.551
V Predictions Min            421.51306
Log Pis Mean                 -0.33206195
Log Pis Std                  3.7508535
Log Pis Max                  15.281734
Log Pis Min                  -7.7785177
Policy mu Mean               -0.029444553
Policy mu Std                0.8632292
Policy mu Max                2.6837106
Policy mu Min                -2.3424075
Policy log std Mean          -0.5165652
Policy log std Std           0.23452973
Policy log std Max           -0.133264
Policy log std Min           -2.2750778
Z mean eval                  2.4419208
Z variance eval              0.026683161
total_rewards                [7456.09690126 6959.95167564 6831.45323564 7252.66427049 7102.63070254
 7400.4018499  8130.75286323 7141.32157154 7415.21181649 7418.39661665]
total_rewards_mean           7310.888150339783
total_rewards_std            339.4475194990347
total_rewards_max            8130.752863228237
total_rewards_min            6831.4532356412155
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               187.4606619873084
(Previous) Eval Time (s)     33.798020243644714
Sample Time (s)              7.493794263806194
Epoch Time (s)               228.75247649475932
Total Train Time (s)         34236.222359329
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:19.164633 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #149 | Epoch Duration: 228.8371958732605
2020-01-13 09:07:19.164828 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4428735
Z variance train             0.026665887
KL Divergence                38.256687
KL Loss                      3.8256688
QF Loss                      142.20737
VF Loss                      47.71485
Policy Loss                  -1025.1183
Q Predictions Mean           1022.65466
Q Predictions Std            1061.2374
Q Predictions Max            3618.6147
Q Predictions Min            424.19476
V Predictions Mean           1023.0142
V Predictions Std            1059.1815
V Predictions Max            3619.723
V Predictions Min            431.23138
Log Pis Mean                 -0.46575317
Log Pis Std                  3.400404
Log Pis Max                  13.370354
Log Pis Min                  -6.076937
Policy mu Mean               -0.08069101
Policy mu Std                0.8571596
Policy mu Max                2.7518475
Policy mu Min                -2.4584832
Policy log std Mean          -0.4880176
Policy log std Std           0.23299603
Policy log std Max           -0.100791186
Policy log std Min           -1.9172451
Z mean eval                  2.4408023
Z variance eval              0.02176003
total_rewards                [8012.8623353  8570.18949731 8553.25280326 8184.4029022  8362.21486546
 8531.68994633 8252.6310239  8063.44793361 8611.00960383 8222.28413419]
total_rewards_mean           8336.39850453931
total_rewards_std            209.3370280669032
total_rewards_max            8611.009603829803
total_rewards_min            8012.862335301304
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               183.67122075613588
(Previous) Eval Time (s)     34.78408143715933
Sample Time (s)              7.472439868375659
Epoch Time (s)               225.92774206167087
Total Train Time (s)         34462.22815411212
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:11:05.173030 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #150 | Epoch Duration: 226.00800490379333
2020-01-13 09:11:05.173297 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.441103
Z variance train             0.021792684
KL Divergence                37.85436
KL Loss                      3.785436
QF Loss                      171.13858
VF Loss                      49.920563
Policy Loss                  -1059.4562
Q Predictions Mean           1054.5092
Q Predictions Std            1086.8147
Q Predictions Max            3438.136
Q Predictions Min            418.77826
V Predictions Mean           1064.0557
V Predictions Std            1086.221
V Predictions Max            3435.1338
V Predictions Min            428.84702
Log Pis Mean                 -0.7647376
Log Pis Std                  2.9567878
Log Pis Max                  9.30682
Log Pis Min                  -5.814426
Policy mu Mean               -8.238541e-05
Policy mu Std                0.84509826
Policy mu Max                2.5636578
Policy mu Min                -2.4686785
Policy log std Mean          -0.5109148
Policy log std Std           0.23620805
Policy log std Max           -0.11414762
Policy log std Min           -2.2356033
Z mean eval                  2.4274163
Z variance eval              0.041576754
total_rewards                [8215.79406033 8585.76661177 8406.57707302 8429.32342471 8409.39854779
 8346.30453804 8708.24889517 8581.55332089 8569.86395624 8409.28916278]
total_rewards_mean           8466.211959073136
total_rewards_std            136.159658250957
total_rewards_max            8708.24889516517
total_rewards_min            8215.794060330676
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               187.20649427827448
(Previous) Eval Time (s)     32.65581464767456
Sample Time (s)              6.519315097946674
Epoch Time (s)               226.3816240238957
Total Train Time (s)         34688.69071672438
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:14:51.636544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #151 | Epoch Duration: 226.46307635307312
2020-01-13 09:14:51.636705 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4261456
Z variance train             0.041571252
KL Divergence                36.496033
KL Loss                      3.6496034
QF Loss                      309.8502
VF Loss                      56.867958
Policy Loss                  -940.3989
Q Predictions Mean           937.5719
Q Predictions Std            1016.1579
Q Predictions Max            3657.469
Q Predictions Min            433.12418
V Predictions Mean           940.6489
V Predictions Std            1010.85767
V Predictions Max            3648.3335
V Predictions Min            441.00647
Log Pis Mean                 -0.5808267
Log Pis Std                  3.7169852
Log Pis Max                  16.899899
Log Pis Min                  -6.126029
Policy mu Mean               -0.013443855
Policy mu Std                0.84090656
Policy mu Max                3.422895
Policy mu Min                -3.0878437
Policy log std Mean          -0.4859991
Policy log std Std           0.24320543
Policy log std Max           -0.03610775
Policy log std Min           -2.8200157
Z mean eval                  2.385617
Z variance eval              0.029302651
total_rewards                [8723.18447131 8576.2884879  8433.59246222 8752.97662148 8955.44079117
 8815.46926711 8604.48545638 8797.86625242 8501.78399497 8768.09782022]
total_rewards_mean           8692.918562518586
total_rewards_std            151.7665864387429
total_rewards_max            8955.440791171464
total_rewards_min            8433.592462216811
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               183.7330760443583
(Previous) Eval Time (s)     32.80384503304958
Sample Time (s)              8.241053423378617
Epoch Time (s)               224.7779745007865
Total Train Time (s)         34913.54829000402
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:18:36.497820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #152 | Epoch Duration: 224.86091589927673
2020-01-13 09:18:36.498135 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3842824
Z variance train             0.029244754
KL Divergence                36.329823
KL Loss                      3.6329823
QF Loss                      201.95436
VF Loss                      113.00283
Policy Loss                  -939.2903
Q Predictions Mean           937.0554
Q Predictions Std            1006.74445
Q Predictions Max            3570.082
Q Predictions Min            437.32504
V Predictions Mean           943.7345
V Predictions Std            1008.5738
V Predictions Max            3517.6672
V Predictions Min            442.40747
Log Pis Mean                 -0.653438
Log Pis Std                  3.1569183
Log Pis Max                  13.77956
Log Pis Min                  -6.6531563
Policy mu Mean               0.024634367
Policy mu Std                0.81865054
Policy mu Max                2.5277913
Policy mu Min                -2.1321766
Policy log std Mean          -0.48390737
Policy log std Std           0.25890428
Policy log std Max           -0.039681047
Policy log std Min           -2.429492
Z mean eval                  2.4107382
Z variance eval              0.026703525
total_rewards                [8438.40078423 8504.81689201 8329.44927514 8226.71461269 8401.13465788
 8201.05172343 8236.17663464 8644.30588384 8546.28802501 8113.00261428]
total_rewards_mean           8364.13411031553
total_rewards_std            162.62707667268072
total_rewards_max            8644.305883844898
total_rewards_min            8113.002614284515
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               188.59276571730152
(Previous) Eval Time (s)     31.05930149089545
Sample Time (s)              7.769247747492045
Epoch Time (s)               227.421314955689
Total Train Time (s)         35141.05434795609
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:24.006650 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #153 | Epoch Duration: 227.50828576087952
2020-01-13 09:22:24.006907 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.410052
Z variance train             0.026729828
KL Divergence                37.61958
KL Loss                      3.761958
QF Loss                      147.77911
VF Loss                      73.10322
Policy Loss                  -936.21747
Q Predictions Mean           931.9667
Q Predictions Std            985.10284
Q Predictions Max            3549.561
Q Predictions Min            447.737
V Predictions Mean           934.5985
V Predictions Std            980.8498
V Predictions Max            3545.6052
V Predictions Min            447.82178
Log Pis Mean                 -0.6068728
Log Pis Std                  3.617838
Log Pis Max                  16.975918
Log Pis Min                  -6.466221
Policy mu Mean               0.015531495
Policy mu Std                0.84715074
Policy mu Max                3.678093
Policy mu Min                -2.7194126
Policy log std Mean          -0.51668686
Policy log std Std           0.28193113
Policy log std Max           -0.13571486
Policy log std Min           -2.8680441
Z mean eval                  2.4010205
Z variance eval              0.024351044
total_rewards                [7656.43719101 7557.13793908 7605.70411354 7926.46195233 7470.30065966
 8121.96623449 7785.07206253 7762.65231795 7587.3479471  7406.72045645]
total_rewards_mean           7687.980087415548
total_rewards_std            205.35882457555238
total_rewards_max            8121.966234493
total_rewards_min            7406.720456447448
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               194.02972084190696
(Previous) Eval Time (s)     37.44425646774471
Sample Time (s)              6.820239259395748
Epoch Time (s)               238.29421656904742
Total Train Time (s)         35379.42982444726
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:26:22.384422 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #154 | Epoch Duration: 238.37723994255066
2020-01-13 09:26:22.384723 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4001315
Z variance train             0.024456937
KL Divergence                38.30935
KL Loss                      3.830935
QF Loss                      160.75885
VF Loss                      39.77053
Policy Loss                  -1011.9108
Q Predictions Mean           1012.45544
Q Predictions Std            1050.9266
Q Predictions Max            3714.857
Q Predictions Min            455.2223
V Predictions Mean           1009.239
V Predictions Std            1050.7587
V Predictions Max            3694.9321
V Predictions Min            452.19968
Log Pis Mean                 -0.3893494
Log Pis Std                  3.471801
Log Pis Max                  17.568985
Log Pis Min                  -6.6641197
Policy mu Mean               0.037640605
Policy mu Std                0.8472282
Policy mu Max                3.0713859
Policy mu Min                -2.5487046
Policy log std Mean          -0.5033818
Policy log std Std           0.2611123
Policy log std Max           -0.120228365
Policy log std Min           -2.1504774
Z mean eval                  2.4318862
Z variance eval              0.01848026
total_rewards                [8359.09960631 8462.57461542 8429.85127414 8504.57245606 8440.36888673
 8809.06571382 8744.53914393 8637.7102056  8206.04511215 8567.22120854]
total_rewards_mean           8516.104822271029
total_rewards_std            170.9885446987031
total_rewards_max            8809.065713822216
total_rewards_min            8206.045112152382
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               193.49760560085997
(Previous) Eval Time (s)     37.44096833700314
Sample Time (s)              6.835883586201817
Epoch Time (s)               237.77445752406493
Total Train Time (s)         35617.289683518466
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:30:20.246811 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #155 | Epoch Duration: 237.86189937591553
2020-01-13 09:30:20.246955 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.43255
Z variance train             0.01847331
KL Divergence                39.420536
KL Loss                      3.9420536
QF Loss                      180.69563
VF Loss                      65.22434
Policy Loss                  -1026.6808
Q Predictions Mean           1022.5934
Q Predictions Std            1055.5748
Q Predictions Max            3545.8652
Q Predictions Min            425.91577
V Predictions Mean           1028.4902
V Predictions Std            1057.2191
V Predictions Max            3565.6418
V Predictions Min            437.90088
Log Pis Mean                 -0.2282753
Log Pis Std                  3.562007
Log Pis Max                  12.933177
Log Pis Min                  -6.538318
Policy mu Mean               -0.0042193406
Policy mu Std                0.8617969
Policy mu Max                3.3179014
Policy mu Min                -2.7087696
Policy log std Mean          -0.5037536
Policy log std Std           0.25482628
Policy log std Max           -0.12580195
Policy log std Min           -2.5462065
Z mean eval                  2.3822465
Z variance eval              0.03597284
total_rewards                [8481.09808554 8270.09869373 8673.26617131 8651.53449512 8656.50862302
 8731.10812268 8549.93414666 8708.37942249 8760.98534585 8605.59437788]
total_rewards_mean           8608.850748428016
total_rewards_std            138.1288339015502
total_rewards_max            8760.985345848352
total_rewards_min            8270.098693729471
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               188.84211618313566
(Previous) Eval Time (s)     32.17677267920226
Sample Time (s)              6.602204966824502
Epoch Time (s)               227.62109382916242
Total Train Time (s)         35844.99907166185
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:07.962901 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #156 | Epoch Duration: 227.71571254730225
2020-01-13 09:34:07.963348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806229
Z variance train             0.035813265
KL Divergence                37.53037
KL Loss                      3.753037
QF Loss                      142.60754
VF Loss                      25.143818
Policy Loss                  -992.08435
Q Predictions Mean           988.6426
Q Predictions Std            1028.2407
Q Predictions Max            3539.6765
Q Predictions Min            412.41006
V Predictions Mean           992.99817
V Predictions Std            1026.6748
V Predictions Max            3523.2766
V Predictions Min            432.79877
Log Pis Mean                 -0.43874836
Log Pis Std                  3.3540568
Log Pis Max                  11.986463
Log Pis Min                  -7.2687507
Policy mu Mean               0.002115335
Policy mu Std                0.82752615
Policy mu Max                2.4634027
Policy mu Min                -2.3892293
Policy log std Mean          -0.4954954
Policy log std Std           0.2454772
Policy log std Max           -0.065368116
Policy log std Min           -2.4388871
Z mean eval                  2.4083314
Z variance eval              0.016944638
total_rewards                [8595.30874942 8569.19385631 8255.92559792 8863.72118696 8468.13717251
 8530.85397587 8651.09075762 8499.91467964 8317.40424212 8526.61270685]
total_rewards_mean           8527.816292521702
total_rewards_std            160.2637141216548
total_rewards_max            8863.721186956189
total_rewards_min            8255.925597924868
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               198.0911775860004
(Previous) Eval Time (s)     34.16549845645204
Sample Time (s)              6.083365375176072
Epoch Time (s)               238.34004141762853
Total Train Time (s)         36083.432064890396
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:38:06.397579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #157 | Epoch Duration: 238.43394899368286
2020-01-13 09:38:06.397782 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.408617
Z variance train             0.016952338
KL Divergence                39.224167
KL Loss                      3.9224167
QF Loss                      101.90656
VF Loss                      140.85748
Policy Loss                  -950.86444
Q Predictions Mean           947.59143
Q Predictions Std            1019.0214
Q Predictions Max            3654.6829
Q Predictions Min            449.51288
V Predictions Mean           952.0108
V Predictions Std            1017.97253
V Predictions Max            3653.8074
V Predictions Min            456.22366
Log Pis Mean                 -0.75190586
Log Pis Std                  3.4940977
Log Pis Max                  16.975677
Log Pis Min                  -7.0850964
Policy mu Mean               -0.017157141
Policy mu Std                0.8105603
Policy mu Max                2.8199656
Policy mu Min                -3.3168278
Policy log std Mean          -0.48851982
Policy log std Std           0.26559094
Policy log std Max           -0.047459215
Policy log std Min           -2.4339108
Z mean eval                  2.3644786
Z variance eval              0.033531446
total_rewards                [8194.79258731 7876.31937821 7705.81824568 7855.08232812 7785.27381777
 7732.28856559 8035.15333762 7876.09757788 7908.55425106 7654.49161247]
total_rewards_mean           7862.387170171007
total_rewards_std            152.8119297673611
total_rewards_max            8194.792587305226
total_rewards_min            7654.491612465896
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               197.94975996157154
(Previous) Eval Time (s)     33.53783855214715
Sample Time (s)              7.061828764155507
Epoch Time (s)               238.5494272778742
Total Train Time (s)         36322.06512250425
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:42:05.062770 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #158 | Epoch Duration: 238.66466903686523
2020-01-13 09:42:05.063267 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3643682
Z variance train             0.033506535
KL Divergence                37.90095
KL Loss                      3.790095
QF Loss                      162.48286
VF Loss                      42.545288
Policy Loss                  -1053.8499
Q Predictions Mean           1053.6443
Q Predictions Std            1076.2333
Q Predictions Max            3641.429
Q Predictions Min            452.18573
V Predictions Mean           1052.4365
V Predictions Std            1074.5343
V Predictions Max            3625.8093
V Predictions Min            454.8034
Log Pis Mean                 -0.4804741
Log Pis Std                  3.3176181
Log Pis Max                  14.158477
Log Pis Min                  -7.702931
Policy mu Mean               -0.03570349
Policy mu Std                0.8579585
Policy mu Max                2.5928962
Policy mu Min                -3.30721
Policy log std Mean          -0.5012321
Policy log std Std           0.23586692
Policy log std Max           -0.022967935
Policy log std Min           -2.246514
Z mean eval                  2.401785
Z variance eval              0.033095773
total_rewards                [8720.7373714  8788.79512857 8743.20980018 8919.29352166 8709.11913637
 9007.21325828 8577.27248909 8847.03159211 8852.16503881 8588.6427259 ]
total_rewards_mean           8775.348006237775
total_rewards_std            129.6904953012659
total_rewards_max            9007.21325827836
total_rewards_min            8577.272489094672
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               194.09355587605387
(Previous) Eval Time (s)     33.81753265298903
Sample Time (s)              6.451299498323351
Epoch Time (s)               234.36238802736625
Total Train Time (s)         36556.5367479478
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:45:59.506429 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #159 | Epoch Duration: 234.4428472518921
2020-01-13 09:45:59.506621 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.39893
Z variance train             0.03311574
KL Divergence                39.204338
KL Loss                      3.9204338
QF Loss                      1039.0142
VF Loss                      29.610615
Policy Loss                  -929.02167
Q Predictions Mean           926.9936
Q Predictions Std            969.4419
Q Predictions Max            3717.7683
Q Predictions Min            444.6311
V Predictions Mean           929.7678
V Predictions Std            968.43665
V Predictions Max            3714.0378
V Predictions Min            449.60745
Log Pis Mean                 -0.6953819
Log Pis Std                  3.3092232
Log Pis Max                  12.766029
Log Pis Min                  -6.328636
Policy mu Mean               0.032873247
Policy mu Std                0.8220893
Policy mu Max                2.412716
Policy mu Min                -2.544317
Policy log std Mean          -0.49159908
Policy log std Std           0.2448608
Policy log std Max           -0.048644423
Policy log std Min           -2.5689132
Z mean eval                  2.3931782
Z variance eval              0.030150067
total_rewards                [8502.30169584 8809.74648762 8747.01601004 8457.26619662 8597.08295006
 8857.59577888 8429.22602336 8696.61254487 8542.76407006 8679.02189081]
total_rewards_mean           8631.863364816025
total_rewards_std            141.33460074263786
total_rewards_max            8857.595778878405
total_rewards_min            8429.226023360043
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               199.36772057414055
(Previous) Eval Time (s)     30.6291898121126
Sample Time (s)              10.921960877254605
Epoch Time (s)               240.91887126350775
Total Train Time (s)         36797.55748072732
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:50:00.529753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #160 | Epoch Duration: 241.0229833126068
2020-01-13 09:50:00.529945 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.391074
Z variance train             0.030182594
KL Divergence                40.595993
KL Loss                      4.0595994
QF Loss                      101.57713
VF Loss                      45.682747
Policy Loss                  -929.54724
Q Predictions Mean           927.82416
Q Predictions Std            998.7584
Q Predictions Max            3749.7153
Q Predictions Min            446.6535
V Predictions Mean           930.10345
V Predictions Std            998.7908
V Predictions Max            3756.7117
V Predictions Min            461.16095
Log Pis Mean                 -0.7244947
Log Pis Std                  3.5495493
Log Pis Max                  14.913955
Log Pis Min                  -9.039433
Policy mu Mean               -0.027271008
Policy mu Std                0.83883435
Policy mu Max                2.6207418
Policy mu Min                -2.6898532
Policy log std Mean          -0.48002324
Policy log std Std           0.25564134
Policy log std Max           -0.089483336
Policy log std Min           -2.4878428
Z mean eval                  2.3704395
Z variance eval              0.021429483
total_rewards                [8188.00993228 7992.45706183 8226.80487096 8256.82734137 8112.56173741
 7912.66786965 8329.2987943  8370.57838679 8043.92822212 8043.94152134]
total_rewards_mean           8147.707573806115
total_rewards_std            143.02227732933807
total_rewards_max            8370.578386786183
total_rewards_min            7912.667869649577
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               196.66255162470043
(Previous) Eval Time (s)     31.88932300079614
Sample Time (s)              7.597680341918021
Epoch Time (s)               236.1495549674146
Total Train Time (s)         37033.787976080086
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:53:56.762371 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #161 | Epoch Duration: 236.23227095603943
2020-01-13 09:53:56.762572 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3699584
Z variance train             0.02142394
KL Divergence                41.927197
KL Loss                      4.19272
QF Loss                      247.38304
VF Loss                      91.23015
Policy Loss                  -1028.1499
Q Predictions Mean           1028.2803
Q Predictions Std            1051.1515
Q Predictions Max            3684.1255
Q Predictions Min            462.44177
V Predictions Mean           1028.582
V Predictions Std            1051.2755
V Predictions Max            3683.3772
V Predictions Min            461.41437
Log Pis Mean                 -0.52615726
Log Pis Std                  3.536072
Log Pis Max                  11.857637
Log Pis Min                  -7.487826
Policy mu Mean               0.047933694
Policy mu Std                0.83790576
Policy mu Max                3.1756723
Policy mu Min                -2.3073497
Policy log std Mean          -0.5018073
Policy log std Std           0.25625205
Policy log std Max           -0.08374104
Policy log std Min           -2.5049448
Z mean eval                  2.3613133
Z variance eval              0.018735815
total_rewards                [8185.10359605 8087.73635594 8249.80893125 8101.40697076 7874.59815712
 8461.98525439 8099.91360149 8219.9847572  8325.72027137 8221.54500142]
total_rewards_mean           8182.780289699423
total_rewards_std            149.42236904869657
total_rewards_max            8461.98525439442
total_rewards_min            7874.598157124048
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               195.7335666557774
(Previous) Eval Time (s)     30.269435283727944
Sample Time (s)              7.665997886098921
Epoch Time (s)               233.66899982560426
Total Train Time (s)         37267.55272126151
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:57:50.528963 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #162 | Epoch Duration: 233.76624059677124
2020-01-13 09:57:50.529152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3633246
Z variance train             0.01876519
KL Divergence                41.70572
KL Loss                      4.170572
QF Loss                      2303.0132
VF Loss                      340.29535
Policy Loss                  -1043.9248
Q Predictions Mean           1040.8677
Q Predictions Std            1083.8179
Q Predictions Max            3830.6365
Q Predictions Min            464.54535
V Predictions Mean           1034.9988
V Predictions Std            1078.4384
V Predictions Max            3832.4985
V Predictions Min            460.17862
Log Pis Mean                 -0.64613813
Log Pis Std                  3.72247
Log Pis Max                  12.42642
Log Pis Min                  -6.4657655
Policy mu Mean               0.056518864
Policy mu Std                0.8576335
Policy mu Max                3.3148782
Policy mu Min                -2.5855777
Policy log std Mean          -0.4943339
Policy log std Std           0.28522155
Policy log std Max           -0.117195725
Policy log std Min           -3.0814805
Z mean eval                  2.3622513
Z variance eval              0.02696138
total_rewards                [9059.56231234 8693.73896234 8996.9747272  8979.50167516 9108.76749884
 8827.81607944 8983.03567991 8617.54763339 8747.03333544 8605.48655568]
total_rewards_mean           8861.946445972413
total_rewards_std            177.44104693075488
total_rewards_max            9108.767498840212
total_rewards_min            8605.486555676236
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               200.35125959012657
(Previous) Eval Time (s)     32.11348411999643
Sample Time (s)              8.15147953806445
Epoch Time (s)               240.61622324818745
Total Train Time (s)         37508.24896263983
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:01:51.227405 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #163 | Epoch Duration: 240.69810438156128
2020-01-13 10:01:51.227601 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3636382
Z variance train             0.026809925
KL Divergence                40.019215
KL Loss                      4.0019217
QF Loss                      107.16016
VF Loss                      87.99205
Policy Loss                  -1001.6045
Q Predictions Mean           997.0319
Q Predictions Std            1052.9489
Q Predictions Max            3597.122
Q Predictions Min            456.28268
V Predictions Mean           1003.1428
V Predictions Std            1049.4785
V Predictions Max            3595.3853
V Predictions Min            468.79407
Log Pis Mean                 -0.43760437
Log Pis Std                  3.6693695
Log Pis Max                  17.908785
Log Pis Min                  -9.939147
Policy mu Mean               0.0039303224
Policy mu Std                0.870735
Policy mu Max                3.4142442
Policy mu Min                -2.9731653
Policy log std Mean          -0.48996362
Policy log std Std           0.25046095
Policy log std Max           -0.097969115
Policy log std Min           -2.2883236
Z mean eval                  2.3103528
Z variance eval              0.11827862
total_rewards                [8656.70730681 9193.40196892 8831.70032493 8975.86154642 8904.33779721
 9012.80527612 8830.09845887 9149.67973896 9104.37747677 9077.53677042]
total_rewards_mean           8973.650666542047
total_rewards_std            159.5967308912919
total_rewards_max            9193.401968917371
total_rewards_min            8656.707306806567
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               196.02842684229836
(Previous) Eval Time (s)     35.70406479202211
Sample Time (s)              6.472682774066925
Epoch Time (s)               238.2051744083874
Total Train Time (s)         37746.53782926407
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:49.518711 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #164 | Epoch Duration: 238.29096579551697
2020-01-13 10:05:49.518871 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3114974
Z variance train             0.117971204
KL Divergence                36.609097
KL Loss                      3.6609097
QF Loss                      446.14557
VF Loss                      182.06702
Policy Loss                  -1112.0112
Q Predictions Mean           1106.369
Q Predictions Std            1141.9031
Q Predictions Max            3652.7163
Q Predictions Min            455.81494
V Predictions Mean           1105.0681
V Predictions Std            1136.7875
V Predictions Max            3617.5466
V Predictions Min            453.9754
Log Pis Mean                 -0.18663669
Log Pis Std                  4.0769515
Log Pis Max                  14.794214
Log Pis Min                  -7.209957
Policy mu Mean               -0.0018674601
Policy mu Std                0.9294503
Policy mu Max                3.4533246
Policy mu Min                -3.052772
Policy log std Mean          -0.5008688
Policy log std Std           0.2832429
Policy log std Max           -0.0703316
Policy log std Min           -3.2746363
Z mean eval                  2.3182282
Z variance eval              0.051657032
total_rewards                [8566.42716807 8809.92943072 8724.7797057  8759.01628593 8718.96590759
 8581.3215382  8771.42591539 8395.68643011 8719.12859853 8637.78669957]
total_rewards_mean           8668.446767980206
total_rewards_std            118.51420322617773
total_rewards_max            8809.929430716506
total_rewards_min            8395.686430110623
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               197.59099452989176
(Previous) Eval Time (s)     33.323704125825316
Sample Time (s)              6.526736920699477
Epoch Time (s)               237.44143557641655
Total Train Time (s)         37984.264979748055
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:09:47.262157 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #165 | Epoch Duration: 237.7430717945099
2020-01-13 10:09:47.262540 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.314942
Z variance train             0.0516333
KL Divergence                37.548103
KL Loss                      3.7548103
QF Loss                      99.59041
VF Loss                      59.97848
Policy Loss                  -1118.8385
Q Predictions Mean           1116.389
Q Predictions Std            1119.8564
Q Predictions Max            3798.8843
Q Predictions Min            470.59732
V Predictions Mean           1122.4496
V Predictions Std            1116.5457
V Predictions Max            3792.187
V Predictions Min            475.96896
Log Pis Mean                 -0.23142137
Log Pis Std                  3.4500542
Log Pis Max                  12.430486
Log Pis Min                  -9.187861
Policy mu Mean               -0.06709383
Policy mu Std                0.89722794
Policy mu Max                2.532171
Policy mu Min                -2.5341225
Policy log std Mean          -0.4787682
Policy log std Std           0.24378482
Policy log std Max           -0.07532662
Policy log std Min           -2.5524812
Z mean eval                  2.3003447
Z variance eval              0.049869917
total_rewards                [7210.31501149 7385.0904048  7377.73855514 7349.05264029 7288.06871709
 7448.18574639 7309.04079067 7369.54716227 7281.29335468 7163.84031494]
total_rewards_mean           7318.21726977558
total_rewards_std            81.43945142422258
total_rewards_max            7448.18574639256
total_rewards_min            7163.840314941377
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               199.43184405192733
(Previous) Eval Time (s)     32.31514943391085
Sample Time (s)              6.853175998199731
Epoch Time (s)               238.6001694840379
Total Train Time (s)         38222.958453329746
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:13:45.961388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #166 | Epoch Duration: 238.69857382774353
2020-01-13 10:13:45.961737 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.303522
Z variance train             0.049889337
KL Divergence                38.856995
KL Loss                      3.8856995
QF Loss                      300.61078
VF Loss                      80.0616
Policy Loss                  -1003.47485
Q Predictions Mean           999.67554
Q Predictions Std            1029.0963
Q Predictions Max            3845.4558
Q Predictions Min            466.86002
V Predictions Mean           1004.9242
V Predictions Std            1023.5431
V Predictions Max            3825.0598
V Predictions Min            474.35315
Log Pis Mean                 -0.5781963
Log Pis Std                  3.448686
Log Pis Max                  10.962179
Log Pis Min                  -7.8570313
Policy mu Mean               0.0016051643
Policy mu Std                0.83515924
Policy mu Max                3.9298348
Policy mu Min                -3.3689697
Policy log std Mean          -0.4892186
Policy log std Std           0.25589645
Policy log std Max           -0.10398428
Policy log std Min           -2.341651
Z mean eval                  2.2710292
Z variance eval              0.026781734
total_rewards                [8694.44809912 8685.99666984 9081.98116063 8972.58432532 8958.48494829
 9040.28648814 8950.6418254  8941.2565976  8773.24332103 8556.23798707]
total_rewards_mean           8865.51614224411
total_rewards_std            166.17771763314994
total_rewards_max            9081.981160632307
total_rewards_min            8556.23798707052
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               198.89671636605635
(Previous) Eval Time (s)     34.86238725995645
Sample Time (s)              6.234475594013929
Epoch Time (s)               239.99357922002673
Total Train Time (s)         38463.05960456934
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:46.051273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #167 | Epoch Duration: 240.08925819396973
2020-01-13 10:17:46.051579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2699733
Z variance train             0.026800832
KL Divergence                39.189034
KL Loss                      3.9189034
QF Loss                      128.55154
VF Loss                      237.43484
Policy Loss                  -1034.8257
Q Predictions Mean           1032.4663
Q Predictions Std            1107.5192
Q Predictions Max            3884.0688
Q Predictions Min            485.05707
V Predictions Mean           1042.114
V Predictions Std            1110.1802
V Predictions Max            3907.3179
V Predictions Min            496.65436
Log Pis Mean                 -0.19098741
Log Pis Std                  3.798803
Log Pis Max                  16.456995
Log Pis Min                  -6.408305
Policy mu Mean               -0.0144683
Policy mu Std                0.8950655
Policy mu Max                3.5859604
Policy mu Min                -2.78806
Policy log std Mean          -0.5076646
Policy log std Std           0.26436257
Policy log std Max           -0.11920874
Policy log std Min           -2.5923493
Z mean eval                  2.2807145
Z variance eval              0.037931226
total_rewards                [9180.81612288 8970.39454771 8993.39471913 8727.8705477  8906.35381969
 8246.13775575 8593.41534246 8935.36251388 8973.43490433 8716.72736237]
total_rewards_mean           8824.390763590223
total_rewards_std            250.35955200667317
total_rewards_max            9180.816122881255
total_rewards_min            8246.137755749294
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               198.89640342770144
(Previous) Eval Time (s)     30.812013930641115
Sample Time (s)              6.347304398659617
Epoch Time (s)               236.05572175700217
Total Train Time (s)         38699.20297008287
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:21:42.196205 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #168 | Epoch Duration: 236.14438772201538
2020-01-13 10:21:42.196401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2802823
Z variance train             0.03773505
KL Divergence                39.588104
KL Loss                      3.9588106
QF Loss                      178.4272
VF Loss                      103.415245
Policy Loss                  -1088.6335
Q Predictions Mean           1087.0883
Q Predictions Std            1095.2692
Q Predictions Max            3747.6643
Q Predictions Min            482.1916
V Predictions Mean           1090.4331
V Predictions Std            1092.4391
V Predictions Max            3726.0815
V Predictions Min            480.59924
Log Pis Mean                 -0.31209958
Log Pis Std                  3.9853609
Log Pis Max                  23.534504
Log Pis Min                  -6.8441353
Policy mu Mean               0.040179763
Policy mu Std                0.8767543
Policy mu Max                3.1056058
Policy mu Min                -3.0495837
Policy log std Mean          -0.47908762
Policy log std Std           0.26310545
Policy log std Max           -0.11580089
Policy log std Min           -2.6125348
Z mean eval                  2.2833133
Z variance eval              0.029147863
total_rewards                [8962.98494372 9035.55390409 9021.71851021 8909.30098531 9191.39149857
 8965.3932313  9076.29841486 8957.56355805 9418.65681098 8874.59389496]
total_rewards_mean           9041.345575205763
total_rewards_std            151.88432571685905
total_rewards_max            9418.656810976787
total_rewards_min            8874.59389496461
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               196.0498073170893
(Previous) Eval Time (s)     33.40418306645006
Sample Time (s)              7.710145119111985
Epoch Time (s)               237.16413550265133
Total Train Time (s)         38936.44999478897
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:25:39.445910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #169 | Epoch Duration: 237.24937295913696
2020-01-13 10:25:39.446082 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2837746
Z variance train             0.02921823
KL Divergence                38.939167
KL Loss                      3.8939168
QF Loss                      146.66638
VF Loss                      56.60215
Policy Loss                  -956.54407
Q Predictions Mean           952.97546
Q Predictions Std            1008.6818
Q Predictions Max            3842.9302
Q Predictions Min            475.41208
V Predictions Mean           952.98425
V Predictions Std            1005.7913
V Predictions Max            3835.8267
V Predictions Min            476.27457
Log Pis Mean                 -0.61904925
Log Pis Std                  3.2093074
Log Pis Max                  11.307009
Log Pis Min                  -6.6387596
Policy mu Mean               8.5386135e-05
Policy mu Std                0.8261019
Policy mu Max                2.6744175
Policy mu Min                -2.3883657
Policy log std Mean          -0.47562027
Policy log std Std           0.24505259
Policy log std Max           -0.10382673
Policy log std Min           -2.3426585
Z mean eval                  2.3087955
Z variance eval              0.025946636
total_rewards                [8674.60088603 9264.95772349 9040.71744719 8875.32368912 9039.18840732
 9071.70940525 9207.48600539 8689.95433086 8548.246682   8754.30124146]
total_rewards_mean           8916.648581810927
total_rewards_std            231.11043944340977
total_rewards_max            9264.957723491116
total_rewards_min            8548.246681998251
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               194.3323347843252
(Previous) Eval Time (s)     32.99638127209619
Sample Time (s)              7.386443657334894
Epoch Time (s)               234.7151597137563
Total Train Time (s)         39171.25486123795
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:34.253053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #170 | Epoch Duration: 234.8068470954895
2020-01-13 10:29:34.253184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3091404
Z variance train             0.025981912
KL Divergence                39.71903
KL Loss                      3.9719028
QF Loss                      140.35406
VF Loss                      40.886326
Policy Loss                  -1001.37994
Q Predictions Mean           998.2178
Q Predictions Std            1044.3698
Q Predictions Max            3827.6138
Q Predictions Min            479.10153
V Predictions Mean           999.66504
V Predictions Std            1044.1139
V Predictions Max            3822.946
V Predictions Min            479.4585
Log Pis Mean                 -0.9838983
Log Pis Std                  3.2781224
Log Pis Max                  11.944997
Log Pis Min                  -8.56932
Policy mu Mean               -0.006694184
Policy mu Std                0.80537736
Policy mu Max                2.5846968
Policy mu Min                -2.9820664
Policy log std Mean          -0.4588132
Policy log std Std           0.23783255
Policy log std Max           -0.03527522
Policy log std Min           -2.461133
Z mean eval                  2.359784
Z variance eval              0.025709853
total_rewards                [8818.33547326 8492.13792654 8898.48301566 8578.84471955 8958.81423834
 8845.76924414 8596.4209952  8942.66124381 8748.43915313 8801.803892  ]
total_rewards_mean           8768.17099016182
total_rewards_std            153.41712820807751
total_rewards_max            8958.814238337623
total_rewards_min            8492.137926535344
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               196.17916781408712
(Previous) Eval Time (s)     30.792167284991592
Sample Time (s)              7.899895780719817
Epoch Time (s)               234.87123087979853
Total Train Time (s)         39406.204473697115
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:33:29.204315 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #171 | Epoch Duration: 234.95102429389954
2020-01-13 10:33:29.204476 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.357312
Z variance train             0.025624022
KL Divergence                41.346775
KL Loss                      4.1346774
QF Loss                      199.03947
VF Loss                      41.989563
Policy Loss                  -1077.2268
Q Predictions Mean           1074.8757
Q Predictions Std            1112.8358
Q Predictions Max            3921.1882
Q Predictions Min            485.56845
V Predictions Mean           1077.0552
V Predictions Std            1112.4027
V Predictions Max            3917.8225
V Predictions Min            487.9644
Log Pis Mean                 -0.13116074
Log Pis Std                  3.990454
Log Pis Max                  14.355639
Log Pis Min                  -8.463099
Policy mu Mean               0.014093048
Policy mu Std                0.90597266
Policy mu Max                3.3322797
Policy mu Min                -3.1072917
Policy log std Mean          -0.4757352
Policy log std Std           0.2720169
Policy log std Max           -0.055715263
Policy log std Min           -2.845032
Z mean eval                  2.2898388
Z variance eval              0.05128888
total_rewards                [8134.74931742 8272.56360352 8032.84040544 8151.28031079 8206.25503352
 8078.19573641 8122.13338502 8289.74541197 8009.64379549 8017.90058632]
total_rewards_mean           8131.530758590983
total_rewards_std            95.57574479910735
total_rewards_max            8289.745411969663
total_rewards_min            8009.643795492832
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               193.452646327205
(Previous) Eval Time (s)     33.01866207597777
Sample Time (s)              7.36119319871068
Epoch Time (s)               233.83250160189345
Total Train Time (s)         39640.12133622402
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:37:23.124611 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #172 | Epoch Duration: 233.9200098514557
2020-01-13 10:37:23.124803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2924302
Z variance train             0.051306866
KL Divergence                39.188835
KL Loss                      3.9188836
QF Loss                      153.90193
VF Loss                      94.07384
Policy Loss                  -1077.3982
Q Predictions Mean           1075.2045
Q Predictions Std            1124.3301
Q Predictions Max            3974.9548
Q Predictions Min            491.27002
V Predictions Mean           1076.7498
V Predictions Std            1119.2214
V Predictions Max            3930.162
V Predictions Min            493.89807
Log Pis Mean                 -0.15096813
Log Pis Std                  3.5597012
Log Pis Max                  13.984491
Log Pis Min                  -5.750243
Policy mu Mean               0.058429927
Policy mu Std                0.8852834
Policy mu Max                2.8424041
Policy mu Min                -2.9688127
Policy log std Mean          -0.49357298
Policy log std Std           0.2525545
Policy log std Max           -0.116827965
Policy log std Min           -2.4122944
Z mean eval                  2.3078835
Z variance eval              0.03721481
total_rewards                [8963.34439023 8670.90603288 8771.70969248 8674.54314814 8397.75687322
 8920.24549284 8519.67379112 8729.8549317  8535.08869988 8801.30083703]
total_rewards_mean           8698.442388952504
total_rewards_std            169.31870434746696
total_rewards_max            8963.344390231083
total_rewards_min            8397.756873220582
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               197.8335533021018
(Previous) Eval Time (s)     32.14479268388823
Sample Time (s)              7.247579722199589
Epoch Time (s)               237.2259257081896
Total Train Time (s)         39877.42880550772
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:20.437096 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #173 | Epoch Duration: 237.31214594841003
2020-01-13 10:41:20.437287 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3094192
Z variance train             0.03737718
KL Divergence                40.899113
KL Loss                      4.0899115
QF Loss                      484.09918
VF Loss                      36.22066
Policy Loss                  -1033.8115
Q Predictions Mean           1032.7866
Q Predictions Std            1077.9518
Q Predictions Max            3956.049
Q Predictions Min            498.20474
V Predictions Mean           1031.6249
V Predictions Std            1075.3484
V Predictions Max            3940.4712
V Predictions Min            497.98578
Log Pis Mean                 -0.1735796
Log Pis Std                  3.9081006
Log Pis Max                  16.397823
Log Pis Min                  -6.5450354
Policy mu Mean               0.0037498798
Policy mu Std                0.89895463
Policy mu Max                2.9203167
Policy mu Min                -2.752336
Policy log std Mean          -0.5025267
Policy log std Std           0.25291178
Policy log std Max           -0.09131494
Policy log std Min           -2.4862514
Z mean eval                  2.343226
Z variance eval              0.068926506
total_rewards                [8744.48583983 9101.33876328 8723.45275846 9008.38073501 8844.42175016
 8745.8343286  8790.94241495 9099.5310072  8824.63898044 8719.44524933]
total_rewards_mean           8860.247182725201
total_rewards_std            144.45617884325878
total_rewards_max            9101.33876327881
total_rewards_min            8719.445249328468
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               195.12323524383828
(Previous) Eval Time (s)     28.12844387581572
Sample Time (s)              6.517639393918216
Epoch Time (s)               229.76931851357222
Total Train Time (s)         40107.279744552914
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:10.291299 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #174 | Epoch Duration: 229.8538179397583
2020-01-13 10:45:10.291649 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3389204
Z variance train             0.06899841
KL Divergence                39.0654
KL Loss                      3.90654
QF Loss                      176.08322
VF Loss                      53.10522
Policy Loss                  -1029.9786
Q Predictions Mean           1029.4973
Q Predictions Std            1063.8231
Q Predictions Max            3883.9258
Q Predictions Min            495.3691
V Predictions Mean           1027.7915
V Predictions Std            1063.8817
V Predictions Max            3878.3232
V Predictions Min            494.9773
Log Pis Mean                 -0.6727686
Log Pis Std                  3.446114
Log Pis Max                  12.878304
Log Pis Min                  -5.6949406
Policy mu Mean               0.057530493
Policy mu Std                0.83889645
Policy mu Max                2.768176
Policy mu Min                -2.438661
Policy log std Mean          -0.49087262
Policy log std Std           0.24473692
Policy log std Max           -0.13019444
Policy log std Min           -2.5593834
Z mean eval                  2.3681538
Z variance eval              0.109321475
total_rewards                [9179.42395981 9091.00237103 9251.76079925 8883.71331038 8940.40068896
 9138.00908588 9112.95725029 9074.57368561 8958.7793845  9251.68938674]
total_rewards_mean           9088.230992245433
total_rewards_std            120.62307008397289
total_rewards_max            9251.760799249112
total_rewards_min            8883.713310382524
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               197.5254672942683
(Previous) Eval Time (s)     30.837706588208675
Sample Time (s)              8.624143915716559
Epoch Time (s)               236.98731779819354
Total Train Time (s)         40344.367971040774
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:49:07.384487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #175 | Epoch Duration: 237.09252262115479
2020-01-13 10:49:07.384719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3682654
Z variance train             0.10974483
KL Divergence                41.305637
KL Loss                      4.1305637
QF Loss                      155.4617
VF Loss                      47.836025
Policy Loss                  -1056.6034
Q Predictions Mean           1054.4651
Q Predictions Std            1109.5928
Q Predictions Max            3955.884
Q Predictions Min            498.40414
V Predictions Mean           1053.9542
V Predictions Std            1109.1448
V Predictions Max            3938.949
V Predictions Min            499.01935
Log Pis Mean                 -0.84310573
Log Pis Std                  3.6217184
Log Pis Max                  13.898384
Log Pis Min                  -7.5195312
Policy mu Mean               0.056850433
Policy mu Std                0.85179275
Policy mu Max                3.0497873
Policy mu Min                -2.9114144
Policy log std Mean          -0.48587584
Policy log std Std           0.24326774
Policy log std Max           -0.10178128
Policy log std Min           -2.6411989
Z mean eval                  2.3578823
Z variance eval              0.08422201
total_rewards                [9449.83121062 9337.51807639 9244.21798403 9393.29693313 5486.31430348
 9334.81316699 9283.12124911 9456.63716497 9415.07266468 9316.79254187]
total_rewards_mean           8971.761529526888
total_rewards_std            1163.701953401468
total_rewards_max            9456.637164965025
total_rewards_min            5486.314303482218
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               197.9632556163706
(Previous) Eval Time (s)     36.2925906162709
Sample Time (s)              8.177079770248383
Epoch Time (s)               242.43292600288987
Total Train Time (s)         40586.89197028754
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:09.909132 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #176 | Epoch Duration: 242.52417039871216
2020-01-13 10:53:09.909452 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3562572
Z variance train             0.08468657
KL Divergence                41.264973
KL Loss                      4.1264973
QF Loss                      76.04454
VF Loss                      75.56843
Policy Loss                  -927.90063
Q Predictions Mean           924.6224
Q Predictions Std            958.12964
Q Predictions Max            3937.5962
Q Predictions Min            495.21268
V Predictions Mean           922.8439
V Predictions Std            953.89825
V Predictions Max            3908.3904
V Predictions Min            496.81165
Log Pis Mean                 -0.7244475
Log Pis Std                  3.0936513
Log Pis Max                  13.179373
Log Pis Min                  -7.632245
Policy mu Mean               0.053211674
Policy mu Std                0.8211501
Policy mu Max                3.070564
Policy mu Min                -2.3502564
Policy log std Mean          -0.49579993
Policy log std Std           0.24871673
Policy log std Max           -0.092000306
Policy log std Min           -2.626874
Z mean eval                  2.3649364
Z variance eval              0.08436237
total_rewards                [8760.45598647 8615.7440391  8826.68647303 8762.05404292 8791.09239557
 8895.6295646  8771.56275341 8660.41083232 8721.7535207  9130.66078769]
total_rewards_mean           8793.605039581515
total_rewards_std            134.9941984872432
total_rewards_max            9130.660787686355
total_rewards_min            8615.744039104004
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               195.45036283927038
(Previous) Eval Time (s)     32.32362456386909
Sample Time (s)              7.126255128998309
Epoch Time (s)               234.90024253213778
Total Train Time (s)         40821.87402334763
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:57:04.893122 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #177 | Epoch Duration: 234.98348188400269
2020-01-13 10:57:04.893310 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #177 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364962
Z variance train             0.08419279
KL Divergence                38.73901
KL Loss                      3.8739011
QF Loss                      555.95984
VF Loss                      47.925434
Policy Loss                  -1025.5249
Q Predictions Mean           1021.458
Q Predictions Std            1074.389
Q Predictions Max            3916.4417
Q Predictions Min            507.925
V Predictions Mean           1023.17505
V Predictions Std            1071.8136
V Predictions Max            3913.1392
V Predictions Min            509.5965
Log Pis Mean                 -0.5243333
Log Pis Std                  3.3430274
Log Pis Max                  16.457365
Log Pis Min                  -6.862321
Policy mu Mean               0.040033214
Policy mu Std                0.8438345
Policy mu Max                3.4411666
Policy mu Min                -3.3528495
Policy log std Mean          -0.4862926
Policy log std Std           0.25589362
Policy log std Max           -0.12389217
Policy log std Min           -2.4172962
Z mean eval                  2.3875651
Z variance eval              0.07194315
total_rewards                [8871.05892346 9281.79543326 9170.92855801 9217.43399196 9178.9466165
 8933.77566136 9099.15263321 8998.08841932 9173.82975847 8957.45179516]
total_rewards_mean           9088.246179071652
total_rewards_std            131.50067949848128
total_rewards_max            9281.795433261937
total_rewards_min            8871.058923460205
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               194.72038896894082
(Previous) Eval Time (s)     36.13250879524276
Sample Time (s)              6.969183281995356
Epoch Time (s)               237.82208104617894
Total Train Time (s)         41059.78170217993
Epoch                        178
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:01:02.806807 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #178 | Epoch Duration: 237.91323804855347
2020-01-13 11:01:02.807247 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3897436
Z variance train             0.0719074
KL Divergence                39.270245
KL Loss                      3.9270246
QF Loss                      507.62158
VF Loss                      39.65754
Policy Loss                  -1046.1512
Q Predictions Mean           1045.5496
Q Predictions Std            1070.3596
Q Predictions Max            4030.1887
Q Predictions Min            522.72156
V Predictions Mean           1045.6643
V Predictions Std            1070.9613
V Predictions Max            4012.0583
V Predictions Min            523.43756
Log Pis Mean                 -0.71079004
Log Pis Std                  3.379068
Log Pis Max                  11.891918
Log Pis Min                  -7.207199
Policy mu Mean               0.02919921
Policy mu Std                0.8311736
Policy mu Max                2.707872
Policy mu Min                -2.9856994
Policy log std Mean          -0.4756404
Policy log std Std           0.2469254
Policy log std Max           -0.09751761
Policy log std Min           -2.4466841
Z mean eval                  2.3682697
Z variance eval              0.043527268
total_rewards                [8735.07419231 8509.20303536 8767.04949921 8943.61500093 8818.03291428
 8490.58425159 8807.85767147 8474.89690396 8290.90840022 8570.98511287]
total_rewards_mean           8640.820698221603
total_rewards_std            192.4962001968341
total_rewards_max            8943.615000932388
total_rewards_min            8290.90840022325
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               195.43024510424584
(Previous) Eval Time (s)     32.68013679375872
Sample Time (s)              7.097317824605852
Epoch Time (s)               235.2076997226104
Total Train Time (s)         41295.12322419882
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:04:58.151323 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #179 | Epoch Duration: 235.3437843322754
2020-01-13 11:04:58.151587 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3651485
Z variance train             0.043712884
KL Divergence                40.067127
KL Loss                      4.006713
QF Loss                      112.251785
VF Loss                      50.990166
Policy Loss                  -957.12384
Q Predictions Mean           957.0607
Q Predictions Std            1009.67206
Q Predictions Max            4004.353
Q Predictions Min            505.54034
V Predictions Mean           960.984
V Predictions Std            1010.44977
V Predictions Max            3996.398
V Predictions Min            508.30478
Log Pis Mean                 -0.74656963
Log Pis Std                  3.175733
Log Pis Max                  10.655453
Log Pis Min                  -8.167763
Policy mu Mean               0.001932978
Policy mu Std                0.8418178
Policy mu Max                2.7178326
Policy mu Min                -2.4440608
Policy log std Mean          -0.4933013
Policy log std Std           0.24981159
Policy log std Max           -0.12329364
Policy log std Min           -2.8165975
Z mean eval                  2.3404956
Z variance eval              0.019968811
total_rewards                [9289.8031044  9663.00236951 9458.46741204 9673.0847231  9501.34171516
 9149.74437415 9469.14496772 9555.32668776 9596.38150284 9498.81072197]
total_rewards_mean           9485.510757864291
total_rewards_std            153.72738556977382
total_rewards_max            9673.084723095564
total_rewards_min            9149.744374154994
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               199.09679378801957
(Previous) Eval Time (s)     36.165040674153715
Sample Time (s)              10.662934507708997
Epoch Time (s)               245.92476896988228
Total Train Time (s)         41541.12898805132
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:04.162642 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #180 | Epoch Duration: 246.0108449459076
2020-01-13 11:09:04.162843 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3404963
Z variance train             0.01990588
KL Divergence                42.12699
KL Loss                      4.2126994
QF Loss                      2607.061
VF Loss                      82.18762
Policy Loss                  -1103.7286
Q Predictions Mean           1100.7778
Q Predictions Std            1132.986
Q Predictions Max            4045.5864
Q Predictions Min            504.82565
V Predictions Mean           1101.3787
V Predictions Std            1134.9015
V Predictions Max            4031.5596
V Predictions Min            506.20343
Log Pis Mean                 -0.4496723
Log Pis Std                  3.5047183
Log Pis Max                  10.791496
Log Pis Min                  -9.0592575
Policy mu Mean               -0.0012815073
Policy mu Std                0.85642934
Policy mu Max                2.7316482
Policy mu Min                -2.5072553
Policy log std Mean          -0.5020817
Policy log std Std           0.27505633
Policy log std Max           -0.086660564
Policy log std Min           -2.6794057
Z mean eval                  2.325675
Z variance eval              0.028969437
total_rewards                [9454.47045383 8895.69014442 9044.74476337 9352.18296908 9200.6200045
 9257.43122145 9221.94254883 9258.20798189 8966.69977295 9270.51139267]
total_rewards_mean           9192.250125299546
total_rewards_std            164.49685885189854
total_rewards_max            9454.470453826707
total_rewards_min            8895.690144420056
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               193.54775823000818
(Previous) Eval Time (s)     36.5919778579846
Sample Time (s)              7.347154021263123
Epoch Time (s)               237.4868901092559
Total Train Time (s)         41778.70514441747
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:13:01.740772 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #181 | Epoch Duration: 237.57777214050293
2020-01-13 11:13:01.740952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3246136
Z variance train             0.028941948
KL Divergence                41.14902
KL Loss                      4.114902
QF Loss                      71.63379
VF Loss                      63.279808
Policy Loss                  -874.465
Q Predictions Mean           869.8053
Q Predictions Std            909.2192
Q Predictions Max            3810.5908
Q Predictions Min            479.2965
V Predictions Mean           874.1233
V Predictions Std            906.6177
V Predictions Max            3796.4966
V Predictions Min            488.32666
Log Pis Mean                 -0.9630003
Log Pis Std                  3.1055448
Log Pis Max                  14.797337
Log Pis Min                  -8.5580225
Policy mu Mean               -0.0053083613
Policy mu Std                0.7979719
Policy mu Max                3.8892438
Policy mu Min                -3.238409
Policy log std Mean          -0.4941754
Policy log std Std           0.27337456
Policy log std Max           -0.07473646
Policy log std Min           -3.0326204
Z mean eval                  2.3618453
Z variance eval              0.028526064
total_rewards                [9155.51543516 9243.65516278 9096.0662158  9142.83527011 8789.66963443
 9393.02818195 9211.53807395 9313.63304777 9232.77407008 9347.72467988]
total_rewards_mean           9192.643977190863
total_rewards_std            160.93066277757248
total_rewards_max            9393.028181954636
total_rewards_min            8789.669634430637
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               195.55711871990934
(Previous) Eval Time (s)     31.17698450991884
Sample Time (s)              7.028492461424321
Epoch Time (s)               233.7625956912525
Total Train Time (s)         42012.55557222292
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:16:55.591594 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #182 | Epoch Duration: 233.85049962997437
2020-01-13 11:16:55.591777 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3612041
Z variance train             0.028543513
KL Divergence                42.02036
KL Loss                      4.202036
QF Loss                      114.85153
VF Loss                      62.616753
Policy Loss                  -1009.4642
Q Predictions Mean           1007.29834
Q Predictions Std            1040.5133
Q Predictions Max            3968.747
Q Predictions Min            522.11786
V Predictions Mean           1004.16797
V Predictions Std            1039.2086
V Predictions Max            3939.5686
V Predictions Min            530.3583
Log Pis Mean                 -0.4399762
Log Pis Std                  3.412522
Log Pis Max                  14.102625
Log Pis Min                  -6.460994
Policy mu Mean               -0.021317622
Policy mu Std                0.8617114
Policy mu Max                3.0762935
Policy mu Min                -2.8615162
Policy log std Mean          -0.4897578
Policy log std Std           0.24148908
Policy log std Max           -0.05374056
Policy log std Min           -2.6651566
Z mean eval                  2.3313406
Z variance eval              0.03575007
total_rewards                [9394.17973594 9117.50228394 9160.541132   9331.01140419 9060.23537465
 9197.59125649 9028.54341647 9085.80917295 9124.54359397 9376.73250218]
total_rewards_mean           9187.668987277002
total_rewards_std            126.73476186379303
total_rewards_max            9394.179735935013
total_rewards_min            9028.543416470686
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               196.28275192994624
(Previous) Eval Time (s)     32.723115116823465
Sample Time (s)              6.626898911315948
Epoch Time (s)               235.63276595808566
Total Train Time (s)         42248.29936787393
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:51.336744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #183 | Epoch Duration: 235.74483060836792
2020-01-13 11:20:51.336892 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3322492
Z variance train             0.035630114
KL Divergence                41.76643
KL Loss                      4.176643
QF Loss                      269.70367
VF Loss                      96.57024
Policy Loss                  -1189.5696
Q Predictions Mean           1182.8826
Q Predictions Std            1220.2384
Q Predictions Max            3993.1895
Q Predictions Min            503.40826
V Predictions Mean           1184.577
V Predictions Std            1215.7865
V Predictions Max            3958.8838
V Predictions Min            504.36282
Log Pis Mean                 0.06853464
Log Pis Std                  3.997225
Log Pis Max                  17.068802
Log Pis Min                  -6.175335
Policy mu Mean               0.037234515
Policy mu Std                0.9275935
Policy mu Max                3.2156656
Policy mu Min                -3.1284397
Policy log std Mean          -0.528178
Policy log std Std           0.3041473
Policy log std Max           -0.11875394
Policy log std Min           -2.8539553
Z mean eval                  2.3544145
Z variance eval              0.05076114
total_rewards                [9519.55200878 9588.11546725 9245.14298724 9546.79803891 9581.26847582
 9554.62852686 9397.66427958 9548.45585438 9620.7184494  9499.7112934 ]
total_rewards_mean           9510.205538163644
total_rewards_std            105.46548151362869
total_rewards_max            9620.71844940435
total_rewards_min            9245.142987238853
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               196.1926587941125
(Previous) Eval Time (s)     30.643963272683322
Sample Time (s)              7.951398191973567
Epoch Time (s)               234.7880202587694
Total Train Time (s)         42483.1818630551
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:46.225154 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #184 | Epoch Duration: 234.8881323337555
2020-01-13 11:24:46.225361 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.352823
Z variance train             0.050807774
KL Divergence                41.359863
KL Loss                      4.1359863
QF Loss                      2440.667
VF Loss                      44.275246
Policy Loss                  -1009.2772
Q Predictions Mean           1011.0812
Q Predictions Std            1059.8021
Q Predictions Max            3901.2322
Q Predictions Min            518.06036
V Predictions Mean           1010.7401
V Predictions Std            1055.8822
V Predictions Max            3889.5964
V Predictions Min            515.98224
Log Pis Mean                 -0.6152626
Log Pis Std                  3.3431647
Log Pis Max                  11.686294
Log Pis Min                  -6.991334
Policy mu Mean               0.09035567
Policy mu Std                0.8369027
Policy mu Max                2.5932798
Policy mu Min                -2.4114063
Policy log std Mean          -0.49345264
Policy log std Std           0.26267377
Policy log std Max           -0.051678658
Policy log std Min           -2.5566027
Z mean eval                  2.3417907
Z variance eval              0.059282504
total_rewards                [9409.54030483 9264.21900849 9089.22118808 9481.01094429 9574.91658995
 9332.09556092 9245.62334394 9363.32538991 9525.85656746 9572.78526281]
total_rewards_mean           9385.859416068803
total_rewards_std            150.250725400147
total_rewards_max            9574.916589949018
total_rewards_min            9089.221188080159
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               196.36968523124233
(Previous) Eval Time (s)     32.48384229000658
Sample Time (s)              7.58120169211179
Epoch Time (s)               236.4347292133607
Total Train Time (s)         42719.69983329112
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:42.744652 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #185 | Epoch Duration: 236.51913595199585
2020-01-13 11:28:42.744841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3403482
Z variance train             0.059325766
KL Divergence                40.58191
KL Loss                      4.058191
QF Loss                      212.2445
VF Loss                      69.50513
Policy Loss                  -1047.3875
Q Predictions Mean           1044.5897
Q Predictions Std            1097.2023
Q Predictions Max            4079.0474
Q Predictions Min            506.7822
V Predictions Mean           1052.5375
V Predictions Std            1098.2747
V Predictions Max            4076.4248
V Predictions Min            517.3215
Log Pis Mean                 -0.5186356
Log Pis Std                  3.6294613
Log Pis Max                  14.2994995
Log Pis Min                  -6.149392
Policy mu Mean               0.0019906356
Policy mu Std                0.86247426
Policy mu Max                3.049921
Policy mu Min                -2.9593554
Policy log std Mean          -0.4885924
Policy log std Std           0.2699246
Policy log std Max           -0.058009505
Policy log std Min           -2.561809
Z mean eval                  2.3681004
Z variance eval              0.058739044
total_rewards                [8641.97764157 8223.97308728 8280.83888131 8812.62340745 8805.75153039
 7992.44376026 8279.17262205 8237.59997697 8228.15378803 8413.62552442]
total_rewards_mean           8391.616021971717
total_rewards_std            259.75361054639797
total_rewards_max            8812.623407446341
total_rewards_min            7992.443760258882
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               195.6841295468621
(Previous) Eval Time (s)     32.90039739198983
Sample Time (s)              6.855395201127976
Epoch Time (s)               235.4399221399799
Total Train Time (s)         42955.22168440092
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:32:38.269515 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #186 | Epoch Duration: 235.52453637123108
2020-01-13 11:32:38.269683 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.368241
Z variance train             0.058682095
KL Divergence                40.663834
KL Loss                      4.0663834
QF Loss                      190.59494
VF Loss                      44.907013
Policy Loss                  -1153.7201
Q Predictions Mean           1150.4088
Q Predictions Std            1179.792
Q Predictions Max            3973.588
Q Predictions Min            509.30795
V Predictions Mean           1155.9043
V Predictions Std            1180.5265
V Predictions Max            3983.7434
V Predictions Min            516.30676
Log Pis Mean                 -0.35869968
Log Pis Std                  3.4656475
Log Pis Max                  11.154762
Log Pis Min                  -5.5102153
Policy mu Mean               0.05528908
Policy mu Std                0.87815785
Policy mu Max                3.1176233
Policy mu Min                -2.5381432
Policy log std Mean          -0.51153344
Policy log std Std           0.27603218
Policy log std Max           -0.014272153
Policy log std Min           -2.6316347
Z mean eval                  2.3657556
Z variance eval              0.064892136
total_rewards                [8608.91448419 8773.62010486 8853.34900773 8819.47272818 8724.94235992
 9083.5796749  8752.45984179 9061.07821103 8618.69820707 8327.57784595]
total_rewards_mean           8762.369246559641
total_rewards_std            209.47557207639295
total_rewards_max            9083.57967489664
total_rewards_min            8327.577845946158
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               195.31667242618278
(Previous) Eval Time (s)     31.206304964609444
Sample Time (s)              6.666143889538944
Epoch Time (s)               233.18912128033116
Total Train Time (s)         43188.49111136794
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:31.540639 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #187 | Epoch Duration: 233.27081990242004
2020-01-13 11:36:31.540804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #187 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3655837
Z variance train             0.06489935
KL Divergence                40.682476
KL Loss                      4.068248
QF Loss                      143.45584
VF Loss                      74.50597
Policy Loss                  -1150.0604
Q Predictions Mean           1146.8062
Q Predictions Std            1203.0219
Q Predictions Max            4141.8647
Q Predictions Min            514.64764
V Predictions Mean           1151.4204
V Predictions Std            1206.2262
V Predictions Max            4147.5786
V Predictions Min            524.29535
Log Pis Mean                 -0.17327344
Log Pis Std                  3.7422612
Log Pis Max                  13.66614
Log Pis Min                  -9.269585
Policy mu Mean               0.059938192
Policy mu Std                0.8943024
Policy mu Max                2.7013958
Policy mu Min                -2.5142655
Policy log std Mean          -0.5105701
Policy log std Std           0.26624337
Policy log std Max           -0.14720133
Policy log std Min           -2.4341984
Z mean eval                  2.403944
Z variance eval              0.05675576
total_rewards                [8825.09249369 9375.83154944 9232.6841775  9278.49532385 9092.18995
 9572.37030468 9255.93111417 9669.36504722 9817.37245788 9456.33281909]
total_rewards_mean           9357.566523751218
total_rewards_std            274.04375617358335
total_rewards_max            9817.372457882091
total_rewards_min            8825.092493694128
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               196.49476894922554
(Previous) Eval Time (s)     34.24799347203225
Sample Time (s)              7.020607649348676
Epoch Time (s)               237.76337007060647
Total Train Time (s)         43426.338152546436
Epoch                        188
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:40:29.389870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #188 | Epoch Duration: 237.84893107414246
2020-01-13 11:40:29.390041 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4021149
Z variance train             0.056984086
KL Divergence                41.93605
KL Loss                      4.193605
QF Loss                      127.29078
VF Loss                      75.160034
Policy Loss                  -1132.3429
Q Predictions Mean           1133.2374
Q Predictions Std            1176.9775
Q Predictions Max            4101.3228
Q Predictions Min            528.1935
V Predictions Mean           1138.9001
V Predictions Std            1177.3298
V Predictions Max            4086.3323
V Predictions Min            535.1124
Log Pis Mean                 -0.5810492
Log Pis Std                  3.776583
Log Pis Max                  16.62828
Log Pis Min                  -6.7842464
Policy mu Mean               0.014035188
Policy mu Std                0.8464262
Policy mu Max                3.0436695
Policy mu Min                -2.8239121
Policy log std Mean          -0.50852287
Policy log std Std           0.26015088
Policy log std Max           -0.10715349
Policy log std Min           -2.6100898
Z mean eval                  2.383393
Z variance eval              0.034094267
total_rewards                [9522.39834249 9180.69086288 9418.73406872 9082.21109948 9181.84042333
 9055.38668768 9441.92806359 9437.186917   9492.32699168 9295.44573172]
total_rewards_mean           9310.814918854496
total_rewards_std            165.47732447431275
total_rewards_max            9522.398342491764
total_rewards_min            9055.386687677477
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               196.49217834230512
(Previous) Eval Time (s)     35.89029821520671
Sample Time (s)              7.03850485291332
Epoch Time (s)               239.42098141042516
Total Train Time (s)         43665.84477289766
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:44:28.901949 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #189 | Epoch Duration: 239.51172804832458
2020-01-13 11:44:28.902300 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806307
Z variance train             0.03416244
KL Divergence                42.82197
KL Loss                      4.2821975
QF Loss                      95.20988
VF Loss                      67.0311
Policy Loss                  -1208.1188
Q Predictions Mean           1207.3545
Q Predictions Std            1220.9912
Q Predictions Max            4098.0083
Q Predictions Min            512.36316
V Predictions Mean           1213.7397
V Predictions Std            1222.4268
V Predictions Max            4090.5256
V Predictions Min            523.05054
Log Pis Mean                 -0.05549048
Log Pis Std                  3.4807446
Log Pis Max                  12.342579
Log Pis Min                  -5.7298465
Policy mu Mean               0.0109849945
Policy mu Std                0.88339883
Policy mu Max                2.5949845
Policy mu Min                -2.569033
Policy log std Mean          -0.51387537
Policy log std Std           0.28160575
Policy log std Max           -0.07037632
Policy log std Min           -2.6221852
Z mean eval                  2.3746004
Z variance eval              0.061400145
total_rewards                [9439.52122128 9211.88150825 9428.51877392 9489.53696574 9678.67408414
 9498.49316425 9260.90819745 9426.27312434 9413.65388503 9465.62201485]
total_rewards_mean           9431.30829392534
total_rewards_std            121.6010783125786
total_rewards_max            9678.674084139971
total_rewards_min            9211.88150825419
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               196.51231682812795
(Previous) Eval Time (s)     35.08706777309999
Sample Time (s)              6.799885699991137
Epoch Time (s)               238.39927030121908
Total Train Time (s)         43904.3501604842
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:27.410968 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #190 | Epoch Duration: 238.5084047317505
2020-01-13 11:48:27.411190 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3735797
Z variance train             0.0613536
KL Divergence                42.327995
KL Loss                      4.2327995
QF Loss                      247.96207
VF Loss                      148.09006
Policy Loss                  -948.4408
Q Predictions Mean           943.31946
Q Predictions Std            957.2378
Q Predictions Max            4067.2493
Q Predictions Min            519.8059
V Predictions Mean           943.7511
V Predictions Std            954.2044
V Predictions Max            4052.9675
V Predictions Min            520.1062
Log Pis Mean                 -0.5248268
Log Pis Std                  3.212253
Log Pis Max                  12.227437
Log Pis Min                  -6.6149225
Policy mu Mean               0.030492345
Policy mu Std                0.828775
Policy mu Max                2.6929328
Policy mu Min                -2.7062078
Policy log std Mean          -0.48141864
Policy log std Std           0.2355231
Policy log std Max           -0.021471798
Policy log std Min           -2.5915623
Z mean eval                  2.3655086
Z variance eval              0.0396479
total_rewards                [9379.35399583 9509.06749338 9363.65614737 9403.50221162 9134.43325854
 9313.81904779 9379.98849172 9249.03615765 9304.35759035 9177.39647545]
total_rewards_mean           9321.461086969468
total_rewards_std            105.74247048054073
total_rewards_max            9509.067493382143
total_rewards_min            9134.433258537132
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               198.39122917223722
(Previous) Eval Time (s)     30.907971957232803
Sample Time (s)              7.8516645627096295
Epoch Time (s)               237.15086569217965
Total Train Time (s)         44141.584272291046
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:24.647729 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #191 | Epoch Duration: 237.23637199401855
2020-01-13 11:52:24.647904 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3663304
Z variance train             0.039501093
KL Divergence                41.60468
KL Loss                      4.160468
QF Loss                      183.04074
VF Loss                      60.635937
Policy Loss                  -1164.5304
Q Predictions Mean           1162.7112
Q Predictions Std            1182.4387
Q Predictions Max            4242.846
Q Predictions Min            524.5032
V Predictions Mean           1163.2654
V Predictions Std            1181.4783
V Predictions Max            4213.47
V Predictions Min            519.67084
Log Pis Mean                 -0.13029796
Log Pis Std                  3.9726293
Log Pis Max                  16.392315
Log Pis Min                  -7.7797613
Policy mu Mean               0.06907829
Policy mu Std                0.8970711
Policy mu Max                2.7503388
Policy mu Min                -3.0247083
Policy log std Mean          -0.5118243
Policy log std Std           0.25575176
Policy log std Max           -0.050135136
Policy log std Min           -2.2679605
Z mean eval                  2.31978
Z variance eval              0.046694063
total_rewards                [9723.35157121 9464.54568484 9179.19904087 9274.34741344 9394.5188801
 9483.07488088 9232.15406019 9089.78336122 9530.26888969 9153.4628238 ]
total_rewards_mean           9352.470660624713
total_rewards_std            189.6740105941735
total_rewards_max            9723.351571211482
total_rewards_min            9089.783361218551
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               194.37319021625444
(Previous) Eval Time (s)     33.92444388009608
Sample Time (s)              6.665647005662322
Epoch Time (s)               234.96328110201284
Total Train Time (s)         44376.637189983856
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:56:19.704172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #192 | Epoch Duration: 235.05610370635986
2020-01-13 11:56:19.704358 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.323752
Z variance train             0.046862043
KL Divergence                41.372643
KL Loss                      4.1372643
QF Loss                      2606.4204
VF Loss                      47.99762
Policy Loss                  -1143.5713
Q Predictions Mean           1139.6772
Q Predictions Std            1144.1174
Q Predictions Max            4012.3901
Q Predictions Min            518.0958
V Predictions Mean           1140.8711
V Predictions Std            1141.3381
V Predictions Max            4000.1277
V Predictions Min            517.609
Log Pis Mean                 -0.40321684
Log Pis Std                  3.683666
Log Pis Max                  13.900585
Log Pis Min                  -6.409444
Policy mu Mean               0.025048673
Policy mu Std                0.86395013
Policy mu Max                2.6797197
Policy mu Min                -2.631922
Policy log std Mean          -0.5105376
Policy log std Std           0.25888392
Policy log std Max           -0.10524064
Policy log std Min           -2.4018798
Z mean eval                  2.3446803
Z variance eval              0.051783077
total_rewards                [8318.57379554 8330.14233396 8617.11502043 8063.27371921 8950.02644477
 8864.26356427 8939.36163131 8844.17930335 8703.6936182  8098.69153084]
total_rewards_mean           8572.932096187556
total_rewards_std            325.92504028734635
total_rewards_max            8950.026444771021
total_rewards_min            8063.273719207273
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               197.80285135889426
(Previous) Eval Time (s)     34.07929621404037
Sample Time (s)              6.807236083317548
Epoch Time (s)               238.68938365625218
Total Train Time (s)         44615.442579227965
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:00:18.510289 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #193 | Epoch Duration: 238.80579733848572
2020-01-13 12:00:18.510430 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3440099
Z variance train             0.051768295
KL Divergence                41.746796
KL Loss                      4.1746798
QF Loss                      198.04553
VF Loss                      45.106827
Policy Loss                  -1039.8092
Q Predictions Mean           1038.3015
Q Predictions Std            1102.3195
Q Predictions Max            4068.1045
Q Predictions Min            506.17493
V Predictions Mean           1039.0161
V Predictions Std            1098.2311
V Predictions Max            4033.156
V Predictions Min            511.04205
Log Pis Mean                 -0.2777874
Log Pis Std                  3.62537
Log Pis Max                  21.35176
Log Pis Min                  -5.839252
Policy mu Mean               0.048130456
Policy mu Std                0.8771811
Policy mu Max                4.47602
Policy mu Min                -2.9126084
Policy log std Mean          -0.4951525
Policy log std Std           0.26146787
Policy log std Max           -0.030338228
Policy log std Min           -2.7699327
Z mean eval                  2.3307354
Z variance eval              0.04095624
total_rewards                [9260.88413021 9444.82202124 9127.22016762 9416.77552774 9638.64787412
 9436.03558632 9302.46209823 9283.25160639 9355.89766449 9358.35242118]
total_rewards_mean           9362.434909753429
total_rewards_std            129.23462069504643
total_rewards_max            9638.647874117578
total_rewards_min            9127.220167622501
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               196.59347250591964
(Previous) Eval Time (s)     31.814988404046744
Sample Time (s)              7.19865071401
Epoch Time (s)               235.60711162397638
Total Train Time (s)         44851.313944912516
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:14.393522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #194 | Epoch Duration: 235.88295078277588
2020-01-13 12:04:14.393800 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3306785
Z variance train             0.04094363
KL Divergence                42.164967
KL Loss                      4.216497
QF Loss                      2891.1646
VF Loss                      69.402596
Policy Loss                  -1230.9479
Q Predictions Mean           1227.5845
Q Predictions Std            1234.8037
Q Predictions Max            4067.6313
Q Predictions Min            523.77747
V Predictions Mean           1235.5273
V Predictions Std            1237.1929
V Predictions Max            4066.2307
V Predictions Min            528.8043
Log Pis Mean                 -0.11903061
Log Pis Std                  3.6373668
Log Pis Max                  12.905974
Log Pis Min                  -8.496889
Policy mu Mean               0.01776875
Policy mu Std                0.91985446
Policy mu Max                2.8299332
Policy mu Min                -3.1149204
Policy log std Mean          -0.5204403
Policy log std Std           0.2591991
Policy log std Max           -0.101044
Policy log std Min           -2.3140025
Z mean eval                  2.3778
Z variance eval              0.06607994
total_rewards                [9243.59578202 9543.0157531  9546.95913314 9469.69333044 9409.19104447
 9181.07232471 9293.15777133 9262.70433107 9267.13064387 9181.6501834 ]
total_rewards_mean           9339.817029755714
total_rewards_std            133.70119899825048
total_rewards_max            9546.959133142864
total_rewards_min            9181.072324710056
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               194.5609214757569
(Previous) Eval Time (s)     31.28904126631096
Sample Time (s)              6.917036384809762
Epoch Time (s)               232.76699912687764
Total Train Time (s)         45084.16868727794
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:08:07.244913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #195 | Epoch Duration: 232.85090613365173
2020-01-13 12:08:07.245096 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3773086
Z variance train             0.06601741
KL Divergence                42.68558
KL Loss                      4.268558
QF Loss                      427.13757
VF Loss                      48.18004
Policy Loss                  -1175.6017
Q Predictions Mean           1176.1062
Q Predictions Std            1215.801
Q Predictions Max            4140.253
Q Predictions Min            525.3767
V Predictions Mean           1175.884
V Predictions Std            1211.0388
V Predictions Max            4124.9233
V Predictions Min            535.14496
Log Pis Mean                 -0.015427515
Log Pis Std                  3.8675008
Log Pis Max                  13.68766
Log Pis Min                  -7.0998864
Policy mu Mean               0.06713538
Policy mu Std                0.9104153
Policy mu Max                3.3421152
Policy mu Min                -2.9468482
Policy log std Mean          -0.51575315
Policy log std Std           0.28048518
Policy log std Max           -0.10811339
Policy log std Min           -2.8144975
Z mean eval                  2.3425498
Z variance eval              0.058491837
total_rewards                [9744.58885411 9491.55112089 9744.6710699  9674.12409871 9749.75601227
 9674.27143306 9654.78778833 9412.69224071 9664.17903892 9808.71546977]
total_rewards_mean           9661.93371266701
total_rewards_std            115.94975322115575
total_rewards_max            9808.715469767862
total_rewards_min            9412.692240710805
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               193.10018029995263
(Previous) Eval Time (s)     29.85309000732377
Sample Time (s)              6.968828381970525
Epoch Time (s)               229.92209868924692
Total Train Time (s)         45314.17858810723
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:57.260982 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #196 | Epoch Duration: 230.01570796966553
2020-01-13 12:11:57.261305 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.342463
Z variance train             0.05842524
KL Divergence                42.941734
KL Loss                      4.2941737
QF Loss                      89.30239
VF Loss                      77.76656
Policy Loss                  -1050.7592
Q Predictions Mean           1047.3887
Q Predictions Std            1077.9612
Q Predictions Max            4081.5376
Q Predictions Min            521.30426
V Predictions Mean           1053.8513
V Predictions Std            1078.4175
V Predictions Max            4093.4072
V Predictions Min            533.8463
Log Pis Mean                 -0.49942574
Log Pis Std                  3.5579367
Log Pis Max                  26.497742
Log Pis Min                  -7.2952886
Policy mu Mean               0.04477528
Policy mu Std                0.8501153
Policy mu Max                4.7743626
Policy mu Min                -2.6151242
Policy log std Mean          -0.50182885
Policy log std Std           0.26258832
Policy log std Max           -0.052553833
Policy log std Min           -2.682726
Z mean eval                  2.3578386
Z variance eval              0.06740702
total_rewards                [8960.63726275 9195.11799587 9051.67934499 9262.85930864 9131.2323432
 8940.59352675 9047.55952075 9165.63972245 8996.99504584 9369.72542158]
total_rewards_mean           9112.203949281866
total_rewards_std            131.39420292937777
total_rewards_max            9369.72542157922
total_rewards_min            8940.593526746026
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               197.21336832083762
(Previous) Eval Time (s)     33.38288265187293
Sample Time (s)              6.3826864953152835
Epoch Time (s)               236.97893746802583
Total Train Time (s)         45551.31993742753
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:15:54.402952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #197 | Epoch Duration: 237.14141082763672
2020-01-13 12:15:54.403128 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3561606
Z variance train             0.06745019
KL Divergence                42.83439
KL Loss                      4.283439
QF Loss                      3004.911
VF Loss                      121.367424
Policy Loss                  -974.5796
Q Predictions Mean           974.45483
Q Predictions Std            993.6393
Q Predictions Max            4133.8936
Q Predictions Min            527.46716
V Predictions Mean           982.63074
V Predictions Std            996.52856
V Predictions Max            4154.0684
V Predictions Min            526.1649
Log Pis Mean                 -0.7791941
Log Pis Std                  3.4416518
Log Pis Max                  15.468447
Log Pis Min                  -6.750371
Policy mu Mean               0.050475344
Policy mu Std                0.8262003
Policy mu Max                3.4859524
Policy mu Min                -3.0873773
Policy log std Mean          -0.49005976
Policy log std Std           0.25973716
Policy log std Max           -0.10392845
Policy log std Min           -2.7497165
Z mean eval                  2.359917
Z variance eval              0.074436374
total_rewards                [9376.68036745 9540.71912991 9598.76299854 9623.17153312 9784.27049326
 9241.64678018 9681.87847109 9503.70715301 9541.60549905 9294.77346572]
total_rewards_mean           9518.721589133096
total_rewards_std            162.10636182902937
total_rewards_max            9784.270493259515
total_rewards_min            9241.646780175422
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               196.06266003660858
(Previous) Eval Time (s)     31.206191719044
Sample Time (s)              5.953605487477034
Epoch Time (s)               233.2224572431296
Total Train Time (s)         45784.63198094675
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:19:47.718500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #198 | Epoch Duration: 233.31522727012634
2020-01-13 12:19:47.718677 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3608952
Z variance train             0.07499403
KL Divergence                42.829437
KL Loss                      4.2829437
QF Loss                      248.21564
VF Loss                      73.278946
Policy Loss                  -1206.0967
Q Predictions Mean           1201.0846
Q Predictions Std            1240.6113
Q Predictions Max            4189.821
Q Predictions Min            518.2576
V Predictions Mean           1210.6196
V Predictions Std            1241.4244
V Predictions Max            4200.8374
V Predictions Min            525.9913
Log Pis Mean                 0.010441929
Log Pis Std                  3.9679022
Log Pis Max                  15.274396
Log Pis Min                  -5.9215465
Policy mu Mean               0.009853925
Policy mu Std                0.90550137
Policy mu Max                2.7352605
Policy mu Min                -2.673469
Policy log std Mean          -0.5011136
Policy log std Std           0.27851906
Policy log std Max           0.06579995
Policy log std Min           -2.8025823
Z mean eval                  2.3811822
Z variance eval              0.08804292
total_rewards                [9521.65487917 9683.31003929 9685.54170128 9662.06301329 9712.18984479
 9497.41767186 9692.4802086  9623.51735924 9546.03879664 9608.33629802]
total_rewards_mean           9623.254981219981
total_rewards_std            73.50947910673543
total_rewards_max            9712.189844788909
total_rewards_min            9497.417671864216
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               197.4615757302381
(Previous) Eval Time (s)     30.607211170252413
Sample Time (s)              7.239091456402093
Epoch Time (s)               235.30787835689262
Total Train Time (s)         46020.05770620238
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:23:43.145699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #199 | Epoch Duration: 235.42687511444092
2020-01-13 12:23:43.145906 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3807902
Z variance train             0.08830996
KL Divergence                43.05302
KL Loss                      4.305302
QF Loss                      264.41217
VF Loss                      194.33864
Policy Loss                  -1254.873
Q Predictions Mean           1253.1
Q Predictions Std            1259.63
Q Predictions Max            4265.4287
Q Predictions Min            532.48773
V Predictions Mean           1246.4897
V Predictions Std            1253.9014
V Predictions Max            4257.3477
V Predictions Min            532.7251
Log Pis Mean                 0.38294572
Log Pis Std                  4.069057
Log Pis Max                  14.928526
Log Pis Min                  -7.816333
Policy mu Mean               0.027249439
Policy mu Std                0.94706285
Policy mu Max                3.1481903
Policy mu Min                -3.508844
Policy log std Mean          -0.5366691
Policy log std Std           0.2866643
Policy log std Max           -0.101685256
Policy log std Min           -2.9021246
Z mean eval                  2.3228583
Z variance eval              0.16166346
total_rewards                [8577.22984088 9789.41644989 9694.57864267 9091.73891831 9444.81931506
 9033.07051737 9486.76032223 9477.14878888 9782.50319005 9186.27082598]
total_rewards_mean           9356.353681132154
total_rewards_std            365.165924132182
total_rewards_max            9789.416449885524
total_rewards_min            8577.22984087605
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               195.91828371910378
(Previous) Eval Time (s)     34.17196895740926
Sample Time (s)              10.089390392415226
Epoch Time (s)               240.17964306892827
Total Train Time (s)         46260.34019062994
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:27:43.433722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #200 | Epoch Duration: 240.2875850200653
2020-01-13 12:27:43.434056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.321506
Z variance train             0.16204916
KL Divergence                38.851418
KL Loss                      3.8851418
QF Loss                      4908.929
VF Loss                      70.79598
Policy Loss                  -1085.9962
Q Predictions Mean           1082.9573
Q Predictions Std            1146.9974
Q Predictions Max            4133.5156
Q Predictions Min            521.4335
V Predictions Mean           1080.4565
V Predictions Std            1144.0497
V Predictions Max            4118.6826
V Predictions Min            515.7908
Log Pis Mean                 -0.3189606
Log Pis Std                  3.6580966
Log Pis Max                  12.405842
Log Pis Min                  -9.049832
Policy mu Mean               0.07187034
Policy mu Std                0.86424416
Policy mu Max                2.8797224
Policy mu Min                -2.305129
Policy log std Mean          -0.51223063
Policy log std Std           0.2834127
Policy log std Max           -0.08425683
Policy log std Min           -2.5215838
Z mean eval                  2.3460467
Z variance eval              0.09898951
total_rewards                [9852.37559133 9797.42663738 9459.87850058 9775.09706372 9875.05142424
 9649.08718748 9637.61412176 9492.36858538 9741.4495661  9623.17891742]
total_rewards_mean           9690.352759539684
total_rewards_std            135.2534452390618
total_rewards_max            9875.051424241752
total_rewards_min            9459.878500576438
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               197.3692497271113
(Previous) Eval Time (s)     34.56238829297945
Sample Time (s)              7.602177802938968
Epoch Time (s)               239.53381582302973
Total Train Time (s)         46499.96239004657
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:31:43.061668 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #201 | Epoch Duration: 239.62741231918335
2020-01-13 12:31:43.061860 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.344434
Z variance train             0.09871207
KL Divergence                41.1741
KL Loss                      4.11741
QF Loss                      263.70712
VF Loss                      185.08154
Policy Loss                  -1247.8557
Q Predictions Mean           1250.1144
Q Predictions Std            1266.1664
Q Predictions Max            4295.3296
Q Predictions Min            505.00626
V Predictions Mean           1254.6014
V Predictions Std            1271.5872
V Predictions Max            4300.673
V Predictions Min            516.19147
Log Pis Mean                 0.0029628873
Log Pis Std                  3.8740184
Log Pis Max                  13.7572155
Log Pis Min                  -5.932822
Policy mu Mean               0.023885204
Policy mu Std                0.9163347
Policy mu Max                3.119235
Policy mu Min                -2.4227676
Policy log std Mean          -0.51967996
Policy log std Std           0.28210893
Policy log std Max           -0.11449246
Policy log std Min           -2.5953598
Z mean eval                  2.3724658
Z variance eval              0.13387232
total_rewards                [9484.17831889 9706.70848287 9692.56662283 9368.03059982 9776.87958754
 9466.91338115 9592.94322799 9662.42918774 9411.19590081 9947.02973042]
total_rewards_mean           9610.887504007615
total_rewards_std            171.76048054300944
total_rewards_max            9947.029730420178
total_rewards_min            9368.03059981709
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               192.1639361283742
(Previous) Eval Time (s)     33.7557159033604
Sample Time (s)              6.608291095122695
Epoch Time (s)               232.52794312685728
Total Train Time (s)         46732.57894561812
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:35.675925 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #202 | Epoch Duration: 232.6139211654663
2020-01-13 12:35:35.676101 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.370464
Z variance train             0.1342449
KL Divergence                42.19132
KL Loss                      4.219132
QF Loss                      151.89374
VF Loss                      100.13189
Policy Loss                  -1144.8055
Q Predictions Mean           1145.1707
Q Predictions Std            1212.5536
Q Predictions Max            4256.056
Q Predictions Min            523.95404
V Predictions Mean           1152.0527
V Predictions Std            1215.4729
V Predictions Max            4279.5063
V Predictions Min            529.98517
Log Pis Mean                 -0.33459902
Log Pis Std                  3.9139597
Log Pis Max                  17.710548
Log Pis Min                  -8.203734
Policy mu Mean               0.035810098
Policy mu Std                0.878141
Policy mu Max                3.2574751
Policy mu Min                -2.624202
Policy log std Mean          -0.5078617
Policy log std Std           0.29122525
Policy log std Max           -0.10014397
Policy log std Min           -2.7607818
Z mean eval                  2.3814054
Z variance eval              0.09706648
total_rewards                [9511.84313358 9583.70553645 9174.02388929 9668.08083799 9235.65032514
 9516.94153858 9273.13256027 9531.0481112  9330.65633609 9621.14142695]
total_rewards_mean           9444.622369553394
total_rewards_std            166.41657325554146
total_rewards_max            9668.080837993675
total_rewards_min            9174.023889289241
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               196.50879424065351
(Previous) Eval Time (s)     28.461804450955242
Sample Time (s)              6.573631635867059
Epoch Time (s)               231.54423032747582
Total Train Time (s)         46964.20503364643
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:39:27.304295 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #203 | Epoch Duration: 231.62804579734802
2020-01-13 12:39:27.304495 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3764434
Z variance train             0.097459264
KL Divergence                41.640457
KL Loss                      4.164046
QF Loss                      105.27887
VF Loss                      152.69402
Policy Loss                  -1197.4595
Q Predictions Mean           1202.5785
Q Predictions Std            1234.8566
Q Predictions Max            4262.131
Q Predictions Min            531.1196
V Predictions Mean           1205.2148
V Predictions Std            1237.2225
V Predictions Max            4290.79
V Predictions Min            530.5142
Log Pis Mean                 0.09714187
Log Pis Std                  3.8213356
Log Pis Max                  11.91896
Log Pis Min                  -7.710458
Policy mu Mean               0.014900376
Policy mu Std                0.9217618
Policy mu Max                2.557114
Policy mu Min                -2.670986
Policy log std Mean          -0.5070312
Policy log std Std           0.26746172
Policy log std Max           -0.10490677
Policy log std Min           -2.7920926
Z mean eval                  2.3931854
Z variance eval              0.10536343
total_rewards                [9278.28738483 9656.46691868 9576.40933606 9382.15801957 9505.75962173
 9511.82796393 9466.80564605 9362.00066755 9515.8667374  9543.56669203]
total_rewards_mean           9479.914898783813
total_rewards_std            105.73455032197975
total_rewards_max            9656.466918678572
total_rewards_min            9278.287384833835
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               196.86867831088603
(Previous) Eval Time (s)     31.611285253893584
Sample Time (s)              7.2026204145513475
Epoch Time (s)               235.68258397933096
Total Train Time (s)         47199.984645104036
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:43:23.086189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #204 | Epoch Duration: 235.7815399169922
2020-01-13 12:43:23.086388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3929048
Z variance train             0.1061305
KL Divergence                41.070393
KL Loss                      4.1070395
QF Loss                      139.95537
VF Loss                      69.77413
Policy Loss                  -1222.0981
Q Predictions Mean           1216.5239
Q Predictions Std            1237.5746
Q Predictions Max            4309.7803
Q Predictions Min            537.3694
V Predictions Mean           1220.9397
V Predictions Std            1238.6174
V Predictions Max            4299.5674
V Predictions Min            539.12213
Log Pis Mean                 0.10863441
Log Pis Std                  3.8629417
Log Pis Max                  14.837879
Log Pis Min                  -7.739481
Policy mu Mean               -0.009355065
Policy mu Std                0.92675716
Policy mu Max                2.6749964
Policy mu Min                -2.41089
Policy log std Mean          -0.51674473
Policy log std Std           0.28248426
Policy log std Max           -0.048550636
Policy log std Min           -2.6347017
Z mean eval                  2.3911452
Z variance eval              0.08869241
total_rewards                [9363.49686813 9466.44789852 9520.01520651 9510.15107593 9640.61285866
 9469.89569425 9486.77732338 9452.99769112 9592.85588119 9717.3757073 ]
total_rewards_mean           9522.06262049953
total_rewards_std            97.12446827883258
total_rewards_max            9717.375707300514
total_rewards_min            9363.496868131037
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               197.130171273835
(Previous) Eval Time (s)     31.13417045492679
Sample Time (s)              7.088534634560347
Epoch Time (s)               235.35287636332214
Total Train Time (s)         47435.42585941078
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:18.531059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #205 | Epoch Duration: 235.44451451301575
2020-01-13 12:47:18.531273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #205 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3969886
Z variance train             0.08813298
KL Divergence                41.40408
KL Loss                      4.140408
QF Loss                      176.24568
VF Loss                      202.77347
Policy Loss                  -1128.4076
Q Predictions Mean           1123.0745
Q Predictions Std            1176.9501
Q Predictions Max            4269.321
Q Predictions Min            529.9783
V Predictions Mean           1116.6274
V Predictions Std            1170.5452
V Predictions Max            4249.967
V Predictions Min            529.1355
Log Pis Mean                 -0.5299915
Log Pis Std                  3.4515479
Log Pis Max                  14.265929
Log Pis Min                  -6.1686096
Policy mu Mean               0.0515424
Policy mu Std                0.8590332
Policy mu Max                2.7504187
Policy mu Min                -2.7396379
Policy log std Mean          -0.4969274
Policy log std Std           0.25773427
Policy log std Max           -0.095601305
Policy log std Min           -2.5379524
Z mean eval                  2.361887
Z variance eval              0.08234035
total_rewards                [ 9952.5918113   9855.41539697  9833.62571865  9894.26689376
 10094.2702043   9605.47789702 10020.82731197  9884.26951797
  9809.06020761  9719.61298705]
total_rewards_mean           9866.941794659342
total_rewards_std            133.56797477464005
total_rewards_max            10094.270204297018
total_rewards_min            9605.47789702461
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               192.5060055698268
(Previous) Eval Time (s)     33.71947978390381
Sample Time (s)              8.110527695156634
Epoch Time (s)               234.33601304888725
Total Train Time (s)         47669.892360715196
Epoch                        206
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:51:13.000401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #206 | Epoch Duration: 234.46896815299988
2020-01-13 12:51:13.000581 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3637958
Z variance train             0.08244461
KL Divergence                41.42488
KL Loss                      4.142488
QF Loss                      248.23485
VF Loss                      39.415264
Policy Loss                  -1008.6428
Q Predictions Mean           1006.0989
Q Predictions Std            1057.5309
Q Predictions Max            4300.7637
Q Predictions Min            540.99854
V Predictions Mean           1007.2248
V Predictions Std            1055.6859
V Predictions Max            4281.6377
V Predictions Min            551.0641
Log Pis Mean                 -0.65624255
Log Pis Std                  3.1645947
Log Pis Max                  12.036101
Log Pis Min                  -7.3222923
Policy mu Mean               -0.011202439
Policy mu Std                0.82209045
Policy mu Max                2.7993393
Policy mu Min                -2.4523249
Policy log std Mean          -0.51570874
Policy log std Std           0.25484607
Policy log std Max           -0.10310304
Policy log std Min           -2.7425895
Z mean eval                  2.365963
Z variance eval              0.06243979
total_rewards                [ 9677.41492663  9409.77430963  9642.62856649  9544.06455915
  9666.17679656 10029.10700514  9697.36803721  9837.88270014
  9583.18091331  9494.80574767]
total_rewards_mean           9658.240356193932
total_rewards_std            167.07336048293365
total_rewards_max            10029.107005142256
total_rewards_min            9409.774309634622
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               194.18150487029925
(Previous) Eval Time (s)     34.20940967602655
Sample Time (s)              7.630823771469295
Epoch Time (s)               236.0217383177951
Total Train Time (s)         47905.992961213924
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:09.103635 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #207 | Epoch Duration: 236.1029074192047
2020-01-13 12:55:09.103841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364978
Z variance train             0.06237177
KL Divergence                41.1943
KL Loss                      4.11943
QF Loss                      189.15195
VF Loss                      107.25026
Policy Loss                  -1060.0845
Q Predictions Mean           1059.1289
Q Predictions Std            1111.4215
Q Predictions Max            4221.361
Q Predictions Min            527.388
V Predictions Mean           1065.988
V Predictions Std            1112.4993
V Predictions Max            4248.939
V Predictions Min            540.2156
Log Pis Mean                 -0.11394047
Log Pis Std                  3.7959068
Log Pis Max                  18.111189
Log Pis Min                  -5.792542
Policy mu Mean               0.014688738
Policy mu Std                0.88799703
Policy mu Max                2.863607
Policy mu Min                -3.1002705
Policy log std Mean          -0.5044163
Policy log std Std           0.2562308
Policy log std Max           0.2617241
Policy log std Min           -2.2731295
Z mean eval                  2.3815465
Z variance eval              0.086417384
total_rewards                [9666.37126526 9965.44572734 9910.41229108 9844.54429946 9938.73516508
 9776.06579738 9768.85070058 9831.90882407 9902.3056304  9861.60826367]
total_rewards_mean           9846.624796430591
total_rewards_std            85.86969419745047
total_rewards_max            9965.445727342514
total_rewards_min            9666.371265256406
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               193.33769765123725
(Previous) Eval Time (s)     36.57446942618117
Sample Time (s)              6.347179894335568
Epoch Time (s)               236.25934697175398
Total Train Time (s)         48142.342309506144
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:59:05.454254 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #208 | Epoch Duration: 236.3502733707428
2020-01-13 12:59:05.454408 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #208 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3814197
Z variance train             0.086310685
KL Divergence                40.96343
KL Loss                      4.096343
QF Loss                      195.34886
VF Loss                      46.102585
Policy Loss                  -1137.2583
Q Predictions Mean           1134.9519
Q Predictions Std            1180.1469
Q Predictions Max            4331.7363
Q Predictions Min            555.4265
V Predictions Mean           1138.6388
V Predictions Std            1178.4805
V Predictions Max            4344.413
V Predictions Min            547.1596
Log Pis Mean                 -0.25121796
Log Pis Std                  3.8391175
Log Pis Max                  16.848969
Log Pis Min                  -5.6944656
Policy mu Mean               -0.032834496
Policy mu Std                0.8766588
Policy mu Max                3.0217671
Policy mu Min                -3.2792869
Policy log std Mean          -0.49791732
Policy log std Std           0.2764027
Policy log std Max           -0.054453015
Policy log std Min           -2.795714
Z mean eval                  2.367709
Z variance eval              0.083346434
total_rewards                [9664.02797282 9575.18368524 9686.89146737 9418.61135172 9417.9848642
 9637.30176892 9449.72991231 9509.46540799 9649.95181885 9664.7735246 ]
total_rewards_mean           9567.392177401689
total_rewards_std            103.21048182530875
total_rewards_max            9686.891467365242
total_rewards_min            9417.984864203632
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               195.93584007769823
(Previous) Eval Time (s)     30.985991314984858
Sample Time (s)              7.020067872479558
Epoch Time (s)               233.94189926516265
Total Train Time (s)         48376.37126434781
Epoch                        209
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:02:59.486698 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #209 | Epoch Duration: 234.03211522102356
2020-01-13 13:02:59.486960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3699334
Z variance train             0.08348967
KL Divergence                40.182884
KL Loss                      4.0182886
QF Loss                      209.90569
VF Loss                      59.298996
Policy Loss                  -1106.8552
Q Predictions Mean           1102.1873
Q Predictions Std            1140.0571
Q Predictions Max            4292.4136
Q Predictions Min            534.7798
V Predictions Mean           1103.6968
V Predictions Std            1138.196
V Predictions Max            4273.3496
V Predictions Min            538.27734
Log Pis Mean                 -0.35097295
Log Pis Std                  3.8380613
Log Pis Max                  16.771626
Log Pis Min                  -7.4791374
Policy mu Mean               0.0073901913
Policy mu Std                0.8921599
Policy mu Max                3.8344486
Policy mu Min                -3.6880882
Policy log std Mean          -0.5274003
Policy log std Std           0.29121962
Policy log std Max           0.050424933
Policy log std Min           -2.8251896
Z mean eval                  2.3953285
Z variance eval              0.08192095
total_rewards                [9194.4266181  9384.97133902 9172.37804264 9215.95064673 9217.70785105
 9191.59804837 9375.64809553 9254.11141315 9021.02748114 9182.91539679]
total_rewards_mean           9221.073493252105
total_rewards_std            98.64554666833394
total_rewards_max            9384.971339022604
total_rewards_min            9021.027481143083
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               192.09275465505198
(Previous) Eval Time (s)     30.720669914968312
Sample Time (s)              8.6426423615776
Epoch Time (s)               231.4560669315979
Total Train Time (s)         48607.90824969951
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:51.027522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #210 | Epoch Duration: 231.54037976264954
2020-01-13 13:06:51.027742 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3913798
Z variance train             0.0813347
KL Divergence                41.748478
KL Loss                      4.174848
QF Loss                      115.48562
VF Loss                      126.99902
Policy Loss                  -1309.0742
Q Predictions Mean           1308.0918
Q Predictions Std            1293.4707
Q Predictions Max            4439.2886
Q Predictions Min            542.1568
V Predictions Mean           1314.0562
V Predictions Std            1295.8794
V Predictions Max            4436.2437
V Predictions Min            546.4589
Log Pis Mean                 -0.04537572
Log Pis Std                  3.8043137
Log Pis Max                  19.459082
Log Pis Min                  -6.471422
Policy mu Mean               -0.00825988
Policy mu Std                0.92964023
Policy mu Max                3.8777637
Policy mu Min                -2.9387953
Policy log std Mean          -0.50828916
Policy log std Std           0.2784738
Policy log std Max           0.40763587
Policy log std Min           -2.6488674
Z mean eval                  2.401567
Z variance eval              0.064511925
total_rewards                [ 9921.93718429 10135.74271791  9960.44717235  9958.12785908
  9695.94708253  6667.09416578  9879.90402023  9667.36175267
  9836.31277671  9921.10569305]
total_rewards_mean           9564.398042460054
total_rewards_std            974.122450208172
total_rewards_max            10135.74271790887
total_rewards_min            6667.094165777532
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               193.63102536508814
(Previous) Eval Time (s)     31.431543877813965
Sample Time (s)              7.9429297666065395
Epoch Time (s)               233.00549900950864
Total Train Time (s)         48841.00886760419
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:44.131241 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #211 | Epoch Duration: 233.1033375263214
2020-01-13 13:10:44.131416 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3972347
Z variance train             0.06431613
KL Divergence                42.061
KL Loss                      4.2061
QF Loss                      2915.0588
VF Loss                      112.82703
Policy Loss                  -1064.0155
Q Predictions Mean           1065.2834
Q Predictions Std            1117.1743
Q Predictions Max            4343.3623
Q Predictions Min            563.1755
V Predictions Mean           1068.8777
V Predictions Std            1120.07
V Predictions Max            4352.4346
V Predictions Min            571.84705
Log Pis Mean                 -0.9108555
Log Pis Std                  3.108888
Log Pis Max                  12.525963
Log Pis Min                  -8.681697
Policy mu Mean               0.06757532
Policy mu Std                0.83588743
Policy mu Max                2.6483588
Policy mu Min                -2.3473952
Policy log std Mean          -0.4917264
Policy log std Std           0.2571502
Policy log std Max           0.12800527
Policy log std Min           -2.5545135
Z mean eval                  2.4272206
Z variance eval              0.07410838
total_rewards                [9804.5167291  9652.18724248 9679.05362608 9871.71700939 9757.64876986
 9834.61805982 9808.26414159 9704.82127281 9673.76051338 9549.59570717]
total_rewards_mean           9733.618307167771
total_rewards_std            93.98569904489304
total_rewards_max            9871.717009393453
total_rewards_min            9549.595707171138
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               197.59790648939088
(Previous) Eval Time (s)     32.88015077775344
Sample Time (s)              8.193725450430065
Epoch Time (s)               238.6717827175744
Total Train Time (s)         49079.76451358665
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:14:42.889567 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #212 | Epoch Duration: 238.75801181793213
2020-01-13 13:14:42.889744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #212 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4291644
Z variance train             0.07414045
KL Divergence                43.136284
KL Loss                      4.3136287
QF Loss                      214.37552
VF Loss                      43.471252
Policy Loss                  -1106.2263
Q Predictions Mean           1105.7496
Q Predictions Std            1159.3663
Q Predictions Max            4473.9233
Q Predictions Min            554.51685
V Predictions Mean           1102.2856
V Predictions Std            1153.4385
V Predictions Max            4455.9307
V Predictions Min            555.2538
Log Pis Mean                 -0.40712038
Log Pis Std                  3.4205093
Log Pis Max                  13.339331
Log Pis Min                  -6.1068964
Policy mu Mean               0.0034241274
Policy mu Std                0.87360555
Policy mu Max                3.3781745
Policy mu Min                -2.8659842
Policy log std Mean          -0.495039
Policy log std Std           0.2678651
Policy log std Max           0.1315727
Policy log std Min           -3.0624812
Z mean eval                  2.4006236
Z variance eval              0.054712348
total_rewards                [ 9977.82973155  9837.71631995  9739.40078662  9707.45634483
  9961.82304172  9838.06447988 10013.04188473  9507.30530726
  9881.06580601  9845.21055944]
total_rewards_mean           9830.891426198858
total_rewards_std            142.4949170031183
total_rewards_max            10013.041884727809
total_rewards_min            9507.305307263136
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               196.29146390408278
(Previous) Eval Time (s)     33.52027611574158
Sample Time (s)              6.40070890635252
Epoch Time (s)               236.21244892617688
Total Train Time (s)         49316.06313459156
Epoch                        213
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:39.193172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #213 | Epoch Duration: 236.30328559875488
2020-01-13 13:18:39.193371 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3996491
Z variance train             0.054622192
KL Divergence                41.843002
KL Loss                      4.1843004
QF Loss                      208.61826
VF Loss                      74.17007
Policy Loss                  -1355.8491
Q Predictions Mean           1358.0286
Q Predictions Std            1366.9224
Q Predictions Max            4435.0117
Q Predictions Min            551.6612
V Predictions Mean           1357.2897
V Predictions Std            1360.7406
V Predictions Max            4407.352
V Predictions Min            550.73444
Log Pis Mean                 0.18897292
Log Pis Std                  4.037646
Log Pis Max                  13.671999
Log Pis Min                  -6.6684866
Policy mu Mean               0.068535596
Policy mu Std                0.93551046
Policy mu Max                2.7632394
Policy mu Min                -3.234562
Policy log std Mean          -0.537909
Policy log std Std           0.3074948
Policy log std Max           0.12843478
Policy log std Min           -2.9771025
Z mean eval                  2.3698163
Z variance eval              0.058105987
total_rewards                [9191.98546656 9481.0720188  9131.86537204 8954.32624131 9149.78587567
 9251.27174513 9612.32653381 9400.04695827 9503.62234987 9154.66316522]
total_rewards_mean           9283.096572668353
total_rewards_std            196.07075199975887
total_rewards_max            9612.326533807847
total_rewards_min            8954.326241314704
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               195.09279798297212
(Previous) Eval Time (s)     32.367227524053305
Sample Time (s)              7.190275221131742
Epoch Time (s)               234.65030072815716
Total Train Time (s)         49550.85383482231
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:33.989020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #214 | Epoch Duration: 234.7954888343811
2020-01-13 13:22:33.989189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #214 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3684196
Z variance train             0.057948776
KL Divergence                40.912186
KL Loss                      4.0912185
QF Loss                      143.01028
VF Loss                      167.2269
Policy Loss                  -1138.2063
Q Predictions Mean           1132.1182
Q Predictions Std            1174.6088
Q Predictions Max            4390.7085
Q Predictions Min            559.6255
V Predictions Mean           1129.5183
V Predictions Std            1168.902
V Predictions Max            4368.356
V Predictions Min            555.5538
Log Pis Mean                 -0.14965722
Log Pis Std                  3.6722002
Log Pis Max                  17.60027
Log Pis Min                  -6.710083
Policy mu Mean               0.044784326
Policy mu Std                0.88986254
Policy mu Max                2.8358889
Policy mu Min                -2.3645782
Policy log std Mean          -0.5162209
Policy log std Std           0.2717125
Policy log std Max           -0.013916314
Policy log std Min           -2.7828603
Z mean eval                  2.3963752
Z variance eval              0.07721842
total_rewards                [ 9673.04267793  9487.66450363  9838.25186728  9940.2304229
  9905.63421663  9783.87383154  9835.72019942  9603.72895716
 10090.24331307  5958.60871214]
total_rewards_mean           9411.699870169856
total_rewards_std            1162.702653119491
total_rewards_max            10090.243313066292
total_rewards_min            5958.608712135163
Number of train steps total  864000
Number of env steps total    2594000
Number of rollouts total     0
Train Time (s)               194.09128446877003
(Previous) Eval Time (s)     32.04744624206796
Sample Time (s)              6.222460553981364
Epoch Time (s)               232.36119126481935
Total Train Time (s)         49783.30006806832
Epoch                        215
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:26:26.436971 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #215 | Epoch Duration: 232.44765329360962
2020-01-13 13:26:26.437144 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3956985
Z variance train             0.07709024
KL Divergence                40.865177
KL Loss                      4.086518
QF Loss                      100.110016
VF Loss                      69.54259
Policy Loss                  -1173.2561
Q Predictions Mean           1171.7399
Q Predictions Std            1217.898
Q Predictions Max            4389.261
Q Predictions Min            553.63965
V Predictions Mean           1169.0222
V Predictions Std            1215.9323
V Predictions Max            4357.8066
V Predictions Min            550.43787
Log Pis Mean                 0.09202564
Log Pis Std                  4.0705123
Log Pis Max                  15.458209
Log Pis Min                  -8.769483
Policy mu Mean               0.009804007
Policy mu Std                0.9319345
Policy mu Max                3.6179485
Policy mu Min                -3.4006183
Policy log std Mean          -0.5182452
Policy log std Std           0.27844146
Policy log std Max           -0.047925472
Policy log std Min           -2.9094942
Z mean eval                  2.4044788
Z variance eval              0.07836102
total_rewards                [9540.77741501 9702.6153219  9678.84492438 9548.697543   9703.04958862
 9851.08547379 9521.20061114 9568.86154316 9608.36849328 9507.98502388]
total_rewards_mean           9623.1485938183
total_rewards_std            103.39534643876965
total_rewards_max            9851.085473792069
total_rewards_min            9507.985023884967
Number of train steps total  868000
Number of env steps total    2606000
Number of rollouts total     0
Train Time (s)               194.0066422871314
(Previous) Eval Time (s)     30.221007737796754
Sample Time (s)              6.617266785353422
Epoch Time (s)               230.84491681028157
Total Train Time (s)         50014.229901847895
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:30:17.373803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #216 | Epoch Duration: 230.93648028373718
2020-01-13 13:30:17.374137 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #216 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4035747
Z variance train             0.0786614
KL Divergence                41.096672
KL Loss                      4.1096673
QF Loss                      255.56268
VF Loss                      66.71867
Policy Loss                  -1220.8339
Q Predictions Mean           1220.0276
Q Predictions Std            1282.0522
Q Predictions Max            4446.906
Q Predictions Min            565.7466
V Predictions Mean           1215.9409
V Predictions Std            1278.4171
V Predictions Max            4453.224
V Predictions Min            559.3002
Log Pis Mean                 -0.18714868
Log Pis Std                  3.8069782
Log Pis Max                  11.917628
Log Pis Min                  -7.7387986
Policy mu Mean               0.0014845083
Policy mu Std                0.8798409
Policy mu Max                2.7921953
Policy mu Min                -2.8518052
Policy log std Mean          -0.5360187
Policy log std Std           0.28605726
Policy log std Max           -0.061689913
Policy log std Min           -2.7519956
Z mean eval                  2.3940682
Z variance eval              0.11687682
total_rewards                [10077.88214934 10226.96564358  9850.09434109  9969.99477743
  9753.51801389  9986.13675304  9762.65650428  9697.41891049
  9853.94538584  9998.18902544]
total_rewards_mean           9917.680150442477
total_rewards_std            155.9979217558787
total_rewards_max            10226.96564357809
total_rewards_min            9697.418910490765
Number of train steps total  872000
Number of env steps total    2618000
Number of rollouts total     0
Train Time (s)               197.16664804005995
(Previous) Eval Time (s)     32.956311791203916
Sample Time (s)              6.525584070477635
Epoch Time (s)               236.6485439017415
Total Train Time (s)         50250.965413472615
Epoch                        217
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:34:14.113044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #217 | Epoch Duration: 236.73867535591125
2020-01-13 13:34:14.113189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.394383
Z variance train             0.11698991
KL Divergence                39.653015
KL Loss                      3.9653015
QF Loss                      3156.9185
VF Loss                      48.57525
Policy Loss                  -1265.4824
Q Predictions Mean           1262.4426
Q Predictions Std            1309.8297
Q Predictions Max            4430.55
Q Predictions Min            532.9218
V Predictions Mean           1263.3999
V Predictions Std            1308.203
V Predictions Max            4426.223
V Predictions Min            565.62256
Log Pis Mean                 0.09369622
Log Pis Std                  3.714282
Log Pis Max                  12.567744
Log Pis Min                  -6.26468
Policy mu Mean               0.015193787
Policy mu Std                0.94402623
Policy mu Max                2.5943842
Policy mu Min                -2.7988598
Policy log std Mean          -0.5239001
Policy log std Std           0.27284762
Policy log std Max           0.00022992492
Policy log std Min           -2.6926413
Z mean eval                  2.389146
Z variance eval              0.064722165
total_rewards                [ 9826.34698273  9920.72227679 10028.93684906  9953.91845777
 10072.23961152 10133.05398322  9973.69223498  9987.15329236
  2793.27751836 10168.78919194]
total_rewards_mean           9285.813039872184
total_rewards_std            2166.2845800234354
total_rewards_max            10168.789191943217
total_rewards_min            2793.2775183561293
Number of train steps total  876000
Number of env steps total    2630000
Number of rollouts total     0
Train Time (s)               195.87051881896332
(Previous) Eval Time (s)     33.086490815039724
Sample Time (s)              6.867780792526901
Epoch Time (s)               235.82479042652994
Total Train Time (s)         50486.87554192776
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:38:10.025860 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #218 | Epoch Duration: 235.91255450248718
2020-01-13 13:38:10.026053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3890386
Z variance train             0.06466271
KL Divergence                41.067406
KL Loss                      4.1067405
QF Loss                      143.77045
VF Loss                      79.00502
Policy Loss                  -1105.8611
Q Predictions Mean           1103.8943
Q Predictions Std            1165.2522
Q Predictions Max            4410.751
Q Predictions Min            555.5813
V Predictions Mean           1109.5361
V Predictions Std            1167.0121
V Predictions Max            4425.375
V Predictions Min            561.32623
Log Pis Mean                 -0.22431238
Log Pis Std                  3.5467262
Log Pis Max                  15.037555
Log Pis Min                  -6.7525954
Policy mu Mean               0.046042558
Policy mu Std                0.8778192
Policy mu Max                2.6296332
Policy mu Min                -2.5057287
Policy log std Mean          -0.5042022
Policy log std Std           0.27027833
Policy log std Max           0.009835124
Policy log std Min           -2.8271642
Z mean eval                  2.3946345
Z variance eval              0.106455825
total_rewards                [9102.48272189 9399.24850557 9580.85745479 9419.58412965 9250.70673463
 8829.62243224 9332.25163686 9158.55918967 9585.57625397 8725.56519631]
total_rewards_mean           9238.445425558564
total_rewards_std            275.7561698898649
total_rewards_max            9585.576253968318
total_rewards_min            8725.565196313513
Number of train steps total  880000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               195.05346220871434
(Previous) Eval Time (s)     34.35352937411517
Sample Time (s)              6.480478897690773
Epoch Time (s)               235.88747048052028
Total Train Time (s)         50722.853167992085
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:42:06.005713 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #219 | Epoch Duration: 235.97952246665955
2020-01-13 13:42:06.005852 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3917642
Z variance train             0.10631994
KL Divergence                40.182854
KL Loss                      4.0182853
QF Loss                      3221.8076
VF Loss                      76.72015
Policy Loss                  -1258.2112
Q Predictions Mean           1254.6046
Q Predictions Std            1298.4111
Q Predictions Max            4393.259
Q Predictions Min            532.911
V Predictions Mean           1259.3035
V Predictions Std            1298.0853
V Predictions Max            4366.549
V Predictions Min            543.4902
Log Pis Mean                 0.337017
Log Pis Std                  4.005692
Log Pis Max                  15.837389
Log Pis Min                  -6.1081448
Policy mu Mean               -0.015610941
Policy mu Std                0.9514974
Policy mu Max                2.7504044
Policy mu Min                -2.7630353
Policy log std Mean          -0.5294602
Policy log std Std           0.28755036
Policy log std Max           -0.068615824
Policy log std Min           -2.817626
Z mean eval                  2.404042
Z variance eval              0.07819694
total_rewards                [7699.57123657 7505.99046481 7115.71485465 7053.20812707 6521.90259097
 7314.44186747 6771.97929231 6517.94104283 8432.51467142 6842.89053528]
total_rewards_mean           7177.615468340313
total_rewards_std            559.8911967114506
total_rewards_max            8432.514671419018
total_rewards_min            6517.941042832765
Number of train steps total  884000
Number of env steps total    2654000
Number of rollouts total     0
Train Time (s)               191.17771708779037
(Previous) Eval Time (s)     35.989147680811584
Sample Time (s)              10.94678517896682
Epoch Time (s)               238.11364994756877
Total Train Time (s)         50961.07120645605
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:46:04.226160 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #220 | Epoch Duration: 238.22018551826477
2020-01-13 13:46:04.226368 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #220 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4020784
Z variance train             0.07873983
KL Divergence                40.15359
KL Loss                      4.0153594
QF Loss                      132.34564
VF Loss                      85.71526
Policy Loss                  -1083.3295
Q Predictions Mean           1083.2424
Q Predictions Std            1135.8136
Q Predictions Max            4375.5566
Q Predictions Min            555.6483
V Predictions Mean           1078.5469
V Predictions Std            1130.315
V Predictions Max            4352.8716
V Predictions Min            557.3629
Log Pis Mean                 -0.44187754
Log Pis Std                  3.408955
Log Pis Max                  13.6202965
Log Pis Min                  -7.104838
Policy mu Mean               0.0861907
Policy mu Std                0.87974334
Policy mu Max                2.5019867
Policy mu Min                -3.1004815
Policy log std Mean          -0.49363646
Policy log std Std           0.2529865
Policy log std Max           -0.031652123
Policy log std Min           -2.678272
Z mean eval                  2.3609798
Z variance eval              0.09227412
total_rewards                [10081.41853859 10072.65208371 10026.26548536  9826.66930696
 10094.83406514  9971.70021582  9805.25263375  9868.7970367
 10229.19358752  4765.70591976]
total_rewards_mean           9474.248887331532
total_rewards_std            1574.604640369792
total_rewards_max            10229.193587518273
total_rewards_min            4765.705919763195
Number of train steps total  888000
Number of env steps total    2666000
Number of rollouts total     0
Train Time (s)               195.0261837937869
(Previous) Eval Time (s)     35.13867765804753
Sample Time (s)              6.947510142344981
Epoch Time (s)               237.11237159417942
Total Train Time (s)         51198.26542283455
Epoch                        221
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:50:01.424135 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #221 | Epoch Duration: 237.19754648208618
2020-01-13 13:50:01.424439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #221 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3606632
Z variance train             0.09214312
KL Divergence                39.539368
KL Loss                      3.9539368
QF Loss                      2797.6543
VF Loss                      59.758343
Policy Loss                  -1118.9646
Q Predictions Mean           1118.3585
Q Predictions Std            1188.0872
Q Predictions Max            4483.1553
Q Predictions Min            532.71655
V Predictions Mean           1119.0547
V Predictions Std            1181.7983
V Predictions Max            4469.6865
V Predictions Min            536.17175
Log Pis Mean                 -0.33976546
Log Pis Std                  3.7515135
Log Pis Max                  14.288387
Log Pis Min                  -7.2267857
Policy mu Mean               0.018507276
Policy mu Std                0.8655154
Policy mu Max                3.4768765
Policy mu Min                -5.1936784
Policy log std Mean          -0.4933751
Policy log std Std           0.27471644
Policy log std Max           0.1526055
Policy log std Min           -2.9599118
Z mean eval                  2.3995926
Z variance eval              0.09159069
total_rewards                [ 9998.2271548   9957.41762895  9994.34962085  9654.26793838
  9969.21800965 10100.53445393 10002.08580514 10166.29440854
  9966.20609231 10151.55121876]
total_rewards_mean           9996.01523313031
total_rewards_std            135.66240864887746
total_rewards_max            10166.294408540616
total_rewards_min            9654.267938383497
Number of train steps total  892000
Number of env steps total    2678000
Number of rollouts total     0
Train Time (s)               191.85562705202028
(Previous) Eval Time (s)     34.57243562117219
Sample Time (s)              6.861296225804836
Epoch Time (s)               233.2893588989973
Total Train Time (s)         51431.66434864141
Epoch                        222
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:53:54.831346 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #222 | Epoch Duration: 233.40666222572327
2020-01-13 13:53:54.831525 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #222 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.397653
Z variance train             0.09140006
KL Divergence                40.373493
KL Loss                      4.037349
QF Loss                      2951.921
VF Loss                      71.44578
Policy Loss                  -1208.3152
Q Predictions Mean           1206.9592
Q Predictions Std            1252.6366
Q Predictions Max            4487.6436
Q Predictions Min            570.421
V Predictions Mean           1212.2777
V Predictions Std            1251.7894
V Predictions Max            4486.6724
V Predictions Min            575.80505
Log Pis Mean                 0.08646102
Log Pis Std                  3.9329877
Log Pis Max                  17.101988
Log Pis Min                  -6.8824644
Policy mu Mean               0.033315416
Policy mu Std                0.9316368
Policy mu Max                3.0930526
Policy mu Min                -2.8163104
Policy log std Mean          -0.51461786
Policy log std Std           0.28749168
Policy log std Max           0.08497059
Policy log std Min           -2.94971
Z mean eval                  2.4002438
Z variance eval              0.06861885
total_rewards                [ 9935.96694891 10194.44771058 10037.93764519 10046.60361835
  9944.01017174 10064.76101808  9951.392757    9779.11887606
 10090.23261764 10091.42216255]
total_rewards_mean           10013.589352609413
total_rewards_std            108.9286570700059
total_rewards_max            10194.44771057897
total_rewards_min            9779.118876059149
Number of train steps total  896000
Number of env steps total    2690000
Number of rollouts total     0
Train Time (s)               194.81662129005417
(Previous) Eval Time (s)     29.23098408896476
Sample Time (s)              7.557848425582051
Epoch Time (s)               231.60545380460098
Total Train Time (s)         51663.35027601896
Epoch                        223
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:57:46.520321 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #223 | Epoch Duration: 231.68864178657532
2020-01-13 13:57:46.520515 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3979957
Z variance train             0.068653904
KL Divergence                41.82917
KL Loss                      4.182917
QF Loss                      3208.2388
VF Loss                      58.883087
Policy Loss                  -1233.6865
Q Predictions Mean           1231.6389
Q Predictions Std            1273.4158
Q Predictions Max            4410.803
Q Predictions Min            578.434
V Predictions Mean           1238.0083
V Predictions Std            1273.3785
V Predictions Max            4405.146
V Predictions Min            583.94055
Log Pis Mean                 0.08770079
Log Pis Std                  3.8090575
Log Pis Max                  14.443766
Log Pis Min                  -6.724559
Policy mu Mean               0.032141585
Policy mu Std                0.92190313
Policy mu Max                2.584199
Policy mu Min                -3.1663141
Policy log std Mean          -0.5122244
Policy log std Std           0.2620435
Policy log std Max           0.0039367676
Policy log std Min           -2.5435228
Z mean eval                  2.4106402
Z variance eval              0.08439363
total_rewards                [9317.01046355 9552.15452518 9463.77579658 9389.51446304 9370.64552702
 9487.751913   9286.27733743 9255.9939915  9286.94655723 9203.32282524]
total_rewards_mean           9361.33933997692
total_rewards_std            106.2848742069645
total_rewards_max            9552.154525178468
total_rewards_min            9203.322825240346
Number of train steps total  900000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               196.26131356693804
(Previous) Eval Time (s)     31.142883136868477
Sample Time (s)              7.53200967470184
Epoch Time (s)               234.93620637850836
Total Train Time (s)         51898.37464829115
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:01:41.547821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #224 | Epoch Duration: 235.02709794044495
2020-01-13 14:01:41.548139 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.410561
Z variance train             0.08447728
KL Divergence                41.690968
KL Loss                      4.169097
QF Loss                      318.07028
VF Loss                      49.87278
Policy Loss                  -1196.9904
Q Predictions Mean           1196.0902
Q Predictions Std            1230.327
Q Predictions Max            4481.2314
Q Predictions Min            557.33514
V Predictions Mean           1195.0132
V Predictions Std            1228.9294
V Predictions Max            4469.3657
V Predictions Min            549.55725
Log Pis Mean                 0.14883469
Log Pis Std                  3.8146856
Log Pis Max                  12.585114
Log Pis Min                  -6.5033298
Policy mu Mean               0.03140921
Policy mu Std                0.9130306
Policy mu Max                2.8274224
Policy mu Min                -2.7652836
Policy log std Mean          -0.50712705
Policy log std Std           0.2818716
Policy log std Max           0.34917998
Policy log std Min           -2.9957168
Z mean eval                  2.3959744
Z variance eval              0.12524995
total_rewards                [10011.37636232 10029.08325081 10027.61340583 10233.18973024
 10221.8958175  10010.82742271 10056.32939486 10302.94381139
  9854.87649547  9959.03602829]
total_rewards_mean           10070.717171942502
total_rewards_std            131.58565367425754
total_rewards_max            10302.943811387508
total_rewards_min            9854.876495469854
Number of train steps total  904000
Number of env steps total    2714000
Number of rollouts total     0
Train Time (s)               192.96787288365886
(Previous) Eval Time (s)     32.37242837389931
Sample Time (s)              6.973005533684045
Epoch Time (s)               232.3133067912422
Total Train Time (s)         52130.78075214336
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:05:33.958156 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #225 | Epoch Duration: 232.40979409217834
2020-01-13 14:05:33.958414 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.39852
Z variance train             0.1253998
KL Divergence                41.660194
KL Loss                      4.1660194
QF Loss                      203.80261
VF Loss                      62.186447
Policy Loss                  -1256.364
Q Predictions Mean           1256.3154
Q Predictions Std            1344.8093
Q Predictions Max            4470.1304
Q Predictions Min            552.9969
V Predictions Mean           1254.3086
V Predictions Std            1336.9208
V Predictions Max            4445.73
V Predictions Min            561.49146
Log Pis Mean                 -0.015500799
Log Pis Std                  3.804929
Log Pis Max                  14.459036
Log Pis Min                  -8.192284
Policy mu Mean               0.065311335
Policy mu Std                0.9356456
Policy mu Max                2.8101885
Policy mu Min                -2.5812235
Policy log std Mean          -0.5143346
Policy log std Std           0.27620843
Policy log std Max           0.21264255
Policy log std Min           -2.7324717
Z mean eval                  2.4116669
Z variance eval              0.097880386
total_rewards                [ 9642.42778486  9670.9582329   9724.3030066  10148.47946084
  9551.15313731  9704.31017616  9911.9655435   9900.24202811
  9708.19287445 10152.13760722]
total_rewards_mean           9811.416985194137
total_rewards_std            198.35341385315843
total_rewards_max            10152.137607218236
total_rewards_min            9551.15313731123
Number of train steps total  908000
Number of env steps total    2726000
Number of rollouts total     0
Train Time (s)               196.57286082673818
(Previous) Eval Time (s)     30.52216927986592
Sample Time (s)              7.512237580958754
Epoch Time (s)               234.60726768756285
Total Train Time (s)         52365.47081272816
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:09:28.650191 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #226 | Epoch Duration: 234.6915807723999
2020-01-13 14:09:28.650397 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #226 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4109917
Z variance train             0.0978754
KL Divergence                42.694435
KL Loss                      4.2694435
QF Loss                      196.28522
VF Loss                      32.663155
Policy Loss                  -1258.4579
Q Predictions Mean           1256.2329
Q Predictions Std            1302.0686
Q Predictions Max            4518.6074
Q Predictions Min            555.01013
V Predictions Mean           1257.8323
V Predictions Std            1296.1337
V Predictions Max            4496.5244
V Predictions Min            562.2218
Log Pis Mean                 0.43158644
Log Pis Std                  4.1434693
Log Pis Max                  25.25772
Log Pis Min                  -5.8801894
Policy mu Mean               0.09695526
Policy mu Std                0.958268
Policy mu Max                4.4704976
Policy mu Min                -3.1775637
Policy log std Mean          -0.5395861
Policy log std Std           0.2931645
Policy log std Max           0.34588742
Policy log std Min           -2.8683016
Z mean eval                  2.411726
Z variance eval              0.09582144
total_rewards                [ 9767.25458537  9588.65456707  9858.39495149  9985.92842392
  9829.87403882  9929.68332533  9538.10603912  9733.01116016
  9928.2431775  10002.98964018]
total_rewards_mean           9816.213990896023
total_rewards_std            151.5014354531943
total_rewards_max            10002.989640182679
total_rewards_min            9538.106039115666
Number of train steps total  912000
Number of env steps total    2738000
Number of rollouts total     0
Train Time (s)               193.4586853920482
(Previous) Eval Time (s)     31.10760118998587
Sample Time (s)              6.28512965887785
Epoch Time (s)               230.85141624091193
Total Train Time (s)         52596.40480750054
Epoch                        227
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:13:19.586870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #227 | Epoch Duration: 230.93630647659302
2020-01-13 14:13:19.587073 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.414824
Z variance train             0.095659494
KL Divergence                42.131958
KL Loss                      4.213196
QF Loss                      250.73566
VF Loss                      153.3715
Policy Loss                  -1176.615
Q Predictions Mean           1172.7556
Q Predictions Std            1218.0441
Q Predictions Max            4509.5254
Q Predictions Min            575.27985
V Predictions Mean           1167.6804
V Predictions Std            1209.6605
V Predictions Max            4480.926
V Predictions Min            582.5086
Log Pis Mean                 -0.33662957
Log Pis Std                  3.877576
Log Pis Max                  15.924806
Log Pis Min                  -7.5127563
Policy mu Mean               0.07418477
Policy mu Std                0.89782494
Policy mu Max                3.1637332
Policy mu Min                -3.1792188
Policy log std Mean          -0.5111974
Policy log std Std           0.2874569
Policy log std Max           0.13729832
Policy log std Min           -2.6487935
Z mean eval                  2.4282832
Z variance eval              0.07908715
total_rewards                [ 9847.63808752  9630.61720113  9686.86339118  9592.30855893
  9600.53485451  9707.18433962  9580.4851784  10029.21009911
  9584.89717313  9543.70798977]
total_rewards_mean           9680.34468733006
total_rewards_std            143.10889089528033
total_rewards_max            10029.21009910952
total_rewards_min            9543.707989767083
Number of train steps total  916000
Number of env steps total    2750000
Number of rollouts total     0
Train Time (s)               198.02092743758112
(Previous) Eval Time (s)     33.30674115009606
Sample Time (s)              7.20074018696323
Epoch Time (s)               238.5284087746404
Total Train Time (s)         52835.103105303366
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:17:18.288823 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #228 | Epoch Duration: 238.70158052444458
2020-01-13 14:17:18.289033 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4318097
Z variance train             0.07925366
KL Divergence                41.605488
KL Loss                      4.1605487
QF Loss                      812.78937
VF Loss                      268.66843
Policy Loss                  -1222.9587
Q Predictions Mean           1221.5017
Q Predictions Std            1258.2413
Q Predictions Max            4468.622
Q Predictions Min            560.7407
V Predictions Mean           1218.7087
V Predictions Std            1256.4631
V Predictions Max            4463.512
V Predictions Min            565.95544
Log Pis Mean                 0.365883
Log Pis Std                  3.8209767
Log Pis Max                  13.232721
Log Pis Min                  -6.1055646
Policy mu Mean               0.024550304
Policy mu Std                0.9375917
Policy mu Max                2.8458788
Policy mu Min                -2.326843
Policy log std Mean          -0.52312
Policy log std Std           0.29595685
Policy log std Max           -0.063673854
Policy log std Min           -2.7976031
Z mean eval                  2.4191616
Z variance eval              0.09887032
total_rewards                [9572.88419628 9382.23393701 9482.26725448 9577.51398079 9298.91367001
 9442.62665046 9534.04789382 9631.63253922 9165.90826525 9503.23703505]
total_rewards_mean           9459.126542237334
total_rewards_std            135.14399249188347
total_rewards_max            9631.632539215041
total_rewards_min            9165.90826525392
Number of train steps total  920000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               196.14655710896477
(Previous) Eval Time (s)     30.794014943763614
Sample Time (s)              7.959129402879626
Epoch Time (s)               234.899701455608
Total Train Time (s)         53070.08728917129
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:21:13.276004 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #229 | Epoch Duration: 234.9867331981659
2020-01-13 14:21:13.276288 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #229 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.420576
Z variance train             0.09893491
KL Divergence                40.497593
KL Loss                      4.0497594
QF Loss                      150.84927
VF Loss                      55.408825
Policy Loss                  -1318.4834
Q Predictions Mean           1317.6006
Q Predictions Std            1331.1554
Q Predictions Max            4636.87
Q Predictions Min            584.3021
V Predictions Mean           1319.7532
V Predictions Std            1331.3922
V Predictions Max            4652.182
V Predictions Min            593.2626
Log Pis Mean                 -0.13969523
Log Pis Std                  3.46042
Log Pis Max                  13.005127
Log Pis Min                  -8.01276
Policy mu Mean               0.018006397
Policy mu Std                0.91460526
Policy mu Max                2.6470058
Policy mu Min                -2.4356089
Policy log std Mean          -0.49817613
Policy log std Std           0.27631614
Policy log std Max           -0.0550465
Policy log std Min           -2.478229
Z mean eval                  2.4620757
Z variance eval              0.07893929
total_rewards                [10018.85538459 10153.41958364 10087.45854455 10224.5201496
 10156.94887526 10104.0730251  10160.75125286 10111.06479377
 10059.74110755  9801.94635807]
total_rewards_mean           10087.877907497783
total_rewards_std            110.07309626889084
total_rewards_max            10224.520149595619
total_rewards_min            9801.946358068084
Number of train steps total  924000
Number of env steps total    2774000
Number of rollouts total     0
Train Time (s)               196.57652425393462
(Previous) Eval Time (s)     32.005833784118295
Sample Time (s)              7.206115423236042
Epoch Time (s)               235.78847346128896
Total Train Time (s)         53305.96336185839
Epoch                        230
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:25:09.154230 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #230 | Epoch Duration: 235.87776279449463
2020-01-13 14:25:09.154407 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4578598
Z variance train             0.07891762
KL Divergence                42.669357
KL Loss                      4.266936
QF Loss                      91.2435
VF Loss                      44.408127
Policy Loss                  -1131.5856
Q Predictions Mean           1129.6079
Q Predictions Std            1174.5278
Q Predictions Max            4549.2056
Q Predictions Min            570.58777
V Predictions Mean           1133.1504
V Predictions Std            1170.825
V Predictions Max            4553.704
V Predictions Min            586.1423
Log Pis Mean                 -0.64285743
Log Pis Std                  3.601396
Log Pis Max                  18.682465
Log Pis Min                  -7.5093007
Policy mu Mean               0.03991191
Policy mu Std                0.8372736
Policy mu Max                3.033994
Policy mu Min                -3.0067952
Policy log std Mean          -0.4995984
Policy log std Std           0.28762516
Policy log std Max           0.08571571
Policy log std Min           -3.0017292
Z mean eval                  2.4020147
Z variance eval              0.08812787
total_rewards                [ 9955.88138488  9702.70471949  9979.97672053  9823.61202438
 10065.74986893  9449.91456658  9936.03527022  9950.91524537
  9712.84689745  9769.94622814]
total_rewards_mean           9834.758292598297
total_rewards_std            172.50966303198769
total_rewards_max            10065.74986893477
total_rewards_min            9449.91456658151
Number of train steps total  928000
Number of env steps total    2786000
Number of rollouts total     0
Train Time (s)               195.21153239207342
(Previous) Eval Time (s)     35.25726231606677
Sample Time (s)              6.966855029109865
Epoch Time (s)               237.43564973725006
Total Train Time (s)         53543.47805478051
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:29:06.671286 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #231 | Epoch Duration: 237.5167429447174
2020-01-13 14:29:06.671456 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4034202
Z variance train             0.08819283
KL Divergence                40.189507
KL Loss                      4.018951
QF Loss                      115.89203
VF Loss                      46.521893
Policy Loss                  -1256.6462
Q Predictions Mean           1254.2876
Q Predictions Std            1289.956
Q Predictions Max            4609.8315
Q Predictions Min            582.82874
V Predictions Mean           1255.1991
V Predictions Std            1287.3025
V Predictions Max            4594.576
V Predictions Min            586.541
Log Pis Mean                 0.066550694
Log Pis Std                  4.1549754
Log Pis Max                  19.677834
Log Pis Min                  -5.8506126
Policy mu Mean               0.0651409
Policy mu Std                0.9190484
Policy mu Max                3.263699
Policy mu Min                -3.1103125
Policy log std Mean          -0.51173997
Policy log std Std           0.28984237
Policy log std Max           -0.056755066
Policy log std Min           -3.1245718
Z mean eval                  2.4659958
Z variance eval              0.105923414
total_rewards                [ 9425.2993767   9812.6919756   9884.37713227  9796.03927002
 10155.86044781  9866.5326589   9617.8901464   9782.99584281
  9638.91056473  9863.53743778]
total_rewards_mean           9784.41348530177
total_rewards_std            184.32868525585693
total_rewards_max            10155.860447810272
total_rewards_min            9425.299376704048
Number of train steps total  932000
Number of env steps total    2798000
Number of rollouts total     0
Train Time (s)               193.81017005071044
(Previous) Eval Time (s)     32.10321555798873
Sample Time (s)              7.201865551993251
Epoch Time (s)               233.11525116069242
Total Train Time (s)         53776.68018702511
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:32:59.879377 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #232 | Epoch Duration: 233.2077512741089
2020-01-13 14:32:59.879680 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4637296
Z variance train             0.104984224
KL Divergence                42.80886
KL Loss                      4.280886
QF Loss                      98.66349
VF Loss                      56.47465
Policy Loss                  -1332.2197
Q Predictions Mean           1332.3134
Q Predictions Std            1380.9562
Q Predictions Max            4576.939
Q Predictions Min            578.2599
V Predictions Mean           1333.668
V Predictions Std            1375.5468
V Predictions Max            4561.4434
V Predictions Min            585.954
Log Pis Mean                 0.13147214
Log Pis Std                  3.9406278
Log Pis Max                  22.669533
Log Pis Min                  -6.7879114
Policy mu Mean               0.00100869
Policy mu Std                0.92025095
Policy mu Max                4.186402
Policy mu Min                -3.3442652
Policy log std Mean          -0.5334646
Policy log std Std           0.29049924
Policy log std Max           0.10173851
Policy log std Min           -2.6531467
Z mean eval                  2.4346063
Z variance eval              0.05230067
total_rewards                [9881.75690044 9664.18214655 9798.87481691 9453.06614502 9599.32170283
 9958.07257823 9936.57457493 9864.50994219 9423.25599899 9636.32041461]
total_rewards_mean           9721.593522068846
total_rewards_std            184.61289313398083
total_rewards_max            9958.072578227284
total_rewards_min            9423.255998987785
Number of train steps total  936000
Number of env steps total    2810000
Number of rollouts total     0
Train Time (s)               194.72435270482674
(Previous) Eval Time (s)     31.116095033939928
Sample Time (s)              7.896603373344988
Epoch Time (s)               233.73705111211166
Total Train Time (s)         54010.497566146776
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:36:53.699245 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #233 | Epoch Duration: 233.81928181648254
2020-01-13 14:36:53.699557 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #233 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4345481
Z variance train             0.052402712
KL Divergence                43.523094
KL Loss                      4.3523097
QF Loss                      160.55228
VF Loss                      35.319878
Policy Loss                  -1290.4368
Q Predictions Mean           1287.2961
Q Predictions Std            1321.4323
Q Predictions Max            4516.8726
Q Predictions Min            567.1451
V Predictions Mean           1290.3191
V Predictions Std            1318.5409
V Predictions Max            4499.938
V Predictions Min            571.35925
Log Pis Mean                 0.16266537
Log Pis Std                  4.02417
Log Pis Max                  16.043005
Log Pis Min                  -6.666869
Policy mu Mean               0.028262364
Policy mu Std                0.92615753
Policy mu Max                2.671039
Policy mu Min                -2.9620805
Policy log std Mean          -0.526436
Policy log std Std           0.2986904
Policy log std Max           0.058363914
Policy log std Min           -3.0339184
Z mean eval                  2.4336777
Z variance eval              0.046117533
total_rewards                [10116.30107356  9859.2581396  10181.58582001 10285.07532466
 10190.41215773 10250.37202542 10152.58387921  9991.6213032
  9998.50498024 10227.81869153]
total_rewards_mean           10125.35333951568
total_rewards_std            128.31193998904925
total_rewards_max            10285.075324662954
total_rewards_min            9859.25813959727
Number of train steps total  940000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               195.6043453346938
(Previous) Eval Time (s)     31.61825718637556
Sample Time (s)              7.1636961391195655
Epoch Time (s)               234.3862986601889
Total Train Time (s)         54244.981321642175
Epoch                        234
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:40:48.186027 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #234 | Epoch Duration: 234.48627066612244
2020-01-13 14:40:48.186242 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #234 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4353006
Z variance train             0.04623424
KL Divergence                44.457306
KL Loss                      4.4457307
QF Loss                      183.90561
VF Loss                      33.685135
Policy Loss                  -1154.1045
Q Predictions Mean           1151.4662
Q Predictions Std            1211.5354
Q Predictions Max            4527.4116
Q Predictions Min            589.4103
V Predictions Mean           1155.4417
V Predictions Std            1212.5957
V Predictions Max            4531.2407
V Predictions Min            591.5016
Log Pis Mean                 -0.31189808
Log Pis Std                  3.8685932
Log Pis Max                  13.564377
Log Pis Min                  -7.721276
Policy mu Mean               0.025800286
Policy mu Std                0.86092585
Policy mu Max                2.7946079
Policy mu Min                -2.6434789
Policy log std Mean          -0.52303034
Policy log std Std           0.29360846
Policy log std Max           -0.054675996
Policy log std Min           -2.915548
Z mean eval                  2.4461184
Z variance eval              0.058813713
total_rewards                [10489.39215365 10233.24728104 10410.72737963 10434.98268068
 10590.24683785 10263.65752709 10203.45434124 10228.67936758
 10326.07323994 10268.37405839]
total_rewards_mean           10344.883486708171
total_rewards_std            123.41500286479234
total_rewards_max            10590.246837847066
total_rewards_min            10203.454341236018
Number of train steps total  944000
Number of env steps total    2834000
Number of rollouts total     0
Train Time (s)               194.48738196212798
(Previous) Eval Time (s)     35.70289871795103
Sample Time (s)              6.999385957606137
Epoch Time (s)               237.18966663768515
Total Train Time (s)         54482.257302054204
Epoch                        235
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:44:45.466906 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #235 | Epoch Duration: 237.2804844379425
2020-01-13 14:44:45.467199 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #235 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4484043
Z variance train             0.058625598
KL Divergence                43.75884
KL Loss                      4.375884
QF Loss                      2834.355
VF Loss                      92.02283
Policy Loss                  -1142.1694
Q Predictions Mean           1140.3467
Q Predictions Std            1202.7743
Q Predictions Max            4517.4624
Q Predictions Min            579.3158
V Predictions Mean           1136.3588
V Predictions Std            1197.8378
V Predictions Max            4486.952
V Predictions Min            579.5096
Log Pis Mean                 -0.16023901
Log Pis Std                  3.6631474
Log Pis Max                  21.39516
Log Pis Min                  -8.089535
Policy mu Mean               0.052458514
Policy mu Std                0.8946423
Policy mu Max                3.5524383
Policy mu Min                -3.2585394
Policy log std Mean          -0.5137632
Policy log std Std           0.2832538
Policy log std Max           0.031698287
Policy log std Min           -3.0669236
Z mean eval                  2.451985
Z variance eval              0.06048706
total_rewards                [ 9344.30995898  9840.91906027  9790.01051943  9949.04901066
  9979.77807637  9343.32442891 10107.68445728  9635.71684698
  3383.56684037 10008.54153902]
total_rewards_mean           9138.290073825989
total_rewards_std            1934.6751250631776
total_rewards_max            10107.684457281166
total_rewards_min            3383.5668403716436
Number of train steps total  948000
Number of env steps total    2846000
Number of rollouts total     0
Train Time (s)               197.16367768403143
(Previous) Eval Time (s)     32.0531685766764
Sample Time (s)              6.442511627916247
Epoch Time (s)               235.65935788862407
Total Train Time (s)         54718.1818493912
Epoch                        236
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:48:41.393442 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #236 | Epoch Duration: 235.9260115623474
2020-01-13 14:48:41.393684 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #236 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4537158
Z variance train             0.060535885
KL Divergence                44.15611
KL Loss                      4.415611
QF Loss                      3081.2192
VF Loss                      47.783623
Policy Loss                  -1220.7064
Q Predictions Mean           1217.1948
Q Predictions Std            1253.1144
Q Predictions Max            4584.3823
Q Predictions Min            576.3718
V Predictions Mean           1217.1443
V Predictions Std            1250.6833
V Predictions Max            4567.703
V Predictions Min            576.60077
Log Pis Mean                 -0.36050296
Log Pis Std                  3.402899
Log Pis Max                  11.578382
Log Pis Min                  -6.45387
Policy mu Mean               0.075586356
Policy mu Std                0.895862
Policy mu Max                2.9305713
Policy mu Min                -2.8815937
Policy log std Mean          -0.51485497
Policy log std Std           0.2859915
Policy log std Max           0.04414904
Policy log std Min           -2.9710138
Z mean eval                  2.4284866
Z variance eval              0.09292008
total_rewards                [10210.41227893 10073.84803043  9763.03790565 10059.00858361
 10099.84137627  9675.93619762 10205.3696796  10114.15465823
 10046.1592565  10100.4442564 ]
total_rewards_mean           10034.821222323613
total_rewards_std            167.22682078673185
total_rewards_max            10210.412278928026
total_rewards_min            9675.936197617662
Number of train steps total  952000
Number of env steps total    2858000
Number of rollouts total     0
Train Time (s)               197.4590585064143
(Previous) Eval Time (s)     29.27610050793737
Sample Time (s)              6.576246878132224
Epoch Time (s)               233.3114058924839
Total Train Time (s)         54951.571329383645
Epoch                        237
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:52:34.784821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #237 | Epoch Duration: 233.3909204006195
2020-01-13 14:52:34.785037 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #237 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.429174
Z variance train             0.09233722
KL Divergence                42.761074
KL Loss                      4.2761073
QF Loss                      3216.1216
VF Loss                      66.66252
Policy Loss                  -1161.4706
Q Predictions Mean           1157.5529
Q Predictions Std            1172.4027
Q Predictions Max            4525.3496
Q Predictions Min            590.4592
V Predictions Mean           1157.5225
V Predictions Std            1169.3663
V Predictions Max            4508.022
V Predictions Min            589.3313
Log Pis Mean                 -0.2799439
Log Pis Std                  3.518029
Log Pis Max                  16.204786
Log Pis Min                  -8.1314945
Policy mu Mean               0.03976816
Policy mu Std                0.8755277
Policy mu Max                3.175318
Policy mu Min                -2.6284683
Policy log std Mean          -0.5211642
Policy log std Std           0.2748319
Policy log std Max           -0.08463448
Policy log std Min           -2.7914534
Z mean eval                  2.4352508
Z variance eval              0.12903342
total_rewards                [10001.5497177   9853.64952715  9926.65590085 10012.3250298
 10008.94932525 10021.36419655 10093.8950637   9949.01438414
 10072.45338652  9941.93928893]
total_rewards_mean           9988.179582058492
total_rewards_std            67.91743346254125
total_rewards_max            10093.895063696538
total_rewards_min            9853.649527149633
Number of train steps total  956000
Number of env steps total    2870000
Number of rollouts total     0
Train Time (s)               198.57387296902016
(Previous) Eval Time (s)     31.901637189090252
Sample Time (s)              5.549863871652633
Epoch Time (s)               236.02537402976304
Total Train Time (s)         55187.688224718906
Epoch                        238
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:56:30.908756 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #238 | Epoch Duration: 236.12353086471558
2020-01-13 14:56:30.909093 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #238 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4360623
Z variance train             0.12942947
KL Divergence                42.41222
KL Loss                      4.241222
QF Loss                      259.12976
VF Loss                      55.464066
Policy Loss                  -1168.5768
Q Predictions Mean           1165.7404
Q Predictions Std            1183.9772
Q Predictions Max            4480.4785
Q Predictions Min            599.7473
V Predictions Mean           1166.2676
V Predictions Std            1184.8828
V Predictions Max            4479.4287
V Predictions Min            594.443
Log Pis Mean                 -0.06158214
Log Pis Std                  3.6031787
Log Pis Max                  17.734154
Log Pis Min                  -5.6478386
Policy mu Mean               0.050845087
Policy mu Std                0.87285525
Policy mu Max                2.859379
Policy mu Min                -2.7226806
Policy log std Mean          -0.52305084
Policy log std Std           0.28262407
Policy log std Max           -0.088623315
Policy log std Min           -2.6616683
Z mean eval                  2.4298973
Z variance eval              0.0830058
total_rewards                [10077.76827315  9896.49033284 10093.19564171  9957.9056528
  9926.35813505  9860.15461785  9522.17250188 10094.97626665
 10026.25306242 10142.49472817]
total_rewards_mean           9959.776921251005
total_rewards_std            171.56747703903267
total_rewards_max            10142.49472817361
total_rewards_min            9522.172501881018
Number of train steps total  960000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               198.08578472677618
(Previous) Eval Time (s)     27.170612109359354
Sample Time (s)              7.014418813865632
Epoch Time (s)               232.27081565000117
Total Train Time (s)         55420.06836672081
Epoch                        239
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:00:23.290752 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #239 | Epoch Duration: 232.38135147094727
2020-01-13 15:00:23.291060 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #239 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4284668
Z variance train             0.08288099
KL Divergence                43.160564
KL Loss                      4.3160567
QF Loss                      3082.8813
VF Loss                      30.600695
Policy Loss                  -1278.9059
Q Predictions Mean           1277.2512
Q Predictions Std            1292.4578
Q Predictions Max            4568.9146
Q Predictions Min            589.2656
V Predictions Mean           1277.4225
V Predictions Std            1292.8242
V Predictions Max            4557.018
V Predictions Min            601.1708
Log Pis Mean                 -0.25163886
Log Pis Std                  3.4318373
Log Pis Max                  11.787699
Log Pis Min                  -6.8620143
Policy mu Mean               0.01248335
Policy mu Std                0.87811065
Policy mu Max                2.5689018
Policy mu Min                -2.737016
Policy log std Mean          -0.5171698
Policy log std Std           0.27432927
Policy log std Max           -0.06167832
Policy log std Min           -2.8766294
Z mean eval                  2.4281955
Z variance eval              0.06639183
total_rewards                [ 9914.78539808 10166.34375754  9880.53031624 10166.66434514
  9751.09281593  9793.74616398  9949.7852362   9739.10160096
  9737.18112717  9991.88395727]
total_rewards_mean           9909.111471849761
total_rewards_std            154.4665323559619
total_rewards_max            10166.664345137007
total_rewards_min            9737.181127172453
Number of train steps total  964000
Number of env steps total    2894000
Number of rollouts total     0
Train Time (s)               196.58118242304772
(Previous) Eval Time (s)     33.14005814213306
Sample Time (s)              8.439356827642769
Epoch Time (s)               238.16059739282355
Total Train Time (s)         55658.330625605304
Epoch                        240
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:04:21.554484 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #240 | Epoch Duration: 238.26324892044067
2020-01-13 15:04:21.554635 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #240 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4262376
Z variance train             0.06650236
KL Divergence                43.32369
KL Loss                      4.332369
QF Loss                      157.49438
VF Loss                      60.65896
Policy Loss                  -1267.5092
Q Predictions Mean           1265.3479
Q Predictions Std            1329.3431
Q Predictions Max            4556.972
Q Predictions Min            603.4655
V Predictions Mean           1271.7244
V Predictions Std            1329.7545
V Predictions Max            4563.138
V Predictions Min            608.4014
Log Pis Mean                 -0.15197407
Log Pis Std                  3.7633889
Log Pis Max                  17.572334
Log Pis Min                  -7.2172
Policy mu Mean               0.051377084
Policy mu Std                0.8869179
Policy mu Max                3.1791513
Policy mu Min                -2.5202556
Policy log std Mean          -0.53224796
Policy log std Std           0.29128742
Policy log std Max           -0.091513395
Policy log std Min           -2.7154765
Z mean eval                  2.4187787
Z variance eval              0.057434976
total_rewards                [10020.99165804 10009.92950988 10017.03872794  9708.19615101
  9831.8542363  10138.74653013  9811.52645974  9849.0106614
 10255.55323762  9725.92206343]
total_rewards_mean           9936.876923548058
total_rewards_std            170.9981425049216
total_rewards_max            10255.553237624139
total_rewards_min            9708.196151005384
Number of train steps total  968000
Number of env steps total    2906000
Number of rollouts total     0
Train Time (s)               194.42304257210344
(Previous) Eval Time (s)     32.65268359705806
Sample Time (s)              7.135210526641458
Epoch Time (s)               234.21093669580296
Total Train Time (s)         55892.62255970109
Epoch                        241
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:08:15.849446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #241 | Epoch Duration: 234.29468250274658
2020-01-13 15:08:15.849640 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #241 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.417994
Z variance train             0.05743126
KL Divergence                43.74251
KL Loss                      4.3742514
QF Loss                      199.17819
VF Loss                      44.328854
Policy Loss                  -1333.7964
Q Predictions Mean           1331.1537
Q Predictions Std            1372.3977
Q Predictions Max            4523.563
Q Predictions Min            593.51355
V Predictions Mean           1332.6926
V Predictions Std            1370.5651
V Predictions Max            4514.1636
V Predictions Min            595.04816
Log Pis Mean                 -0.116267785
Log Pis Std                  4.112
Log Pis Max                  13.930082
Log Pis Min                  -7.121718
Policy mu Mean               -0.02507402
Policy mu Std                0.91285336
Policy mu Max                3.0429592
Policy mu Min                -3.1665924
Policy log std Mean          -0.518991
Policy log std Std           0.3011048
Policy log std Max           -0.03383416
Policy log std Min           -2.86472
Z mean eval                  2.4514785
Z variance eval              0.06993577
total_rewards                [10030.2069322  10077.67202995  9901.78721521 10122.04477881
  9970.58301265 10174.94442904 10181.95235238 10003.55190506
 10043.729265    9859.01605752]
total_rewards_mean           10036.54879778116
total_rewards_std            102.22858873399039
total_rewards_max            10181.952352381108
total_rewards_min            9859.016057516172
Number of train steps total  972000
Number of env steps total    2918000
Number of rollouts total     0
Train Time (s)               195.6038527050987
(Previous) Eval Time (s)     35.452341373078525
Sample Time (s)              6.979200796689838
Epoch Time (s)               238.03539487486705
Total Train Time (s)         56130.74202546524
Epoch                        242
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:12:13.973811 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #242 | Epoch Duration: 238.1240096092224
2020-01-13 15:12:13.974044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #242 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4515882
Z variance train             0.06997164
KL Divergence                45.58004
KL Loss                      4.558004
QF Loss                      3690.8005
VF Loss                      82.90807
Policy Loss                  -1361.0681
Q Predictions Mean           1361.5223
Q Predictions Std            1364.8639
Q Predictions Max            4584.5015
Q Predictions Min            581.7612
V Predictions Mean           1361.7299
V Predictions Std            1364.9946
V Predictions Max            4564.6626
V Predictions Min            601.69653
Log Pis Mean                 0.17767388
Log Pis Std                  4.1592703
Log Pis Max                  15.24107
Log Pis Min                  -8.317644
Policy mu Mean               0.049292788
Policy mu Std                0.93557215
Policy mu Max                2.6523218
Policy mu Min                -2.6455495
Policy log std Mean          -0.55560005
Policy log std Std           0.30712453
Policy log std Max           0.012417465
Policy log std Min           -3.00222
Z mean eval                  2.458138
Z variance eval              0.080647066
total_rewards                [10031.68157626  9921.20226235 10341.10688487  9907.67610683
 10188.37696047 10210.82893686 10365.74020471 10328.7443794
 10289.36291018 10254.243433  ]
total_rewards_mean           10183.896365492394
total_rewards_std            162.49793311433936
total_rewards_max            10365.74020470599
total_rewards_min            9907.676106826544
Number of train steps total  976000
Number of env steps total    2930000
Number of rollouts total     0
Train Time (s)               194.65164951886982
(Previous) Eval Time (s)     30.9236213658005
Sample Time (s)              6.9767662370577455
Epoch Time (s)               232.55203712172806
Total Train Time (s)         56363.379692917224
Epoch                        243
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:16:06.615810 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #243 | Epoch Duration: 232.64157629013062
2020-01-13 15:16:06.616026 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #243 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4556937
Z variance train             0.08119635
KL Divergence                43.845287
KL Loss                      4.3845286
QF Loss                      3520.0051
VF Loss                      92.936935
Policy Loss                  -1299.8784
Q Predictions Mean           1301.6406
Q Predictions Std            1349.121
Q Predictions Max            4707.9683
Q Predictions Min            586.25793
V Predictions Mean           1299.9342
V Predictions Std            1347.0011
V Predictions Max            4711.439
V Predictions Min            591.1598
Log Pis Mean                 0.07545072
Log Pis Std                  4.0502295
Log Pis Max                  13.671849
Log Pis Min                  -6.8034244
Policy mu Mean               0.05940025
Policy mu Std                0.916328
Policy mu Max                2.5606353
Policy mu Min                -2.8309536
Policy log std Mean          -0.5246605
Policy log std Std           0.29175708
Policy log std Max           0.035028815
Policy log std Min           -2.7777328
Z mean eval                  2.4464624
Z variance eval              0.056756873
total_rewards                [10108.55268881  9764.83873231 10117.49657465 10221.01533958
 10147.81352575 10105.84183057 10036.09015022 10199.2123856
 10197.61651616 10116.14497726]
total_rewards_mean           10101.46227209022
total_rewards_std            123.84391591564408
total_rewards_max            10221.015339581925
total_rewards_min            9764.838732305014
Number of train steps total  980000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               194.69908753689378
(Previous) Eval Time (s)     34.82237693760544
Sample Time (s)              7.363772738259286
Epoch Time (s)               236.8852372127585
Total Train Time (s)         56600.345442296006
Epoch                        244
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:20:03.589366 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #244 | Epoch Duration: 236.9731423854828
2020-01-13 15:20:03.589708 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4477582
Z variance train             0.056781013
KL Divergence                44.637466
KL Loss                      4.4637465
QF Loss                      3400.6606
VF Loss                      89.02337
Policy Loss                  -1212.2793
Q Predictions Mean           1208.5885
Q Predictions Std            1262.9146
Q Predictions Max            4613.9727
Q Predictions Min            599.7386
V Predictions Mean           1211.1122
V Predictions Std            1264.9335
V Predictions Max            4611.02
V Predictions Min            610.4553
Log Pis Mean                 0.022383735
Log Pis Std                  3.5750606
Log Pis Max                  15.265373
Log Pis Min                  -5.925748
Policy mu Mean               0.092790864
Policy mu Std                0.90939313
Policy mu Max                2.9714048
Policy mu Min                -2.5334544
Policy log std Mean          -0.5298487
Policy log std Std           0.2509684
Policy log std Max           0.01840508
Policy log std Min           -2.7324274
Z mean eval                  2.4163125
Z variance eval              0.05544447
total_rewards                [10265.10650002 10064.42850522 10602.02215589 10518.36960587
 10405.66116758 10482.95634279 10203.1530115  10445.87923459
 10321.12297427 10545.88042802]
total_rewards_mean           10385.4579925748
total_rewards_std            160.86771859325137
total_rewards_max            10602.022155888346
total_rewards_min            10064.42850521837
Number of train steps total  984000
Number of env steps total    2954000
Number of rollouts total     0
Train Time (s)               191.32608453696594
(Previous) Eval Time (s)     30.848838839679956
Sample Time (s)              6.999941999092698
Epoch Time (s)               229.1748653757386
Total Train Time (s)         56829.60467245802
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:23:52.849936 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #245 | Epoch Duration: 229.2599709033966
2020-01-13 15:23:52.850126 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4158692
Z variance train             0.055422414
KL Divergence                43.723824
KL Loss                      4.3723826
QF Loss                      6648.583
VF Loss                      66.210396
Policy Loss                  -1299.8687
Q Predictions Mean           1298.9133
Q Predictions Std            1321.3738
Q Predictions Max            4609.8086
Q Predictions Min            580.57056
V Predictions Mean           1300.112
V Predictions Std            1319.2561
V Predictions Max            4599.908
V Predictions Min            584.3602
Log Pis Mean                 -0.3051741
Log Pis Std                  3.37503
Log Pis Max                  11.319864
Log Pis Min                  -7.1069746
Policy mu Mean               0.052692633
Policy mu Std                0.84731996
Policy mu Max                2.679463
Policy mu Min                -2.2649543
Policy log std Mean          -0.5441689
Policy log std Std           0.30717263
Policy log std Max           -0.03804359
Policy log std Min           -2.8816037
Z mean eval                  2.4650986
Z variance eval              0.06414724
total_rewards                [10442.61182971 10515.35800159 10108.01701827  9915.64281591
  4687.10087132 10102.04753309 10257.93789607 10474.88634177
 10156.33372865 10371.39431076]
total_rewards_mean           9703.133034713828
total_rewards_std            1681.9844463230568
total_rewards_max            10515.358001586636
total_rewards_min            4687.100871318144
Number of train steps total  988000
Number of env steps total    2966000
Number of rollouts total     0
Train Time (s)               191.01926864217967
(Previous) Eval Time (s)     31.361455456353724
Sample Time (s)              7.1727522956207395
Epoch Time (s)               229.55347639415413
Total Train Time (s)         57059.2399435672
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:27:42.488283 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #246 | Epoch Duration: 229.63800597190857
2020-01-13 15:27:42.488479 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #246 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4639843
Z variance train             0.06419765
KL Divergence                44.465534
KL Loss                      4.4465537
QF Loss                      81.373
VF Loss                      73.10804
Policy Loss                  -1200.8798
Q Predictions Mean           1198.5875
Q Predictions Std            1258.3872
Q Predictions Max            4610.2524
Q Predictions Min            597.72626
V Predictions Mean           1195.4756
V Predictions Std            1255.0527
V Predictions Max            4590.3296
V Predictions Min            590.8958
Log Pis Mean                 -0.2585008
Log Pis Std                  3.5934298
Log Pis Max                  12.464167
Log Pis Min                  -9.08115
Policy mu Mean               0.083510816
Policy mu Std                0.88119036
Policy mu Max                2.872817
Policy mu Min                -2.436489
Policy log std Mean          -0.52090555
Policy log std Std           0.26835185
Policy log std Max           0.028307348
Policy log std Min           -2.9376779
Z mean eval                  2.448197
Z variance eval              0.053185165
total_rewards                [10088.76209029  3951.65198136 10231.70664285  9928.07074603
  9677.67461772  9903.98196055 10029.13785974  9855.80788167
  9681.33472879  9829.32774539]
total_rewards_mean           9317.745625439733
total_rewards_std            1796.1061773883528
total_rewards_max            10231.706642851994
total_rewards_min            3951.651981357833
Number of train steps total  992000
Number of env steps total    2978000
Number of rollouts total     0
Train Time (s)               194.53572070784867
(Previous) Eval Time (s)     30.82422578893602
Sample Time (s)              6.681621616706252
Epoch Time (s)               232.04156811349094
Total Train Time (s)         57291.49530395912
Epoch                        247
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:31:34.750379 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #247 | Epoch Duration: 232.26171112060547
2020-01-13 15:31:34.750729 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #247 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4490526
Z variance train             0.05317732
KL Divergence                44.558014
KL Loss                      4.4558015
QF Loss                      156.58047
VF Loss                      106.25975
Policy Loss                  -1274.755
Q Predictions Mean           1272.2634
Q Predictions Std            1301.1149
Q Predictions Max            4576.9126
Q Predictions Min            607.0842
V Predictions Mean           1271.4767
V Predictions Std            1294.4924
V Predictions Max            4564.7646
V Predictions Min            611.42163
Log Pis Mean                 -0.45018172
Log Pis Std                  3.559772
Log Pis Max                  11.391883
Log Pis Min                  -8.274536
Policy mu Mean               0.10261049
Policy mu Std                0.85234284
Policy mu Max                2.7616763
Policy mu Min                -2.5390153
Policy log std Mean          -0.5181239
Policy log std Std           0.2939653
Policy log std Max           0.05152142
Policy log std Min           -3.1665668
Z mean eval                  2.455417
Z variance eval              0.070573345
total_rewards                [10233.84038538 10267.29361932 10155.91542481 10148.64339762
 10202.80986976 10097.05752053 10332.05714841 10218.90890718
 10262.93068941 10291.54785745]
total_rewards_mean           10221.100481986696
total_rewards_std            68.22405616668563
total_rewards_max            10332.05714840526
total_rewards_min            10097.05752053308
Number of train steps total  996000
Number of env steps total    2990000
Number of rollouts total     0
Train Time (s)               196.53399805584922
(Previous) Eval Time (s)     33.251951488200575
Sample Time (s)              6.642359143123031
Epoch Time (s)               236.42830868717283
Total Train Time (s)         57528.205429173075
Epoch                        248
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:35:31.463504 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #248 | Epoch Duration: 236.71243953704834
2020-01-13 15:35:31.463843 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.451966
Z variance train             0.0705397
KL Divergence                45.89226
KL Loss                      4.5892262
QF Loss                      97.79199
VF Loss                      64.01313
Policy Loss                  -1261.0299
Q Predictions Mean           1259.8119
Q Predictions Std            1268.0466
Q Predictions Max            4650.452
Q Predictions Min            601.9962
V Predictions Mean           1265.321
V Predictions Std            1264.5779
V Predictions Max            4643.5806
V Predictions Min            611.7049
Log Pis Mean                 -0.12280119
Log Pis Std                  3.521939
Log Pis Max                  10.354697
Log Pis Min                  -6.439238
Policy mu Mean               0.07342208
Policy mu Std                0.8942721
Policy mu Max                2.4834886
Policy mu Min                -2.4106374
Policy log std Mean          -0.5138884
Policy log std Std           0.297922
Policy log std Max           -0.022916496
Policy log std Min           -2.9140975
Z mean eval                  2.467815
Z variance eval              0.06969173
total_rewards                [9837.80257916 9844.15444342 9870.0067891  9836.38709932 9770.98159242
 9654.05392539 9789.20736448 9471.58873339 9455.3218488  9420.53238172]
total_rewards_mean           9695.003675720833
total_rewards_std            170.95988043559768
total_rewards_max            9870.006789102525
total_rewards_min            9420.532381721072
Number of train steps total  1000000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               195.18091889610514
(Previous) Eval Time (s)     31.135841843672097
Sample Time (s)              7.199332120362669
Epoch Time (s)               233.5160928601399
Total Train Time (s)         57761.80495654652
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:39:25.072774 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #249 | Epoch Duration: 233.60864996910095
2020-01-13 15:39:25.073080 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4692028
Z variance train             0.06957527
KL Divergence                46.491184
KL Loss                      4.6491184
QF Loss                      120.704704
VF Loss                      74.33055
Policy Loss                  -1283.7819
Q Predictions Mean           1280.3003
Q Predictions Std            1328.7736
Q Predictions Max            4575.005
Q Predictions Min            604.4347
V Predictions Mean           1280.5991
V Predictions Std            1325.7352
V Predictions Max            4562.1
V Predictions Min            603.5824
Log Pis Mean                 -0.21018378
Log Pis Std                  3.5768852
Log Pis Max                  17.178766
Log Pis Min                  -6.5728393
Policy mu Mean               0.07749327
Policy mu Std                0.9015554
Policy mu Max                2.7358365
Policy mu Min                -3.0331357
Policy log std Mean          -0.5066405
Policy log std Std           0.26547047
Policy log std Max           -0.030481339
Policy log std Min           -2.7899132
Z mean eval                  2.4696233
Z variance eval              0.059062194
total_rewards                [10330.1802732  10173.96975632 10346.74428061 10397.51537107
 10296.81213642 10558.0624087  10500.33856153 10482.09049659
 10382.54779383 10163.1517173 ]
total_rewards_mean           10363.141279555606
total_rewards_std            124.12130474599327
total_rewards_max            10558.062408695881
total_rewards_min            10163.151717303968
Number of train steps total  1004000
Number of env steps total    3014000
Number of rollouts total     0
Train Time (s)               195.59239705465734
(Previous) Eval Time (s)     36.46420176932588
Sample Time (s)              7.982946292962879
Epoch Time (s)               240.0395451169461
Total Train Time (s)         58001.92964421259
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:43:25.203823 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #250 | Epoch Duration: 240.13048458099365
2020-01-13 15:43:25.204189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4668293
Z variance train             0.059000485
KL Divergence                46.869267
KL Loss                      4.686927
QF Loss                      117.44396
VF Loss                      31.608303
Policy Loss                  -1260.7134
Q Predictions Mean           1259.5294
Q Predictions Std            1317.0209
Q Predictions Max            4593.796
Q Predictions Min            609.7278
V Predictions Mean           1261.8044
V Predictions Std            1316.2354
V Predictions Max            4602.014
V Predictions Min            608.00555
Log Pis Mean                 0.050128058
Log Pis Std                  3.9150229
Log Pis Max                  15.70752
Log Pis Min                  -7.976564
Policy mu Mean               0.054876983
Policy mu Std                0.89866906
Policy mu Max                3.7580771
Policy mu Min                -2.4443579
Policy log std Mean          -0.50872135
Policy log std Std           0.27192193
Policy log std Max           -0.0017193556
Policy log std Min           -2.6739626
Z mean eval                  2.4588265
Z variance eval              0.057672787
total_rewards                [10256.19129483 10200.39526288 10056.21550564 10290.81289707
 10084.74415853 10422.06121932 10495.20114376 10415.80966448
 10227.95048763 10221.64210785]
total_rewards_mean           10267.102374198555
total_rewards_std            135.8725601352718
total_rewards_max            10495.201143756312
total_rewards_min            10056.215505638591
Number of train steps total  1008000
Number of env steps total    3026000
Number of rollouts total     0
Train Time (s)               194.13989360583946
(Previous) Eval Time (s)     29.741769414860755
Sample Time (s)              6.905892765149474
Epoch Time (s)               230.7875557858497
Total Train Time (s)         58232.79952265974
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:47:16.075079 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #251 | Epoch Duration: 230.87066268920898
2020-01-13 15:47:16.075255 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4564998
Z variance train             0.0575791
KL Divergence                47.45895
KL Loss                      4.745895
QF Loss                      168.71698
VF Loss                      60.73631
Policy Loss                  -1161.044
Q Predictions Mean           1156.7524
Q Predictions Std            1209.1044
Q Predictions Max            4627.181
Q Predictions Min            621.35913
V Predictions Mean           1163.956
V Predictions Std            1210.8258
V Predictions Max            4632.8354
V Predictions Min            623.03253
Log Pis Mean                 -0.58847487
Log Pis Std                  3.5406635
Log Pis Max                  12.155722
Log Pis Min                  -7.144922
Policy mu Mean               0.03920341
Policy mu Std                0.8467972
Policy mu Max                3.147592
Policy mu Min                -2.9772217
Policy log std Mean          -0.5001353
Policy log std Std           0.26646692
Policy log std Max           -0.077073336
Policy log std Min           -2.711525
Z mean eval                  2.4512305
Z variance eval              0.046061855
total_rewards                [10214.04706759 10316.61613717 10143.71786491 10255.86633992
 10351.15507209 10390.15044338 10211.94114779 10461.04716074
 10248.21672499 10308.53495683]
total_rewards_mean           10290.129291540925
total_rewards_std            89.58260198543623
total_rewards_max            10461.047160739958
total_rewards_min            10143.717864913306
Number of train steps total  1012000
Number of env steps total    3038000
Number of rollouts total     0
Train Time (s)               189.4119706726633
(Previous) Eval Time (s)     35.09246945613995
Sample Time (s)              7.638643227983266
Epoch Time (s)               232.14308335678652
Total Train Time (s)         58465.044226787984
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:51:08.330149 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #252 | Epoch Duration: 232.25471329689026
2020-01-13 15:51:08.330494 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #252 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.448803
Z variance train             0.04625245
KL Divergence                46.603745
KL Loss                      4.6603746
QF Loss                      183.08525
VF Loss                      52.446938
Policy Loss                  -1294.0906
Q Predictions Mean           1291.8992
Q Predictions Std            1322.5953
Q Predictions Max            4677.41
Q Predictions Min            610.19653
V Predictions Mean           1296.843
V Predictions Std            1327.5424
V Predictions Max            4688.1484
V Predictions Min            609.1881
Log Pis Mean                 -0.2867682
Log Pis Std                  3.734802
Log Pis Max                  14.267788
Log Pis Min                  -7.0332212
Policy mu Mean               0.09033424
Policy mu Std                0.87030995
Policy mu Max                2.6816692
Policy mu Min                -2.8668604
Policy log std Mean          -0.5354101
Policy log std Std           0.29571688
Policy log std Max           0.0018440485
Policy log std Min           -2.8375435
Z mean eval                  2.4605749
Z variance eval              0.05014684
total_rewards                [10326.15343517 10302.73722169 10504.37673438 10221.64187633
 10326.02237324  9993.29670571 10483.29703141 10039.7395961
 10152.97363761 10354.98719046]
total_rewards_mean           10270.522580210985
total_rewards_std            161.44034608274796
total_rewards_max            10504.376734378757
total_rewards_min            9993.296705710194
Number of train steps total  1016000
Number of env steps total    3050000
Number of rollouts total     0
Train Time (s)               193.77305503375828
(Previous) Eval Time (s)     29.91145131131634
Sample Time (s)              7.286632126197219
Epoch Time (s)               230.97113847127184
Total Train Time (s)         58696.10587594099
Epoch                        253
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:54:59.390635 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #253 | Epoch Duration: 231.0598909854889
2020-01-13 15:54:59.390827 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4592965
Z variance train             0.05002231
KL Divergence                45.01212
KL Loss                      4.501212
QF Loss                      81.600975
VF Loss                      43.655018
Policy Loss                  -1378.6692
Q Predictions Mean           1378.3633
Q Predictions Std            1403.6412
Q Predictions Max            4637.139
Q Predictions Min            619.90375
V Predictions Mean           1378.8201
V Predictions Std            1401.3103
V Predictions Max            4647.577
V Predictions Min            621.8032
Log Pis Mean                 -0.17805302
Log Pis Std                  3.541975
Log Pis Max                  16.106796
Log Pis Min                  -8.969593
Policy mu Mean               -0.0032241673
Policy mu Std                0.88070905
Policy mu Max                2.7783532
Policy mu Min                -3.0267348
Policy log std Mean          -0.53833896
Policy log std Std           0.30351484
Policy log std Max           -0.008319497
Policy log std Min           -2.8156428
Z mean eval                  2.4573627
Z variance eval              0.047021054
total_rewards                [10174.92750978 10113.64939729 10623.95021801 10541.88012563
  9886.81478445 10465.09408505  9972.37955958 10415.55284179
 10183.58116643 10055.88898872]
total_rewards_mean           10243.371867673133
total_rewards_std            239.49137401757628
total_rewards_max            10623.950218011742
total_rewards_min            9886.814784447271
Number of train steps total  1020000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               195.28799960808828
(Previous) Eval Time (s)     30.050721727777272
Sample Time (s)              7.329606792423874
Epoch Time (s)               232.66832812828943
Total Train Time (s)         58929.104209325276
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:58:52.391124 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #254 | Epoch Duration: 233.00015592575073
2020-01-13 15:58:52.391295 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.457972
Z variance train             0.047091566
KL Divergence                46.25167
KL Loss                      4.6251674
QF Loss                      180.47244
VF Loss                      64.62084
Policy Loss                  -1306.5972
Q Predictions Mean           1302.0276
Q Predictions Std            1335.1277
Q Predictions Max            4742.1846
Q Predictions Min            604.10754
V Predictions Mean           1304.7487
V Predictions Std            1333.543
V Predictions Max            4720.349
V Predictions Min            606.84674
Log Pis Mean                 -0.17184797
Log Pis Std                  3.6968086
Log Pis Max                  15.785353
Log Pis Min                  -6.7602754
Policy mu Mean               0.08824372
Policy mu Std                0.8918653
Policy mu Max                3.1976998
Policy mu Min                -2.9566875
Policy log std Mean          -0.5374138
Policy log std Std           0.28282025
Policy log std Max           0.015326738
Policy log std Min           -2.7617178
Z mean eval                  2.456802
Z variance eval              0.051227946
total_rewards                [10358.67112565 10194.28511769 10140.38571478  9718.26391312
 10012.5265004  10606.72743164 10118.52948915 10243.36693064
 10082.86350417 10294.44485976]
total_rewards_mean           10177.006458701528
total_rewards_std            220.7437697155177
total_rewards_max            10606.727431640551
total_rewards_min            9718.263913123998
Number of train steps total  1024000
Number of env steps total    3074000
Number of rollouts total     0
Train Time (s)               192.48427382484078
(Previous) Eval Time (s)     30.85236215731129
Sample Time (s)              7.234696601051837
Epoch Time (s)               230.5713325832039
Total Train Time (s)         59159.75565739721
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:02:43.047111 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #255 | Epoch Duration: 230.65568566322327
2020-01-13 16:02:43.047281 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455718
Z variance train             0.051160246
KL Divergence                44.47747
KL Loss                      4.447747
QF Loss                      169.00739
VF Loss                      36.80851
Policy Loss                  -1344.0422
Q Predictions Mean           1342.1143
Q Predictions Std            1375.599
Q Predictions Max            4658.093
Q Predictions Min            600.7233
V Predictions Mean           1343.8761
V Predictions Std            1372.1687
V Predictions Max            4642.1494
V Predictions Min            604.1006
Log Pis Mean                 -0.07587753
Log Pis Std                  3.8036563
Log Pis Max                  11.763008
Log Pis Min                  -7.197968
Policy mu Mean               0.1045937
Policy mu Std                0.8874779
Policy mu Max                3.383345
Policy mu Min                -2.4586642
Policy log std Mean          -0.5359404
Policy log std Std           0.31766468
Policy log std Max           0.0021384954
Policy log std Min           -2.9936533
Z mean eval                  2.4450598
Z variance eval              0.0575499
total_rewards                [10402.42782385 10232.93795849 10368.14409479 10405.95514815
  9896.2680505  10264.08129475 10421.95227337 10051.91767871
 10236.28036843 10346.65485778]
total_rewards_mean           10262.661954882627
total_rewards_std            162.43807872678082
total_rewards_max            10421.952273373825
total_rewards_min            9896.268050501212
Number of train steps total  1028000
Number of env steps total    3086000
Number of rollouts total     0
Train Time (s)               194.10021142382175
(Previous) Eval Time (s)     31.250354028772563
Sample Time (s)              7.109693370759487
Epoch Time (s)               232.4602588233538
Total Train Time (s)         59392.29678773787
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:06:35.592515 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #256 | Epoch Duration: 232.54509210586548
2020-01-13 16:06:35.592720 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4462845
Z variance train             0.057635605
KL Divergence                42.931213
KL Loss                      4.2931213
QF Loss                      3422.482
VF Loss                      73.98686
Policy Loss                  -1376.1284
Q Predictions Mean           1373.4506
Q Predictions Std            1384.1859
Q Predictions Max            4488.992
Q Predictions Min            601.00433
V Predictions Mean           1374.4652
V Predictions Std            1381.9907
V Predictions Max            4500.5444
V Predictions Min            603.5375
Log Pis Mean                 -0.17427552
Log Pis Std                  3.5632012
Log Pis Max                  10.999269
Log Pis Min                  -6.9172735
Policy mu Mean               0.056461718
Policy mu Std                0.9111732
Policy mu Max                2.5730426
Policy mu Min                -2.8946629
Policy log std Mean          -0.55432516
Policy log std Std           0.28862235
Policy log std Max           -0.09703386
Policy log std Min           -2.8342795
Z mean eval                  2.429707
Z variance eval              0.074880734
total_rewards                [9428.50602565 9146.45922633 9727.1089234  9279.799919   3853.66350137
 9564.07680397 8947.8248353  8852.74481669 9677.59801376 9182.96803021]
total_rewards_mean           8766.075009567965
total_rewards_std            1660.8678090592957
total_rewards_max            9727.108923400776
total_rewards_min            3853.6635013733726
Number of train steps total  1032000
Number of env steps total    3098000
Number of rollouts total     0
Train Time (s)               194.88797244708985
(Previous) Eval Time (s)     31.864325057249516
Sample Time (s)              7.335887819062918
Epoch Time (s)               234.08818532340229
Total Train Time (s)         59626.46542536514
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:10:29.763865 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #257 | Epoch Duration: 234.1709804534912
2020-01-13 16:10:29.764076 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #257 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4303713
Z variance train             0.07462181
KL Divergence                41.9962
KL Loss                      4.1996202
QF Loss                      145.85004
VF Loss                      53.579212
Policy Loss                  -1216.2812
Q Predictions Mean           1213.1562
Q Predictions Std            1256.3949
Q Predictions Max            4508.52
Q Predictions Min            594.9794
V Predictions Mean           1218.5317
V Predictions Std            1259.7997
V Predictions Max            4516.2393
V Predictions Min            596.2279
Log Pis Mean                 -0.3181067
Log Pis Std                  3.6282034
Log Pis Max                  14.909067
Log Pis Min                  -9.665405
Policy mu Mean               0.061211046
Policy mu Std                0.9029878
Policy mu Max                3.0153077
Policy mu Min                -2.692833
Policy log std Mean          -0.52558553
Policy log std Std           0.28275406
Policy log std Max           0.113482475
Policy log std Min           -2.9529734
Z mean eval                  2.438414
Z variance eval              0.051787823
total_rewards                [ 9737.82857015 10266.44064061 10286.71045311 10227.99296523
 10096.22947309  9596.97422857  9877.13786348  9598.76988387
 10198.98185982  9780.43194822]
total_rewards_mean           9966.749788613528
total_rewards_std            264.2776737919515
total_rewards_max            10286.710453105314
total_rewards_min            9596.974228573004
Number of train steps total  1036000
Number of env steps total    3110000
Number of rollouts total     0
Train Time (s)               194.78192466730252
(Previous) Eval Time (s)     36.49742467002943
Sample Time (s)              6.958978695329279
Epoch Time (s)               238.23832803266123
Total Train Time (s)         59864.90740711102
Epoch                        258
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:14:28.208118 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #258 | Epoch Duration: 238.44389653205872
2020-01-13 16:14:28.208315 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4367685
Z variance train             0.051966004
KL Divergence                43.69333
KL Loss                      4.369333
QF Loss                      199.39096
VF Loss                      34.39611
Policy Loss                  -1273.9806
Q Predictions Mean           1271.8442
Q Predictions Std            1312.9319
Q Predictions Max            4690.105
Q Predictions Min            604.66516
V Predictions Mean           1275.9882
V Predictions Std            1311.1278
V Predictions Max            4670.712
V Predictions Min            603.3523
Log Pis Mean                 -0.29347506
Log Pis Std                  3.964184
Log Pis Max                  13.049637
Log Pis Min                  -7.7770185
Policy mu Mean               0.066013575
Policy mu Std                0.85805035
Policy mu Max                2.656151
Policy mu Min                -2.5450914
Policy log std Mean          -0.53137094
Policy log std Std           0.2928263
Policy log std Max           -0.058015883
Policy log std Min           -2.8304029
Z mean eval                  2.4386392
Z variance eval              0.07713234
total_rewards                [8545.06260623 9344.85478719 9086.21690274 8930.56279455 9287.79417583
 9216.97234021 9521.55245825 3028.82986856 9236.05910532 9607.77358417]
total_rewards_mean           8580.567862304997
total_rewards_std            1872.4534540323739
total_rewards_max            9607.773584170896
total_rewards_min            3028.8298685605996
Number of train steps total  1040000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               193.12073427811265
(Previous) Eval Time (s)     30.488903053104877
Sample Time (s)              7.018214087001979
Epoch Time (s)               230.6278514182195
Total Train Time (s)         60095.61426773062
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:18:18.917911 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #259 | Epoch Duration: 230.70945119857788
2020-01-13 16:18:18.918101 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #259 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4394164
Z variance train             0.07734626
KL Divergence                42.630592
KL Loss                      4.263059
QF Loss                      155.24239
VF Loss                      105.57056
Policy Loss                  -1237.3508
Q Predictions Mean           1234.5531
Q Predictions Std            1283.5189
Q Predictions Max            4700.5415
Q Predictions Min            628.8186
V Predictions Mean           1238.0251
V Predictions Std            1285.1088
V Predictions Max            4681.9023
V Predictions Min            629.09393
Log Pis Mean                 0.047490567
Log Pis Std                  4.13074
Log Pis Max                  18.397833
Log Pis Min                  -8.473826
Policy mu Mean               0.07655842
Policy mu Std                0.917994
Policy mu Max                2.5506523
Policy mu Min                -5.065394
Policy log std Mean          -0.5187118
Policy log std Std           0.27764416
Policy log std Max           1.2339902
Policy log std Min           -2.97013
Z mean eval                  2.4358838
Z variance eval              0.086044505
total_rewards                [10017.6243164  10141.44998386  9627.86471928 10029.41710509
 10451.28941331 10329.92622712 10059.34506989  9619.87896072
  9913.2532521   9866.03074708]
total_rewards_mean           10005.607979486555
total_rewards_std            254.03824595493253
total_rewards_max            10451.289413310657
total_rewards_min            9619.87896072187
Number of train steps total  1044000
Number of env steps total    3134000
Number of rollouts total     0
Train Time (s)               189.43212759494781
(Previous) Eval Time (s)     34.62782870000228
Sample Time (s)              7.842395739629865
Epoch Time (s)               231.90235203457996
Total Train Time (s)         60327.59906638367
Epoch                        260
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:22:10.905284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #260 | Epoch Duration: 231.98703932762146
2020-01-13 16:22:10.905463 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #260 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4373627
Z variance train             0.08592798
KL Divergence                41.686985
KL Loss                      4.168699
QF Loss                      132.3973
VF Loss                      42.533142
Policy Loss                  -1033.6425
Q Predictions Mean           1030.449
Q Predictions Std            1019.577
Q Predictions Max            4561.5938
Q Predictions Min            609.48395
V Predictions Mean           1032.874
V Predictions Std            1017.8342
V Predictions Max            4570.51
V Predictions Min            608.5279
Log Pis Mean                 -0.53807783
Log Pis Std                  3.4022014
Log Pis Max                  14.763876
Log Pis Min                  -6.374533
Policy mu Mean               0.0787171
Policy mu Std                0.8342907
Policy mu Max                2.8009574
Policy mu Min                -2.4549444
Policy log std Mean          -0.5193166
Policy log std Std           0.26779383
Policy log std Max           -0.05604601
Policy log std Min           -2.8285036
Z mean eval                  2.464606
Z variance eval              0.050487928
total_rewards                [10157.02425732 10205.2831438   9819.29805817 10263.5541428
 10098.10429144 10267.57493049  9915.79521706 10227.54252632
 10264.30745844 10161.72212725]
total_rewards_mean           10138.020615310033
total_rewards_std            146.46302713935722
total_rewards_max            10267.5749304945
total_rewards_min            9819.298058173123
Number of train steps total  1048000
Number of env steps total    3146000
Number of rollouts total     0
Train Time (s)               196.89575392892584
(Previous) Eval Time (s)     30.438015575986356
Sample Time (s)              7.297533452510834
Epoch Time (s)               234.63130295742303
Total Train Time (s)         60562.3120251596
Epoch                        261
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:26:05.621031 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #261 | Epoch Duration: 234.71542811393738
2020-01-13 16:26:05.621207 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #261 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4645402
Z variance train             0.050389104
KL Divergence                43.95242
KL Loss                      4.395242
QF Loss                      123.48806
VF Loss                      23.266672
Policy Loss                  -1292.7587
Q Predictions Mean           1293.6285
Q Predictions Std            1327.5845
Q Predictions Max            4799.2324
Q Predictions Min            605.541
V Predictions Mean           1293.7682
V Predictions Std            1323.5706
V Predictions Max            4771.774
V Predictions Min            614.98083
Log Pis Mean                 -0.49607295
Log Pis Std                  3.567003
Log Pis Max                  16.657434
Log Pis Min                  -7.4931707
Policy mu Mean               0.03946634
Policy mu Std                0.8525588
Policy mu Max                2.441125
Policy mu Min                -2.4166102
Policy log std Mean          -0.50370926
Policy log std Std           0.27157432
Policy log std Max           0.030806541
Policy log std Min           -2.7138312
Z mean eval                  2.465709
Z variance eval              0.038835373
total_rewards                [10387.76593624 10275.58204488 10206.22889181 10114.77955993
 10370.38787116 10082.13112786 10269.9508104  10551.76289663
 10387.3236508  10055.3531522 ]
total_rewards_mean           10270.126594191921
total_rewards_std            150.5525929358381
total_rewards_max            10551.762896634244
total_rewards_min            10055.353152204356
Number of train steps total  1052000
Number of env steps total    3158000
Number of rollouts total     0
Train Time (s)               194.7228784468025
(Previous) Eval Time (s)     30.537463716231287
Sample Time (s)              7.762802122160792
Epoch Time (s)               233.02314428519458
Total Train Time (s)         60795.42078593187
Epoch                        262
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:29:58.732967 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #262 | Epoch Duration: 233.11161923408508
2020-01-13 16:29:58.733146 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4668472
Z variance train             0.038690202
KL Divergence                45.482124
KL Loss                      4.5482125
QF Loss                      10405.27
VF Loss                      48.08721
Policy Loss                  -1416.9501
Q Predictions Mean           1413.1343
Q Predictions Std            1439.5928
Q Predictions Max            4762.3433
Q Predictions Min            640.33276
V Predictions Mean           1413.6621
V Predictions Std            1432.8995
V Predictions Max            4743.4883
V Predictions Min            644.7603
Log Pis Mean                 0.21928239
Log Pis Std                  4.1083255
Log Pis Max                  16.301752
Log Pis Min                  -7.8803606
Policy mu Mean               0.087085426
Policy mu Std                0.92354476
Policy mu Max                3.0338855
Policy mu Min                -3.076664
Policy log std Mean          -0.52435607
Policy log std Std           0.28446102
Policy log std Max           0.09221232
Policy log std Min           -2.8728893
Z mean eval                  2.4832497
Z variance eval              0.030304188
total_rewards                [ 9788.14510836 10201.30466923  9975.21593482 10064.12870816
  9831.14678179  9892.63037599  3651.38227652  9721.91984309
 10304.28267412  9769.95352885]
total_rewards_mean           9320.010990092404
total_rewards_std            1898.2651767553964
total_rewards_max            10304.282674122207
total_rewards_min            3651.3822765169757
Number of train steps total  1056000
Number of env steps total    3170000
Number of rollouts total     0
Train Time (s)               191.7943460927345
(Previous) Eval Time (s)     33.23244130704552
Sample Time (s)              7.6757385563105345
Epoch Time (s)               232.70252595609054
Total Train Time (s)         61028.20614612335
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:33:51.530471 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #263 | Epoch Duration: 232.79715394973755
2020-01-13 16:33:51.530778 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #263 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.483366
Z variance train             0.0302917
KL Divergence                45.19098
KL Loss                      4.519098
QF Loss                      142.84537
VF Loss                      34.252728
Policy Loss                  -1294.1704
Q Predictions Mean           1292.0176
Q Predictions Std            1309.9779
Q Predictions Max            4699.818
Q Predictions Min            630.0591
V Predictions Mean           1294.9247
V Predictions Std            1311.0813
V Predictions Max            4698.739
V Predictions Min            634.78577
Log Pis Mean                 -0.20772578
Log Pis Std                  3.606107
Log Pis Max                  12.241552
Log Pis Min                  -6.605467
Policy mu Mean               0.07458566
Policy mu Std                0.88874334
Policy mu Max                3.2639794
Policy mu Min                -2.2508993
Policy log std Mean          -0.5189406
Policy log std Std           0.27913395
Policy log std Max           0.1094296
Policy log std Min           -2.6181848
Z mean eval                  2.4427204
Z variance eval              0.05985468
total_rewards                [10168.0339001  10177.33882969 10367.10664042 10237.63294922
 10263.95110552 10239.02001496 10100.50991638 10032.57802638
 10479.28645569 10132.37728718]
total_rewards_mean           10219.783512554975
total_rewards_std            123.7242133580693
total_rewards_max            10479.28645569216
total_rewards_min            10032.578026378866
Number of train steps total  1060000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               196.77294888393953
(Previous) Eval Time (s)     31.81403526989743
Sample Time (s)              6.565116767305881
Epoch Time (s)               235.15210092114285
Total Train Time (s)         61263.47487064684
Epoch                        264
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:37:46.800747 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #264 | Epoch Duration: 235.26972913742065
2020-01-13 16:37:46.800945 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4429135
Z variance train             0.060391597
KL Divergence                43.916943
KL Loss                      4.3916945
QF Loss                      129.92911
VF Loss                      75.32205
Policy Loss                  -1256.2191
Q Predictions Mean           1256.4331
Q Predictions Std            1292.6616
Q Predictions Max            4694.9404
Q Predictions Min            618.47675
V Predictions Mean           1253.831
V Predictions Std            1289.8696
V Predictions Max            4672.362
V Predictions Min            624.1447
Log Pis Mean                 -0.43004167
Log Pis Std                  3.9013839
Log Pis Max                  19.213367
Log Pis Min                  -7.2530155
Policy mu Mean               0.047311753
Policy mu Std                0.85626453
Policy mu Max                2.9629736
Policy mu Min                -3.155789
Policy log std Mean          -0.5304802
Policy log std Std           0.29176256
Policy log std Max           -0.061094046
Policy log std Min           -2.7941053
Z mean eval                  2.4358304
Z variance eval              0.046897773
total_rewards                [10297.15454225 10790.32825646 10250.94119113 10262.08776185
  9852.50288931 10503.06314278 10412.08626008 10643.33417632
 10499.35964565 10661.74512926]
total_rewards_mean           10417.260299507685
total_rewards_std            254.81523091409835
total_rewards_max            10790.328256462035
total_rewards_min            9852.502889306386
Number of train steps total  1064000
Number of env steps total    3194000
Number of rollouts total     0
Train Time (s)               198.37405304191634
(Previous) Eval Time (s)     31.141663441900164
Sample Time (s)              7.416706898715347
Epoch Time (s)               236.93242338253185
Total Train Time (s)         61500.490073865745
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:41:43.820320 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #265 | Epoch Duration: 237.01921391487122
2020-01-13 16:41:43.820544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #265 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4363754
Z variance train             0.046947032
KL Divergence                43.589367
KL Loss                      4.358937
QF Loss                      100.09757
VF Loss                      36.52475
Policy Loss                  -1272.3219
Q Predictions Mean           1271.9202
Q Predictions Std            1303.9895
Q Predictions Max            4728.485
Q Predictions Min            626.84216
V Predictions Mean           1270.654
V Predictions Std            1300.5012
V Predictions Max            4721.0464
V Predictions Min            617.3081
Log Pis Mean                 -0.4509473
Log Pis Std                  3.6432958
Log Pis Max                  17.545494
Log Pis Min                  -6.36003
Policy mu Mean               0.07808084
Policy mu Std                0.86316854
Policy mu Max                2.8537042
Policy mu Min                -3.1455975
Policy log std Mean          -0.5262045
Policy log std Std           0.29373756
Policy log std Max           0.14858723
Policy log std Min           -2.767498
Z mean eval                  2.4412599
Z variance eval              0.041892156
total_rewards                [10354.99628412 10290.94999077 10404.98954018 10158.19372854
  4445.78529026 10303.97186672 10003.69579655 10144.15038382
 10330.21746804 10215.20564354]
total_rewards_mean           9665.215599252242
total_rewards_std            1743.466663498784
total_rewards_max            10404.989540179797
total_rewards_min            4445.785290263154
Number of train steps total  1068000
Number of env steps total    3206000
Number of rollouts total     0
Train Time (s)               193.57670367974788
(Previous) Eval Time (s)     36.561005889903754
Sample Time (s)              7.9523397530429065
Epoch Time (s)               238.09004932269454
Total Train Time (s)         61738.66518934863
Epoch                        266
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:45:41.996415 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #266 | Epoch Duration: 238.17571234703064
2020-01-13 16:45:41.996549 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #266 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.440333
Z variance train             0.041844115
KL Divergence                44.530926
KL Loss                      4.4530926
QF Loss                      111.47194
VF Loss                      45.024147
Policy Loss                  -1314.3645
Q Predictions Mean           1312.6262
Q Predictions Std            1343.9662
Q Predictions Max            4787.489
Q Predictions Min            644.62946
V Predictions Mean           1315.2417
V Predictions Std            1339.4924
V Predictions Max            4771.811
V Predictions Min            644.0786
Log Pis Mean                 -0.36038038
Log Pis Std                  3.6156616
Log Pis Max                  12.311675
Log Pis Min                  -8.494949
Policy mu Mean               0.091880165
Policy mu Std                0.86482453
Policy mu Max                2.7992952
Policy mu Min                -2.7643554
Policy log std Mean          -0.5170254
Policy log std Std           0.29890314
Policy log std Max           -0.060957134
Policy log std Min           -2.8289106
Z mean eval                  2.4467099
Z variance eval              0.06423487
total_rewards                [10301.34669593 10378.30641314 10512.16473973 10141.6841953
  9808.95523458 10744.66337504 10372.41883791 10427.14982791
 10104.78203192 10567.21317927]
total_rewards_mean           10335.868453074336
total_rewards_std            251.6189586019877
total_rewards_max            10744.66337504112
total_rewards_min            9808.955234583278
Number of train steps total  1072000
Number of env steps total    3218000
Number of rollouts total     0
Train Time (s)               196.2097878730856
(Previous) Eval Time (s)     31.25592246791348
Sample Time (s)              7.54296511458233
Epoch Time (s)               235.0086754555814
Total Train Time (s)         61973.77728132997
Epoch                        267
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:49:37.114064 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #267 | Epoch Duration: 235.11735677719116
2020-01-13 16:49:37.114329 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #267 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.44589
Z variance train             0.063994765
KL Divergence                43.543896
KL Loss                      4.3543897
QF Loss                      115.01375
VF Loss                      56.03409
Policy Loss                  -1182.5287
Q Predictions Mean           1178.3445
Q Predictions Std            1218.3735
Q Predictions Max            4813.955
Q Predictions Min            637.2304
V Predictions Mean           1180.3335
V Predictions Std            1214.216
V Predictions Max            4805.5723
V Predictions Min            638.76215
Log Pis Mean                 -0.39780968
Log Pis Std                  4.09099
Log Pis Max                  16.69158
Log Pis Min                  -8.172199
Policy mu Mean               0.059719622
Policy mu Std                0.87859225
Policy mu Max                2.6796486
Policy mu Min                -2.918851
Policy log std Mean          -0.5089422
Policy log std Std           0.2680382
Policy log std Max           -0.076735705
Policy log std Min           -2.620575
Z mean eval                  2.4318473
Z variance eval              0.06768121
total_rewards                [10037.6979778   9998.01894427 10011.45577497 10057.81260827
  9963.88339268  9974.0078209  10139.05305553  9914.46790035
 10207.97640728 10292.81549872]
total_rewards_mean           10059.718938077487
total_rewards_std            112.63288872056143
total_rewards_max            10292.81549871909
total_rewards_min            9914.467900348387
Number of train steps total  1076000
Number of env steps total    3230000
Number of rollouts total     0
Train Time (s)               196.4075436173007
(Previous) Eval Time (s)     31.49951369082555
Sample Time (s)              7.670001518912613
Epoch Time (s)               235.57705882703885
Total Train Time (s)         62209.44053377723
Epoch                        268
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:53:32.784593 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #268 | Epoch Duration: 235.6700530052185
2020-01-13 16:53:32.784804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4290912
Z variance train             0.06785014
KL Divergence                43.25054
KL Loss                      4.325054
QF Loss                      83.72887
VF Loss                      117.74364
Policy Loss                  -1152.6581
Q Predictions Mean           1152.2227
Q Predictions Std            1162.823
Q Predictions Max            4726.157
Q Predictions Min            617.7629
V Predictions Mean           1159.7601
V Predictions Std            1161.7987
V Predictions Max            4732.536
V Predictions Min            629.5543
Log Pis Mean                 -0.34837702
Log Pis Std                  3.5088046
Log Pis Max                  13.172525
Log Pis Min                  -6.8000765
Policy mu Mean               0.12152934
Policy mu Std                0.83439153
Policy mu Max                2.7249553
Policy mu Min                -2.607163
Policy log std Mean          -0.52221614
Policy log std Std           0.27981734
Policy log std Max           -0.08739191
Policy log std Min           -2.6701055
Z mean eval                  2.4305584
Z variance eval              0.05377674
total_rewards                [10349.43831864 10619.77949638 10347.98125777 10313.48192968
 10574.72366338 10721.02082542 10650.83154936 10599.06054267
 10383.1087423  10625.20916667]
total_rewards_mean           10518.463549229364
total_rewards_std            144.16778064925592
total_rewards_max            10721.020825424968
total_rewards_min            10313.481929678223
Number of train steps total  1080000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               195.21194524411112
(Previous) Eval Time (s)     31.21689946297556
Sample Time (s)              6.916359766386449
Epoch Time (s)               233.34520447347313
Total Train Time (s)         62442.87006453704
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:57:26.215606 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #269 | Epoch Duration: 233.43064546585083
2020-01-13 16:57:26.215779 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #269 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4293303
Z variance train             0.053896464
KL Divergence                44.499046
KL Loss                      4.449905
QF Loss                      7428.7188
VF Loss                      74.214355
Policy Loss                  -1296.7008
Q Predictions Mean           1293.156
Q Predictions Std            1290.3992
Q Predictions Max            4718.5107
Q Predictions Min            636.3871
V Predictions Mean           1297.6746
V Predictions Std            1289.1467
V Predictions Max            4709.7236
V Predictions Min            644.2498
Log Pis Mean                 0.10384704
Log Pis Std                  3.7949831
Log Pis Max                  13.052395
Log Pis Min                  -5.2625217
Policy mu Mean               0.0575206
Policy mu Std                0.92026407
Policy mu Max                2.7976968
Policy mu Min                -3.1860256
Policy log std Mean          -0.54482526
Policy log std Std           0.29317003
Policy log std Max           0.3080986
Policy log std Min           -2.8014698
Z mean eval                  2.4432921
Z variance eval              0.047934152
total_rewards                [10140.3975469   9846.48484182 10389.92560611 10206.06849989
 10063.71975975 10214.44328913 10274.69033954  9923.26064694
 10208.90440954 10068.08476092]
total_rewards_mean           10133.597970055296
total_rewards_std            154.58552126937644
total_rewards_max            10389.9256061114
total_rewards_min            9846.484841824904
Number of train steps total  1084000
Number of env steps total    3254000
Number of rollouts total     0
Train Time (s)               195.78361419169232
(Previous) Eval Time (s)     31.252291971817613
Sample Time (s)              7.323578113224357
Epoch Time (s)               234.3594842767343
Total Train Time (s)         62677.31995584257
Epoch                        270
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:01:20.668455 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #270 | Epoch Duration: 234.45253348350525
2020-01-13 17:01:20.668658 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.442613
Z variance train             0.04792204
KL Divergence                45.31906
KL Loss                      4.531906
QF Loss                      3547.0654
VF Loss                      42.530678
Policy Loss                  -1027.6841
Q Predictions Mean           1026.009
Q Predictions Std            1043.418
Q Predictions Max            4617.9336
Q Predictions Min            622.375
V Predictions Mean           1025.1573
V Predictions Std            1037.6006
V Predictions Max            4604.6113
V Predictions Min            627.8877
Log Pis Mean                 -0.7147633
Log Pis Std                  3.3331583
Log Pis Max                  15.059651
Log Pis Min                  -6.7818775
Policy mu Mean               0.103264906
Policy mu Std                0.808226
Policy mu Max                3.0802238
Policy mu Min                -3.4854913
Policy log std Mean          -0.51224357
Policy log std Std           0.26535684
Policy log std Max           0.06836319
Policy log std Min           -2.645978
Z mean eval                  2.4448714
Z variance eval              0.04473682
total_rewards                [10380.70652545 10100.60068864 10476.93846394 10213.36393116
 10754.43496615 10102.95142729 10292.09559295  9864.22715828
 10597.53548968  9959.29157712]
total_rewards_mean           10274.214582065808
total_rewards_std            268.01998134960917
total_rewards_max            10754.434966150653
total_rewards_min            9864.227158275027
Number of train steps total  1088000
Number of env steps total    3266000
Number of rollouts total     0
Train Time (s)               187.395263931714
(Previous) Eval Time (s)     28.555387115105987
Sample Time (s)              7.048784215003252
Epoch Time (s)               222.99943526182324
Total Train Time (s)         62900.40526339365
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:05:03.757002 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #271 | Epoch Duration: 223.08812475204468
2020-01-13 17:05:03.757329 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4447048
Z variance train             0.04482902
KL Divergence                44.558876
KL Loss                      4.455888
QF Loss                      192.26917
VF Loss                      25.86962
Policy Loss                  -1370.07
Q Predictions Mean           1369.4062
Q Predictions Std            1396.6578
Q Predictions Max            4826.394
Q Predictions Min            647.6727
V Predictions Mean           1367.277
V Predictions Std            1394.4188
V Predictions Max            4809.036
V Predictions Min            653.8827
Log Pis Mean                 -0.0061985254
Log Pis Std                  3.820404
Log Pis Max                  12.343327
Log Pis Min                  -7.4639606
Policy mu Mean               0.07342912
Policy mu Std                0.9057401
Policy mu Max                2.8159835
Policy mu Min                -2.5859332
Policy log std Mean          -0.5349526
Policy log std Std           0.29305267
Policy log std Max           -0.0058352947
Policy log std Min           -2.6723104
Z mean eval                  2.4439254
Z variance eval              0.06332509
total_rewards                [10099.86837981 10205.767847    9868.40016526  9739.81208533
 10106.33701016 10132.09851526 10027.4807181  10092.84284722
 10055.90665594 10210.85697182]
total_rewards_mean           10053.937119590435
total_rewards_std            139.26845200857457
total_rewards_max            10210.856971821368
total_rewards_min            9739.812085327372
Number of train steps total  1092000
Number of env steps total    3278000
Number of rollouts total     0
Train Time (s)               191.9767631352879
(Previous) Eval Time (s)     32.019289528019726
Sample Time (s)              7.42803759034723
Epoch Time (s)               231.42409025365487
Total Train Time (s)         63131.909090564586
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:08:55.265546 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #272 | Epoch Duration: 231.50799822807312
2020-01-13 17:08:55.265820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.442162
Z variance train             0.06316151
KL Divergence                44.714577
KL Loss                      4.471458
QF Loss                      612.0024
VF Loss                      62.72658
Policy Loss                  -1508.6168
Q Predictions Mean           1505.388
Q Predictions Std            1461.7103
Q Predictions Max            4736.345
Q Predictions Min            633.1804
V Predictions Mean           1509.8986
V Predictions Std            1460.7297
V Predictions Max            4719.2334
V Predictions Min            640.7793
Log Pis Mean                 0.41413942
Log Pis Std                  4.364424
Log Pis Max                  16.55081
Log Pis Min                  -9.05569
Policy mu Mean               0.051894486
Policy mu Std                0.9794098
Policy mu Max                3.31944
Policy mu Min                -2.9431808
Policy log std Mean          -0.5497605
Policy log std Std           0.324603
Policy log std Max           0.07689667
Policy log std Min           -2.8385937
Z mean eval                  2.4451232
Z variance eval              0.07043404
total_rewards                [10034.56416348 10304.80095841 10241.87476842 10368.87148329
  9262.10746898 10487.81548174 10259.50777166 10288.40790678
 10159.04950598 10405.1758301 ]
total_rewards_mean           10181.217533885894
total_rewards_std            329.0451137784764
total_rewards_max            10487.815481741201
total_rewards_min            9262.107468980608
Number of train steps total  1096000
Number of env steps total    3290000
Number of rollouts total     0
Train Time (s)               195.59609306324273
(Previous) Eval Time (s)     35.755059408955276
Sample Time (s)              7.487892782781273
Epoch Time (s)               238.83904525497928
Total Train Time (s)         63370.85144003015
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:12:54.211312 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #273 | Epoch Duration: 238.9452440738678
2020-01-13 17:12:54.211586 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #273 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4450054
Z variance train             0.07033932
KL Divergence                44.860546
KL Loss                      4.486055
QF Loss                      3980.1895
VF Loss                      39.276123
Policy Loss                  -1280.3167
Q Predictions Mean           1277.573
Q Predictions Std            1289.5785
Q Predictions Max            4687.6655
Q Predictions Min            639.92633
V Predictions Mean           1283.3276
V Predictions Std            1291.7748
V Predictions Max            4696.3486
V Predictions Min            644.5531
Log Pis Mean                 -0.278795
Log Pis Std                  3.4857128
Log Pis Max                  14.548176
Log Pis Min                  -7.732093
Policy mu Mean               0.07635949
Policy mu Std                0.8438541
Policy mu Max                2.8651967
Policy mu Min                -3.480427
Policy log std Mean          -0.5347422
Policy log std Std           0.28072122
Policy log std Max           -0.025459379
Policy log std Min           -2.5938108
Z mean eval                  2.448944
Z variance eval              0.06225118
total_rewards                [10433.95321749  9877.78024106  9999.80711116  9989.55842896
 10014.96023384 10372.54850775 10006.47474684  9525.55824335
  9781.16394607 10195.8889907 ]
total_rewards_mean           10019.769366722016
total_rewards_std            254.92521778826597
total_rewards_max            10433.953217488888
total_rewards_min            9525.55824335409
Number of train steps total  1100000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               194.35441915225238
(Previous) Eval Time (s)     31.98996787983924
Sample Time (s)              7.443738772068173
Epoch Time (s)               233.7881258041598
Total Train Time (s)         63604.723664218094
Epoch                        274
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:16:48.087384 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #274 | Epoch Duration: 233.87559962272644
2020-01-13 17:16:48.087634 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4490006
Z variance train             0.062277306
KL Divergence                45.166206
KL Loss                      4.5166206
QF Loss                      125.59157
VF Loss                      53.33794
Policy Loss                  -1243.0548
Q Predictions Mean           1238.0288
Q Predictions Std            1236.2633
Q Predictions Max            4758.1553
Q Predictions Min            636.79803
V Predictions Mean           1241.0472
V Predictions Std            1238.5977
V Predictions Max            4738.75
V Predictions Min            635.15985
Log Pis Mean                 -0.551827
Log Pis Std                  3.7413745
Log Pis Max                  15.399175
Log Pis Min                  -6.9962454
Policy mu Mean               0.12659864
Policy mu Std                0.84705615
Policy mu Max                3.1788185
Policy mu Min                -3.0373087
Policy log std Mean          -0.53113854
Policy log std Std           0.27745035
Policy log std Max           -0.020330846
Policy log std Min           -2.3716366
Z mean eval                  2.437577
Z variance eval              0.040830534
total_rewards                [10572.50295602 10398.02960636 10423.99251012 10781.75458166
  5805.9016567  10522.17658961 10346.91094439 10625.91326525
   862.23638066  7704.51861303]
total_rewards_mean           8804.393710380296
total_rewards_std            3067.9888487865633
total_rewards_max            10781.754581657826
total_rewards_min            862.2363806628897
Number of train steps total  1104000
Number of env steps total    3314000
Number of rollouts total     0
Train Time (s)               191.77604756318033
(Previous) Eval Time (s)     31.432565681170672
Sample Time (s)              7.195152395870537
Epoch Time (s)               230.40376564022154
Total Train Time (s)         63835.232366900425
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:20:38.601345 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #275 | Epoch Duration: 230.5134961605072
2020-01-13 17:20:38.601619 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.438416
Z variance train             0.040870994
KL Divergence                45.826202
KL Loss                      4.58262
QF Loss                      96.36153
VF Loss                      28.811981
Policy Loss                  -1206.9261
Q Predictions Mean           1204.0001
Q Predictions Std            1220.7819
Q Predictions Max            4746.203
Q Predictions Min            646.938
V Predictions Mean           1206.1553
V Predictions Std            1217.1761
V Predictions Max            4731.7393
V Predictions Min            647.3361
Log Pis Mean                 -0.4141676
Log Pis Std                  3.3915837
Log Pis Max                  15.794505
Log Pis Min                  -6.551729
Policy mu Mean               0.0984345
Policy mu Std                0.85211396
Policy mu Max                3.5482407
Policy mu Min                -2.9817843
Policy log std Mean          -0.5102534
Policy log std Std           0.2658888
Policy log std Max           0.13626063
Policy log std Min           -2.5681517
Z mean eval                  2.4380631
Z variance eval              0.07853305
total_rewards                [6210.9047974  6248.26061084 6325.79832573 7189.00675948 7023.43151085
 1137.8022115  6741.09782978 1979.33389014 7343.8317819  7864.87793778]
total_rewards_mean           5806.434565541375
total_rewards_std            2189.48247187426
total_rewards_max            7864.877937783237
total_rewards_min            1137.8022115039346
Number of train steps total  1108000
Number of env steps total    3326000
Number of rollouts total     0
Train Time (s)               196.0812983890064
(Previous) Eval Time (s)     29.82958515593782
Sample Time (s)              6.832604091614485
Epoch Time (s)               232.7434876365587
Total Train Time (s)         64068.05462158006
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:24:31.464922 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #276 | Epoch Duration: 232.86307621002197
2020-01-13 17:24:31.465237 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4388287
Z variance train             0.07845961
KL Divergence                42.742878
KL Loss                      4.2742877
QF Loss                      220.88297
VF Loss                      55.939377
Policy Loss                  -1245.462
Q Predictions Mean           1242.8566
Q Predictions Std            1228.756
Q Predictions Max            4705.1284
Q Predictions Min            648.83167
V Predictions Mean           1241.6272
V Predictions Std            1225.9108
V Predictions Max            4700.865
V Predictions Min            656.1414
Log Pis Mean                 -0.36104816
Log Pis Std                  3.3921125
Log Pis Max                  13.914956
Log Pis Min                  -10.31203
Policy mu Mean               0.10174351
Policy mu Std                0.8746224
Policy mu Max                2.7780569
Policy mu Min                -2.5545688
Policy log std Mean          -0.49717
Policy log std Std           0.2621168
Policy log std Max           0.05394271
Policy log std Min           -2.9118836
Z mean eval                  2.4277809
Z variance eval              0.08378582
total_rewards                [10013.92203712 10152.71832853 10094.33484237 10238.78902461
 10236.94562246 10061.68526324 10143.69042115 10012.11065991
 10048.80160382 10046.12541785]
total_rewards_mean           10104.912322107204
total_rewards_std            80.38723410853532
total_rewards_max            10238.789024613547
total_rewards_min            10012.110659911299
Number of train steps total  1112000
Number of env steps total    3338000
Number of rollouts total     0
Train Time (s)               193.7836871049367
(Previous) Eval Time (s)     31.362471227999777
Sample Time (s)              6.571370963007212
Epoch Time (s)               231.71752929594368
Total Train Time (s)         64300.18834510166
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:28:23.568676 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #277 | Epoch Duration: 232.10319709777832
2020-01-13 17:28:23.568941 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #277 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.425845
Z variance train             0.0837252
KL Divergence                41.85529
KL Loss                      4.185529
QF Loss                      245.88911
VF Loss                      39.116516
Policy Loss                  -1327.4894
Q Predictions Mean           1327.3984
Q Predictions Std            1319.6838
Q Predictions Max            4654.004
Q Predictions Min            646.4073
V Predictions Mean           1326.9844
V Predictions Std            1315.0865
V Predictions Max            4652.992
V Predictions Min            649.84015
Log Pis Mean                 -0.037361823
Log Pis Std                  3.796979
Log Pis Max                  14.106557
Log Pis Min                  -6.654684
Policy mu Mean               0.090878986
Policy mu Std                0.8771767
Policy mu Max                2.7488286
Policy mu Min                -2.3726382
Policy log std Mean          -0.5309319
Policy log std Std           0.2915354
Policy log std Max           -0.029524922
Policy log std Min           -2.9113755
Z mean eval                  2.3975568
Z variance eval              0.08054569
total_rewards                [ 5107.56707694 10109.68384153 10296.51146245  9780.67235029
  9936.9726026  10173.7629063   9904.48335881 10071.25136523
  9910.95357423  9995.157648  ]
total_rewards_mean           9528.701618637664
total_rewards_std            1480.5084050683704
total_rewards_max            10296.511462446148
total_rewards_min            5107.567076942913
Number of train steps total  1116000
Number of env steps total    3350000
Number of rollouts total     0
Train Time (s)               195.67838700581342
(Previous) Eval Time (s)     31.918225045781583
Sample Time (s)              7.015304115135223
Epoch Time (s)               234.61191616673023
Total Train Time (s)         64534.880659361836
Epoch                        278
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:32:18.270827 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #278 | Epoch Duration: 234.70165824890137
2020-01-13 17:32:18.271169 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #278 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4013767
Z variance train             0.080567874
KL Divergence                42.474377
KL Loss                      4.247438
QF Loss                      300.64337
VF Loss                      54.56706
Policy Loss                  -1400.2057
Q Predictions Mean           1397.064
Q Predictions Std            1383.3156
Q Predictions Max            4799.9824
Q Predictions Min            639.36084
V Predictions Mean           1395.5847
V Predictions Std            1380.962
V Predictions Max            4774.3574
V Predictions Min            628.2142
Log Pis Mean                 0.16302066
Log Pis Std                  3.86895
Log Pis Max                  15.698573
Log Pis Min                  -7.0347114
Policy mu Mean               0.076946996
Policy mu Std                0.9254022
Policy mu Max                3.3393474
Policy mu Min                -3.1474931
Policy log std Mean          -0.52557665
Policy log std Std           0.28419557
Policy log std Max           0.013805002
Policy log std Min           -2.7129898
Z mean eval                  2.3618355
Z variance eval              0.07774465
total_rewards                [10454.82343821 10204.91738827 10352.9618671  10478.79538561
 10400.94773029 10143.52263207 10209.46838216 10568.79230551
 10378.77917839 10266.68989822]
total_rewards_mean           10345.969820584281
total_rewards_std            130.03388611897398
total_rewards_max            10568.79230550901
total_rewards_min            10143.522632073991
Number of train steps total  1120000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               197.4214028469287
(Previous) Eval Time (s)     36.084768999833614
Sample Time (s)              7.063921922352165
Epoch Time (s)               240.57009376911446
Total Train Time (s)         64775.533698546235
Epoch                        279
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:36:18.924204 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #279 | Epoch Duration: 240.65279388427734
2020-01-13 17:36:18.924339 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #279 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3623977
Z variance train             0.077804886
KL Divergence                41.583996
KL Loss                      4.1583996
QF Loss                      3735.5068
VF Loss                      32.739456
Policy Loss                  -1278.053
Q Predictions Mean           1276.5603
Q Predictions Std            1279.118
Q Predictions Max            4724.413
Q Predictions Min            623.455
V Predictions Mean           1278.237
V Predictions Std            1275.0045
V Predictions Max            4700.4355
V Predictions Min            631.3584
Log Pis Mean                 -0.095156476
Log Pis Std                  3.7378874
Log Pis Max                  14.036092
Log Pis Min                  -5.9166107
Policy mu Mean               0.08294291
Policy mu Std                0.9058245
Policy mu Max                3.1913445
Policy mu Min                -3.224945
Policy log std Mean          -0.54002357
Policy log std Std           0.29813293
Policy log std Max           0.06197822
Policy log std Min           -2.8967152
Z mean eval                  2.3751113
Z variance eval              0.059213925
total_rewards                [ 9939.97151929 10022.17041875 10196.8975325  10077.91003936
 10133.64553828 10083.0804266   9911.76413036 10137.78368704
 10062.64582049 10091.85239437]
total_rewards_mean           10065.77215070398
total_rewards_std            83.40777055378106
total_rewards_max            10196.89753250223
total_rewards_min            9911.764130360325
Number of train steps total  1124000
Number of env steps total    3374000
Number of rollouts total     0
Train Time (s)               195.04860994778574
(Previous) Eval Time (s)     30.904452863149345
Sample Time (s)              9.096061335876584
Epoch Time (s)               235.04912414681166
Total Train Time (s)         65010.665971424896
Epoch                        280
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:40:14.059428 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #280 | Epoch Duration: 235.13499093055725
2020-01-13 17:40:14.059556 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #280 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3727815
Z variance train             0.059025753
KL Divergence                43.800358
KL Loss                      4.380036
QF Loss                      112.051285
VF Loss                      48.105972
Policy Loss                  -1246.0629
Q Predictions Mean           1247.1525
Q Predictions Std            1262.2822
Q Predictions Max            4708.2725
Q Predictions Min            630.22577
V Predictions Mean           1248.024
V Predictions Std            1264.3695
V Predictions Max            4714.593
V Predictions Min            619.06226
Log Pis Mean                 -0.25719526
Log Pis Std                  3.8166468
Log Pis Max                  13.837334
Log Pis Min                  -7.29312
Policy mu Mean               0.09349682
Policy mu Std                0.855058
Policy mu Max                2.921168
Policy mu Min                -3.756263
Policy log std Mean          -0.5245216
Policy log std Std           0.30383042
Policy log std Max           0.57927084
Policy log std Min           -2.6800964
Z mean eval                  2.3994765
Z variance eval              0.04731474
total_rewards                [10134.96526993  9717.95472254  9950.14040385 10067.84986555
 10115.26802468 10484.1980525   9899.62875078  9635.6595174
  9808.83142463 10190.70042568]
total_rewards_mean           10000.519645754439
total_rewards_std            238.39399508827748
total_rewards_max            10484.19805249843
total_rewards_min            9635.659517400993
Number of train steps total  1128000
Number of env steps total    3386000
Number of rollouts total     0
Train Time (s)               194.53010248206556
(Previous) Eval Time (s)     33.50856356974691
Sample Time (s)              5.975308207329363
Epoch Time (s)               234.01397425914183
Total Train Time (s)         65244.77083976148
Epoch                        281
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:44:08.166981 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #281 | Epoch Duration: 234.10731983184814
2020-01-13 17:44:08.167157 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3997478
Z variance train             0.047350846
KL Divergence                44.165375
KL Loss                      4.416538
QF Loss                      243.9152
VF Loss                      125.726166
Policy Loss                  -1332.1514
Q Predictions Mean           1327.9248
Q Predictions Std            1317.6564
Q Predictions Max            4748.669
Q Predictions Min            631.43524
V Predictions Mean           1337.9224
V Predictions Std            1321.9801
V Predictions Max            4763.661
V Predictions Min            631.5772
Log Pis Mean                 -0.064170524
Log Pis Std                  4.124818
Log Pis Max                  14.539204
Log Pis Min                  -7.3865542
Policy mu Mean               0.04590452
Policy mu Std                0.924387
Policy mu Max                3.0119102
Policy mu Min                -3.301683
Policy log std Mean          -0.53839874
Policy log std Std           0.29801103
Policy log std Max           0.0964129
Policy log std Min           -2.6500623
Z mean eval                  2.3909883
Z variance eval              0.041523546
total_rewards                [10061.53378884 10213.7857147  10312.84569643 10061.29220907
 10368.94816109 10109.34471936 10379.26566414 10092.41594068
 10249.39917243 10035.59635954]
total_rewards_mean           10188.442742629337
total_rewards_std            126.46835275364016
total_rewards_max            10379.265664143732
total_rewards_min            10035.596359544095
Number of train steps total  1132000
Number of env steps total    3398000
Number of rollouts total     0
Train Time (s)               192.39502195920795
(Previous) Eval Time (s)     30.87853539409116
Sample Time (s)              7.506923347711563
Epoch Time (s)               230.78048070101067
Total Train Time (s)         65475.64212350594
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:47:59.041399 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #282 | Epoch Duration: 230.87409901618958
2020-01-13 17:47:59.041604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.387435
Z variance train             0.041477766
KL Divergence                43.390053
KL Loss                      4.3390055
QF Loss                      260.2423
VF Loss                      73.08417
Policy Loss                  -1390.5432
Q Predictions Mean           1390.6323
Q Predictions Std            1406.2228
Q Predictions Max            4701.6626
Q Predictions Min            632.76575
V Predictions Mean           1391.4153
V Predictions Std            1404.11
V Predictions Max            4690.063
V Predictions Min            620.88586
Log Pis Mean                 -0.086790845
Log Pis Std                  3.8920996
Log Pis Max                  12.09495
Log Pis Min                  -6.1147976
Policy mu Mean               0.02100271
Policy mu Std                0.88662004
Policy mu Max                2.7519436
Policy mu Min                -2.996582
Policy log std Mean          -0.53767484
Policy log std Std           0.3092234
Policy log std Max           -0.037614822
Policy log std Min           -2.8015594
Z mean eval                  2.3919752
Z variance eval              0.05031343
total_rewards                [9402.76652248 9344.8497266  9542.61927111 9476.13530775 9563.77740206
 9552.17708868 9552.5215091  9287.81416559 9298.22853086 9568.00126722]
total_rewards_mean           9458.889079146902
total_rewards_std            109.04955070869688
total_rewards_max            9568.001267217269
total_rewards_min            9287.814165593481
Number of train steps total  1136000
Number of env steps total    3410000
Number of rollouts total     0
Train Time (s)               194.55845088278875
(Previous) Eval Time (s)     31.28751887474209
Sample Time (s)              7.294668241403997
Epoch Time (s)               233.14063799893484
Total Train Time (s)         65708.86948450562
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:51:52.271425 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #283 | Epoch Duration: 233.2296667098999
2020-01-13 17:51:52.271605 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.392316
Z variance train             0.05078398
KL Divergence                44.220078
KL Loss                      4.422008
QF Loss                      3880.9092
VF Loss                      127.63493
Policy Loss                  -1324.8944
Q Predictions Mean           1322.5542
Q Predictions Std            1365.7261
Q Predictions Max            4705.192
Q Predictions Min            645.5627
V Predictions Mean           1316.621
V Predictions Std            1360.8531
V Predictions Max            4670.462
V Predictions Min            646.6889
Log Pis Mean                 -0.29652363
Log Pis Std                  3.688836
Log Pis Max                  11.997171
Log Pis Min                  -6.734928
Policy mu Mean               0.031503517
Policy mu Std                0.8589003
Policy mu Max                2.5471308
Policy mu Min                -2.6184537
Policy log std Mean          -0.528762
Policy log std Std           0.31615418
Policy log std Max           -0.06707567
Policy log std Min           -2.596327
Z mean eval                  2.4047253
Z variance eval              0.06625581
total_rewards                [10029.67040783 10038.08594972  9294.79461712 10039.51298994
  9986.55824946 10299.95185609 10634.06446856 10222.35858944
  9381.06005522 10068.5687788 ]
total_rewards_mean           9999.462596216843
total_rewards_std            378.2360526113788
total_rewards_max            10634.064468561728
total_rewards_min            9294.794617120868
Number of train steps total  1140000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               200.04617172898725
(Previous) Eval Time (s)     33.23750383872539
Sample Time (s)              7.065738930832595
Epoch Time (s)               240.34941449854523
Total Train Time (s)         65949.30125306314
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:55:52.704994 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #284 | Epoch Duration: 240.43326091766357
2020-01-13 17:55:52.705124 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.406957
Z variance train             0.066143796
KL Divergence                44.009613
KL Loss                      4.4009614
QF Loss                      3512.96
VF Loss                      83.84186
Policy Loss                  -1240.4252
Q Predictions Mean           1237.7285
Q Predictions Std            1252.2327
Q Predictions Max            4695.9434
Q Predictions Min            625.5758
V Predictions Mean           1236.6497
V Predictions Std            1249.3485
V Predictions Max            4668.106
V Predictions Min            629.60254
Log Pis Mean                 -0.62973166
Log Pis Std                  3.3397863
Log Pis Max                  11.072542
Log Pis Min                  -7.121514
Policy mu Mean               0.035639603
Policy mu Std                0.817491
Policy mu Max                2.4903693
Policy mu Min                -2.7892053
Policy log std Mean          -0.5059585
Policy log std Std           0.26806292
Policy log std Max           -0.06844592
Policy log std Min           -2.5473895
Z mean eval                  2.406215
Z variance eval              0.04000204
total_rewards                [10325.87987723 10296.74243963 10111.65572251  9962.04257639
 10411.15431378 10242.94497404 10440.51148265 10131.04365143
 10517.53998385 10098.32559536]
total_rewards_mean           10253.784061685152
total_rewards_std            167.6026638328288
total_rewards_max            10517.539983845425
total_rewards_min            9962.042576385833
Number of train steps total  1144000
Number of env steps total    3434000
Number of rollouts total     0
Train Time (s)               193.1966743208468
(Previous) Eval Time (s)     29.67923262901604
Sample Time (s)              6.6025628643110394
Epoch Time (s)               229.47846981417388
Total Train Time (s)         66178.85918240156
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:59:42.266363 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #285 | Epoch Duration: 229.56111764907837
2020-01-13 17:59:42.266563 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.409846
Z variance train             0.04011618
KL Divergence                44.782017
KL Loss                      4.478202
QF Loss                      153.89893
VF Loss                      96.486664
Policy Loss                  -1363.4506
Q Predictions Mean           1362.8284
Q Predictions Std            1356.7367
Q Predictions Max            4829.573
Q Predictions Min            659.8015
V Predictions Mean           1357.98
V Predictions Std            1349.9467
V Predictions Max            4793.9526
V Predictions Min            660.38165
Log Pis Mean                 0.0689615
Log Pis Std                  4.0535727
Log Pis Max                  16.42041
Log Pis Min                  -7.437357
Policy mu Mean               0.07290717
Policy mu Std                0.90839213
Policy mu Max                2.816948
Policy mu Min                -2.992813
Policy log std Mean          -0.5099731
Policy log std Std           0.26389924
Policy log std Max           0.0066486895
Policy log std Min           -2.5678754
Z mean eval                  2.4357758
Z variance eval              0.042870615
total_rewards                [10175.66871544 10288.8730833  10301.87799468 10007.78340421
 10105.89545779  9986.60785189 10076.72110643  9791.41966241
 10251.06354238 10232.86744359]
total_rewards_mean           10121.877826212085
total_rewards_std            153.29750398369563
total_rewards_max            10301.877994676515
total_rewards_min            9791.41966241438
Number of train steps total  1148000
Number of env steps total    3446000
Number of rollouts total     0
Train Time (s)               194.72295451909304
(Previous) Eval Time (s)     33.60870545776561
Sample Time (s)              8.62014748994261
Epoch Time (s)               236.95180746680126
Total Train Time (s)         66415.89512437116
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:03:39.307558 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #286 | Epoch Duration: 237.04082322120667
2020-01-13 18:03:39.307826 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4372284
Z variance train             0.042916626
KL Divergence                45.830917
KL Loss                      4.5830917
QF Loss                      163.65552
VF Loss                      23.681904
Policy Loss                  -1330.1476
Q Predictions Mean           1329.7844
Q Predictions Std            1364.3296
Q Predictions Max            4871.4243
Q Predictions Min            651.3211
V Predictions Mean           1329.5059
V Predictions Std            1361.0483
V Predictions Max            4848.5503
V Predictions Min            651.1936
Log Pis Mean                 -0.39962593
Log Pis Std                  3.5541255
Log Pis Max                  13.86393
Log Pis Min                  -6.898711
Policy mu Mean               0.07580058
Policy mu Std                0.8542538
Policy mu Max                2.3885498
Policy mu Min                -2.6229234
Policy log std Mean          -0.5155173
Policy log std Std           0.27761543
Policy log std Max           0.05888015
Policy log std Min           -2.532342
Z mean eval                  2.4243374
Z variance eval              0.047684565
total_rewards                [ 9822.67129597  4199.59074425 10332.78508314  9888.96534515
 10234.07145435 10257.09424256 10423.8619877   9814.53785476
  9935.93255542 10227.14574438]
total_rewards_mean           9513.66563076722
total_rewards_std            1783.9478225707003
total_rewards_max            10423.861987703796
total_rewards_min            4199.590744246832
Number of train steps total  1152000
Number of env steps total    3458000
Number of rollouts total     0
Train Time (s)               193.77773990295827
(Previous) Eval Time (s)     30.34365465119481
Sample Time (s)              7.131337970029563
Epoch Time (s)               231.25273252418265
Total Train Time (s)         66647.23016158072
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:07:30.644849 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #287 | Epoch Duration: 231.3368239402771
2020-01-13 18:07:30.645017 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4233477
Z variance train             0.047554646
KL Divergence                44.734035
KL Loss                      4.4734035
QF Loss                      140.03468
VF Loss                      106.74346
Policy Loss                  -1334.7604
Q Predictions Mean           1331.4938
Q Predictions Std            1322.6877
Q Predictions Max            4729.2754
Q Predictions Min            649.21967
V Predictions Mean           1336.1643
V Predictions Std            1328.6372
V Predictions Max            4741.129
V Predictions Min            644.34656
Log Pis Mean                 -0.15113878
Log Pis Std                  3.782432
Log Pis Max                  15.195152
Log Pis Min                  -6.850823
Policy mu Mean               0.06637459
Policy mu Std                0.8831637
Policy mu Max                2.7919667
Policy mu Min                -3.0492802
Policy log std Mean          -0.51707655
Policy log std Std           0.2799439
Policy log std Max           -0.095458955
Policy log std Min           -2.692857
Z mean eval                  2.4013813
Z variance eval              0.053126566
total_rewards                [10123.39489245 10408.34950663  8625.40002135 10381.61862619
 10626.16931459 10318.86532067 10547.37548247 10435.72401544
 10412.60686086 10374.8091557 ]
total_rewards_mean           10225.43131963584
total_rewards_std            547.9877244972727
total_rewards_max            10626.169314590325
total_rewards_min            8625.400021354579
Number of train steps total  1156000
Number of env steps total    3470000
Number of rollouts total     0
Train Time (s)               195.09582438180223
(Previous) Eval Time (s)     30.408913395833224
Sample Time (s)              6.885050818324089
Epoch Time (s)               232.38978859595954
Total Train Time (s)         66879.70729593793
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:11:23.125812 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #288 | Epoch Duration: 232.48065853118896
2020-01-13 18:11:23.126004 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #288 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.400884
Z variance train             0.05307003
KL Divergence                43.80305
KL Loss                      4.3803053
QF Loss                      94.29984
VF Loss                      22.225285
Policy Loss                  -1180.4193
Q Predictions Mean           1178.4243
Q Predictions Std            1203.0963
Q Predictions Max            4762.844
Q Predictions Min            635.6304
V Predictions Mean           1179.49
V Predictions Std            1202.863
V Predictions Max            4763.9795
V Predictions Min            631.7348
Log Pis Mean                 -0.41003966
Log Pis Std                  3.7566543
Log Pis Max                  14.351276
Log Pis Min                  -6.0162225
Policy mu Mean               0.07813188
Policy mu Std                0.8601849
Policy mu Max                3.4930172
Policy mu Min                -2.7068996
Policy log std Mean          -0.5102963
Policy log std Std           0.26401737
Policy log std Max           0.10097301
Policy log std Min           -2.5025496
Z mean eval                  2.4561224
Z variance eval              0.05948431
total_rewards                [10260.24592145 10300.84886048 10149.84700857 10198.852955
 10291.19120045 10351.21788953 10334.26901689 10112.13843727
 10171.31372415 10231.33535917]
total_rewards_mean           10240.126037295497
total_rewards_std            76.77957325697537
total_rewards_max            10351.217889530863
total_rewards_min            10112.138437270392
Number of train steps total  1160000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               194.891582720913
(Previous) Eval Time (s)     34.20858991891146
Sample Time (s)              7.784041230101138
Epoch Time (s)               236.8842138699256
Total Train Time (s)         67116.69845672743
Epoch                        289
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:15:20.119859 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #289 | Epoch Duration: 236.9937047958374
2020-01-13 18:15:20.120082 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4566734
Z variance train             0.0595582
KL Divergence                44.60042
KL Loss                      4.4600425
QF Loss                      113.33435
VF Loss                      93.07823
Policy Loss                  -1436.7242
Q Predictions Mean           1435.9836
Q Predictions Std            1449.2252
Q Predictions Max            4870.1562
Q Predictions Min            637.0709
V Predictions Mean           1432.2065
V Predictions Std            1438.3209
V Predictions Max            4837.286
V Predictions Min            647.6368
Log Pis Mean                 -0.010732055
Log Pis Std                  3.923311
Log Pis Max                  20.723759
Log Pis Min                  -5.621012
Policy mu Mean               0.03168453
Policy mu Std                0.91165274
Policy mu Max                2.992101
Policy mu Min                -2.7947
Policy log std Mean          -0.5223109
Policy log std Std           0.299905
Policy log std Max           -0.059088632
Policy log std Min           -2.6888564
Z mean eval                  2.4090478
Z variance eval              0.04612812
total_rewards                [9877.49450313 9952.78033104 9805.61846351 9737.23798178 9506.45927388
 9593.4803275  9913.77549991 9848.03355712 9939.89373412 9835.79547102]
total_rewards_mean           9801.056914300154
total_rewards_std            140.79307069271792
total_rewards_max            9952.780331038251
total_rewards_min            9506.45927388153
Number of train steps total  1164000
Number of env steps total    3494000
Number of rollouts total     0
Train Time (s)               193.44103871891275
(Previous) Eval Time (s)     32.089986962266266
Sample Time (s)              6.771633490920067
Epoch Time (s)               232.30265917209908
Total Train Time (s)         67349.08895550389
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:19:12.514911 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #290 | Epoch Duration: 232.39465022087097
2020-01-13 18:19:12.515131 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4075027
Z variance train             0.046115167
KL Divergence                44.81978
KL Loss                      4.481978
QF Loss                      117.97069
VF Loss                      105.28313
Policy Loss                  -1360.1196
Q Predictions Mean           1357.5208
Q Predictions Std            1366.934
Q Predictions Max            4709.6177
Q Predictions Min            627.71765
V Predictions Mean           1362.4482
V Predictions Std            1369.3076
V Predictions Max            4744.73
V Predictions Min            635.83905
Log Pis Mean                 0.08576739
Log Pis Std                  3.733265
Log Pis Max                  13.781731
Log Pis Min                  -8.346739
Policy mu Mean               0.0025315743
Policy mu Std                0.90377367
Policy mu Max                5.629763
Policy mu Min                -2.8923101
Policy log std Mean          -0.530009
Policy log std Std           0.29070354
Policy log std Max           0.5352422
Policy log std Min           -2.6163983
Z mean eval                  2.4124742
Z variance eval              0.056801565
total_rewards                [10107.21848218 10404.33596884 10190.8210771  10352.11908586
  9594.63787451 10453.27217255  9997.13120934 10402.17437245
 10815.38846212 10045.17082575]
total_rewards_mean           10236.226953070081
total_rewards_std            312.37437439738665
total_rewards_max            10815.38846212048
total_rewards_min            9594.637874512675
Number of train steps total  1168000
Number of env steps total    3506000
Number of rollouts total     0
Train Time (s)               192.4725745888427
(Previous) Eval Time (s)     31.382191758602858
Sample Time (s)              7.581389266066253
Epoch Time (s)               231.4361556135118
Total Train Time (s)         67580.61758901039
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:23:04.045894 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #291 | Epoch Duration: 231.53059244155884
2020-01-13 18:23:04.046088 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4124238
Z variance train             0.05677079
KL Divergence                43.99096
KL Loss                      4.399096
QF Loss                      3880.8933
VF Loss                      76.40593
Policy Loss                  -1431.3475
Q Predictions Mean           1432.3358
Q Predictions Std            1427.8849
Q Predictions Max            4748.8984
Q Predictions Min            638.4902
V Predictions Mean           1434.2256
V Predictions Std            1428.0005
V Predictions Max            4739.037
V Predictions Min            641.7639
Log Pis Mean                 -0.16836727
Log Pis Std                  3.755274
Log Pis Max                  13.140597
Log Pis Min                  -8.025299
Policy mu Mean               0.002335622
Policy mu Std                0.86934376
Policy mu Max                2.4429517
Policy mu Min                -2.9986868
Policy log std Mean          -0.51703405
Policy log std Std           0.2952167
Policy log std Max           0.42247546
Policy log std Min           -2.6830683
Z mean eval                  2.4196904
Z variance eval              0.066766515
total_rewards                [10718.00564801 10417.04654482 10689.3656326  10588.29851496
 10677.24445591 10840.53156759 10757.83343464 10798.26046424
 10801.92602949 10665.92541274]
total_rewards_mean           10695.443770500322
total_rewards_std            117.29720144512903
total_rewards_max            10840.531567593658
total_rewards_min            10417.046544823988
Number of train steps total  1172000
Number of env steps total    3518000
Number of rollouts total     0
Train Time (s)               191.9345689630136
(Previous) Eval Time (s)     34.767025106120855
Sample Time (s)              7.179425658658147
Epoch Time (s)               233.8810197277926
Total Train Time (s)         67814.58279436175
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:26:58.014443 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #292 | Epoch Duration: 233.96821093559265
2020-01-13 18:26:58.014632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4220066
Z variance train             0.06659305
KL Divergence                43.591652
KL Loss                      4.359165
QF Loss                      149.19632
VF Loss                      112.893684
Policy Loss                  -1387.4465
Q Predictions Mean           1380.136
Q Predictions Std            1382.7821
Q Predictions Max            4752.8003
Q Predictions Min            644.326
V Predictions Mean           1385.95
V Predictions Std            1377.5321
V Predictions Max            4761.3677
V Predictions Min            645.87604
Log Pis Mean                 -0.26451564
Log Pis Std                  4.1273103
Log Pis Max                  24.308315
Log Pis Min                  -7.14972
Policy mu Mean               0.0626295
Policy mu Std                0.8975112
Policy mu Max                3.1456852
Policy mu Min                -3.9703753
Policy log std Mean          -0.52567667
Policy log std Std           0.30272067
Policy log std Max           -0.08734733
Policy log std Min           -2.641333
Z mean eval                  2.4065928
Z variance eval              0.06720562
total_rewards                [10320.71749997 10420.47989999 10644.68556672 10380.47053708
 10588.19136939 10498.66014276 10404.86860258 10335.68987008
 10644.16120281 10637.66821343]
total_rewards_mean           10487.559290482048
total_rewards_std            124.78039033545396
total_rewards_max            10644.685566723287
total_rewards_min            10320.717499965616
Number of train steps total  1176000
Number of env steps total    3530000
Number of rollouts total     0
Train Time (s)               193.06268293969333
(Previous) Eval Time (s)     32.40556365484372
Sample Time (s)              7.079236080870032
Epoch Time (s)               232.54748267540708
Total Train Time (s)         68047.2511118874
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:30:50.687854 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #293 | Epoch Duration: 232.67306470870972
2020-01-13 18:30:50.688121 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4047856
Z variance train             0.06735059
KL Divergence                43.08646
KL Loss                      4.308646
QF Loss                      226.35326
VF Loss                      73.20797
Policy Loss                  -1236.2906
Q Predictions Mean           1234.081
Q Predictions Std            1263.8174
Q Predictions Max            4732.6685
Q Predictions Min            636.12994
V Predictions Mean           1237.2952
V Predictions Std            1259.5643
V Predictions Max            4709.577
V Predictions Min            648.4263
Log Pis Mean                 -0.35555667
Log Pis Std                  3.9810874
Log Pis Max                  13.600391
Log Pis Min                  -8.455105
Policy mu Mean               0.06762592
Policy mu Std                0.8521607
Policy mu Max                2.8894608
Policy mu Min                -3.3127735
Policy log std Mean          -0.4963729
Policy log std Std           0.29633316
Policy log std Max           -0.032162994
Policy log std Min           -2.9582095
Z mean eval                  2.4048104
Z variance eval              0.04690093
total_rewards                [10131.65204391 10375.14566566 10251.81898256 10493.88649934
 10425.15273932 10315.60230674 10275.89899364  9862.48066467
 10266.99719065 10346.81966598]
total_rewards_mean           10274.545475246148
total_rewards_std            166.91731370071693
total_rewards_max            10493.886499339853
total_rewards_min            9862.480664665733
Number of train steps total  1180000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               199.15930065186694
(Previous) Eval Time (s)     29.719141259789467
Sample Time (s)              7.244938436895609
Epoch Time (s)               236.12338034855202
Total Train Time (s)         68283.45649321564
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:34:46.897722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #294 | Epoch Duration: 236.20941495895386
2020-01-13 18:34:46.897918 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4020104
Z variance train             0.04689555
KL Divergence                43.990185
KL Loss                      4.399019
QF Loss                      150.13028
VF Loss                      85.43473
Policy Loss                  -1253.4915
Q Predictions Mean           1251.3385
Q Predictions Std            1270.2125
Q Predictions Max            4735.0244
Q Predictions Min            643.08386
V Predictions Mean           1258.8628
V Predictions Std            1272.6261
V Predictions Max            4758.1675
V Predictions Min            658.75366
Log Pis Mean                 -0.1317825
Log Pis Std                  3.7519093
Log Pis Max                  12.565958
Log Pis Min                  -6.4657
Policy mu Mean               0.116268955
Policy mu Std                0.88444775
Policy mu Max                2.9359188
Policy mu Min                -2.7178135
Policy log std Mean          -0.51074594
Policy log std Std           0.291112
Policy log std Max           -0.0055793524
Policy log std Min           -2.5964088
Z mean eval                  2.4244075
Z variance eval              0.06822007
total_rewards                [10641.13814102 10308.80560153 10364.85428214 10437.46732849
 10235.12395435 10214.65925821 10340.15892471 10470.32198277
 10634.29409572 10588.71721045]
total_rewards_mean           10423.554077937772
total_rewards_std            149.70786319881728
total_rewards_max            10641.138141018211
total_rewards_min            10214.65925821356
Number of train steps total  1184000
Number of env steps total    3554000
Number of rollouts total     0
Train Time (s)               195.72347775800154
(Previous) Eval Time (s)     29.910162148065865
Sample Time (s)              6.297041541431099
Epoch Time (s)               231.9306814474985
Total Train Time (s)         68515.46873629745
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:38:38.913728 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #295 | Epoch Duration: 232.01565217971802
2020-01-13 18:38:38.913914 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4197407
Z variance train             0.06843804
KL Divergence                43.949997
KL Loss                      4.395
QF Loss                      174.5882
VF Loss                      91.18294
Policy Loss                  -1356.5591
Q Predictions Mean           1356.3638
Q Predictions Std            1356.7106
Q Predictions Max            4741.8223
Q Predictions Min            629.59766
V Predictions Mean           1356.4673
V Predictions Std            1347.72
V Predictions Max            4708.4893
V Predictions Min            639.2972
Log Pis Mean                 -0.19901398
Log Pis Std                  3.7326176
Log Pis Max                  12.444638
Log Pis Min                  -7.1420646
Policy mu Mean               0.06699204
Policy mu Std                0.8998239
Policy mu Max                3.2074635
Policy mu Min                -3.1163201
Policy log std Mean          -0.5319763
Policy log std Std           0.29745498
Policy log std Max           0.1383295
Policy log std Min           -2.4182162
Z mean eval                  2.4015129
Z variance eval              0.05281809
total_rewards                [10349.79947443  2549.32740451 10714.24609652 10172.32976604
 10807.45070825 10840.53645089 10466.75752076 10828.10754351
 10791.92426834 10696.74374652]
total_rewards_mean           9821.722297975528
total_rewards_std            2433.754223316645
total_rewards_max            10840.536450893025
total_rewards_min            2549.3274045139137
Number of train steps total  1188000
Number of env steps total    3566000
Number of rollouts total     0
Train Time (s)               194.97260379092768
(Previous) Eval Time (s)     30.423595257103443
Sample Time (s)              7.406188636086881
Epoch Time (s)               232.802387684118
Total Train Time (s)         68748.35421816213
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:42:31.802070 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #296 | Epoch Duration: 232.88794612884521
2020-01-13 18:42:31.802365 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #296 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3997734
Z variance train             0.052834414
KL Divergence                43.98146
KL Loss                      4.398146
QF Loss                      138.17447
VF Loss                      36.06487
Policy Loss                  -1173.0314
Q Predictions Mean           1171.1284
Q Predictions Std            1201.5748
Q Predictions Max            4719.8037
Q Predictions Min            620.4978
V Predictions Mean           1173.8357
V Predictions Std            1197.0248
V Predictions Max            4722.0283
V Predictions Min            630.18567
Log Pis Mean                 -0.5961463
Log Pis Std                  3.5947275
Log Pis Max                  15.879224
Log Pis Min                  -8.342917
Policy mu Mean               0.053622022
Policy mu Std                0.8439322
Policy mu Max                2.9634678
Policy mu Min                -2.5387537
Policy log std Mean          -0.4856653
Policy log std Std           0.27051502
Policy log std Max           0.07450664
Policy log std Min           -3.0897546
Z mean eval                  2.394854
Z variance eval              0.087977305
total_rewards                [10624.87623736  8493.5777784  10594.24639898 10597.05888695
 10990.45869355 11053.18096004 10553.49969968 10927.11873024
 10917.04701201 10847.18554819]
total_rewards_mean           10559.824994542023
total_rewards_std            710.6443741306381
total_rewards_max            11053.180960038519
total_rewards_min            8493.577778403976
Number of train steps total  1192000
Number of env steps total    3578000
Number of rollouts total     0
Train Time (s)               195.48190577328205
(Previous) Eval Time (s)     32.603372626937926
Sample Time (s)              7.499589430168271
Epoch Time (s)               235.58486783038825
Total Train Time (s)         68984.02198602026
Epoch                        297
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:46:27.473166 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #297 | Epoch Duration: 235.67060351371765
2020-01-13 18:46:27.473366 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.394584
Z variance train             0.087987304
KL Divergence                43.341473
KL Loss                      4.3341475
QF Loss                      3374.0083
VF Loss                      57.389015
Policy Loss                  -1222.116
Q Predictions Mean           1218.1848
Q Predictions Std            1260.5659
Q Predictions Max            4813.967
Q Predictions Min            640.7065
V Predictions Mean           1222.2771
V Predictions Std            1256.0007
V Predictions Max            4830.976
V Predictions Min            640.91266
Log Pis Mean                 -0.7057784
Log Pis Std                  3.564564
Log Pis Max                  18.706356
Log Pis Min                  -8.30444
Policy mu Mean               0.13935728
Policy mu Std                0.81839967
Policy mu Max                3.337882
Policy mu Min                -3.6383975
Policy log std Mean          -0.5118099
Policy log std Std           0.27862516
Policy log std Max           -0.03717649
Policy log std Min           -2.7274067
Z mean eval                  2.3936296
Z variance eval              0.0678963
total_rewards                [10377.74371476 10504.70073839 10510.46157112 10481.31973822
 10554.76525588 10553.525582   10697.121362    1135.61670472
 10525.82840613 10464.16442638]
total_rewards_mean           9580.524749959748
total_rewards_std            2816.0153867977206
total_rewards_max            10697.121362001386
total_rewards_min            1135.6167047225563
Number of train steps total  1196000
Number of env steps total    3590000
Number of rollouts total     0
Train Time (s)               194.79549452802166
(Previous) Eval Time (s)     32.142128146253526
Sample Time (s)              8.390588829759508
Epoch Time (s)               235.3282115040347
Total Train Time (s)         69219.43729311321
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:50:22.891051 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #298 | Epoch Duration: 235.41752982139587
2020-01-13 18:50:22.891250 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3964632
Z variance train             0.06823811
KL Divergence                44.877525
KL Loss                      4.4877524
QF Loss                      3763.6047
VF Loss                      111.51381
Policy Loss                  -1386.3969
Q Predictions Mean           1382.6602
Q Predictions Std            1373.5166
Q Predictions Max            4852.5723
Q Predictions Min            646.51086
V Predictions Mean           1380.8777
V Predictions Std            1366.5619
V Predictions Max            4826.928
V Predictions Min            645.2177
Log Pis Mean                 -0.14964409
Log Pis Std                  3.902875
Log Pis Max                  13.904691
Log Pis Min                  -7.50513
Policy mu Mean               0.04204014
Policy mu Std                0.8791114
Policy mu Max                2.7775567
Policy mu Min                -2.875344
Policy log std Mean          -0.5383808
Policy log std Std           0.30662388
Policy log std Max           -0.08876169
Policy log std Min           -2.6487036
Z mean eval                  2.3970475
Z variance eval              0.05816377
total_rewards                [10894.8789057  10706.94893489 10457.74610225 10849.44737087
 10950.47783945 10848.55979924 10427.72965674 10737.44218644
 10834.22524977 10673.88198264]
total_rewards_mean           10738.133802799306
total_rewards_std            168.3883789681929
total_rewards_max            10950.477839452902
total_rewards_min            10427.72965674093
Number of train steps total  1200000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               195.93385124625638
(Previous) Eval Time (s)     34.73266026098281
Sample Time (s)              7.374812124297023
Epoch Time (s)               238.04132363153622
Total Train Time (s)         69457.56002336508
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:54:21.015604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #299 | Epoch Duration: 238.12421464920044
2020-01-13 18:54:21.015744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4020648
Z variance train             0.058158793
KL Divergence                44.691776
KL Loss                      4.4691777
QF Loss                      138.67914
VF Loss                      137.6625
Policy Loss                  -1335.6306
Q Predictions Mean           1330.7039
Q Predictions Std            1351.4269
Q Predictions Max            4927.341
Q Predictions Min            648.4289
V Predictions Mean           1335.4753
V Predictions Std            1344.4802
V Predictions Max            4902.6807
V Predictions Min            660.06006
Log Pis Mean                 0.051374897
Log Pis Std                  4.4925046
Log Pis Max                  22.727215
Log Pis Min                  -7.6175165
Policy mu Mean               0.055084467
Policy mu Std                0.94376606
Policy mu Max                3.8483205
Policy mu Min                -4.5095487
Policy log std Mean          -0.52493066
Policy log std Std           0.31676278
Policy log std Max           0.34894556
Policy log std Min           -2.8440323
Z mean eval                  2.4148865
Z variance eval              0.041246332
total_rewards                [10574.2035826  10121.70321619 10432.65129518 10447.93100663
 10061.72772805 10251.72984548  7966.66826255 10224.00866176
 10543.24686374 10393.16115374]
total_rewards_mean           10101.703161591722
total_rewards_std            730.096181103514
total_rewards_max            10574.203582600861
total_rewards_min            7966.668262546549
Number of train steps total  1204000
Number of env steps total    3614000
Number of rollouts total     0
Train Time (s)               193.1987367477268
(Previous) Eval Time (s)     36.04763235198334
Sample Time (s)              7.643550182227045
Epoch Time (s)               236.88991928193718
Total Train Time (s)         69694.57136344304
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:58:18.029784 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #300 | Epoch Duration: 237.0138783454895
2020-01-13 18:58:18.030026 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4150853
Z variance train             0.04124923
KL Divergence                45.78263
KL Loss                      4.5782633
QF Loss                      170.12279
VF Loss                      33.174145
Policy Loss                  -1429.2012
Q Predictions Mean           1427.1265
Q Predictions Std            1431.2269
Q Predictions Max            4811.5015
Q Predictions Min            642.0887
V Predictions Mean           1430.383
V Predictions Std            1429.1235
V Predictions Max            4811.4307
V Predictions Min            648.1469
Log Pis Mean                 0.441356
Log Pis Std                  4.2863803
Log Pis Max                  20.421316
Log Pis Min                  -6.0901346
Policy mu Mean               0.08204856
Policy mu Std                0.9892083
Policy mu Max                2.9671524
Policy mu Min                -4.5214906
Policy log std Mean          -0.5320413
Policy log std Std           0.30781275
Policy log std Max           -0.013721049
Policy log std Min           -3.265779
Z mean eval                  2.390077
Z variance eval              0.043923397
total_rewards                [10967.24073082 10709.9738493  10490.72574456 10854.70796105
 10497.05961312 10803.40603436 10939.39274627 10583.38716771
 10645.59157404 10724.85115377]
total_rewards_mean           10721.633657500646
total_rewards_std            161.53331129079288
total_rewards_max            10967.240730821402
total_rewards_min            10490.725744559917
Number of train steps total  1208000
Number of env steps total    3626000
Number of rollouts total     0
Train Time (s)               193.76352429389954
(Previous) Eval Time (s)     31.304843667894602
Sample Time (s)              7.427374925464392
Epoch Time (s)               232.49574288725853
Total Train Time (s)         69927.14860327588
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:02:10.611743 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #301 | Epoch Duration: 232.58155846595764
2020-01-13 19:02:10.612069 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3905926
Z variance train             0.043903906
KL Divergence                45.46127
KL Loss                      4.546127
QF Loss                      498.7748
VF Loss                      152.10281
Policy Loss                  -1343.2881
Q Predictions Mean           1337.1394
Q Predictions Std            1370.2562
Q Predictions Max            4815.8467
Q Predictions Min            641.23895
V Predictions Mean           1344.8878
V Predictions Std            1370.41
V Predictions Max            4812.3022
V Predictions Min            642.55334
Log Pis Mean                 -0.0066813454
Log Pis Std                  4.068918
Log Pis Max                  19.324432
Log Pis Min                  -7.8060946
Policy mu Mean               0.044739265
Policy mu Std                0.9089767
Policy mu Max                2.881301
Policy mu Min                -3.9488485
Policy log std Mean          -0.5216196
Policy log std Std           0.2942431
Policy log std Max           -0.06143856
Policy log std Min           -2.7180767
Z mean eval                  2.3957765
Z variance eval              0.039269496
total_rewards                [10916.11748011 10858.47336379 10780.51889255 10807.37569378
 10965.33535111 10894.80111728 10739.86205925 10948.12089244
 10753.47242041 10848.00962358]
total_rewards_mean           10851.20868942972
total_rewards_std            75.80379911966116
total_rewards_max            10965.335351106549
total_rewards_min            10739.86205925278
Number of train steps total  1212000
Number of env steps total    3638000
Number of rollouts total     0
Train Time (s)               193.76247327309102
(Previous) Eval Time (s)     32.67498639598489
Sample Time (s)              8.124597450252622
Epoch Time (s)               234.56205711932853
Total Train Time (s)         70161.8274524333
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:06:05.296322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #302 | Epoch Duration: 234.68399667739868
2020-01-13 19:06:05.296638 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #302 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3965614
Z variance train             0.03926439
KL Divergence                46.085056
KL Loss                      4.6085057
QF Loss                      3910.9844
VF Loss                      42.814102
Policy Loss                  -1381.2572
Q Predictions Mean           1382.7504
Q Predictions Std            1407.891
Q Predictions Max            4843.4116
Q Predictions Min            647.6099
V Predictions Mean           1384.377
V Predictions Std            1404.5175
V Predictions Max            4831.5186
V Predictions Min            657.7469
Log Pis Mean                 -0.1464315
Log Pis Std                  3.9475276
Log Pis Max                  14.106213
Log Pis Min                  -5.8364105
Policy mu Mean               0.08666613
Policy mu Std                0.9066354
Policy mu Max                3.2150288
Policy mu Min                -2.4013157
Policy log std Mean          -0.53135294
Policy log std Std           0.29980657
Policy log std Max           0.001206398
Policy log std Min           -2.7232604
Z mean eval                  2.3960662
Z variance eval              0.040278483
total_rewards                [10798.48818967 10371.76442287 10980.23489242 10932.54440905
 10972.93896007 10807.13918082 10822.448022   10309.9045197
 10769.65809935 10875.73421762]
total_rewards_mean           10764.085491357127
total_rewards_std            223.1265919973277
total_rewards_max            10980.234892424305
total_rewards_min            10309.904519703048
Number of train steps total  1216000
Number of env steps total    3650000
Number of rollouts total     0
Train Time (s)               195.41398755507544
(Previous) Eval Time (s)     34.223607029765844
Sample Time (s)              6.649428981356323
Epoch Time (s)               236.2870235661976
Total Train Time (s)         70398.19802211458
Epoch                        303
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:10:01.673283 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #303 | Epoch Duration: 236.3764374256134
2020-01-13 19:10:01.673498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3946018
Z variance train             0.040133547
KL Divergence                46.1755
KL Loss                      4.61755
QF Loss                      3617.602
VF Loss                      104.41338
Policy Loss                  -1353.2157
Q Predictions Mean           1348.1306
Q Predictions Std            1357.982
Q Predictions Max            4837.2124
Q Predictions Min            640.1185
V Predictions Mean           1359.2202
V Predictions Std            1354.0677
V Predictions Max            4821.7837
V Predictions Min            654.20526
Log Pis Mean                 -0.2240564
Log Pis Std                  3.9389646
Log Pis Max                  12.262259
Log Pis Min                  -6.8120494
Policy mu Mean               0.022647528
Policy mu Std                0.881028
Policy mu Max                2.7380614
Policy mu Min                -2.7018824
Policy log std Mean          -0.52124184
Policy log std Std           0.31297532
Policy log std Max           0.0695833
Policy log std Min           -2.7730117
Z mean eval                  2.4127192
Z variance eval              0.06394164
total_rewards                [10538.87788002 10658.72743682 10464.59957496 10145.55656151
 10431.12069769 10519.74122019 10390.13850402 10434.57598115
 10534.11499116 10620.77959491]
total_rewards_mean           10473.823244243273
total_rewards_std            135.6364524329718
total_rewards_max            10658.727436816154
total_rewards_min            10145.556561510917
Number of train steps total  1220000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               195.39899925002828
(Previous) Eval Time (s)     34.023189950268716
Sample Time (s)              7.268469944130629
Epoch Time (s)               236.69065914442763
Total Train Time (s)         70634.97502430901
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:13:58.452938 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #304 | Epoch Duration: 236.77927327156067
2020-01-13 19:13:58.453139 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4146934
Z variance train             0.06413098
KL Divergence                46.325054
KL Loss                      4.6325054
QF Loss                      4242.838
VF Loss                      33.206055
Policy Loss                  -1277.4285
Q Predictions Mean           1277.2858
Q Predictions Std            1304.383
Q Predictions Max            4892.259
Q Predictions Min            673.458
V Predictions Mean           1276.81
V Predictions Std            1300.6567
V Predictions Max            4886.0
V Predictions Min            679.05035
Log Pis Mean                 -0.05133981
Log Pis Std                  3.9212756
Log Pis Max                  16.9655
Log Pis Min                  -6.7351327
Policy mu Mean               0.08834416
Policy mu Std                0.88594
Policy mu Max                2.7191303
Policy mu Min                -2.4852808
Policy log std Mean          -0.5318435
Policy log std Std           0.30787507
Policy log std Max           -0.033524543
Policy log std Min           -2.678611
Z mean eval                  2.4088974
Z variance eval              0.07145065
total_rewards                [10723.13962656  9901.60308831 10158.74898222 10886.88877058
 10683.69379246 10516.64314036 10138.33920124  9947.01305733
 10200.97175068 10007.06831283]
total_rewards_mean           10316.410972257829
total_rewards_std            337.63427868861976
total_rewards_max            10886.888770580166
total_rewards_min            9901.603088312075
Number of train steps total  1224000
Number of env steps total    3674000
Number of rollouts total     0
Train Time (s)               192.7641960438341
(Previous) Eval Time (s)     34.69524600589648
Sample Time (s)              5.871096114628017
Epoch Time (s)               233.3305381643586
Total Train Time (s)         70868.38827287406
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:17:51.869593 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #305 | Epoch Duration: 233.4162826538086
2020-01-13 19:17:51.869806 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4089217
Z variance train             0.071507946
KL Divergence                45.796513
KL Loss                      4.5796514
QF Loss                      137.91815
VF Loss                      61.143047
Policy Loss                  -1389.6963
Q Predictions Mean           1390.0103
Q Predictions Std            1400.3962
Q Predictions Max            4802.8716
Q Predictions Min            640.80646
V Predictions Mean           1392.5498
V Predictions Std            1396.5828
V Predictions Max            4778.674
V Predictions Min            639.81323
Log Pis Mean                 -0.086971514
Log Pis Std                  3.7436614
Log Pis Max                  13.245323
Log Pis Min                  -5.973599
Policy mu Mean               0.023295054
Policy mu Std                0.90001535
Policy mu Max                3.4818425
Policy mu Min                -2.7815633
Policy log std Mean          -0.51622725
Policy log std Std           0.3003291
Policy log std Max           0.017848939
Policy log std Min           -2.7119625
Z mean eval                  2.4022593
Z variance eval              0.04144948
total_rewards                [10388.88999222 10597.58017721 10166.01976409 10124.35022931
 10324.05546013 10454.73032142 10378.79937709 10391.99586277
 10462.49182201 10423.19710632]
total_rewards_mean           10371.211011256808
total_rewards_std            132.40947634323172
total_rewards_max            10597.580177213858
total_rewards_min            10124.350229306929
Number of train steps total  1228000
Number of env steps total    3686000
Number of rollouts total     0
Train Time (s)               195.44897924736142
(Previous) Eval Time (s)     35.21780483284965
Sample Time (s)              7.4936144961975515
Epoch Time (s)               238.16039857640862
Total Train Time (s)         71106.63933898276
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:21:50.126273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #306 | Epoch Duration: 238.25629568099976
2020-01-13 19:21:50.126498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4028788
Z variance train             0.041384537
KL Divergence                46.8548
KL Loss                      4.68548
QF Loss                      316.84192
VF Loss                      166.66272
Policy Loss                  -1279.224
Q Predictions Mean           1278.5344
Q Predictions Std            1282.3696
Q Predictions Max            4835.666
Q Predictions Min            643.13617
V Predictions Mean           1283.1467
V Predictions Std            1283.3103
V Predictions Max            4830.2734
V Predictions Min            653.2259
Log Pis Mean                 -0.42986476
Log Pis Std                  4.0333996
Log Pis Max                  14.549679
Log Pis Min                  -10.001263
Policy mu Mean               0.06395596
Policy mu Std                0.8610869
Policy mu Max                3.8158
Policy mu Min                -2.698272
Policy log std Mean          -0.50446844
Policy log std Std           0.3019109
Policy log std Max           0.12180129
Policy log std Min           -2.794992
Z mean eval                  2.3994904
Z variance eval              0.044519138
total_rewards                [10610.98908509 10586.00403456 10506.08988    10666.09702381
 10554.55829424 10404.67015534 10515.75153774 10325.90266236
 10414.72507029 10415.2550302 ]
total_rewards_mean           10500.00427736287
total_rewards_std            102.1843838133857
total_rewards_max            10666.097023806564
total_rewards_min            10325.902662362056
Number of train steps total  1232000
Number of env steps total    3698000
Number of rollouts total     0
Train Time (s)               194.99725483823568
(Previous) Eval Time (s)     29.967189732007682
Sample Time (s)              7.296636884100735
Epoch Time (s)               232.2610814543441
Total Train Time (s)         71338.97909207875
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:25:42.469636 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #307 | Epoch Duration: 232.34290480613708
2020-01-13 19:25:42.469931 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.399664
Z variance train             0.044538453
KL Divergence                44.317005
KL Loss                      4.4317007
QF Loss                      307.04843
VF Loss                      40.989437
Policy Loss                  -1441.1229
Q Predictions Mean           1439.6423
Q Predictions Std            1444.2887
Q Predictions Max            4853.7227
Q Predictions Min            644.82
V Predictions Mean           1442.2
V Predictions Std            1443.728
V Predictions Max            4828.711
V Predictions Min            653.85443
Log Pis Mean                 0.038834523
Log Pis Std                  3.681137
Log Pis Max                  10.898818
Log Pis Min                  -6.570462
Policy mu Mean               0.07510459
Policy mu Std                0.9174333
Policy mu Max                2.9241285
Policy mu Min                -2.7349393
Policy log std Mean          -0.5336566
Policy log std Std           0.31552008
Policy log std Max           -0.014269531
Policy log std Min           -2.7704887
Z mean eval                  2.4082992
Z variance eval              0.060774703
total_rewards                [10655.597794   10550.52339564 10728.20600692 10538.47944012
 10737.84611595 10422.76835933 10633.21000699 10500.93986113
 10739.18205509 10597.22075661]
total_rewards_mean           10610.397379177539
total_rewards_std            102.65833824046506
total_rewards_max            10739.182055086403
total_rewards_min            10422.768359329857
Number of train steps total  1236000
Number of env steps total    3710000
Number of rollouts total     0
Train Time (s)               194.38351696310565
(Previous) Eval Time (s)     32.06340020801872
Sample Time (s)              8.424116956535727
Epoch Time (s)               234.8710341276601
Total Train Time (s)         71573.93061156431
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:29:37.427801 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #308 | Epoch Duration: 234.95769715309143
2020-01-13 19:29:37.427989 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4109008
Z variance train             0.060886584
KL Divergence                44.70861
KL Loss                      4.470861
QF Loss                      3769.6665
VF Loss                      51.05725
Policy Loss                  -1348.4703
Q Predictions Mean           1348.7332
Q Predictions Std            1386.8477
Q Predictions Max            4874.9863
Q Predictions Min            652.1821
V Predictions Mean           1351.8785
V Predictions Std            1383.3553
V Predictions Max            4874.236
V Predictions Min            670.31134
Log Pis Mean                 -0.31212783
Log Pis Std                  3.907834
Log Pis Max                  14.093636
Log Pis Min                  -8.318434
Policy mu Mean               0.059065092
Policy mu Std                0.86470294
Policy mu Max                2.9090064
Policy mu Min                -3.1978755
Policy log std Mean          -0.4944028
Policy log std Std           0.30958432
Policy log std Max           -0.051510364
Policy log std Min           -3.1394985
Z mean eval                  2.4418907
Z variance eval              0.08324761
total_rewards                [8999.2921201  9664.03460409 9405.01183451 9881.15367528 9777.61001605
 9094.5690316  9686.24250422 9492.5912311  9791.23980217 9492.49969763]
total_rewards_mean           9528.424451673985
total_rewards_std            280.1600867097139
total_rewards_max            9881.153675281172
total_rewards_min            8999.292120097452
Number of train steps total  1240000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               195.16340704960749
(Previous) Eval Time (s)     35.124117098748684
Sample Time (s)              7.14417118113488
Epoch Time (s)               237.43169532949105
Total Train Time (s)         71811.4433714156
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:33:34.944660 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #309 | Epoch Duration: 237.51653456687927
2020-01-13 19:33:34.944842 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #309 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4391637
Z variance train             0.08280714
KL Divergence                45.835545
KL Loss                      4.5835547
QF Loss                      4013.5293
VF Loss                      110.029015
Policy Loss                  -1315.2336
Q Predictions Mean           1317.3242
Q Predictions Std            1365.8679
Q Predictions Max            4870.207
Q Predictions Min            649.4991
V Predictions Mean           1318.55
V Predictions Std            1363.177
V Predictions Max            4848.567
V Predictions Min            645.4341
Log Pis Mean                 -0.2597938
Log Pis Std                  3.8727188
Log Pis Max                  14.065474
Log Pis Min                  -6.6608124
Policy mu Mean               0.04483312
Policy mu Std                0.88255364
Policy mu Max                2.6485667
Policy mu Min                -2.3346186
Policy log std Mean          -0.5071867
Policy log std Std           0.28056973
Policy log std Max           -0.045570374
Policy log std Min           -2.6554399
Z mean eval                  2.4033551
Z variance eval              0.09275775
total_rewards                [10593.01209352 10252.3083006  10456.63091503 10545.66528986
 10335.97721599 10674.33361864 10198.46419851  8774.2260739
 10298.93222837 10706.47844591]
total_rewards_mean           10283.602838031997
total_rewards_std            530.5909980297542
total_rewards_max            10706.478445911884
total_rewards_min            8774.22607390251
Number of train steps total  1244000
Number of env steps total    3734000
Number of rollouts total     0
Train Time (s)               194.59901072224602
(Previous) Eval Time (s)     31.10088690230623
Sample Time (s)              7.038277624640614
Epoch Time (s)               232.73817524919286
Total Train Time (s)         72044.27029724931
Epoch                        310
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:37:27.779460 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #310 | Epoch Duration: 232.83434891700745
2020-01-13 19:37:27.779940 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.40392
Z variance train             0.09290863
KL Divergence                45.926037
KL Loss                      4.5926037
QF Loss                      98.73175
VF Loss                      40.32023
Policy Loss                  -1364.9772
Q Predictions Mean           1362.1394
Q Predictions Std            1395.8319
Q Predictions Max            4844.988
Q Predictions Min            629.7024
V Predictions Mean           1361.7427
V Predictions Std            1393.5414
V Predictions Max            4858.679
V Predictions Min            633.4179
Log Pis Mean                 -0.36865345
Log Pis Std                  3.3462298
Log Pis Max                  12.029579
Log Pis Min                  -6.2954445
Policy mu Mean               0.018699853
Policy mu Std                0.8779989
Policy mu Max                2.7736573
Policy mu Min                -2.9583323
Policy log std Mean          -0.507052
Policy log std Std           0.28923744
Policy log std Max           0.06725812
Policy log std Min           -2.8182082
Z mean eval                  2.4061627
Z variance eval              0.0616184
total_rewards                [ 9757.47993042  9429.61365677  9959.14883116 10007.03655086
  9996.04637799  9682.09988048  9465.99212843 10502.74775147
  9994.0246798   9710.27732186]
total_rewards_mean           9850.446710923507
total_rewards_std            297.52038473172644
total_rewards_max            10502.747751470471
total_rewards_min            9429.613656773872
Number of train steps total  1248000
Number of env steps total    3746000
Number of rollouts total     0
Train Time (s)               194.98584457393736
(Previous) Eval Time (s)     32.1784641277045
Sample Time (s)              6.375565779861063
Epoch Time (s)               233.53987448150292
Total Train Time (s)         72277.89324987773
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:41:21.403328 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #311 | Epoch Duration: 233.6230752468109
2020-01-13 19:41:21.403530 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4005485
Z variance train             0.061436325
KL Divergence                45.004673
KL Loss                      4.5004673
QF Loss                      139.28183
VF Loss                      50.25205
Policy Loss                  -1319.4244
Q Predictions Mean           1318.9082
Q Predictions Std            1353.3756
Q Predictions Max            4875.0806
Q Predictions Min            651.40607
V Predictions Mean           1323.5515
V Predictions Std            1353.728
V Predictions Max            4896.7026
V Predictions Min            651.0542
Log Pis Mean                 -0.54863036
Log Pis Std                  3.7237928
Log Pis Max                  16.18856
Log Pis Min                  -7.284562
Policy mu Mean               0.059651505
Policy mu Std                0.8594113
Policy mu Max                3.1925344
Policy mu Min                -2.6964023
Policy log std Mean          -0.51171273
Policy log std Std           0.26407388
Policy log std Max           -0.020860016
Policy log std Min           -2.5383968
Z mean eval                  2.4015014
Z variance eval              0.0518241
total_rewards                [10670.03037937 10350.67562572 10643.1293458  10266.07235083
 10944.33779618 10774.75217713 10903.60699715 10782.26697445
 10806.73151385 10927.77756797]
total_rewards_mean           10706.938072845314
total_rewards_std            221.53070929847559
total_rewards_max            10944.337796184167
total_rewards_min            10266.072350831677
Number of train steps total  1252000
Number of env steps total    3758000
Number of rollouts total     0
Train Time (s)               194.62056531896815
(Previous) Eval Time (s)     30.09127256460488
Sample Time (s)              5.976817732211202
Epoch Time (s)               230.68865561578423
Total Train Time (s)         72508.66999939596
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:45:12.185214 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #312 | Epoch Duration: 230.78152465820312
2020-01-13 19:45:12.185435 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4023385
Z variance train             0.05178042
KL Divergence                45.338818
KL Loss                      4.5338817
QF Loss                      7934.1895
VF Loss                      128.04117
Policy Loss                  -1352.6621
Q Predictions Mean           1347.9677
Q Predictions Std            1405.3971
Q Predictions Max            4856.376
Q Predictions Min            624.30884
V Predictions Mean           1355.6704
V Predictions Std            1418.0315
V Predictions Max            4883.2266
V Predictions Min            644.6202
Log Pis Mean                 -0.19875579
Log Pis Std                  4.1137075
Log Pis Max                  17.53542
Log Pis Min                  -6.1286345
Policy mu Mean               0.01594202
Policy mu Std                0.9169013
Policy mu Max                2.776809
Policy mu Min                -2.8597758
Policy log std Mean          -0.49266705
Policy log std Std           0.28059962
Policy log std Max           0.06562394
Policy log std Min           -2.6662629
Z mean eval                  2.3886228
Z variance eval              0.040915176
total_rewards                [10769.58880435 10004.20340249 10194.90669623 11008.77354972
 10409.53984324 10485.64709068 10345.09910666 10614.08748269
  7831.21440455  3268.01279503]
total_rewards_mean           9493.107317563088
total_rewards_std            2236.1026557991217
total_rewards_max            11008.773549715575
total_rewards_min            3268.0127950329584
Number of train steps total  1256000
Number of env steps total    3770000
Number of rollouts total     0
Train Time (s)               194.43714451324195
(Previous) Eval Time (s)     31.551424794830382
Sample Time (s)              7.922061747405678
Epoch Time (s)               233.910631055478
Total Train Time (s)         72742.66333998367
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:49:06.183974 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #313 | Epoch Duration: 233.99835753440857
2020-01-13 19:49:06.184184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3879285
Z variance train             0.040899046
KL Divergence                46.069355
KL Loss                      4.6069355
QF Loss                      187.00732
VF Loss                      142.19354
Policy Loss                  -1454.876
Q Predictions Mean           1454.5007
Q Predictions Std            1475.2231
Q Predictions Max            4897.6294
Q Predictions Min            657.23035
V Predictions Mean           1455.6226
V Predictions Std            1477.4038
V Predictions Max            4902.0664
V Predictions Min            657.94293
Log Pis Mean                 -0.009938765
Log Pis Std                  4.3902307
Log Pis Max                  18.212088
Log Pis Min                  -9.927866
Policy mu Mean               0.045763735
Policy mu Std                0.9102555
Policy mu Max                2.95586
Policy mu Min                -3.365641
Policy log std Mean          -0.5058314
Policy log std Std           0.30081233
Policy log std Max           -0.018477887
Policy log std Min           -2.655738
Z mean eval                  2.3853824
Z variance eval              0.04133529
total_rewards                [10760.01910953 10620.36802479 10646.03806639 10612.27701066
 10979.76177783 10700.064752   10631.87488682 10548.94157635
 10775.63511762 10742.15552881]
total_rewards_mean           10701.71358507992
total_rewards_std            115.6483847441465
total_rewards_max            10979.7617778281
total_rewards_min            10548.941576345374
Number of train steps total  1260000
Number of env steps total    3782000
Number of rollouts total     0
Train Time (s)               196.0739614381455
(Previous) Eval Time (s)     29.83288290211931
Sample Time (s)              7.564126763492823
Epoch Time (s)               233.47097110375762
Total Train Time (s)         72976.2139936043
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:52:59.739146 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #314 | Epoch Duration: 233.55480241775513
2020-01-13 19:52:59.739343 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3864858
Z variance train             0.04138024
KL Divergence                47.33725
KL Loss                      4.733725
QF Loss                      4614.7246
VF Loss                      36.97419
Policy Loss                  -1367.4368
Q Predictions Mean           1365.9719
Q Predictions Std            1406.3186
Q Predictions Max            4930.251
Q Predictions Min            649.72034
V Predictions Mean           1369.4844
V Predictions Std            1403.8
V Predictions Max            4930.1245
V Predictions Min            656.7022
Log Pis Mean                 -0.04931988
Log Pis Std                  3.9310515
Log Pis Max                  17.710089
Log Pis Min                  -7.5248475
Policy mu Mean               0.043529924
Policy mu Std                0.9090134
Policy mu Max                3.3325682
Policy mu Min                -3.1203468
Policy log std Mean          -0.52836937
Policy log std Std           0.3154858
Policy log std Max           -0.054444134
Policy log std Min           -2.6547792
Z mean eval                  2.4292014
Z variance eval              0.0594593
total_rewards                [3737.43116894 8078.08728186 8376.57430075 8540.94595209 8596.45666981
 8407.35474724 8393.83515448 8706.58593435 8481.17093694 8257.75334503]
total_rewards_mean           7957.619549148922
total_rewards_std            1416.5483006949758
total_rewards_max            8706.585934348364
total_rewards_min            3737.4311689432557
Number of train steps total  1264000
Number of env steps total    3794000
Number of rollouts total     0
Train Time (s)               195.5599912079051
(Previous) Eval Time (s)     31.10902765020728
Sample Time (s)              6.236369743011892
Epoch Time (s)               232.9053886011243
Total Train Time (s)         73209.21580912033
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:56:52.744719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #315 | Epoch Duration: 233.00522685050964
2020-01-13 19:56:52.744911 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4264646
Z variance train             0.05935616
KL Divergence                47.633785
KL Loss                      4.7633786
QF Loss                      196.03033
VF Loss                      78.08535
Policy Loss                  -1387.1532
Q Predictions Mean           1384.548
Q Predictions Std            1422.63
Q Predictions Max            4967.002
Q Predictions Min            650.5606
V Predictions Mean           1384.0603
V Predictions Std            1415.1409
V Predictions Max            4967.8716
V Predictions Min            665.62744
Log Pis Mean                 -0.13117391
Log Pis Std                  4.269812
Log Pis Max                  15.196686
Log Pis Min                  -6.969751
Policy mu Mean               0.13387366
Policy mu Std                0.9101498
Policy mu Max                3.5134351
Policy mu Min                -2.5300584
Policy log std Mean          -0.49913272
Policy log std Std           0.28054217
Policy log std Max           -0.08062196
Policy log std Min           -2.9184427
Z mean eval                  2.4229684
Z variance eval              0.04987396
total_rewards                [10579.14598331 10349.21723919 11032.85881953 10367.72606371
 10585.70331729 10714.64237217 10874.11044898 10933.67033989
 10760.74936715 10922.64300809]
total_rewards_mean           10712.046695931109
total_rewards_std            225.5789825922986
total_rewards_max            11032.858819534307
total_rewards_min            10349.217239193436
Number of train steps total  1268000
Number of env steps total    3806000
Number of rollouts total     0
Train Time (s)               193.98897266574204
(Previous) Eval Time (s)     32.0263691698201
Sample Time (s)              7.656999646220356
Epoch Time (s)               233.6723414817825
Total Train Time (s)         73442.97031759564
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:00:46.505020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #316 | Epoch Duration: 233.7599537372589
2020-01-13 20:00:46.505242 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #316 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4224222
Z variance train             0.049936652
KL Divergence                47.24714
KL Loss                      4.724714
QF Loss                      139.06009
VF Loss                      65.91399
Policy Loss                  -1384.2301
Q Predictions Mean           1380.1702
Q Predictions Std            1402.1266
Q Predictions Max            4908.5464
Q Predictions Min            654.6165
V Predictions Mean           1385.756
V Predictions Std            1402.0205
V Predictions Max            4903.346
V Predictions Min            664.0519
Log Pis Mean                 -0.070361674
Log Pis Std                  4.1898236
Log Pis Max                  17.575085
Log Pis Min                  -8.465435
Policy mu Mean               -0.0019722346
Policy mu Std                0.9179806
Policy mu Max                2.9983888
Policy mu Min                -3.5624108
Policy log std Mean          -0.5133183
Policy log std Std           0.30243972
Policy log std Max           0.032516032
Policy log std Min           -2.6147115
Z mean eval                  2.4260433
Z variance eval              0.040167596
total_rewards                [10414.16181357 10750.41980929 10678.31631592 10362.78646813
 10532.92332525 10529.63827734 10491.36793216 10710.0990117
 10596.08219659 10717.80340253]
total_rewards_mean           10578.359855247769
total_rewards_std            127.33752731865297
total_rewards_max            10750.419809285615
total_rewards_min            10362.786468130633
Number of train steps total  1272000
Number of env steps total    3818000
Number of rollouts total     0
Train Time (s)               194.18283637892455
(Previous) Eval Time (s)     36.74135251296684
Sample Time (s)              7.613693830091506
Epoch Time (s)               238.5378827219829
Total Train Time (s)         73681.59215701884
Epoch                        317
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:04:45.128400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #317 | Epoch Duration: 238.6230058670044
2020-01-13 20:04:45.128574 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4288173
Z variance train             0.040205896
KL Divergence                46.551655
KL Loss                      4.6551657
QF Loss                      197.7376
VF Loss                      66.0681
Policy Loss                  -1245.9773
Q Predictions Mean           1242.0916
Q Predictions Std            1251.7484
Q Predictions Max            4804.421
Q Predictions Min            655.0368
V Predictions Mean           1246.8093
V Predictions Std            1252.0436
V Predictions Max            4804.6436
V Predictions Min            658.3425
Log Pis Mean                 -0.4022916
Log Pis Std                  3.9161448
Log Pis Max                  15.207786
Log Pis Min                  -11.114741
Policy mu Mean               0.08508217
Policy mu Std                0.8664966
Policy mu Max                2.712414
Policy mu Min                -2.9542458
Policy log std Mean          -0.50319767
Policy log std Std           0.27401292
Policy log std Max           0.015128136
Policy log std Min           -2.6724672
Z mean eval                  2.4135995
Z variance eval              0.041307785
total_rewards                [10003.32651054  2154.66121468 10524.8813698  10234.13026146
 10417.52257648  7381.56209871 10341.04660888 10277.04644162
 10175.38805203 10483.59999662]
total_rewards_mean           9199.31651308193
total_rewards_std            2509.122720834878
total_rewards_max            10524.881369804338
total_rewards_min            2154.6612146832117
Number of train steps total  1276000
Number of env steps total    3830000
Number of rollouts total     0
Train Time (s)               193.29529526364058
(Previous) Eval Time (s)     35.51557572837919
Sample Time (s)              6.771355875767767
Epoch Time (s)               235.58222686778754
Total Train Time (s)         73917.27304511797
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:08:40.814717 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #318 | Epoch Duration: 235.6859803199768
2020-01-13 20:08:40.814960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4146924
Z variance train             0.041419644
KL Divergence                45.677345
KL Loss                      4.5677347
QF Loss                      133.98099
VF Loss                      74.14043
Policy Loss                  -1320.2067
Q Predictions Mean           1314.5298
Q Predictions Std            1269.3334
Q Predictions Max            4926.2183
Q Predictions Min            672.39764
V Predictions Mean           1316.8785
V Predictions Std            1267.1027
V Predictions Max            4932.9263
V Predictions Min            662.9466
Log Pis Mean                 -0.48774433
Log Pis Std                  3.7913845
Log Pis Max                  18.587593
Log Pis Min                  -8.150667
Policy mu Mean               0.027868113
Policy mu Std                0.89352095
Policy mu Max                2.972081
Policy mu Min                -3.3249805
Policy log std Mean          -0.49756494
Policy log std Std           0.28320485
Policy log std Max           0.047026813
Policy log std Min           -2.6154609
Z mean eval                  2.4027424
Z variance eval              0.039369576
total_rewards                [10747.95937491 10421.22632706 10895.76265523 10809.13908141
 10274.08561729 10874.71415068  6145.44705404 10859.70373825
 10710.81768173 10846.05890974]
total_rewards_mean           10258.491459032308
total_rewards_std            1385.055502352071
total_rewards_max            10895.762655231822
total_rewards_min            6145.447054036575
Number of train steps total  1280000
Number of env steps total    3842000
Number of rollouts total     0
Train Time (s)               194.01407701522112
(Previous) Eval Time (s)     32.46113857906312
Sample Time (s)              7.5566189689561725
Epoch Time (s)               234.0318345632404
Total Train Time (s)         74151.38527975325
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:12:34.931535 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #319 | Epoch Duration: 234.11642050743103
2020-01-13 20:12:34.931730 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4069333
Z variance train             0.039421026
KL Divergence                44.46294
KL Loss                      4.4462943
QF Loss                      192.095
VF Loss                      70.58194
Policy Loss                  -1591.9071
Q Predictions Mean           1588.0879
Q Predictions Std            1558.1664
Q Predictions Max            4919.69
Q Predictions Min            651.62085
V Predictions Mean           1588.8555
V Predictions Std            1556.2468
V Predictions Max            4900.075
V Predictions Min            659.29877
Log Pis Mean                 0.5240584
Log Pis Std                  4.5369434
Log Pis Max                  20.73207
Log Pis Min                  -6.8321123
Policy mu Mean               0.02563333
Policy mu Std                0.9834272
Policy mu Max                3.166212
Policy mu Min                -3.8408024
Policy log std Mean          -0.5440941
Policy log std Std           0.31089842
Policy log std Max           0.23053849
Policy log std Min           -2.7283573
Z mean eval                  2.41995
Z variance eval              0.0380824
total_rewards                [10535.32015504 10396.42434309 10647.64122352 10538.19229044
 10871.74594423 10749.86167065 10598.45145115 10476.61141058
 10553.19585014 10770.29784159]
total_rewards_mean           10613.774218042623
total_rewards_std            138.75972851558575
total_rewards_max            10871.745944233997
total_rewards_min            10396.424343094903
Number of train steps total  1284000
Number of env steps total    3854000
Number of rollouts total     0
Train Time (s)               191.31583637092263
(Previous) Eval Time (s)     30.29431178793311
Sample Time (s)              6.4332739203237
Epoch Time (s)               228.04342207917944
Total Train Time (s)         74379.51706543751
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:16:23.066415 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #320 | Epoch Duration: 228.13453197479248
2020-01-13 20:16:23.066606 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.419468
Z variance train             0.038119476
KL Divergence                44.662937
KL Loss                      4.466294
QF Loss                      4572.216
VF Loss                      96.52641
Policy Loss                  -1398.2996
Q Predictions Mean           1397.0187
Q Predictions Std            1395.4443
Q Predictions Max            4833.256
Q Predictions Min            657.27985
V Predictions Mean           1397.8966
V Predictions Std            1395.5691
V Predictions Max            4827.678
V Predictions Min            668.7814
Log Pis Mean                 -0.13729377
Log Pis Std                  4.0786138
Log Pis Max                  14.43732
Log Pis Min                  -6.9593277
Policy mu Mean               0.031215815
Policy mu Std                0.87915945
Policy mu Max                2.602459
Policy mu Min                -2.8948164
Policy log std Mean          -0.53228873
Policy log std Std           0.3157877
Policy log std Max           0.09493649
Policy log std Min           -2.8907337
Z mean eval                  2.4193587
Z variance eval              0.034243934
total_rewards                [10550.36966279 10738.16674321 10763.58764235 10597.49874879
 11120.46139291 10891.50066164 10484.1116731  10956.25691537
 10944.19124114  7495.94356348]
total_rewards_mean           10454.208824476442
total_rewards_std            1004.2711529526697
total_rewards_max            11120.461392907007
total_rewards_min            7495.943563484535
Number of train steps total  1288000
Number of env steps total    3866000
Number of rollouts total     0
Train Time (s)               195.99913998693228
(Previous) Eval Time (s)     35.526123667135835
Sample Time (s)              7.670836196281016
Epoch Time (s)               239.19609985034913
Total Train Time (s)         74618.79958023317
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:20:22.357053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #321 | Epoch Duration: 239.290301322937
2020-01-13 20:20:22.357251 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #321 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.421105
Z variance train             0.034213603
KL Divergence                46.47033
KL Loss                      4.647033
QF Loss                      444.3576
VF Loss                      101.6152
Policy Loss                  -1280.1952
Q Predictions Mean           1279.0416
Q Predictions Std            1285.0837
Q Predictions Max            5020.6157
Q Predictions Min            660.75073
V Predictions Mean           1278.7362
V Predictions Std            1280.0557
V Predictions Max            4975.1006
V Predictions Min            670.1207
Log Pis Mean                 -0.18938856
Log Pis Std                  3.8347576
Log Pis Max                  18.841711
Log Pis Min                  -6.228875
Policy mu Mean               0.058318283
Policy mu Std                0.8729413
Policy mu Max                3.3672638
Policy mu Min                -2.9220293
Policy log std Mean          -0.5094132
Policy log std Std           0.26490307
Policy log std Max           0.034922928
Policy log std Min           -2.8493109
Z mean eval                  2.426768
Z variance eval              0.033752013
total_rewards                [10382.10213116 10784.60425709 10812.79752343 10919.50909689
 11028.90643545 10419.74062985 11028.29034285 11028.4526367
 10740.50995002 10778.22259161]
total_rewards_mean           10792.313559503531
total_rewards_std            222.27163540389625
total_rewards_max            11028.906435450912
total_rewards_min            10382.102131159392
Number of train steps total  1292000
Number of env steps total    3878000
Number of rollouts total     0
Train Time (s)               194.7094220132567
(Previous) Eval Time (s)     31.994573013391346
Sample Time (s)              7.0314438813366
Epoch Time (s)               233.73543890798464
Total Train Time (s)         74852.62557456922
Epoch                        322
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:24:16.185534 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #322 | Epoch Duration: 233.8281352519989
2020-01-13 20:24:16.185719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.427713
Z variance train             0.03369792
KL Divergence                46.793583
KL Loss                      4.6793585
QF Loss                      227.30066
VF Loss                      49.218243
Policy Loss                  -1221.8059
Q Predictions Mean           1219.9717
Q Predictions Std            1266.0955
Q Predictions Max            4968.671
Q Predictions Min            666.16064
V Predictions Mean           1224.8918
V Predictions Std            1263.587
V Predictions Max            4965.004
V Predictions Min            669.61194
Log Pis Mean                 -0.7882273
Log Pis Std                  3.6609755
Log Pis Max                  12.195055
Log Pis Min                  -6.7907047
Policy mu Mean               0.103993654
Policy mu Std                0.8186301
Policy mu Max                2.8078685
Policy mu Min                -2.5344067
Policy log std Mean          -0.50202876
Policy log std Std           0.2744416
Policy log std Max           -0.06193304
Policy log std Min           -2.7196794
Z mean eval                  2.4042473
Z variance eval              0.06322556
total_rewards                [10794.04981772 10904.22747775 10806.54382628 10796.05982878
 10639.31142197 10581.21769351 10867.40315599 10688.27309229
 10797.48868729 10827.58976232]
total_rewards_mean           10770.216476391372
total_rewards_std            96.72985132609195
total_rewards_max            10904.227477754146
total_rewards_min            10581.2176935142
Number of train steps total  1296000
Number of env steps total    3890000
Number of rollouts total     0
Train Time (s)               194.9944659359753
(Previous) Eval Time (s)     31.818283390253782
Sample Time (s)              6.43819895433262
Epoch Time (s)               233.25094828056172
Total Train Time (s)         75085.969003201
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:28:09.532014 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #323 | Epoch Duration: 233.34615421295166
2020-01-13 20:28:09.532185 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #323 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4070168
Z variance train             0.06348861
KL Divergence                44.99997
KL Loss                      4.499997
QF Loss                      98.00804
VF Loss                      123.64885
Policy Loss                  -1340.5933
Q Predictions Mean           1339.5481
Q Predictions Std            1338.2113
Q Predictions Max            4979.5767
Q Predictions Min            656.4386
V Predictions Mean           1335.2441
V Predictions Std            1331.5011
V Predictions Max            4939.2544
V Predictions Min            662.0716
Log Pis Mean                 -0.50441706
Log Pis Std                  3.5838165
Log Pis Max                  12.215001
Log Pis Min                  -6.0790977
Policy mu Mean               0.028956706
Policy mu Std                0.86172813
Policy mu Max                2.6281395
Policy mu Min                -2.458462
Policy log std Mean          -0.5020855
Policy log std Std           0.29663387
Policy log std Max           -0.008353919
Policy log std Min           -2.6765203
Z mean eval                  2.4236026
Z variance eval              0.059813123
total_rewards                [10560.80955143 10427.21042157 10453.73664961 10205.38315745
  9663.73004929  9413.53258411 10081.77353632 10309.6897114
  9776.21613917 10063.59030269]
total_rewards_mean           10095.567210303048
total_rewards_std            356.0173380870175
total_rewards_max            10560.809551427797
total_rewards_min            9413.532584111523
Number of train steps total  1300000
Number of env steps total    3902000
Number of rollouts total     0
Train Time (s)               195.6119078239426
(Previous) Eval Time (s)     32.66895738011226
Sample Time (s)              6.469939874950796
Epoch Time (s)               234.75080507900566
Total Train Time (s)         75320.80477529019
Epoch                        324
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:32:04.371951 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #324 | Epoch Duration: 234.83963227272034
2020-01-13 20:32:04.372144 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.423011
Z variance train             0.060150098
KL Divergence                45.71414
KL Loss                      4.5714145
QF Loss                      119.273834
VF Loss                      164.22566
Policy Loss                  -1382.2633
Q Predictions Mean           1381.0254
Q Predictions Std            1400.458
Q Predictions Max            4855.522
Q Predictions Min            664.2578
V Predictions Mean           1384.524
V Predictions Std            1400.1056
V Predictions Max            4853.9995
V Predictions Min            668.01154
Log Pis Mean                 -0.061957985
Log Pis Std                  3.7627058
Log Pis Max                  13.753656
Log Pis Min                  -7.1052036
Policy mu Mean               0.054898515
Policy mu Std                0.88010454
Policy mu Max                2.843034
Policy mu Min                -2.3364127
Policy log std Mean          -0.51515174
Policy log std Std           0.28855562
Policy log std Max           -0.05946523
Policy log std Min           -2.6481144
Z mean eval                  2.4102306
Z variance eval              0.07283042
total_rewards                [11113.30405159 10890.51172127 11133.13828413 10882.21910571
 11042.09216727 11144.87478133 10999.76145185 11232.90632019
 10865.94478746 10929.4268349 ]
total_rewards_mean           11023.417950570418
total_rewards_std            122.84008478467999
total_rewards_max            11232.906320191803
total_rewards_min            10865.944787459513
Number of train steps total  1304000
Number of env steps total    3914000
Number of rollouts total     0
Train Time (s)               195.62653127778322
(Previous) Eval Time (s)     30.744665462058038
Sample Time (s)              6.992190984077752
Epoch Time (s)               233.363387723919
Total Train Time (s)         75554.2537830011
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:35:57.823516 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #325 | Epoch Duration: 233.4512324333191
2020-01-13 20:35:57.823722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #325 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.411124
Z variance train             0.07259436
KL Divergence                46.175793
KL Loss                      4.6175795
QF Loss                      4449.8467
VF Loss                      42.948494
Policy Loss                  -1352.3048
Q Predictions Mean           1348.9456
Q Predictions Std            1334.2367
Q Predictions Max            4916.399
Q Predictions Min            661.4226
V Predictions Mean           1352.0872
V Predictions Std            1335.1394
V Predictions Max            4914.8813
V Predictions Min            662.4543
Log Pis Mean                 -0.10619269
Log Pis Std                  3.9276562
Log Pis Max                  13.059669
Log Pis Min                  -6.187525
Policy mu Mean               0.028012464
Policy mu Std                0.8837679
Policy mu Max                2.680942
Policy mu Min                -3.2605028
Policy log std Mean          -0.50316995
Policy log std Std           0.29382375
Policy log std Max           -0.076335564
Policy log std Min           -2.7983859
Z mean eval                  2.4127924
Z variance eval              0.041886054
total_rewards                [10939.05384782 10822.94682937 10625.00155963 10971.7156345
 11021.22241622 10759.27054215 11089.92237924 10781.74284933
 10868.57201105 10847.57624844]
total_rewards_mean           10872.702431775639
total_rewards_std            130.02652914026584
total_rewards_max            11089.922379240634
total_rewards_min            10625.00155962866
Number of train steps total  1308000
Number of env steps total    3926000
Number of rollouts total     0
Train Time (s)               193.52318623568863
(Previous) Eval Time (s)     30.888553269207478
Sample Time (s)              7.065524697303772
Epoch Time (s)               231.47726420219988
Total Train Time (s)         75785.84339418495
Epoch                        326
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:39:49.417561 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #326 | Epoch Duration: 231.59362721443176
2020-01-13 20:39:49.417863 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.41184
Z variance train             0.041841466
KL Divergence                45.653984
KL Loss                      4.5653987
QF Loss                      121.90523
VF Loss                      31.814959
Policy Loss                  -1254.8198
Q Predictions Mean           1250.4419
Q Predictions Std            1255.0334
Q Predictions Max            4862.033
Q Predictions Min            662.6924
V Predictions Mean           1254.3071
V Predictions Std            1253.0942
V Predictions Max            4814.5293
V Predictions Min            668.7394
Log Pis Mean                 -0.39550614
Log Pis Std                  3.895672
Log Pis Max                  18.115211
Log Pis Min                  -6.664733
Policy mu Mean               0.017713234
Policy mu Std                0.8587939
Policy mu Max                2.9460099
Policy mu Min                -2.8799107
Policy log std Mean          -0.5110499
Policy log std Std           0.30170327
Policy log std Max           0.16822916
Policy log std Min           -3.2354445
Z mean eval                  2.4775362
Z variance eval              0.054683257
total_rewards                [10409.3785579  10495.99307249 10572.25743203 10500.29916031
 10664.35118276 10573.92780565 10393.36588513  9128.71333387
 10619.48871719 10398.7714152 ]
total_rewards_mean           10375.654656254195
total_rewards_std            425.1624688161127
total_rewards_max            10664.351182762268
total_rewards_min            9128.713333871749
Number of train steps total  1312000
Number of env steps total    3938000
Number of rollouts total     0
Train Time (s)               194.78836202109233
(Previous) Eval Time (s)     30.002450444269925
Sample Time (s)              7.314004945103079
Epoch Time (s)               232.10481741046533
Total Train Time (s)         76018.03241708549
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:43:41.611436 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #327 | Epoch Duration: 232.19337153434753
2020-01-13 20:43:41.611687 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4794374
Z variance train             0.054684233
KL Divergence                45.170704
KL Loss                      4.5170703
QF Loss                      122.587006
VF Loss                      65.22826
Policy Loss                  -1457.5906
Q Predictions Mean           1455.3574
Q Predictions Std            1451.1504
Q Predictions Max            5037.0576
Q Predictions Min            672.78296
V Predictions Mean           1459.031
V Predictions Std            1445.9495
V Predictions Max            5036.675
V Predictions Min            688.5392
Log Pis Mean                 0.019067511
Log Pis Std                  4.3044353
Log Pis Max                  16.975063
Log Pis Min                  -9.929651
Policy mu Mean               0.06668768
Policy mu Std                0.93363947
Policy mu Max                3.277773
Policy mu Min                -2.8056831
Policy log std Mean          -0.502763
Policy log std Std           0.29351023
Policy log std Max           -0.024832964
Policy log std Min           -2.720397
Z mean eval                  2.4611409
Z variance eval              0.05237187
total_rewards                [10680.48458298 10701.92196285 10940.15850822 10747.56649104
 10877.01219081 10611.68630607 11032.72509277 10178.52874391
 11172.21679587 10923.48568787]
total_rewards_mean           10786.578636239265
total_rewards_std            260.78152936049344
total_rewards_max            11172.216795867724
total_rewards_min            10178.528743908355
Number of train steps total  1316000
Number of env steps total    3950000
Number of rollouts total     0
Train Time (s)               197.09222677582875
(Previous) Eval Time (s)     34.64889180799946
Sample Time (s)              6.958779541309923
Epoch Time (s)               238.69989812513813
Total Train Time (s)         76256.82466481347
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:47:40.409268 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #328 | Epoch Duration: 238.79738306999207
2020-01-13 20:47:40.409498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #328 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4603868
Z variance train             0.052290507
KL Divergence                44.97851
KL Loss                      4.4978514
QF Loss                      150.64201
VF Loss                      56.155857
Policy Loss                  -1353.5734
Q Predictions Mean           1352.4813
Q Predictions Std            1379.9843
Q Predictions Max            5097.3496
Q Predictions Min            665.6223
V Predictions Mean           1352.6532
V Predictions Std            1375.0731
V Predictions Max            5062.7134
V Predictions Min            679.4399
Log Pis Mean                 -0.4861954
Log Pis Std                  3.9563506
Log Pis Max                  13.758665
Log Pis Min                  -6.320446
Policy mu Mean               0.05833177
Policy mu Std                0.8427793
Policy mu Max                3.147088
Policy mu Min                -3.0681312
Policy log std Mean          -0.47891364
Policy log std Std           0.28308547
Policy log std Max           0.024656653
Policy log std Min           -2.7756696
Z mean eval                  2.4401283
Z variance eval              0.026857639
total_rewards                [10975.59976505 11170.69836929 10935.75676133 11140.5451993
 10946.00943172 11106.88927469 11112.19632159 10643.53409661
 11200.165661   10411.91361278]
total_rewards_mean           10964.33084933623
total_rewards_std            240.99765817449298
total_rewards_max            11200.165661001947
total_rewards_min            10411.913612777611
Number of train steps total  1320000
Number of env steps total    3962000
Number of rollouts total     0
Train Time (s)               196.75952222011983
(Previous) Eval Time (s)     33.80124487215653
Sample Time (s)              7.248041565995663
Epoch Time (s)               237.80880865827203
Total Train Time (s)         76494.74913619133
Epoch                        329
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:51:38.338124 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #329 | Epoch Duration: 237.92843794822693
2020-01-13 20:51:38.338376 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #329 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4408278
Z variance train             0.026849214
KL Divergence                45.970905
KL Loss                      4.5970907
QF Loss                      253.54619
VF Loss                      120.57509
Policy Loss                  -1210.3828
Q Predictions Mean           1208.084
Q Predictions Std            1188.5377
Q Predictions Max            4884.524
Q Predictions Min            665.58673
V Predictions Mean           1202.9016
V Predictions Std            1184.1589
V Predictions Max            4871.6304
V Predictions Min            659.6536
Log Pis Mean                 -0.6599778
Log Pis Std                  3.5429716
Log Pis Max                  20.690844
Log Pis Min                  -6.9910755
Policy mu Mean               0.05337627
Policy mu Std                0.825786
Policy mu Max                3.0738275
Policy mu Min                -3.186248
Policy log std Mean          -0.47830334
Policy log std Std           0.273153
Policy log std Max           -0.03522563
Policy log std Min           -2.6272497
Z mean eval                  2.4221778
Z variance eval              0.064999804
total_rewards                [10416.62901914 10516.82916118 10224.73517879 10229.15170687
 10329.16086288 10530.1603832  10425.9482958  10583.04890395
 10449.96151213 10300.36362496]
total_rewards_mean           10400.598864889474
total_rewards_std            119.32835854419139
total_rewards_max            10583.048903954757
total_rewards_min            10224.735178788871
Number of train steps total  1324000
Number of env steps total    3974000
Number of rollouts total     0
Train Time (s)               197.21803197078407
(Previous) Eval Time (s)     36.92148448666558
Sample Time (s)              7.747968208510429
Epoch Time (s)               241.88748466596007
Total Train Time (s)         76736.7252803701
Epoch                        330
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:55:40.321085 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #330 | Epoch Duration: 241.98247933387756
2020-01-13 20:55:40.321331 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #330 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4220653
Z variance train             0.06522964
KL Divergence                43.78976
KL Loss                      4.3789763
QF Loss                      389.87527
VF Loss                      228.89188
Policy Loss                  -1422.2979
Q Predictions Mean           1421.15
Q Predictions Std            1427.1029
Q Predictions Max            5042.3784
Q Predictions Min            674.8782
V Predictions Mean           1425.9438
V Predictions Std            1431.7755
V Predictions Max            5058.465
V Predictions Min            676.6168
Log Pis Mean                 -0.239161
Log Pis Std                  3.847969
Log Pis Max                  15.079346
Log Pis Min                  -6.2556243
Policy mu Mean               0.040637463
Policy mu Std                0.87087303
Policy mu Max                3.359698
Policy mu Min                -3.1555886
Policy log std Mean          -0.49258423
Policy log std Std           0.30132023
Policy log std Max           0.15852916
Policy log std Min           -2.7036972
Z mean eval                  2.4667428
Z variance eval              0.036442146
total_rewards                [10935.72233552 10750.78750706 10921.70848878 10952.1613985
 10324.42877933 10809.10067817 10743.58575635 11072.96227342
 10606.1859102  11004.14148711]
total_rewards_mean           10812.078461444227
total_rewards_std            209.88782789472583
total_rewards_max            11072.962273423862
total_rewards_min            10324.42877932742
Number of train steps total  1328000
Number of env steps total    3986000
Number of rollouts total     0
Train Time (s)               192.75330900400877
(Previous) Eval Time (s)     34.77103376900777
Sample Time (s)              7.133295267820358
Epoch Time (s)               234.6576380408369
Total Train Time (s)         76971.48588136258
Epoch                        331
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:59:35.083203 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #331 | Epoch Duration: 234.76174092292786
2020-01-13 20:59:35.083336 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4681156
Z variance train             0.036265627
KL Divergence                46.93357
KL Loss                      4.693357
QF Loss                      90.98975
VF Loss                      48.504837
Policy Loss                  -1293.3364
Q Predictions Mean           1289.0156
Q Predictions Std            1289.1072
Q Predictions Max            5070.454
Q Predictions Min            675.9821
V Predictions Mean           1289.2648
V Predictions Std            1286.1616
V Predictions Max            5082.016
V Predictions Min            682.1517
Log Pis Mean                 -0.32368177
Log Pis Std                  3.7653692
Log Pis Max                  13.169896
Log Pis Min                  -6.817522
Policy mu Mean               0.007371407
Policy mu Std                0.8645598
Policy mu Max                2.7564743
Policy mu Min                -2.9103808
Policy log std Mean          -0.48718274
Policy log std Std           0.27585775
Policy log std Max           0.2748896
Policy log std Min           -2.5142431
Z mean eval                  2.4663591
Z variance eval              0.0377573
total_rewards                [10463.14583743 10979.22833981 11108.37182263 11106.36966409
 10945.39284977 11009.13547582 11097.37483782 11169.55722151
 11139.05390933 10954.24944468]
total_rewards_mean           10997.187940287888
total_rewards_std            193.48119947680502
total_rewards_max            11169.557221508232
total_rewards_min            10463.145837428307
Number of train steps total  1332000
Number of env steps total    3998000
Number of rollouts total     0
Train Time (s)               192.5943522900343
(Previous) Eval Time (s)     34.84697544993833
Sample Time (s)              7.790513786487281
Epoch Time (s)               235.2318415264599
Total Train Time (s)         77206.80691534374
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:03:30.417697 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #332 | Epoch Duration: 235.33425188064575
2020-01-13 21:03:30.417875 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #332 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4670513
Z variance train             0.03781739
KL Divergence                46.958942
KL Loss                      4.6958942
QF Loss                      4194.8457
VF Loss                      48.408512
Policy Loss                  -1463.7278
Q Predictions Mean           1462.4243
Q Predictions Std            1429.0631
Q Predictions Max            4945.3936
Q Predictions Min            672.8724
V Predictions Mean           1466.7866
V Predictions Std            1429.3364
V Predictions Max            4931.3633
V Predictions Min            691.26105
Log Pis Mean                 0.05184883
Log Pis Std                  4.2664843
Log Pis Max                  15.786655
Log Pis Min                  -8.359369
Policy mu Mean               0.01640326
Policy mu Std                0.91803414
Policy mu Max                3.4570527
Policy mu Min                -3.153574
Policy log std Mean          -0.5224061
Policy log std Std           0.300048
Policy log std Max           0.04938802
Policy log std Min           -2.6913242
Z mean eval                  2.4275079
Z variance eval              0.041118983
total_rewards                [10441.25049589  9882.32558057 10411.29190287 10343.6036992
 10354.9710658  10321.92407928 10179.87711404 10495.84111703
 10250.15147774 10851.16461376]
total_rewards_mean           10353.240114618411
total_rewards_std            233.0018747195416
total_rewards_max            10851.164613759445
total_rewards_min            9882.325580571598
Number of train steps total  1336000
Number of env steps total    4010000
Number of rollouts total     0
Train Time (s)               193.40081342495978
(Previous) Eval Time (s)     29.913648007903248
Sample Time (s)              7.620495366398245
Epoch Time (s)               230.93495679926127
Total Train Time (s)         77437.82516114647
Epoch                        333
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:07:21.470777 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #333 | Epoch Duration: 231.05275082588196
2020-01-13 21:07:21.470998 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #333 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4282928
Z variance train             0.04114745
KL Divergence                46.430294
KL Loss                      4.6430297
QF Loss                      191.26129
VF Loss                      156.2073
Policy Loss                  -1483.247
Q Predictions Mean           1480.6481
Q Predictions Std            1456.8656
Q Predictions Max            4934.3296
Q Predictions Min            665.8145
V Predictions Mean           1480.5647
V Predictions Std            1458.2498
V Predictions Max            4947.832
V Predictions Min            662.5871
Log Pis Mean                 -0.50193936
Log Pis Std                  4.0446258
Log Pis Max                  16.562061
Log Pis Min                  -7.6665144
Policy mu Mean               0.056403548
Policy mu Std                0.8696649
Policy mu Max                3.1868796
Policy mu Min                -3.0445466
Policy log std Mean          -0.50280565
Policy log std Std           0.30731174
Policy log std Max           -0.008490026
Policy log std Min           -2.7523117
Z mean eval                  2.472886
Z variance eval              0.078067966
total_rewards                [11156.47493017 11068.57429223 10699.14298621 11205.02231331
 10594.38958067 10899.03894909 11315.18137118 10959.51000018
 10912.80722583 11042.57789518]
total_rewards_mean           10985.271954405307
total_rewards_std            210.87292753405552
total_rewards_max            11315.181371175584
total_rewards_min            10594.389580673715
Number of train steps total  1340000
Number of env steps total    4022000
Number of rollouts total     0
Train Time (s)               190.4175387499854
(Previous) Eval Time (s)     30.759611323010176
Sample Time (s)              7.317178763914853
Epoch Time (s)               228.49432883691043
Total Train Time (s)         77666.41260318365
Epoch                        334
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:11:10.064853 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #334 | Epoch Duration: 228.59367537498474
2020-01-13 21:11:10.065103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4731402
Z variance train             0.07817519
KL Divergence                47.051167
KL Loss                      4.7051167
QF Loss                      93.210686
VF Loss                      96.01495
Policy Loss                  -1374.4973
Q Predictions Mean           1368.0791
Q Predictions Std            1336.3965
Q Predictions Max            4948.0283
Q Predictions Min            666.9951
V Predictions Mean           1373.9807
V Predictions Std            1338.4243
V Predictions Max            4940.3643
V Predictions Min            672.9344
Log Pis Mean                 0.21504468
Log Pis Std                  4.214318
Log Pis Max                  16.364676
Log Pis Min                  -7.147862
Policy mu Mean               0.03807503
Policy mu Std                0.9303354
Policy mu Max                3.5803945
Policy mu Min                -3.9343548
Policy log std Mean          -0.5259942
Policy log std Std           0.30656788
Policy log std Max           -0.013032317
Policy log std Min           -2.5879786
Z mean eval                  2.447929
Z variance eval              0.062905535
total_rewards                [10914.16206489 10682.36873552 10783.31197912 10967.73464953
 10911.78963    10612.0630044  10754.47736464 10341.34682159
 10742.59601216 11009.85635998]
total_rewards_mean           10771.970662182524
total_rewards_std            188.4182183549161
total_rewards_max            11009.85635997584
total_rewards_min            10341.346821588166
Number of train steps total  1344000
Number of env steps total    4034000
Number of rollouts total     0
Train Time (s)               194.00120020005852
(Previous) Eval Time (s)     32.39938425319269
Sample Time (s)              6.314122032374144
Epoch Time (s)               232.71470648562536
Total Train Time (s)         77899.22659018403
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:15:02.882244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #335 | Epoch Duration: 232.81694149971008
2020-01-13 21:15:02.882442 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.449468
Z variance train             0.063001834
KL Divergence                46.531628
KL Loss                      4.653163
QF Loss                      4385.8257
VF Loss                      61.667236
Policy Loss                  -1407.9803
Q Predictions Mean           1405.951
Q Predictions Std            1402.0518
Q Predictions Max            4957.7393
Q Predictions Min            660.3933
V Predictions Mean           1403.6797
V Predictions Std            1398.8708
V Predictions Max            4965.32
V Predictions Min            663.276
Log Pis Mean                 -0.32660088
Log Pis Std                  3.9410183
Log Pis Max                  16.414654
Log Pis Min                  -6.9436703
Policy mu Mean               0.0037030305
Policy mu Std                0.89439195
Policy mu Max                2.8873224
Policy mu Min                -3.2520235
Policy log std Mean          -0.49430394
Policy log std Std           0.3021137
Policy log std Max           -0.03317958
Policy log std Min           -2.679089
Z mean eval                  2.4436285
Z variance eval              0.045863066
total_rewards                [10473.4053584  10735.87987294 10361.52519884 10571.98610324
 10079.03750104 10666.84684229  6471.50571208 10879.12461378
 10455.29665221 10840.08144655]
total_rewards_mean           10153.468930136714
total_rewards_std            1248.0011542355342
total_rewards_max            10879.12461378171
total_rewards_min            6471.50571207739
Number of train steps total  1348000
Number of env steps total    4046000
Number of rollouts total     0
Train Time (s)               195.05912702018395
(Previous) Eval Time (s)     31.97162770293653
Sample Time (s)              7.787524885032326
Epoch Time (s)               234.8182796081528
Total Train Time (s)         78134.13760060351
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:18:57.796284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #336 | Epoch Duration: 234.91369462013245
2020-01-13 21:18:57.796468 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4464054
Z variance train             0.04564179
KL Divergence                46.588127
KL Loss                      4.658813
QF Loss                      624.772
VF Loss                      150.62953
Policy Loss                  -1575.8358
Q Predictions Mean           1570.1641
Q Predictions Std            1550.3971
Q Predictions Max            4990.349
Q Predictions Min            657.74316
V Predictions Mean           1568.6017
V Predictions Std            1544.2102
V Predictions Max            4959.1445
V Predictions Min            658.7422
Log Pis Mean                 0.06710894
Log Pis Std                  4.4405437
Log Pis Max                  14.59207
Log Pis Min                  -6.1094146
Policy mu Mean               0.03398956
Policy mu Std                0.9248529
Policy mu Max                3.0369089
Policy mu Min                -3.0575733
Policy log std Mean          -0.5153756
Policy log std Std           0.32094693
Policy log std Max           0.05604118
Policy log std Min           -2.871346
Z mean eval                  2.4814324
Z variance eval              0.093843415
total_rewards                [10754.45034229 10370.6057879  10921.26529034 10749.29821236
 10230.91820187 10601.094156   10474.20743927 10544.12367396
 10631.8644586  10051.60104284]
total_rewards_mean           10532.942860542888
total_rewards_std            247.7774443342602
total_rewards_max            10921.265290336154
total_rewards_min            10051.601042841237
Number of train steps total  1352000
Number of env steps total    4058000
Number of rollouts total     0
Train Time (s)               194.64729589922354
(Previous) Eval Time (s)     33.23187120165676
Sample Time (s)              7.13517843419686
Epoch Time (s)               235.01434553507715
Total Train Time (s)         78369.4036528687
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:22:53.065751 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #337 | Epoch Duration: 235.2691400051117
2020-01-13 21:22:53.065947 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #337 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4811764
Z variance train             0.09429637
KL Divergence                46.07553
KL Loss                      4.607553
QF Loss                      213.09204
VF Loss                      94.59537
Policy Loss                  -1535.048
Q Predictions Mean           1531.8928
Q Predictions Std            1512.7292
Q Predictions Max            4976.8975
Q Predictions Min            681.5082
V Predictions Mean           1533.783
V Predictions Std            1516.7412
V Predictions Max            5007.1436
V Predictions Min            678.9076
Log Pis Mean                 0.23855501
Log Pis Std                  4.254621
Log Pis Max                  17.891169
Log Pis Min                  -5.810548
Policy mu Mean               0.08486842
Policy mu Std                0.93550557
Policy mu Max                2.7821133
Policy mu Min                -3.4170952
Policy log std Mean          -0.50987786
Policy log std Std           0.3105067
Policy log std Max           0.16573572
Policy log std Min           -2.6879168
Z mean eval                  2.4811804
Z variance eval              0.05659633
total_rewards                [10937.57590435 11085.58961115 10611.78754493 11066.42972939
 10865.45607182 11002.11028362 10900.83525559 10771.144431
 11116.56234604 11166.76197554]
total_rewards_mean           10952.425315342862
total_rewards_std            162.91778269249315
total_rewards_max            11166.761975538737
total_rewards_min            10611.787544930567
Number of train steps total  1356000
Number of env steps total    4070000
Number of rollouts total     0
Train Time (s)               195.42406752798706
(Previous) Eval Time (s)     31.064252555835992
Sample Time (s)              7.070120326709002
Epoch Time (s)               233.55844041053206
Total Train Time (s)         78603.07351126336
Epoch                        338
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:26:46.738863 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #338 | Epoch Duration: 233.6727786064148
2020-01-13 21:26:46.739033 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #338 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4779077
Z variance train             0.056484155
KL Divergence                47.83535
KL Loss                      4.783535
QF Loss                      287.77744
VF Loss                      124.80025
Policy Loss                  -1363.8105
Q Predictions Mean           1360.4596
Q Predictions Std            1333.4976
Q Predictions Max            5012.7476
Q Predictions Min            677.9794
V Predictions Mean           1368.2046
V Predictions Std            1332.4956
V Predictions Max            5029.311
V Predictions Min            682.2536
Log Pis Mean                 -0.06764683
Log Pis Std                  4.272974
Log Pis Max                  16.462917
Log Pis Min                  -8.257257
Policy mu Mean               0.043725464
Policy mu Std                0.9349561
Policy mu Max                3.052231
Policy mu Min                -3.2410684
Policy log std Mean          -0.49291024
Policy log std Std           0.2677346
Policy log std Max           -0.015764356
Policy log std Min           -2.4529796
Z mean eval                  2.4644477
Z variance eval              0.05292468
total_rewards                [11290.99015355 10876.63677058 11412.43947198 10744.21468305
 10985.31195292 10786.80250034 10910.10013515 11120.31120519
 10807.25089753 11103.12045908]
total_rewards_mean           11003.717822934788
total_rewards_std            212.43815809338204
total_rewards_max            11412.439471976046
total_rewards_min            10744.214683045122
Number of train steps total  1360000
Number of env steps total    4082000
Number of rollouts total     0
Train Time (s)               194.55953165702522
(Previous) Eval Time (s)     32.46053404826671
Sample Time (s)              7.761398306116462
Epoch Time (s)               234.7814640114084
Total Train Time (s)         78837.95792406099
Epoch                        339
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:30:41.628969 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #339 | Epoch Duration: 234.88980197906494
2020-01-13 21:30:41.629142 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4687476
Z variance train             0.052828632
KL Divergence                48.307045
KL Loss                      4.8307047
QF Loss                      196.21252
VF Loss                      123.63564
Policy Loss                  -1385.5925
Q Predictions Mean           1380.729
Q Predictions Std            1393.2507
Q Predictions Max            5063.2554
Q Predictions Min            669.2722
V Predictions Mean           1379.0603
V Predictions Std            1386.5278
V Predictions Max            5024.3047
V Predictions Min            679.5051
Log Pis Mean                 -0.083146825
Log Pis Std                  3.7717624
Log Pis Max                  14.7230215
Log Pis Min                  -5.9133945
Policy mu Mean               0.060079228
Policy mu Std                0.9164319
Policy mu Max                2.6266847
Policy mu Min                -2.598606
Policy log std Mean          -0.5026459
Policy log std Std           0.29906604
Policy log std Max           -0.0399217
Policy log std Min           -2.7144175
Z mean eval                  2.4508991
Z variance eval              0.065492615
total_rewards                [ 7625.69102793 10861.53514829 10902.4176962  11093.04464053
 10836.24599391 10995.66891516  8538.39925367 11175.05413785
 10926.61564224 10767.91918546]
total_rewards_mean           10372.259164123447
total_rewards_std            1168.7142799595774
total_rewards_max            11175.054137854177
total_rewards_min            7625.691027928583
Number of train steps total  1364000
Number of env steps total    4094000
Number of rollouts total     0
Train Time (s)               195.19086342304945
(Previous) Eval Time (s)     31.993010530713946
Sample Time (s)              7.788272910285741
Epoch Time (s)               234.97214686404914
Total Train Time (s)         79073.01629009424
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:34:36.691012 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #340 | Epoch Duration: 235.06173181533813
2020-01-13 21:34:36.691186 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4526794
Z variance train             0.0655471
KL Divergence                48.504894
KL Loss                      4.8504896
QF Loss                      189.72667
VF Loss                      70.22526
Policy Loss                  -1420.3921
Q Predictions Mean           1415.9612
Q Predictions Std            1396.5751
Q Predictions Max            5005.9873
Q Predictions Min            671.0428
V Predictions Mean           1419.947
V Predictions Std            1397.2375
V Predictions Max            4987.4727
V Predictions Min            675.6319
Log Pis Mean                 -0.036750704
Log Pis Std                  4.3619533
Log Pis Max                  20.272842
Log Pis Min                  -8.22651
Policy mu Mean               0.031868234
Policy mu Std                0.9283657
Policy mu Max                3.1551046
Policy mu Min                -2.9341652
Policy log std Mean          -0.5461657
Policy log std Std           0.31224692
Policy log std Max           -0.071804464
Policy log std Min           -2.6606274
Z mean eval                  2.457365
Z variance eval              0.074083015
total_rewards                [ 3501.93828729 11045.28706282 10980.6860514  10337.22104132
  8904.3610501  10668.97114815 11123.35733657 10757.14475717
 11104.50376684 10571.39732942]
total_rewards_mean           9899.486783107275
total_rewards_std            2220.8429848571805
total_rewards_max            11123.357336570878
total_rewards_min            3501.938287287527
Number of train steps total  1368000
Number of env steps total    4106000
Number of rollouts total     0
Train Time (s)               195.7167044878006
(Previous) Eval Time (s)     35.224400461651385
Sample Time (s)              7.090787030290812
Epoch Time (s)               238.0318919797428
Total Train Time (s)         79311.12976960791
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:38:34.808987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #341 | Epoch Duration: 238.11767745018005
2020-01-13 21:38:34.809122 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4565854
Z variance train             0.0740325
KL Divergence                47.07492
KL Loss                      4.7074924
QF Loss                      4090.0654
VF Loss                      70.72829
Policy Loss                  -1418.7769
Q Predictions Mean           1416.5125
Q Predictions Std            1405.1583
Q Predictions Max            4918.1074
Q Predictions Min            665.4826
V Predictions Mean           1420.9746
V Predictions Std            1400.3254
V Predictions Max            4873.5415
V Predictions Min            663.93207
Log Pis Mean                 -0.2709995
Log Pis Std                  3.998094
Log Pis Max                  14.10392
Log Pis Min                  -8.400255
Policy mu Mean               0.065724574
Policy mu Std                0.8782945
Policy mu Max                2.7095103
Policy mu Min                -2.5969424
Policy log std Mean          -0.5125703
Policy log std Std           0.2917735
Policy log std Max           0.022289157
Policy log std Min           -2.532001
Z mean eval                  2.4584508
Z variance eval              0.044300895
total_rewards                [10889.28199611 11083.30964544 10870.27338653 10795.74308255
 10870.62679096 11223.06982509 10875.47136773 10762.07186825
 11004.16586754 11109.7284811 ]
total_rewards_mean           10948.374231129248
total_rewards_std            142.0454505058492
total_rewards_max            11223.069825087281
total_rewards_min            10762.071868249574
Number of train steps total  1372000
Number of env steps total    4118000
Number of rollouts total     0
Train Time (s)               194.1544154328294
(Previous) Eval Time (s)     31.482524702325463
Sample Time (s)              6.873796623200178
Epoch Time (s)               232.51073675835505
Total Train Time (s)         79543.72802383266
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:42:27.412154 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #342 | Epoch Duration: 232.60291600227356
2020-01-13 21:42:27.412349 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4607074
Z variance train             0.04450826
KL Divergence                48.809864
KL Loss                      4.8809867
QF Loss                      120.345474
VF Loss                      73.22136
Policy Loss                  -1267.1268
Q Predictions Mean           1261.2965
Q Predictions Std            1282.293
Q Predictions Max            5021.7856
Q Predictions Min            679.66846
V Predictions Mean           1266.1223
V Predictions Std            1283.7244
V Predictions Max            5015.6147
V Predictions Min            685.86896
Log Pis Mean                 -0.35102457
Log Pis Std                  3.639679
Log Pis Max                  15.391172
Log Pis Min                  -7.986047
Policy mu Mean               0.08291057
Policy mu Std                0.852858
Policy mu Max                2.5907876
Policy mu Min                -2.9153533
Policy log std Mean          -0.5048384
Policy log std Std           0.28233504
Policy log std Max           -0.057077944
Policy log std Min           -2.407324
Z mean eval                  2.4647312
Z variance eval              0.044769328
total_rewards                [11286.58147326  1343.4461046  11519.96961241 11141.17527654
 11102.40155983 11026.78886801 10986.33820445 11266.42666694
 11536.2863674  11174.52152749]
total_rewards_mean           10238.393566093517
total_rewards_std            2970.209617152608
total_rewards_max            11536.286367403905
total_rewards_min            1343.4461046010085
Number of train steps total  1376000
Number of env steps total    4130000
Number of rollouts total     0
Train Time (s)               196.9211352514103
(Previous) Eval Time (s)     32.78411092283204
Sample Time (s)              8.084046957548708
Epoch Time (s)               237.78929313179106
Total Train Time (s)         79781.5976864039
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:46:25.287265 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #343 | Epoch Duration: 237.8746919631958
2020-01-13 21:46:25.287586 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #343 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4706244
Z variance train             0.04473578
KL Divergence                49.721035
KL Loss                      4.9721036
QF Loss                      108.62981
VF Loss                      57.049927
Policy Loss                  -1416.6978
Q Predictions Mean           1412.9894
Q Predictions Std            1396.0334
Q Predictions Max            4965.4097
Q Predictions Min            692.01855
V Predictions Mean           1414.3335
V Predictions Std            1391.3167
V Predictions Max            4952.717
V Predictions Min            698.8896
Log Pis Mean                 -0.13668066
Log Pis Std                  4.2022495
Log Pis Max                  17.341259
Log Pis Min                  -7.177146
Policy mu Mean               0.030877387
Policy mu Std                0.92120284
Policy mu Max                2.8815758
Policy mu Min                -3.1397958
Policy log std Mean          -0.5035999
Policy log std Std           0.2842821
Policy log std Max           -0.02099657
Policy log std Min           -2.4233532
Z mean eval                  2.486566
Z variance eval              0.037893113
total_rewards                [11023.07126369 10854.15085554 10692.51865362 10924.25958641
 11034.77367927 10912.46568022 11045.88261209  6528.26373983
 10719.85199084  5577.68801723]
total_rewards_mean           9931.292607874095
total_rewards_std            1954.1771350355973
total_rewards_max            11045.88261209497
total_rewards_min            5577.688017231038
Number of train steps total  1380000
Number of env steps total    4142000
Number of rollouts total     0
Train Time (s)               195.51320699881762
(Previous) Eval Time (s)     29.90735433390364
Sample Time (s)              7.813330134842545
Epoch Time (s)               233.2338914675638
Total Train Time (s)         80014.911831968
Epoch                        344
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:50:18.603449 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #344 | Epoch Duration: 233.3156726360321
2020-01-13 21:50:18.603596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #344 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.488255
Z variance train             0.037953414
KL Divergence                51.01347
KL Loss                      5.101347
QF Loss                      301.76764
VF Loss                      78.089836
Policy Loss                  -1417.6431
Q Predictions Mean           1413.1962
Q Predictions Std            1379.5405
Q Predictions Max            4953.535
Q Predictions Min            690.8581
V Predictions Mean           1420.0479
V Predictions Std            1376.7053
V Predictions Max            4949.091
V Predictions Min            695.9119
Log Pis Mean                 -0.14439237
Log Pis Std                  3.8876219
Log Pis Max                  14.865033
Log Pis Min                  -5.9497395
Policy mu Mean               0.06192005
Policy mu Std                0.9028046
Policy mu Max                2.844285
Policy mu Min                -3.5266416
Policy log std Mean          -0.5126686
Policy log std Std           0.2991287
Policy log std Max           -0.031593025
Policy log std Min           -2.6549325
Z mean eval                  2.4556646
Z variance eval              0.06321678
total_rewards                [11124.05635272 10958.55250089 11135.71003126 10789.89171865
 10982.74971822 10767.39945322 10901.88021081 11168.1631185
 11327.06134796 10774.08855088]
total_rewards_mean           10992.955300310883
total_rewards_std            181.51758057620938
total_rewards_max            11327.061347963157
total_rewards_min            10767.399453223195
Number of train steps total  1384000
Number of env steps total    4154000
Number of rollouts total     0
Train Time (s)               195.53454547002912
(Previous) Eval Time (s)     31.360218598041683
Sample Time (s)              7.805866779759526
Epoch Time (s)               234.70063084783033
Total Train Time (s)         80249.70040460164
Epoch                        345
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:54:13.395806 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #345 | Epoch Duration: 234.79208302497864
2020-01-13 21:54:13.396029 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.456079
Z variance train             0.06366069
KL Divergence                49.847878
KL Loss                      4.984788
QF Loss                      179.87793
VF Loss                      60.31225
Policy Loss                  -1406.2327
Q Predictions Mean           1402.3401
Q Predictions Std            1403.8217
Q Predictions Max            4945.418
Q Predictions Min            692.00714
V Predictions Mean           1401.4628
V Predictions Std            1399.3165
V Predictions Max            4910.1284
V Predictions Min            696.5832
Log Pis Mean                 0.3490873
Log Pis Std                  3.9887457
Log Pis Max                  15.141067
Log Pis Min                  -5.556837
Policy mu Mean               0.014561005
Policy mu Std                0.94168514
Policy mu Max                2.6903841
Policy mu Min                -3.242729
Policy log std Mean          -0.52320045
Policy log std Std           0.3001948
Policy log std Max           -0.02269119
Policy log std Min           -3.093834
Z mean eval                  2.5004487
Z variance eval              0.04093984
total_rewards                [10817.8797989  10798.19086712  4943.99816162 11087.71799612
 11279.74968127 11076.50649494 10921.30064598 11044.67471132
 10729.6867288  11192.99816497]
total_rewards_mean           10389.270325105948
total_rewards_std            1822.8949545002467
total_rewards_max            11279.749681265992
total_rewards_min            4943.998161623276
Number of train steps total  1388000
Number of env steps total    4166000
Number of rollouts total     0
Train Time (s)               195.5124804941006
(Previous) Eval Time (s)     30.308044083882123
Sample Time (s)              6.447049124166369
Epoch Time (s)               232.2675737021491
Total Train Time (s)         80482.05113834515
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:58:05.749993 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #346 | Epoch Duration: 232.3537995815277
2020-01-13 21:58:05.750184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.500388
Z variance train             0.040909767
KL Divergence                50.6762
KL Loss                      5.0676203
QF Loss                      134.52316
VF Loss                      49.00753
Policy Loss                  -1412.3898
Q Predictions Mean           1409.6814
Q Predictions Std            1418.1246
Q Predictions Max            5107.2456
Q Predictions Min            688.6706
V Predictions Mean           1407.8237
V Predictions Std            1416.7317
V Predictions Max            5120.4365
V Predictions Min            682.15204
Log Pis Mean                 -0.24072874
Log Pis Std                  4.0964017
Log Pis Max                  22.099857
Log Pis Min                  -6.0696635
Policy mu Mean               0.061975192
Policy mu Std                0.9037615
Policy mu Max                2.9619846
Policy mu Min                -2.7384534
Policy log std Mean          -0.5015859
Policy log std Std           0.28746292
Policy log std Max           0.036780417
Policy log std Min           -2.8829389
Z mean eval                  2.4839995
Z variance eval              0.02888752
total_rewards                [11406.27270759 11250.43628713 10842.15886562 11404.14491938
 10761.09032818 11223.3351431  11309.11584009 11143.37167527
 11128.51463872 11232.75502176]
total_rewards_mean           11170.119542684757
total_rewards_std            205.02964863627656
total_rewards_max            11406.27270759329
total_rewards_min            10761.090328176828
Number of train steps total  1392000
Number of env steps total    4178000
Number of rollouts total     0
Train Time (s)               197.52629900211468
(Previous) Eval Time (s)     30.96162050170824
Sample Time (s)              6.78498575463891
Epoch Time (s)               235.27290525846183
Total Train Time (s)         80717.40398380859
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:02:01.106958 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #347 | Epoch Duration: 235.35661625862122
2020-01-13 22:02:01.107145 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.483857
Z variance train             0.028837701
KL Divergence                48.439236
KL Loss                      4.8439236
QF Loss                      135.833
VF Loss                      61.720116
Policy Loss                  -1528.6201
Q Predictions Mean           1528.8726
Q Predictions Std            1513.9598
Q Predictions Max            5101.694
Q Predictions Min            682.1677
V Predictions Mean           1525.6399
V Predictions Std            1513.7916
V Predictions Max            5102.5625
V Predictions Min            684.68744
Log Pis Mean                 0.26716572
Log Pis Std                  4.422917
Log Pis Max                  14.275427
Log Pis Min                  -10.116563
Policy mu Mean               0.045122117
Policy mu Std                0.94399554
Policy mu Max                2.8579922
Policy mu Min                -2.9529321
Policy log std Mean          -0.53381604
Policy log std Std           0.32676417
Policy log std Max           0.17220658
Policy log std Min           -3.251729
Z mean eval                  2.4565046
Z variance eval              0.050311305
total_rewards                [10804.79123488 10392.32024658 10264.50064212 10168.59966065
 10625.86842625 10530.32502582 10448.74276197 10522.66892305
 10503.36362384 10632.84890433]
total_rewards_mean           10489.4029449472
total_rewards_std            174.9913085460894
total_rewards_max            10804.791234876819
total_rewards_min            10168.599660651154
Number of train steps total  1396000
Number of env steps total    4190000
Number of rollouts total     0
Train Time (s)               194.5721671129577
(Previous) Eval Time (s)     32.359154583886266
Sample Time (s)              6.942866340279579
Epoch Time (s)               233.87418803712353
Total Train Time (s)         80951.36540832277
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:05:55.071637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #348 | Epoch Duration: 233.9643087387085
2020-01-13 22:05:55.071887 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4567528
Z variance train             0.05032722
KL Divergence                47.236633
KL Loss                      4.7236633
QF Loss                      425.86414
VF Loss                      46.99463
Policy Loss                  -1323.413
Q Predictions Mean           1319.3564
Q Predictions Std            1339.4469
Q Predictions Max            5020.609
Q Predictions Min            682.722
V Predictions Mean           1325.6608
V Predictions Std            1339.1523
V Predictions Max            5011.0034
V Predictions Min            697.37537
Log Pis Mean                 -0.31379977
Log Pis Std                  4.209502
Log Pis Max                  22.04744
Log Pis Min                  -5.84646
Policy mu Mean               0.046214387
Policy mu Std                0.869001
Policy mu Max                3.128111
Policy mu Min                -3.240459
Policy log std Mean          -0.50967586
Policy log std Std           0.2921513
Policy log std Max           -0.040234327
Policy log std Min           -3.035213
Z mean eval                  2.4947162
Z variance eval              0.037131906
total_rewards                [10930.73859426 10637.93427968 10762.63218767  2996.64271795
  5926.45216103 10463.30205743 10721.1013988  10405.26507535
 10916.88623289 10920.28471982]
total_rewards_mean           9468.123942487959
total_rewards_std            2593.3223146243167
total_rewards_max            10930.738594262493
total_rewards_min            2996.6427179486086
Number of train steps total  1400000
Number of env steps total    4202000
Number of rollouts total     0
Train Time (s)               191.60631950199604
(Previous) Eval Time (s)     35.963789850939065
Sample Time (s)              6.2831699857488275
Epoch Time (s)               233.85327933868393
Total Train Time (s)         81185.3106330526
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:09:49.019099 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #349 | Epoch Duration: 233.94703340530396
2020-01-13 22:09:49.019301 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4984195
Z variance train             0.037346445
KL Divergence                49.138737
KL Loss                      4.9138737
QF Loss                      576.81824
VF Loss                      271.98798
Policy Loss                  -1465.8423
Q Predictions Mean           1458.6107
Q Predictions Std            1477.0188
Q Predictions Max            5054.3037
Q Predictions Min            681.1749
V Predictions Mean           1457.3855
V Predictions Std            1471.9229
V Predictions Max            5025.3423
V Predictions Min            673.3969
Log Pis Mean                 0.123569205
Log Pis Std                  4.253622
Log Pis Max                  14.883662
Log Pis Min                  -7.814088
Policy mu Mean               0.064765744
Policy mu Std                0.94078374
Policy mu Max                3.3316295
Policy mu Min                -2.6015773
Policy log std Mean          -0.5321306
Policy log std Std           0.31947994
Policy log std Max           0.058144033
Policy log std Min           -2.8729827
Z mean eval                  2.5029743
Z variance eval              0.0569767
total_rewards                [10465.10932874 10805.33754941 10494.97459155 10707.78139251
 10315.55689715 10265.60715075 10661.52217384 10755.53742825
 10994.3501016  10551.02119793]
total_rewards_mean           10601.679781172697
total_rewards_std            214.84696932255542
total_rewards_max            10994.350101602371
total_rewards_min            10265.607150747202
Number of train steps total  1404000
Number of env steps total    4214000
Number of rollouts total     0
Train Time (s)               197.08051095390692
(Previous) Eval Time (s)     35.60961683373898
Sample Time (s)              7.138472511898726
Epoch Time (s)               239.82860029954463
Total Train Time (s)         81425.25193283288
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:13:48.968222 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #350 | Epoch Duration: 239.9487202167511
2020-01-13 22:13:48.968595 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5034134
Z variance train             0.056965835
KL Divergence                49.846085
KL Loss                      4.9846087
QF Loss                      127.00348
VF Loss                      83.76105
Policy Loss                  -1407.3757
Q Predictions Mean           1403.7648
Q Predictions Std            1393.4457
Q Predictions Max            5113.2583
Q Predictions Min            694.5756
V Predictions Mean           1409.8474
V Predictions Std            1389.2605
V Predictions Max            5102.93
V Predictions Min            703.6407
Log Pis Mean                 0.0031002015
Log Pis Std                  4.1522245
Log Pis Max                  17.023544
Log Pis Min                  -9.117216
Policy mu Mean               -0.027860165
Policy mu Std                0.9343585
Policy mu Max                3.3391414
Policy mu Min                -3.4256237
Policy log std Mean          -0.51457924
Policy log std Std           0.29382512
Policy log std Max           -0.0046817064
Policy log std Min           -2.7507553
Z mean eval                  2.4700058
Z variance eval              0.045959093
total_rewards                [11151.81508604 10806.2868127  10967.49478393 10933.95580753
 10602.51132645 11316.8360627   8838.53584016 10801.91888043
 11167.32289116 10729.46183437]
total_rewards_mean           10731.613932545903
total_rewards_std            664.5610476927766
total_rewards_max            11316.836062702438
total_rewards_min            8838.535840155026
Number of train steps total  1408000
Number of env steps total    4226000
Number of rollouts total     0
Train Time (s)               193.85996234091
(Previous) Eval Time (s)     30.587614357937127
Sample Time (s)              5.933787210378796
Epoch Time (s)               230.3813639092259
Total Train Time (s)         81655.71790341428
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:17:39.438382 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #351 | Epoch Duration: 230.4695074558258
2020-01-13 22:17:39.438557 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.468804
Z variance train             0.046025652
KL Divergence                47.595726
KL Loss                      4.7595725
QF Loss                      345.72208
VF Loss                      200.42279
Policy Loss                  -1465.6055
Q Predictions Mean           1461.9858
Q Predictions Std            1478.8342
Q Predictions Max            5005.2363
Q Predictions Min            682.7838
V Predictions Mean           1459.3058
V Predictions Std            1464.7028
V Predictions Max            4950.707
V Predictions Min            689.3816
Log Pis Mean                 -0.23296726
Log Pis Std                  4.1200376
Log Pis Max                  13.133473
Log Pis Min                  -7.783007
Policy mu Mean               0.062528275
Policy mu Std                0.89273435
Policy mu Max                2.7737095
Policy mu Min                -2.6228876
Policy log std Mean          -0.514368
Policy log std Std           0.3002796
Policy log std Max           0.19222891
Policy log std Min           -2.8373208
Z mean eval                  2.4896786
Z variance eval              0.043588985
total_rewards                [11153.86319659 10688.3838182  11360.73568755 11449.97211614
  7097.99715574 10868.65900402 10881.12970972 10849.23239829
 10736.46684555 10932.34485821]
total_rewards_mean           10601.87847900106
total_rewards_std            1192.566175353509
total_rewards_max            11449.972116142035
total_rewards_min            7097.997155737803
Number of train steps total  1412000
Number of env steps total    4238000
Number of rollouts total     0
Train Time (s)               194.54671459412202
(Previous) Eval Time (s)     30.848549081012607
Sample Time (s)              7.52712903637439
Epoch Time (s)               232.92239271150902
Total Train Time (s)         81888.71845144825
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:21:32.442537 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #352 | Epoch Duration: 233.00383234024048
2020-01-13 22:21:32.442733 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.489859
Z variance train             0.043583285
KL Divergence                48.626637
KL Loss                      4.8626637
QF Loss                      186.91696
VF Loss                      126.582405
Policy Loss                  -1615.7759
Q Predictions Mean           1615.9387
Q Predictions Std            1556.1803
Q Predictions Max            5013.497
Q Predictions Min            695.6995
V Predictions Mean           1620.6289
V Predictions Std            1553.0833
V Predictions Max            5016.6606
V Predictions Min            704.1846
Log Pis Mean                 -0.08031195
Log Pis Std                  3.8828282
Log Pis Max                  11.5266
Log Pis Min                  -6.8667436
Policy mu Mean               0.008637948
Policy mu Std                0.894441
Policy mu Max                2.732579
Policy mu Min                -2.4058974
Policy log std Mean          -0.53389746
Policy log std Std           0.30414367
Policy log std Max           -0.10343316
Policy log std Min           -2.5441794
Z mean eval                  2.4569447
Z variance eval              0.11667299
total_rewards                [10614.20413661 10362.58806387 10460.66230299 10081.29048269
 10181.96110497  9543.5569604  10119.29893064 10487.65158411
  9840.58701132 10493.18792318]
total_rewards_mean           10218.498850078422
total_rewards_std            318.15883982642504
total_rewards_max            10614.204136613536
total_rewards_min            9543.556960402704
Number of train steps total  1416000
Number of env steps total    4250000
Number of rollouts total     0
Train Time (s)               195.03386238310486
(Previous) Eval Time (s)     33.58389376336709
Sample Time (s)              6.996943786740303
Epoch Time (s)               235.61469993321225
Total Train Time (s)         82124.41797075002
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:25:28.146380 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #353 | Epoch Duration: 235.70350337028503
2020-01-13 22:25:28.146568 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4583673
Z variance train             0.1166203
KL Divergence                44.654736
KL Loss                      4.4654737
QF Loss                      252.93402
VF Loss                      118.741035
Policy Loss                  -1374.2407
Q Predictions Mean           1371.2363
Q Predictions Std            1353.9291
Q Predictions Max            5101.291
Q Predictions Min            701.0746
V Predictions Mean           1370.3264
V Predictions Std            1350.9645
V Predictions Max            5098.4824
V Predictions Min            710.79425
Log Pis Mean                 -0.26485616
Log Pis Std                  4.429592
Log Pis Max                  23.02427
Log Pis Min                  -9.092686
Policy mu Mean               0.07925301
Policy mu Std                0.9097251
Policy mu Max                4.1559305
Policy mu Min                -2.7886345
Policy log std Mean          -0.48779908
Policy log std Std           0.2643372
Policy log std Max           0.0018337369
Policy log std Min           -2.6518884
Z mean eval                  2.4613671
Z variance eval              0.05710081
total_rewards                [10860.43542607 10840.74172911 10876.84655908 11013.18890792
 10956.06341692 10867.04751659 10878.46749958 11070.17790807
 10855.91428662 11059.39156149]
total_rewards_mean           10927.827481145752
total_rewards_std            84.6660402186112
total_rewards_max            11070.177908074602
total_rewards_min            10840.741729106363
Number of train steps total  1420000
Number of env steps total    4262000
Number of rollouts total     0
Train Time (s)               196.05417915200815
(Previous) Eval Time (s)     33.25563420774415
Sample Time (s)              6.250529343727976
Epoch Time (s)               235.56034270348027
Total Train Time (s)         82360.06207395252
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:29:23.793727 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #354 | Epoch Duration: 235.64702558517456
2020-01-13 22:29:23.793897 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4605765
Z variance train             0.057068
KL Divergence                46.523315
KL Loss                      4.652332
QF Loss                      4348.26
VF Loss                      62.823624
Policy Loss                  -1391.6665
Q Predictions Mean           1389.3269
Q Predictions Std            1375.0146
Q Predictions Max            5072.9087
Q Predictions Min            693.02637
V Predictions Mean           1394.513
V Predictions Std            1377.451
V Predictions Max            5100.803
V Predictions Min            693.7202
Log Pis Mean                 -0.15682292
Log Pis Std                  4.5221677
Log Pis Max                  17.164036
Log Pis Min                  -8.313608
Policy mu Mean               0.031170614
Policy mu Std                0.92646396
Policy mu Max                2.7430456
Policy mu Min                -3.1563401
Policy log std Mean          -0.4844005
Policy log std Std           0.29151717
Policy log std Max           -0.03912431
Policy log std Min           -3.0293264
Z mean eval                  2.4711163
Z variance eval              0.095248125
total_rewards                [10492.70098988 10898.9779249  10719.73169206 10375.76809224
 10917.85968758 10848.77412722 10880.49754561 10665.65252862
 10537.71155078 10870.93718049]
total_rewards_mean           10720.861131938085
total_rewards_std            185.10582195377805
total_rewards_max            10917.859687577118
total_rewards_min            10375.768092236196
Number of train steps total  1424000
Number of env steps total    4274000
Number of rollouts total     0
Train Time (s)               193.82982030510902
(Previous) Eval Time (s)     36.5042245159857
Sample Time (s)              6.968885353766382
Epoch Time (s)               237.3029301748611
Total Train Time (s)         82597.44555056235
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:33:21.179059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #355 | Epoch Duration: 237.38503766059875
2020-01-13 22:33:21.179189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4709258
Z variance train             0.09532379
KL Divergence                46.62245
KL Loss                      4.6622453
QF Loss                      112.99951
VF Loss                      77.563835
Policy Loss                  -1359.0865
Q Predictions Mean           1355.8453
Q Predictions Std            1315.8654
Q Predictions Max            5029.9873
Q Predictions Min            689.85986
V Predictions Mean           1363.5186
V Predictions Std            1313.6254
V Predictions Max            5027.5513
V Predictions Min            698.44586
Log Pis Mean                 -0.2067534
Log Pis Std                  3.8915613
Log Pis Max                  14.903138
Log Pis Min                  -6.2599335
Policy mu Mean               0.089989275
Policy mu Std                0.8871027
Policy mu Max                3.2971516
Policy mu Min                -3.4375129
Policy log std Mean          -0.49105415
Policy log std Std           0.2764359
Policy log std Max           -0.0011112094
Policy log std Min           -2.5817242
Z mean eval                  2.4916968
Z variance eval              0.06973818
total_rewards                [10467.98114297 11183.88501968  9955.39876873 10932.72387283
 10949.30585978 11019.61675637 10712.22900287 10414.90229193
 10930.48748653 10930.74585178]
total_rewards_mean           10749.727605346587
total_rewards_std            349.84956387567775
total_rewards_max            11183.885019676556
total_rewards_min            9955.39876872952
Number of train steps total  1428000
Number of env steps total    4286000
Number of rollouts total     0
Train Time (s)               194.2241249200888
(Previous) Eval Time (s)     34.4038250381127
Sample Time (s)              6.9812505091540515
Epoch Time (s)               235.60920046735555
Total Train Time (s)         82833.13500758493
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:37:16.873034 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #356 | Epoch Duration: 235.69371128082275
2020-01-13 22:37:16.873237 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #356 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4927137
Z variance train             0.06984223
KL Divergence                47.014133
KL Loss                      4.7014136
QF Loss                      131.78485
VF Loss                      83.89287
Policy Loss                  -1349.0836
Q Predictions Mean           1346.3696
Q Predictions Std            1327.101
Q Predictions Max            5104.049
Q Predictions Min            696.705
V Predictions Mean           1343.1177
V Predictions Std            1320.5176
V Predictions Max            5052.5547
V Predictions Min            692.34503
Log Pis Mean                 -0.23084943
Log Pis Std                  3.617058
Log Pis Max                  16.890415
Log Pis Min                  -5.6651707
Policy mu Mean               0.06623045
Policy mu Std                0.8861354
Policy mu Max                2.4966094
Policy mu Min                -3.1167629
Policy log std Mean          -0.5066888
Policy log std Std           0.29014125
Policy log std Max           -0.007916689
Policy log std Min           -2.6662605
Z mean eval                  2.4680543
Z variance eval              0.058491826
total_rewards                [10964.05962547 10953.63299345 10826.50832809 11378.4276944
 11001.81170522 10965.09515765 10993.47951831 11074.79750216
 11109.65368643 11161.66335549]
total_rewards_mean           11042.91295666686
total_rewards_std            142.60121184281294
total_rewards_max            11378.427694395414
total_rewards_min            10826.5083280866
Number of train steps total  1432000
Number of env steps total    4298000
Number of rollouts total     0
Train Time (s)               191.2205330482684
(Previous) Eval Time (s)     32.994524330832064
Sample Time (s)              7.911628737580031
Epoch Time (s)               232.1266861166805
Total Train Time (s)         83065.36858821195
Epoch                        357
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:41:09.113607 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #357 | Epoch Duration: 232.24013328552246
2020-01-13 22:41:09.113985 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4659476
Z variance train             0.05859979
KL Divergence                47.56522
KL Loss                      4.756522
QF Loss                      329.8133
VF Loss                      1054.714
Policy Loss                  -1339.701
Q Predictions Mean           1337.2505
Q Predictions Std            1327.266
Q Predictions Max            4938.49
Q Predictions Min            686.7175
V Predictions Mean           1338.9277
V Predictions Std            1328.5776
V Predictions Max            4948.649
V Predictions Min            702.26385
Log Pis Mean                 -0.20328729
Log Pis Std                  3.971819
Log Pis Max                  17.323963
Log Pis Min                  -9.3647175
Policy mu Mean               0.072308384
Policy mu Std                0.88976145
Policy mu Max                4.5002704
Policy mu Min                -3.489023
Policy log std Mean          -0.4940338
Policy log std Std           0.29648072
Policy log std Max           0.38790476
Policy log std Min           -2.5626292
Z mean eval                  2.4919827
Z variance eval              0.04818159
total_rewards                [ 4663.7015387  11248.89505684 11038.41655929 10809.09502865
 11206.49187679 10837.75065603 11232.61917473 10493.71327957
 11123.77912373 10948.31782255]
total_rewards_mean           10360.278011687193
total_rewards_std            1911.8969439883679
total_rewards_max            11248.895056837217
total_rewards_min            4663.701538695494
Number of train steps total  1436000
Number of env steps total    4310000
Number of rollouts total     0
Train Time (s)               192.78686000220478
(Previous) Eval Time (s)     34.36647640215233
Sample Time (s)              7.23531073750928
Epoch Time (s)               234.3886471418664
Total Train Time (s)         83299.86045002984
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:45:03.608360 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #358 | Epoch Duration: 234.49416828155518
2020-01-13 22:45:03.608549 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4905314
Z variance train             0.04820095
KL Divergence                48.751083
KL Loss                      4.8751082
QF Loss                      271.51166
VF Loss                      65.42257
Policy Loss                  -1460.0676
Q Predictions Mean           1454.93
Q Predictions Std            1456.5177
Q Predictions Max            5050.881
Q Predictions Min            701.9529
V Predictions Mean           1461.9336
V Predictions Std            1459.3287
V Predictions Max            5065.7646
V Predictions Min            695.8805
Log Pis Mean                 -0.14901249
Log Pis Std                  4.121393
Log Pis Max                  16.357742
Log Pis Min                  -6.0187306
Policy mu Mean               0.0889912
Policy mu Std                0.8956399
Policy mu Max                2.9566197
Policy mu Min                -3.5888677
Policy log std Mean          -0.5062631
Policy log std Std           0.28702044
Policy log std Max           -0.053116202
Policy log std Min           -2.6333828
Z mean eval                  2.4742112
Z variance eval              0.06239898
total_rewards                [10890.18761452 10982.79200571 10852.56483619 11425.82639902
 11150.32086575  2155.17212513 10638.67491485 10805.74866927
 11114.82096742 10624.44798321]
total_rewards_mean           10064.055638106065
total_rewards_std            2646.3482519568834
total_rewards_max            11425.82639901633
total_rewards_min            2155.172125130976
Number of train steps total  1440000
Number of env steps total    4322000
Number of rollouts total     0
Train Time (s)               192.02896398631856
(Previous) Eval Time (s)     30.349002027884126
Sample Time (s)              7.709834273438901
Epoch Time (s)               230.08780028764158
Total Train Time (s)         83530.07037983695
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:48:53.821973 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #359 | Epoch Duration: 230.21327757835388
2020-01-13 22:48:53.822163 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4752178
Z variance train             0.06242284
KL Divergence                47.918297
KL Loss                      4.7918296
QF Loss                      207.55283
VF Loss                      59.61242
Policy Loss                  -1222.3629
Q Predictions Mean           1216.9553
Q Predictions Std            1208.2882
Q Predictions Max            4895.0273
Q Predictions Min            687.308
V Predictions Mean           1220.3159
V Predictions Std            1207.0786
V Predictions Max            4887.206
V Predictions Min            691.06525
Log Pis Mean                 -0.3411895
Log Pis Std                  3.8446844
Log Pis Max                  19.497643
Log Pis Min                  -8.168694
Policy mu Mean               0.045998167
Policy mu Std                0.8773914
Policy mu Max                3.2402322
Policy mu Min                -2.990386
Policy log std Mean          -0.49381742
Policy log std Std           0.2709484
Policy log std Max           -0.0075410604
Policy log std Min           -3.006134
Z mean eval                  2.5156944
Z variance eval              0.06472991
total_rewards                [11098.69310055 10771.75696322 10805.50421584 10592.75983195
 10218.32922023 10286.48754012 10489.91753929 10677.10906292
 10471.23820574 10825.83292867]
total_rewards_mean           10623.762860853747
total_rewards_std            253.85815800470544
total_rewards_max            11098.6931005503
total_rewards_min            10218.32922023239
Number of train steps total  1444000
Number of env steps total    4334000
Number of rollouts total     0
Train Time (s)               198.8128948546946
(Previous) Eval Time (s)     33.12711948296055
Sample Time (s)              7.202559011057019
Epoch Time (s)               239.14257334871218
Total Train Time (s)         83769.29480151925
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:52:53.049688 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #360 | Epoch Duration: 239.22737455368042
2020-01-13 22:52:53.049888 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5159843
Z variance train             0.065072216
KL Divergence                48.127087
KL Loss                      4.812709
QF Loss                      133.15967
VF Loss                      224.16869
Policy Loss                  -1337.4296
Q Predictions Mean           1332.2888
Q Predictions Std            1325.4095
Q Predictions Max            5055.8735
Q Predictions Min            706.3443
V Predictions Mean           1342.4812
V Predictions Std            1325.113
V Predictions Max            5067.5137
V Predictions Min            709.7357
Log Pis Mean                 -0.2872806
Log Pis Std                  4.5314417
Log Pis Max                  26.84011
Log Pis Min                  -6.5043144
Policy mu Mean               0.13706814
Policy mu Std                0.89966094
Policy mu Max                4.2771134
Policy mu Min                -4.2412667
Policy log std Mean          -0.486668
Policy log std Std           0.2821366
Policy log std Max           0.24987566
Policy log std Min           -2.8528233
Z mean eval                  2.4912262
Z variance eval              0.08577646
total_rewards                [10891.10393882 10632.99307933 10611.42287031 10679.04112558
 10768.9977742  10727.03481071 11236.59393029 10567.97019783
 10983.41225065  5394.42163717]
total_rewards_mean           10249.299161489786
total_rewards_std            1629.6724862170086
total_rewards_max            11236.593930285353
total_rewards_min            5394.421637167128
Number of train steps total  1448000
Number of env steps total    4346000
Number of rollouts total     0
Train Time (s)               191.95032214792445
(Previous) Eval Time (s)     32.36269420012832
Sample Time (s)              7.372837965842336
Epoch Time (s)               231.6858543138951
Total Train Time (s)         84001.07221995201
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:56:44.830736 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #361 | Epoch Duration: 231.78068852424622
2020-01-13 22:56:44.830930 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4886768
Z variance train             0.085817136
KL Divergence                46.729687
KL Loss                      4.672969
QF Loss                      109.25191
VF Loss                      49.27097
Policy Loss                  -1264.395
Q Predictions Mean           1259.6865
Q Predictions Std            1236.714
Q Predictions Max            5008.1934
Q Predictions Min            704.6689
V Predictions Mean           1266.0533
V Predictions Std            1236.5538
V Predictions Max            5022.533
V Predictions Min            713.9529
Log Pis Mean                 -0.646928
Log Pis Std                  3.827082
Log Pis Max                  14.1925335
Log Pis Min                  -7.2363043
Policy mu Mean               0.021125635
Policy mu Std                0.8424669
Policy mu Max                3.489039
Policy mu Min                -3.154603
Policy log std Mean          -0.4659512
Policy log std Std           0.2606038
Policy log std Max           0.056902945
Policy log std Min           -2.6878188
Z mean eval                  2.5046604
Z variance eval              0.06828257
total_rewards                [8856.79625239  933.73600032 8172.98296107 7627.25469244  531.26003802
 8858.64649954 8385.23123658 8925.61155637 9537.10620625 1755.78682368]
total_rewards_mean           6358.4412266649515
total_rewards_std            3503.7879617319727
total_rewards_max            9537.106206254577
total_rewards_min            531.2600380175625
Number of train steps total  1452000
Number of env steps total    4358000
Number of rollouts total     0
Train Time (s)               196.08190121129155
(Previous) Eval Time (s)     29.565200811251998
Sample Time (s)              7.309883303940296
Epoch Time (s)               232.95698532648385
Total Train Time (s)         84234.16436314164
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:00:37.926483 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #362 | Epoch Duration: 233.0953986644745
2020-01-13 23:00:37.926693 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #362 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5017216
Z variance train             0.0680397
KL Divergence                48.85418
KL Loss                      4.885418
QF Loss                      352.55505
VF Loss                      245.35565
Policy Loss                  -1418.6417
Q Predictions Mean           1416.0847
Q Predictions Std            1417.5698
Q Predictions Max            5153.953
Q Predictions Min            693.5379
V Predictions Mean           1418.1582
V Predictions Std            1416.9901
V Predictions Max            5135.5303
V Predictions Min            707.95844
Log Pis Mean                 -0.24908836
Log Pis Std                  3.9292283
Log Pis Max                  15.333429
Log Pis Min                  -6.740666
Policy mu Mean               -0.014274797
Policy mu Std                0.87463427
Policy mu Max                3.0206652
Policy mu Min                -3.164391
Policy log std Mean          -0.4867092
Policy log std Std           0.269856
Policy log std Max           -0.0020967722
Policy log std Min           -2.4965043
Z mean eval                  2.4766173
Z variance eval              0.064978525
total_rewards                [11093.25659769 10835.81070558 11298.08968646 10899.01170475
 11065.01316513 10665.93422651 11203.47425858 11056.96071731
 11222.19908454 11284.89782922]
total_rewards_mean           11062.464797575969
total_rewards_std            196.64807681394754
total_rewards_max            11298.08968645568
total_rewards_min            10665.934226509078
Number of train steps total  1456000
Number of env steps total    4370000
Number of rollouts total     0
Train Time (s)               192.422476853244
(Previous) Eval Time (s)     34.941413660068065
Sample Time (s)              6.448076315689832
Epoch Time (s)               233.8119668290019
Total Train Time (s)         84468.08249657229
Epoch                        363
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:04:31.850021 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #363 | Epoch Duration: 233.92318201065063
2020-01-13 23:04:31.850171 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #363 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4770973
Z variance train             0.065181814
KL Divergence                47.78671
KL Loss                      4.778671
QF Loss                      354.29083
VF Loss                      38.8837
Policy Loss                  -1290.7487
Q Predictions Mean           1287.0199
Q Predictions Std            1293.3289
Q Predictions Max            4973.843
Q Predictions Min            686.29517
V Predictions Mean           1292.7272
V Predictions Std            1289.0863
V Predictions Max            4964.2983
V Predictions Min            691.03534
Log Pis Mean                 -0.60684174
Log Pis Std                  3.700235
Log Pis Max                  11.821787
Log Pis Min                  -8.016277
Policy mu Mean               0.0448245
Policy mu Std                0.85101205
Policy mu Max                2.834056
Policy mu Min                -2.389481
Policy log std Mean          -0.4768889
Policy log std Std           0.28983438
Policy log std Max           -0.011949539
Policy log std Min           -2.7244964
Z mean eval                  2.4846988
Z variance eval              0.07893287
total_rewards                [11197.55231546 11279.64061898 11324.11630397 10995.77375372
 11316.67253105 11044.75027987 10588.80294904 10876.54169077
 10819.16809056 10854.18430354]
total_rewards_mean           11029.720283698141
total_rewards_std            235.37916756979163
total_rewards_max            11324.116303970395
total_rewards_min            10588.802949043155
Number of train steps total  1460000
Number of env steps total    4382000
Number of rollouts total     0
Train Time (s)               194.72334808576852
(Previous) Eval Time (s)     32.93373996717855
Sample Time (s)              7.6327688647434115
Epoch Time (s)               235.28985691769049
Total Train Time (s)         84703.45413601724
Epoch                        364
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:08:27.228417 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #364 | Epoch Duration: 235.37804436683655
2020-01-13 23:08:27.228708 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.484861
Z variance train             0.079456806
KL Divergence                48.09615
KL Loss                      4.809615
QF Loss                      143.10687
VF Loss                      143.26256
Policy Loss                  -1375.849
Q Predictions Mean           1375.4565
Q Predictions Std            1378.4602
Q Predictions Max            5128.3853
Q Predictions Min            704.82684
V Predictions Mean           1372.0127
V Predictions Std            1377.9534
V Predictions Max            5149.4263
V Predictions Min            703.0915
Log Pis Mean                 -0.16257894
Log Pis Std                  4.332635
Log Pis Max                  24.720657
Log Pis Min                  -8.460663
Policy mu Mean               0.020173198
Policy mu Std                0.9172034
Policy mu Max                3.1809633
Policy mu Min                -3.455583
Policy log std Mean          -0.4982438
Policy log std Std           0.28105372
Policy log std Max           0.058140576
Policy log std Min           -2.5241275
Z mean eval                  2.4870155
Z variance eval              0.042215496
total_rewards                [11094.73901719 11069.39135425 11070.36078555 11059.76659796
 10978.9068325  10771.39440882 10893.77273869 10354.63818708
 11172.77347572 11190.37099327]
total_rewards_mean           10965.611439102686
total_rewards_std            236.02138128443647
total_rewards_max            11190.370993268862
total_rewards_min            10354.638187078803
Number of train steps total  1464000
Number of env steps total    4394000
Number of rollouts total     0
Train Time (s)               192.43844342092052
(Previous) Eval Time (s)     29.736512043047696
Sample Time (s)              7.053324060514569
Epoch Time (s)               229.2282795244828
Total Train Time (s)         84932.76600994915
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:12:16.541785 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #365 | Epoch Duration: 229.3129050731659
2020-01-13 23:12:16.541916 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4894931
Z variance train             0.04212533
KL Divergence                49.16033
KL Loss                      4.9160333
QF Loss                      157.24046
VF Loss                      334.24356
Policy Loss                  -1302.668
Q Predictions Mean           1299.2977
Q Predictions Std            1307.8015
Q Predictions Max            4922.6606
Q Predictions Min            688.6093
V Predictions Mean           1295.8541
V Predictions Std            1295.7606
V Predictions Max            4880.1714
V Predictions Min            696.08685
Log Pis Mean                 -0.52766335
Log Pis Std                  3.778658
Log Pis Max                  15.891569
Log Pis Min                  -7.96873
Policy mu Mean               0.029856592
Policy mu Std                0.86643374
Policy mu Max                3.2263737
Policy mu Min                -3.4213033
Policy log std Mean          -0.48217782
Policy log std Std           0.28244692
Policy log std Max           -0.09179193
Policy log std Min           -2.8834887
Z mean eval                  2.4978986
Z variance eval              0.05476709
total_rewards                [10344.06234611 11216.30340256 10965.90531218 11209.21845212
 11154.78389792 11166.15454774 10738.91665671 11060.16360662
 11047.66621583 11250.05185457]
total_rewards_mean           11015.32262923611
total_rewards_std            266.0405805745237
total_rewards_max            11250.051854567806
total_rewards_min            10344.062346112536
Number of train steps total  1468000
Number of env steps total    4406000
Number of rollouts total     0
Train Time (s)               195.06412655767053
(Previous) Eval Time (s)     29.217869699001312
Sample Time (s)              6.487060664221644
Epoch Time (s)               230.7690569208935
Total Train Time (s)         85163.62305123545
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:16:07.404955 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #366 | Epoch Duration: 230.86292386054993
2020-01-13 23:16:07.405149 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4977417
Z variance train             0.054625593
KL Divergence                49.866844
KL Loss                      4.9866843
QF Loss                      247.47774
VF Loss                      99.70885
Policy Loss                  -1507.6733
Q Predictions Mean           1503.4285
Q Predictions Std            1508.4905
Q Predictions Max            5143.9844
Q Predictions Min            693.7644
V Predictions Mean           1506.2391
V Predictions Std            1500.9572
V Predictions Max            5068.8066
V Predictions Min            700.5373
Log Pis Mean                 -0.103060395
Log Pis Std                  4.29369
Log Pis Max                  17.50065
Log Pis Min                  -6.3543863
Policy mu Mean               0.023227632
Policy mu Std                0.9207026
Policy mu Max                3.273343
Policy mu Min                -3.044352
Policy log std Mean          -0.5070681
Policy log std Std           0.3285975
Policy log std Max           0.2074818
Policy log std Min           -3.2002912
Z mean eval                  2.4920802
Z variance eval              0.042769328
total_rewards                [11147.85347901 11163.49446043 11216.65112991 11232.86190879
 11272.80896448 11165.44335444 11092.4544277  10906.78781403
 11205.5643735  11102.51707745]
total_rewards_mean           11150.643698972668
total_rewards_std            97.27140400078919
total_rewards_max            11272.808964475917
total_rewards_min            10906.787814026697
Number of train steps total  1472000
Number of env steps total    4418000
Number of rollouts total     0
Train Time (s)               193.88599895266816
(Previous) Eval Time (s)     29.870957252103835
Sample Time (s)              7.511378351133317
Epoch Time (s)               231.2683345559053
Total Train Time (s)         85394.9723835364
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:19:58.758254 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #367 | Epoch Duration: 231.3529131412506
2020-01-13 23:19:58.758544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #367 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.492017
Z variance train             0.04260359
KL Divergence                52.3438
KL Loss                      5.2343802
QF Loss                      4465.84
VF Loss                      88.103584
Policy Loss                  -1347.66
Q Predictions Mean           1343.0054
Q Predictions Std            1338.2141
Q Predictions Max            5123.3267
Q Predictions Min            684.3634
V Predictions Mean           1344.607
V Predictions Std            1338.0134
V Predictions Max            5107.1157
V Predictions Min            690.70135
Log Pis Mean                 -0.39610085
Log Pis Std                  3.8884852
Log Pis Max                  17.123482
Log Pis Min                  -6.960647
Policy mu Mean               0.06679036
Policy mu Std                0.8682312
Policy mu Max                3.1391315
Policy mu Min                -3.130218
Policy log std Mean          -0.5076628
Policy log std Std           0.30219844
Policy log std Max           0.37646955
Policy log std Min           -2.6736832
Z mean eval                  2.4995263
Z variance eval              0.0633286
total_rewards                [11158.36933374 11222.37926866 11665.89439002 11363.35823085
 11407.74851807 10979.61842234 11242.36741817 11121.1791191
 11005.82602144 11354.83168916]
total_rewards_mean           11252.157241154615
total_rewards_std            194.98339982220236
total_rewards_max            11665.894390015528
total_rewards_min            10979.618422343045
Number of train steps total  1476000
Number of env steps total    4430000
Number of rollouts total     0
Train Time (s)               196.9922444471158
(Previous) Eval Time (s)     31.95908330474049
Sample Time (s)              6.630182257853448
Epoch Time (s)               235.58151000970975
Total Train Time (s)         85630.64082277054
Epoch                        368
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:23:54.430677 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #368 | Epoch Duration: 235.67194652557373
2020-01-13 23:23:54.430890 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #368 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4998016
Z variance train             0.06329195
KL Divergence                50.753
KL Loss                      5.0752997
QF Loss                      215.73042
VF Loss                      118.525505
Policy Loss                  -1437.9452
Q Predictions Mean           1436.7677
Q Predictions Std            1435.4814
Q Predictions Max            4966.0957
Q Predictions Min            689.539
V Predictions Mean           1441.5754
V Predictions Std            1440.8168
V Predictions Max            4994.586
V Predictions Min            699.3222
Log Pis Mean                 -0.11506926
Log Pis Std                  3.9178076
Log Pis Max                  15.728927
Log Pis Min                  -6.8026547
Policy mu Mean               0.050706256
Policy mu Std                0.911954
Policy mu Max                2.8321943
Policy mu Min                -2.4807003
Policy log std Mean          -0.48949668
Policy log std Std           0.281988
Policy log std Max           -0.0014661252
Policy log std Min           -2.739202
Z mean eval                  2.4927304
Z variance eval              0.06337412
total_rewards                [10906.61895032 10048.45650026 10035.69565654  4078.90794535
 10832.27077606 10872.12021611 10926.22229483 10769.72453181
 10033.62325399 10673.4779837 ]
total_rewards_mean           9917.711810896795
total_rewards_std            1979.2810012840173
total_rewards_max            10926.222294828172
total_rewards_min            4078.907945351202
Number of train steps total  1480000
Number of env steps total    4442000
Number of rollouts total     0
Train Time (s)               193.27916060108691
(Previous) Eval Time (s)     32.8872965592891
Sample Time (s)              6.926299318205565
Epoch Time (s)               233.09275647858158
Total Train Time (s)         85863.81335989153
Epoch                        369
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:27:47.606819 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #369 | Epoch Duration: 233.17575693130493
2020-01-13 23:27:47.607032 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4910648
Z variance train             0.06353824
KL Divergence                50.88711
KL Loss                      5.0887113
QF Loss                      4431.51
VF Loss                      34.557747
Policy Loss                  -1380.805
Q Predictions Mean           1379.4905
Q Predictions Std            1393.4895
Q Predictions Max            4948.4443
Q Predictions Min            677.8403
V Predictions Mean           1380.8379
V Predictions Std            1392.6101
V Predictions Max            4942.368
V Predictions Min            682.54236
Log Pis Mean                 -0.39237064
Log Pis Std                  3.819018
Log Pis Max                  14.936593
Log Pis Min                  -7.98315
Policy mu Mean               0.09568647
Policy mu Std                0.8902585
Policy mu Max                3.1106849
Policy mu Min                -3.388541
Policy log std Mean          -0.49716583
Policy log std Std           0.25816494
Policy log std Max           -0.07837951
Policy log std Min           -2.437203
Z mean eval                  2.474983
Z variance eval              0.057808973
total_rewards                [11043.80592212  5250.47710789 10925.22131088 11038.17068587
 11172.27305491 11106.60780056 11195.4974721  11347.25788757
 10924.58224425  9486.34253928]
total_rewards_mean           10349.023602541181
total_rewards_std            1769.8863205250282
total_rewards_max            11347.25788756539
total_rewards_min            5250.4771078862095
Number of train steps total  1484000
Number of env steps total    4454000
Number of rollouts total     0
Train Time (s)               193.66952256299555
(Previous) Eval Time (s)     31.072069498244673
Sample Time (s)              7.496323132887483
Epoch Time (s)               232.2379151941277
Total Train Time (s)         86096.1310007968
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:31:39.931506 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #370 | Epoch Duration: 232.3242793083191
2020-01-13 23:31:39.931812 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4752758
Z variance train             0.05746472
KL Divergence                49.99819
KL Loss                      4.9998193
QF Loss                      337.0573
VF Loss                      66.87771
Policy Loss                  -1354.0339
Q Predictions Mean           1352.5409
Q Predictions Std            1362.5128
Q Predictions Max            5128.7373
Q Predictions Min            710.76373
V Predictions Mean           1352.9285
V Predictions Std            1355.3417
V Predictions Max            5109.717
V Predictions Min            714.0205
Log Pis Mean                 -0.09788912
Log Pis Std                  4.3267674
Log Pis Max                  15.674887
Log Pis Min                  -8.952265
Policy mu Mean               0.06606149
Policy mu Std                0.9252701
Policy mu Max                3.1158414
Policy mu Min                -2.6502235
Policy log std Mean          -0.4875706
Policy log std Std           0.29221123
Policy log std Max           0.13230169
Policy log std Min           -3.074981
Z mean eval                  2.500644
Z variance eval              0.048614576
total_rewards                [10991.49646614 11351.69014521 11234.57007286 10879.35794979
 11200.70654161 10915.51021933 11181.32774202 11233.18484652
 11272.67372813 11275.79782127]
total_rewards_mean           11153.63155328924
total_rewards_std            155.69242493262175
total_rewards_max            11351.690145214
total_rewards_min            10879.35794979386
Number of train steps total  1488000
Number of env steps total    4466000
Number of rollouts total     0
Train Time (s)               196.57403204403818
(Previous) Eval Time (s)     34.09085669973865
Sample Time (s)              7.152911768294871
Epoch Time (s)               237.8178005120717
Total Train Time (s)         86334.03703323845
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:35:37.837939 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #371 | Epoch Duration: 237.90587425231934
2020-01-13 23:35:37.838140 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #371 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5024247
Z variance train             0.04846696
KL Divergence                50.505905
KL Loss                      5.0505905
QF Loss                      290.203
VF Loss                      73.09995
Policy Loss                  -1419.39
Q Predictions Mean           1416.5413
Q Predictions Std            1401.5498
Q Predictions Max            5121.7144
Q Predictions Min            722.8783
V Predictions Mean           1418.2408
V Predictions Std            1399.2213
V Predictions Max            5111.098
V Predictions Min            717.0765
Log Pis Mean                 -0.4722371
Log Pis Std                  3.8622832
Log Pis Max                  13.779528
Log Pis Min                  -7.45416
Policy mu Mean               0.058558047
Policy mu Std                0.8820125
Policy mu Max                2.9640048
Policy mu Min                -3.1062498
Policy log std Mean          -0.48340663
Policy log std Std           0.29893953
Policy log std Max           -0.049105763
Policy log std Min           -3.1058779
Z mean eval                  2.4777722
Z variance eval              0.037262395
total_rewards                [11018.35708601 11086.36811959 10855.10690064 10914.17386489
 11005.73607741 11068.9026797  10786.30015329 10986.7094614
 10988.11955577 10972.62197283]
total_rewards_mean           10968.23958715373
total_rewards_std            88.08222194870399
total_rewards_max            11086.368119587041
total_rewards_min            10786.30015329173
Number of train steps total  1492000
Number of env steps total    4478000
Number of rollouts total     0
Train Time (s)               195.63847544929013
(Previous) Eval Time (s)     30.086734268814325
Sample Time (s)              7.20616933144629
Epoch Time (s)               232.93137904955074
Total Train Time (s)         86567.05184503598
Epoch                        372
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:39:30.861218 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #372 | Epoch Duration: 233.0229001045227
2020-01-13 23:39:30.861531 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #372 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4796944
Z variance train             0.03719709
KL Divergence                49.697357
KL Loss                      4.9697356
QF Loss                      4719.0645
VF Loss                      86.74431
Policy Loss                  -1237.5175
Q Predictions Mean           1239.2064
Q Predictions Std            1243.9971
Q Predictions Max            5083.11
Q Predictions Min            695.53253
V Predictions Mean           1241.6293
V Predictions Std            1243.6948
V Predictions Max            5073.3325
V Predictions Min            698.8317
Log Pis Mean                 -0.4692541
Log Pis Std                  3.7085278
Log Pis Max                  12.36039
Log Pis Min                  -7.454077
Policy mu Mean               0.094840415
Policy mu Std                0.8734097
Policy mu Max                2.6989455
Policy mu Min                -2.928043
Policy log std Mean          -0.48414573
Policy log std Std           0.27205563
Policy log std Max           -0.035800457
Policy log std Min           -2.5264094
Z mean eval                  2.5020478
Z variance eval              0.023398345
total_rewards                [11252.43498239  1645.18666608 10656.53691777 10845.8004461
 11165.49133769 10853.77272069 11024.40892618 10581.24109143
 10847.97473708 11119.13686691]
total_rewards_mean           9999.198469231018
total_rewards_std            2792.203308807669
total_rewards_max            11252.434982389921
total_rewards_min            1645.1866660753121
Number of train steps total  1496000
Number of env steps total    4490000
Number of rollouts total     0
Train Time (s)               193.74529086891562
(Previous) Eval Time (s)     33.484625002834946
Sample Time (s)              7.24286755733192
Epoch Time (s)               234.47278342908248
Total Train Time (s)         86801.60840799846
Epoch                        373
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:43:25.423608 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #373 | Epoch Duration: 234.56184244155884
2020-01-13 23:43:25.423832 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5015967
Z variance train             0.02339553
KL Divergence                50.96036
KL Loss                      5.0960364
QF Loss                      4491.4795
VF Loss                      57.52205
Policy Loss                  -1365.9943
Q Predictions Mean           1365.7874
Q Predictions Std            1367.8069
Q Predictions Max            5024.8247
Q Predictions Min            707.308
V Predictions Mean           1369.495
V Predictions Std            1367.6774
V Predictions Max            5011.9937
V Predictions Min            709.4248
Log Pis Mean                 -0.6391429
Log Pis Std                  3.8330822
Log Pis Max                  13.811332
Log Pis Min                  -6.7996407
Policy mu Mean               0.06700417
Policy mu Std                0.8560915
Policy mu Max                2.6341588
Policy mu Min                -2.4259033
Policy log std Mean          -0.49254605
Policy log std Std           0.29598808
Policy log std Max           0.013849258
Policy log std Min           -2.9423332
Z mean eval                  2.4745717
Z variance eval              0.047494926
total_rewards                [10879.34015861 11064.65123119 11306.02931492 10967.44822015
 11323.15560143 11045.03964435 11079.85521405 11062.91091743
 11032.62240552 10962.59434785]
total_rewards_mean           11072.364705551134
total_rewards_std            134.29139513929667
total_rewards_max            11323.155601433245
total_rewards_min            10879.340158609628
Number of train steps total  1500000
Number of env steps total    4502000
Number of rollouts total     0
Train Time (s)               194.60831171413884
(Previous) Eval Time (s)     29.73850659187883
Sample Time (s)              7.209736248478293
Epoch Time (s)               231.55655455449596
Total Train Time (s)         87033.2677302584
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:47:17.088636 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #374 | Epoch Duration: 231.66464257240295
2020-01-13 23:47:17.088822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4750178
Z variance train             0.047780413
KL Divergence                48.935028
KL Loss                      4.8935027
QF Loss                      375.6297
VF Loss                      60.30428
Policy Loss                  -1337.9579
Q Predictions Mean           1333.7499
Q Predictions Std            1364.122
Q Predictions Max            5069.95
Q Predictions Min            664.9652
V Predictions Mean           1339.3966
V Predictions Std            1361.9948
V Predictions Max            5064.2104
V Predictions Min            686.8588
Log Pis Mean                 -0.30901003
Log Pis Std                  3.9501798
Log Pis Max                  16.958916
Log Pis Min                  -7.036124
Policy mu Mean               0.06288334
Policy mu Std                0.880572
Policy mu Max                3.3092182
Policy mu Min                -3.4788573
Policy log std Mean          -0.49970022
Policy log std Std           0.27094224
Policy log std Max           0.03951627
Policy log std Min           -2.6392183
Z mean eval                  2.5234504
Z variance eval              0.023418725
total_rewards                [8861.51867269 3212.90325902 9739.93357334 9443.05788515 8734.63767772
 9083.58865856 3402.83327123 9739.7497488  5437.29606469 9958.82731695]
total_rewards_mean           7761.434612814801
total_rewards_std            2539.2546943437706
total_rewards_max            9958.8273169452
total_rewards_min            3212.903259022595
Number of train steps total  1504000
Number of env steps total    4514000
Number of rollouts total     0
Train Time (s)               195.6259188549593
(Previous) Eval Time (s)     32.29613540414721
Sample Time (s)              6.140766259748489
Epoch Time (s)               234.062820518855
Total Train Time (s)         87267.41249369225
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:51:11.239373 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #375 | Epoch Duration: 234.1503381729126
2020-01-13 23:51:11.239695 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5225136
Z variance train             0.023383122
KL Divergence                51.494938
KL Loss                      5.1494937
QF Loss                      224.84692
VF Loss                      112.38396
Policy Loss                  -1348.245
Q Predictions Mean           1343.9788
Q Predictions Std            1303.6125
Q Predictions Max            4972.154
Q Predictions Min            681.782
V Predictions Mean           1351.6746
V Predictions Std            1306.8615
V Predictions Max            4990.7373
V Predictions Min            690.61304
Log Pis Mean                 -0.5057041
Log Pis Std                  3.8616347
Log Pis Max                  14.65963
Log Pis Min                  -9.159707
Policy mu Mean               0.02731266
Policy mu Std                0.8909629
Policy mu Max                3.3461092
Policy mu Min                -3.2213154
Policy log std Mean          -0.5022018
Policy log std Std           0.2845193
Policy log std Max           -0.064127445
Policy log std Min           -2.6715646
Z mean eval                  2.4782133
Z variance eval              0.049227085
total_rewards                [11143.35239466 11268.54806312 11228.44548313 11272.57886098
 11121.7034247  10869.62289219 11041.7534975  10949.91575156
 10835.07353301 11047.87055718]
total_rewards_mean           11077.886445801947
total_rewards_std            149.68152563203108
total_rewards_max            11272.57886098176
total_rewards_min            10835.07353300714
Number of train steps total  1508000
Number of env steps total    4526000
Number of rollouts total     0
Train Time (s)               195.56869102735072
(Previous) Eval Time (s)     33.43384025385603
Sample Time (s)              6.189775079023093
Epoch Time (s)               235.19230636022985
Total Train Time (s)         87502.70047993632
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:55:06.534363 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #376 | Epoch Duration: 235.2944531440735
2020-01-13 23:55:06.534577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #376 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4792795
Z variance train             0.0491864
KL Divergence                49.642582
KL Loss                      4.964258
QF Loss                      160.99983
VF Loss                      91.34855
Policy Loss                  -1252.8524
Q Predictions Mean           1250.9104
Q Predictions Std            1263.1818
Q Predictions Max            4995.8945
Q Predictions Min            677.44684
V Predictions Mean           1252.4563
V Predictions Std            1262.2776
V Predictions Max            4996.5117
V Predictions Min            687.201
Log Pis Mean                 -0.595173
Log Pis Std                  3.8555171
Log Pis Max                  12.914042
Log Pis Min                  -8.236803
Policy mu Mean               0.082030006
Policy mu Std                0.8233615
Policy mu Max                2.6480794
Policy mu Min                -2.7670312
Policy log std Mean          -0.49254093
Policy log std Std           0.3018551
Policy log std Max           -0.023297548
Policy log std Min           -2.8784766
Z mean eval                  2.5313456
Z variance eval              0.047985442
total_rewards                [10766.97318062 11187.61980684 11398.48010118 11422.41320234
 10976.81262653 11312.94893912 10964.21652114 11291.05249348
 11416.76413809 11427.0297864 ]
total_rewards_mean           11216.431079574813
total_rewards_std            223.34085213858796
total_rewards_max            11427.029786404686
total_rewards_min            10766.9731806212
Number of train steps total  1512000
Number of env steps total    4538000
Number of rollouts total     0
Train Time (s)               195.06598443817347
(Previous) Eval Time (s)     31.787554264068604
Sample Time (s)              7.323224023450166
Epoch Time (s)               234.17676272569224
Total Train Time (s)         87736.96405679453
Epoch                        377
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:59:00.805368 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #377 | Epoch Duration: 234.2706265449524
2020-01-13 23:59:00.805580 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5340607
Z variance train             0.048100878
KL Divergence                49.272114
KL Loss                      4.9272113
QF Loss                      143.95056
VF Loss                      42.270176
Policy Loss                  -1471.6302
Q Predictions Mean           1468.7422
Q Predictions Std            1424.9562
Q Predictions Max            4958.3164
Q Predictions Min            685.0552
V Predictions Mean           1467.7972
V Predictions Std            1422.9419
V Predictions Max            4943.2417
V Predictions Min            684.1671
Log Pis Mean                 0.0376565
Log Pis Std                  4.111862
Log Pis Max                  15.817745
Log Pis Min                  -7.1900387
Policy mu Mean               0.025896082
Policy mu Std                0.92046875
Policy mu Max                3.066831
Policy mu Min                -2.417439
Policy log std Mean          -0.52979493
Policy log std Std           0.2974254
Policy log std Max           -0.069871485
Policy log std Min           -2.6884546
Z mean eval                  2.500922
Z variance eval              0.03818706
total_rewards                [11286.45712916  9269.09489121 11587.65922299 11351.74315338
 11214.84129094 11313.85416912 11451.10376488 11491.78938188
 11568.65288412 11275.42839751]
total_rewards_mean           11181.062428519672
total_rewards_std            648.7341742159947
total_rewards_max            11587.659222990631
total_rewards_min            9269.094891207516
Number of train steps total  1516000
Number of env steps total    4550000
Number of rollouts total     0
Train Time (s)               195.46491287602112
(Previous) Eval Time (s)     32.424109359271824
Sample Time (s)              7.055634142830968
Epoch Time (s)               234.9446563781239
Total Train Time (s)         87971.99263403285
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:02:55.838424 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #378 | Epoch Duration: 235.03269338607788
2020-01-14 00:02:55.838557 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.49923
Z variance train             0.038315475
KL Divergence                50.792072
KL Loss                      5.0792074
QF Loss                      113.612854
VF Loss                      115.42656
Policy Loss                  -1347.8159
Q Predictions Mean           1345.7507
Q Predictions Std            1375.6069
Q Predictions Max            5067.8076
Q Predictions Min            689.8825
V Predictions Mean           1352.9807
V Predictions Std            1376.9004
V Predictions Max            5092.9556
V Predictions Min            717.24243
Log Pis Mean                 -0.4854259
Log Pis Std                  3.5934734
Log Pis Max                  14.836396
Log Pis Min                  -5.9106035
Policy mu Mean               0.058675136
Policy mu Std                0.8387838
Policy mu Max                3.1953762
Policy mu Min                -3.3913703
Policy log std Mean          -0.4980971
Policy log std Std           0.26973516
Policy log std Max           0.02546528
Policy log std Min           -2.8359118
Z mean eval                  2.5105767
Z variance eval              0.027017396
total_rewards                [11311.15082671 11304.71745463 11404.29593536 11475.98708817
 11197.39983633 11728.47199727 11147.63695656 11358.11839383
 11490.83106439 11435.14821428]
total_rewards_mean           11385.375776753555
total_rewards_std            156.36313049619142
total_rewards_max            11728.4719972738
total_rewards_min            11147.636956563007
Number of train steps total  1520000
Number of env steps total    4562000
Number of rollouts total     0
Train Time (s)               198.75398341193795
(Previous) Eval Time (s)     32.17106207692996
Sample Time (s)              7.919546767603606
Epoch Time (s)               238.84459225647151
Total Train Time (s)         88210.96100528259
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:06:54.809903 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #379 | Epoch Duration: 238.97124791145325
2020-01-14 00:06:54.810043 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #379 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5096772
Z variance train             0.02695558
KL Divergence                52.47899
KL Loss                      5.247899
QF Loss                      4531.669
VF Loss                      25.681686
Policy Loss                  -1198.0936
Q Predictions Mean           1198.1841
Q Predictions Std            1207.4895
Q Predictions Max            4988.9336
Q Predictions Min            692.0839
V Predictions Mean           1198.3269
V Predictions Std            1206.6951
V Predictions Max            4976.531
V Predictions Min            691.4234
Log Pis Mean                 -0.8723285
Log Pis Std                  3.712226
Log Pis Max                  14.325401
Log Pis Min                  -8.406174
Policy mu Mean               0.06709915
Policy mu Std                0.7978074
Policy mu Max                2.843142
Policy mu Min                -2.5715399
Policy log std Mean          -0.44904408
Policy log std Std           0.25903526
Policy log std Max           0.034009337
Policy log std Min           -2.6107519
Z mean eval                  2.526194
Z variance eval              0.045564186
total_rewards                [10999.0624407  11255.58961689 11342.8854305  10958.80714193
  7924.49311632 10915.97168556 11190.48766109 11643.33624542
  7292.664763   10968.70822468]
total_rewards_mean           10449.200632609358
total_rewards_std            1442.6392108795453
total_rewards_max            11643.336245419345
total_rewards_min            7292.664763003426
Number of train steps total  1524000
Number of env steps total    4574000
Number of rollouts total     0
Train Time (s)               199.18922588508576
(Previous) Eval Time (s)     31.79646994313225
Sample Time (s)              7.718319721519947
Epoch Time (s)               238.70401554973796
Total Train Time (s)         88449.74948092503
Epoch                        380
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:10:53.607627 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #380 | Epoch Duration: 238.79743647575378
2020-01-14 00:10:53.607956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5263164
Z variance train             0.04549315
KL Divergence                50.463997
KL Loss                      5.0463996
QF Loss                      4986.123
VF Loss                      61.22567
Policy Loss                  -1407.4198
Q Predictions Mean           1405.5707
Q Predictions Std            1376.221
Q Predictions Max            5092.5283
Q Predictions Min            707.4692
V Predictions Mean           1410.177
V Predictions Std            1377.3202
V Predictions Max            5110.272
V Predictions Min            721.7774
Log Pis Mean                 -0.4640199
Log Pis Std                  3.8612092
Log Pis Max                  16.149843
Log Pis Min                  -6.324668
Policy mu Mean               0.017316412
Policy mu Std                0.8819689
Policy mu Max                2.6799812
Policy mu Min                -3.6283715
Policy log std Mean          -0.46482047
Policy log std Std           0.2698512
Policy log std Max           -0.041492343
Policy log std Min           -2.5413156
Z mean eval                  2.5126662
Z variance eval              0.039976403
total_rewards                [10775.12859928 11114.64636954 11255.01858403 11361.25090314
 11253.32763802 11307.66367235 10764.48592829 11059.24939275
 11124.81197938 11286.33581306]
total_rewards_mean           11130.19188798361
total_rewards_std            201.27686831449756
total_rewards_max            11361.250903139387
total_rewards_min            10764.485928289347
Number of train steps total  1528000
Number of env steps total    4586000
Number of rollouts total     0
Train Time (s)               193.45816300390288
(Previous) Eval Time (s)     32.05828473623842
Sample Time (s)              7.693004633300006
Epoch Time (s)               233.2094523734413
Total Train Time (s)         88683.04058270017
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:14:46.901686 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #381 | Epoch Duration: 233.2934067249298
2020-01-14 00:14:46.901883 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.510112
Z variance train             0.04018731
KL Divergence                50.56075
KL Loss                      5.056075
QF Loss                      157.63867
VF Loss                      135.05595
Policy Loss                  -1297.77
Q Predictions Mean           1298.1199
Q Predictions Std            1288.1544
Q Predictions Max            4991.692
Q Predictions Min            690.2313
V Predictions Mean           1302.5414
V Predictions Std            1283.8407
V Predictions Max            4967.47
V Predictions Min            694.9426
Log Pis Mean                 -0.03467515
Log Pis Std                  3.8724256
Log Pis Max                  13.279192
Log Pis Min                  -7.0740213
Policy mu Mean               0.088364445
Policy mu Std                0.91161716
Policy mu Max                3.303029
Policy mu Min                -3.2639024
Policy log std Mean          -0.48711255
Policy log std Std           0.27757746
Policy log std Max           -0.10077858
Policy log std Min           -2.7112367
Z mean eval                  2.4971778
Z variance eval              0.04469432
total_rewards                [10866.988415   10950.78303427 10692.57689457 11248.26553584
 10263.0813064  10567.95071687 11082.37139696 10932.08989008
 11344.81021247 10960.59587769]
total_rewards_mean           10890.951328013485
total_rewards_std            303.1340209306931
total_rewards_max            11344.810212469454
total_rewards_min            10263.081306399929
Number of train steps total  1532000
Number of env steps total    4598000
Number of rollouts total     0
Train Time (s)               196.5719323027879
(Previous) Eval Time (s)     26.570350045803934
Sample Time (s)              6.640655041672289
Epoch Time (s)               229.78293739026412
Total Train Time (s)         88912.90756177716
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:18:36.773359 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #382 | Epoch Duration: 229.8712499141693
2020-01-14 00:18:36.773655 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.497141
Z variance train             0.044488993
KL Divergence                51.557255
KL Loss                      5.1557255
QF Loss                      4416.6206
VF Loss                      49.5127
Policy Loss                  -1399.1805
Q Predictions Mean           1397.9755
Q Predictions Std            1404.7358
Q Predictions Max            5049.095
Q Predictions Min            713.372
V Predictions Mean           1398.2659
V Predictions Std            1403.1504
V Predictions Max            5043.7275
V Predictions Min            699.6442
Log Pis Mean                 -0.5655513
Log Pis Std                  3.8602817
Log Pis Max                  16.274414
Log Pis Min                  -7.9084935
Policy mu Mean               0.027521685
Policy mu Std                0.86644405
Policy mu Max                3.0569286
Policy mu Min                -3.1622145
Policy log std Mean          -0.4794598
Policy log std Std           0.2723261
Policy log std Max           -0.010064483
Policy log std Min           -2.7141979
Z mean eval                  2.5026467
Z variance eval              0.033343248
total_rewards                [11025.97624188 10713.87215006 10745.82616447 10970.32673885
 11185.66895835 11296.04936767 10945.5315857  11060.89512891
 11516.50330272  7022.25227632]
total_rewards_mean           10648.290191493747
total_rewards_std            1230.0031174254011
total_rewards_max            11516.503302722738
total_rewards_min            7022.252276323485
Number of train steps total  1536000
Number of env steps total    4610000
Number of rollouts total     0
Train Time (s)               198.88194993836805
(Previous) Eval Time (s)     31.37107923673466
Sample Time (s)              7.102832962758839
Epoch Time (s)               237.35586213786155
Total Train Time (s)         89150.34529596101
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:22:34.216374 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #383 | Epoch Duration: 237.44252347946167
2020-01-14 00:22:34.216579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #383 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.499928
Z variance train             0.033415552
KL Divergence                51.666473
KL Loss                      5.1666474
QF Loss                      10192.85
VF Loss                      292.44272
Policy Loss                  -1470.9912
Q Predictions Mean           1469.5374
Q Predictions Std            1459.0126
Q Predictions Max            4947.9004
Q Predictions Min            675.12317
V Predictions Mean           1475.8232
V Predictions Std            1468.2826
V Predictions Max            4958.576
V Predictions Min            640.0268
Log Pis Mean                 -0.13708737
Log Pis Std                  3.9743798
Log Pis Max                  13.778578
Log Pis Min                  -6.3421307
Policy mu Mean               0.06281814
Policy mu Std                0.9055378
Policy mu Max                2.789979
Policy mu Min                -2.631776
Policy log std Mean          -0.5003115
Policy log std Std           0.3180571
Policy log std Max           0.01543808
Policy log std Min           -3.1180065
Z mean eval                  2.5070207
Z variance eval              0.034343623
total_rewards                [10926.93653897 10795.5341225  11118.12685697 10967.62075742
 11147.49079928 11137.65325474 11129.53537723 11019.96054286
 11041.40017095 11022.35003906]
total_rewards_mean           11030.660845997843
total_rewards_std            106.2258675430633
total_rewards_max            11147.4907992761
total_rewards_min            10795.534122497978
Number of train steps total  1540000
Number of env steps total    4622000
Number of rollouts total     0
Train Time (s)               194.55060460790992
(Previous) Eval Time (s)     32.14143305784091
Sample Time (s)              6.518853397574276
Epoch Time (s)               233.2108910633251
Total Train Time (s)         89383.63706858968
Epoch                        384
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:26:27.511787 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #384 | Epoch Duration: 233.29505014419556
2020-01-14 00:26:27.511983 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5053103
Z variance train             0.03437395
KL Divergence                52.526955
KL Loss                      5.2526956
QF Loss                      4746.296
VF Loss                      89.081154
Policy Loss                  -1477.7974
Q Predictions Mean           1475.6617
Q Predictions Std            1410.8883
Q Predictions Max            5059.097
Q Predictions Min            722.9519
V Predictions Mean           1481.1588
V Predictions Std            1412.929
V Predictions Max            5044.675
V Predictions Min            725.6645
Log Pis Mean                 -0.27873006
Log Pis Std                  3.9900057
Log Pis Max                  15.254067
Log Pis Min                  -8.072622
Policy mu Mean               0.046947334
Policy mu Std                0.88333786
Policy mu Max                2.8891943
Policy mu Min                -2.830214
Policy log std Mean          -0.49599078
Policy log std Std           0.28596574
Policy log std Max           -0.041771263
Policy log std Min           -2.821027
Z mean eval                  2.4987292
Z variance eval              0.03745358
total_rewards                [11493.89914555 11054.3695057  11329.15766955 11124.64538382
 11073.41021938 10859.52538756 11082.66239223 11298.93549917
  6850.88458636 11186.76130474]
total_rewards_mean           10735.42510940702
total_rewards_std            1305.455135438515
total_rewards_max            11493.89914555328
total_rewards_min            6850.884586356058
Number of train steps total  1544000
Number of env steps total    4634000
Number of rollouts total     0
Train Time (s)               198.43702100031078
(Previous) Eval Time (s)     32.20953433262184
Sample Time (s)              6.517627853900194
Epoch Time (s)               237.16418318683282
Total Train Time (s)         89620.8862532503
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:30:24.769186 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #385 | Epoch Duration: 237.2570629119873
2020-01-14 00:30:24.769335 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4950693
Z variance train             0.037705403
KL Divergence                51.790546
KL Loss                      5.1790547
QF Loss                      185.21942
VF Loss                      66.37407
Policy Loss                  -1502.0151
Q Predictions Mean           1502.2992
Q Predictions Std            1532.5624
Q Predictions Max            5021.186
Q Predictions Min            695.0021
V Predictions Mean           1503.8602
V Predictions Std            1532.706
V Predictions Max            5025.455
V Predictions Min            678.0181
Log Pis Mean                 -0.1537776
Log Pis Std                  4.00832
Log Pis Max                  14.460822
Log Pis Min                  -8.209748
Policy mu Mean               -0.022951828
Policy mu Std                0.8906075
Policy mu Max                3.0871465
Policy mu Min                -3.0854642
Policy log std Mean          -0.48702565
Policy log std Std           0.28080475
Policy log std Max           -0.03243795
Policy log std Min           -2.5596204
Z mean eval                  2.492572
Z variance eval              0.038081054
total_rewards                [10814.09675514 11265.49736113 11381.68819747 11494.52211519
 10949.17355731 10972.73150908 11042.01059784 10969.98048752
 10932.17204352 11383.12937597]
total_rewards_mean           11120.500200017717
total_rewards_std            225.2699703515008
total_rewards_max            11494.52211518507
total_rewards_min            10814.096755143297
Number of train steps total  1548000
Number of env steps total    4646000
Number of rollouts total     0
Train Time (s)               192.27112649707124
(Previous) Eval Time (s)     27.857898753602058
Sample Time (s)              6.579268709290773
Epoch Time (s)               226.70829395996407
Total Train Time (s)         89847.69111265335
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:34:11.580861 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #386 | Epoch Duration: 226.81140279769897
2020-01-14 00:34:11.581072 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4918907
Z variance train             0.038196146
KL Divergence                52.201675
KL Loss                      5.2201676
QF Loss                      4623.303
VF Loss                      155.56291
Policy Loss                  -1390.914
Q Predictions Mean           1389.56
Q Predictions Std            1400.4141
Q Predictions Max            5101.8047
Q Predictions Min            682.46405
V Predictions Mean           1395.8186
V Predictions Std            1403.0183
V Predictions Max            5107.016
V Predictions Min            679.42676
Log Pis Mean                 -0.41935772
Log Pis Std                  3.897927
Log Pis Max                  18.69131
Log Pis Min                  -6.2273083
Policy mu Mean               0.029068574
Policy mu Std                0.9096494
Policy mu Max                3.441669
Policy mu Min                -3.0463538
Policy log std Mean          -0.49772266
Policy log std Std           0.28603035
Policy log std Max           0.12589613
Policy log std Min           -2.6687753
Z mean eval                  2.492949
Z variance eval              0.042519756
total_rewards                [10869.35390397 10871.44895463 10726.46071049 10906.23882562
 10968.1572084  10708.31927319 11026.16323494 10822.16535997
 10891.00928058 10805.66592743]
total_rewards_mean           10859.498267921634
total_rewards_std            93.72689034494076
total_rewards_max            11026.163234940203
total_rewards_min            10708.31927319287
Number of train steps total  1552000
Number of env steps total    4658000
Number of rollouts total     0
Train Time (s)               193.10943307029083
(Previous) Eval Time (s)     33.74857654981315
Sample Time (s)              6.523501488380134
Epoch Time (s)               233.38151110848412
Total Train Time (s)         90081.29145528376
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:38:05.185816 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #387 | Epoch Duration: 233.6045961380005
2020-01-14 00:38:05.185970 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4929578
Z variance train             0.04247908
KL Divergence                50.311104
KL Loss                      5.0311103
QF Loss                      167.59546
VF Loss                      54.98408
Policy Loss                  -1366.1709
Q Predictions Mean           1363.3193
Q Predictions Std            1391.5562
Q Predictions Max            5085.9355
Q Predictions Min            706.1825
V Predictions Mean           1365.8071
V Predictions Std            1387.0625
V Predictions Max            5077.9707
V Predictions Min            710.1748
Log Pis Mean                 -0.017982155
Log Pis Std                  4.449651
Log Pis Max                  21.21017
Log Pis Min                  -8.636466
Policy mu Mean               0.0699321
Policy mu Std                0.9256638
Policy mu Max                4.1131735
Policy mu Min                -2.744039
Policy log std Mean          -0.48554954
Policy log std Std           0.2952629
Policy log std Max           -0.0043722987
Policy log std Min           -3.0017986
Z mean eval                  2.493047
Z variance eval              0.03741125
total_rewards                [ 9925.74234476  3820.99426267 10489.3686014  10354.28492723
  9004.75927776  9731.44908194  9705.11591532  9348.61840923
  2245.95428553 10354.71551552]
total_rewards_mean           8498.100262136406
total_rewards_std            2789.597168823823
total_rewards_max            10489.368601401558
total_rewards_min            2245.9542855299896
Number of train steps total  1556000
Number of env steps total    4670000
Number of rollouts total     0
Train Time (s)               195.36961103603244
(Previous) Eval Time (s)     28.601052217185497
Sample Time (s)              6.482965575065464
Epoch Time (s)               230.4536288282834
Total Train Time (s)         90311.82628331007
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:41:55.729658 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #388 | Epoch Duration: 230.54356360435486
2020-01-14 00:41:55.729862 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #388 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4957283
Z variance train             0.037367616
KL Divergence                50.076824
KL Loss                      5.0076823
QF Loss                      121.84332
VF Loss                      71.76588
Policy Loss                  -1456.3303
Q Predictions Mean           1455.0208
Q Predictions Std            1407.2952
Q Predictions Max            4986.3667
Q Predictions Min            705.68866
V Predictions Mean           1453.3861
V Predictions Std            1407.7161
V Predictions Max            4982.9917
V Predictions Min            708.72504
Log Pis Mean                 -0.12786177
Log Pis Std                  3.792126
Log Pis Max                  13.422888
Log Pis Min                  -6.7346582
Policy mu Mean               0.04834427
Policy mu Std                0.900183
Policy mu Max                2.5936785
Policy mu Min                -2.969134
Policy log std Mean          -0.51596093
Policy log std Std           0.30216396
Policy log std Max           -0.03804803
Policy log std Min           -2.8219967
Z mean eval                  2.4566379
Z variance eval              0.042764314
total_rewards                [10846.64220856 11194.96397381 11363.45659417 11279.46510765
  9528.79723715 10554.68013635 10931.83597828 11295.60108315
 10810.08903075 10982.26831394]
total_rewards_mean           10878.779966381662
total_rewards_std            511.4628347717216
total_rewards_max            11363.456594170222
total_rewards_min            9528.797237154407
Number of train steps total  1560000
Number of env steps total    4682000
Number of rollouts total     0
Train Time (s)               194.06947430595756
(Previous) Eval Time (s)     31.355540549382567
Sample Time (s)              6.4637412880547345
Epoch Time (s)               231.88875614339486
Total Train Time (s)         90543.79567494662
Epoch                        389
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:45:47.705463 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #389 | Epoch Duration: 231.97540640830994
2020-01-14 00:45:47.705805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455956
Z variance train             0.042716525
KL Divergence                49.618355
KL Loss                      4.9618354
QF Loss                      149.49448
VF Loss                      109.44881
Policy Loss                  -1307.9132
Q Predictions Mean           1304.2655
Q Predictions Std            1313.3951
Q Predictions Max            4998.239
Q Predictions Min            682.28613
V Predictions Mean           1309.098
V Predictions Std            1305.3958
V Predictions Max            4984.13
V Predictions Min            689.7337
Log Pis Mean                 -0.07566094
Log Pis Std                  4.1032834
Log Pis Max                  14.023234
Log Pis Min                  -6.8514533
Policy mu Mean               0.09465643
Policy mu Std                0.9116463
Policy mu Max                3.2149792
Policy mu Min                -3.0415392
Policy log std Mean          -0.4867897
Policy log std Std           0.27150786
Policy log std Max           0.41417027
Policy log std Min           -2.810481
Z mean eval                  2.448235
Z variance eval              0.11622004
total_rewards                [10181.28716619  9649.26665774 10739.13019295 10390.90243106
 11555.90881072 10642.26835698 10592.71478927 10388.89141131
 10623.17909891 10313.63710495]
total_rewards_mean           10507.718602008255
total_rewards_std            458.24053970288935
total_rewards_max            11555.90881072123
total_rewards_min            9649.266657741213
Number of train steps total  1564000
Number of env steps total    4694000
Number of rollouts total     0
Train Time (s)               196.22977868141606
(Previous) Eval Time (s)     35.922784184105694
Sample Time (s)              6.539202403277159
Epoch Time (s)               238.69176526879892
Total Train Time (s)         90782.57189991884
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:49:46.481969 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #390 | Epoch Duration: 238.77587151527405
2020-01-14 00:49:46.482202 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4459739
Z variance train             0.116097346
KL Divergence                47.059258
KL Loss                      4.705926
QF Loss                      349.7359
VF Loss                      194.61484
Policy Loss                  -1489.9126
Q Predictions Mean           1487.9121
Q Predictions Std            1510.317
Q Predictions Max            5203.9365
Q Predictions Min            720.2643
V Predictions Mean           1497.9424
V Predictions Std            1513.2334
V Predictions Max            5228.863
V Predictions Min            723.1571
Log Pis Mean                 0.025777757
Log Pis Std                  4.2460823
Log Pis Max                  14.984266
Log Pis Min                  -5.6317406
Policy mu Mean               0.04278784
Policy mu Std                0.9465091
Policy mu Max                3.0897677
Policy mu Min                -3.4069285
Policy log std Mean          -0.4672979
Policy log std Std           0.2971063
Policy log std Max           0.1883316
Policy log std Min           -2.931744
Z mean eval                  2.5195472
Z variance eval              0.0477175
total_rewards                [11117.44749538  4249.80644202 11360.78476336 11484.44156309
 11045.97798285 11177.140471   11276.16239108 11046.95513849
 11101.96435589  3091.49191243]
total_rewards_mean           9695.217251560654
total_rewards_std            3026.3184915870916
total_rewards_max            11484.441563090366
total_rewards_min            3091.4919124330854
Number of train steps total  1568000
Number of env steps total    4706000
Number of rollouts total     0
Train Time (s)               194.5886985710822
(Previous) Eval Time (s)     30.98314727190882
Sample Time (s)              6.7177161909639835
Epoch Time (s)               232.289562033955
Total Train Time (s)         91014.94053973164
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:53:38.853839 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #391 | Epoch Duration: 232.37148761749268
2020-01-14 00:53:38.854025 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5193787
Z variance train             0.047510248
KL Divergence                50.744106
KL Loss                      5.074411
QF Loss                      186.14087
VF Loss                      80.68802
Policy Loss                  -1451.7563
Q Predictions Mean           1450.8757
Q Predictions Std            1444.1194
Q Predictions Max            5027.5596
Q Predictions Min            705.5552
V Predictions Mean           1452.2285
V Predictions Std            1442.7953
V Predictions Max            5009.312
V Predictions Min            701.87366
Log Pis Mean                 -0.17561321
Log Pis Std                  4.1517553
Log Pis Max                  15.032551
Log Pis Min                  -8.894712
Policy mu Mean               0.013403039
Policy mu Std                0.9233623
Policy mu Max                3.1666954
Policy mu Min                -2.6059413
Policy log std Mean          -0.4980087
Policy log std Std           0.29571003
Policy log std Max           0.057646036
Policy log std Min           -2.9356174
Z mean eval                  2.4628634
Z variance eval              0.045454357
total_rewards                [11150.56346752 10195.83882251 10401.13263716 11115.41524418
 11070.35632394 10518.50622844 10627.84206566 10924.81195365
 10816.53361382 11195.66815599]
total_rewards_mean           10801.666851287422
total_rewards_std            331.78817822797214
total_rewards_max            11195.668155989992
total_rewards_min            10195.838822511445
Number of train steps total  1572000
Number of env steps total    4718000
Number of rollouts total     0
Train Time (s)               195.3369027688168
(Previous) Eval Time (s)     31.858347378205508
Sample Time (s)              5.735122412443161
Epoch Time (s)               232.93037255946547
Total Train Time (s)         91247.95478091156
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:57:31.878692 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #392 | Epoch Duration: 233.0245234966278
2020-01-14 00:57:31.878875 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #392 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4590216
Z variance train             0.045448683
KL Divergence                49.649666
KL Loss                      4.964967
QF Loss                      4274.1606
VF Loss                      64.812164
Policy Loss                  -1445.8551
Q Predictions Mean           1445.8584
Q Predictions Std            1443.3772
Q Predictions Max            5115.403
Q Predictions Min            698.2914
V Predictions Mean           1448.1919
V Predictions Std            1441.7642
V Predictions Max            5103.526
V Predictions Min            695.21063
Log Pis Mean                 -0.09031312
Log Pis Std                  4.09353
Log Pis Max                  15.133499
Log Pis Min                  -7.710356
Policy mu Mean               0.034772184
Policy mu Std                0.9159928
Policy mu Max                3.2296596
Policy mu Min                -3.610647
Policy log std Mean          -0.48822653
Policy log std Std           0.29509327
Policy log std Max           -0.022430718
Policy log std Min           -2.8092284
Z mean eval                  2.4856927
Z variance eval              0.079024084
total_rewards                [10960.68680667 11588.90368181 11529.33538531 11303.4983782
 10988.38369508 11366.92460981 11186.64192977 11215.79724419
 10896.38526212 11146.06714661]
total_rewards_mean           11218.262413957123
total_rewards_std            221.92777416617812
total_rewards_max            11588.903681807877
total_rewards_min            10896.38526211993
Number of train steps total  1576000
Number of env steps total    4730000
Number of rollouts total     0
Train Time (s)               191.85532488720492
(Previous) Eval Time (s)     30.375356716103852
Sample Time (s)              6.2875547469593585
Epoch Time (s)               228.51823635026813
Total Train Time (s)         91476.55694716796
Epoch                        393
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:01:20.489011 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #393 | Epoch Duration: 228.6100037097931
2020-01-14 01:01:20.489190 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #393 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4844823
Z variance train             0.07898218
KL Divergence                50.25454
KL Loss                      5.025454
QF Loss                      410.79337
VF Loss                      74.33501
Policy Loss                  -1440.631
Q Predictions Mean           1438.0591
Q Predictions Std            1441.6538
Q Predictions Max            5130.892
Q Predictions Min            713.107
V Predictions Mean           1439.0198
V Predictions Std            1435.948
V Predictions Max            5119.28
V Predictions Min            710.73956
Log Pis Mean                 0.072674595
Log Pis Std                  4.197615
Log Pis Max                  26.357998
Log Pis Min                  -6.9952745
Policy mu Mean               0.1017887
Policy mu Std                0.94425654
Policy mu Max                3.089656
Policy mu Min                -3.6348774
Policy log std Mean          -0.4989024
Policy log std Std           0.3029617
Policy log std Max           -0.05078423
Policy log std Min           -2.8911328
Z mean eval                  2.481049
Z variance eval              0.055065293
total_rewards                [11261.33237656 11189.38579138 11363.11002011 11014.8054317
 11422.55509355 11492.69836768 11293.46552299 11453.23105947
 11165.59551754 11779.25447138]
total_rewards_mean           11343.543365235168
total_rewards_std            200.8764645731528
total_rewards_max            11779.254471376624
total_rewards_min            11014.80543170409
Number of train steps total  1580000
Number of env steps total    4742000
Number of rollouts total     0
Train Time (s)               198.2992562018335
(Previous) Eval Time (s)     30.9590690783225
Sample Time (s)              7.518204371910542
Epoch Time (s)               236.77652965206653
Total Train Time (s)         91713.42891565058
Epoch                        394
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:05:17.365913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #394 | Epoch Duration: 236.87658262252808
2020-01-14 01:05:17.366112 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4797587
Z variance train             0.05483336
KL Divergence                50.604885
KL Loss                      5.0604887
QF Loss                      182.19734
VF Loss                      116.87623
Policy Loss                  -1453.5564
Q Predictions Mean           1452.0173
Q Predictions Std            1473.3225
Q Predictions Max            5098.915
Q Predictions Min            710.6603
V Predictions Mean           1448.6346
V Predictions Std            1464.8856
V Predictions Max            5067.978
V Predictions Min            713.3513
Log Pis Mean                 -0.12904002
Log Pis Std                  4.387893
Log Pis Max                  17.480606
Log Pis Min                  -6.4742084
Policy mu Mean               0.09328463
Policy mu Std                0.93056166
Policy mu Max                2.9922147
Policy mu Min                -2.795296
Policy log std Mean          -0.501455
Policy log std Std           0.3169423
Policy log std Max           -0.064285606
Policy log std Min           -2.794477
Z mean eval                  2.4872637
Z variance eval              0.044814147
total_rewards                [10224.87095811  2061.40358744 10088.10436701  9983.76281978
 11132.84592051  7888.18946954 10093.86483819  9203.64080952
 10526.74456237  6877.40427176]
total_rewards_mean           8808.083160422717
total_rewards_std            2555.139810860091
total_rewards_max            11132.845920511023
total_rewards_min            2061.4035874414435
Number of train steps total  1584000
Number of env steps total    4754000
Number of rollouts total     0
Train Time (s)               195.0658864909783
(Previous) Eval Time (s)     34.98039650404826
Sample Time (s)              7.266165306326002
Epoch Time (s)               237.31244830135256
Total Train Time (s)         91950.82325856062
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:09:14.762771 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #395 | Epoch Duration: 237.39651894569397
2020-01-14 01:09:14.762912 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #395 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4817736
Z variance train             0.044856887
KL Divergence                51.178143
KL Loss                      5.1178145
QF Loss                      259.55035
VF Loss                      179.67886
Policy Loss                  -1611.6954
Q Predictions Mean           1610.9822
Q Predictions Std            1581.3623
Q Predictions Max            5132.5723
Q Predictions Min            702.8034
V Predictions Mean           1617.2222
V Predictions Std            1585.9254
V Predictions Max            5140.769
V Predictions Min            704.5732
Log Pis Mean                 -0.04432235
Log Pis Std                  4.218634
Log Pis Max                  13.853218
Log Pis Min                  -6.859254
Policy mu Mean               0.054601517
Policy mu Std                0.9279326
Policy mu Max                3.1021695
Policy mu Min                -2.8340397
Policy log std Mean          -0.492296
Policy log std Std           0.31549534
Policy log std Max           -0.06368619
Policy log std Min           -3.0190532
Z mean eval                  2.4943097
Z variance eval              0.033607047
total_rewards                [11391.2673634  11464.11556719 11151.56782935 10776.13442925
  7713.51172812 11556.86023473 11396.1714269  11348.33620856
 11636.67760947 11198.41281144]
total_rewards_mean           10963.305520839851
total_rewards_std            1107.349609656145
total_rewards_max            11636.677609467912
total_rewards_min            7713.511728121768
Number of train steps total  1588000
Number of env steps total    4766000
Number of rollouts total     0
Train Time (s)               193.8005457711406
(Previous) Eval Time (s)     30.90356803778559
Sample Time (s)              6.438556804787368
Epoch Time (s)               231.14267061371356
Total Train Time (s)         92182.04543300858
Epoch                        396
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:13:05.989296 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #396 | Epoch Duration: 231.2262682914734
2020-01-14 01:13:05.989486 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #396 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4953237
Z variance train             0.033512466
KL Divergence                52.756283
KL Loss                      5.2756286
QF Loss                      182.0116
VF Loss                      58.652596
Policy Loss                  -1316.7839
Q Predictions Mean           1314.0544
Q Predictions Std            1330.6122
Q Predictions Max            5087.273
Q Predictions Min            702.9551
V Predictions Mean           1314.9695
V Predictions Std            1329.0756
V Predictions Max            5053.449
V Predictions Min            709.6195
Log Pis Mean                 -0.2929951
Log Pis Std                  3.847038
Log Pis Max                  14.723674
Log Pis Min                  -5.78997
Policy mu Mean               0.09540252
Policy mu Std                0.88492066
Policy mu Max                2.9167612
Policy mu Min                -3.479402
Policy log std Mean          -0.46049848
Policy log std Std           0.28209564
Policy log std Max           -0.072608784
Policy log std Min           -2.8174987
Z mean eval                  2.4931884
Z variance eval              0.03275544
total_rewards                [10619.22131387 10933.73988379 10842.89670923 10857.85018118
 10866.93941143 10463.60305992 10867.88569013 10796.70262941
 11136.68283617 10870.51260472]
total_rewards_mean           10825.60343198484
total_rewards_std            170.23195615965253
total_rewards_max            11136.682836169337
total_rewards_min            10463.603059918227
Number of train steps total  1592000
Number of env steps total    4778000
Number of rollouts total     0
Train Time (s)               196.46776343509555
(Previous) Eval Time (s)     34.28683798201382
Sample Time (s)              6.898468081839383
Epoch Time (s)               237.65306949894875
Total Train Time (s)         92419.7842150908
Epoch                        397
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:17:03.731662 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #397 | Epoch Duration: 237.74202346801758
2020-01-14 01:17:03.731856 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #397 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.495047
Z variance train             0.032696325
KL Divergence                53.72955
KL Loss                      5.372955
QF Loss                      97.36068
VF Loss                      40.686684
Policy Loss                  -1436.3585
Q Predictions Mean           1432.3591
Q Predictions Std            1433.1407
Q Predictions Max            5125.4126
Q Predictions Min            699.305
V Predictions Mean           1436.248
V Predictions Std            1437.0264
V Predictions Max            5126.722
V Predictions Min            698.8555
Log Pis Mean                 -0.12699369
Log Pis Std                  3.980486
Log Pis Max                  13.225785
Log Pis Min                  -6.690461
Policy mu Mean               0.02197813
Policy mu Std                0.88951534
Policy mu Max                3.0921545
Policy mu Min                -2.7197752
Policy log std Mean          -0.4857998
Policy log std Std           0.27791736
Policy log std Max           -0.05685672
Policy log std Min           -2.7357392
Z mean eval                  2.5118754
Z variance eval              0.045765657
total_rewards                [11252.34526783 11126.6046672  11043.68842865 11238.42717676
 10715.08531207 11439.30398579 11200.08583211 11253.30786588
 11444.72894325 11262.11867136]
total_rewards_mean           11197.569615090208
total_rewards_std            198.23702040649866
total_rewards_max            11444.728943250766
total_rewards_min            10715.08531207182
Number of train steps total  1596000
Number of env steps total    4790000
Number of rollouts total     0
Train Time (s)               197.46840620506555
(Previous) Eval Time (s)     30.552043460775167
Sample Time (s)              7.277037472464144
Epoch Time (s)               235.29748713830486
Total Train Time (s)         92655.1621639384
Epoch                        398
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:20:59.113840 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #398 | Epoch Duration: 235.38183403015137
2020-01-14 01:20:59.114024 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.512344
Z variance train             0.04580729
KL Divergence                52.76991
KL Loss                      5.276991
QF Loss                      187.3889
VF Loss                      61.05098
Policy Loss                  -1526.9769
Q Predictions Mean           1526.4028
Q Predictions Std            1522.8805
Q Predictions Max            5189.21
Q Predictions Min            693.6844
V Predictions Mean           1524.189
V Predictions Std            1518.1655
V Predictions Max            5164.861
V Predictions Min            679.1636
Log Pis Mean                 0.11958878
Log Pis Std                  4.0522475
Log Pis Max                  12.706335
Log Pis Min                  -6.339324
Policy mu Mean               0.07584941
Policy mu Std                0.93291116
Policy mu Max                3.0544856
Policy mu Min                -2.9456558
Policy log std Mean          -0.50206167
Policy log std Std           0.31356624
Policy log std Max           -0.04082784
Policy log std Min           -2.7829952
Z mean eval                  2.4621422
Z variance eval              0.040048026
total_rewards                [10210.93749398 10180.10190111 10216.4621908  10104.34812909
 10034.76066888 10095.63104586 10469.65578595 10062.52678834
 10463.00283267 10374.54683632]
total_rewards_mean           10221.197367298742
total_rewards_std            153.26111491869267
total_rewards_max            10469.655785948278
total_rewards_min            10034.76066888314
Number of train steps total  1600000
Number of env steps total    4802000
Number of rollouts total     0
Train Time (s)               197.4521180880256
(Previous) Eval Time (s)     30.2809966718778
Sample Time (s)              7.531474033836275
Epoch Time (s)               235.26458879373968
Total Train Time (s)         92890.69905450707
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:24:54.656569 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #399 | Epoch Duration: 235.54236936569214
2020-01-14 01:24:54.656861 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #399 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4564793
Z variance train             0.040092815
KL Divergence                52.225655
KL Loss                      5.2225657
QF Loss                      258.2527
VF Loss                      104.52336
Policy Loss                  -1420.4061
Q Predictions Mean           1420.4275
Q Predictions Std            1454.8888
Q Predictions Max            5107.2764
Q Predictions Min            659.12897
V Predictions Mean           1424.1597
V Predictions Std            1453.3927
V Predictions Max            5119.476
V Predictions Min            688.2835
Log Pis Mean                 -0.21183097
Log Pis Std                  3.9314294
Log Pis Max                  14.500097
Log Pis Min                  -9.492302
Policy mu Mean               0.017866934
Policy mu Std                0.8925159
Policy mu Max                3.3234222
Policy mu Min                -3.138335
Policy log std Mean          -0.5059915
Policy log std Std           0.2921148
Policy log std Max           -0.028461754
Policy log std Min           -2.809208
Z mean eval                  2.4895797
Z variance eval              0.033091508
total_rewards                [11325.8351477  11556.76540721 11489.0273967  11303.2202591
 11541.41368115 11108.21931811  8909.42887095 11251.38070761
  4605.93405964 11529.1769631 ]
total_rewards_mean           10462.040181125752
total_rewards_std            2091.7902983762087
total_rewards_max            11556.765407213225
total_rewards_min            4605.934059641195
Number of train steps total  1604000
Number of env steps total    4814000
Number of rollouts total     0
Train Time (s)               192.2148786811158
(Previous) Eval Time (s)     33.495191395282745
Sample Time (s)              7.1709948386996984
Epoch Time (s)               232.88106491509825
Total Train Time (s)         93123.86258621048
Epoch                        400
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:28:47.840561 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #400 | Epoch Duration: 233.18347239494324
2020-01-14 01:28:47.840832 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4900577
Z variance train             0.033101603
KL Divergence                53.264824
KL Loss                      5.3264823
QF Loss                      4568.569
VF Loss                      133.24854
Policy Loss                  -1383.283
Q Predictions Mean           1381.1365
Q Predictions Std            1417.6357
Q Predictions Max            5135.705
Q Predictions Min            694.5893
V Predictions Mean           1386.5029
V Predictions Std            1417.0336
V Predictions Max            5158.151
V Predictions Min            713.4113
Log Pis Mean                 0.24010621
Log Pis Std                  4.273432
Log Pis Max                  24.51228
Log Pis Min                  -6.444353
Policy mu Mean               0.092882454
Policy mu Std                0.96447045
Policy mu Max                2.9707818
Policy mu Min                -3.3724036
Policy log std Mean          -0.4816784
Policy log std Std           0.2722094
Policy log std Max           -0.034182608
Policy log std Min           -2.738258
Z mean eval                  2.5069828
Z variance eval              0.037611783
total_rewards                [11030.46387427 11263.77465413 11112.33334354 11333.93309656
 11033.51894976 11000.71410034 10696.10561285 10908.87317284
 10628.95725217 11256.675328  ]
total_rewards_mean           11026.534938445617
total_rewards_std            222.02005564603323
total_rewards_max            11333.933096557055
total_rewards_min            10628.95725216703
Number of train steps total  1608000
Number of env steps total    4826000
Number of rollouts total     0
Train Time (s)               194.13865536917
(Previous) Eval Time (s)     30.51258895918727
Sample Time (s)              6.216710162814707
Epoch Time (s)               230.867954491172
Total Train Time (s)         93354.8349311431
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:32:38.799227 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #401 | Epoch Duration: 230.9582028388977
2020-01-14 01:32:38.799392 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5074296
Z variance train             0.037719723
KL Divergence                53.616947
KL Loss                      5.361695
QF Loss                      4883.5166
VF Loss                      144.18242
Policy Loss                  -1490.873
Q Predictions Mean           1487.6382
Q Predictions Std            1492.6073
Q Predictions Max            5143.9536
Q Predictions Min            691.1994
V Predictions Mean           1485.9258
V Predictions Std            1494.057
V Predictions Max            5136.96
V Predictions Min            683.77734
Log Pis Mean                 -0.24844655
Log Pis Std                  4.148587
Log Pis Max                  15.160043
Log Pis Min                  -6.9265842
Policy mu Mean               0.09186888
Policy mu Std                0.8935475
Policy mu Max                2.8777573
Policy mu Min                -3.1377487
Policy log std Mean          -0.47925854
Policy log std Std           0.29440632
Policy log std Max           0.07591426
Policy log std Min           -2.8342557
Z mean eval                  2.4827137
Z variance eval              0.030053118
total_rewards                [11054.77110914  9000.84951218 10869.23709772 11430.43336664
 11541.73081413 11659.70395302 11511.87342677 11551.43291511
 11186.20343262 11535.87731019]
total_rewards_mean           11134.211293751836
total_rewards_std            750.896671237787
total_rewards_max            11659.703953017017
total_rewards_min            9000.849512183142
Number of train steps total  1612000
Number of env steps total    4838000
Number of rollouts total     0
Train Time (s)               192.01782546099275
(Previous) Eval Time (s)     32.64692638581619
Sample Time (s)              7.11141815315932
Epoch Time (s)               231.77616999996826
Total Train Time (s)         93586.7312492542
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:36:30.702388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #402 | Epoch Duration: 231.9028468132019
2020-01-14 01:36:30.702619 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #402 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4830468
Z variance train             0.030062135
KL Divergence                53.86877
KL Loss                      5.386877
QF Loss                      345.88858
VF Loss                      110.69063
Policy Loss                  -1386.5582
Q Predictions Mean           1379.6354
Q Predictions Std            1394.6324
Q Predictions Max            5166.0625
Q Predictions Min            686.58575
V Predictions Mean           1390.4911
V Predictions Std            1393.5598
V Predictions Max            5180.704
V Predictions Min            704.46234
Log Pis Mean                 0.01616972
Log Pis Std                  4.390091
Log Pis Max                  15.537272
Log Pis Min                  -7.7772894
Policy mu Mean               0.095731385
Policy mu Std                0.9605693
Policy mu Max                3.2436523
Policy mu Min                -2.696459
Policy log std Mean          -0.48124266
Policy log std Std           0.32273594
Policy log std Max           0.0011999607
Policy log std Min           -2.89787
Z mean eval                  2.5007596
Z variance eval              0.048450187
total_rewards                [10275.21137232 10513.96961363 10689.28905774 10036.4596341
 10549.66114396 10139.00123151 10864.18796718 10727.59087186
 10900.86869248 10302.94546407]
total_rewards_mean           10499.918504886093
total_rewards_std            286.03636975360223
total_rewards_max            10900.86869247685
total_rewards_min            10036.459634104292
Number of train steps total  1616000
Number of env steps total    4850000
Number of rollouts total     0
Train Time (s)               193.6242320491001
(Previous) Eval Time (s)     30.154474199283868
Sample Time (s)              6.13476758543402
Epoch Time (s)               229.913473833818
Total Train Time (s)         93816.73197710095
Epoch                        403
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:40:20.706447 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #403 | Epoch Duration: 230.00365710258484
2020-01-14 01:40:20.706633 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #403 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5026665
Z variance train             0.048367694
KL Divergence                52.76531
KL Loss                      5.2765307
QF Loss                      4591.61
VF Loss                      110.83794
Policy Loss                  -1334.004
Q Predictions Mean           1330.5132
Q Predictions Std            1352.1672
Q Predictions Max            5041.6606
Q Predictions Min            687.3792
V Predictions Mean           1329.9426
V Predictions Std            1354.249
V Predictions Max            5063.631
V Predictions Min            684.1465
Log Pis Mean                 -0.30658802
Log Pis Std                  4.020802
Log Pis Max                  14.100342
Log Pis Min                  -9.503679
Policy mu Mean               0.110303946
Policy mu Std                0.8735497
Policy mu Max                3.5164142
Policy mu Min                -2.7471728
Policy log std Mean          -0.49497595
Policy log std Std           0.2863328
Policy log std Max           0.012473822
Policy log std Min           -2.6659527
Z mean eval                  2.483487
Z variance eval              0.06347065
total_rewards                [11458.99802873 11317.09692719 11187.70031402 11094.80373168
 11346.59052587 11337.6563551  11518.15403483 11335.0501373
 11201.86544382 11442.07913335]
total_rewards_mean           11323.999463189886
total_rewards_std            125.201800384527
total_rewards_max            11518.154034832809
total_rewards_min            11094.803731683354
Number of train steps total  1620000
Number of env steps total    4862000
Number of rollouts total     0
Train Time (s)               189.9909011432901
(Previous) Eval Time (s)     32.424083231948316
Sample Time (s)              7.136908163782209
Epoch Time (s)               229.55189253902063
Total Train Time (s)         94046.41476697568
Epoch                        404
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:44:10.395686 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #404 | Epoch Duration: 229.68890142440796
2020-01-14 01:44:10.395900 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4838998
Z variance train             0.06335434
KL Divergence                51.627945
KL Loss                      5.1627946
QF Loss                      4523.3877
VF Loss                      52.764587
Policy Loss                  -1437.0621
Q Predictions Mean           1437.4227
Q Predictions Std            1443.917
Q Predictions Max            5146.314
Q Predictions Min            713.42114
V Predictions Mean           1433.5054
V Predictions Std            1439.0128
V Predictions Max            5139.288
V Predictions Min            704.8449
Log Pis Mean                 -0.34829065
Log Pis Std                  3.9596744
Log Pis Max                  16.03431
Log Pis Min                  -7.1014366
Policy mu Mean               0.023331454
Policy mu Std                0.8870675
Policy mu Max                3.100775
Policy mu Min                -2.879162
Policy log std Mean          -0.48620403
Policy log std Std           0.27790728
Policy log std Max           -0.020431757
Policy log std Min           -2.5703754
Z mean eval                  2.4708896
Z variance eval              0.08772906
total_rewards                [ 6278.20143391 10696.86527949 11106.184054   11084.56229876
 10874.48052417  7350.75163115 11018.28670647 11267.64156282
  9304.5761355  11270.0461149 ]
total_rewards_mean           10025.159574116911
total_rewards_std            1710.4000065617288
total_rewards_max            11270.046114895395
total_rewards_min            6278.201433907398
Number of train steps total  1624000
Number of env steps total    4874000
Number of rollouts total     0
Train Time (s)               197.307228022255
(Previous) Eval Time (s)     31.571385610848665
Sample Time (s)              6.428572293370962
Epoch Time (s)               235.30718592647463
Total Train Time (s)         94281.92183740996
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:48:05.909577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #405 | Epoch Duration: 235.51342511177063
2020-01-14 01:48:05.909955 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #405 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.472962
Z variance train             0.08782574
KL Divergence                50.72493
KL Loss                      5.072493
QF Loss                      577.3511
VF Loss                      104.85597
Policy Loss                  -1460.3341
Q Predictions Mean           1460.5735
Q Predictions Std            1468.5658
Q Predictions Max            5100.751
Q Predictions Min            681.52734
V Predictions Mean           1464.065
V Predictions Std            1465.8103
V Predictions Max            5098.4766
V Predictions Min            690.25696
Log Pis Mean                 -0.121690646
Log Pis Std                  4.1298704
Log Pis Max                  16.038692
Log Pis Min                  -6.8623757
Policy mu Mean               0.0074179606
Policy mu Std                0.911444
Policy mu Max                3.1866798
Policy mu Min                -2.7430797
Policy log std Mean          -0.49502707
Policy log std Std           0.26726612
Policy log std Max           0.15397215
Policy log std Min           -2.811082
Z mean eval                  2.5018663
Z variance eval              0.04992497
total_rewards                [11375.30194737 11348.58369876 10945.1135751  11370.71513503
 11226.92061603 11512.85734086 11408.47432655 11271.70676742
 11243.43443369 10816.34175391]
total_rewards_mean           11251.944959471502
total_rewards_std            204.01565810492443
total_rewards_max            11512.857340864126
total_rewards_min            10816.341753906805
Number of train steps total  1628000
Number of env steps total    4886000
Number of rollouts total     0
Train Time (s)               191.48204994294792
(Previous) Eval Time (s)     31.56625298690051
Sample Time (s)              8.14625405613333
Epoch Time (s)               231.19455698598176
Total Train Time (s)         94513.19698732579
Epoch                        406
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:51:57.187803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #406 | Epoch Duration: 231.2775993347168
2020-01-14 01:51:57.188017 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.501061
Z variance train             0.049900305
KL Divergence                53.104206
KL Loss                      5.3104205
QF Loss                      178.26091
VF Loss                      107.72682
Policy Loss                  -1458.637
Q Predictions Mean           1457.3069
Q Predictions Std            1441.5442
Q Predictions Max            5226.373
Q Predictions Min            721.036
V Predictions Mean           1463.6268
V Predictions Std            1441.3184
V Predictions Max            5230.3145
V Predictions Min            724.6755
Log Pis Mean                 -0.015540466
Log Pis Std                  4.012988
Log Pis Max                  15.2386055
Log Pis Min                  -7.7359304
Policy mu Mean               0.08211839
Policy mu Std                0.914798
Policy mu Max                2.7465177
Policy mu Min                -2.5541515
Policy log std Mean          -0.48625305
Policy log std Std           0.3054092
Policy log std Max           -0.053507805
Policy log std Min           -2.8055542
Z mean eval                  2.505156
Z variance eval              0.034517616
total_rewards                [9722.79418868 9624.68931616 9696.16489295 9262.34323483 9865.87894019
 9350.11633858 9679.40607044 9747.07140439 9907.92427955 9485.15530505]
total_rewards_mean           9634.154397081116
total_rewards_std            199.08740979625216
total_rewards_max            9907.924279554236
total_rewards_min            9262.343234833801
Number of train steps total  1632000
Number of env steps total    4898000
Number of rollouts total     0
Train Time (s)               192.99203867418692
(Previous) Eval Time (s)     31.332482672762126
Sample Time (s)              7.188073656987399
Epoch Time (s)               231.51259500393644
Total Train Time (s)         94744.80037292093
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:55:48.797344 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #407 | Epoch Duration: 231.60917448997498
2020-01-14 01:55:48.797531 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.505811
Z variance train             0.03459389
KL Divergence                54.059727
KL Loss                      5.405973
QF Loss                      271.1205
VF Loss                      153.92384
Policy Loss                  -1395.0205
Q Predictions Mean           1392.3636
Q Predictions Std            1402.1748
Q Predictions Max            5082.623
Q Predictions Min            696.23596
V Predictions Mean           1396.4817
V Predictions Std            1407.3451
V Predictions Max            5096.9116
V Predictions Min            708.6191
Log Pis Mean                 0.011675373
Log Pis Std                  3.9016063
Log Pis Max                  18.597874
Log Pis Min                  -8.185349
Policy mu Mean               0.110816084
Policy mu Std                0.92058855
Policy mu Max                2.9542742
Policy mu Min                -3.1395147
Policy log std Mean          -0.48887458
Policy log std Std           0.2807185
Policy log std Max           -0.066615045
Policy log std Min           -3.0593543
Z mean eval                  2.5055664
Z variance eval              0.04071867
total_rewards                [11364.8653139  11301.48535147 11300.74361446 11330.89791448
 11250.16169684 11469.1438187  11291.34694736 11180.86056977
 11458.00580062 11377.93991108]
total_rewards_mean           11332.545093866845
total_rewards_std            84.24734283037567
total_rewards_max            11469.14381869982
total_rewards_min            11180.860569766664
Number of train steps total  1636000
Number of env steps total    4910000
Number of rollouts total     0
Train Time (s)               191.02557031391189
(Previous) Eval Time (s)     30.876540464814752
Sample Time (s)              8.25635347655043
Epoch Time (s)               230.15846425527707
Total Train Time (s)         94975.0403463603
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:59:39.039961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #408 | Epoch Duration: 230.2422559261322
2020-01-14 01:59:39.040201 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #408 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.505094
Z variance train             0.04072461
KL Divergence                54.081646
KL Loss                      5.4081645
QF Loss                      253.17046
VF Loss                      49.251915
Policy Loss                  -1369.7361
Q Predictions Mean           1367.9038
Q Predictions Std            1380.6367
Q Predictions Max            5203.9106
Q Predictions Min            722.15
V Predictions Mean           1370.8401
V Predictions Std            1379.0267
V Predictions Max            5197.0557
V Predictions Min            729.29034
Log Pis Mean                 -0.33794314
Log Pis Std                  4.009113
Log Pis Max                  16.838043
Log Pis Min                  -7.0609465
Policy mu Mean               0.02881328
Policy mu Std                0.8798539
Policy mu Max                3.101624
Policy mu Min                -2.6894007
Policy log std Mean          -0.48432097
Policy log std Std           0.29446903
Policy log std Max           -0.096861094
Policy log std Min           -2.9694843
Z mean eval                  2.48939
Z variance eval              0.03929499
total_rewards                [11205.68212993 11321.56796916 11297.67128965  8745.24087683
 10667.7421983  11226.69309621 10903.52757471 10905.09388328
 11204.54891071 11230.91894169]
total_rewards_mean           10870.868687045171
total_rewards_std            736.6662717080311
total_rewards_max            11321.567969159434
total_rewards_min            8745.240876826458
Number of train steps total  1640000
Number of env steps total    4922000
Number of rollouts total     0
Train Time (s)               193.4416142879054
(Previous) Eval Time (s)     31.882163624744862
Sample Time (s)              6.103965613991022
Epoch Time (s)               231.42774352664128
Total Train Time (s)         95206.55848311028
Epoch                        409
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:03:30.561644 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #409 | Epoch Duration: 231.52129650115967
2020-01-14 02:03:30.561814 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4905255
Z variance train             0.03940975
KL Divergence                54.527615
KL Loss                      5.4527617
QF Loss                      336.199
VF Loss                      115.168015
Policy Loss                  -1408.8032
Q Predictions Mean           1404.9517
Q Predictions Std            1379.5549
Q Predictions Max            5139.67
Q Predictions Min            699.96533
V Predictions Mean           1408.3252
V Predictions Std            1388.7137
V Predictions Max            5157.671
V Predictions Min            693.4718
Log Pis Mean                 -0.18084861
Log Pis Std                  4.0488563
Log Pis Max                  21.816734
Log Pis Min                  -7.787489
Policy mu Mean               0.028764367
Policy mu Std                0.90009147
Policy mu Max                2.5344064
Policy mu Min                -5.52079
Policy log std Mean          -0.4905107
Policy log std Std           0.26813123
Policy log std Max           0.028084755
Policy log std Min           -2.9764156
Z mean eval                  2.5329897
Z variance eval              0.035366528
total_rewards                [11349.20891975 11261.19394412 11285.57692102 11200.86222321
 11311.22269553 11170.74696045 11425.02993025 11256.82777538
 11428.03946931 11088.00956421]
total_rewards_mean           11277.671840320767
total_rewards_std            102.29416246170696
total_rewards_max            11428.039469311594
total_rewards_min            11088.00956420525
Number of train steps total  1644000
Number of env steps total    4934000
Number of rollouts total     0
Train Time (s)               196.53771263128147
(Previous) Eval Time (s)     33.1801393032074
Sample Time (s)              7.623186373151839
Epoch Time (s)               237.3410383076407
Total Train Time (s)         95443.97991088545
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:07:27.989165 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #410 | Epoch Duration: 237.42720699310303
2020-01-14 02:07:27.989366 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5329328
Z variance train             0.035301216
KL Divergence                53.42374
KL Loss                      5.3423743
QF Loss                      333.2624
VF Loss                      69.534035
Policy Loss                  -1603.1199
Q Predictions Mean           1598.8015
Q Predictions Std            1565.2485
Q Predictions Max            5153.933
Q Predictions Min            715.0607
V Predictions Mean           1599.8606
V Predictions Std            1560.6599
V Predictions Max            5118.8296
V Predictions Min            716.3394
Log Pis Mean                 0.25835925
Log Pis Std                  4.7190895
Log Pis Max                  17.896212
Log Pis Min                  -6.2452893
Policy mu Mean               0.045682415
Policy mu Std                0.9634645
Policy mu Max                3.7123432
Policy mu Min                -3.1494617
Policy log std Mean          -0.51341057
Policy log std Std           0.31362408
Policy log std Max           -0.07319522
Policy log std Min           -3.4717891
Z mean eval                  2.509277
Z variance eval              0.043357335
total_rewards                [11176.67359146 11441.57289033 11293.2040109  10987.97151325
 11524.34776822 11500.9385665  11190.26056872 11105.88832476
 11326.32233053 11334.10966377]
total_rewards_mean           11288.128922843756
total_rewards_std            165.38974324671736
total_rewards_max            11524.347768222306
total_rewards_min            10987.971513246737
Number of train steps total  1648000
Number of env steps total    4946000
Number of rollouts total     0
Train Time (s)               193.05485553760082
(Previous) Eval Time (s)     32.72194261895493
Sample Time (s)              8.179851696360856
Epoch Time (s)               233.9566498529166
Total Train Time (s)         95678.0298563377
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:11:22.043075 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #411 | Epoch Duration: 234.05355668067932
2020-01-14 02:11:22.043270 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.509892
Z variance train             0.043174982
KL Divergence                55.446182
KL Loss                      5.544618
QF Loss                      4770.1084
VF Loss                      41.31421
Policy Loss                  -1447.2639
Q Predictions Mean           1443.0009
Q Predictions Std            1458.2461
Q Predictions Max            5177.946
Q Predictions Min            713.35364
V Predictions Mean           1448.6097
V Predictions Std            1457.3485
V Predictions Max            5147.8623
V Predictions Min            716.42523
Log Pis Mean                 -0.29998156
Log Pis Std                  4.081276
Log Pis Max                  15.831766
Log Pis Min                  -9.808423
Policy mu Mean               0.115054876
Policy mu Std                0.88232595
Policy mu Max                2.8514717
Policy mu Min                -2.8058715
Policy log std Mean          -0.48671412
Policy log std Std           0.27655658
Policy log std Max           -0.04795623
Policy log std Min           -2.580625
Z mean eval                  2.511787
Z variance eval              0.023769144
total_rewards                [ 8516.7646089  11319.71482143 11561.87962853  3776.34639375
 10761.18200908 11242.58768664 11389.90922531 11401.68266225
 11662.54983312 11570.87508769]
total_rewards_mean           10320.349195668727
total_rewards_std            2352.454785691665
total_rewards_max            11662.549833119947
total_rewards_min            3776.3463937455926
Number of train steps total  1652000
Number of env steps total    4958000
Number of rollouts total     0
Train Time (s)               197.528543967288
(Previous) Eval Time (s)     34.43386260699481
Sample Time (s)              7.231582007370889
Epoch Time (s)               239.19398858165368
Total Train Time (s)         95917.30387901515
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:15:21.326444 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #412 | Epoch Duration: 239.28303384780884
2020-01-14 02:15:21.326624 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5128822
Z variance train             0.02380201
KL Divergence                55.253166
KL Loss                      5.5253167
QF Loss                      200.98029
VF Loss                      64.967285
Policy Loss                  -1404.3167
Q Predictions Mean           1403.4606
Q Predictions Std            1440.6547
Q Predictions Max            5066.3276
Q Predictions Min            678.1421
V Predictions Mean           1403.5923
V Predictions Std            1434.5917
V Predictions Max            5080.338
V Predictions Min            679.9143
Log Pis Mean                 -0.05224833
Log Pis Std                  4.1617002
Log Pis Max                  17.680687
Log Pis Min                  -6.9419913
Policy mu Mean               0.07515905
Policy mu Std                0.9293632
Policy mu Max                3.1905203
Policy mu Min                -2.7108493
Policy log std Mean          -0.47729495
Policy log std Std           0.2668806
Policy log std Max           0.16740632
Policy log std Min           -2.7346585
Z mean eval                  2.5296268
Z variance eval              0.02758803
total_rewards                [10726.33150678 11222.19662588 11410.03968489 10438.58519842
  3510.58444056  5936.43654828 10816.74467913  1443.69155924
 10364.78134553 10900.20242612]
total_rewards_mean           8676.959401483222
total_rewards_std            3466.1723090128553
total_rewards_max            11410.039684888865
total_rewards_min            1443.6915592386422
Number of train steps total  1656000
Number of env steps total    4970000
Number of rollouts total     0
Train Time (s)               196.63525769207627
(Previous) Eval Time (s)     31.227008334826678
Sample Time (s)              7.347381724044681
Epoch Time (s)               235.20964775094762
Total Train Time (s)         96152.61802610615
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:19:16.646578 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #413 | Epoch Duration: 235.319806098938
2020-01-14 02:19:16.646776 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.528852
Z variance train             0.027522799
KL Divergence                55.376965
KL Loss                      5.5376964
QF Loss                      186.68681
VF Loss                      82.37755
Policy Loss                  -1476.6061
Q Predictions Mean           1473.6665
Q Predictions Std            1520.6769
Q Predictions Max            5209.744
Q Predictions Min            726.08514
V Predictions Mean           1479.2368
V Predictions Std            1524.3385
V Predictions Max            5231.385
V Predictions Min            729.4793
Log Pis Mean                 -0.480377
Log Pis Std                  4.295023
Log Pis Max                  18.82125
Log Pis Min                  -7.9612207
Policy mu Mean               0.041629106
Policy mu Std                0.8841017
Policy mu Max                3.1457782
Policy mu Min                -3.5389802
Policy log std Mean          -0.4876891
Policy log std Std           0.30106384
Policy log std Max           0.023014188
Policy log std Min           -2.7871547
Z mean eval                  2.5121796
Z variance eval              0.0351615
total_rewards                [11110.62820362 11253.61032762 10661.37574446 11261.42237915
 11072.92291449 11055.08649011 11170.42644685 10886.22633717
 11064.27325664  9672.27047184]
total_rewards_mean           10920.824257196331
total_rewards_std            448.80012326750204
total_rewards_max            11261.422379154636
total_rewards_min            9672.270471840553
Number of train steps total  1660000
Number of env steps total    4982000
Number of rollouts total     0
Train Time (s)               194.12343753920868
(Previous) Eval Time (s)     31.22538141719997
Sample Time (s)              6.035093293525279
Epoch Time (s)               231.38391224993393
Total Train Time (s)         96384.08697695425
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:23:08.123009 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #414 | Epoch Duration: 231.47605633735657
2020-01-14 02:23:08.123268 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #414 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5126805
Z variance train             0.035228506
KL Divergence                54.496796
KL Loss                      5.44968
QF Loss                      170.98575
VF Loss                      75.80412
Policy Loss                  -1372.339
Q Predictions Mean           1371.9318
Q Predictions Std            1403.2006
Q Predictions Max            5198.0283
Q Predictions Min            697.1661
V Predictions Mean           1370.1047
V Predictions Std            1402.2896
V Predictions Max            5222.229
V Predictions Min            696.9109
Log Pis Mean                 -0.5509031
Log Pis Std                  3.5162628
Log Pis Max                  15.230158
Log Pis Min                  -6.905041
Policy mu Mean               0.08183811
Policy mu Std                0.8370955
Policy mu Max                2.6659353
Policy mu Min                -2.9630089
Policy log std Mean          -0.49235073
Policy log std Std           0.27294096
Policy log std Max           0.15639395
Policy log std Min           -2.6548557
Z mean eval                  2.516668
Z variance eval              0.05001413
total_rewards                [11216.14055637 11296.48024375  6949.84776046 10633.6593832
 10934.62289797  5513.06098521 10889.06807697 11065.38855948
 10722.64979649 10835.3553126 ]
total_rewards_mean           10005.627357250729
total_rewards_std            1923.9587532145642
total_rewards_max            11296.480243749113
total_rewards_min            5513.060985210717
Number of train steps total  1664000
Number of env steps total    4994000
Number of rollouts total     0
Train Time (s)               197.3890935932286
(Previous) Eval Time (s)     32.538646599743515
Sample Time (s)              7.961720374412835
Epoch Time (s)               237.88946056738496
Total Train Time (s)         96622.05943623139
Epoch                        415
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:27:06.098558 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #415 | Epoch Duration: 237.9751000404358
2020-01-14 02:27:06.098751 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.518147
Z variance train             0.04957428
KL Divergence                54.62009
KL Loss                      5.462009
QF Loss                      319.01605
VF Loss                      117.95497
Policy Loss                  -1268.8834
Q Predictions Mean           1264.7615
Q Predictions Std            1288.6687
Q Predictions Max            5128.966
Q Predictions Min            694.5396
V Predictions Mean           1266.1389
V Predictions Std            1290.2604
V Predictions Max            5109.1953
V Predictions Min            699.82416
Log Pis Mean                 -0.43644577
Log Pis Std                  4.2102304
Log Pis Max                  21.837475
Log Pis Min                  -7.55348
Policy mu Mean               0.13666892
Policy mu Std                0.85468525
Policy mu Max                3.629797
Policy mu Min                -3.3024037
Policy log std Mean          -0.47778258
Policy log std Std           0.27032104
Policy log std Max           -0.028827667
Policy log std Min           -3.0614054
Z mean eval                  2.5153556
Z variance eval              0.06743874
total_rewards                [11330.51690803 11651.99093796 11205.98324464 10834.73912772
 11460.62177821 11362.09251107 11351.05798786 11434.71530219
 11644.39780493 11499.62505712]
total_rewards_mean           11377.574065974077
total_rewards_std            223.3446557090181
total_rewards_max            11651.990937961315
total_rewards_min            10834.739127718029
Number of train steps total  1668000
Number of env steps total    5006000
Number of rollouts total     0
Train Time (s)               192.6538802748546
(Previous) Eval Time (s)     30.798313457984477
Sample Time (s)              7.184132075402886
Epoch Time (s)               230.63632580824196
Total Train Time (s)         96852.78384144139
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:30:56.827565 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #416 | Epoch Duration: 230.7286021709442
2020-01-14 02:30:56.827901 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #416 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5150185
Z variance train             0.06715517
KL Divergence                54.967587
KL Loss                      5.496759
QF Loss                      142.65108
VF Loss                      90.92039
Policy Loss                  -1465.3411
Q Predictions Mean           1464.3325
Q Predictions Std            1447.9458
Q Predictions Max            5064.0615
Q Predictions Min            695.7965
V Predictions Mean           1466.8599
V Predictions Std            1445.4963
V Predictions Max            5076.196
V Predictions Min            707.3632
Log Pis Mean                 -0.057446167
Log Pis Std                  4.3150573
Log Pis Max                  19.08892
Log Pis Min                  -7.5076756
Policy mu Mean               0.033814717
Policy mu Std                0.9391655
Policy mu Max                3.1090305
Policy mu Min                -2.8877294
Policy log std Mean          -0.49079445
Policy log std Std           0.27787194
Policy log std Max           -0.043898582
Policy log std Min           -2.5838938
Z mean eval                  2.56663
Z variance eval              0.06945467
total_rewards                [10736.43058273  9933.13238022  1982.28465026  6805.28258915
 11215.63241209 11024.70184921 10924.36038413 10875.401274
 10585.76216113  2537.67351452]
total_rewards_mean           8662.066179743833
total_rewards_std            3425.114456616532
total_rewards_max            11215.632412086914
total_rewards_min            1982.2846502603716
Number of train steps total  1672000
Number of env steps total    5018000
Number of rollouts total     0
Train Time (s)               194.89637760072947
(Previous) Eval Time (s)     30.391600731760263
Sample Time (s)              7.573978136759251
Epoch Time (s)               232.86195646924898
Total Train Time (s)         97085.72796435747
Epoch                        417
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:34:49.780618 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #417 | Epoch Duration: 232.95250844955444
2020-01-14 02:34:49.780832 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #417 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5705144
Z variance train             0.0694048
KL Divergence                55.246235
KL Loss                      5.5246234
QF Loss                      66.10615
VF Loss                      160.04861
Policy Loss                  -1436.0092
Q Predictions Mean           1435.2738
Q Predictions Std            1461.6261
Q Predictions Max            5178.469
Q Predictions Min            722.63873
V Predictions Mean           1427.8721
V Predictions Std            1450.877
V Predictions Max            5146.444
V Predictions Min            716.4982
Log Pis Mean                 -0.50763303
Log Pis Std                  3.815023
Log Pis Max                  13.41562
Log Pis Min                  -7.785285
Policy mu Mean               0.05146521
Policy mu Std                0.8580992
Policy mu Max                2.4556484
Policy mu Min                -2.504518
Policy log std Mean          -0.48943123
Policy log std Std           0.26254466
Policy log std Max           -0.0055612028
Policy log std Min           -2.4771652
Z mean eval                  2.5325007
Z variance eval              0.082518086
total_rewards                [ 4506.21485714 11034.03581624 10638.89285891 10864.7087928
 10889.8248457  10979.41267809  3976.35064959 11495.43331076
 10708.2049998  11056.151057  ]
total_rewards_mean           9614.922986602982
total_rewards_std            2698.3826025004964
total_rewards_max            11495.433310757106
total_rewards_min            3976.3506495918004
Number of train steps total  1676000
Number of env steps total    5030000
Number of rollouts total     0
Train Time (s)               191.03812054777518
(Previous) Eval Time (s)     33.79226175323129
Sample Time (s)              7.834176569711417
Epoch Time (s)               232.66455887071788
Total Train Time (s)         97318.47512278054
Epoch                        418
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:38:42.532004 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #418 | Epoch Duration: 232.75094604492188
2020-01-14 02:38:42.532295 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.533581
Z variance train             0.082569435
KL Divergence                54.566925
KL Loss                      5.4566927
QF Loss                      284.80423
VF Loss                      384.5428
Policy Loss                  -1481.1487
Q Predictions Mean           1479.6791
Q Predictions Std            1506.7646
Q Predictions Max            5247.5386
Q Predictions Min            723.941
V Predictions Mean           1470.7148
V Predictions Std            1491.6517
V Predictions Max            5182.592
V Predictions Min            714.625
Log Pis Mean                 -0.22873938
Log Pis Std                  4.255933
Log Pis Max                  14.601856
Log Pis Min                  -6.413446
Policy mu Mean               0.01318846
Policy mu Std                0.93024784
Policy mu Max                3.0028
Policy mu Min                -2.8649685
Policy log std Mean          -0.49873075
Policy log std Std           0.3148276
Policy log std Max           -0.0032064915
Policy log std Min           -2.8240151
Z mean eval                  2.5239348
Z variance eval              0.072307065
total_rewards                [11459.85120922 11458.13910879 11529.21985387 11060.61553942
 11522.99182085 11328.11020555  7024.98243174 11671.44272792
 11123.25809807 11197.74039656]
total_rewards_mean           10937.63513919993
total_rewards_std            1317.3184617264433
total_rewards_max            11671.44272792297
total_rewards_min            7024.982431738432
Number of train steps total  1680000
Number of env steps total    5042000
Number of rollouts total     0
Train Time (s)               195.49904771428555
(Previous) Eval Time (s)     31.711564789060503
Sample Time (s)              7.168350901920348
Epoch Time (s)               234.3789634052664
Total Train Time (s)         97552.93702119496
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:42:37.000489 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #419 | Epoch Duration: 234.46800780296326
2020-01-14 02:42:37.000699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5249126
Z variance train             0.07237714
KL Divergence                56.313107
KL Loss                      5.631311
QF Loss                      193.7098
VF Loss                      165.2489
Policy Loss                  -1251.3319
Q Predictions Mean           1247.2084
Q Predictions Std            1218.222
Q Predictions Max            5169.831
Q Predictions Min            727.09186
V Predictions Mean           1248.5848
V Predictions Std            1214.1713
V Predictions Max            5176.5415
V Predictions Min            730.6671
Log Pis Mean                 -0.6878511
Log Pis Std                  3.3260489
Log Pis Max                  12.708494
Log Pis Min                  -5.958128
Policy mu Mean               0.102432095
Policy mu Std                0.8258467
Policy mu Max                3.6297214
Policy mu Min                -2.8385732
Policy log std Mean          -0.49599695
Policy log std Std           0.25184885
Policy log std Max           0.060664386
Policy log std Min           -2.9934392
Z mean eval                  2.5341482
Z variance eval              0.090385176
total_rewards                [11685.60246261 11235.62093243 10900.27446165 10835.04463273
 11058.03660217  3935.7413866  11075.69460592 11483.46510278
  5709.9276445  11431.90428121]
total_rewards_mean           9935.131211261572
total_rewards_std            2598.87015955175
total_rewards_max            11685.602462613144
total_rewards_min            3935.7413866046472
Number of train steps total  1684000
Number of env steps total    5054000
Number of rollouts total     0
Train Time (s)               194.05885566864163
(Previous) Eval Time (s)     34.26483298186213
Sample Time (s)              8.516577802598476
Epoch Time (s)               236.84026645310223
Total Train Time (s)         97789.860930074
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:46:33.928114 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #420 | Epoch Duration: 236.9272482395172
2020-01-14 02:46:33.928312 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5325303
Z variance train             0.09021785
KL Divergence                55.719917
KL Loss                      5.571992
QF Loss                      767.949
VF Loss                      69.48001
Policy Loss                  -1511.8755
Q Predictions Mean           1511.6743
Q Predictions Std            1537.5238
Q Predictions Max            5215.8306
Q Predictions Min            664.1576
V Predictions Mean           1513.8582
V Predictions Std            1535.1226
V Predictions Max            5217.222
V Predictions Min            693.44244
Log Pis Mean                 0.14531535
Log Pis Std                  4.284228
Log Pis Max                  15.497154
Log Pis Min                  -6.780608
Policy mu Mean               0.06594222
Policy mu Std                0.93526673
Policy mu Max                4.4644504
Policy mu Min                -2.984704
Policy log std Mean          -0.523821
Policy log std Std           0.2862129
Policy log std Max           0.59427166
Policy log std Min           -2.7083719
Z mean eval                  2.4880745
Z variance eval              0.06324899
total_rewards                [11114.10946043 11263.94789007 11324.28017027 11542.83227895
 11044.87272835 11171.72866282 11184.43638771 11138.29596777
 11318.4378722  11100.44413433]
total_rewards_mean           11220.338555290025
total_rewards_std            138.982636983741
total_rewards_max            11542.832278948457
total_rewards_min            11044.872728345463
Number of train steps total  1688000
Number of env steps total    5066000
Number of rollouts total     0
Train Time (s)               195.33487867983058
(Previous) Eval Time (s)     30.8878488750197
Sample Time (s)              7.295740598347038
Epoch Time (s)               233.51846815319732
Total Train Time (s)         98023.4676587116
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:50:27.538881 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #421 | Epoch Duration: 233.6104176044464
2020-01-14 02:50:27.539059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #421 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.488872
Z variance train             0.0632744
KL Divergence                52.98403
KL Loss                      5.2984033
QF Loss                      4497.539
VF Loss                      80.30613
Policy Loss                  -1422.5565
Q Predictions Mean           1419.1304
Q Predictions Std            1437.8597
Q Predictions Max            5023.9385
Q Predictions Min            660.3105
V Predictions Mean           1420.4431
V Predictions Std            1430.8655
V Predictions Max            4996.21
V Predictions Min            660.8756
Log Pis Mean                 -0.39918387
Log Pis Std                  3.3091342
Log Pis Max                  12.679476
Log Pis Min                  -7.995354
Policy mu Mean               0.06853006
Policy mu Std                0.8683622
Policy mu Max                3.6446567
Policy mu Min                -2.7286901
Policy log std Mean          -0.5012696
Policy log std Std           0.2607223
Policy log std Max           -0.0395436
Policy log std Min           -3.0448663
Z mean eval                  2.4901268
Z variance eval              0.10251576
total_rewards                [11099.87135251  3759.16333766 10842.02576885 10602.9658074
 10969.17355132  9722.92808801 10838.72415373 11408.34031213
 10800.95323791 10681.72556739]
total_rewards_mean           10072.587117690833
total_rewards_std            2144.4549003923776
total_rewards_max            11408.340312127493
total_rewards_min            3759.163337662507
Number of train steps total  1692000
Number of env steps total    5078000
Number of rollouts total     0
Train Time (s)               198.39474669098854
(Previous) Eval Time (s)     35.497298730071634
Sample Time (s)              7.21625997312367
Epoch Time (s)               241.10830539418384
Total Train Time (s)         98264.67581758229
Epoch                        422
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:54:28.750761 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #422 | Epoch Duration: 241.21156811714172
2020-01-14 02:54:28.750931 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #422 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4896758
Z variance train             0.102353714
KL Divergence                51.159397
KL Loss                      5.1159396
QF Loss                      131.41837
VF Loss                      47.559067
Policy Loss                  -1439.8829
Q Predictions Mean           1436.8057
Q Predictions Std            1433.4374
Q Predictions Max            5186.272
Q Predictions Min            711.65204
V Predictions Mean           1439.0166
V Predictions Std            1428.6416
V Predictions Max            5167.7754
V Predictions Min            710.0962
Log Pis Mean                 -0.33985093
Log Pis Std                  3.930597
Log Pis Max                  15.972582
Log Pis Min                  -6.9092975
Policy mu Mean               0.04157387
Policy mu Std                0.87816554
Policy mu Max                3.2548795
Policy mu Min                -2.4288712
Policy log std Mean          -0.48715124
Policy log std Std           0.288512
Policy log std Max           0.014120579
Policy log std Min           -2.6688356
Z mean eval                  2.4926846
Z variance eval              0.07741349
total_rewards                [10978.7732896  10741.28096749  7761.53604389 10760.04644619
 11094.46994176  7944.43027402  2075.69737435 11135.67560192
  8819.39058054 11016.90943267]
total_rewards_mean           9232.820995242837
total_rewards_std            2704.5472038396188
total_rewards_max            11135.675601920297
total_rewards_min            2075.697374351096
Number of train steps total  1696000
Number of env steps total    5090000
Number of rollouts total     0
Train Time (s)               193.42903529386967
(Previous) Eval Time (s)     29.093492029234767
Sample Time (s)              7.309333990793675
Epoch Time (s)               229.83186131389812
Total Train Time (s)         98494.59258709941
Epoch                        423
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:58:18.671501 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #423 | Epoch Duration: 229.92043328285217
2020-01-14 02:58:18.671696 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #423 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4938114
Z variance train             0.07741854
KL Divergence                51.946438
KL Loss                      5.194644
QF Loss                      4395.842
VF Loss                      249.55609
Policy Loss                  -1510.4031
Q Predictions Mean           1507.8813
Q Predictions Std            1505.5114
Q Predictions Max            5204.9287
Q Predictions Min            714.833
V Predictions Mean           1516.6919
V Predictions Std            1508.4863
V Predictions Max            5151.34
V Predictions Min            719.3689
Log Pis Mean                 0.11517542
Log Pis Std                  4.2464256
Log Pis Max                  17.177475
Log Pis Min                  -10.754647
Policy mu Mean               0.006502509
Policy mu Std                0.961208
Policy mu Max                3.6832774
Policy mu Min                -2.9490726
Policy log std Mean          -0.5019815
Policy log std Std           0.3011217
Policy log std Max           0.05950892
Policy log std Min           -2.7990885
Z mean eval                  2.511744
Z variance eval              0.050408196
total_rewards                [10753.80971107 11287.30111598 11292.29800162 10898.18664352
 10878.79408818 11104.14809803 11114.70132387 10753.5902181
 10689.66687164 10830.46536025]
total_rewards_mean           10960.296143225853
total_rewards_std            211.57793524271548
total_rewards_max            11292.298001623258
total_rewards_min            10689.666871643622
Number of train steps total  1700000
Number of env steps total    5102000
Number of rollouts total     0
Train Time (s)               193.2073195418343
(Previous) Eval Time (s)     32.2033485150896
Sample Time (s)              6.978622226975858
Epoch Time (s)               232.38929028389975
Total Train Time (s)         98727.10943350289
Epoch                        424
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:02:11.192391 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #424 | Epoch Duration: 232.52054286003113
2020-01-14 03:02:11.192587 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #424 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5066633
Z variance train             0.05039333
KL Divergence                53.73637
KL Loss                      5.373637
QF Loss                      228.42456
VF Loss                      96.33457
Policy Loss                  -1432.739
Q Predictions Mean           1429.3242
Q Predictions Std            1487.8546
Q Predictions Max            5213.3354
Q Predictions Min            679.2306
V Predictions Mean           1436.5918
V Predictions Std            1484.7742
V Predictions Max            5207.9395
V Predictions Min            703.35724
Log Pis Mean                 0.20007253
Log Pis Std                  4.8220453
Log Pis Max                  23.252043
Log Pis Min                  -6.5256033
Policy mu Mean               0.09826294
Policy mu Std                0.9534863
Policy mu Max                3.5030882
Policy mu Min                -3.7301593
Policy log std Mean          -0.49045324
Policy log std Std           0.31104013
Policy log std Max           0.079830885
Policy log std Min           -2.9108737
Z mean eval                  2.5169506
Z variance eval              0.08050097
total_rewards                [11532.20382987 11366.42164048 11072.68214745 11384.86761746
 11093.92558535 11426.58521588 11273.42520856 11462.90690324
 11554.900406   11601.70695592]
total_rewards_mean           11376.962551020893
total_rewards_std            173.1215448935619
total_rewards_max            11601.70695591809
total_rewards_min            11072.682147448248
Number of train steps total  1704000
Number of env steps total    5114000
Number of rollouts total     0
Train Time (s)               193.3224603771232
(Previous) Eval Time (s)     31.092821224126965
Sample Time (s)              7.213358823675662
Epoch Time (s)               231.62864042492583
Total Train Time (s)         98958.82251572283
Epoch                        425
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:06:02.914215 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #425 | Epoch Duration: 231.72148871421814
2020-01-14 03:06:02.914388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5175538
Z variance train             0.08050082
KL Divergence                52.961094
KL Loss                      5.2961097
QF Loss                      295.47388
VF Loss                      58.32957
Policy Loss                  -1495.6863
Q Predictions Mean           1491.6674
Q Predictions Std            1494.485
Q Predictions Max            5047.1157
Q Predictions Min            661.93695
V Predictions Mean           1491.8553
V Predictions Std            1489.6733
V Predictions Max            5038.0703
V Predictions Min            664.0241
Log Pis Mean                 0.15911078
Log Pis Std                  4.472316
Log Pis Max                  19.610096
Log Pis Min                  -6.432229
Policy mu Mean               -0.004399616
Policy mu Std                0.94600964
Policy mu Max                2.920981
Policy mu Min                -3.8665924
Policy log std Mean          -0.505387
Policy log std Std           0.2963122
Policy log std Max           -0.06624055
Policy log std Min           -2.7216554
Z mean eval                  2.5168347
Z variance eval              0.04275597
total_rewards                [11021.76377205 11540.90631066 11055.26629442 11233.11400493
 11368.1448941  11200.45200033 11428.92507816 11248.75640664
 11614.52351032 11423.30791026]
total_rewards_mean           11313.516018186885
total_rewards_std            185.99025144150977
total_rewards_max            11614.52351032145
total_rewards_min            11021.763772049624
Number of train steps total  1708000
Number of env steps total    5126000
Number of rollouts total     0
Train Time (s)               194.68207630701363
(Previous) Eval Time (s)     29.9608397022821
Sample Time (s)              7.228863887488842
Epoch Time (s)               231.87177989678457
Total Train Time (s)         99190.78595345514
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:09:54.884896 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #426 | Epoch Duration: 231.97033500671387
2020-01-14 03:09:54.885162 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5175972
Z variance train             0.04268198
KL Divergence                54.186874
KL Loss                      5.4186873
QF Loss                      184.5436
VF Loss                      44.534325
Policy Loss                  -1361.0193
Q Predictions Mean           1355.703
Q Predictions Std            1345.7549
Q Predictions Max            5254.1978
Q Predictions Min            700.87616
V Predictions Mean           1358.1538
V Predictions Std            1344.5548
V Predictions Max            5240.47
V Predictions Min            701.5993
Log Pis Mean                 -0.1500084
Log Pis Std                  4.416239
Log Pis Max                  18.540903
Log Pis Min                  -7.102665
Policy mu Mean               0.07583039
Policy mu Std                0.9056942
Policy mu Max                3.4531014
Policy mu Min                -4.3814764
Policy log std Mean          -0.4787414
Policy log std Std           0.29576707
Policy log std Max           0.0036312342
Policy log std Min           -2.921124
Z mean eval                  2.481018
Z variance eval              0.05297628
total_rewards                [11099.69290789 10883.2730128   2117.18496804 10756.10677695
 10850.60331844  8061.32351265 10867.96495907 11102.61055211
  4664.1905403  10956.1791165 ]
total_rewards_mean           9135.912966475193
total_rewards_std            3050.7334986650267
total_rewards_max            11102.610552109547
total_rewards_min            2117.1849680430832
Number of train steps total  1712000
Number of env steps total    5138000
Number of rollouts total     0
Train Time (s)               192.06535433605313
(Previous) Eval Time (s)     34.22125215083361
Sample Time (s)              7.646036591380835
Epoch Time (s)               233.93264307826757
Total Train Time (s)         99424.81223457819
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:13:48.914772 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #427 | Epoch Duration: 234.02941870689392
2020-01-14 03:13:48.914945 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4792614
Z variance train             0.052960895
KL Divergence                53.61436
KL Loss                      5.3614364
QF Loss                      170.07648
VF Loss                      127.78687
Policy Loss                  -1485.2512
Q Predictions Mean           1480.5154
Q Predictions Std            1471.7764
Q Predictions Max            5283.377
Q Predictions Min            725.49896
V Predictions Mean           1488.1296
V Predictions Std            1473.8782
V Predictions Max            5311.881
V Predictions Min            733.9347
Log Pis Mean                 0.10462944
Log Pis Std                  4.0647883
Log Pis Max                  20.329449
Log Pis Min                  -5.997462
Policy mu Mean               0.06958382
Policy mu Std                0.9076967
Policy mu Max                3.2397668
Policy mu Min                -2.8671503
Policy log std Mean          -0.48188257
Policy log std Std           0.30911148
Policy log std Max           -0.013256609
Policy log std Min           -3.1247518
Z mean eval                  2.5970707
Z variance eval              0.0913329
total_rewards                [11098.43132444 11352.560668   10879.9556076  11413.49268905
 11592.19483527 11237.82574823 10774.55984933 10700.71387023
 11211.28746372 11789.58131595]
total_rewards_mean           11205.06033718141
total_rewards_std            333.8576787661867
total_rewards_max            11789.581315945035
total_rewards_min            10700.71387023436
Number of train steps total  1716000
Number of env steps total    5150000
Number of rollouts total     0
Train Time (s)               194.22673176415265
(Previous) Eval Time (s)     31.51151157170534
Sample Time (s)              7.033685442991555
Epoch Time (s)               232.77192877884954
Total Train Time (s)         99657.6650708043
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:17:41.771842 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #428 | Epoch Duration: 232.85675930976868
2020-01-14 03:17:41.772082 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5960464
Z variance train             0.09268276
KL Divergence                55.001316
KL Loss                      5.5001316
QF Loss                      662.0784
VF Loss                      332.01733
Policy Loss                  -1344.9762
Q Predictions Mean           1348.8625
Q Predictions Std            1387.5535
Q Predictions Max            5148.585
Q Predictions Min            722.4481
V Predictions Mean           1350.102
V Predictions Std            1377.8596
V Predictions Max            5188.833
V Predictions Min            717.1486
Log Pis Mean                 -0.6368421
Log Pis Std                  3.8746967
Log Pis Max                  23.485527
Log Pis Min                  -8.630578
Policy mu Mean               0.07978491
Policy mu Std                0.85334414
Policy mu Max                5.3221564
Policy mu Min                -2.3913398
Policy log std Mean          -0.48232093
Policy log std Std           0.2677672
Policy log std Max           0.07653123
Policy log std Min           -2.627962
Z mean eval                  2.5096428
Z variance eval              0.07326502
total_rewards                [11064.55151076 11273.31235141 11188.92051003 11078.05565124
 11172.19264946 11391.43826028 11119.01398505 11203.64610899
 11457.93774539 10997.02548226]
total_rewards_mean           11194.609425486113
total_rewards_std            137.89416622298006
total_rewards_max            11457.937745386944
total_rewards_min            10997.025482255716
Number of train steps total  1720000
Number of env steps total    5162000
Number of rollouts total     0
Train Time (s)               194.6658871411346
(Previous) Eval Time (s)     33.08391015883535
Sample Time (s)              6.978383996058255
Epoch Time (s)               234.7281812960282
Total Train Time (s)         99892.47606738284
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:21:36.586982 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #429 | Epoch Duration: 234.81474685668945
2020-01-14 03:21:36.587174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5047498
Z variance train             0.07322687
KL Divergence                54.776268
KL Loss                      5.477627
QF Loss                      180.12666
VF Loss                      147.67299
Policy Loss                  -1412.5087
Q Predictions Mean           1411.8784
Q Predictions Std            1404.9852
Q Predictions Max            5130.911
Q Predictions Min            697.5725
V Predictions Mean           1413.2509
V Predictions Std            1409.605
V Predictions Max            5158.8013
V Predictions Min            703.1217
Log Pis Mean                 -0.27069607
Log Pis Std                  3.8172758
Log Pis Max                  15.031842
Log Pis Min                  -6.286496
Policy mu Mean               -0.0014452705
Policy mu Std                0.8585801
Policy mu Max                2.4928706
Policy mu Min                -2.8767295
Policy log std Mean          -0.4957703
Policy log std Std           0.26659173
Policy log std Max           -0.061879724
Policy log std Min           -2.669877
Z mean eval                  2.5194414
Z variance eval              0.058330454
total_rewards                [10653.60569599 10856.2369812  10709.60023083 10775.46469586
 10846.33189605 10893.06920746 10700.36661967 10838.08163937
 10717.34729797 10503.55409173]
total_rewards_mean           10749.36583561377
total_rewards_std            111.63646047290405
total_rewards_max            10893.069207458626
total_rewards_min            10503.554091732316
Number of train steps total  1724000
Number of env steps total    5174000
Number of rollouts total     0
Train Time (s)               195.1020242436789
(Previous) Eval Time (s)     32.02799603296444
Sample Time (s)              8.33804649533704
Epoch Time (s)               235.46806677198038
Total Train Time (s)         100128.03297680616
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:25:32.172753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #430 | Epoch Duration: 235.585444688797
2020-01-14 03:25:32.172921 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5165334
Z variance train             0.058245085
KL Divergence                54.72991
KL Loss                      5.4729915
QF Loss                      839.7977
VF Loss                      57.87168
Policy Loss                  -1469.2545
Q Predictions Mean           1466.5864
Q Predictions Std            1454.7484
Q Predictions Max            5268.9023
Q Predictions Min            733.51196
V Predictions Mean           1467.3582
V Predictions Std            1453.7186
V Predictions Max            5236.4644
V Predictions Min            742.3007
Log Pis Mean                 -0.12551261
Log Pis Std                  3.976705
Log Pis Max                  12.734493
Log Pis Min                  -7.8507347
Policy mu Mean               0.056078527
Policy mu Std                0.91160244
Policy mu Max                2.6168478
Policy mu Min                -2.567656
Policy log std Mean          -0.5027695
Policy log std Std           0.29994422
Policy log std Max           -0.019307315
Policy log std Min           -2.8545065
Z mean eval                  2.4971895
Z variance eval              0.072749674
total_rewards                [11540.25512476 10926.9222234  11424.02358216 11166.69917019
 11123.34863262 10820.67084996 11318.12708986  6996.65436242
 11054.91698261 11404.5257873 ]
total_rewards_mean           10777.614380527944
total_rewards_std            1278.7595118451316
total_rewards_max            11540.255124760304
total_rewards_min            6996.654362423976
Number of train steps total  1728000
Number of env steps total    5186000
Number of rollouts total     0
Train Time (s)               191.4491384900175
(Previous) Eval Time (s)     32.239063533023
Sample Time (s)              7.270269462373108
Epoch Time (s)               230.9584714854136
Total Train Time (s)         100359.07334857062
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:29:23.217234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #431 | Epoch Duration: 231.0441768169403
2020-01-14 03:29:23.217426 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #431 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5004363
Z variance train             0.0724125
KL Divergence                55.107185
KL Loss                      5.510719
QF Loss                      1968.3103
VF Loss                      597.186
Policy Loss                  -1389.0078
Q Predictions Mean           1389.4529
Q Predictions Std            1414.5061
Q Predictions Max            5199.7
Q Predictions Min            691.23047
V Predictions Mean           1397.1189
V Predictions Std            1427.0365
V Predictions Max            5212.1035
V Predictions Min            698.5738
Log Pis Mean                 -0.31349534
Log Pis Std                  4.079945
Log Pis Max                  14.324384
Log Pis Min                  -8.376291
Policy mu Mean               0.093747705
Policy mu Std                0.90837294
Policy mu Max                2.849492
Policy mu Min                -2.6539047
Policy log std Mean          -0.50159097
Policy log std Std           0.28775817
Policy log std Max           0.1497519
Policy log std Min           -2.8265152
Z mean eval                  2.4983282
Z variance eval              0.056106996
total_rewards                [11070.70178886 11343.98481    11368.90945866 11408.16816843
 11060.22558416 11161.51601095 11250.21748625 11362.42582714
 11408.92797116 11329.45661337]
total_rewards_mean           11276.453371895179
total_rewards_std            126.96244547281586
total_rewards_max            11408.927971159826
total_rewards_min            11060.225584156326
Number of train steps total  1732000
Number of env steps total    5198000
Number of rollouts total     0
Train Time (s)               194.45337448595092
(Previous) Eval Time (s)     34.34483598778024
Sample Time (s)              6.600752792786807
Epoch Time (s)               235.39896326651797
Total Train Time (s)         100594.55388562242
Epoch                        432
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:33:18.708202 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #432 | Epoch Duration: 235.4906063079834
2020-01-14 03:33:18.708361 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.498213
Z variance train             0.055968575
KL Divergence                55.72381
KL Loss                      5.572381
QF Loss                      325.51895
VF Loss                      28.528906
Policy Loss                  -1422.1592
Q Predictions Mean           1418.7634
Q Predictions Std            1433.36
Q Predictions Max            5152.8945
Q Predictions Min            713.03613
V Predictions Mean           1419.9135
V Predictions Std            1429.0656
V Predictions Max            5159.8223
V Predictions Min            705.60614
Log Pis Mean                 -0.112438574
Log Pis Std                  4.3290224
Log Pis Max                  19.07614
Log Pis Min                  -7.1523266
Policy mu Mean               0.051000174
Policy mu Std                0.9374249
Policy mu Max                3.4042373
Policy mu Min                -3.67081
Policy log std Mean          -0.5006121
Policy log std Std           0.29714274
Policy log std Max           0.33308566
Policy log std Min           -2.8678348
Z mean eval                  2.5215232
Z variance eval              0.06939349
total_rewards                [10868.55230763 11295.56963766 10479.63059483 11258.92805968
 11308.88304165 10854.35242329 11194.50381515 11048.38784958
 11449.57543938 10932.78002161]
total_rewards_mean           11069.116319043607
total_rewards_std            275.341420455315
total_rewards_max            11449.575439376718
total_rewards_min            10479.630594826951
Number of train steps total  1736000
Number of env steps total    5210000
Number of rollouts total     0
Train Time (s)               194.82470015110448
(Previous) Eval Time (s)     32.58889566920698
Sample Time (s)              7.280462872702628
Epoch Time (s)               234.69405869301409
Total Train Time (s)         100829.32891711965
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:37:13.487881 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #433 | Epoch Duration: 234.77940034866333
2020-01-14 03:37:13.488110 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5190856
Z variance train             0.069438055
KL Divergence                55.709988
KL Loss                      5.5709987
QF Loss                      98.48986
VF Loss                      38.664112
Policy Loss                  -1434.3074
Q Predictions Mean           1434.3997
Q Predictions Std            1469.2743
Q Predictions Max            5190.093
Q Predictions Min            702.1836
V Predictions Mean           1438.2318
V Predictions Std            1467.2108
V Predictions Max            5192.9746
V Predictions Min            705.0172
Log Pis Mean                 -0.27182513
Log Pis Std                  3.614444
Log Pis Max                  12.214792
Log Pis Min                  -7.3086166
Policy mu Mean               0.0067928643
Policy mu Std                0.8966663
Policy mu Max                2.564722
Policy mu Min                -2.3309615
Policy log std Mean          -0.4863976
Policy log std Std           0.27302158
Policy log std Max           0.033190966
Policy log std Min           -2.5296786
Z mean eval                  2.506888
Z variance eval              0.06064415
total_rewards                [11559.93072886  9888.33249554 11551.87646486 11509.49303267
 11733.11430471 11481.08905142 11603.21986515 11404.88298605
 11640.23281386 11392.19783027]
total_rewards_mean           11376.436957339025
total_rewards_std            505.65352833543477
total_rewards_max            11733.11430470638
total_rewards_min            9888.332495538181
Number of train steps total  1740000
Number of env steps total    5222000
Number of rollouts total     0
Train Time (s)               192.57797162001953
(Previous) Eval Time (s)     30.899480991065502
Sample Time (s)              7.094878617208451
Epoch Time (s)               230.57233122829348
Total Train Time (s)         101059.98682044027
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:41:04.153181 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #434 | Epoch Duration: 230.6649031639099
2020-01-14 03:41:04.153362 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #434 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.506473
Z variance train             0.06065619
KL Divergence                55.96669
KL Loss                      5.596669
QF Loss                      69.52075
VF Loss                      44.398224
Policy Loss                  -1357.4955
Q Predictions Mean           1354.8594
Q Predictions Std            1368.1455
Q Predictions Max            5211.8706
Q Predictions Min            696.8606
V Predictions Mean           1358.9193
V Predictions Std            1365.5463
V Predictions Max            5211.2725
V Predictions Min            718.0091
Log Pis Mean                 -0.090716146
Log Pis Std                  4.3167486
Log Pis Max                  28.027277
Log Pis Min                  -7.3925133
Policy mu Mean               0.006421326
Policy mu Std                0.8941841
Policy mu Max                3.4060822
Policy mu Min                -3.6143086
Policy log std Mean          -0.4927455
Policy log std Std           0.27649334
Policy log std Max           0.15223253
Policy log std Min           -2.7262392
Z mean eval                  2.5346959
Z variance eval              0.065350674
total_rewards                [11500.04123654 11497.38015676 11078.43353785 11397.3964259
 11521.66109894 11574.39333946 11509.00436869 10968.60931634
 11426.74518808 11373.17900626]
total_rewards_mean           11384.684367481128
total_rewards_std            191.09846443668184
total_rewards_max            11574.39333946384
total_rewards_min            10968.609316338405
Number of train steps total  1744000
Number of env steps total    5234000
Number of rollouts total     0
Train Time (s)               196.19152704114094
(Previous) Eval Time (s)     35.55613921908662
Sample Time (s)              7.9415575372986495
Epoch Time (s)               239.6892237975262
Total Train Time (s)         101299.79295854829
Epoch                        435
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:45:03.966393 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #435 | Epoch Duration: 239.81285643577576
2020-01-14 03:45:03.966717 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5337424
Z variance train             0.065334484
KL Divergence                55.94875
KL Loss                      5.594875
QF Loss                      4809.0522
VF Loss                      48.893776
Policy Loss                  -1444.254
Q Predictions Mean           1443.8527
Q Predictions Std            1434.6274
Q Predictions Max            5089.9033
Q Predictions Min            703.2568
V Predictions Mean           1442.6488
V Predictions Std            1430.3088
V Predictions Max            5069.6523
V Predictions Min            702.3559
Log Pis Mean                 -0.31693143
Log Pis Std                  4.290529
Log Pis Max                  22.679182
Log Pis Min                  -7.0563207
Policy mu Mean               0.02547667
Policy mu Std                0.89778435
Policy mu Max                2.9504976
Policy mu Min                -2.804885
Policy log std Mean          -0.49462506
Policy log std Std           0.27262253
Policy log std Max           -0.065906614
Policy log std Min           -2.665514
Z mean eval                  2.516875
Z variance eval              0.037456077
total_rewards                [11469.57845533 11590.42386555  2175.96733701 11429.81470477
 11410.4401095  11171.90362923 11601.78073945 11219.85646169
 11316.29315088 11513.71652315]
total_rewards_mean           10489.977497655682
total_rewards_std            2774.682013177628
total_rewards_max            11601.780739450145
total_rewards_min            2175.967337008932
Number of train steps total  1748000
Number of env steps total    5246000
Number of rollouts total     0
Train Time (s)               192.4302634978667
(Previous) Eval Time (s)     32.39588397089392
Sample Time (s)              7.2050821403972805
Epoch Time (s)               232.0312296091579
Total Train Time (s)         101531.87924159179
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:48:56.091477 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #436 | Epoch Duration: 232.1244831085205
2020-01-14 03:48:56.091810 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.517532
Z variance train             0.037437927
KL Divergence                57.53087
KL Loss                      5.753087
QF Loss                      185.37192
VF Loss                      77.86756
Policy Loss                  -1443.3234
Q Predictions Mean           1440.6052
Q Predictions Std            1457.167
Q Predictions Max            5060.6934
Q Predictions Min            703.55206
V Predictions Mean           1444.8657
V Predictions Std            1456.997
V Predictions Max            5063.3994
V Predictions Min            718.0249
Log Pis Mean                 -0.13067773
Log Pis Std                  4.3061867
Log Pis Max                  24.84702
Log Pis Min                  -7.880121
Policy mu Mean               0.032705877
Policy mu Std                0.9187036
Policy mu Max                3.3720589
Policy mu Min                -2.7821531
Policy log std Mean          -0.49867654
Policy log std Std           0.28679493
Policy log std Max           0.15022177
Policy log std Min           -2.7707002
Z mean eval                  2.4936576
Z variance eval              0.036702953
total_rewards                [ 1133.27951718 10410.26415692 10085.15877476  9327.69920331
  2168.52718419  3040.73473827 10317.30908385  7371.99808661
  9720.54859949 10417.22887534]
total_rewards_mean           7399.274821991933
total_rewards_std            3586.5187332684654
total_rewards_max            10417.228875340557
total_rewards_min            1133.2795171777504
Number of train steps total  1752000
Number of env steps total    5258000
Number of rollouts total     0
Train Time (s)               195.86961618019268
(Previous) Eval Time (s)     35.70651278691366
Sample Time (s)              6.828708827961236
Epoch Time (s)               238.40483779506758
Total Train Time (s)         101770.48544670688
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:52:54.700143 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #437 | Epoch Duration: 238.608056306839
2020-01-14 03:52:54.700294 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4939787
Z variance train             0.036707032
KL Divergence                56.339954
KL Loss                      5.6339955
QF Loss                      152.16028
VF Loss                      99.752686
Policy Loss                  -1558.2511
Q Predictions Mean           1554.8618
Q Predictions Std            1519.1669
Q Predictions Max            5119.621
Q Predictions Min            686.42944
V Predictions Mean           1557.6858
V Predictions Std            1517.0737
V Predictions Max            5121.0796
V Predictions Min            705.62415
Log Pis Mean                 0.26173759
Log Pis Std                  4.227699
Log Pis Max                  16.445286
Log Pis Min                  -6.0204806
Policy mu Mean               0.0783919
Policy mu Std                0.9607901
Policy mu Max                3.117711
Policy mu Min                -3.015699
Policy log std Mean          -0.5268584
Policy log std Std           0.3012309
Policy log std Max           -0.089790046
Policy log std Min           -3.0464182
Z mean eval                  2.5165439
Z variance eval              0.11359545
total_rewards                [11136.08069246 10707.65827205 10874.74663307 11294.21857643
 10908.46779834 10684.60811979 10527.98430158 11223.83322876
 11237.54817876 11098.46843104]
total_rewards_mean           10969.361423228185
total_rewards_std            253.7169443651463
total_rewards_max            11294.218576433155
total_rewards_min            10527.984301576655
Number of train steps total  1756000
Number of env steps total    5270000
Number of rollouts total     0
Train Time (s)               194.8224803530611
(Previous) Eval Time (s)     34.18099471507594
Sample Time (s)              6.79941074969247
Epoch Time (s)               235.80288581782952
Total Train Time (s)         102006.36926366854
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:56:50.588819 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #438 | Epoch Duration: 235.88837337493896
2020-01-14 03:56:50.589138 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5151353
Z variance train             0.11352794
KL Divergence                52.386192
KL Loss                      5.2386193
QF Loss                      1017.86456
VF Loss                      523.7049
Policy Loss                  -1467.8008
Q Predictions Mean           1465.919
Q Predictions Std            1490.4114
Q Predictions Max            5179.1445
Q Predictions Min            704.54047
V Predictions Mean           1473.447
V Predictions Std            1495.0073
V Predictions Max            5166.431
V Predictions Min            700.4791
Log Pis Mean                 -0.13423152
Log Pis Std                  4.3440547
Log Pis Max                  25.520432
Log Pis Min                  -8.858227
Policy mu Mean               0.034043524
Policy mu Std                0.9031733
Policy mu Max                5.474104
Policy mu Min                -3.3567657
Policy log std Mean          -0.50660044
Policy log std Std           0.30935314
Policy log std Max           0.025309384
Policy log std Min           -3.528489
Z mean eval                  2.4901843
Z variance eval              0.09456196
total_rewards                [10575.66633043  5190.13299973 11192.41677679 10752.06168647
 10515.68937373 10869.20753433 10827.05706383 10990.78244805
 10648.26274201 10081.71580823]
total_rewards_mean           10164.29927635934
total_rewards_std            1682.194307507542
total_rewards_max            11192.416776785316
total_rewards_min            5190.13299972636
Number of train steps total  1760000
Number of env steps total    5282000
Number of rollouts total     0
Train Time (s)               195.25933321891353
(Previous) Eval Time (s)     31.452244519256055
Sample Time (s)              7.32582640228793
Epoch Time (s)               234.0374041404575
Total Train Time (s)         102240.4913109839
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:00:44.716641 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #439 | Epoch Duration: 234.12727904319763
2020-01-14 04:00:44.716810 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.488833
Z variance train             0.09463526
KL Divergence                53.318737
KL Loss                      5.331874
QF Loss                      8680.27
VF Loss                      86.11857
Policy Loss                  -1540.9857
Q Predictions Mean           1537.0586
Q Predictions Std            1523.4828
Q Predictions Max            5174.118
Q Predictions Min            705.6139
V Predictions Mean           1542.5271
V Predictions Std            1521.574
V Predictions Max            5196.195
V Predictions Min            708.38715
Log Pis Mean                 0.2771826
Log Pis Std                  4.763994
Log Pis Max                  23.27602
Log Pis Min                  -6.9307866
Policy mu Mean               0.08602115
Policy mu Std                0.9684458
Policy mu Max                3.4547782
Policy mu Min                -3.5552251
Policy log std Mean          -0.5069268
Policy log std Std           0.28997004
Policy log std Max           0.023243487
Policy log std Min           -2.7152946
Z mean eval                  2.5031772
Z variance eval              0.068657145
total_rewards                [10911.46146553 11082.79648996 11039.90130311 11195.41937758
 10679.38845585 11040.88954744 10981.93454348 11319.73042931
 10766.01077977 10870.96514378]
total_rewards_mean           10988.849753581344
total_rewards_std            182.11273233673427
total_rewards_max            11319.730429309904
total_rewards_min            10679.388455846722
Number of train steps total  1764000
Number of env steps total    5294000
Number of rollouts total     0
Train Time (s)               195.1201144210063
(Previous) Eval Time (s)     34.0078803608194
Sample Time (s)              6.760881717782468
Epoch Time (s)               235.88887649960816
Total Train Time (s)         102476.46109996922
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:04:40.690934 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #440 | Epoch Duration: 235.97397756576538
2020-01-14 04:04:40.691129 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #440 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5032215
Z variance train             0.06862652
KL Divergence                54.778282
KL Loss                      5.4778285
QF Loss                      110.118065
VF Loss                      40.76172
Policy Loss                  -1317.3527
Q Predictions Mean           1317.9347
Q Predictions Std            1346.3892
Q Predictions Max            5178.188
Q Predictions Min            693.2715
V Predictions Mean           1314.5596
V Predictions Std            1340.8909
V Predictions Max            5171.018
V Predictions Min            698.03894
Log Pis Mean                 -0.34917507
Log Pis Std                  3.7421455
Log Pis Max                  18.5667
Log Pis Min                  -7.9224095
Policy mu Mean               0.112520814
Policy mu Std                0.8674464
Policy mu Max                3.0125325
Policy mu Min                -3.31152
Policy log std Mean          -0.4975171
Policy log std Std           0.26025
Policy log std Max           -0.06837618
Policy log std Min           -2.725923
Z mean eval                  2.5128574
Z variance eval              0.05690614
total_rewards                [10293.72109764 10229.23217784 10781.05941336 10566.00555659
 10608.07200065 10453.43733802 10518.60562873 10561.512314
 10593.66004671 10458.61771635]
total_rewards_mean           10506.392328990367
total_rewards_std            150.75509227546834
total_rewards_max            10781.059413355544
total_rewards_min            10229.232177844406
Number of train steps total  1768000
Number of env steps total    5306000
Number of rollouts total     0
Train Time (s)               195.19159289170057
(Previous) Eval Time (s)     34.23681515874341
Sample Time (s)              7.803513380233198
Epoch Time (s)               237.23192143067718
Total Train Time (s)         102713.8046681839
Epoch                        441
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:08:38.038651 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #441 | Epoch Duration: 237.34737086296082
2020-01-14 04:08:38.038867 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5137088
Z variance train             0.056881703
KL Divergence                55.64218
KL Loss                      5.564218
QF Loss                      306.09518
VF Loss                      93.12604
Policy Loss                  -1496.3086
Q Predictions Mean           1495.3002
Q Predictions Std            1510.582
Q Predictions Max            5176.0454
Q Predictions Min            704.9581
V Predictions Mean           1490.3851
V Predictions Std            1500.5486
V Predictions Max            5139.329
V Predictions Min            705.80817
Log Pis Mean                 0.14823675
Log Pis Std                  4.7210684
Log Pis Max                  23.662716
Log Pis Min                  -6.22096
Policy mu Mean               0.06664482
Policy mu Std                0.937336
Policy mu Max                2.933322
Policy mu Min                -3.4812143
Policy log std Mean          -0.509731
Policy log std Std           0.31840843
Policy log std Max           -0.016831726
Policy log std Min           -3.1573882
Z mean eval                  2.4959226
Z variance eval              0.06849627
total_rewards                [11226.58040847 10360.76159882 11113.21979133 10805.94052819
 10718.39227299 10469.77930772 11299.09071686 11410.21337585
 10275.02541348 10591.05147717]
total_rewards_mean           10827.00548908873
total_rewards_std            390.1493838543163
total_rewards_max            11410.213375845105
total_rewards_min            10275.025413483307
Number of train steps total  1772000
Number of env steps total    5318000
Number of rollouts total     0
Train Time (s)               197.8987453118898
(Previous) Eval Time (s)     33.68044777121395
Sample Time (s)              7.636163591872901
Epoch Time (s)               239.21535667497665
Total Train Time (s)         102953.12108111335
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:12:37.357775 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #442 | Epoch Duration: 239.31876730918884
2020-01-14 04:12:37.357919 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #442 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4998853
Z variance train             0.06874396
KL Divergence                54.95532
KL Loss                      5.495532
QF Loss                      199.87311
VF Loss                      67.5219
Policy Loss                  -1477.9314
Q Predictions Mean           1474.0012
Q Predictions Std            1489.1637
Q Predictions Max            5203.4307
Q Predictions Min            709.3252
V Predictions Mean           1473.9327
V Predictions Std            1487.3202
V Predictions Max            5197.0146
V Predictions Min            708.7187
Log Pis Mean                 0.22308785
Log Pis Std                  4.494306
Log Pis Max                  15.192369
Log Pis Min                  -7.647741
Policy mu Mean               0.074703194
Policy mu Std                0.9462211
Policy mu Max                4.2588615
Policy mu Min                -2.880647
Policy log std Mean          -0.49498656
Policy log std Std           0.29285845
Policy log std Max           0.059902906
Policy log std Min           -2.8764496
Z mean eval                  2.5205727
Z variance eval              0.06915779
total_rewards                [11400.19740056 11559.65258131  8317.17259814 11721.4321561
 11299.20949023 11429.70446564 11285.08512654 11544.95692954
 11372.51789027 11494.20792933]
total_rewards_mean           11142.41365676656
total_rewards_std            949.9481346971208
total_rewards_max            11721.432156104296
total_rewards_min            8317.172598136458
Number of train steps total  1776000
Number of env steps total    5330000
Number of rollouts total     0
Train Time (s)               192.93249553116038
(Previous) Eval Time (s)     34.378463549073786
Sample Time (s)              7.333168031647801
Epoch Time (s)               234.64412711188197
Total Train Time (s)         103187.85660280427
Epoch                        443
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:16:32.100993 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #443 | Epoch Duration: 234.74296617507935
2020-01-14 04:16:32.101123 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5192282
Z variance train             0.06920702
KL Divergence                55.409676
KL Loss                      5.5409675
QF Loss                      101.6725
VF Loss                      65.80856
Policy Loss                  -1334.8208
Q Predictions Mean           1334.5779
Q Predictions Std            1356.357
Q Predictions Max            5302.089
Q Predictions Min            716.6692
V Predictions Mean           1337.6083
V Predictions Std            1356.2284
V Predictions Max            5318.129
V Predictions Min            715.86426
Log Pis Mean                 -0.3910675
Log Pis Std                  3.7133439
Log Pis Max                  14.712731
Log Pis Min                  -7.8119326
Policy mu Mean               0.06497318
Policy mu Std                0.8470479
Policy mu Max                2.3765512
Policy mu Min                -2.3532066
Policy log std Mean          -0.45343414
Policy log std Std           0.24658838
Policy log std Max           -0.025686473
Policy log std Min           -2.5099907
Z mean eval                  2.534698
Z variance eval              0.10013199
total_rewards                [10927.5621725  10831.4268838  10567.23609352 10718.21834324
 10735.49695233 10370.72301726 10900.26507215 11099.55914663
 10907.6492975  10736.26760606]
total_rewards_mean           10779.440458499314
total_rewards_std            194.36522640077857
total_rewards_max            11099.559146632586
total_rewards_min            10370.723017261287
Number of train steps total  1780000
Number of env steps total    5342000
Number of rollouts total     0
Train Time (s)               195.57553785620257
(Previous) Eval Time (s)     27.52179808076471
Sample Time (s)              6.995674033649266
Epoch Time (s)               230.09300997061655
Total Train Time (s)         103418.03392980527
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:20:22.285059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #444 | Epoch Duration: 230.18382215499878
2020-01-14 04:20:22.285253 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.531939
Z variance train             0.10050939
KL Divergence                56.23396
KL Loss                      5.623396
QF Loss                      159.18631
VF Loss                      44.009987
Policy Loss                  -1485.0674
Q Predictions Mean           1483.0536
Q Predictions Std            1494.3799
Q Predictions Max            5226.959
Q Predictions Min            733.73566
V Predictions Mean           1487.0682
V Predictions Std            1489.2384
V Predictions Max            5203.214
V Predictions Min            742.9772
Log Pis Mean                 -0.08913919
Log Pis Std                  4.5594783
Log Pis Max                  15.524513
Log Pis Min                  -7.5492477
Policy mu Mean               0.0007876816
Policy mu Std                0.94266564
Policy mu Max                3.3979278
Policy mu Min                -2.7258756
Policy log std Mean          -0.47878435
Policy log std Std           0.29527658
Policy log std Max           -0.0039183497
Policy log std Min           -2.874148
Z mean eval                  2.5213432
Z variance eval              0.08119098
total_rewards                [11304.54892048 11027.09620455 11527.69726436 11144.19711751
 11073.31741483 11407.34467668 11157.87411876 11635.28942376
 11448.68304899 11634.28917596]
total_rewards_mean           11336.03373658838
total_rewards_std            216.10552861008986
total_rewards_max            11635.289423763317
total_rewards_min            11027.096204554287
Number of train steps total  1784000
Number of env steps total    5354000
Number of rollouts total     0
Train Time (s)               197.527979104314
(Previous) Eval Time (s)     26.737056612968445
Sample Time (s)              6.695423687808216
Epoch Time (s)               230.96045940509066
Total Train Time (s)         103649.07986875856
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:24:13.338472 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #445 | Epoch Duration: 231.0530445575714
2020-01-14 04:24:13.338722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5220826
Z variance train             0.081176594
KL Divergence                56.003006
KL Loss                      5.600301
QF Loss                      399.72632
VF Loss                      77.109726
Policy Loss                  -1403.8551
Q Predictions Mean           1399.8394
Q Predictions Std            1411.5012
Q Predictions Max            5210.982
Q Predictions Min            713.47253
V Predictions Mean           1402.9021
V Predictions Std            1410.8918
V Predictions Max            5214.059
V Predictions Min            726.2676
Log Pis Mean                 -0.20960298
Log Pis Std                  3.9367886
Log Pis Max                  16.076138
Log Pis Min                  -7.8505244
Policy mu Mean               0.03327131
Policy mu Std                0.88887674
Policy mu Max                2.68927
Policy mu Min                -3.0290947
Policy log std Mean          -0.50456995
Policy log std Std           0.295706
Policy log std Max           -0.079536915
Policy log std Min           -2.5974605
Z mean eval                  2.555307
Z variance eval              0.08921863
total_rewards                [ 3465.44464218 11896.95614175 11958.14824233 11554.02229473
 11462.05606287 11003.13738234 11552.77663712 11816.64817178
 11844.48526767 11677.36832577]
total_rewards_mean           10823.104316855652
total_rewards_std            2466.6594374157703
total_rewards_max            11958.148242332569
total_rewards_min            3465.444642183203
Number of train steps total  1788000
Number of env steps total    5366000
Number of rollouts total     0
Train Time (s)               193.65726526500657
(Previous) Eval Time (s)     27.161326058208942
Sample Time (s)              8.067564103752375
Epoch Time (s)               228.8861554269679
Total Train Time (s)         103878.05484951893
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:28:02.318108 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #446 | Epoch Duration: 228.97919583320618
2020-01-14 04:28:02.318291 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5541186
Z variance train             0.08892332
KL Divergence                57.567272
KL Loss                      5.756727
QF Loss                      177.9731
VF Loss                      46.554787
Policy Loss                  -1489.676
Q Predictions Mean           1488.6544
Q Predictions Std            1482.688
Q Predictions Max            5264.7637
Q Predictions Min            718.9997
V Predictions Mean           1492.1152
V Predictions Std            1480.3328
V Predictions Max            5271.412
V Predictions Min            721.51984
Log Pis Mean                 -0.35447934
Log Pis Std                  3.995548
Log Pis Max                  12.99107
Log Pis Min                  -5.809538
Policy mu Mean               0.010740712
Policy mu Std                0.8942276
Policy mu Max                3.1698835
Policy mu Min                -2.730394
Policy log std Mean          -0.5024267
Policy log std Std           0.2820203
Policy log std Max           -0.07233718
Policy log std Min           -2.8432202
Z mean eval                  2.5511694
Z variance eval              0.062809214
total_rewards                [11270.92714171 11613.01420151 11831.64459717 11888.88599394
 11468.03593478 11699.31153009 11575.30673028 11692.56085054
 11847.77014433 11649.7242963 ]
total_rewards_mean           11653.718142066176
total_rewards_std            178.0543113034197
total_rewards_max            11888.88599394309
total_rewards_min            11270.927141705817
Number of train steps total  1792000
Number of env steps total    5378000
Number of rollouts total     0
Train Time (s)               195.65035002399236
(Previous) Eval Time (s)     31.718265395145863
Sample Time (s)              6.670190611388534
Epoch Time (s)               234.03880603052676
Total Train Time (s)         104112.17634252133
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:31:56.442153 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #447 | Epoch Duration: 234.12373757362366
2020-01-14 04:31:56.442285 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5510354
Z variance train             0.06264416
KL Divergence                57.721066
KL Loss                      5.7721066
QF Loss                      318.1431
VF Loss                      92.90216
Policy Loss                  -1388.8928
Q Predictions Mean           1386.164
Q Predictions Std            1382.8346
Q Predictions Max            5223.201
Q Predictions Min            722.4417
V Predictions Mean           1382.7924
V Predictions Std            1378.9359
V Predictions Max            5192.6484
V Predictions Min            724.2245
Log Pis Mean                 -0.3995521
Log Pis Std                  3.9539635
Log Pis Max                  14.897194
Log Pis Min                  -6.8841524
Policy mu Mean               0.018087866
Policy mu Std                0.848484
Policy mu Max                2.6889114
Policy mu Min                -2.7718482
Policy log std Mean          -0.48503244
Policy log std Std           0.27648857
Policy log std Max           0.07957852
Policy log std Min           -2.7678432
Z mean eval                  2.5281844
Z variance eval              0.08500188
total_rewards                [11454.54749715  7853.96258497 11102.39238588 10707.48495454
 11395.35894121 11681.77316287 11310.28666037 11409.45936466
 11329.03995265 11383.91370061]
total_rewards_mean           10962.82192048995
total_rewards_std            1064.2888302218546
total_rewards_max            11681.773162866182
total_rewards_min            7853.962584968722
Number of train steps total  1796000
Number of env steps total    5390000
Number of rollouts total     0
Train Time (s)               198.60124636208639
(Previous) Eval Time (s)     31.778149707708508
Sample Time (s)              6.59072306798771
Epoch Time (s)               236.9701191377826
Total Train Time (s)         104349.22659738595
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:35:53.495348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #448 | Epoch Duration: 237.0529661178589
2020-01-14 04:35:53.495479 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5287337
Z variance train             0.08479378
KL Divergence                56.52108
KL Loss                      5.652108
QF Loss                      613.5627
VF Loss                      123.046234
Policy Loss                  -1454.4069
Q Predictions Mean           1452.0012
Q Predictions Std            1433.5745
Q Predictions Max            5198.1187
Q Predictions Min            743.2403
V Predictions Mean           1455.8262
V Predictions Std            1432.2277
V Predictions Max            5216.6465
V Predictions Min            740.0952
Log Pis Mean                 -0.38413662
Log Pis Std                  4.130891
Log Pis Max                  15.175131
Log Pis Min                  -7.0535383
Policy mu Mean               0.038066555
Policy mu Std                0.8709837
Policy mu Max                3.540073
Policy mu Min                -2.9415698
Policy log std Mean          -0.49573353
Policy log std Std           0.2879564
Policy log std Max           -0.033494413
Policy log std Min           -2.9268534
Z mean eval                  2.55204
Z variance eval              0.0927173
total_rewards                [11211.12425684 11360.0343986  10979.64909959 11118.48022319
 11215.96572491 11309.48693429 11129.58671827 11449.11219065
 11195.37179594 11030.79495557]
total_rewards_mean           11199.960629786192
total_rewards_std            137.4204169358601
total_rewards_max            11449.112190649908
total_rewards_min            10979.64909958769
Number of train steps total  1800000
Number of env steps total    5402000
Number of rollouts total     0
Train Time (s)               199.0543110119179
(Previous) Eval Time (s)     27.089701669290662
Sample Time (s)              6.534355589654297
Epoch Time (s)               232.67836827086285
Total Train Time (s)         104581.9835980488
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:39:46.256659 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #449 | Epoch Duration: 232.76106786727905
2020-01-14 04:39:46.256848 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #449 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5524304
Z variance train             0.09322892
KL Divergence                57.7799
KL Loss                      5.77799
QF Loss                      193.59412
VF Loss                      55.262043
Policy Loss                  -1364.4464
Q Predictions Mean           1362.3057
Q Predictions Std            1362.4087
Q Predictions Max            5113.906
Q Predictions Min            731.93915
V Predictions Mean           1362.1315
V Predictions Std            1360.5582
V Predictions Max            5116.754
V Predictions Min            737.65045
Log Pis Mean                 -0.5177938
Log Pis Std                  4.0682335
Log Pis Max                  14.734556
Log Pis Min                  -6.859274
Policy mu Mean               0.0335301
Policy mu Std                0.8797094
Policy mu Max                2.7855892
Policy mu Min                -3.5908136
Policy log std Mean          -0.50143397
Policy log std Std           0.28853893
Policy log std Max           0.004046917
Policy log std Min           -2.7503211
Z mean eval                  2.5680575
Z variance eval              0.0821082
total_rewards                [11082.17306111 11044.46496182 11318.05128923  5379.43364632
 11392.3612322  11813.84966048 11297.24151761 11348.10883067
 11379.82197015 11085.57453916]
total_rewards_mean           10714.108070874408
total_rewards_std            1790.551003660761
total_rewards_max            11813.849660481736
total_rewards_min            5379.433646315513
Number of train steps total  1804000
Number of env steps total    5414000
Number of rollouts total     0
Train Time (s)               198.60092183900997
(Previous) Eval Time (s)     28.03002091590315
Sample Time (s)              5.767102167475969
Epoch Time (s)               232.3980449223891
Total Train Time (s)         104814.46363771381
Epoch                        450
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:43:38.746441 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #450 | Epoch Duration: 232.4894142150879
2020-01-14 04:43:38.746754 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #450 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.570617
Z variance train             0.08239164
KL Divergence                58.712814
KL Loss                      5.8712816
QF Loss                      297.39792
VF Loss                      168.1967
Policy Loss                  -1665.8223
Q Predictions Mean           1663.9219
Q Predictions Std            1621.8915
Q Predictions Max            5097.6694
Q Predictions Min            -856.3485
V Predictions Mean           1659.5775
V Predictions Std            1613.0521
V Predictions Max            5084.505
V Predictions Min            -870.9011
Log Pis Mean                 0.3973532
Log Pis Std                  4.3736873
Log Pis Max                  14.654499
Log Pis Min                  -6.5104175
Policy mu Mean               0.025917158
Policy mu Std                0.97045404
Policy mu Max                2.9585836
Policy mu Min                -3.4804401
Policy log std Mean          -0.51048553
Policy log std Std           0.29643843
Policy log std Max           0.98182595
Policy log std Min           -2.7667625
Z mean eval                  2.5846925
Z variance eval              0.08077277
total_rewards                [11899.89596916 11668.4439809  11819.04992648 11482.41392458
 11667.35729905 12056.31477719 11197.39578615 11581.0647082
 11603.90795236 11923.12638883]
total_rewards_mean           11689.8970712893
total_rewards_std            235.63775316178098
total_rewards_max            12056.31477718806
total_rewards_min            11197.395786145325
Number of train steps total  1808000
Number of env steps total    5426000
Number of rollouts total     0
Train Time (s)               195.2504091062583
(Previous) Eval Time (s)     32.675607830286026
Sample Time (s)              6.448158453218639
Epoch Time (s)               234.37417538976297
Total Train Time (s)         105048.92154166382
Epoch                        451
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:47:33.213809 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #451 | Epoch Duration: 234.46677565574646
2020-01-14 04:47:33.214135 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5840344
Z variance train             0.08090929
KL Divergence                58.51445
KL Loss                      5.851445
QF Loss                      596.624
VF Loss                      47.422318
Policy Loss                  -1359.7096
Q Predictions Mean           1359.7661
Q Predictions Std            1341.1086
Q Predictions Max            5179.978
Q Predictions Min            737.59625
V Predictions Mean           1359.793
V Predictions Std            1336.5922
V Predictions Max            5164.026
V Predictions Min            726.20087
Log Pis Mean                 -0.32895628
Log Pis Std                  4.366525
Log Pis Max                  15.643785
Log Pis Min                  -6.7337646
Policy mu Mean               0.025162905
Policy mu Std                0.9047493
Policy mu Max                3.3249524
Policy mu Min                -2.443543
Policy log std Mean          -0.48664382
Policy log std Std           0.28451878
Policy log std Max           -0.02319634
Policy log std Min           -2.888196
Z mean eval                  2.585833
Z variance eval              0.06820729
total_rewards                [11094.28392441 11061.26195973 11026.52891184 11447.27939105
 10940.98757087 10976.43322661   869.06044354 11541.87367272
 10984.28660537 11021.80038515]
total_rewards_mean           10096.379609129046
total_rewards_std            3081.921972016975
total_rewards_max            11541.873672722984
total_rewards_min            869.0604435374248
Number of train steps total  1812000
Number of env steps total    5438000
Number of rollouts total     0
Train Time (s)               202.3709584157914
(Previous) Eval Time (s)     32.537859234027565
Sample Time (s)              6.633248886559159
Epoch Time (s)               241.54206653637812
Total Train Time (s)         105290.57583926385
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:51:34.870093 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #452 | Epoch Duration: 241.65571761131287
2020-01-14 04:51:34.870239 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #452 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5859432
Z variance train             0.068227015
KL Divergence                58.880535
KL Loss                      5.8880534
QF Loss                      85.61249
VF Loss                      85.50209
Policy Loss                  -1379.8927
Q Predictions Mean           1376.9739
Q Predictions Std            1364.8938
Q Predictions Max            5165.407
Q Predictions Min            731.2535
V Predictions Mean           1376.6892
V Predictions Std            1360.0776
V Predictions Max            5142.022
V Predictions Min            730.7024
Log Pis Mean                 -0.45124745
Log Pis Std                  4.201337
Log Pis Max                  22.753431
Log Pis Min                  -6.172225
Policy mu Mean               0.079455085
Policy mu Std                0.90476674
Policy mu Max                3.3693922
Policy mu Min                -3.6477854
Policy log std Mean          -0.49222556
Policy log std Std           0.2764231
Policy log std Max           -0.11808893
Policy log std Min           -2.8947039
Z mean eval                  2.5305896
Z variance eval              0.091550834
total_rewards                [11656.73273274 11668.29561459 11851.83352844 11803.5172008
 11678.4274627  11737.5609861  11775.87300088 12053.13340822
 11746.82074815 12053.5266127 ]
total_rewards_mean           11802.57212953215
total_rewards_std            138.18299633963477
total_rewards_max            12053.52661270201
total_rewards_min            11656.732732743769
Number of train steps total  1816000
Number of env steps total    5450000
Number of rollouts total     0
Train Time (s)               201.48984153335914
(Previous) Eval Time (s)     32.76878642104566
Sample Time (s)              6.571984568145126
Epoch Time (s)               240.83061252254993
Total Train Time (s)         105531.49335133238
Epoch                        453
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:55:35.794443 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #453 | Epoch Duration: 240.9240710735321
2020-01-14 04:55:35.794691 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5298882
Z variance train             0.091637716
KL Divergence                59.773148
KL Loss                      5.977315
QF Loss                      213.74425
VF Loss                      178.99084
Policy Loss                  -1291.2863
Q Predictions Mean           1288.0913
Q Predictions Std            1291.4908
Q Predictions Max            5158.1113
Q Predictions Min            717.45483
V Predictions Mean           1280.8137
V Predictions Std            1284.1901
V Predictions Max            5109.631
V Predictions Min            730.601
Log Pis Mean                 0.013049103
Log Pis Std                  4.1611576
Log Pis Max                  15.142757
Log Pis Min                  -6.9122114
Policy mu Mean               0.022972375
Policy mu Std                0.923701
Policy mu Max                3.6569922
Policy mu Min                -2.9214952
Policy log std Mean          -0.5005835
Policy log std Std           0.26084483
Policy log std Max           -0.061480045
Policy log std Min           -2.5792413
Z mean eval                  2.5502906
Z variance eval              0.11021229
total_rewards                [11369.2072406  11241.44709257 11214.51136319 11107.64246349
 11255.75842016 11129.03936008 11770.34956428 10839.91321501
 11482.46841069 11253.57609218]
total_rewards_mean           11266.39132222447
total_rewards_std            232.5458453764038
total_rewards_max            11770.34956427618
total_rewards_min            10839.913215011527
Number of train steps total  1820000
Number of env steps total    5462000
Number of rollouts total     0
Train Time (s)               194.0332207432948
(Previous) Eval Time (s)     35.04406784614548
Sample Time (s)              6.572324147913605
Epoch Time (s)               235.6496127373539
Total Train Time (s)         105767.22618023353
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:59:31.529990 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #454 | Epoch Duration: 235.73512172698975
2020-01-14 04:59:31.530129 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5503259
Z variance train             0.110474005
KL Divergence                58.618423
KL Loss                      5.8618426
QF Loss                      455.7472
VF Loss                      48.540565
Policy Loss                  -1347.5729
Q Predictions Mean           1347.4165
Q Predictions Std            1363.662
Q Predictions Max            5175.285
Q Predictions Min            709.5577
V Predictions Mean           1347.2128
V Predictions Std            1359.7806
V Predictions Max            5180.6826
V Predictions Min            723.45184
Log Pis Mean                 -0.63479376
Log Pis Std                  3.6523483
Log Pis Max                  16.20756
Log Pis Min                  -9.03424
Policy mu Mean               0.07458609
Policy mu Std                0.8417371
Policy mu Max                3.1020823
Policy mu Min                -2.5690205
Policy log std Mean          -0.4956285
Policy log std Std           0.27664357
Policy log std Max           0.0047240257
Policy log std Min           -2.7334557
Z mean eval                  2.5528102
Z variance eval              0.09570274
total_rewards                [11022.44581792 10591.02076238 10239.06491146 10554.34347256
 10761.50793975 10924.18047885  5611.21408547 10334.08516231
 10338.05425923  9942.0279753 ]
total_rewards_mean           10031.79448652381
total_rewards_std            1505.7802247584236
total_rewards_max            11022.445817919326
total_rewards_min            5611.214085470881
Number of train steps total  1824000
Number of env steps total    5474000
Number of rollouts total     0
Train Time (s)               191.55899776797742
(Previous) Eval Time (s)     30.173335005994886
Sample Time (s)              6.523754384368658
Epoch Time (s)               228.25608715834096
Total Train Time (s)         105995.56936807372
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:03:19.878044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #455 | Epoch Duration: 228.34780550003052
2020-01-14 05:03:19.878210 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5540257
Z variance train             0.09571656
KL Divergence                58.049866
KL Loss                      5.8049865
QF Loss                      317.92743
VF Loss                      34.789078
Policy Loss                  -1404.18
Q Predictions Mean           1403.626
Q Predictions Std            1403.1194
Q Predictions Max            5281.96
Q Predictions Min            759.83936
V Predictions Mean           1404.033
V Predictions Std            1398.002
V Predictions Max            5256.604
V Predictions Min            763.5731
Log Pis Mean                 -0.20117477
Log Pis Std                  4.0821123
Log Pis Max                  16.644339
Log Pis Min                  -7.722941
Policy mu Mean               0.026245946
Policy mu Std                0.8892772
Policy mu Max                3.516702
Policy mu Min                -3.4278839
Policy log std Mean          -0.48873207
Policy log std Std           0.29949045
Policy log std Max           -0.050207287
Policy log std Min           -2.9691594
Z mean eval                  2.5418396
Z variance eval              0.117436185
total_rewards                [8166.70796059 7636.187865   6954.14001198 6367.12714922 5738.82266319
 7618.6807687  7249.04565078 7715.53512234 9380.5954486  8046.87502548]
total_rewards_mean           7487.371766587688
total_rewards_std            954.1379190003204
total_rewards_max            9380.595448599977
total_rewards_min            5738.822663194717
Number of train steps total  1828000
Number of env steps total    5486000
Number of rollouts total     0
Train Time (s)               194.7162241912447
(Previous) Eval Time (s)     29.418867255095392
Sample Time (s)              6.601935499813408
Epoch Time (s)               230.7370269461535
Total Train Time (s)         106226.59614468599
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:07:10.912019 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #456 | Epoch Duration: 231.0336651802063
2020-01-14 05:07:10.912202 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5418334
Z variance train             0.11729048
KL Divergence                56.630253
KL Loss                      5.6630254
QF Loss                      206.01656
VF Loss                      49.197712
Policy Loss                  -1374.9474
Q Predictions Mean           1369.5181
Q Predictions Std            1394.4003
Q Predictions Max            5156.365
Q Predictions Min            717.607
V Predictions Mean           1373.9407
V Predictions Std            1391.2557
V Predictions Max            5145.091
V Predictions Min            717.5648
Log Pis Mean                 -0.43145007
Log Pis Std                  4.298684
Log Pis Max                  24.242634
Log Pis Min                  -7.523688
Policy mu Mean               0.06280121
Policy mu Std                0.8980957
Policy mu Max                3.0928748
Policy mu Min                -2.9614959
Policy log std Mean          -0.5091644
Policy log std Std           0.28807613
Policy log std Max           -0.027454853
Policy log std Min           -2.9659152
Z mean eval                  2.5563178
Z variance eval              0.10154708
total_rewards                [11768.7304501  11407.88412    11132.15695831  4573.74467585
  8187.01909701  2263.68531964 11308.32385044 11536.78194082
 11387.91790081 11100.56350157]
total_rewards_mean           9466.68078145698
total_rewards_std            3214.6649618994566
total_rewards_max            11768.730450098354
total_rewards_min            2263.685319644324
Number of train steps total  1832000
Number of env steps total    5498000
Number of rollouts total     0
Train Time (s)               195.2622299110517
(Previous) Eval Time (s)     34.74337593698874
Sample Time (s)              5.843826158903539
Epoch Time (s)               235.84943200694397
Total Train Time (s)         106462.53608153481
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:11:06.863107 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #457 | Epoch Duration: 235.95072293281555
2020-01-14 05:11:06.863429 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5562563
Z variance train             0.10122889
KL Divergence                58.467155
KL Loss                      5.8467155
QF Loss                      93.60671
VF Loss                      49.012764
Policy Loss                  -1284.5989
Q Predictions Mean           1283.3823
Q Predictions Std            1282.2458
Q Predictions Max            5120.633
Q Predictions Min            720.84204
V Predictions Mean           1289.3574
V Predictions Std            1280.0603
V Predictions Max            5127.3755
V Predictions Min            726.70087
Log Pis Mean                 -0.80689883
Log Pis Std                  3.7322938
Log Pis Max                  13.955807
Log Pis Min                  -7.9412556
Policy mu Mean               0.007548181
Policy mu Std                0.8111309
Policy mu Max                2.4992952
Policy mu Min                -2.6214957
Policy log std Mean          -0.48800543
Policy log std Std           0.2673206
Policy log std Max           -0.028478503
Policy log std Min           -2.5826738
Z mean eval                  2.5867324
Z variance eval              0.075884916
total_rewards                [11411.58380883 11621.77768749 11894.95088068 11350.96155366
 11511.21960387 11700.84105789 11748.80811468 11792.51750946
 11697.26171637 11914.05399045]
total_rewards_mean           11664.39759233917
total_rewards_std            181.34720126597605
total_rewards_max            11914.053990450342
total_rewards_min            11350.961553664096
Number of train steps total  1836000
Number of env steps total    5510000
Number of rollouts total     0
Train Time (s)               191.74367242399603
(Previous) Eval Time (s)     33.98811042169109
Sample Time (s)              6.641502075362951
Epoch Time (s)               232.37328492105007
Total Train Time (s)         106695.00582831027
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:14:59.336540 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #458 | Epoch Duration: 232.47286462783813
2020-01-14 05:14:59.336735 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5858116
Z variance train             0.07578595
KL Divergence                58.758194
KL Loss                      5.8758197
QF Loss                      267.19562
VF Loss                      89.70181
Policy Loss                  -1540.5316
Q Predictions Mean           1538.4581
Q Predictions Std            1546.866
Q Predictions Max            5118.824
Q Predictions Min            675.66583
V Predictions Mean           1540.0518
V Predictions Std            1541.9722
V Predictions Max            5106.517
V Predictions Min            691.95074
Log Pis Mean                 0.12762576
Log Pis Std                  4.6515136
Log Pis Max                  18.660957
Log Pis Min                  -7.3906407
Policy mu Mean               0.010561249
Policy mu Std                0.93709236
Policy mu Max                3.4306638
Policy mu Min                -3.776121
Policy log std Mean          -0.49490166
Policy log std Std           0.31050032
Policy log std Max           -0.03944421
Policy log std Min           -3.009355
Z mean eval                  2.6047406
Z variance eval              0.0656452
total_rewards                [11648.4217968  11267.62877275 11556.79903699 10835.22952087
 11529.13196757 11488.59752757 11192.20548627 11479.24538144
 11251.4572489  11390.68158177]
total_rewards_mean           11363.93983209391
total_rewards_std            224.92633574264005
total_rewards_max            11648.421796796212
total_rewards_min            10835.22952087279
Number of train steps total  1840000
Number of env steps total    5522000
Number of rollouts total     0
Train Time (s)               196.14141084393486
(Previous) Eval Time (s)     33.37901363009587
Sample Time (s)              5.882751911878586
Epoch Time (s)               235.40317638590932
Total Train Time (s)         106930.53783979686
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:18:54.874747 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #459 | Epoch Duration: 235.53785824775696
2020-01-14 05:18:54.874948 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6055222
Z variance train             0.06567849
KL Divergence                59.22463
KL Loss                      5.922463
QF Loss                      349.841
VF Loss                      77.4896
Policy Loss                  -1484.2886
Q Predictions Mean           1479.5337
Q Predictions Std            1429.7968
Q Predictions Max            5221.446
Q Predictions Min            748.3101
V Predictions Mean           1480.7339
V Predictions Std            1426.7533
V Predictions Max            5230.8315
V Predictions Min            749.6668
Log Pis Mean                 0.1256399
Log Pis Std                  4.4411826
Log Pis Max                  21.027733
Log Pis Min                  -5.855304
Policy mu Mean               0.01401071
Policy mu Std                0.9441625
Policy mu Max                3.5516677
Policy mu Min                -3.8376148
Policy log std Mean          -0.49007425
Policy log std Std           0.292528
Policy log std Max           0.40217882
Policy log std Min           -3.123392
Z mean eval                  2.537121
Z variance eval              0.088246174
total_rewards                [11529.16506263 11365.72145268 11323.87538535 11393.87484294
 11178.46234878 11648.04168285 11698.19870529 11053.63899475
 11236.75634818 11015.03412949]
total_rewards_mean           11344.27689529294
total_rewards_std            220.67616436459662
total_rewards_max            11698.198705290764
total_rewards_min            11015.034129490417
Number of train steps total  1844000
Number of env steps total    5534000
Number of rollouts total     0
Train Time (s)               195.5567537159659
(Previous) Eval Time (s)     36.242222322151065
Sample Time (s)              6.8450726619921625
Epoch Time (s)               238.64404870010912
Total Train Time (s)         107169.26761360513
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:22:53.607395 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #460 | Epoch Duration: 238.73230504989624
2020-01-14 05:22:53.607527 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.537807
Z variance train             0.08826332
KL Divergence                57.49636
KL Loss                      5.749636
QF Loss                      170.95844
VF Loss                      46.8691
Policy Loss                  -1482.4733
Q Predictions Mean           1481.1753
Q Predictions Std            1494.2667
Q Predictions Max            5215.452
Q Predictions Min            741.8966
V Predictions Mean           1483.1571
V Predictions Std            1494.6005
V Predictions Max            5217.9624
V Predictions Min            723.9925
Log Pis Mean                 -0.104612306
Log Pis Std                  4.245702
Log Pis Max                  13.511071
Log Pis Min                  -7.338318
Policy mu Mean               0.014065846
Policy mu Std                0.9262814
Policy mu Max                2.8021402
Policy mu Min                -2.9445755
Policy log std Mean          -0.47260007
Policy log std Std           0.26402155
Policy log std Max           -0.049910367
Policy log std Min           -2.7306995
Z mean eval                  2.5537612
Z variance eval              0.07297293
total_rewards                [ 3344.63870195  9630.71175255  1921.29178858 11022.25855476
 11226.11857182 10473.65156964 10444.92027784  6512.31386197
 10287.29832081 10636.68393102]
total_rewards_mean           8549.988733094273
total_rewards_std            3229.441870657216
total_rewards_max            11226.118571821355
total_rewards_min            1921.2917885829186
Number of train steps total  1848000
Number of env steps total    5546000
Number of rollouts total     0
Train Time (s)               194.31910188915208
(Previous) Eval Time (s)     30.963829611893743
Sample Time (s)              6.477894545998424
Epoch Time (s)               231.76082604704425
Total Train Time (s)         107401.11947500659
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:26:45.466540 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #461 | Epoch Duration: 231.85886693000793
2020-01-14 05:26:45.466843 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #461 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.553985
Z variance train             0.07290592
KL Divergence                59.31256
KL Loss                      5.9312563
QF Loss                      524.26807
VF Loss                      174.01224
Policy Loss                  -1569.6654
Q Predictions Mean           1567.1846
Q Predictions Std            1568.908
Q Predictions Max            5061.3696
Q Predictions Min            712.60803
V Predictions Mean           1561.2544
V Predictions Std            1559.0272
V Predictions Max            4996.4087
V Predictions Min            708.886
Log Pis Mean                 0.4919648
Log Pis Std                  4.4521904
Log Pis Max                  15.550556
Log Pis Min                  -6.124719
Policy mu Mean               0.055283654
Policy mu Std                0.9581321
Policy mu Max                2.9785213
Policy mu Min                -3.2656107
Policy log std Mean          -0.53227264
Policy log std Std           0.29374906
Policy log std Max           -0.09433964
Policy log std Min           -2.6859226
Z mean eval                  2.60993
Z variance eval              0.05145691
total_rewards                [ 8699.59455864 11175.56458887 11225.15607373 11255.52390258
 10972.09313209 10936.39189699 10084.43821494 11342.5994697
 11142.45603059 11428.28904986]
total_rewards_mean           10826.210691797698
total_rewards_std            793.7774498702629
total_rewards_max            11428.289049861247
total_rewards_min            8699.5945586354
Number of train steps total  1852000
Number of env steps total    5558000
Number of rollouts total     0
Train Time (s)               196.7136292872019
(Previous) Eval Time (s)     32.08597978902981
Sample Time (s)              7.398271436803043
Epoch Time (s)               236.19788051303476
Total Train Time (s)         107637.40476524178
Epoch                        462
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:30:41.758201 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #462 | Epoch Duration: 236.29109477996826
2020-01-14 05:30:41.758488 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6092417
Z variance train             0.05151217
KL Divergence                60.101204
KL Loss                      6.0101204
QF Loss                      4910.6875
VF Loss                      50.769302
Policy Loss                  -1339.9254
Q Predictions Mean           1338.5579
Q Predictions Std            1320.4178
Q Predictions Max            5283.7593
Q Predictions Min            751.4683
V Predictions Mean           1338.4873
V Predictions Std            1315.7515
V Predictions Max            5241.26
V Predictions Min            747.9126
Log Pis Mean                 -0.5875508
Log Pis Std                  4.0941124
Log Pis Max                  21.543707
Log Pis Min                  -7.575367
Policy mu Mean               0.06663427
Policy mu Std                0.8837387
Policy mu Max                2.9245834
Policy mu Min                -3.232687
Policy log std Mean          -0.47782674
Policy log std Std           0.27249423
Policy log std Max           0.0034741163
Policy log std Min           -2.704053
Z mean eval                  2.5638072
Z variance eval              0.083250284
total_rewards                [11513.84788308 11658.68902644 11613.51132617 11461.62043556
 11411.12616498 11728.39471035 11412.73812053 11605.00489949
 11434.27345987 11405.47197701]
total_rewards_mean           11524.467800349084
total_rewards_std            112.11776958786706
total_rewards_max            11728.394710352602
total_rewards_min            11405.471977013718
Number of train steps total  1856000
Number of env steps total    5570000
Number of rollouts total     0
Train Time (s)               194.6332123549655
(Previous) Eval Time (s)     33.046657720115036
Sample Time (s)              6.372360810637474
Epoch Time (s)               234.05223088571802
Total Train Time (s)         107871.54046049155
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:34:35.897848 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #463 | Epoch Duration: 234.13915014266968
2020-01-14 05:34:35.898035 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #463 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5586965
Z variance train             0.083381996
KL Divergence                57.861088
KL Loss                      5.786109
QF Loss                      4534.907
VF Loss                      116.894646
Policy Loss                  -1489.6462
Q Predictions Mean           1489.1497
Q Predictions Std            1499.3011
Q Predictions Max            5094.7188
Q Predictions Min            717.26556
V Predictions Mean           1491.7108
V Predictions Std            1499.5051
V Predictions Max            5094.953
V Predictions Min            715.3471
Log Pis Mean                 -0.23548779
Log Pis Std                  4.1743016
Log Pis Max                  15.878595
Log Pis Min                  -7.7785983
Policy mu Mean               0.047463585
Policy mu Std                0.8892841
Policy mu Max                2.6618867
Policy mu Min                -3.0463207
Policy log std Mean          -0.50595504
Policy log std Std           0.32567304
Policy log std Max           -0.011246324
Policy log std Min           -2.8331203
Z mean eval                  2.5683753
Z variance eval              0.048267037
total_rewards                [11394.43173259 11748.43015353 11251.61869763 11248.41404672
 11685.78493666 11514.48406973 11499.10571925 11404.61361003
 10873.63446894 11636.15463798]
total_rewards_mean           11425.667207306129
total_rewards_std            244.3960680646751
total_rewards_max            11748.430153527303
total_rewards_min            10873.634468941937
Number of train steps total  1860000
Number of env steps total    5582000
Number of rollouts total     0
Train Time (s)               193.0355420350097
(Previous) Eval Time (s)     30.500683397985995
Sample Time (s)              7.429664931260049
Epoch Time (s)               230.96589036425576
Total Train Time (s)         108102.58506377647
Epoch                        464
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:38:26.946700 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #464 | Epoch Duration: 231.04851818084717
2020-01-14 05:38:26.946896 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5682614
Z variance train             0.048164837
KL Divergence                59.311035
KL Loss                      5.9311037
QF Loss                      128.50772
VF Loss                      138.8972
Policy Loss                  -1197.3655
Q Predictions Mean           1192.9104
Q Predictions Std            1173.1833
Q Predictions Max            5168.028
Q Predictions Min            715.3658
V Predictions Mean           1199.5613
V Predictions Std            1171.2244
V Predictions Max            5155.0034
V Predictions Min            721.23364
Log Pis Mean                 -0.8486279
Log Pis Std                  3.6232243
Log Pis Max                  14.924625
Log Pis Min                  -7.572381
Policy mu Mean               0.022417543
Policy mu Std                0.84324545
Policy mu Max                3.0505219
Policy mu Min                -2.929635
Policy log std Mean          -0.46631327
Policy log std Std           0.27037844
Policy log std Max           -0.07287225
Policy log std Min           -3.332634
Z mean eval                  2.5392175
Z variance eval              0.07545543
total_rewards                [11471.44303489 11264.27538372 11605.70567818 11464.81437591
 11684.49690585 11748.30282398 11709.35852635 11549.25495394
 11435.66840704 11585.05628069]
total_rewards_mean           11551.837637054337
total_rewards_std            139.73026723191842
total_rewards_max            11748.302823975127
total_rewards_min            11264.27538371599
Number of train steps total  1864000
Number of env steps total    5594000
Number of rollouts total     0
Train Time (s)               194.19358597602695
(Previous) Eval Time (s)     31.24737816210836
Sample Time (s)              7.063127189408988
Epoch Time (s)               232.5040913275443
Total Train Time (s)         108335.180574066
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:42:19.566285 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #465 | Epoch Duration: 232.61920070648193
2020-01-14 05:42:19.566644 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #465 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.540917
Z variance train             0.07543445
KL Divergence                59.57083
KL Loss                      5.957083
QF Loss                      142.32466
VF Loss                      72.384094
Policy Loss                  -1478.1075
Q Predictions Mean           1475.7603
Q Predictions Std            1461.3447
Q Predictions Max            5261.0103
Q Predictions Min            727.6057
V Predictions Mean           1473.784
V Predictions Std            1459.2968
V Predictions Max            5279.6455
V Predictions Min            733.4076
Log Pis Mean                 -0.14661415
Log Pis Std                  3.9352326
Log Pis Max                  12.4238825
Log Pis Min                  -5.603378
Policy mu Mean               0.07384238
Policy mu Std                0.8983846
Policy mu Max                2.8175254
Policy mu Min                -2.6442733
Policy log std Mean          -0.4915072
Policy log std Std           0.28921387
Policy log std Max           0.008624136
Policy log std Min           -2.7131453
Z mean eval                  2.5830283
Z variance eval              0.033384986
total_rewards                [10913.58106304  4648.46818105 11089.88691888 11152.74079854
 11487.26656198 11175.24130213 11224.01899337 11278.80465581
 11168.29008236 11123.18743729]
total_rewards_mean           10526.148599445207
total_rewards_std            1964.0528009685106
total_rewards_max            11487.266561984476
total_rewards_min            4648.468181045476
Number of train steps total  1868000
Number of env steps total    5606000
Number of rollouts total     0
Train Time (s)               195.81858861399814
(Previous) Eval Time (s)     32.48568764515221
Sample Time (s)              7.024866070598364
Epoch Time (s)               235.32914232974872
Total Train Time (s)         108570.60014924733
Epoch                        466
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:46:14.987884 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #466 | Epoch Duration: 235.42099404335022
2020-01-14 05:46:14.988091 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #466 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5844827
Z variance train             0.0334965
KL Divergence                62.055622
KL Loss                      6.205562
QF Loss                      10188.92
VF Loss                      115.012375
Policy Loss                  -1439.1567
Q Predictions Mean           1434.4448
Q Predictions Std            1416.506
Q Predictions Max            5190.9707
Q Predictions Min            714.77094
V Predictions Mean           1438.0349
V Predictions Std            1408.3009
V Predictions Max            5175.0405
V Predictions Min            752.6013
Log Pis Mean                 -0.18030451
Log Pis Std                  4.6114793
Log Pis Max                  25.279728
Log Pis Min                  -8.564388
Policy mu Mean               -0.015868582
Policy mu Std                0.90812355
Policy mu Max                3.507472
Policy mu Min                -5.0509987
Policy log std Mean          -0.5070891
Policy log std Std           0.32333595
Policy log std Max           0.18955347
Policy log std Min           -2.8072014
Z mean eval                  2.55116
Z variance eval              0.034565363
total_rewards                [11503.17310016 11709.47896895 11645.44155532 11980.58979267
 11624.14582752 11616.26780534 11471.83387074 11410.1541789
 11406.00725569 11706.18060805]
total_rewards_mean           11607.327296334139
total_rewards_std            164.30486512190384
total_rewards_max            11980.589792674491
total_rewards_min            11406.00725568772
Number of train steps total  1872000
Number of env steps total    5618000
Number of rollouts total     0
Train Time (s)               194.01499876007438
(Previous) Eval Time (s)     30.060291523113847
Sample Time (s)              6.767393392510712
Epoch Time (s)               230.84268367569894
Total Train Time (s)         108801.53004889237
Epoch                        467
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:50:05.921250 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #467 | Epoch Duration: 230.93299651145935
2020-01-14 05:50:05.921447 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5556698
Z variance train             0.034433436
KL Divergence                60.976643
KL Loss                      6.0976644
QF Loss                      435.58545
VF Loss                      195.31528
Policy Loss                  -1506.3694
Q Predictions Mean           1503.457
Q Predictions Std            1452.1849
Q Predictions Max            5291.9805
Q Predictions Min            727.7664
V Predictions Mean           1502.1428
V Predictions Std            1438.9764
V Predictions Max            5227.3345
V Predictions Min            730.53656
Log Pis Mean                 0.2516922
Log Pis Std                  4.03515
Log Pis Max                  12.343895
Log Pis Min                  -5.96101
Policy mu Mean               -0.012926318
Policy mu Std                0.93792206
Policy mu Max                3.2670293
Policy mu Min                -3.0898476
Policy log std Mean          -0.51018435
Policy log std Std           0.31602278
Policy log std Max           -0.035133004
Policy log std Min           -2.7018929
Z mean eval                  2.5705502
Z variance eval              0.07461315
total_rewards                [11029.82417949 11608.95582802 11465.28434481 11589.31514738
 11031.02428977 11427.21970316 11178.81496971 10871.08451696
 11346.43797826 10313.05674218]
total_rewards_mean           11186.10176997394
total_rewards_std            375.9179893904465
total_rewards_max            11608.955828022039
total_rewards_min            10313.056742183762
Number of train steps total  1876000
Number of env steps total    5630000
Number of rollouts total     0
Train Time (s)               196.38952945591882
(Previous) Eval Time (s)     31.37659342493862
Sample Time (s)              6.420187865849584
Epoch Time (s)               234.18631074670702
Total Train Time (s)         109035.80693686195
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:54:00.203015 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #468 | Epoch Duration: 234.2813572883606
2020-01-14 05:54:00.203318 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5713832
Z variance train             0.074945666
KL Divergence                59.19581
KL Loss                      5.919581
QF Loss                      331.1546
VF Loss                      89.98612
Policy Loss                  -1520.4504
Q Predictions Mean           1516.7423
Q Predictions Std            1492.3376
Q Predictions Max            5188.4834
Q Predictions Min            739.4045
V Predictions Mean           1521.8704
V Predictions Std            1494.4789
V Predictions Max            5214.3696
V Predictions Min            751.91223
Log Pis Mean                 -0.19397013
Log Pis Std                  4.352129
Log Pis Max                  14.701918
Log Pis Min                  -7.389965
Policy mu Mean               0.037486523
Policy mu Std                0.8929117
Policy mu Max                3.1786892
Policy mu Min                -2.5368698
Policy log std Mean          -0.5273091
Policy log std Std           0.31822336
Policy log std Max           0.011405468
Policy log std Min           -2.940566
Z mean eval                  2.5534334
Z variance eval              0.12225802
total_rewards                [10285.25755469 10581.9785496   9393.86360713 10524.09856656
 10738.08451601  4756.96068847 10616.4494287  10325.67640483
 10444.56534128 10886.50305059]
total_rewards_mean           9855.343770786014
total_rewards_std            1742.318234066196
total_rewards_max            10886.503050585341
total_rewards_min            4756.960688473163
Number of train steps total  1880000
Number of env steps total    5642000
Number of rollouts total     0
Train Time (s)               194.1525026350282
(Previous) Eval Time (s)     34.11838292097673
Sample Time (s)              6.1899859313853085
Epoch Time (s)               234.46087148739025
Total Train Time (s)         109270.36097483011
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:57:54.760847 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #469 | Epoch Duration: 234.55732917785645
2020-01-14 05:57:54.761051 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5533347
Z variance train             0.12251325
KL Divergence                59.10133
KL Loss                      5.910133
QF Loss                      232.69832
VF Loss                      109.254776
Policy Loss                  -1531.979
Q Predictions Mean           1528.3612
Q Predictions Std            1510.899
Q Predictions Max            5322.0093
Q Predictions Min            762.0751
V Predictions Mean           1527.9421
V Predictions Std            1504.164
V Predictions Max            5305.686
V Predictions Min            758.9374
Log Pis Mean                 -0.06065043
Log Pis Std                  4.679449
Log Pis Max                  21.412924
Log Pis Min                  -8.548046
Policy mu Mean               -0.035824038
Policy mu Std                0.9360043
Policy mu Max                3.536255
Policy mu Min                -4.199332
Policy log std Mean          -0.50306344
Policy log std Std           0.31065387
Policy log std Max           -0.05194038
Policy log std Min           -3.1204355
Z mean eval                  2.5462751
Z variance eval              0.081617236
total_rewards                [11261.93582529 11172.17092857 11190.07228628 11166.52082278
 11598.59775454 11471.53027583 11071.03570876 10954.43277692
 11146.330327   11218.52694987]
total_rewards_mean           11225.115365585118
total_rewards_std            176.7172018650561
total_rewards_max            11598.59775454112
total_rewards_min            10954.432776919693
Number of train steps total  1884000
Number of env steps total    5654000
Number of rollouts total     0
Train Time (s)               196.43848346313462
(Previous) Eval Time (s)     32.90158435096964
Sample Time (s)              6.893749210983515
Epoch Time (s)               236.23381702508777
Total Train Time (s)         109506.6857460523
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:01:51.097446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #470 | Epoch Duration: 236.3361794948578
2020-01-14 06:01:51.097758 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.544679
Z variance train             0.08169269
KL Divergence                58.73777
KL Loss                      5.873777
QF Loss                      5006.605
VF Loss                      119.44676
Policy Loss                  -1503.1135
Q Predictions Mean           1501.4247
Q Predictions Std            1503.9421
Q Predictions Max            5248.602
Q Predictions Min            761.95447
V Predictions Mean           1504.8202
V Predictions Std            1501.0681
V Predictions Max            5284.084
V Predictions Min            763.6105
Log Pis Mean                 0.1070362
Log Pis Std                  4.5379834
Log Pis Max                  18.861473
Log Pis Min                  -6.9525657
Policy mu Mean               0.020352647
Policy mu Std                0.9248495
Policy mu Max                3.2358315
Policy mu Min                -3.5864263
Policy log std Mean          -0.49508736
Policy log std Std           0.29787967
Policy log std Max           0.08006573
Policy log std Min           -2.8224845
Z mean eval                  2.5323892
Z variance eval              0.10035751
total_rewards                [11577.92772387 11885.73605797 11107.39084698 11373.31547428
 11496.1503781  11336.76269847 11414.1568107  11132.78980258
 11446.50156884 11612.7062019 ]
total_rewards_mean           11438.343756369035
total_rewards_std            217.1357679879892
total_rewards_max            11885.736057973101
total_rewards_min            11107.390846977052
Number of train steps total  1888000
Number of env steps total    5666000
Number of rollouts total     0
Train Time (s)               195.0818089437671
(Previous) Eval Time (s)     34.48040171479806
Sample Time (s)              7.695099585689604
Epoch Time (s)               237.25731024425477
Total Train Time (s)         109744.02756611211
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:05:48.449963 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #471 | Epoch Duration: 237.35203790664673
2020-01-14 06:05:48.450099 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.530901
Z variance train             0.100207314
KL Divergence                58.837692
KL Loss                      5.8837695
QF Loss                      293.95752
VF Loss                      39.492107
Policy Loss                  -1526.4417
Q Predictions Mean           1525.7881
Q Predictions Std            1499.2006
Q Predictions Max            5302.0215
Q Predictions Min            709.4142
V Predictions Mean           1527.1731
V Predictions Std            1493.9
V Predictions Max            5297.959
V Predictions Min            752.77136
Log Pis Mean                 -0.29223937
Log Pis Std                  4.2889633
Log Pis Max                  15.698294
Log Pis Min                  -6.902933
Policy mu Mean               0.037903663
Policy mu Std                0.90943193
Policy mu Max                2.8604827
Policy mu Min                -2.4491444
Policy log std Mean          -0.49721658
Policy log std Std           0.31631944
Policy log std Max           0.13587296
Policy log std Min           -2.8611798
Z mean eval                  2.5285084
Z variance eval              0.07895667
total_rewards                [11560.79441496 11558.17150463 11486.89756562 11569.12700014
 11748.99247656 11274.97662761 11369.03923191 11640.38422049
 11612.69715471 11583.17524295]
total_rewards_mean           11540.425543957526
total_rewards_std            128.37361415126034
total_rewards_max            11748.992476558955
total_rewards_min            11274.97662760612
Number of train steps total  1892000
Number of env steps total    5678000
Number of rollouts total     0
Train Time (s)               193.09300920227543
(Previous) Eval Time (s)     29.945355020929128
Sample Time (s)              6.9655175362713635
Epoch Time (s)               230.00388175947592
Total Train Time (s)         109974.1236030492
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:09:38.549271 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #472 | Epoch Duration: 230.09904742240906
2020-01-14 06:09:38.549489 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #472 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5267696
Z variance train             0.07912106
KL Divergence                58.878036
KL Loss                      5.8878036
QF Loss                      1743.552
VF Loss                      67.23078
Policy Loss                  -1376.297
Q Predictions Mean           1376.5801
Q Predictions Std            1377.3712
Q Predictions Max            5144.2534
Q Predictions Min            733.10425
V Predictions Mean           1378.8319
V Predictions Std            1372.0854
V Predictions Max            5118.314
V Predictions Min            743.3043
Log Pis Mean                 -0.14793853
Log Pis Std                  4.201338
Log Pis Max                  15.958817
Log Pis Min                  -6.336485
Policy mu Mean               0.05190347
Policy mu Std                0.9015514
Policy mu Max                2.9883263
Policy mu Min                -2.8234773
Policy log std Mean          -0.5034104
Policy log std Std           0.28571606
Policy log std Max           -0.07443267
Policy log std Min           -2.7775178
Z mean eval                  2.5169277
Z variance eval              0.13150954
total_rewards                [10926.69786466 11286.75771234 11370.43660167 11116.1866641
 11248.89209199 10882.48507768 11109.31043373 11523.74405488
 11140.79458357 11160.16781057]
total_rewards_mean           11176.547289518317
total_rewards_std            182.79136459449464
total_rewards_max            11523.744054875522
total_rewards_min            10882.485077681335
Number of train steps total  1896000
Number of env steps total    5690000
Number of rollouts total     0
Train Time (s)               194.0645343591459
(Previous) Eval Time (s)     34.16869926499203
Sample Time (s)              7.153567811939865
Epoch Time (s)               235.3868014360778
Total Train Time (s)         110209.59427791508
Epoch                        473
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:13:34.067043 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #473 | Epoch Duration: 235.5173897743225
2020-01-14 06:13:34.067248 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5161011
Z variance train             0.13106726
KL Divergence                58.001144
KL Loss                      5.8001146
QF Loss                      1814.842
VF Loss                      170.8277
Policy Loss                  -1650.0647
Q Predictions Mean           1650.8005
Q Predictions Std            1615.3486
Q Predictions Max            5337.0303
Q Predictions Min            749.56006
V Predictions Mean           1652.0741
V Predictions Std            1613.2255
V Predictions Max            5312.201
V Predictions Min            757.86456
Log Pis Mean                 -0.17522156
Log Pis Std                  4.4706388
Log Pis Max                  19.226936
Log Pis Min                  -8.635369
Policy mu Mean               0.018958824
Policy mu Std                0.94446796
Policy mu Max                3.0856562
Policy mu Min                -2.9072714
Policy log std Mean          -0.4919397
Policy log std Std           0.30054104
Policy log std Max           0.17564511
Policy log std Min           -2.6273532
Z mean eval                  2.5657315
Z variance eval              0.067049116
total_rewards                [11456.05073589 11361.24378782 11202.38041476 10974.51394381
 11513.34793384 11069.92233809 11410.76243896 11483.71290771
 11599.8308221  10971.60172059]
total_rewards_mean           11304.336704354999
total_rewards_std            220.36358442359221
total_rewards_max            11599.8308221009
total_rewards_min            10971.601720587092
Number of train steps total  1900000
Number of env steps total    5702000
Number of rollouts total     0
Train Time (s)               194.63246590970084
(Previous) Eval Time (s)     29.8954985011369
Sample Time (s)              7.680278884712607
Epoch Time (s)               232.20824329555035
Total Train Time (s)         110441.89566763397
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:17:26.372564 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #474 | Epoch Duration: 232.30517601966858
2020-01-14 06:17:26.372740 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5663276
Z variance train             0.067077234
KL Divergence                60.601734
KL Loss                      6.0601735
QF Loss                      128.70163
VF Loss                      38.82675
Policy Loss                  -1488.7677
Q Predictions Mean           1485.2279
Q Predictions Std            1493.7391
Q Predictions Max            5262.581
Q Predictions Min            745.36206
V Predictions Mean           1486.5787
V Predictions Std            1491.0808
V Predictions Max            5266.3657
V Predictions Min            751.60913
Log Pis Mean                 -0.37356335
Log Pis Std                  3.701123
Log Pis Max                  12.860502
Log Pis Min                  -7.250167
Policy mu Mean               0.10440225
Policy mu Std                0.8934163
Policy mu Max                3.0481217
Policy mu Min                -2.7812812
Policy log std Mean          -0.48337603
Policy log std Std           0.30792382
Policy log std Max           0.16463792
Policy log std Min           -2.8227916
Z mean eval                  2.6237893
Z variance eval              0.06778134
total_rewards                [10395.79658667 11418.81037753 11130.23956004 11180.37396758
 11422.50156572 11369.9055425  11516.67106012 11222.42362808
 11401.50278312 11320.75132197]
total_rewards_mean           11237.897639332567
total_rewards_std            303.2907802249089
total_rewards_max            11516.671060124316
total_rewards_min            10395.796586665285
Number of train steps total  1904000
Number of env steps total    5714000
Number of rollouts total     0
Train Time (s)               196.3258298849687
(Previous) Eval Time (s)     30.931780400220305
Sample Time (s)              6.814781753811985
Epoch Time (s)               234.072392039001
Total Train Time (s)         110676.06520177517
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:21:20.546818 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #475 | Epoch Duration: 234.17393398284912
2020-01-14 06:21:20.547007 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6246572
Z variance train             0.06781273
KL Divergence                61.837307
KL Loss                      6.1837306
QF Loss                      243.31682
VF Loss                      62.159996
Policy Loss                  -1452.7181
Q Predictions Mean           1448.687
Q Predictions Std            1422.67
Q Predictions Max            5152.924
Q Predictions Min            725.1675
V Predictions Mean           1452.8417
V Predictions Std            1416.6558
V Predictions Max            5129.427
V Predictions Min            744.43164
Log Pis Mean                 -0.38300437
Log Pis Std                  4.352717
Log Pis Max                  19.44422
Log Pis Min                  -6.9050875
Policy mu Mean               -0.010198526
Policy mu Std                0.888753
Policy mu Max                3.358375
Policy mu Min                -3.5630548
Policy log std Mean          -0.50030726
Policy log std Std           0.3127559
Policy log std Max           0.01761064
Policy log std Min           -3.2736902
Z mean eval                  2.5751696
Z variance eval              0.044074047
total_rewards                [11301.46837835 11027.05997371 11133.97872605 11331.70352183
 11221.81080987 11211.63991621 10381.06593134 11227.37582813
 11075.46737508 10815.06175854]
total_rewards_mean           11072.663221909816
total_rewards_std            271.19395798797933
total_rewards_max            11331.703521828287
total_rewards_min            10381.065931340729
Number of train steps total  1908000
Number of env steps total    5726000
Number of rollouts total     0
Train Time (s)               191.77426429279149
(Previous) Eval Time (s)     32.23828656412661
Sample Time (s)              6.516408637166023
Epoch Time (s)               230.52895949408412
Total Train Time (s)         110906.68896520557
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:25:11.177786 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #476 | Epoch Duration: 230.63056254386902
2020-01-14 06:25:11.178101 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.577565
Z variance train             0.04418021
KL Divergence                62.025455
KL Loss                      6.2025456
QF Loss                      554.6593
VF Loss                      147.494
Policy Loss                  -1440.0771
Q Predictions Mean           1436.6758
Q Predictions Std            1425.8857
Q Predictions Max            5239.678
Q Predictions Min            740.4334
V Predictions Mean           1432.5894
V Predictions Std            1419.7548
V Predictions Max            5206.427
V Predictions Min            746.1214
Log Pis Mean                 -0.0797078
Log Pis Std                  4.376887
Log Pis Max                  16.234226
Log Pis Min                  -7.6973414
Policy mu Mean               -0.0007388356
Policy mu Std                0.93456775
Policy mu Max                2.845946
Policy mu Min                -2.5972002
Policy log std Mean          -0.4877282
Policy log std Std           0.31133544
Policy log std Max           -0.0593642
Policy log std Min           -2.9530406
Z mean eval                  2.629047
Z variance eval              0.065276094
total_rewards                [11727.392647   11749.48045147 11331.06423345 11691.13298549
 11339.96238468 11650.88161884 11156.41427527 11624.63154748
 11832.48634351 11353.51731651]
total_rewards_mean           11545.696380369456
total_rewards_std            217.27937095262794
total_rewards_max            11832.486343509925
total_rewards_min            11156.414275273224
Number of train steps total  1912000
Number of env steps total    5738000
Number of rollouts total     0
Train Time (s)               191.75228892313316
(Previous) Eval Time (s)     32.55050054285675
Sample Time (s)              7.563244289718568
Epoch Time (s)               231.8660337557085
Total Train Time (s)         111138.64002169296
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:29:03.133083 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #477 | Epoch Duration: 231.95478343963623
2020-01-14 06:29:03.133264 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6292603
Z variance train             0.065167286
KL Divergence                61.48378
KL Loss                      6.148378
QF Loss                      175.1011
VF Loss                      54.443047
Policy Loss                  -1427.0898
Q Predictions Mean           1427.2078
Q Predictions Std            1435.4237
Q Predictions Max            5126.927
Q Predictions Min            751.05896
V Predictions Mean           1428.8656
V Predictions Std            1435.582
V Predictions Max            5122.9424
V Predictions Min            751.14154
Log Pis Mean                 -0.18200833
Log Pis Std                  4.1403522
Log Pis Max                  16.973015
Log Pis Min                  -6.5131607
Policy mu Mean               0.060168084
Policy mu Std                0.9062912
Policy mu Max                3.4228904
Policy mu Min                -2.7653694
Policy log std Mean          -0.49206087
Policy log std Std           0.28870076
Policy log std Max           -0.032959938
Policy log std Min           -2.8459506
Z mean eval                  2.5728743
Z variance eval              0.06781398
total_rewards                [ 3241.88342547 11649.36931776 11872.38911691 11964.12757437
 11784.35000789 11145.61461828 11679.64355796 11871.61982483
 11937.794556   11623.38959504]
total_rewards_mean           10877.018159449963
total_rewards_std            2554.9076493697967
total_rewards_max            11964.127574372244
total_rewards_min            3241.8834254687567
Number of train steps total  1916000
Number of env steps total    5750000
Number of rollouts total     0
Train Time (s)               192.4189867861569
(Previous) Eval Time (s)     32.94184644008055
Sample Time (s)              7.029564004857093
Epoch Time (s)               232.39039723109454
Total Train Time (s)         111371.11868623318
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:32:55.618206 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #478 | Epoch Duration: 232.48473858833313
2020-01-14 06:32:55.618506 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #478 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5729742
Z variance train             0.06798913
KL Divergence                62.312885
KL Loss                      6.2312884
QF Loss                      163.10718
VF Loss                      51.51219
Policy Loss                  -1427.3118
Q Predictions Mean           1426.3558
Q Predictions Std            1426.0891
Q Predictions Max            5256.8374
Q Predictions Min            764.24414
V Predictions Mean           1427.8962
V Predictions Std            1422.1252
V Predictions Max            5272.388
V Predictions Min            768.47925
Log Pis Mean                 -0.53255576
Log Pis Std                  4.030836
Log Pis Max                  14.232539
Log Pis Min                  -6.405001
Policy mu Mean               0.07285968
Policy mu Std                0.86050415
Policy mu Max                2.878385
Policy mu Min                -2.982274
Policy log std Mean          -0.47822085
Policy log std Std           0.26136175
Policy log std Max           -0.058636546
Policy log std Min           -2.7834492
Z mean eval                  2.572412
Z variance eval              0.051463474
total_rewards                [11766.98568191 11561.84389878 11619.33482784 11332.48152974
 11796.46376722 11630.68859996 11603.10247714  2645.7359055
 11698.03582823 11570.29388164]
total_rewards_mean           10722.496639795874
total_rewards_std            2694.996233398159
total_rewards_max            11796.46376721513
total_rewards_min            2645.7359055011293
Number of train steps total  1920000
Number of env steps total    5762000
Number of rollouts total     0
Train Time (s)               195.1608641766943
(Previous) Eval Time (s)     32.05272411927581
Sample Time (s)              6.096452487166971
Epoch Time (s)               233.31004078313708
Total Train Time (s)         111604.5143671725
Epoch                        479
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:36:49.017470 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #479 | Epoch Duration: 233.39878940582275
2020-01-14 06:36:49.017637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5727563
Z variance train             0.05145343
KL Divergence                62.141132
KL Loss                      6.214113
QF Loss                      4684.9033
VF Loss                      34.696198
Policy Loss                  -1408.2198
Q Predictions Mean           1404.3728
Q Predictions Std            1395.9535
Q Predictions Max            5091.2324
Q Predictions Min            718.6675
V Predictions Mean           1407.2228
V Predictions Std            1392.9905
V Predictions Max            5073.997
V Predictions Min            725.13605
Log Pis Mean                 -0.24429426
Log Pis Std                  4.139916
Log Pis Max                  14.04645
Log Pis Min                  -6.0276885
Policy mu Mean               0.10317681
Policy mu Std                0.8925211
Policy mu Max                2.8699722
Policy mu Min                -3.00007
Policy log std Mean          -0.48529005
Policy log std Std           0.30330318
Policy log std Max           -0.06370214
Policy log std Min           -3.0968568
Z mean eval                  2.601828
Z variance eval              0.045999154
total_rewards                [9952.27204365 8741.1184437  8882.41386586 9154.89097245 8931.5898001
 9294.25213328 9213.49818281 9288.28322613 8313.66158144 9130.54688419]
total_rewards_mean           9090.252713361206
total_rewards_std            404.75421858032007
total_rewards_max            9952.27204365106
total_rewards_min            8313.661581442819
Number of train steps total  1924000
Number of env steps total    5774000
Number of rollouts total     0
Train Time (s)               195.47171243885532
(Previous) Eval Time (s)     33.009322392288595
Sample Time (s)              7.003283661790192
Epoch Time (s)               235.4843184929341
Total Train Time (s)         111840.10719023412
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:40:44.617376 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #480 | Epoch Duration: 235.5995831489563
2020-01-14 06:40:44.617637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6000597
Z variance train             0.046054725
KL Divergence                63.096428
KL Loss                      6.309643
QF Loss                      1388.7764
VF Loss                      43.957607
Policy Loss                  -1229.4565
Q Predictions Mean           1229.3767
Q Predictions Std            1220.8925
Q Predictions Max            5040.6553
Q Predictions Min            729.5831
V Predictions Mean           1229.814
V Predictions Std            1221.4636
V Predictions Max            5035.315
V Predictions Min            734.64496
Log Pis Mean                 -0.71426326
Log Pis Std                  3.5045087
Log Pis Max                  14.38929
Log Pis Min                  -8.647647
Policy mu Mean               0.06589963
Policy mu Std                0.8252142
Policy mu Max                2.4677012
Policy mu Min                -2.28216
Policy log std Mean          -0.46507522
Policy log std Std           0.2459958
Policy log std Max           -0.026598811
Policy log std Min           -2.9501212
Z mean eval                  2.6184087
Z variance eval              0.060080964
total_rewards                [11993.88752374  3251.34253378 11890.74253537 11390.28345865
  3399.15464233 11902.0434966  11793.37973248 12087.85162953
 11974.26502738 11531.59833663]
total_rewards_mean           10121.454891648467
total_rewards_std            3404.2330653308295
total_rewards_max            12087.851629533154
total_rewards_min            3251.3425337781455
Number of train steps total  1928000
Number of env steps total    5786000
Number of rollouts total     0
Train Time (s)               192.92748389672488
(Previous) Eval Time (s)     32.357042335905135
Sample Time (s)              7.878645209595561
Epoch Time (s)               233.16317144222558
Total Train Time (s)         112073.36263491167
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:44:37.877233 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #481 | Epoch Duration: 233.25939917564392
2020-01-14 06:44:37.877408 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6228638
Z variance train             0.059869774
KL Divergence                62.960068
KL Loss                      6.2960067
QF Loss                      472.87738
VF Loss                      390.3783
Policy Loss                  -1578.9379
Q Predictions Mean           1577.1401
Q Predictions Std            1538.809
Q Predictions Max            5270.6187
Q Predictions Min            736.64655
V Predictions Mean           1566.4199
V Predictions Std            1525.3112
V Predictions Max            5220.7363
V Predictions Min            734.24304
Log Pis Mean                 -0.2343823
Log Pis Std                  4.362831
Log Pis Max                  21.268404
Log Pis Min                  -7.535322
Policy mu Mean               0.1371285
Policy mu Std                0.91814655
Policy mu Max                4.1173806
Policy mu Min                -2.9526453
Policy log std Mean          -0.503576
Policy log std Std           0.29407406
Policy log std Max           -0.015438199
Policy log std Min           -2.7118154
Z mean eval                  2.6214557
Z variance eval              0.058049046
total_rewards                [11827.51393081 11500.48454975 11585.95579885 11628.21359052
 11855.68201542 11916.65646308 11674.54151835 11824.85777846
 11760.29945854 11748.4583458 ]
total_rewards_mean           11732.266344958978
total_rewards_std            125.3846735829683
total_rewards_max            11916.656463078978
total_rewards_min            11500.48454975472
Number of train steps total  1932000
Number of env steps total    5798000
Number of rollouts total     0
Train Time (s)               194.5663163177669
(Previous) Eval Time (s)     33.64614834589884
Sample Time (s)              6.658498989418149
Epoch Time (s)               234.8709636530839
Total Train Time (s)         112308.32497696579
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:48:32.852125 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #482 | Epoch Duration: 234.97457647323608
2020-01-14 06:48:32.852327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.621476
Z variance train             0.05776484
KL Divergence                64.83168
KL Loss                      6.483168
QF Loss                      344.51556
VF Loss                      95.406586
Policy Loss                  -1357.3495
Q Predictions Mean           1352.0522
Q Predictions Std            1348.294
Q Predictions Max            5167.972
Q Predictions Min            752.24915
V Predictions Mean           1352.8984
V Predictions Std            1345.9181
V Predictions Max            5134.8364
V Predictions Min            756.1549
Log Pis Mean                 -0.5723916
Log Pis Std                  4.341328
Log Pis Max                  15.877295
Log Pis Min                  -6.9544086
Policy mu Mean               0.029664628
Policy mu Std                0.85691625
Policy mu Max                3.3595989
Policy mu Min                -2.8793368
Policy log std Mean          -0.48478422
Policy log std Std           0.28177178
Policy log std Max           -0.029309988
Policy log std Min           -2.6893547
Z mean eval                  2.5700498
Z variance eval              0.06201159
total_rewards                [11417.84581078 10937.73831139 11394.0949504  11399.34186069
 11477.51300033 11743.88898614 11614.6807006  11598.55789201
 11535.96751212 11736.77027519]
total_rewards_mean           11485.639929965586
total_rewards_std            219.63150747047527
total_rewards_max            11743.888986143405
total_rewards_min            10937.738311390229
Number of train steps total  1936000
Number of env steps total    5810000
Number of rollouts total     0
Train Time (s)               194.58770752185956
(Previous) Eval Time (s)     33.30839339410886
Sample Time (s)              6.3098313910886645
Epoch Time (s)               234.20593230705708
Total Train Time (s)         112542.6132234619
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:52:27.149322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #483 | Epoch Duration: 234.29682636260986
2020-01-14 06:52:27.149559 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5670266
Z variance train             0.06189351
KL Divergence                62.66523
KL Loss                      6.266523
QF Loss                      4942.2
VF Loss                      93.29906
Policy Loss                  -1517.8713
Q Predictions Mean           1517.2844
Q Predictions Std            1498.4231
Q Predictions Max            5209.7944
Q Predictions Min            737.95294
V Predictions Mean           1517.9888
V Predictions Std            1496.4131
V Predictions Max            5191.5396
V Predictions Min            744.0481
Log Pis Mean                 0.17706533
Log Pis Std                  4.461
Log Pis Max                  17.39058
Log Pis Min                  -8.056494
Policy mu Mean               0.06189098
Policy mu Std                0.9461471
Policy mu Max                3.2075987
Policy mu Min                -2.8355868
Policy log std Mean          -0.50730634
Policy log std Std           0.27863792
Policy log std Max           -0.060355783
Policy log std Min           -2.9133916
Z mean eval                  2.565275
Z variance eval              0.06379603
total_rewards                [11628.57386382 12094.94588637 11646.02801459 11687.79949506
 12005.03810739 11470.61341917 11502.44928798 11620.44622672
 11684.08260011 11809.94205323]
total_rewards_mean           11714.991895444158
total_rewards_std            191.11785895244756
total_rewards_max            12094.945886369876
total_rewards_min            11470.613419165462
Number of train steps total  1940000
Number of env steps total    5822000
Number of rollouts total     0
Train Time (s)               195.11276177410036
(Previous) Eval Time (s)     29.63463382795453
Sample Time (s)              6.9879742176271975
Epoch Time (s)               231.7353698196821
Total Train Time (s)         112774.43387971958
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:56:18.975609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #484 | Epoch Duration: 231.82586455345154
2020-01-14 06:56:18.975847 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5675166
Z variance train             0.06390715
KL Divergence                61.748684
KL Loss                      6.1748686
QF Loss                      139.63402
VF Loss                      50.030304
Policy Loss                  -1286.8213
Q Predictions Mean           1285.2441
Q Predictions Std            1255.2771
Q Predictions Max            5137.252
Q Predictions Min            716.867
V Predictions Mean           1286.8179
V Predictions Std            1249.2045
V Predictions Max            5111.5703
V Predictions Min            714.5752
Log Pis Mean                 -0.98158526
Log Pis Std                  3.7634387
Log Pis Max                  14.917545
Log Pis Min                  -6.716236
Policy mu Mean               0.060419764
Policy mu Std                0.8150198
Policy mu Max                2.838167
Policy mu Min                -2.7499545
Policy log std Mean          -0.48375106
Policy log std Std           0.26884937
Policy log std Max           -0.10086578
Policy log std Min           -2.8315349
Z mean eval                  2.5666459
Z variance eval              0.053771805
total_rewards                [11600.89096939  3010.1688355  11641.88383249 11593.57582697
 11469.71491081 11371.15584461 11489.55033497 11924.36003704
 11555.15135336 11918.90980791]
total_rewards_mean           10757.53617530577
total_rewards_std            2588.049653220735
total_rewards_max            11924.360037041175
total_rewards_min            3010.1688355036586
Number of train steps total  1944000
Number of env steps total    5834000
Number of rollouts total     0
Train Time (s)               194.2508343490772
(Previous) Eval Time (s)     31.908526619896293
Sample Time (s)              7.154618733096868
Epoch Time (s)               233.31397970207036
Total Train Time (s)         113007.8364623636
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:00:12.381825 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #485 | Epoch Duration: 233.40578293800354
2020-01-14 07:00:12.381992 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #485 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5657372
Z variance train             0.053804755
KL Divergence                62.377808
KL Loss                      6.237781
QF Loss                      243.32428
VF Loss                      42.006157
Policy Loss                  -1294.2084
Q Predictions Mean           1292.7546
Q Predictions Std            1289.6613
Q Predictions Max            5107.012
Q Predictions Min            719.07904
V Predictions Mean           1295.1011
V Predictions Std            1286.6149
V Predictions Max            5097.647
V Predictions Min            726.5143
Log Pis Mean                 -0.3815965
Log Pis Std                  3.7347305
Log Pis Max                  12.941012
Log Pis Min                  -5.489688
Policy mu Mean               -0.052958474
Policy mu Std                0.85360765
Policy mu Max                2.7913868
Policy mu Min                -3.0910876
Policy log std Mean          -0.4796354
Policy log std Std           0.27234182
Policy log std Max           -0.06300986
Policy log std Min           -2.6418152
Z mean eval                  2.5530794
Z variance eval              0.055368207
total_rewards                [11581.69104151 11303.7797973  11789.18271028 11945.63348637
 11553.50163354 11968.19283491 11892.1590126  11631.6142814
 11838.68771052 11465.45218602]
total_rewards_mean           11696.989469445243
total_rewards_std            211.76024413857894
total_rewards_max            11968.19283490702
total_rewards_min            11303.779797304334
Number of train steps total  1948000
Number of env steps total    5846000
Number of rollouts total     0
Train Time (s)               195.02459093602374
(Previous) Eval Time (s)     29.42951844120398
Sample Time (s)              7.118126331828535
Epoch Time (s)               231.57223570905626
Total Train Time (s)         113239.49376524752
Epoch                        486
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:04:04.043546 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #486 | Epoch Duration: 231.6614122390747
2020-01-14 07:04:04.043741 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5535574
Z variance train             0.055275954
KL Divergence                61.897964
KL Loss                      6.1897964
QF Loss                      105.55173
VF Loss                      70.503624
Policy Loss                  -1512.8892
Q Predictions Mean           1509.5544
Q Predictions Std            1487.5525
Q Predictions Max            5129.8447
Q Predictions Min            735.35236
V Predictions Mean           1508.5765
V Predictions Std            1483.3956
V Predictions Max            5119.101
V Predictions Min            737.806
Log Pis Mean                 0.022384897
Log Pis Std                  4.2235794
Log Pis Max                  16.229286
Log Pis Min                  -7.808429
Policy mu Mean               0.04031902
Policy mu Std                0.9256875
Policy mu Max                3.3184884
Policy mu Min                -2.8501472
Policy log std Mean          -0.5059199
Policy log std Std           0.29496488
Policy log std Max           -0.029534757
Policy log std Min           -2.7535472
Z mean eval                  2.5674236
Z variance eval              0.035013814
total_rewards                [10831.78021963 10333.25954124 10771.01701989 10746.44240847
 10512.03816957 10796.9428631  10577.4180634  10780.30958349
 10669.81971886 10365.64635805]
total_rewards_mean           10638.467394570627
total_rewards_std            173.23655085477594
total_rewards_max            10831.780219630637
total_rewards_min            10333.259541244635
Number of train steps total  1952000
Number of env steps total    5858000
Number of rollouts total     0
Train Time (s)               191.52233305713162
(Previous) Eval Time (s)     32.43647321127355
Sample Time (s)              7.642573921009898
Epoch Time (s)               231.60138018941507
Total Train Time (s)         113471.1908089649
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:07:55.745178 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #487 | Epoch Duration: 231.70128989219666
2020-01-14 07:07:55.745366 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.567799
Z variance train             0.03467554
KL Divergence                63.97894
KL Loss                      6.397894
QF Loss                      469.1848
VF Loss                      61.799847
Policy Loss                  -1607.184
Q Predictions Mean           1599.4417
Q Predictions Std            1594.4529
Q Predictions Max            5401.486
Q Predictions Min            759.2278
V Predictions Mean           1603.875
V Predictions Std            1594.814
V Predictions Max            5378.477
V Predictions Min            759.78186
Log Pis Mean                 0.14907849
Log Pis Std                  4.7598686
Log Pis Max                  15.902196
Log Pis Min                  -7.196803
Policy mu Mean               0.028720258
Policy mu Std                0.95344156
Policy mu Max                3.1059976
Policy mu Min                -3.29858
Policy log std Mean          -0.5115351
Policy log std Std           0.34483144
Policy log std Max           -0.10945216
Policy log std Min           -3.4110541
Z mean eval                  2.6769497
Z variance eval              0.030835131
total_rewards                [11577.34038065 11854.99481632 11981.59319429 11849.62584434
 11750.36924654 11831.03081418 11962.73902822 11870.76820973
 11839.38606909  8446.40040082]
total_rewards_mean           11496.424800420758
total_rewards_std            1022.230958176163
total_rewards_max            11981.593194294917
total_rewards_min            8446.400400821942
Number of train steps total  1956000
Number of env steps total    5870000
Number of rollouts total     0
Train Time (s)               193.82604569010437
(Previous) Eval Time (s)     31.945362749975175
Sample Time (s)              6.263406191021204
Epoch Time (s)               232.03481463110074
Total Train Time (s)         113703.33711522538
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:11:47.900368 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #488 | Epoch Duration: 232.1504693031311
2020-01-14 07:11:47.900596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #488 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6755962
Z variance train             0.030730646
KL Divergence                65.43835
KL Loss                      6.5438347
QF Loss                      223.02054
VF Loss                      113.907845
Policy Loss                  -1487.921
Q Predictions Mean           1485.3119
Q Predictions Std            1491.7614
Q Predictions Max            5189.1704
Q Predictions Min            745.96857
V Predictions Mean           1492.4886
V Predictions Std            1491.9224
V Predictions Max            5190.662
V Predictions Min            751.76843
Log Pis Mean                 0.24230413
Log Pis Std                  4.678588
Log Pis Max                  15.194537
Log Pis Min                  -6.597836
Policy mu Mean               0.020190084
Policy mu Std                0.96973985
Policy mu Max                3.4560342
Policy mu Min                -2.6079516
Policy log std Mean          -0.49606857
Policy log std Std           0.2988956
Policy log std Max           0.089855134
Policy log std Min           -2.9741898
Z mean eval                  2.5933385
Z variance eval              0.050419055
total_rewards                [11708.75603498 11649.06210407 11345.57022655 11672.5919739
 11369.68857355 11908.08178887 11739.6928155  11597.0692608
 11276.31563139 11377.96672424]
total_rewards_mean           11564.479513385964
total_rewards_std            198.28584910436328
total_rewards_max            11908.08178887458
total_rewards_min            11276.315631388612
Number of train steps total  1960000
Number of env steps total    5882000
Number of rollouts total     0
Train Time (s)               195.67925154790282
(Previous) Eval Time (s)     30.782614786177874
Sample Time (s)              6.851600480265915
Epoch Time (s)               233.3134668143466
Total Train Time (s)         113936.7493899758
Epoch                        489
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:15:41.312854 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #489 | Epoch Duration: 233.41212105751038
2020-01-14 07:15:41.313025 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5929737
Z variance train             0.05069349
KL Divergence                63.0213
KL Loss                      6.30213
QF Loss                      167.47766
VF Loss                      115.118065
Policy Loss                  -1598.5879
Q Predictions Mean           1595.5161
Q Predictions Std            1546.3073
Q Predictions Max            5126.353
Q Predictions Min            723.4401
V Predictions Mean           1599.5634
V Predictions Std            1543.044
V Predictions Max            5150.862
V Predictions Min            722.8153
Log Pis Mean                 0.33968085
Log Pis Std                  4.6803665
Log Pis Max                  18.044868
Log Pis Min                  -6.5316563
Policy mu Mean               0.016317056
Policy mu Std                0.9637315
Policy mu Max                3.4881895
Policy mu Min                -2.9329624
Policy log std Mean          -0.521312
Policy log std Std           0.3271827
Policy log std Max           -0.066407114
Policy log std Min           -3.0321581
Z mean eval                  2.6470532
Z variance eval              0.033521634
total_rewards                [11108.26774408 12005.57136559 11635.46919234  2270.46326655
 12014.56689149 11363.04508971 11708.34553328  1828.17556999
 11824.59949277 11540.53841817]
total_rewards_mean           9729.904256397149
total_rewards_std            3850.422145173667
total_rewards_max            12014.56689148949
total_rewards_min            1828.1755699912424
Number of train steps total  1964000
Number of env steps total    5894000
Number of rollouts total     0
Train Time (s)               191.32305832300335
(Previous) Eval Time (s)     31.80610789731145
Sample Time (s)              7.3704235586337745
Epoch Time (s)               230.49958977894858
Total Train Time (s)         114167.34475690965
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:19:31.915692 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #490 | Epoch Duration: 230.60251641273499
2020-01-14 07:19:31.915941 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6463785
Z variance train             0.03343945
KL Divergence                65.40785
KL Loss                      6.5407853
QF Loss                      1465.8376
VF Loss                      58.936806
Policy Loss                  -1272.1846
Q Predictions Mean           1270.9443
Q Predictions Std            1249.2126
Q Predictions Max            5274.6533
Q Predictions Min            743.47375
V Predictions Mean           1269.2277
V Predictions Std            1244.6051
V Predictions Max            5259.8057
V Predictions Min            749.7258
Log Pis Mean                 -1.1324772
Log Pis Std                  3.5359998
Log Pis Max                  16.237024
Log Pis Min                  -8.130415
Policy mu Mean               -0.009791497
Policy mu Std                0.829384
Policy mu Max                2.8495839
Policy mu Min                -2.3296313
Policy log std Mean          -0.44990158
Policy log std Std           0.2572225
Policy log std Max           0.022151351
Policy log std Min           -2.7768779
Z mean eval                  2.5870774
Z variance eval              0.041543543
total_rewards                [11821.92589531 11255.77728341  5110.84802152 11846.44789395
 11717.64172941 11705.45588621 11984.59464915 10335.04817724
 11865.11639748 11860.60722995]
total_rewards_mean           10950.34631636116
total_rewards_std            2000.7061445960503
total_rewards_max            11984.594649149301
total_rewards_min            5110.848021518689
Number of train steps total  1968000
Number of env steps total    5906000
Number of rollouts total     0
Train Time (s)               194.1880422597751
(Previous) Eval Time (s)     30.924741480033845
Sample Time (s)              6.932736380025744
Epoch Time (s)               232.0455201198347
Total Train Time (s)         114399.47376843635
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:23:24.052231 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #491 | Epoch Duration: 232.1360845565796
2020-01-14 07:23:24.052443 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.585215
Z variance train             0.04162072
KL Divergence                64.14488
KL Loss                      6.4144883
QF Loss                      121.43445
VF Loss                      82.86668
Policy Loss                  -1406.753
Q Predictions Mean           1404.3174
Q Predictions Std            1409.2305
Q Predictions Max            5238.4526
Q Predictions Min            725.93164
V Predictions Mean           1410.1257
V Predictions Std            1412.7413
V Predictions Max            5256.877
V Predictions Min            723.65106
Log Pis Mean                 -0.16852611
Log Pis Std                  4.1379523
Log Pis Max                  14.935723
Log Pis Min                  -7.1420016
Policy mu Mean               0.027644088
Policy mu Std                0.8934051
Policy mu Max                3.1232457
Policy mu Min                -2.4362848
Policy log std Mean          -0.50074637
Policy log std Std           0.30345064
Policy log std Max           -0.08030823
Policy log std Min           -3.365839
Z mean eval                  2.593593
Z variance eval              0.04353075
total_rewards                [12030.02556642 11876.95323947 11603.91445297 11678.44609529
 11788.7486916  11830.44862856 11789.28385613 12023.62257653
 11551.88484175 11623.3370086 ]
total_rewards_mean           11779.666495732068
total_rewards_std            158.70428144685138
total_rewards_max            12030.025566415981
total_rewards_min            11551.884841752908
Number of train steps total  1972000
Number of env steps total    5918000
Number of rollouts total     0
Train Time (s)               195.0960824880749
(Previous) Eval Time (s)     33.115752887912095
Sample Time (s)              7.3597506810911
Epoch Time (s)               235.5715860570781
Total Train Time (s)         114635.20581967384
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:27:19.795201 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #492 | Epoch Duration: 235.7426028251648
2020-01-14 07:27:19.795404 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5944016
Z variance train             0.043436278
KL Divergence                63.898117
KL Loss                      6.389812
QF Loss                      4795.2344
VF Loss                      194.77332
Policy Loss                  -1345.2654
Q Predictions Mean           1339.564
Q Predictions Std            1353.8204
Q Predictions Max            5242.851
Q Predictions Min            728.3536
V Predictions Mean           1336.9451
V Predictions Std            1348.506
V Predictions Max            5246.687
V Predictions Min            747.1619
Log Pis Mean                 -0.14776853
Log Pis Std                  4.0522976
Log Pis Max                  15.190941
Log Pis Min                  -6.7138824
Policy mu Mean               0.05681245
Policy mu Std                0.89154047
Policy mu Max                2.8779626
Policy mu Min                -3.1808257
Policy log std Mean          -0.48266944
Policy log std Std           0.29821745
Policy log std Max           -0.024850607
Policy log std Min           -3.0335784
Z mean eval                  2.5996232
Z variance eval              0.06475848
total_rewards                [11459.44762015 11708.20947587 11378.70456946 11653.24550185
 11658.2560452  11347.16367107 11445.94715097 11513.41841237
 11660.67770061 11520.29423241]
total_rewards_mean           11534.536437994726
total_rewards_std            122.06541445894636
total_rewards_max            11708.20947586828
total_rewards_min            11347.163671066834
Number of train steps total  1976000
Number of env steps total    5930000
Number of rollouts total     0
Train Time (s)               197.63799204397947
(Previous) Eval Time (s)     31.08853129670024
Sample Time (s)              7.406950960867107
Epoch Time (s)               236.1334743015468
Total Train Time (s)         114871.679027237
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:31:16.272630 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #493 | Epoch Duration: 236.47706007957458
2020-01-14 07:31:16.272853 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5970867
Z variance train             0.064826556
KL Divergence                64.926636
KL Loss                      6.492664
QF Loss                      4900.6455
VF Loss                      113.20973
Policy Loss                  -1577.8544
Q Predictions Mean           1573.98
Q Predictions Std            1529.496
Q Predictions Max            5280.9663
Q Predictions Min            744.47095
V Predictions Mean           1581.5278
V Predictions Std            1529.6189
V Predictions Max            5277.672
V Predictions Min            746.0575
Log Pis Mean                 0.45592415
Log Pis Std                  4.9544816
Log Pis Max                  26.83479
Log Pis Min                  -8.725357
Policy mu Mean               0.030236676
Policy mu Std                1.000523
Policy mu Max                4.402598
Policy mu Min                -4.8742495
Policy log std Mean          -0.52723545
Policy log std Std           0.34366906
Policy log std Max           0.26161957
Policy log std Min           -3.2537313
Z mean eval                  2.6473725
Z variance eval              0.042858817
total_rewards                [11255.7616691  11142.86081874 11546.12987989 11469.64875844
 11342.18500848 11722.5597353  11507.51449396 11393.02662593
 11664.33443097 11457.72300619]
total_rewards_mean           11450.174442697515
total_rewards_std            167.37842939435396
total_rewards_max            11722.55973529831
total_rewards_min            11142.860818739733
Number of train steps total  1980000
Number of env steps total    5942000
Number of rollouts total     0
Train Time (s)               193.41272127907723
(Previous) Eval Time (s)     34.35656542982906
Sample Time (s)              7.191592988092452
Epoch Time (s)               234.96087969699875
Total Train Time (s)         115106.7228287668
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:35:11.321822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #494 | Epoch Duration: 235.04875135421753
2020-01-14 07:35:11.322137 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6475005
Z variance train             0.04283587
KL Divergence                66.949875
KL Loss                      6.694988
QF Loss                      112.89019
VF Loss                      153.36073
Policy Loss                  -1440.1215
Q Predictions Mean           1435.6078
Q Predictions Std            1449.6527
Q Predictions Max            5200.069
Q Predictions Min            730.8264
V Predictions Mean           1433.009
V Predictions Std            1441.9545
V Predictions Max            5174.5913
V Predictions Min            720.7259
Log Pis Mean                 -0.40776348
Log Pis Std                  4.172242
Log Pis Max                  23.615828
Log Pis Min                  -5.5989733
Policy mu Mean               0.008223943
Policy mu Std                0.9043163
Policy mu Max                3.7689695
Policy mu Min                -4.4937897
Policy log std Mean          -0.48671308
Policy log std Std           0.266651
Policy log std Max           0.21902716
Policy log std Min           -2.8406167
Z mean eval                  2.5914543
Z variance eval              0.051754337
total_rewards                [11370.49038951 11300.51212156 11304.96172911 11558.98771495
 11394.3596594  11119.40649209 11471.1072836  11514.16552642
 11410.28784877 11335.13643855]
total_rewards_mean           11377.941520394852
total_rewards_std            118.90328887209907
total_rewards_max            11558.987714948371
total_rewards_min            11119.406492086675
Number of train steps total  1984000
Number of env steps total    5954000
Number of rollouts total     0
Train Time (s)               194.33239339664578
(Previous) Eval Time (s)     31.460419927723706
Sample Time (s)              7.2262213276699185
Epoch Time (s)               233.0190346520394
Total Train Time (s)         115339.82613853132
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:39:04.433592 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #495 | Epoch Duration: 233.11126732826233
2020-01-14 07:39:04.433805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5971742
Z variance train             0.0520855
KL Divergence                67.04513
KL Loss                      6.704513
QF Loss                      9928.976
VF Loss                      260.229
Policy Loss                  -1528.9807
Q Predictions Mean           1529.7772
Q Predictions Std            1497.5592
Q Predictions Max            5298.135
Q Predictions Min            736.97485
V Predictions Mean           1522.2234
V Predictions Std            1484.1759
V Predictions Max            5239.885
V Predictions Min            742.1895
Log Pis Mean                 -0.11693838
Log Pis Std                  4.2721868
Log Pis Max                  30.014051
Log Pis Min                  -6.6068854
Policy mu Mean               0.010593176
Policy mu Std                0.92181885
Policy mu Max                4.587285
Policy mu Min                -4.2971764
Policy log std Mean          -0.49768838
Policy log std Std           0.30828884
Policy log std Max           -0.025823116
Policy log std Min           -2.8440714
Z mean eval                  2.6290584
Z variance eval              0.06223178
total_rewards                [11936.74357117 12261.16920296 11517.96697603 12032.96475934
 11479.52255134 11609.57141596 11813.80365629 12156.80549404
 11736.43975894 11617.84026562]
total_rewards_mean           11816.28276516697
total_rewards_std            258.11458203576314
total_rewards_max            12261.169202956007
total_rewards_min            11479.522551337845
Number of train steps total  1988000
Number of env steps total    5966000
Number of rollouts total     0
Train Time (s)               193.16960509400815
(Previous) Eval Time (s)     30.651574198622257
Sample Time (s)              7.2022353038191795
Epoch Time (s)               231.02341459644958
Total Train Time (s)         115570.92918834044
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:42:55.540732 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #496 | Epoch Duration: 231.10676836967468
2020-01-14 07:42:55.540929 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #496 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6273239
Z variance train             0.062097825
KL Divergence                66.48802
KL Loss                      6.6488023
QF Loss                      5094.266
VF Loss                      161.62311
Policy Loss                  -1389.8403
Q Predictions Mean           1390.075
Q Predictions Std            1384.4642
Q Predictions Max            5199.049
Q Predictions Min            733.95435
V Predictions Mean           1395.998
V Predictions Std            1386.106
V Predictions Max            5237.935
V Predictions Min            744.03284
Log Pis Mean                 -0.44700643
Log Pis Std                  4.1416545
Log Pis Max                  14.877721
Log Pis Min                  -6.728375
Policy mu Mean               -0.0067990646
Policy mu Std                0.88351303
Policy mu Max                2.7556038
Policy mu Min                -2.5213447
Policy log std Mean          -0.48414955
Policy log std Std           0.28022963
Policy log std Max           -0.050990105
Policy log std Min           -2.9678965
Z mean eval                  2.6040323
Z variance eval              0.051255614
total_rewards                [9292.74271469 7093.45883043 7288.75645256 7792.14610975 7050.454063
 6973.4952993  7930.41309489 6323.3070512  7306.2257901   943.51708039]
total_rewards_mean           6799.45164863072
total_rewards_std            2089.872546837835
total_rewards_max            9292.742714690487
total_rewards_min            943.5170803893957
Number of train steps total  1992000
Number of env steps total    5978000
Number of rollouts total     0
Train Time (s)               193.08491395181045
(Previous) Eval Time (s)     30.95986499125138
Sample Time (s)              8.140314473304898
Epoch Time (s)               232.18509341636673
Total Train Time (s)         115803.20129232295
Epoch                        497
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:46:47.821431 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #497 | Epoch Duration: 232.28035378456116
2020-01-14 07:46:47.821620 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6042717
Z variance train             0.051208448
KL Divergence                65.34783
KL Loss                      6.5347834
QF Loss                      186.81674
VF Loss                      59.80133
Policy Loss                  -1429.2236
Q Predictions Mean           1424.3644
Q Predictions Std            1401.308
Q Predictions Max            5205.959
Q Predictions Min            745.5225
V Predictions Mean           1429.0563
V Predictions Std            1404.7168
V Predictions Max            5213.059
V Predictions Min            749.31445
Log Pis Mean                 -0.204164
Log Pis Std                  4.21496
Log Pis Max                  13.252913
Log Pis Min                  -7.6274195
Policy mu Mean               0.008503191
Policy mu Std                0.89767253
Policy mu Max                3.18486
Policy mu Min                -3.1036847
Policy log std Mean          -0.47534505
Policy log std Std           0.28290436
Policy log std Max           0.099429846
Policy log std Min           -2.729589
Z mean eval                  2.6129563
Z variance eval              0.07568394
total_rewards                [11562.74179045 11568.80831059 11748.95930511 11658.17272549
 11303.76547359 11860.62697429 11649.97370714 11501.96595363
 11587.48333671 11569.38862386]
total_rewards_mean           11601.188620084471
total_rewards_std            140.28648947298512
total_rewards_max            11860.62697428546
total_rewards_min            11303.765473585932
Number of train steps total  1996000
Number of env steps total    5990000
Number of rollouts total     0
Train Time (s)               196.45042574917898
(Previous) Eval Time (s)     29.61918222066015
Sample Time (s)              6.949797788169235
Epoch Time (s)               233.01940575800836
Total Train Time (s)         116036.30942404084
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:50:40.934540 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #498 | Epoch Duration: 233.1127700805664
2020-01-14 07:50:40.934743 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.612509
Z variance train             0.0756129
KL Divergence                65.79682
KL Loss                      6.5796824
QF Loss                      161.6857
VF Loss                      47.008324
Policy Loss                  -1428.8225
Q Predictions Mean           1425.1133
Q Predictions Std            1421.468
Q Predictions Max            5237.163
Q Predictions Min            737.89215
V Predictions Mean           1432.2396
V Predictions Std            1417.3925
V Predictions Max            5226.51
V Predictions Min            746.13007
Log Pis Mean                 -0.21718976
Log Pis Std                  4.2017956
Log Pis Max                  25.268328
Log Pis Min                  -6.6638203
Policy mu Mean               0.026340848
Policy mu Std                0.924296
Policy mu Max                4.910967
Policy mu Min                -4.8692107
Policy log std Mean          -0.49456105
Policy log std Std           0.26620287
Policy log std Max           0.6516303
Policy log std Min           -2.7308655
Z mean eval                  2.6183379
Z variance eval              0.113136604
total_rewards                [11504.93347103 11729.662663   11360.89507952 11312.97310409
 11535.20555599 11438.00517592 11364.8398236  11303.51270238
 11509.00135311 11248.07181885]
total_rewards_mean           11430.710074748813
total_rewards_std            135.86564422496613
total_rewards_max            11729.662663004796
total_rewards_min            11248.071818849046
Number of train steps total  2000000
Number of env steps total    6002000
Number of rollouts total     0
Train Time (s)               195.16392732411623
(Previous) Eval Time (s)     30.395111151970923
Sample Time (s)              7.644431319087744
Epoch Time (s)               233.2034697951749
Total Train Time (s)         116269.59536934411
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:54:34.227486 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #499 | Epoch Duration: 233.2925899028778
2020-01-14 07:54:34.227670 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #499 | Started Training: True
2020-01-14 07:54:34.698266 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Variant:
2020-01-14 07:54:34.698963 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 100,
    "embedding_mini_batch_size": 100,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-100",
    "use_gpu": true,
    "gpu_id": 1,
    "debug": false,
    "docker": false
  }
}
