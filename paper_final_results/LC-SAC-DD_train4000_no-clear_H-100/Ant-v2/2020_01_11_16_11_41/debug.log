---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0008408131
Z variance train             0.6928118
KL Divergence                0.14952566
KL Loss                      0.014952566
QF Loss                      147.66669
VF Loss                      28.727133
Policy Loss                  -5.325657
Q Predictions Mean           0.003558436
Q Predictions Std            0.0015986895
Q Predictions Max            0.008415287
Q Predictions Min            -0.000106915366
V Predictions Mean           0.000113580965
V Predictions Std            0.0020082172
V Predictions Max            0.005039024
V Predictions Min            -0.006700429
Log Pis Mean                 -5.343969
Log Pis Std                  0.6047572
Log Pis Max                  -3.4557877
Log Pis Min                  -6.993613
Policy mu Mean               0.0015156651
Policy mu Std                0.001634151
Policy mu Max                0.0054207407
Policy mu Min                -0.0034111398
Policy log std Mean          0.0004242684
Policy log std Std           0.001777176
Policy log std Max           0.005271704
Policy log std Min           -0.0044090054
Z mean eval                  1.6890411
Z variance eval              0.0017095543
total_rewards                [177.56332038  42.41356443  23.18477802  22.76385939  63.34257041
 192.02985618 103.30741227 100.16171072   6.79773851 186.52580752]
total_rewards_mean           91.8090617832726
total_rewards_std            68.20920384866785
total_rewards_max            192.0298561786551
total_rewards_min            6.797738511554804
Number of train steps total  4000
Number of env steps total    5832
Number of rollouts total     0
Train Time (s)               181.01582340802997
(Previous) Eval Time (s)     0
Sample Time (s)              17.21999104693532
Epoch Time (s)               198.2358144549653
Total Train Time (s)         226.78802388394251
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:15:28.052011 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #0 | Epoch Duration: 226.79062175750732
2020-01-11 16:15:28.052171 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6925627
Z variance train             0.0017046279
KL Divergence                22.790974
KL Loss                      2.2790973
QF Loss                      181.24971
VF Loss                      33.62452
Policy Loss                  -87.0624
Q Predictions Mean           75.92819
Q Predictions Std            25.247452
Q Predictions Max            144.70903
Q Predictions Min            -20.726137
V Predictions Mean           85.81979
V Predictions Std            22.354326
V Predictions Max            142.05084
V Predictions Min            -7.7285256
Log Pis Mean                 -2.4815352
Log Pis Std                  1.7904583
Log Pis Max                  2.2005134
Log Pis Min                  -10.310062
Policy mu Mean               -0.015121566
Policy mu Std                0.3686454
Policy mu Max                1.3618882
Policy mu Min                -1.3727616
Policy log std Mean          -0.8110032
Policy log std Std           0.12576813
Policy log std Max           -0.23445654
Policy log std Min           -1.1036825
Z mean eval                  1.7717469
Z variance eval              0.008114017
total_rewards                [ 26.05023615   6.74751985   8.83916902  -4.46161843 -53.11718269
  33.60017933  57.30542469  -9.69322663  39.68610193  -1.9799271 ]
total_rewards_mean           10.297667612348102
total_rewards_std            29.44307300478424
total_rewards_max            57.30542468673712
total_rewards_min            -53.117182688402266
Number of train steps total  8000
Number of env steps total    9625
Number of rollouts total     0
Train Time (s)               179.51027357112616
(Previous) Eval Time (s)     10.075063060969114
Sample Time (s)              10.440442647319287
Epoch Time (s)               200.02577927941456
Total Train Time (s)         426.9149040286429
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:18:48.180321 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #1 | Epoch Duration: 200.1280016899109
2020-01-11 16:18:48.180553 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7700436
Z variance train             0.008066255
KL Divergence                21.398884
KL Loss                      2.1398885
QF Loss                      326.3734
VF Loss                      88.350716
Policy Loss                  -163.18484
Q Predictions Mean           155.48784
Q Predictions Std            30.900137
Q Predictions Max            235.16779
Q Predictions Min            0.046503633
V Predictions Mean           168.89655
V Predictions Std            24.885178
V Predictions Max            232.26857
V Predictions Min            78.422745
Log Pis Mean                 -1.8407872
Log Pis Std                  2.0815384
Log Pis Max                  4.905369
Log Pis Min                  -8.62546
Policy mu Mean               0.03745662
Policy mu Std                0.49911252
Policy mu Max                1.6385403
Policy mu Min                -1.7099965
Policy log std Mean          -0.8014393
Policy log std Std           0.12712449
Policy log std Max           -0.32539234
Policy log std Min           -1.2827942
Z mean eval                  1.7909466
Z variance eval              0.002527596
total_rewards                [  1.03566688  19.1321668  -33.91579431  23.34019464 -52.50516197
 -74.38668145  67.64881481 -79.97019547  19.56499592  -2.4062387 ]
total_rewards_mean           -11.24622328530838
total_rewards_std            45.21916251996244
total_rewards_max            67.64881481488436
total_rewards_min            -79.9701954660951
Number of train steps total  12000
Number of env steps total    12408
Number of rollouts total     0
Train Time (s)               180.75508003868163
(Previous) Eval Time (s)     19.197686758823693
Sample Time (s)              9.613187538925558
Epoch Time (s)               209.56595433643088
Total Train Time (s)         636.5733807417564
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:22:17.839332 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #2 | Epoch Duration: 209.6585829257965
2020-01-11 16:22:17.839506 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #2 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7862562
Z variance train             0.002522918
KL Divergence                22.866196
KL Loss                      2.2866197
QF Loss                      177.8201
VF Loss                      65.56425
Policy Loss                  -211.30295
Q Predictions Mean           200.49004
Q Predictions Std            34.57323
Q Predictions Max            305.7663
Q Predictions Min            0.48504853
V Predictions Mean           215.04408
V Predictions Std            24.087713
V Predictions Max            309.21643
V Predictions Min            120.29804
Log Pis Mean                 -1.9777759
Log Pis Std                  2.2468772
Log Pis Max                  5.3548207
Log Pis Min                  -9.954056
Policy mu Mean               0.026532277
Policy mu Std                0.5298688
Policy mu Max                1.8884499
Policy mu Min                -1.8100784
Policy log std Mean          -0.7816998
Policy log std Std           0.1312425
Policy log std Max           -0.27049044
Policy log std Min           -1.3018371
Z mean eval                  1.7319784
Z variance eval              0.0010720957
total_rewards                [-38.72676178  61.89556997  32.9019445   41.49066869  -0.5532133
   0.67775817 102.42250553  46.51837132  30.62148419  -4.92506626]
total_rewards_mean           27.232326102256756
total_rewards_std            37.862734756598805
total_rewards_max            102.42250552646149
total_rewards_min            -38.72676178255279
Number of train steps total  16000
Number of env steps total    16023
Number of rollouts total     0
Train Time (s)               179.64992354856804
(Previous) Eval Time (s)     15.210598646197468
Sample Time (s)              10.293179504573345
Epoch Time (s)               205.15370169933885
Total Train Time (s)         841.8362183943391
Epoch                        3
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:25:43.102227 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #3 | Epoch Duration: 205.26260423660278
2020-01-11 16:25:43.102348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #3 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7281606
Z variance train             0.0010761479
KL Divergence                23.897898
KL Loss                      2.3897898
QF Loss                      113.18805
VF Loss                      46.165565
Policy Loss                  -234.16098
Q Predictions Mean           225.34372
Q Predictions Std            27.888485
Q Predictions Max            302.9716
Q Predictions Min            131.2316
V Predictions Mean           234.8648
V Predictions Std            25.780811
V Predictions Max            306.47092
V Predictions Min            145.47993
Log Pis Mean                 -2.1221237
Log Pis Std                  2.156499
Log Pis Max                  5.096643
Log Pis Min                  -8.305198
Policy mu Mean               -0.010665379
Policy mu Std                0.5124103
Policy mu Max                1.4781525
Policy mu Min                -1.7392429
Policy log std Mean          -0.7619507
Policy log std Std           0.121833354
Policy log std Max           -0.22055128
Policy log std Min           -1.2236922
Z mean eval                  1.6328814
Z variance eval              0.009733704
total_rewards                [ -4.06551402  30.16460929  90.89326523  -9.05516889  38.6862641
  95.29956736  26.18449635 -41.85506749 -29.02612267 -52.91441313]
total_rewards_mean           14.431191611788273
total_rewards_std            48.832346756766825
total_rewards_max            95.29956735675508
total_rewards_min            -52.914413132783025
Number of train steps total  20000
Number of env steps total    18923
Number of rollouts total     0
Train Time (s)               179.00475621875376
(Previous) Eval Time (s)     15.062291969079524
Sample Time (s)              10.205887359566987
Epoch Time (s)               204.27293554740027
Total Train Time (s)         1046.2153292186558
Epoch                        4
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:29:07.482771 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #4 | Epoch Duration: 204.38031673431396
2020-01-11 16:29:07.482946 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6273801
Z variance train             0.0096279
KL Divergence                20.976341
KL Loss                      2.097634
QF Loss                      261.3344
VF Loss                      94.57967
Policy Loss                  -233.26913
Q Predictions Mean           229.77951
Q Predictions Std            33.471073
Q Predictions Max            318.8669
Q Predictions Min            -16.4615
V Predictions Mean           234.89212
V Predictions Std            32.98936
V Predictions Max            323.5096
V Predictions Min            9.31748
Log Pis Mean                 -1.7797935
Log Pis Std                  2.3690388
Log Pis Max                  15.498306
Log Pis Min                  -7.804632
Policy mu Mean               -0.0058296593
Policy mu Std                0.5243093
Policy mu Max                2.6047223
Policy mu Min                -2.301397
Policy log std Mean          -0.7722572
Policy log std Std           0.13338657
Policy log std Max           -0.21080208
Policy log std Min           -1.5167053
Z mean eval                  1.6013689
Z variance eval              0.010436955
total_rewards                [  3.61228052  12.19456573 -56.63342102  31.67607962  -4.42042162
  28.25955943 -14.57692769  24.28316685  16.83189619  10.52826752]
total_rewards_mean           5.175504553947424
total_rewards_std            24.73676395961504
total_rewards_max            31.6760796190471
total_rewards_min            -56.63342101677725
Number of train steps total  24000
Number of env steps total    21623
Number of rollouts total     0
Train Time (s)               182.8028871496208
(Previous) Eval Time (s)     11.545437798835337
Sample Time (s)              11.215893271844834
Epoch Time (s)               205.56421822030097
Total Train Time (s)         1251.8759612240829
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:32:33.163497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #5 | Epoch Duration: 205.68037486076355
2020-01-11 16:32:33.163804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6021931
Z variance train             0.010425856
KL Divergence                19.261694
KL Loss                      1.9261694
QF Loss                      471.8437
VF Loss                      77.79667
Policy Loss                  -245.73808
Q Predictions Mean           238.28491
Q Predictions Std            39.378468
Q Predictions Max            334.7862
Q Predictions Min            -33.553898
V Predictions Mean           249.81161
V Predictions Std            32.120586
V Predictions Max            328.76352
V Predictions Min            34.839184
Log Pis Mean                 -2.0297897
Log Pis Std                  2.2679899
Log Pis Max                  5.140923
Log Pis Min                  -11.467411
Policy mu Mean               0.0044477177
Policy mu Std                0.49571344
Policy mu Max                2.1264315
Policy mu Min                -2.316184
Policy log std Mean          -0.7723772
Policy log std Std           0.13237837
Policy log std Max           -0.26003978
Policy log std Min           -1.6348174
Z mean eval                  1.5582664
Z variance eval              0.067302056
total_rewards                [ -5.340186   138.16944506 131.9149812  101.23735688   9.96983971
 100.44044231 139.63174227 116.1631567  109.12661218  72.86412008]
total_rewards_mean           91.41775103861961
total_rewards_std            48.57386729399457
total_rewards_max            139.63174227412105
total_rewards_min            -5.3401860023527234
Number of train steps total  28000
Number of env steps total    24835
Number of rollouts total     0
Train Time (s)               183.97254979377612
(Previous) Eval Time (s)     19.915252462029457
Sample Time (s)              10.07689546002075
Epoch Time (s)               213.96469771582633
Total Train Time (s)         1465.9656728054397
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:36:07.237040 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #6 | Epoch Duration: 214.07293486595154
2020-01-11 16:36:07.237306 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5474927
Z variance train             0.06706138
KL Divergence                19.344318
KL Loss                      1.9344319
QF Loss                      126.66022
VF Loss                      69.982475
Policy Loss                  -255.58968
Q Predictions Mean           248.39975
Q Predictions Std            41.255817
Q Predictions Max            371.69962
Q Predictions Min            -18.797802
V Predictions Mean           260.29688
V Predictions Std            34.222374
V Predictions Max            366.73645
V Predictions Min            153.48015
Log Pis Mean                 -2.2750323
Log Pis Std                  1.9427384
Log Pis Max                  5.057677
Log Pis Min                  -7.818779
Policy mu Mean               0.0019196454
Policy mu Std                0.44806853
Policy mu Max                2.0312457
Policy mu Min                -1.6738119
Policy log std Mean          -0.7706859
Policy log std Std           0.11397878
Policy log std Max           -0.37193552
Policy log std Min           -1.1716143
Z mean eval                  1.5598696
Z variance eval              0.17634854
total_rewards                [ 35.72760279  31.40922285 107.87181649  35.63119858  64.34976518
  90.46257379  28.43151889  62.69144539  99.59292321  25.18335074]
total_rewards_mean           58.13514178994798
total_rewards_std            29.979750683136356
total_rewards_max            107.87181649046165
total_rewards_min            25.18335073926023
Number of train steps total  32000
Number of env steps total    27356
Number of rollouts total     0
Train Time (s)               179.29976256983355
(Previous) Eval Time (s)     18.922258260194212
Sample Time (s)              9.842172005213797
Epoch Time (s)               208.06419283524156
Total Train Time (s)         1674.1232892987318
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:39:35.396129 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #7 | Epoch Duration: 208.15861344337463
2020-01-11 16:39:35.396343 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5634413
Z variance train             0.17535141
KL Divergence                15.030239
KL Loss                      1.503024
QF Loss                      127.37198
VF Loss                      46.187225
Policy Loss                  -238.42564
Q Predictions Mean           229.04616
Q Predictions Std            36.294575
Q Predictions Max            304.64722
Q Predictions Min            28.213255
V Predictions Mean           237.77087
V Predictions Std            34.521564
V Predictions Max            326.91733
V Predictions Min            82.03144
Log Pis Mean                 -2.1689825
Log Pis Std                  1.8944769
Log Pis Max                  6.6234303
Log Pis Min                  -8.057707
Policy mu Mean               0.031377226
Policy mu Std                0.45652655
Policy mu Max                1.8951073
Policy mu Min                -1.6273594
Policy log std Mean          -0.7767085
Policy log std Std           0.1170613
Policy log std Max           -0.3411525
Policy log std Min           -1.6864685
Z mean eval                  1.5989338
Z variance eval              0.030427625
total_rewards                [ 53.1359269   65.26102598 140.06311414  92.60582384 100.90073013
  10.7781366  190.41838304  43.75998549 199.90415971  12.41340773]
total_rewards_mean           90.92406935518912
total_rewards_std            64.18026734807944
total_rewards_max            199.90415970997034
total_rewards_min            10.778136600719993
Number of train steps total  36000
Number of env steps total    30612
Number of rollouts total     0
Train Time (s)               180.26505747204646
(Previous) Eval Time (s)     21.763684940058738
Sample Time (s)              11.315283870324492
Epoch Time (s)               213.3440262824297
Total Train Time (s)         1887.562130072154
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:43:08.837479 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #8 | Epoch Duration: 213.44093871116638
2020-01-11 16:43:08.837758 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6042929
Z variance train             0.030667145
KL Divergence                18.760231
KL Loss                      1.8760232
QF Loss                      143.13754
VF Loss                      41.30147
Policy Loss                  -269.89453
Q Predictions Mean           257.6585
Q Predictions Std            50.895576
Q Predictions Max            345.9616
Q Predictions Min            -42.306843
V Predictions Mean           268.04398
V Predictions Std            38.36138
V Predictions Max            346.2894
V Predictions Min            153.82808
Log Pis Mean                 -2.0954566
Log Pis Std                  2.4144392
Log Pis Max                  13.777977
Log Pis Min                  -7.4636774
Policy mu Mean               0.020394085
Policy mu Std                0.46353206
Policy mu Max                2.5980031
Policy mu Min                -2.3624983
Policy log std Mean          -0.7856616
Policy log std Std           0.12529597
Policy log std Max           -0.3613073
Policy log std Min           -1.4271209
Z mean eval                  1.5586812
Z variance eval              0.028551156
total_rewards                [ 18.25590179 462.23585811 153.03518267  58.53338448  32.75572339
 243.91519335  15.18633882  19.33858157 150.33075058 400.59615963]
total_rewards_mean           155.41830743742153
total_rewards_std            156.0581526540749
total_rewards_max            462.2358581062855
total_rewards_min            15.186338818770183
Number of train steps total  40000
Number of env steps total    34271
Number of rollouts total     0
Train Time (s)               181.93124464713037
(Previous) Eval Time (s)     24.309308286756277
Sample Time (s)              8.986457924824208
Epoch Time (s)               215.22701085871086
Total Train Time (s)         2102.8926477781497
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:46:44.169701 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #9 | Epoch Duration: 215.33171844482422
2020-01-11 16:46:44.169953 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5533316
Z variance train             0.028460747
KL Divergence                19.606184
KL Loss                      1.9606184
QF Loss                      167.88425
VF Loss                      46.573444
Policy Loss                  -281.87485
Q Predictions Mean           274.53455
Q Predictions Std            45.967434
Q Predictions Max            358.9624
Q Predictions Min            -41.61342
V Predictions Mean           284.08594
V Predictions Std            35.230682
V Predictions Max            374.0461
V Predictions Min            147.42203
Log Pis Mean                 -2.299418
Log Pis Std                  2.0504038
Log Pis Max                  3.4842052
Log Pis Min                  -8.909234
Policy mu Mean               0.019435998
Policy mu Std                0.4495146
Policy mu Max                1.9251502
Policy mu Min                -2.058383
Policy log std Mean          -0.7875496
Policy log std Std           0.11192977
Policy log std Max           -0.37148196
Policy log std Min           -1.208711
Z mean eval                  1.5191205
Z variance eval              0.13789597
total_rewards                [ 51.03782112 243.73293161 370.54495176  54.00157919 298.17819101
  64.55060437 149.00680233  87.16677553 109.12277104 179.75803135]
total_rewards_mean           160.71004593168055
total_rewards_std            105.38119440440492
total_rewards_max            370.54495175644024
total_rewards_min            51.037821116681776
Number of train steps total  44000
Number of env steps total    37061
Number of rollouts total     0
Train Time (s)               183.32803066587076
(Previous) Eval Time (s)     24.417529047932476
Sample Time (s)              10.941917696967721
Epoch Time (s)               218.68747741077095
Total Train Time (s)         2321.6720085763372
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:50:22.960579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #10 | Epoch Duration: 218.79043841362
2020-01-11 16:50:22.960898 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5205128
Z variance train             0.13774702
KL Divergence                16.717516
KL Loss                      1.6717516
QF Loss                      143.46973
VF Loss                      33.177086
Policy Loss                  -297.9567
Q Predictions Mean           290.05753
Q Predictions Std            44.71569
Q Predictions Max            382.79837
Q Predictions Min            13.91575
V Predictions Mean           298.90192
V Predictions Std            40.11093
V Predictions Max            388.36224
V Predictions Min            133.91678
Log Pis Mean                 -2.3366404
Log Pis Std                  2.0963519
Log Pis Max                  9.884487
Log Pis Min                  -9.973799
Policy mu Mean               -0.0032960614
Policy mu Std                0.4306143
Policy mu Max                1.4487412
Policy mu Min                -2.1754537
Policy log std Mean          -0.7841183
Policy log std Std           0.11527407
Policy log std Max           -0.43703398
Policy log std Min           -1.271217
Z mean eval                  1.5233529
Z variance eval              0.03098014
total_rewards                [126.64802212   5.3289123   69.42697094  34.78438662 378.67531486
 159.17921005 366.37679298  74.36120905  90.1660598  175.79814551]
total_rewards_mean           148.07450242234617
total_rewards_std            122.62424683767865
total_rewards_max            378.67531485681315
total_rewards_min            5.328912302752255
Number of train steps total  48000
Number of env steps total    40686
Number of rollouts total     0
Train Time (s)               182.5903726099059
(Previous) Eval Time (s)     22.317509829998016
Sample Time (s)              9.742211380507797
Epoch Time (s)               214.6500938204117
Total Train Time (s)         2536.461436041631
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:53:57.738897 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #11 | Epoch Duration: 214.77778601646423
2020-01-11 16:53:57.739057 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #11 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.529041
Z variance train             0.031008253
KL Divergence                19.107035
KL Loss                      1.9107035
QF Loss                      179.41074
VF Loss                      40.504215
Policy Loss                  -294.31216
Q Predictions Mean           286.13986
Q Predictions Std            44.47488
Q Predictions Max            398.1241
Q Predictions Min            27.148495
V Predictions Mean           292.4863
V Predictions Std            40.772793
V Predictions Max            396.51688
V Predictions Min            106.19374
Log Pis Mean                 -2.1243823
Log Pis Std                  1.8144802
Log Pis Max                  2.941335
Log Pis Min                  -8.342952
Policy mu Mean               0.011521227
Policy mu Std                0.45437598
Policy mu Max                2.1765082
Policy mu Min                -2.6340086
Policy log std Mean          -0.78393173
Policy log std Std           0.10719066
Policy log std Max           -0.47188658
Policy log std Min           -1.2066078
Z mean eval                  1.435332
Z variance eval              0.09358429
total_rewards                [  9.63703187  57.68419118  27.4222669  187.77998529 218.6176711
 117.84139849 450.4261447   41.05715413  88.62398256  64.19878826]
total_rewards_mean           126.32886144939974
total_rewards_std            125.72557706999183
total_rewards_max            450.42614470436615
total_rewards_min            9.637031869043632
Number of train steps total  52000
Number of env steps total    44328
Number of rollouts total     0
Train Time (s)               183.1630649259314
(Previous) Eval Time (s)     21.350707925856113
Sample Time (s)              11.16914074588567
Epoch Time (s)               215.68291359767318
Total Train Time (s)         2752.307968409732
Epoch                        12
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:57:33.588877 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #12 | Epoch Duration: 215.84968948364258
2020-01-11 16:57:33.589046 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4399949
Z variance train             0.09401474
KL Divergence                16.839037
KL Loss                      1.6839037
QF Loss                      168.32834
VF Loss                      66.211624
Policy Loss                  -290.62247
Q Predictions Mean           282.778
Q Predictions Std            46.63182
Q Predictions Max            377.17346
Q Predictions Min            10.636674
V Predictions Mean           291.85263
V Predictions Std            38.232918
V Predictions Max            371.1231
V Predictions Min            175.33527
Log Pis Mean                 -2.2819824
Log Pis Std                  2.187872
Log Pis Max                  9.965768
Log Pis Min                  -13.17622
Policy mu Mean               0.010771584
Policy mu Std                0.43362522
Policy mu Max                1.6576562
Policy mu Min                -2.255216
Policy log std Mean          -0.7978368
Policy log std Std           0.10758407
Policy log std Max           -0.43112063
Policy log std Min           -1.3330222
Z mean eval                  1.3414268
Z variance eval              0.3006783
total_rewards                [ 35.52187725  48.12546636  79.90709654  47.46035258 203.24259318
  56.18797018 123.00702491 106.26117523  39.8124304  132.29663227]
total_rewards_mean           87.18226188778185
total_rewards_std            51.16860294677928
total_rewards_max            203.24259317500275
total_rewards_min            35.5218772495393
Number of train steps total  56000
Number of env steps total    47033
Number of rollouts total     0
Train Time (s)               182.18902114825323
(Previous) Eval Time (s)     21.25705675408244
Sample Time (s)              10.144223223440349
Epoch Time (s)               213.59030112577602
Total Train Time (s)         2966.004549330566
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:01:07.284310 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #13 | Epoch Duration: 213.69512343406677
2020-01-11 17:01:07.284472 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3549389
Z variance train             0.29235697
KL Divergence                15.795876
KL Loss                      1.5795876
QF Loss                      290.28824
VF Loss                      134.06374
Policy Loss                  -331.8418
Q Predictions Mean           321.98172
Q Predictions Std            57.01605
Q Predictions Max            440.3762
Q Predictions Min            -18.450766
V Predictions Mean           324.9756
V Predictions Std            44.746258
V Predictions Max            433.75653
V Predictions Min            50.9141
Log Pis Mean                 -2.3775997
Log Pis Std                  2.1905172
Log Pis Max                  9.581164
Log Pis Min                  -7.962841
Policy mu Mean               -0.0039865645
Policy mu Std                0.45436236
Policy mu Max                1.7546289
Policy mu Min                -2.7067156
Policy log std Mean          -0.76797795
Policy log std Std           0.10773728
Policy log std Max           -0.35464728
Policy log std Min           -1.2601242
Z mean eval                  1.3530555
Z variance eval              0.06747856
total_rewards                [  8.14187809  10.78156934 186.17517017 102.22956563 121.26083435
   5.96861969  28.52958561 149.89579912  59.36946042   8.81620635]
total_rewards_mean           68.11686887679352
total_rewards_std            63.655708918572145
total_rewards_max            186.17517017016675
total_rewards_min            5.96861968664935
Number of train steps total  60000
Number of env steps total    49634
Number of rollouts total     0
Train Time (s)               182.92403292795643
(Previous) Eval Time (s)     14.010791996959597
Sample Time (s)              9.288192499894649
Epoch Time (s)               206.22301742481068
Total Train Time (s)         3172.313550661318
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:04:33.594192 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #14 | Epoch Duration: 206.30959844589233
2020-01-11 17:04:33.594346 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3479571
Z variance train             0.06781204
KL Divergence                16.817183
KL Loss                      1.6817182
QF Loss                      120.68812
VF Loss                      48.117603
Policy Loss                  -289.66046
Q Predictions Mean           282.4364
Q Predictions Std            50.873947
Q Predictions Max            393.07684
Q Predictions Min            -14.582897
V Predictions Mean           291.36377
V Predictions Std            43.816814
V Predictions Max            405.27063
V Predictions Min            152.71736
Log Pis Mean                 -2.30485
Log Pis Std                  1.944773
Log Pis Max                  6.4039826
Log Pis Min                  -8.644242
Policy mu Mean               0.024610195
Policy mu Std                0.46592343
Policy mu Max                2.1360435
Policy mu Min                -2.0344028
Policy log std Mean          -0.77803344
Policy log std Std           0.105964206
Policy log std Max           -0.25790262
Policy log std Min           -1.2293203
Z mean eval                  1.2842222
Z variance eval              0.106696226
total_rewards                [  4.19862342 255.13330713   3.81514132 104.17516405 214.49610073
  26.17568264 257.72247398  84.97120015   6.37264602  65.17333267]
total_rewards_mean           102.22336721097224
total_rewards_std            98.0328418756032
total_rewards_max            257.7224739809419
total_rewards_min            3.815141319640544
Number of train steps total  64000
Number of env steps total    52805
Number of rollouts total     0
Train Time (s)               179.72112961206585
(Previous) Eval Time (s)     16.645219799131155
Sample Time (s)              10.698773220181465
Epoch Time (s)               207.06512263137847
Total Train Time (s)         3379.7680542562157
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:08:01.049987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #15 | Epoch Duration: 207.45551228523254
2020-01-11 17:08:01.050166 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2969148
Z variance train             0.110198066
KL Divergence                17.400066
KL Loss                      1.7400067
QF Loss                      149.9486
VF Loss                      69.81809
Policy Loss                  -299.15515
Q Predictions Mean           286.7218
Q Predictions Std            55.97206
Q Predictions Max            382.0262
Q Predictions Min            -13.332435
V Predictions Mean           294.99036
V Predictions Std            42.175316
V Predictions Max            383.07812
V Predictions Min            195.9239
Log Pis Mean                 -2.103934
Log Pis Std                  2.0885205
Log Pis Max                  6.9177685
Log Pis Min                  -7.5689206
Policy mu Mean               -0.012589923
Policy mu Std                0.4847639
Policy mu Max                2.3003366
Policy mu Min                -2.5137653
Policy log std Mean          -0.80977255
Policy log std Std           0.111715406
Policy log std Max           -0.46849734
Policy log std Min           -1.4263473
Z mean eval                  1.2740092
Z variance eval              0.07765347
total_rewards                [ 26.62508315   9.34506485  60.41347134  61.7768752   20.50570935
 361.95813596 130.04488756  70.98586574  83.85421261 151.82198516]
total_rewards_mean           97.73312909157289
total_rewards_std            98.08722458285499
total_rewards_max            361.9581359550649
total_rewards_min            9.345064846079108
Number of train steps total  68000
Number of env steps total    56422
Number of rollouts total     0
Train Time (s)               179.04861899092793
(Previous) Eval Time (s)     15.653172424063087
Sample Time (s)              10.344413053244352
Epoch Time (s)               205.04620446823537
Total Train Time (s)         3584.9353184369393
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:11:26.218290 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #16 | Epoch Duration: 205.16798615455627
2020-01-11 17:11:26.218449 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2817633
Z variance train             0.07740238
KL Divergence                18.013264
KL Loss                      1.8013264
QF Loss                      148.40103
VF Loss                      53.933544
Policy Loss                  -300.8031
Q Predictions Mean           293.04095
Q Predictions Std            50.06106
Q Predictions Max            407.87323
Q Predictions Min            145.73004
V Predictions Mean           297.78064
V Predictions Std            46.139606
V Predictions Max            392.92194
V Predictions Min            189.99837
Log Pis Mean                 -2.3229995
Log Pis Std                  1.8931643
Log Pis Max                  4.693446
Log Pis Min                  -10.82831
Policy mu Mean               -0.0023427024
Policy mu Std                0.4160146
Policy mu Max                1.9826553
Policy mu Min                -1.5775038
Policy log std Mean          -0.7974359
Policy log std Std           0.10510224
Policy log std Max           -0.48233
Policy log std Min           -1.2401698
Z mean eval                  1.2362154
Z variance eval              0.08538775
total_rewards                [  8.55601238 180.92830471 642.16837416 573.54252272  30.63078349
  55.27410362 211.23330771  56.73056258 344.79368182 108.13075798]
total_rewards_mean           221.19884111661287
total_rewards_std            216.16116952533824
total_rewards_max            642.1683741604202
total_rewards_min            8.556012382691382
Number of train steps total  72000
Number of env steps total    60532
Number of rollouts total     0
Train Time (s)               181.31027106195688
(Previous) Eval Time (s)     19.817141356877983
Sample Time (s)              10.885393290780485
Epoch Time (s)               212.01280570961535
Total Train Time (s)         3797.0522375362925
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:14:58.337531 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #17 | Epoch Duration: 212.11894702911377
2020-01-11 17:14:58.337731 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2411193
Z variance train             0.085559145
KL Divergence                17.724846
KL Loss                      1.7724847
QF Loss                      878.2734
VF Loss                      87.91575
Policy Loss                  -293.23218
Q Predictions Mean           284.37555
Q Predictions Std            60.839317
Q Predictions Max            421.61395
Q Predictions Min            -25.464924
V Predictions Mean           293.39246
V Predictions Std            55.980206
V Predictions Max            413.2037
V Predictions Min            -58.189682
Log Pis Mean                 -2.0937052
Log Pis Std                  2.6557894
Log Pis Max                  16.068573
Log Pis Min                  -9.3435755
Policy mu Mean               0.0162762
Policy mu Std                0.469086
Policy mu Max                2.5656717
Policy mu Min                -3.270732
Policy log std Mean          -0.7999668
Policy log std Std           0.10989339
Policy log std Max           -0.45649052
Policy log std Min           -1.6293889
Z mean eval                  1.1491933
Z variance eval              0.19590263
total_rewards                [ 83.32535704  39.98880253 342.86331707  37.10659305 284.01578552
 238.53727449 206.86467614 478.86657001 287.21927811 210.85816079]
total_rewards_mean           220.96458147525163
total_rewards_std            132.60775685079693
total_rewards_max            478.8665700111207
total_rewards_min            37.106593051562925
Number of train steps total  76000
Number of env steps total    64156
Number of rollouts total     0
Train Time (s)               182.56454988196492
(Previous) Eval Time (s)     29.150099946185946
Sample Time (s)              11.122344613075256
Epoch Time (s)               222.83699444122612
Total Train Time (s)         4019.9814922846854
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:18:41.267020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #18 | Epoch Duration: 222.92913699150085
2020-01-11 17:18:41.267179 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1483562
Z variance train             0.19598544
KL Divergence                15.8281145
KL Loss                      1.5828115
QF Loss                      161.56662
VF Loss                      42.40635
Policy Loss                  -287.30295
Q Predictions Mean           278.47272
Q Predictions Std            59.140812
Q Predictions Max            406.01846
Q Predictions Min            -93.999374
V Predictions Mean           288.27594
V Predictions Std            50.251625
V Predictions Max            411.8064
V Predictions Min            186.672
Log Pis Mean                 -2.4357462
Log Pis Std                  1.924148
Log Pis Max                  3.9920251
Log Pis Min                  -9.851122
Policy mu Mean               -0.008366538
Policy mu Std                0.39760968
Policy mu Max                1.6871475
Policy mu Min                -1.6134611
Policy log std Mean          -0.81474733
Policy log std Std           0.095439166
Policy log std Max           -0.4146647
Policy log std Min           -1.2611285
Z mean eval                  1.0947735
Z variance eval              0.16360845
total_rewards                [251.83623135  54.83272021 348.39557215 184.76906471 323.78414688
 280.01611743  20.57258248 531.09734969 493.97064237 483.23849009]
total_rewards_mean           297.2512917360468
total_rewards_std            167.81631381514399
total_rewards_max            531.0973496941052
total_rewards_min            20.572582478537925
Number of train steps total  80000
Number of env steps total    67750
Number of rollouts total     0
Train Time (s)               179.5235739289783
(Previous) Eval Time (s)     32.66453409474343
Sample Time (s)              10.220520491711795
Epoch Time (s)               222.40862851543352
Total Train Time (s)         4242.650675056968
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:22:23.937850 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #19 | Epoch Duration: 222.6705343723297
2020-01-11 17:22:23.938050 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.089591
Z variance train             0.16367576
KL Divergence                16.148926
KL Loss                      1.6148926
QF Loss                      159.51132
VF Loss                      49.247086
Policy Loss                  -280.3707
Q Predictions Mean           271.95172
Q Predictions Std            59.648148
Q Predictions Max            382.91714
Q Predictions Min            -13.975785
V Predictions Mean           283.0561
V Predictions Std            57.132355
V Predictions Max            394.45056
V Predictions Min            -8.482923
Log Pis Mean                 -2.2791982
Log Pis Std                  2.6097953
Log Pis Max                  19.443878
Log Pis Min                  -10.096113
Policy mu Mean               0.0058556553
Policy mu Std                0.44594523
Policy mu Max                4.544363
Policy mu Min                -2.2245386
Policy log std Mean          -0.8255271
Policy log std Std           0.10813575
Policy log std Max           -0.42208868
Policy log std Min           -1.2748065
Z mean eval                  1.1179564
Z variance eval              0.13181174
total_rewards                [ 12.49589241 381.2055581  105.070185   164.70505264  72.44078298
 203.57499796 305.28853777 322.19610497 351.29830884 428.55547207]
total_rewards_mean           234.68308927520167
total_rewards_std            135.51825032110878
total_rewards_max            428.55547207007186
total_rewards_min            12.495892413572271
Number of train steps total  84000
Number of env steps total    70401
Number of rollouts total     0
Train Time (s)               183.61348981503397
(Previous) Eval Time (s)     26.01122118998319
Sample Time (s)              11.147840552497655
Epoch Time (s)               220.77255155751482
Total Train Time (s)         4463.6496916622855
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:26:04.939171 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #20 | Epoch Duration: 221.00088953971863
2020-01-11 17:26:04.939495 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #20 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1282897
Z variance train             0.13163951
KL Divergence                17.12545
KL Loss                      1.712545
QF Loss                      294.42773
VF Loss                      76.38111
Policy Loss                  -311.00473
Q Predictions Mean           299.6753
Q Predictions Std            70.18777
Q Predictions Max            425.50385
Q Predictions Min            -64.364914
V Predictions Mean           306.9986
V Predictions Std            54.563297
V Predictions Max            421.219
V Predictions Min            125.34625
Log Pis Mean                 -2.0070448
Log Pis Std                  2.5939653
Log Pis Max                  15.986242
Log Pis Min                  -7.9140673
Policy mu Mean               0.017788619
Policy mu Std                0.46804014
Policy mu Max                2.3904223
Policy mu Min                -3.1998231
Policy log std Mean          -0.81524265
Policy log std Std           0.10589097
Policy log std Max           -0.3334416
Policy log std Min           -1.2483118
Z mean eval                  1.1397139
Z variance eval              0.14330728
total_rewards                [323.3987255  614.37556027 285.48178087 271.75328059 313.2465836
 522.50019236 490.63396378  51.39905068 350.19573589 176.43041729]
total_rewards_mean           339.94152908260384
total_rewards_std            158.12953330600618
total_rewards_max            614.3755602667472
total_rewards_min            51.39905068357003
Number of train steps total  88000
Number of env steps total    72846
Number of rollouts total     0
Train Time (s)               180.1546820406802
(Previous) Eval Time (s)     28.325530089903623
Sample Time (s)              9.594219466205686
Epoch Time (s)               218.0744315967895
Total Train Time (s)         4681.8702284106985
Epoch                        21
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:29:43.159575 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #21 | Epoch Duration: 218.219895362854
2020-01-11 17:29:43.159752 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1358559
Z variance train             0.14290245
KL Divergence                18.322502
KL Loss                      1.8322502
QF Loss                      174.85855
VF Loss                      36.649563
Policy Loss                  -310.33435
Q Predictions Mean           299.98584
Q Predictions Std            59.18244
Q Predictions Max            436.46594
Q Predictions Min            173.601
V Predictions Mean           309.9149
V Predictions Std            54.8767
V Predictions Max            435.3395
V Predictions Min            199.82831
Log Pis Mean                 -2.1621299
Log Pis Std                  1.8514693
Log Pis Max                  4.3382397
Log Pis Min                  -8.752154
Policy mu Mean               0.03803254
Policy mu Std                0.42015952
Policy mu Max                1.9868003
Policy mu Min                -2.1758661
Policy log std Mean          -0.82166266
Policy log std Std           0.10168155
Policy log std Max           -0.4907756
Policy log std Min           -1.2095323
Z mean eval                  1.3255367
Z variance eval              0.39696547
total_rewards                [381.4817191  317.12274568 169.96277102 105.8377406   70.58079301
 289.05095934 320.48277997 503.38376452 369.57378099 190.66281566]
total_rewards_mean           271.81398698922646
total_rewards_std            128.42480072761992
total_rewards_max            503.38376451751753
total_rewards_min            70.58079301170496
Number of train steps total  92000
Number of env steps total    76690
Number of rollouts total     0
Train Time (s)               183.03978347498924
(Previous) Eval Time (s)     28.705209196079522
Sample Time (s)              11.12643530825153
Epoch Time (s)               222.8714279793203
Total Train Time (s)         4904.86160813272
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:33:26.154015 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #22 | Epoch Duration: 222.99403524398804
2020-01-11 17:33:26.154401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3264691
Z variance train             0.3930406
KL Divergence                16.460438
KL Loss                      1.6460438
QF Loss                      174.50752
VF Loss                      43.429806
Policy Loss                  -346.30365
Q Predictions Mean           337.075
Q Predictions Std            66.52162
Q Predictions Max            468.12418
Q Predictions Min            54.79698
V Predictions Mean           346.6579
V Predictions Std            61.400986
V Predictions Max            464.51822
V Predictions Min            163.63503
Log Pis Mean                 -2.145803
Log Pis Std                  2.0595417
Log Pis Max                  11.367162
Log Pis Min                  -8.710533
Policy mu Mean               0.03780869
Policy mu Std                0.41850019
Policy mu Max                2.6799526
Policy mu Min                -2.7213647
Policy log std Mean          -0.813472
Policy log std Std           0.10050648
Policy log std Max           -0.42204788
Policy log std Min           -1.2118607
Z mean eval                  1.1718035
Z variance eval              0.12186785
total_rewards                [ 11.47058772  54.18853008  48.06306979 254.19788374 423.18805916
 326.0738592  501.21245243 411.78019912 318.60894892 399.0417518 ]
total_rewards_mean           274.7825341948264
total_rewards_std            167.8914276837884
total_rewards_max            501.21245242521206
total_rewards_min            11.470587718942902
Number of train steps total  96000
Number of env steps total    79521
Number of rollouts total     0
Train Time (s)               180.23178208013996
(Previous) Eval Time (s)     27.491736782714725
Sample Time (s)              10.936160037759691
Epoch Time (s)               218.65967890061438
Total Train Time (s)         5123.610523079522
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:37:04.901605 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #23 | Epoch Duration: 218.74700808525085
2020-01-11 17:37:04.901720 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1645607
Z variance train             0.12210526
KL Divergence                19.342916
KL Loss                      1.9342917
QF Loss                      153.53522
VF Loss                      40.27171
Policy Loss                  -337.1676
Q Predictions Mean           333.17014
Q Predictions Std            65.279724
Q Predictions Max            485.1902
Q Predictions Min            100.137764
V Predictions Mean           338.814
V Predictions Std            60.88164
V Predictions Max            470.98312
V Predictions Min            80.03837
Log Pis Mean                 -2.2312603
Log Pis Std                  2.5469828
Log Pis Max                  16.454836
Log Pis Min                  -8.068568
Policy mu Mean               0.016031483
Policy mu Std                0.44275966
Policy mu Max                2.743991
Policy mu Min                -2.1912572
Policy log std Mean          -0.82251084
Policy log std Std           0.09696916
Policy log std Max           -0.49687043
Policy log std Min           -1.3736876
Z mean eval                  1.130048
Z variance eval              0.19028285
total_rewards                [700.52336646 205.45283669 484.09126988  31.50432411 568.95668608
 530.93964847 227.26428945 347.71945152 104.75831758 724.00744702]
total_rewards_mean           392.521763726544
total_rewards_std            232.56718786297893
total_rewards_max            724.0074470240885
total_rewards_min            31.504324113672737
Number of train steps total  100000
Number of env steps total    83447
Number of rollouts total     0
Train Time (s)               181.99774251691997
(Previous) Eval Time (s)     34.999812284018844
Sample Time (s)              10.031334941275418
Epoch Time (s)               227.02888974221423
Total Train Time (s)         5350.792754852679
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:40:52.088408 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #24 | Epoch Duration: 227.1865475177765
2020-01-11 17:40:52.088712 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1289604
Z variance train             0.18891366
KL Divergence                16.96503
KL Loss                      1.696503
QF Loss                      210.27628
VF Loss                      56.827057
Policy Loss                  -321.23456
Q Predictions Mean           314.18082
Q Predictions Std            66.5566
Q Predictions Max            440.97293
Q Predictions Min            -41.676876
V Predictions Mean           324.19904
V Predictions Std            61.17086
V Predictions Max            444.42117
V Predictions Min            160.68076
Log Pis Mean                 -2.2820663
Log Pis Std                  2.0034614
Log Pis Max                  9.826508
Log Pis Min                  -7.65909
Policy mu Mean               0.006839468
Policy mu Std                0.4245312
Policy mu Max                1.9762825
Policy mu Min                -2.1893349
Policy log std Mean          -0.803904
Policy log std Std           0.102169774
Policy log std Max           -0.38946643
Policy log std Min           -1.3344336
Z mean eval                  1.114889
Z variance eval              0.09205666
total_rewards                [ 81.64883802  12.61136419 311.98259179 293.06765214 377.63207984
 215.2363143   21.42486701 217.66473686 361.40260801 332.91070912]
total_rewards_mean           222.55817612812717
total_rewards_std            131.50549592771603
total_rewards_max            377.6320798388844
total_rewards_min            12.61136418844357
Number of train steps total  104000
Number of env steps total    87031
Number of rollouts total     0
Train Time (s)               180.37854788498953
(Previous) Eval Time (s)     25.513216314837337
Sample Time (s)              10.041909465566278
Epoch Time (s)               215.93367366539314
Total Train Time (s)         5566.900763720274
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:44:28.198510 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #25 | Epoch Duration: 216.10957074165344
2020-01-11 17:44:28.198735 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1150663
Z variance train             0.09251985
KL Divergence                18.668089
KL Loss                      1.8668089
QF Loss                      194.86606
VF Loss                      47.569927
Policy Loss                  -338.16443
Q Predictions Mean           330.00345
Q Predictions Std            71.111664
Q Predictions Max            477.34702
Q Predictions Min            2.9708726
V Predictions Mean           337.8615
V Predictions Std            63.648342
V Predictions Max            488.58524
V Predictions Min            82.265625
Log Pis Mean                 -2.141564
Log Pis Std                  2.1956797
Log Pis Max                  11.695005
Log Pis Min                  -9.6940155
Policy mu Mean               0.023067078
Policy mu Std                0.41588253
Policy mu Max                2.3666298
Policy mu Min                -1.9000801
Policy log std Mean          -0.832728
Policy log std Std           0.1015748
Policy log std Max           -0.49006402
Policy log std Min           -1.2818979
Z mean eval                  1.1303757
Z variance eval              0.08732809
total_rewards                [456.19631423 385.89052842 201.58924241 305.05636311 255.71294878
 356.93046248  12.55005766  43.87203965 257.60112378 363.98436558]
total_rewards_mean           263.9383446096781
total_rewards_std            137.04137010652812
total_rewards_max            456.19631422744516
total_rewards_min            12.550057655955545
Number of train steps total  108000
Number of env steps total    91634
Number of rollouts total     0
Train Time (s)               183.42114514485002
(Previous) Eval Time (s)     24.691989259328693
Sample Time (s)              11.106229742057621
Epoch Time (s)               219.21936414623633
Total Train Time (s)         5786.214887836017
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:48:07.512615 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #26 | Epoch Duration: 219.31371974945068
2020-01-11 17:48:07.512795 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1367468
Z variance train             0.086726844
KL Divergence                19.392742
KL Loss                      1.9392742
QF Loss                      275.92578
VF Loss                      45.01595
Policy Loss                  -342.55515
Q Predictions Mean           332.08557
Q Predictions Std            73.75213
Q Predictions Max            464.35608
Q Predictions Min            133.87775
V Predictions Mean           340.74222
V Predictions Std            69.58352
V Predictions Max            464.07913
V Predictions Min            151.8554
Log Pis Mean                 -2.381177
Log Pis Std                  2.161974
Log Pis Max                  4.8424807
Log Pis Min                  -11.177816
Policy mu Mean               0.030492622
Policy mu Std                0.42193666
Policy mu Max                2.3733137
Policy mu Min                -1.8563781
Policy log std Mean          -0.8284335
Policy log std Std           0.10433401
Policy log std Max           -0.478522
Policy log std Min           -1.3302051
Z mean eval                  1.1742742
Z variance eval              0.12693965
total_rewards                [333.58666572 279.6634607  182.00876017  45.82356516  97.51251544
  19.61864405 476.91677337 264.13470932 280.76759966 325.52559063]
total_rewards_mean           230.55582842116928
total_rewards_std            136.03914617775052
total_rewards_max            476.91677336829775
total_rewards_min            19.61864404690973
Number of train steps total  112000
Number of env steps total    94327
Number of rollouts total     0
Train Time (s)               182.7535395808518
(Previous) Eval Time (s)     22.52383784810081
Sample Time (s)              9.687686531804502
Epoch Time (s)               214.9650639607571
Total Train Time (s)         6001.31608602358
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:51:42.617196 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #27 | Epoch Duration: 215.104229927063
2020-01-11 17:51:42.617459 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1813407
Z variance train             0.1256781
KL Divergence                19.727516
KL Loss                      1.9727516
QF Loss                      179.29248
VF Loss                      66.38344
Policy Loss                  -350.02924
Q Predictions Mean           342.60648
Q Predictions Std            74.51821
Q Predictions Max            493.8787
Q Predictions Min            197.52046
V Predictions Mean           345.4131
V Predictions Std            70.61169
V Predictions Max            477.98
V Predictions Min            212.66971
Log Pis Mean                 -2.1967719
Log Pis Std                  2.0969121
Log Pis Max                  12.496247
Log Pis Min                  -7.6927395
Policy mu Mean               0.00922025
Policy mu Std                0.42982024
Policy mu Max                2.5629706
Policy mu Min                -3.226181
Policy log std Mean          -0.8360622
Policy log std Std           0.107114375
Policy log std Max           -0.4244601
Policy log std Min           -1.3689749
Z mean eval                  1.1676159
Z variance eval              0.12181395
total_rewards                [211.94151613 358.36190003 389.24028643 268.38819904 268.96911909
 119.12190959 371.01209002  95.98445264 249.97034826 365.6074052 ]
total_rewards_mean           269.85972264298033
total_rewards_std            99.09154190386623
total_rewards_max            389.24028642717803
total_rewards_min            95.98445264175243
Number of train steps total  116000
Number of env steps total    99967
Number of rollouts total     0
Train Time (s)               181.44524144520983
(Previous) Eval Time (s)     25.39426265936345
Sample Time (s)              11.602968720253557
Epoch Time (s)               218.44247282482684
Total Train Time (s)         6219.856243280228
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:55:21.155624 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #28 | Epoch Duration: 218.53798389434814
2020-01-11 17:55:21.155744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1693387
Z variance train             0.12184076
KL Divergence                20.091984
KL Loss                      2.0091984
QF Loss                      216.13799
VF Loss                      36.40132
Policy Loss                  -344.502
Q Predictions Mean           337.58304
Q Predictions Std            76.16023
Q Predictions Max            517.88916
Q Predictions Min            120.56204
V Predictions Mean           344.62097
V Predictions Std            73.20105
V Predictions Max            510.70334
V Predictions Min            203.58887
Log Pis Mean                 -2.3044133
Log Pis Std                  2.0623777
Log Pis Max                  8.715115
Log Pis Min                  -9.170023
Policy mu Mean               -0.011150785
Policy mu Std                0.3962051
Policy mu Max                1.9819119
Policy mu Min                -2.1732981
Policy log std Mean          -0.8257656
Policy log std Std           0.09873115
Policy log std Max           -0.53575796
Policy log std Min           -1.2531879
Z mean eval                  1.1487491
Z variance eval              0.10507629
total_rewards                [847.76272959 394.42472268 259.56735129 553.75281596 690.60041481
 283.75343753 391.23978334 283.24199451 289.27674328 562.49944687]
total_rewards_mean           455.61194398595234
total_rewards_std            190.60264091937628
total_rewards_max            847.7627295937427
total_rewards_min            259.567351293043
Number of train steps total  120000
Number of env steps total    103225
Number of rollouts total     0
Train Time (s)               180.8575971662067
(Previous) Eval Time (s)     25.4833294400014
Sample Time (s)              11.239177884534001
Epoch Time (s)               217.5801044907421
Total Train Time (s)         6437.557891414501
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:58:58.858989 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #29 | Epoch Duration: 217.70314145088196
2020-01-11 17:58:58.859153 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.145245
Z variance train             0.10404762
KL Divergence                21.327467
KL Loss                      2.1327467
QF Loss                      181.80312
VF Loss                      47.16521
Policy Loss                  -360.2689
Q Predictions Mean           352.58813
Q Predictions Std            77.963234
Q Predictions Max            536.3397
Q Predictions Min            179.53024
V Predictions Mean           362.06042
V Predictions Std            74.89714
V Predictions Max            525.158
V Predictions Min            209.91461
Log Pis Mean                 -2.0985518
Log Pis Std                  1.927501
Log Pis Max                  6.7881355
Log Pis Min                  -8.103656
Policy mu Mean               0.017466843
Policy mu Std                0.4148106
Policy mu Max                1.7936655
Policy mu Min                -2.9794261
Policy log std Mean          -0.840959
Policy log std Std           0.11036393
Policy log std Max           -0.44488364
Policy log std Min           -1.339426
Z mean eval                  1.1603664
Z variance eval              0.07516741
total_rewards                [ 649.6572915  1063.70383779  269.50926495  497.62175433  471.63090682
  697.42037148  241.81935817  797.44081537   57.68691438  520.14840874]
total_rewards_mean           526.6638923526862
total_rewards_std            278.77159829499
total_rewards_max            1063.7038377933845
total_rewards_min            57.68691437940184
Number of train steps total  124000
Number of env steps total    106746
Number of rollouts total     0
Train Time (s)               182.19860317278653
(Previous) Eval Time (s)     30.040167558006942
Sample Time (s)              9.538578768260777
Epoch Time (s)               221.77734949905425
Total Train Time (s)         6659.674702955876
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:02:40.976933 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #30 | Epoch Duration: 222.11765551567078
2020-01-11 18:02:40.977091 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608449
Z variance train             0.074832894
KL Divergence                21.488821
KL Loss                      2.1488822
QF Loss                      243.23961
VF Loss                      43.23728
Policy Loss                  -364.5317
Q Predictions Mean           355.86914
Q Predictions Std            89.45618
Q Predictions Max            508.01282
Q Predictions Min            -42.692486
V Predictions Mean           363.2651
V Predictions Std            86.716194
V Predictions Max            504.00485
V Predictions Min            -109.0439
Log Pis Mean                 -2.2000732
Log Pis Std                  2.644853
Log Pis Max                  14.061277
Log Pis Min                  -10.959858
Policy mu Mean               -0.01118155
Policy mu Std                0.43995675
Policy mu Max                4.3971596
Policy mu Min                -2.3608043
Policy log std Mean          -0.81946194
Policy log std Std           0.10998783
Policy log std Max           -0.5106172
Policy log std Min           -1.4119648
Z mean eval                  1.1430519
Z variance eval              0.104537986
total_rewards                [386.78726435 661.53647256 317.8603958  491.19328029 703.33561575
 266.45949935 155.28786353 437.70054487 380.04933681 549.75519833]
total_rewards_mean           434.9965471632801
total_rewards_std            162.90089593908127
total_rewards_max            703.3356157477933
total_rewards_min            155.28786353039004
Number of train steps total  128000
Number of env steps total    110448
Number of rollouts total     0
Train Time (s)               185.54907040530816
(Previous) Eval Time (s)     20.80588570702821
Sample Time (s)              8.683904469944537
Epoch Time (s)               215.0388605822809
Total Train Time (s)         6874.857368067838
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:06:16.160623 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #31 | Epoch Duration: 215.18340420722961
2020-01-11 18:06:16.160798 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1373407
Z variance train             0.104119346
KL Divergence                20.825428
KL Loss                      2.082543
QF Loss                      300.03766
VF Loss                      41.777897
Policy Loss                  -373.31915
Q Predictions Mean           367.49503
Q Predictions Std            86.59702
Q Predictions Max            538.4524
Q Predictions Min            202.44821
V Predictions Mean           374.67804
V Predictions Std            83.219536
V Predictions Max            538.3493
V Predictions Min            228.41023
Log Pis Mean                 -2.2926114
Log Pis Std                  1.9291813
Log Pis Max                  8.179291
Log Pis Min                  -7.616225
Policy mu Mean               0.027732711
Policy mu Std                0.41224715
Policy mu Max                1.7661345
Policy mu Min                -2.4762363
Policy log std Mean          -0.82729256
Policy log std Std           0.10232085
Policy log std Max           -0.47814023
Policy log std Min           -1.2917106
Z mean eval                  1.1429098
Z variance eval              0.114391185
total_rewards                [ 60.1963944   32.6192873  448.57682934 322.95172599 356.58077499
 568.05693764 594.47994268 996.037698   474.19136916 336.97819584]
total_rewards_mean           419.06691553364305
total_rewards_std            262.256288128354
total_rewards_max            996.0376979987577
total_rewards_min            32.61928729634519
Number of train steps total  132000
Number of env steps total    113246
Number of rollouts total     0
Train Time (s)               183.89943087287247
(Previous) Eval Time (s)     30.807935363147408
Sample Time (s)              10.083778525702655
Epoch Time (s)               224.79114476172253
Total Train Time (s)         7099.75864482997
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:10:01.063741 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #32 | Epoch Duration: 224.90275359153748
2020-01-11 18:10:01.064040 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #32 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1461309
Z variance train             0.11391191
KL Divergence                20.767622
KL Loss                      2.0767622
QF Loss                      741.84
VF Loss                      60.582077
Policy Loss                  -390.13623
Q Predictions Mean           383.72174
Q Predictions Std            90.88152
Q Predictions Max            547.0204
Q Predictions Min            207.00111
V Predictions Mean           391.9258
V Predictions Std            86.77849
V Predictions Max            540.9039
V Predictions Min            217.38823
Log Pis Mean                 -2.436872
Log Pis Std                  2.1278439
Log Pis Max                  7.9284577
Log Pis Min                  -8.676944
Policy mu Mean               -0.016615275
Policy mu Std                0.40735602
Policy mu Max                1.8482515
Policy mu Min                -2.2220964
Policy log std Mean          -0.83392465
Policy log std Std           0.1008495
Policy log std Max           -0.5259704
Policy log std Min           -1.300828
Z mean eval                  1.1251827
Z variance eval              0.067916125
total_rewards                [ 652.7261956   237.72669235  400.14170132  147.16679562  349.3366848
  446.89025177  329.837698   1134.7690119   106.09451245  602.80934946]
total_rewards_mean           440.74988932555743
total_rewards_std            285.4133941063226
total_rewards_max            1134.7690118957423
total_rewards_min            106.09451245145814
Number of train steps total  136000
Number of env steps total    116968
Number of rollouts total     0
Train Time (s)               182.34000556124374
(Previous) Eval Time (s)     33.76112409075722
Sample Time (s)              10.260854091029614
Epoch Time (s)               226.36198374303058
Total Train Time (s)         7326.27736053383
Epoch                        33
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:13:47.583070 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #33 | Epoch Duration: 226.51886081695557
2020-01-11 18:13:47.583247 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1230006
Z variance train             0.06796284
KL Divergence                22.02737
KL Loss                      2.202737
QF Loss                      540.8643
VF Loss                      94.55529
Policy Loss                  -389.5167
Q Predictions Mean           379.3415
Q Predictions Std            97.279434
Q Predictions Max            557.4469
Q Predictions Min            -25.922459
V Predictions Mean           391.54504
V Predictions Std            90.104004
V Predictions Max            565.32776
V Predictions Min            111.76196
Log Pis Mean                 -1.9771664
Log Pis Std                  1.995547
Log Pis Max                  7.2273464
Log Pis Min                  -7.3891087
Policy mu Mean               -0.0057909945
Policy mu Std                0.42464346
Policy mu Max                2.1241488
Policy mu Min                -2.011695
Policy log std Mean          -0.85491264
Policy log std Std           0.10960375
Policy log std Max           -0.48756105
Policy log std Min           -1.4081008
Z mean eval                  1.1644824
Z variance eval              1.0328948
total_rewards                [ 362.80857463  547.84756843  694.7840378   120.99338085   67.59049681
  754.50146471 1264.26265288  408.4880293  1038.00983475  909.17155192]
total_rewards_mean           616.8457592089613
total_rewards_std            369.76548782162763
total_rewards_max            1264.2626528812343
total_rewards_min            67.59049680936101
Number of train steps total  140000
Number of env steps total    119807
Number of rollouts total     0
Train Time (s)               184.18448248738423
(Previous) Eval Time (s)     34.66166361421347
Sample Time (s)              10.32292820001021
Epoch Time (s)               229.1690743016079
Total Train Time (s)         7555.559502862394
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:17:36.867730 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #34 | Epoch Duration: 229.28428888320923
2020-01-11 18:17:36.868094 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #34 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1632748
Z variance train             1.0320327
KL Divergence                15.793717
KL Loss                      1.5793718
QF Loss                      479.17572
VF Loss                      118.93726
Policy Loss                  -489.82812
Q Predictions Mean           482.80585
Q Predictions Std            106.89178
Q Predictions Max            652.39825
Q Predictions Min            -0.06434387
V Predictions Mean           490.67706
V Predictions Std            95.77153
V Predictions Max            649.51404
V Predictions Min            296.5934
Log Pis Mean                 -2.558153
Log Pis Std                  1.897342
Log Pis Max                  3.5037675
Log Pis Min                  -10.820084
Policy mu Mean               0.02249398
Policy mu Std                0.3979253
Policy mu Max                2.413049
Policy mu Min                -1.939165
Policy log std Mean          -0.8071895
Policy log std Std           0.10748168
Policy log std Max           -0.427721
Policy log std Min           -1.2433248
Z mean eval                  1.1625949
Z variance eval              0.08641218
total_rewards                [186.04042867 469.02885321 669.49691344 989.61286861 595.4096438
  40.87510142 164.62261868 381.88331111 335.71177993 471.4178591 ]
total_rewards_mean           430.4099377961408
total_rewards_std            263.3795345723486
total_rewards_max            989.6128686051455
total_rewards_min            40.875101415274
Number of train steps total  144000
Number of env steps total    123404
Number of rollouts total     0
Train Time (s)               180.79643868468702
(Previous) Eval Time (s)     28.126490148715675
Sample Time (s)              10.685460718348622
Epoch Time (s)               219.60838955175132
Total Train Time (s)         7775.341571929399
Epoch                        35
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:21:16.650789 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #35 | Epoch Duration: 219.78250694274902
2020-01-11 18:21:16.650980 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1655117
Z variance train             0.08687336
KL Divergence                21.140745
KL Loss                      2.1140745
QF Loss                      262.60565
VF Loss                      73.82266
Policy Loss                  -400.4973
Q Predictions Mean           387.98682
Q Predictions Std            109.084305
Q Predictions Max            565.4529
Q Predictions Min            -76.698044
V Predictions Mean           396.355
V Predictions Std            98.09624
V Predictions Max            557.82684
V Predictions Min            -22.292696
Log Pis Mean                 -2.0361495
Log Pis Std                  2.6759965
Log Pis Max                  12.806269
Log Pis Min                  -9.37221
Policy mu Mean               0.027378606
Policy mu Std                0.46363565
Policy mu Max                1.9625993
Policy mu Min                -2.9662104
Policy log std Mean          -0.82446206
Policy log std Std           0.10836535
Policy log std Max           -0.52458465
Policy log std Min           -1.221333
Z mean eval                  1.1746418
Z variance eval              0.09195014
total_rewards                [ 120.42436638  387.26903999  352.36499991  916.47623775  283.70619285
   16.85748771 1328.37684977  210.6380477  1092.76522633  504.90683653]
total_rewards_mean           521.3785284914027
total_rewards_std            418.2113101646427
total_rewards_max            1328.3768497685046
total_rewards_min            16.857487707507186
Number of train steps total  148000
Number of env steps total    127128
Number of rollouts total     0
Train Time (s)               182.67129893042147
(Previous) Eval Time (s)     21.633049204945564
Sample Time (s)              11.252314225304872
Epoch Time (s)               215.5566623606719
Total Train Time (s)         7991.077460516244
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:24:52.389023 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #36 | Epoch Duration: 215.73787569999695
2020-01-11 18:24:52.389276 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1743475
Z variance train             0.09184836
KL Divergence                21.003141
KL Loss                      2.1003141
QF Loss                      219.64447
VF Loss                      70.00634
Policy Loss                  -410.75854
Q Predictions Mean           402.43634
Q Predictions Std            109.518845
Q Predictions Max            623.36743
Q Predictions Min            17.268677
V Predictions Mean           412.8801
V Predictions Std            105.655655
V Predictions Max            607.2664
V Predictions Min            -21.868382
Log Pis Mean                 -1.699048
Log Pis Std                  2.5283954
Log Pis Max                  16.382751
Log Pis Min                  -7.8645535
Policy mu Mean               -0.016527563
Policy mu Std                0.45844483
Policy mu Max                2.4929218
Policy mu Min                -3.0169182
Policy log std Mean          -0.8402634
Policy log std Std           0.11427449
Policy log std Max           -0.47133708
Policy log std Min           -1.3412452
Z mean eval                  1.1438087
Z variance eval              0.1464934
total_rewards                [ 713.51580932  366.16283848  390.54369386  441.52126021  606.31174136
  435.22809628  789.35541454 1252.14645775  528.22062663  939.94685624]
total_rewards_mean           646.2952794682856
total_rewards_std            269.10533633424893
total_rewards_max            1252.1464577549186
total_rewards_min            366.1628384786085
Number of train steps total  152000
Number of env steps total    130836
Number of rollouts total     0
Train Time (s)               184.34791170805693
(Previous) Eval Time (s)     37.07430863706395
Sample Time (s)              10.00567711982876
Epoch Time (s)               231.42789746494964
Total Train Time (s)         8222.644508658443
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:28:43.963603 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #37 | Epoch Duration: 231.57405471801758
2020-01-11 18:28:43.964098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1402183
Z variance train             0.14501098
KL Divergence                20.681044
KL Loss                      2.0681045
QF Loss                      823.0198
VF Loss                      113.90501
Policy Loss                  -409.5046
Q Predictions Mean           397.17682
Q Predictions Std            128.22113
Q Predictions Max            575.6297
Q Predictions Min            -54.23366
V Predictions Mean           412.0814
V Predictions Std            110.61144
V Predictions Max            584.34766
V Predictions Min            -9.780056
Log Pis Mean                 -1.5516768
Log Pis Std                  3.033529
Log Pis Max                  18.549149
Log Pis Min                  -8.782911
Policy mu Mean               -0.0035866508
Policy mu Std                0.5095548
Policy mu Max                2.9610274
Policy mu Min                -3.0369506
Policy log std Mean          -0.8566157
Policy log std Std           0.1209038
Policy log std Max           -0.4849013
Policy log std Min           -1.4266534
Z mean eval                  1.1695429
Z variance eval              0.112011135
total_rewards                [562.59354629 219.47193792 445.39134761 694.58252021 680.60763344
 305.06310714 774.54208976  47.63900254 328.50934359  86.62888161]
total_rewards_mean           414.50294101105055
total_rewards_std            245.20787183002116
total_rewards_max            774.5420897645938
total_rewards_min            47.63900253996852
Number of train steps total  156000
Number of env steps total    134879
Number of rollouts total     0
Train Time (s)               178.3936689668335
(Previous) Eval Time (s)     19.062559206970036
Sample Time (s)              10.012169959023595
Epoch Time (s)               207.46839813282713
Total Train Time (s)         8430.221020872239
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:32:11.538139 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #38 | Epoch Duration: 207.57378339767456
2020-01-11 18:32:11.538438 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #38 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1767589
Z variance train             0.11267261
KL Divergence                20.194931
KL Loss                      2.019493
QF Loss                      223.66481
VF Loss                      72.35364
Policy Loss                  -419.23203
Q Predictions Mean           410.06158
Q Predictions Std            111.94089
Q Predictions Max            611.61884
Q Predictions Min            150.75708
V Predictions Mean           414.2471
V Predictions Std            106.67835
V Predictions Max            607.07825
V Predictions Min            215.48119
Log Pis Mean                 -1.9109385
Log Pis Std                  2.4461164
Log Pis Max                  11.740199
Log Pis Min                  -8.254345
Policy mu Mean               0.0026099288
Policy mu Std                0.47140753
Policy mu Max                2.704321
Policy mu Min                -2.5521274
Policy log std Mean          -0.8525196
Policy log std Std           0.12037797
Policy log std Max           -0.46855712
Policy log std Min           -1.6948904
Z mean eval                  1.173641
Z variance eval              0.109868184
total_rewards                [ 81.84207201  93.28914079  23.54303172 453.68264102 239.7574997
 355.90284091 345.87993938 396.95261267 604.12828239 172.70654803]
total_rewards_mean           276.7684608609437
total_rewards_std            176.61504060688344
total_rewards_max            604.128282391101
total_rewards_min            23.5430317150579
Number of train steps total  160000
Number of env steps total    138128
Number of rollouts total     0
Train Time (s)               174.03276340989396
(Previous) Eval Time (s)     18.280216651037335
Sample Time (s)              7.751875674817711
Epoch Time (s)               200.064855735749
Total Train Time (s)         8630.410434118472
Epoch                        39
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:35:31.730031 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #39 | Epoch Duration: 200.19130063056946
2020-01-11 18:35:31.730369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1735708
Z variance train             0.10916126
KL Divergence                20.562881
KL Loss                      2.0562882
QF Loss                      244.95462
VF Loss                      66.31305
Policy Loss                  -423.29202
Q Predictions Mean           414.50937
Q Predictions Std            114.53838
Q Predictions Max            606.2139
Q Predictions Min            29.625113
V Predictions Mean           419.46362
V Predictions Std            110.21396
V Predictions Max            604.4081
V Predictions Min            54.104046
Log Pis Mean                 -2.0297427
Log Pis Std                  2.5800564
Log Pis Max                  16.786371
Log Pis Min                  -8.165742
Policy mu Mean               0.028492589
Policy mu Std                0.44515797
Policy mu Max                2.1269312
Policy mu Min                -2.542935
Policy log std Mean          -0.8452658
Policy log std Std           0.1132065
Policy log std Max           -0.28424355
Policy log std Min           -1.4399989
Z mean eval                  1.1567245
Z variance eval              0.15968929
total_rewards                [  66.40689321  656.17456503   49.72204007  461.29603716  745.42072066
  531.25162014  893.74356871 1021.3153058   293.64702237   34.63337528]
total_rewards_mean           475.3611148430631
total_rewards_std            340.2543541180607
total_rewards_max            1021.3153057986675
total_rewards_min            34.633375278010256
Number of train steps total  164000
Number of env steps total    141544
Number of rollouts total     0
Train Time (s)               175.90345583017915
(Previous) Eval Time (s)     19.48079312313348
Sample Time (s)              8.607297715730965
Epoch Time (s)               203.9915466690436
Total Train Time (s)         8834.739241203293
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:38:56.060690 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #40 | Epoch Duration: 204.33010244369507
2020-01-11 18:38:56.060961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1710182
Z variance train             0.16002782
KL Divergence                18.58401
KL Loss                      1.858401
QF Loss                      276.50076
VF Loss                      76.814865
Policy Loss                  -430.60248
Q Predictions Mean           419.77463
Q Predictions Std            119.658554
Q Predictions Max            631.0615
Q Predictions Min            -4.805912
V Predictions Mean           426.4498
V Predictions Std            114.22586
V Predictions Max            625.9316
V Predictions Min            103.94222
Log Pis Mean                 -1.6729517
Log Pis Std                  2.4554882
Log Pis Max                  18.704107
Log Pis Min                  -8.802155
Policy mu Mean               -0.013117473
Policy mu Std                0.46623436
Policy mu Max                1.6019235
Policy mu Min                -3.7126114
Policy log std Mean          -0.85866225
Policy log std Std           0.12084805
Policy log std Max           -0.5451305
Policy log std Min           -1.4549608
Z mean eval                  1.1503391
Z variance eval              0.14355066
total_rewards                [ 103.9730305   197.37316624 1570.42390644  246.68245593  505.30676138
   70.69174675   94.88075756  490.32202755  191.56859052  586.05442422]
total_rewards_mean           405.72768671065893
total_rewards_std            426.6859604203309
total_rewards_max            1570.4239064354151
total_rewards_min            70.69174675380944
Number of train steps total  168000
Number of env steps total    144853
Number of rollouts total     0
Train Time (s)               174.30007797898725
(Previous) Eval Time (s)     15.356404695194215
Sample Time (s)              7.392840544693172
Epoch Time (s)               197.04932321887463
Total Train Time (s)         9031.886184086557
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:42:13.206752 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #41 | Epoch Duration: 197.14560794830322
2020-01-11 18:42:13.206874 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1556176
Z variance train             0.14340647
KL Divergence                19.887201
KL Loss                      1.9887202
QF Loss                      233.02292
VF Loss                      64.300064
Policy Loss                  -452.0773
Q Predictions Mean           444.6889
Q Predictions Std            122.727844
Q Predictions Max            656.7
Q Predictions Min            64.41861
V Predictions Mean           448.97156
V Predictions Std            119.31959
V Predictions Max            648.8514
V Predictions Min            147.358
Log Pis Mean                 -1.880975
Log Pis Std                  2.5033314
Log Pis Max                  18.150494
Log Pis Min                  -7.7763786
Policy mu Mean               0.04413441
Policy mu Std                0.46490872
Policy mu Max                4.388809
Policy mu Min                -1.9982985
Policy log std Mean          -0.8504884
Policy log std Std           0.11668523
Policy log std Max           -0.46646017
Policy log std Min           -1.5555015
Z mean eval                  1.1646084
Z variance eval              0.13567494
total_rewards                [ 210.19791192  417.13228379  772.14860626 1424.74629911  706.33051135
  123.53523259 1365.2007228   543.69006581  503.67166605  345.65076882]
total_rewards_mean           641.2304068498322
total_rewards_std            421.8090672282102
total_rewards_max            1424.7462991090822
total_rewards_min            123.53523258851492
Number of train steps total  172000
Number of env steps total    147793
Number of rollouts total     0
Train Time (s)               173.58065234916285
(Previous) Eval Time (s)     21.263657494913787
Sample Time (s)              7.6710866200737655
Epoch Time (s)               202.5153964641504
Total Train Time (s)         9234.494326974731
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:45:35.816474 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #42 | Epoch Duration: 202.60948967933655
2020-01-11 18:45:35.816643 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1628724
Z variance train             0.13605998
KL Divergence                21.5927
KL Loss                      2.15927
QF Loss                      292.22437
VF Loss                      71.11747
Policy Loss                  -447.2845
Q Predictions Mean           436.406
Q Predictions Std            128.52052
Q Predictions Max            643.57227
Q Predictions Min            21.91433
V Predictions Mean           449.79807
V Predictions Std            121.808586
V Predictions Max            649.62177
V Predictions Min            129.44788
Log Pis Mean                 -1.5976242
Log Pis Std                  2.3619008
Log Pis Max                  13.963183
Log Pis Min                  -8.4934025
Policy mu Mean               -0.011337571
Policy mu Std                0.4516635
Policy mu Max                2.565474
Policy mu Min                -2.9124856
Policy log std Mean          -0.86331344
Policy log std Std           0.115767404
Policy log std Max           -0.27977717
Policy log std Min           -1.280683
Z mean eval                  1.139847
Z variance eval              0.15061286
total_rewards                [1302.3448154  1273.05100848  182.91554797  576.18563685  457.28622663
  427.79436981 1671.92278757 1271.3192869   210.01066564  534.9206018 ]
total_rewards_mean           790.7750947062855
total_rewards_std            506.25074348473447
total_rewards_max            1671.9227875729962
total_rewards_min            182.91554797293895
Number of train steps total  176000
Number of env steps total    151576
Number of rollouts total     0
Train Time (s)               173.91888088174164
(Previous) Eval Time (s)     22.88566170167178
Sample Time (s)              7.765825959853828
Epoch Time (s)               204.57036854326725
Total Train Time (s)         9439.155176784378
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:49:00.477743 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #43 | Epoch Duration: 204.66097688674927
2020-01-11 18:49:00.477881 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1388919
Z variance train             0.15057613
KL Divergence                19.6972
KL Loss                      1.9697201
QF Loss                      1192.3198
VF Loss                      83.724754
Policy Loss                  -419.90964
Q Predictions Mean           412.383
Q Predictions Std            122.3604
Q Predictions Max            605.93774
Q Predictions Min            -2.9929464
V Predictions Mean           421.7021
V Predictions Std            118.718315
V Predictions Max            605.25397
V Predictions Min            190.35846
Log Pis Mean                 -1.8328185
Log Pis Std                  2.590602
Log Pis Max                  14.76516
Log Pis Min                  -9.460858
Policy mu Mean               -0.014919713
Policy mu Std                0.45578855
Policy mu Max                3.8607204
Policy mu Min                -2.8078902
Policy log std Mean          -0.879148
Policy log std Std           0.11961754
Policy log std Max           -0.48302162
Policy log std Min           -1.3985584
Z mean eval                  1.2024801
Z variance eval              0.34389344
total_rewards                [ 360.06499538  353.51745561  975.83589393  416.63789439  209.69349971
  146.35729171   71.90700939 1470.62809299  727.26835049 1365.63488247]
total_rewards_mean           609.7545366087372
total_rewards_std            478.50241195778045
total_rewards_max            1470.6280929890377
total_rewards_min            71.90700939096332
Number of train steps total  180000
Number of env steps total    154326
Number of rollouts total     0
Train Time (s)               173.18829119484872
(Previous) Eval Time (s)     21.748080108314753
Sample Time (s)              7.559983205515891
Epoch Time (s)               202.49635450867936
Total Train Time (s)         9641.747720927
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:52:23.071039 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #44 | Epoch Duration: 202.5930619239807
2020-01-11 18:52:23.071166 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2028964
Z variance train             0.34469742
KL Divergence                18.68824
KL Loss                      1.868824
QF Loss                      365.0601
VF Loss                      76.91533
Policy Loss                  -459.11972
Q Predictions Mean           448.89136
Q Predictions Std            131.40802
Q Predictions Max            662.28436
Q Predictions Min            -5.032073
V Predictions Mean           457.64554
V Predictions Std            121.10338
V Predictions Max            654.0856
V Predictions Min            248.52245
Log Pis Mean                 -1.9805818
Log Pis Std                  2.3528256
Log Pis Max                  11.137646
Log Pis Min                  -8.466297
Policy mu Mean               0.040589422
Policy mu Std                0.4288049
Policy mu Max                2.8284676
Policy mu Min                -2.6152449
Policy log std Mean          -0.86450106
Policy log std Std           0.11952875
Policy log std Max           -0.54486763
Policy log std Min           -1.3190036
Z mean eval                  1.2113302
Z variance eval              0.26544768
total_rewards                [ 836.1686924   384.21661281 1055.48978189 1572.22653678 1617.61804194
  285.02658817  350.73493877  688.06934125  799.15936609 1524.54135389]
total_rewards_mean           911.32512539802
total_rewards_std            488.352878751582
total_rewards_max            1617.618041942909
total_rewards_min            285.0265881709368
Number of train steps total  184000
Number of env steps total    157748
Number of rollouts total     0
Train Time (s)               175.84900479018688
(Previous) Eval Time (s)     25.51412523398176
Sample Time (s)              7.135825084988028
Epoch Time (s)               208.49895510915667
Total Train Time (s)         9850.454557001125
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:55:51.778641 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #45 | Epoch Duration: 208.70738530158997
2020-01-11 18:55:51.778781 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2051232
Z variance train             0.26792052
KL Divergence                20.541489
KL Loss                      2.054149
QF Loss                      319.41223
VF Loss                      54.18702
Policy Loss                  -462.4693
Q Predictions Mean           453.9771
Q Predictions Std            135.91725
Q Predictions Max            687.30505
Q Predictions Min            -68.51746
V Predictions Mean           463.27658
V Predictions Std            128.31601
V Predictions Max            682.0161
V Predictions Min            185.94499
Log Pis Mean                 -1.7207233
Log Pis Std                  2.5998354
Log Pis Max                  19.268265
Log Pis Min                  -7.034325
Policy mu Mean               0.003316681
Policy mu Std                0.44774097
Policy mu Max                3.1899064
Policy mu Min                -3.0036852
Policy log std Mean          -0.8685354
Policy log std Std           0.12224353
Policy log std Max           -0.51458704
Policy log std Min           -1.352435
Z mean eval                  1.1940842
Z variance eval              0.13613257
total_rewards                [ 394.08333297  483.30517842  467.20297868 1223.52949439  107.82364349
  594.35608742  480.76978542 1420.00222068   75.63356704  646.43042035]
total_rewards_mean           589.3136708850946
total_rewards_std            408.3266221637366
total_rewards_max            1420.0022206750748
total_rewards_min            75.63356703862382
Number of train steps total  188000
Number of env steps total    161668
Number of rollouts total     0
Train Time (s)               174.96631451603025
(Previous) Eval Time (s)     19.265753857791424
Sample Time (s)              7.2890161708928645
Epoch Time (s)               201.52108454471454
Total Train Time (s)         10052.070878261235
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:59:13.395870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #46 | Epoch Duration: 201.6169981956482
2020-01-11 18:59:13.396003 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1974008
Z variance train             0.13660268
KL Divergence                23.238848
KL Loss                      2.3238847
QF Loss                      389.41907
VF Loss                      77.02098
Policy Loss                  -476.0602
Q Predictions Mean           466.451
Q Predictions Std            131.69554
Q Predictions Max            651.97076
Q Predictions Min            -74.36193
V Predictions Mean           472.0581
V Predictions Std            124.47534
V Predictions Max            651.1745
V Predictions Min            145.64172
Log Pis Mean                 -1.7827097
Log Pis Std                  2.1283686
Log Pis Max                  10.430078
Log Pis Min                  -7.3181477
Policy mu Mean               0.014213925
Policy mu Std                0.43220446
Policy mu Max                3.2686994
Policy mu Min                -1.8441874
Policy log std Mean          -0.86652744
Policy log std Std           0.11926815
Policy log std Max           -0.50978476
Policy log std Min           -1.5148392
Z mean eval                  1.1887139
Z variance eval              0.6477066
total_rewards                [ 743.44263481  282.72037516 1050.55798667  931.55011627  794.0122809
  326.44301402  368.01747704  419.57728749 1413.55645912  272.46894915]
total_rewards_mean           660.2346580642713
total_rewards_std            369.57829018480334
total_rewards_max            1413.556459118635
total_rewards_min            272.468949151171
Number of train steps total  192000
Number of env steps total    164296
Number of rollouts total     0
Train Time (s)               175.14993756776676
(Previous) Eval Time (s)     23.83330318890512
Sample Time (s)              7.078705947380513
Epoch Time (s)               206.0619467040524
Total Train Time (s)         10258.314450440928
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:02:39.640550 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #47 | Epoch Duration: 206.24445366859436
2020-01-11 19:02:39.640669 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1943127
Z variance train             0.6491057
KL Divergence                18.117477
KL Loss                      1.8117478
QF Loss                      398.12997
VF Loss                      128.39679
Policy Loss                  -442.79593
Q Predictions Mean           435.08405
Q Predictions Std            140.36446
Q Predictions Max            665.8837
Q Predictions Min            -12.618994
V Predictions Mean           449.9042
V Predictions Std            134.00186
V Predictions Max            669.44135
V Predictions Min            167.57277
Log Pis Mean                 -1.8332322
Log Pis Std                  2.5956006
Log Pis Max                  13.458917
Log Pis Min                  -8.7724085
Policy mu Mean               -0.012633105
Policy mu Std                0.45205376
Policy mu Max                2.3249545
Policy mu Min                -3.125553
Policy log std Mean          -0.8611996
Policy log std Std           0.12851737
Policy log std Max           -0.5011282
Policy log std Min           -1.5255042
Z mean eval                  1.2273633
Z variance eval              0.15703203
total_rewards                [  80.98538076  342.46085525  118.35385277  583.99317862 1066.96038975
  126.67433467  471.57700691  617.68105948  467.1400317   563.65652921]
total_rewards_mean           443.9482619138022
total_rewards_std            283.24675833124115
total_rewards_max            1066.9603897525906
total_rewards_min            80.98538076492866
Number of train steps total  196000
Number of env steps total    168635
Number of rollouts total     0
Train Time (s)               175.30449452390894
(Previous) Eval Time (s)     17.656956982798874
Sample Time (s)              6.73019460728392
Epoch Time (s)               199.69164611399174
Total Train Time (s)         10458.094038713258
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:05:59.421060 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #48 | Epoch Duration: 199.7802984714508
2020-01-11 19:05:59.421185 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2202414
Z variance train             0.15688893
KL Divergence                20.839363
KL Loss                      2.0839365
QF Loss                      392.31378
VF Loss                      103.75046
Policy Loss                  -464.84583
Q Predictions Mean           456.2619
Q Predictions Std            145.60445
Q Predictions Max            692.096
Q Predictions Min            -3.2259378
V Predictions Mean           469.4331
V Predictions Std            136.6157
V Predictions Max            695.85406
V Predictions Min            161.88242
Log Pis Mean                 -1.7791295
Log Pis Std                  2.5765963
Log Pis Max                  10.8646755
Log Pis Min                  -10.453596
Policy mu Mean               0.029925177
Policy mu Std                0.45792967
Policy mu Max                2.4068158
Policy mu Min                -2.3737762
Policy log std Mean          -0.86299884
Policy log std Std           0.122617915
Policy log std Max           -0.547148
Policy log std Min           -1.5367875
Z mean eval                  1.1840632
Z variance eval              0.06569608
total_rewards                [ 117.98076818  135.90184458  382.26969227  324.52096999  514.17929191
  872.37076852  783.56910585  375.71665961  110.89205903 1362.19750693]
total_rewards_mean           497.9598666858363
total_rewards_std            381.1333379399878
total_rewards_max            1362.1975069311272
total_rewards_min            110.892059026462
Number of train steps total  200000
Number of env steps total    171494
Number of rollouts total     0
Train Time (s)               173.40565186087042
(Previous) Eval Time (s)     17.92113777482882
Sample Time (s)              7.890948296524584
Epoch Time (s)               199.21773793222383
Total Train Time (s)         10657.57684103353
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:09:18.905882 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #49 | Epoch Duration: 199.48456263542175
2020-01-11 19:09:18.906164 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1854581
Z variance train             0.06571923
KL Divergence                23.392355
KL Loss                      2.3392355
QF Loss                      586.4229
VF Loss                      76.722626
Policy Loss                  -485.76886
Q Predictions Mean           474.5944
Q Predictions Std            148.8104
Q Predictions Max            685.9765
Q Predictions Min            -55.2076
V Predictions Mean           485.32962
V Predictions Std            137.27829
V Predictions Max            686.1614
V Predictions Min            137.03442
Log Pis Mean                 -1.6888208
Log Pis Std                  2.1897104
Log Pis Max                  8.663214
Log Pis Min                  -8.565546
Policy mu Mean               0.030966341
Policy mu Std                0.43908197
Policy mu Max                2.5151951
Policy mu Min                -2.3438146
Policy log std Mean          -0.87808084
Policy log std Std           0.12485847
Policy log std Max           -0.245013
Policy log std Min           -1.5578799
Z mean eval                  1.214443
Z variance eval              0.17147455
total_rewards                [1900.51733607  642.67811277  480.40081812  869.22003912  198.52710008
  466.36219825  237.53506946  368.09110156  920.48752734  862.63149455]
total_rewards_mean           694.6450797307681
total_rewards_std            471.83290653657224
total_rewards_max            1900.517336067064
total_rewards_min            198.52710007519806
Number of train steps total  204000
Number of env steps total    173753
Number of rollouts total     0
Train Time (s)               175.45323803368956
(Previous) Eval Time (s)     23.313965584151447
Sample Time (s)              6.904940515756607
Epoch Time (s)               205.6721441335976
Total Train Time (s)         10863.336167914793
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:12:44.665529 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #50 | Epoch Duration: 205.75917291641235
2020-01-11 19:12:44.665667 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2262682
Z variance train             0.17354015
KL Divergence                21.992977
KL Loss                      2.1992977
QF Loss                      393.5594
VF Loss                      135.33691
Policy Loss                  -490.3227
Q Predictions Mean           480.18155
Q Predictions Std            146.71622
Q Predictions Max            703.6487
Q Predictions Min            -38.548454
V Predictions Mean           482.34094
V Predictions Std            136.54294
V Predictions Max            692.42566
V Predictions Min            197.05739
Log Pis Mean                 -1.7323787
Log Pis Std                  2.5521233
Log Pis Max                  14.480295
Log Pis Min                  -8.948887
Policy mu Mean               0.017466808
Policy mu Std                0.4551569
Policy mu Max                2.3279436
Policy mu Min                -2.171288
Policy log std Mean          -0.8690752
Policy log std Std           0.12630162
Policy log std Max           -0.4965446
Policy log std Min           -1.640631
Z mean eval                  1.2961409
Z variance eval              0.13336952
total_rewards                [ 972.68394117 1635.35790979  383.24035941  636.09853831   37.20627601
 1868.266168    196.40597906  794.75937957 1063.77512827   16.36929858]
total_rewards_mean           760.4162978169712
total_rewards_std            606.9250897054407
total_rewards_max            1868.2661680004237
total_rewards_min            16.369298583093784
Number of train steps total  208000
Number of env steps total    177316
Number of rollouts total     0
Train Time (s)               177.62569927982986
(Previous) Eval Time (s)     21.878652907907963
Sample Time (s)              7.185896159149706
Epoch Time (s)               206.69024834688753
Total Train Time (s)         11070.115126810968
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:16:11.449011 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #51 | Epoch Duration: 206.7832157611847
2020-01-11 19:16:11.449273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2965639
Z variance train             0.13363627
KL Divergence                21.761656
KL Loss                      2.1761656
QF Loss                      479.1623
VF Loss                      52.21933
Policy Loss                  -478.3351
Q Predictions Mean           469.63745
Q Predictions Std            147.42557
Q Predictions Max            740.8294
Q Predictions Min            -0.3329677
V Predictions Mean           476.41113
V Predictions Std            141.88278
V Predictions Max            724.1074
V Predictions Min            81.79509
Log Pis Mean                 -1.7027943
Log Pis Std                  2.4881883
Log Pis Max                  12.975959
Log Pis Min                  -6.9719706
Policy mu Mean               0.029492153
Policy mu Std                0.47116938
Policy mu Max                2.4958682
Policy mu Min                -2.8662283
Policy log std Mean          -0.8705921
Policy log std Std           0.13266827
Policy log std Max           -0.49518925
Policy log std Min           -1.4459879
Z mean eval                  1.2447262
Z variance eval              0.190878
total_rewards                [130.54495925 870.75172559 539.31142094 279.38311335 103.47176694
 461.81938472 260.4407154  945.99252663 848.38841965 373.23265591]
total_rewards_mean           481.33366883886237
total_rewards_std            295.48630807242085
total_rewards_max            945.992526630505
total_rewards_min            103.47176693544436
Number of train steps total  212000
Number of env steps total    179909
Number of rollouts total     0
Train Time (s)               174.49546411726624
(Previous) Eval Time (s)     20.266227062791586
Sample Time (s)              7.159822017420083
Epoch Time (s)               201.9215131974779
Total Train Time (s)         11272.190715552773
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:19:33.524804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #52 | Epoch Duration: 202.0753402709961
2020-01-11 19:19:33.524969 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2425549
Z variance train             0.18989447
KL Divergence                21.367321
KL Loss                      2.136732
QF Loss                      240.07773
VF Loss                      65.10812
Policy Loss                  -516.7143
Q Predictions Mean           508.42126
Q Predictions Std            153.28151
Q Predictions Max            753.35376
Q Predictions Min            -12.350409
V Predictions Mean           516.1599
V Predictions Std            143.98657
V Predictions Max            750.3667
V Predictions Min            146.59085
Log Pis Mean                 -1.7986157
Log Pis Std                  2.6445794
Log Pis Max                  17.994509
Log Pis Min                  -9.321579
Policy mu Mean               0.04810694
Policy mu Std                0.46983492
Policy mu Max                3.8719666
Policy mu Min                -2.6501927
Policy log std Mean          -0.87151504
Policy log std Std           0.13150486
Policy log std Max           -0.3123812
Policy log std Min           -1.4419925
Z mean eval                  1.2266552
Z variance eval              0.12048974
total_rewards                [ 982.95618667  974.15378501 1953.91275769  515.28381071  122.92419538
  802.56586432  887.80016982  214.76180135  932.66734614  802.47706118]
total_rewards_mean           818.9502978275082
total_rewards_std            479.48377849477583
total_rewards_max            1953.9127576892786
total_rewards_min            122.9241953836072
Number of train steps total  216000
Number of env steps total    183534
Number of rollouts total     0
Train Time (s)               174.60597569309175
(Previous) Eval Time (s)     18.702040791045874
Sample Time (s)              7.209942303132266
Epoch Time (s)               200.5179587872699
Total Train Time (s)         11472.807044953108
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:22:54.142059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #53 | Epoch Duration: 200.616956949234
2020-01-11 19:22:54.142232 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2196233
Z variance train             0.12145604
KL Divergence                21.6486
KL Loss                      2.16486
QF Loss                      238.41354
VF Loss                      61.195026
Policy Loss                  -499.0011
Q Predictions Mean           492.86673
Q Predictions Std            149.10553
Q Predictions Max            720.81757
Q Predictions Min            -19.891123
V Predictions Mean           500.15262
V Predictions Std            146.58098
V Predictions Max            726.83936
V Predictions Min            -13.643785
Log Pis Mean                 -1.6062696
Log Pis Std                  2.5404863
Log Pis Max                  11.451081
Log Pis Min                  -7.808033
Policy mu Mean               0.0536446
Policy mu Std                0.44573095
Policy mu Max                2.6758199
Policy mu Min                -2.972486
Policy log std Mean          -0.88088125
Policy log std Std           0.1388248
Policy log std Max           -0.51657176
Policy log std Min           -1.4879482
Z mean eval                  1.2733333
Z variance eval              0.0408693
total_rewards                [ 970.75877393 1000.29571924  390.37432692  314.79506214 1403.94977436
  645.41094198 1145.22955373  643.61044362  892.14553077  472.88642404]
total_rewards_mean           787.9456550735279
total_rewards_std            334.4890462786316
total_rewards_max            1403.9497743552572
total_rewards_min            314.7950621430359
Number of train steps total  220000
Number of env steps total    186877
Number of rollouts total     0
Train Time (s)               175.09962754882872
(Previous) Eval Time (s)     25.715622212272137
Sample Time (s)              6.685651963111013
Epoch Time (s)               207.50090172421187
Total Train Time (s)         11680.4053908973
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:26:21.742573 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #54 | Epoch Duration: 207.6001479625702
2020-01-11 19:26:21.742851 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2697942
Z variance train             0.04081713
KL Divergence                23.867851
KL Loss                      2.3867853
QF Loss                      317.28848
VF Loss                      75.56938
Policy Loss                  -496.08057
Q Predictions Mean           486.36935
Q Predictions Std            148.66466
Q Predictions Max            714.30914
Q Predictions Min            61.4308
V Predictions Mean           500.6654
V Predictions Std            142.74394
V Predictions Max            725.681
V Predictions Min            243.8227
Log Pis Mean                 -1.5988371
Log Pis Std                  2.6781628
Log Pis Max                  14.424782
Log Pis Min                  -7.3854866
Policy mu Mean               0.022023441
Policy mu Std                0.47942322
Policy mu Max                3.634851
Policy mu Min                -2.3938262
Policy log std Mean          -0.88298285
Policy log std Std           0.13441533
Policy log std Max           -0.4919523
Policy log std Min           -1.6139584
Z mean eval                  1.2639798
Z variance eval              0.03541768
total_rewards                [ 420.51337218 1717.41793063  101.92752716  441.15356591  591.05551398
 1415.00279158  922.83445127 1035.14860151  767.13828498  414.791808  ]
total_rewards_mean           782.6983847201965
total_rewards_std            473.3373938768249
total_rewards_max            1717.4179306324745
total_rewards_min            101.92752715994811
Number of train steps total  224000
Number of env steps total    189414
Number of rollouts total     0
Train Time (s)               175.09444759739563
(Previous) Eval Time (s)     25.473887975793332
Sample Time (s)              7.144074719864875
Epoch Time (s)               207.71241029305384
Total Train Time (s)         11888.210739806294
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:29:49.547748 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #55 | Epoch Duration: 207.8047275543213
2020-01-11 19:29:49.547890 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2550722
Z variance train             0.03598653
KL Divergence                23.88864
KL Loss                      2.388864
QF Loss                      419.78156
VF Loss                      100.2715
Policy Loss                  -504.50565
Q Predictions Mean           495.28033
Q Predictions Std            154.56805
Q Predictions Max            727.8661
Q Predictions Min            11.183664
V Predictions Mean           509.66724
V Predictions Std            147.35785
V Predictions Max            740.35547
V Predictions Min            145.17972
Log Pis Mean                 -1.8988535
Log Pis Std                  2.6311169
Log Pis Max                  14.9672985
Log Pis Min                  -8.711376
Policy mu Mean               0.01985028
Policy mu Std                0.4441297
Policy mu Max                2.2367198
Policy mu Min                -3.7989533
Policy log std Mean          -0.8723912
Policy log std Std           0.14323583
Policy log std Max           -0.414415
Policy log std Min           -1.6813016
Z mean eval                  1.2335521
Z variance eval              0.0954095
total_rewards                [ 646.89830239  642.45641948  367.10232282  404.47816612  517.95241738
  238.86439022 1180.2761241   422.23557927 1034.00871611  653.24729522]
total_rewards_mean           610.7519733097555
total_rewards_std            281.4224953039851
total_rewards_max            1180.276124095722
total_rewards_min            238.86439021835082
Number of train steps total  228000
Number of env steps total    192959
Number of rollouts total     0
Train Time (s)               174.10971558000892
(Previous) Eval Time (s)     20.344430410303175
Sample Time (s)              7.835210818331689
Epoch Time (s)               202.2893568086438
Total Train Time (s)         12090.59598596301
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:33:11.934752 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #56 | Epoch Duration: 202.3867449760437
2020-01-11 19:33:11.934929 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2330406
Z variance train             0.09557187
KL Divergence                23.05602
KL Loss                      2.305602
QF Loss                      228.57
VF Loss                      61.706192
Policy Loss                  -500.90652
Q Predictions Mean           489.17947
Q Predictions Std            157.36081
Q Predictions Max            747.31
Q Predictions Min            -8.41249
V Predictions Mean           498.09824
V Predictions Std            149.71054
V Predictions Max            744.1246
V Predictions Min            250.31955
Log Pis Mean                 -1.5584452
Log Pis Std                  2.5903225
Log Pis Max                  15.206615
Log Pis Min                  -8.305246
Policy mu Mean               0.016323486
Policy mu Std                0.46605662
Policy mu Max                2.0285861
Policy mu Min                -2.9071414
Policy log std Mean          -0.8748907
Policy log std Std           0.13925141
Policy log std Max           -0.43720374
Policy log std Min           -1.5679986
Z mean eval                  1.2045327
Z variance eval              0.07210086
total_rewards                [  14.21417202 1286.84871816  367.05852202 1129.64928272  669.47212134
  515.44484399 1745.89991754  299.33035241  922.75823602  924.43517979]
total_rewards_mean           787.5111346005449
total_rewards_std            492.23855086666947
total_rewards_max            1745.899917535079
total_rewards_min            14.214172024541648
Number of train steps total  232000
Number of env steps total    198164
Number of rollouts total     0
Train Time (s)               174.45596694387496
(Previous) Eval Time (s)     23.630679473746568
Sample Time (s)              6.776038322597742
Epoch Time (s)               204.86268474021927
Total Train Time (s)         12295.57998874737
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:36:36.919287 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #57 | Epoch Duration: 204.98423099517822
2020-01-11 19:36:36.919426 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2030828
Z variance train             0.073062666
KL Divergence                21.902885
KL Loss                      2.1902885
QF Loss                      276.75494
VF Loss                      56.66005
Policy Loss                  -497.5713
Q Predictions Mean           487.0514
Q Predictions Std            150.48154
Q Predictions Max            726.0988
Q Predictions Min            198.39957
V Predictions Mean           498.8561
V Predictions Std            145.48958
V Predictions Max            722.77075
V Predictions Min            266.54742
Log Pis Mean                 -1.8503623
Log Pis Std                  2.4040008
Log Pis Max                  8.310917
Log Pis Min                  -6.893321
Policy mu Mean               0.017828386
Policy mu Std                0.44591257
Policy mu Max                2.0414836
Policy mu Min                -2.424681
Policy log std Mean          -0.8673397
Policy log std Std           0.12934211
Policy log std Max           -0.49229723
Policy log std Min           -1.5292706
Z mean eval                  1.2146571
Z variance eval              0.10134421
total_rewards                [1443.89262985 1376.16393535  412.60034959  608.85520343 1220.76012881
  876.04603305  549.4418972   494.85386288  465.96249462   84.28415414]
total_rewards_mean           753.2860688926885
total_rewards_std            432.88582189779214
total_rewards_max            1443.8926298541166
total_rewards_min            84.28415414230417
Number of train steps total  236000
Number of env steps total    200582
Number of rollouts total     0
Train Time (s)               173.6598856030032
(Previous) Eval Time (s)     18.789650425780565
Sample Time (s)              7.1344200083985925
Epoch Time (s)               199.58395603718236
Total Train Time (s)         12495.258327456191
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:39:56.602129 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #58 | Epoch Duration: 199.68249440193176
2020-01-11 19:39:56.602510 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #58 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.217226
Z variance train             0.10241278
KL Divergence                22.712717
KL Loss                      2.2712717
QF Loss                      297.91043
VF Loss                      73.93297
Policy Loss                  -515.0877
Q Predictions Mean           505.45358
Q Predictions Std            163.5384
Q Predictions Max            750.1743
Q Predictions Min            -37.31379
V Predictions Mean           511.8719
V Predictions Std            155.9437
V Predictions Max            738.6262
V Predictions Min            32.326984
Log Pis Mean                 -1.4537497
Log Pis Std                  3.2892513
Log Pis Max                  29.447083
Log Pis Min                  -9.042778
Policy mu Mean               0.0038653598
Policy mu Std                0.4901695
Policy mu Max                3.8538766
Policy mu Min                -4.340197
Policy log std Mean          -0.88908756
Policy log std Std           0.15279365
Policy log std Max           -0.47048655
Policy log std Min           -1.8869863
Z mean eval                  1.2453407
Z variance eval              0.19887331
total_rewards                [ 746.37956306 1203.77534762   30.89633946 1937.34297717  904.5609187
  562.47541417  210.60394601  346.78841088 1884.73406339  322.751163  ]
total_rewards_mean           815.0308143467884
total_rewards_std            638.2220401579524
total_rewards_max            1937.3429771669225
total_rewards_min            30.896339462922267
Number of train steps total  240000
Number of env steps total    204264
Number of rollouts total     0
Train Time (s)               175.15821389108896
(Previous) Eval Time (s)     17.913097110111266
Sample Time (s)              7.6413607080467045
Epoch Time (s)               200.71267170924693
Total Train Time (s)         12696.078331839293
Epoch                        59
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:43:17.424354 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #59 | Epoch Duration: 200.82159733772278
2020-01-11 19:43:17.424573 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2367133
Z variance train             0.20037512
KL Divergence                20.907934
KL Loss                      2.0907934
QF Loss                      273.5013
VF Loss                      114.785065
Policy Loss                  -524.73914
Q Predictions Mean           517.339
Q Predictions Std            161.81895
Q Predictions Max            765.1497
Q Predictions Min            27.671686
V Predictions Mean           529.9906
V Predictions Std            159.29593
V Predictions Max            766.0121
V Predictions Min            47.595207
Log Pis Mean                 -1.8273463
Log Pis Std                  2.7898078
Log Pis Max                  24.19695
Log Pis Min                  -8.215644
Policy mu Mean               0.00045012217
Policy mu Std                0.46052244
Policy mu Max                2.4897454
Policy mu Min                -3.7040613
Policy log std Mean          -0.87222254
Policy log std Std           0.13538855
Policy log std Max           -0.51630515
Policy log std Min           -1.8045342
Z mean eval                  1.2436079
Z variance eval              0.09019152
total_rewards                [601.8691209  894.4638954  307.43116034 496.69190969  46.23985387
 526.04429584 341.96990355 694.68250736 334.71038209 135.93876116]
total_rewards_mean           438.0041790205725
total_rewards_std            243.71101224086252
total_rewards_max            894.4638954011641
total_rewards_min            46.23985386940571
Number of train steps total  244000
Number of env steps total    207278
Number of rollouts total     0
Train Time (s)               174.62243430083618
(Previous) Eval Time (s)     12.069252226967365
Sample Time (s)              10.957492360379547
Epoch Time (s)               197.6491788881831
Total Train Time (s)         12893.811382755637
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:46:35.162084 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #60 | Epoch Duration: 197.7373993396759
2020-01-11 19:46:35.162270 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2374853
Z variance train             0.089275435
KL Divergence                22.967583
KL Loss                      2.2967584
QF Loss                      313.74146
VF Loss                      83.40678
Policy Loss                  -506.85727
Q Predictions Mean           497.6394
Q Predictions Std            164.86371
Q Predictions Max            747.30365
Q Predictions Min            21.220634
V Predictions Mean           512.90393
V Predictions Std            158.80116
V Predictions Max            759.4161
V Predictions Min            75.99654
Log Pis Mean                 -1.9196997
Log Pis Std                  2.8191283
Log Pis Max                  16.412172
Log Pis Min                  -8.166418
Policy mu Mean               0.02658604
Policy mu Std                0.45997503
Policy mu Max                3.49782
Policy mu Min                -2.2301905
Policy log std Mean          -0.8635483
Policy log std Std           0.13378175
Policy log std Max           -0.44907284
Policy log std Min           -1.5020182
Z mean eval                  1.2175243
Z variance eval              0.033613402
total_rewards                [ 141.56088806  210.09236702 1992.69649782 1179.61005944 1962.08689243
 1721.04103642  768.29005676  369.80709526 1041.88989226  260.64170284]
total_rewards_mean           964.7716488304197
total_rewards_std            693.6077374801835
total_rewards_max            1992.696497819082
total_rewards_min            141.5608880643196
Number of train steps total  248000
Number of env steps total    210864
Number of rollouts total     0
Train Time (s)               175.8122527967207
(Previous) Eval Time (s)     19.08719404740259
Sample Time (s)              6.441962995566428
Epoch Time (s)               201.34140983968973
Total Train Time (s)         13095.246164821554
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:49:56.597864 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #61 | Epoch Duration: 201.43546843528748
2020-01-11 19:49:56.597996 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2170968
Z variance train             0.033429414
KL Divergence                24.37615
KL Loss                      2.4376152
QF Loss                      302.14313
VF Loss                      86.84183
Policy Loss                  -509.8618
Q Predictions Mean           499.27332
Q Predictions Std            164.14742
Q Predictions Max            755.9215
Q Predictions Min            251.83928
V Predictions Mean           504.49777
V Predictions Std            160.54541
V Predictions Max            742.92444
V Predictions Min            264.5733
Log Pis Mean                 -1.5518166
Log Pis Std                  2.4065115
Log Pis Max                  9.675827
Log Pis Min                  -6.810084
Policy mu Mean               0.005210634
Policy mu Std                0.45459676
Policy mu Max                1.8533361
Policy mu Min                -2.2848134
Policy log std Mean          -0.8864878
Policy log std Std           0.1375929
Policy log std Max           -0.487405
Policy log std Min           -1.6614804
Z mean eval                  1.2725517
Z variance eval              0.17122665
total_rewards                [1213.73582187  499.60918205 1612.65186007 1090.89451123  127.99392224
 1368.93268431  120.72309853  795.30908779  907.73903545  399.04006008]
total_rewards_mean           813.6629263605853
total_rewards_std            491.2901520594434
total_rewards_max            1612.6518600665072
total_rewards_min            120.72309853073435
Number of train steps total  252000
Number of env steps total    214247
Number of rollouts total     0
Train Time (s)               175.6433879607357
(Previous) Eval Time (s)     21.636478404980153
Sample Time (s)              7.23019488202408
Epoch Time (s)               204.51006124773994
Total Train Time (s)         13299.853414248675
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:53:21.208401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #62 | Epoch Duration: 204.61028170585632
2020-01-11 19:53:21.208620 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #62 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2726014
Z variance train             0.17130283
KL Divergence                20.73371
KL Loss                      2.073371
QF Loss                      239.80167
VF Loss                      53.46882
Policy Loss                  -566.016
Q Predictions Mean           560.016
Q Predictions Std            164.85162
Q Predictions Max            790.74475
Q Predictions Min            254.44029
V Predictions Mean           565.1263
V Predictions Std            161.26733
V Predictions Max            789.2825
V Predictions Min            306.24237
Log Pis Mean                 -1.7549284
Log Pis Std                  2.4587553
Log Pis Max                  13.045601
Log Pis Min                  -9.936432
Policy mu Mean               0.033825636
Policy mu Std                0.458646
Policy mu Max                2.641489
Policy mu Min                -3.0567093
Policy log std Mean          -0.8782973
Policy log std Std           0.12906927
Policy log std Max           -0.4275415
Policy log std Min           -1.5213172
Z mean eval                  1.2311972
Z variance eval              0.07695016
total_rewards                [ 611.33575759  423.43027592  748.81308325   14.42330558 1737.9891824
 1212.17548217   89.41534253   70.21903104  252.39013204 1928.48441241]
total_rewards_mean           708.8676004935869
total_rewards_std            661.4132931342651
total_rewards_max            1928.484412405359
total_rewards_min            14.423305576652531
Number of train steps total  256000
Number of env steps total    216749
Number of rollouts total     0
Train Time (s)               174.68595243571326
(Previous) Eval Time (s)     15.339069256093353
Sample Time (s)              6.953816661145538
Epoch Time (s)               196.97883835295215
Total Train Time (s)         13496.930452551227
Epoch                        63
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:56:38.285286 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #63 | Epoch Duration: 197.0765142440796
2020-01-11 19:56:38.285421 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2294331
Z variance train             0.076676324
KL Divergence                21.593878
KL Loss                      2.1593878
QF Loss                      441.8995
VF Loss                      61.65929
Policy Loss                  -526.5219
Q Predictions Mean           514.19995
Q Predictions Std            168.715
Q Predictions Max            777.47107
Q Predictions Min            -17.880527
V Predictions Mean           525.00037
V Predictions Std            164.89787
V Predictions Max            781.80994
V Predictions Min            92.42681
Log Pis Mean                 -1.5279703
Log Pis Std                  2.6773572
Log Pis Max                  9.335397
Log Pis Min                  -8.611151
Policy mu Mean               0.038532425
Policy mu Std                0.46765906
Policy mu Max                2.4435093
Policy mu Min                -2.0032837
Policy log std Mean          -0.88900185
Policy log std Std           0.15790632
Policy log std Max           -0.3850196
Policy log std Min           -1.8395661
Z mean eval                  1.1923739
Z variance eval              0.05442508
total_rewards                [1512.9090511  1551.05094535 1193.3292621  1512.66793275  382.08819352
 1876.63711162  642.7221069   538.11850356  544.32397387 1503.14085943]
total_rewards_mean           1125.6987940210001
total_rewards_std            515.8504225719827
total_rewards_max            1876.6371116199648
total_rewards_min            382.088193522829
Number of train steps total  260000
Number of env steps total    220659
Number of rollouts total     0
Train Time (s)               174.950396633707
(Previous) Eval Time (s)     31.469981509726495
Sample Time (s)              7.530192959588021
Epoch Time (s)               213.9505711030215
Total Train Time (s)         13710.972114556469
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:00:12.328046 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #64 | Epoch Duration: 214.0425317287445
2020-01-11 20:00:12.328170 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1905978
Z variance train             0.054259755
KL Divergence                22.10743
KL Loss                      2.210743
QF Loss                      359.28693
VF Loss                      82.19447
Policy Loss                  -533.79846
Q Predictions Mean           525.4947
Q Predictions Std            179.27528
Q Predictions Max            781.01764
Q Predictions Min            -102.83854
V Predictions Mean           531.63806
V Predictions Std            167.52554
V Predictions Max            780.7461
V Predictions Min            106.2989
Log Pis Mean                 -1.2936397
Log Pis Std                  2.8703454
Log Pis Max                  14.877741
Log Pis Min                  -8.153479
Policy mu Mean               0.051844485
Policy mu Std                0.48940352
Policy mu Max                2.666578
Policy mu Min                -2.8415654
Policy log std Mean          -0.9028342
Policy log std Std           0.15406868
Policy log std Max           -0.478704
Policy log std Min           -1.6312915
Z mean eval                  1.189934
Z variance eval              0.096181646
total_rewards                [ 788.48372767 1025.88341542 1476.4586042  1670.2921615  1445.88333984
  194.04655696  794.33369441 1228.03611185  353.34946582  391.60718154]
total_rewards_mean           936.837425922275
total_rewards_std            491.20149611586424
total_rewards_max            1670.2921614964985
total_rewards_min            194.04655696221647
Number of train steps total  264000
Number of env steps total    223705
Number of rollouts total     0
Train Time (s)               174.25590295298025
(Previous) Eval Time (s)     24.41041721124202
Sample Time (s)              7.903391954954714
Epoch Time (s)               206.56971211917698
Total Train Time (s)         13917.674210200086
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:03:39.031108 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #65 | Epoch Duration: 206.70284581184387
2020-01-11 20:03:39.031238 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1933471
Z variance train             0.09756166
KL Divergence                21.021389
KL Loss                      2.102139
QF Loss                      880.42883
VF Loss                      63.71146
Policy Loss                  -532.1518
Q Predictions Mean           526.1932
Q Predictions Std            171.98526
Q Predictions Max            792.4578
Q Predictions Min            -14.60286
V Predictions Mean           532.5884
V Predictions Std            164.80334
V Predictions Max            784.1378
V Predictions Min            229.24443
Log Pis Mean                 -1.7138087
Log Pis Std                  2.5258083
Log Pis Max                  10.246496
Log Pis Min                  -10.199786
Policy mu Mean               0.021140061
Policy mu Std                0.4553114
Policy mu Max                2.8920279
Policy mu Min                -1.7980999
Policy log std Mean          -0.8904761
Policy log std Std           0.14787988
Policy log std Max           -0.2699579
Policy log std Min           -1.6222858
Z mean eval                  1.2273965
Z variance eval              0.046798866
total_rewards                [1701.96669314  194.53446729 2016.27855054   83.44338684   16.98028581
  200.52510546   94.86691045  785.90763005  471.91557072  649.03699645]
total_rewards_mean           621.5455596731306
total_rewards_std            667.442129214854
total_rewards_max            2016.2785505350967
total_rewards_min            16.980285806232544
Number of train steps total  268000
Number of env steps total    227219
Number of rollouts total     0
Train Time (s)               174.77657021395862
(Previous) Eval Time (s)     9.470183801837265
Sample Time (s)              7.221669458318502
Epoch Time (s)               191.4684234741144
Total Train Time (s)         14109.233047211077
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:06:50.591613 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #66 | Epoch Duration: 191.56026887893677
2020-01-11 20:06:50.591791 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2279527
Z variance train             0.046885367
KL Divergence                23.312515
KL Loss                      2.3312516
QF Loss                      345.60684
VF Loss                      101.892586
Policy Loss                  -560.25275
Q Predictions Mean           551.8698
Q Predictions Std            168.93251
Q Predictions Max            773.6498
Q Predictions Min            46.547287
V Predictions Mean           554.10516
V Predictions Std            160.8895
V Predictions Max            760.6302
V Predictions Min            113.1545
Log Pis Mean                 -1.3893944
Log Pis Std                  2.7863116
Log Pis Max                  21.121193
Log Pis Min                  -7.17949
Policy mu Mean               0.023595788
Policy mu Std                0.4790208
Policy mu Max                3.0137186
Policy mu Min                -3.0955849
Policy log std Mean          -0.88664734
Policy log std Std           0.1478731
Policy log std Max           -0.5102122
Policy log std Min           -1.5506036
Z mean eval                  1.2046969
Z variance eval              0.045675583
total_rewards                [1147.83666341 1016.90390561  424.55295565  902.07946129  839.63847396
 1277.33905278  276.22531425  277.86399326 2117.66420887 1278.26798679]
total_rewards_mean           955.8372015867866
total_rewards_std            530.8422514889357
total_rewards_max            2117.664208874442
total_rewards_min            276.2253142484905
Number of train steps total  272000
Number of env steps total    229817
Number of rollouts total     0
Train Time (s)               177.74089301982895
(Previous) Eval Time (s)     23.92547064786777
Sample Time (s)              6.927921229507774
Epoch Time (s)               208.5942848972045
Total Train Time (s)         14317.9207874774
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:10:19.283579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #67 | Epoch Duration: 208.6916127204895
2020-01-11 20:10:19.283875 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2065073
Z variance train             0.045645855
KL Divergence                23.452303
KL Loss                      2.3452303
QF Loss                      642.23956
VF Loss                      88.2754
Policy Loss                  -541.40137
Q Predictions Mean           530.8436
Q Predictions Std            178.6604
Q Predictions Max            782.26447
Q Predictions Min            46.77573
V Predictions Mean           541.5125
V Predictions Std            171.61705
V Predictions Max            795.0841
V Predictions Min            274.98163
Log Pis Mean                 -1.4289253
Log Pis Std                  2.438178
Log Pis Max                  8.803631
Log Pis Min                  -7.083553
Policy mu Mean               0.047202922
Policy mu Std                0.45704523
Policy mu Max                2.4868698
Policy mu Min                -2.24517
Policy log std Mean          -0.881493
Policy log std Std           0.1459487
Policy log std Max           -0.4168522
Policy log std Min           -1.5897971
Z mean eval                  1.1965103
Z variance eval              0.037608143
total_rewards                [ 871.98358119 2310.50467107   49.77866737 1863.22832104  344.96412627
  150.81931091  378.63509342  706.70039887  765.92159955  943.99570178]
total_rewards_mean           838.6531471468039
total_rewards_std            692.9498079280115
total_rewards_max            2310.5046710713223
total_rewards_min            49.778667367118516
Number of train steps total  276000
Number of env steps total    232636
Number of rollouts total     0
Train Time (s)               173.81511308299378
(Previous) Eval Time (s)     20.28916307259351
Sample Time (s)              8.152533784043044
Epoch Time (s)               202.25680993963033
Total Train Time (s)         14520.272288093343
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:13:41.634313 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #68 | Epoch Duration: 202.35020995140076
2020-01-11 20:13:41.634453 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1943022
Z variance train             0.03760578
KL Divergence                22.974876
KL Loss                      2.2974877
QF Loss                      422.80804
VF Loss                      119.573204
Policy Loss                  -549.7426
Q Predictions Mean           536.7594
Q Predictions Std            189.01208
Q Predictions Max            794.01855
Q Predictions Min            -49.73774
V Predictions Mean           547.91455
V Predictions Std            172.56862
V Predictions Max            795.90686
V Predictions Min            22.32848
Log Pis Mean                 -1.1779565
Log Pis Std                  3.6482809
Log Pis Max                  24.739521
Log Pis Min                  -8.56634
Policy mu Mean               0.017503966
Policy mu Std                0.52862924
Policy mu Max                3.0349534
Policy mu Min                -3.0075898
Policy log std Mean          -0.91559076
Policy log std Std           0.16167447
Policy log std Max           -0.49827862
Policy log std Min           -1.770441
Z mean eval                  1.2372507
Z variance eval              0.063645475
total_rewards                [ 247.65251734  666.69811741  620.27797799 1322.44502357 1490.47144857
 1434.93258464  496.95353597   34.35548649  853.86449546 2041.48987537]
total_rewards_mean           920.9141062820814
total_rewards_std            598.6686156502648
total_rewards_max            2041.4898753741904
total_rewards_min            34.355486493063495
Number of train steps total  280000
Number of env steps total    235210
Number of rollouts total     0
Train Time (s)               175.92572011239827
(Previous) Eval Time (s)     20.52585383784026
Sample Time (s)              7.2882486982271075
Epoch Time (s)               203.73982264846563
Total Train Time (s)         14724.13175130589
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:17:05.494822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #69 | Epoch Duration: 203.8602774143219
2020-01-11 20:17:05.494950 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2341634
Z variance train             0.06478694
KL Divergence                22.637651
KL Loss                      2.263765
QF Loss                      325.2716
VF Loss                      70.01498
Policy Loss                  -561.4282
Q Predictions Mean           550.6862
Q Predictions Std            171.76364
Q Predictions Max            807.8053
Q Predictions Min            26.179482
V Predictions Mean           562.9077
V Predictions Std            167.1929
V Predictions Max            806.3197
V Predictions Min            197.2446
Log Pis Mean                 -1.6290779
Log Pis Std                  3.0672166
Log Pis Max                  20.849485
Log Pis Min                  -8.347855
Policy mu Mean               0.014919506
Policy mu Std                0.5061819
Policy mu Max                3.1638045
Policy mu Min                -3.4003823
Policy log std Mean          -0.87546253
Policy log std Std           0.14451575
Policy log std Max           -0.51232886
Policy log std Min           -1.5455205
Z mean eval                  1.2344874
Z variance eval              0.033217575
total_rewards                [  34.03809397  961.1016142    60.61799652  305.25447873 1181.56376193
  543.53084337  686.86819046  573.69113119 1819.66466207 2155.61427155]
total_rewards_mean           832.194504399374
total_rewards_std            674.2798608735199
total_rewards_max            2155.6142715532624
total_rewards_min            34.03809397212282
Number of train steps total  284000
Number of env steps total    237779
Number of rollouts total     0
Train Time (s)               175.38016914995387
(Previous) Eval Time (s)     16.19656796939671
Sample Time (s)              7.151505735237151
Epoch Time (s)               198.72824285458773
Total Train Time (s)         14922.948357824236
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:20:24.313500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #70 | Epoch Duration: 198.81844115257263
2020-01-11 20:20:24.313672 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2312329
Z variance train             0.033108305
KL Divergence                23.488153
KL Loss                      2.3488154
QF Loss                      375.4577
VF Loss                      68.83403
Policy Loss                  -558.889
Q Predictions Mean           552.2025
Q Predictions Std            182.7476
Q Predictions Max            842.1844
Q Predictions Min            271.0452
V Predictions Mean           560.97516
V Predictions Std            179.80278
V Predictions Max            833.9823
V Predictions Min            284.6425
Log Pis Mean                 -1.7740021
Log Pis Std                  2.4710155
Log Pis Max                  8.576104
Log Pis Min                  -10.746599
Policy mu Mean               0.005648685
Policy mu Std                0.4457528
Policy mu Max                2.528844
Policy mu Min                -2.5240192
Policy log std Mean          -0.9127577
Policy log std Std           0.15901005
Policy log std Max           -0.4049803
Policy log std Min           -1.7876419
Z mean eval                  1.1993687
Z variance eval              0.06112074
total_rewards                [1731.18545545  929.75978576 2028.90224785 1056.18586399 1534.18443637
 2159.1324433  1944.92370044 1372.31949445  695.31604912  685.59672886]
total_rewards_mean           1413.750620558706
total_rewards_std            523.6021533926884
total_rewards_max            2159.1324433022883
total_rewards_min            685.5967288573172
Number of train steps total  288000
Number of env steps total    240341
Number of rollouts total     0
Train Time (s)               175.33366930298507
(Previous) Eval Time (s)     21.87015930796042
Sample Time (s)              7.2481042901054025
Epoch Time (s)               204.4519329010509
Total Train Time (s)         15127.49305597553
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:23:48.861677 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #71 | Epoch Duration: 204.5478436946869
2020-01-11 20:23:48.861947 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2132895
Z variance train             0.061802864
KL Divergence                22.63674
KL Loss                      2.263674
QF Loss                      373.97705
VF Loss                      101.216446
Policy Loss                  -556.79694
Q Predictions Mean           546.97107
Q Predictions Std            180.55759
Q Predictions Max            816.4938
Q Predictions Min            8.073501
V Predictions Mean           552.1841
V Predictions Std            176.317
V Predictions Max            799.22504
V Predictions Min            -14.4351425
Log Pis Mean                 -1.5345229
Log Pis Std                  3.1838586
Log Pis Max                  20.532782
Log Pis Min                  -11.109414
Policy mu Mean               0.013496433
Policy mu Std                0.4907147
Policy mu Max                2.1654534
Policy mu Min                -3.8440144
Policy log std Mean          -0.900648
Policy log std Std           0.16121718
Policy log std Max           -0.30003744
Policy log std Min           -1.7271161
Z mean eval                  1.1738112
Z variance eval              0.04114639
total_rewards                [1462.08532551  889.15818653  911.15413221 2142.85888853 1947.79216785
 1349.44512975 1255.91136921 1925.78128843 1036.2700797  1782.16831858]
total_rewards_mean           1470.262488629351
total_rewards_std            434.1021784290463
total_rewards_max            2142.8588885306362
total_rewards_min            889.1581865326707
Number of train steps total  292000
Number of env steps total    243018
Number of rollouts total     0
Train Time (s)               175.9743353468366
(Previous) Eval Time (s)     25.87369561707601
Sample Time (s)              6.713137110695243
Epoch Time (s)               208.56116807460785
Total Train Time (s)         15336.142156646121
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:27:17.510909 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #72 | Epoch Duration: 208.64877200126648
2020-01-11 20:27:17.511080 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1747305
Z variance train             0.04109826
KL Divergence                23.204073
KL Loss                      2.3204074
QF Loss                      377.54532
VF Loss                      148.64345
Policy Loss                  -596.2025
Q Predictions Mean           590.2446
Q Predictions Std            182.15251
Q Predictions Max            856.32404
Q Predictions Min            261.01514
V Predictions Mean           601.72205
V Predictions Std            178.54326
V Predictions Max            864.4932
V Predictions Min            267.46555
Log Pis Mean                 -1.2795725
Log Pis Std                  2.7388103
Log Pis Max                  12.7866955
Log Pis Min                  -7.569473
Policy mu Mean               0.033457294
Policy mu Std                0.5007011
Policy mu Max                2.552685
Policy mu Min                -2.8554423
Policy log std Mean          -0.90289074
Policy log std Std           0.16117498
Policy log std Max           -0.50742286
Policy log std Min           -1.8024461
Z mean eval                  1.2277396
Z variance eval              0.052433748
total_rewards                [1008.78147545 1291.05377633  685.01258622  368.86043559 1515.83928468
  404.78960633  420.21556579  802.26936116  962.01964725  367.00981067]
total_rewards_mean           782.5851549476422
total_rewards_std            388.2503767122973
total_rewards_max            1515.8392846842958
total_rewards_min            367.0098106701174
Number of train steps total  296000
Number of env steps total    245618
Number of rollouts total     0
Train Time (s)               176.05981227010489
(Previous) Eval Time (s)     22.631798080168664
Sample Time (s)              7.43981164554134
Epoch Time (s)               206.1314219958149
Total Train Time (s)         15542.3704382875
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:30:43.740801 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #73 | Epoch Duration: 206.229590177536
2020-01-11 20:30:43.740934 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2274362
Z variance train             0.052824862
KL Divergence                22.766163
KL Loss                      2.2766163
QF Loss                      305.63095
VF Loss                      83.30331
Policy Loss                  -578.69196
Q Predictions Mean           569.6918
Q Predictions Std            194.28853
Q Predictions Max            838.40234
Q Predictions Min            -36.443398
V Predictions Mean           576.19885
V Predictions Std            183.51561
V Predictions Max            828.0896
V Predictions Min            127.32213
Log Pis Mean                 -1.3651626
Log Pis Std                  2.6676538
Log Pis Max                  9.166405
Log Pis Min                  -10.007555
Policy mu Mean               0.039708156
Policy mu Std                0.47988018
Policy mu Max                3.017701
Policy mu Min                -1.8934652
Policy log std Mean          -0.89826256
Policy log std Std           0.16569036
Policy log std Max           -0.4398558
Policy log std Min           -1.6023233
Z mean eval                  1.196792
Z variance eval              0.04824761
total_rewards                [ 727.17713334 1612.43985714  691.97696662  285.9319365   322.22885085
  184.40965964 1980.22755189  470.44239532 1559.2198034   913.48298905]
total_rewards_mean           874.7537143733147
total_rewards_std            598.6209642801932
total_rewards_max            1980.2275518890915
total_rewards_min            184.40965963522999
Number of train steps total  300000
Number of env steps total    248380
Number of rollouts total     0
Train Time (s)               173.96175340609625
(Previous) Eval Time (s)     19.81060972902924
Sample Time (s)              7.369615723378956
Epoch Time (s)               201.14197885850444
Total Train Time (s)         15743.603237870615
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:34:04.974056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #74 | Epoch Duration: 201.2330243587494
2020-01-11 20:34:04.974191 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1937144
Z variance train             0.047389258
KL Divergence                22.396927
KL Loss                      2.2396927
QF Loss                      435.55414
VF Loss                      94.36191
Policy Loss                  -592.2791
Q Predictions Mean           582.6312
Q Predictions Std            194.04335
Q Predictions Max            848.1088
Q Predictions Min            40.72515
V Predictions Mean           589.34216
V Predictions Std            185.46605
V Predictions Max            848.30615
V Predictions Min            114.03154
Log Pis Mean                 -1.1676776
Log Pis Std                  2.9973135
Log Pis Max                  14.602367
Log Pis Min                  -7.253016
Policy mu Mean               0.03320502
Policy mu Std                0.5066266
Policy mu Max                2.1154537
Policy mu Min                -3.176
Policy log std Mean          -0.934721
Policy log std Std           0.17566843
Policy log std Max           -0.50197184
Policy log std Min           -1.7949257
Z mean eval                  1.1581154
Z variance eval              0.072752625
total_rewards                [1024.2243065  1636.89311147 1629.67456766  477.5602784   365.65857544
  668.89619702  580.29767731 2140.81028774 2228.9132375  2210.15279944]
total_rewards_mean           1296.308103847408
total_rewards_std            718.4693813328149
total_rewards_max            2228.913237504586
total_rewards_min            365.65857543759745
Number of train steps total  304000
Number of env steps total    251062
Number of rollouts total     0
Train Time (s)               174.82568478304893
(Previous) Eval Time (s)     23.245028706267476
Sample Time (s)              6.773683643434197
Epoch Time (s)               204.8443971327506
Total Train Time (s)         15948.539977434091
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:37:29.911660 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #75 | Epoch Duration: 204.9373710155487
2020-01-11 20:37:29.911784 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1588482
Z variance train             0.07241832
KL Divergence                20.463285
KL Loss                      2.0463285
QF Loss                      472.7176
VF Loss                      123.09038
Policy Loss                  -565.89307
Q Predictions Mean           554.8998
Q Predictions Std            205.02997
Q Predictions Max            831.5118
Q Predictions Min            -38.843533
V Predictions Mean           562.6762
V Predictions Std            192.8617
V Predictions Max            838.3907
V Predictions Min            -14.999328
Log Pis Mean                 -1.3085084
Log Pis Std                  3.1861498
Log Pis Max                  15.575052
Log Pis Min                  -7.1880035
Policy mu Mean               0.036978588
Policy mu Std                0.5007878
Policy mu Max                3.1099257
Policy mu Min                -2.7204475
Policy log std Mean          -0.9244827
Policy log std Std           0.16438797
Policy log std Max           -0.43379065
Policy log std Min           -1.7990859
Z mean eval                  1.1844809
Z variance eval              0.04877838
total_rewards                [1635.92856481 2135.99114895 1216.53937206  363.12643756  429.15899329
  394.87607915 2240.51494719  103.25647817 1671.61691497  153.79047494]
total_rewards_mean           1034.4799411105912
total_rewards_std            796.0961081600648
total_rewards_max            2240.5149471899927
total_rewards_min            103.25647817231739
Number of train steps total  308000
Number of env steps total    253365
Number of rollouts total     0
Train Time (s)               174.50949184317142
(Previous) Eval Time (s)     21.17261709785089
Sample Time (s)              6.670317616779357
Epoch Time (s)               202.35242655780166
Total Train Time (s)         16150.981691304594
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:40:52.357311 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #76 | Epoch Duration: 202.44537687301636
2020-01-11 20:40:52.357651 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1859006
Z variance train             0.04903039
KL Divergence                21.727802
KL Loss                      2.1727803
QF Loss                      322.36932
VF Loss                      57.668873
Policy Loss                  -578.3446
Q Predictions Mean           570.427
Q Predictions Std            199.4716
Q Predictions Max            867.92694
Q Predictions Min            -35.60588
V Predictions Mean           578.55096
V Predictions Std            196.41896
V Predictions Max            862.798
V Predictions Min            -11.604637
Log Pis Mean                 -1.5504098
Log Pis Std                  2.705141
Log Pis Max                  16.506609
Log Pis Min                  -9.6665745
Policy mu Mean               -0.007239336
Policy mu Std                0.4566335
Policy mu Max                2.7812617
Policy mu Min                -4.1549335
Policy log std Mean          -0.87716734
Policy log std Std           0.15273863
Policy log std Max           -0.089594245
Policy log std Min           -1.7170956
Z mean eval                  1.1775782
Z variance eval              0.031151423
total_rewards                [ 366.42239113  791.03689425  499.03181819  181.53407421 1740.38309447
  134.84215978  694.23192545  932.62443146  424.86900769 1335.37139624]
total_rewards_mean           710.0347192864981
total_rewards_std            486.1164002756521
total_rewards_max            1740.3830944731612
total_rewards_min            134.84215977879506
Number of train steps total  312000
Number of env steps total    256961
Number of rollouts total     0
Train Time (s)               175.0244600502774
(Previous) Eval Time (s)     14.035298590082675
Sample Time (s)              7.339347125496715
Epoch Time (s)               196.3991057658568
Total Train Time (s)         16347.509637423791
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:44:08.885582 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #77 | Epoch Duration: 196.52770924568176
2020-01-11 20:44:08.885708 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1819731
Z variance train             0.03120183
KL Divergence                22.764961
KL Loss                      2.2764962
QF Loss                      416.75415
VF Loss                      84.62981
Policy Loss                  -583.2985
Q Predictions Mean           575.30835
Q Predictions Std            201.44217
Q Predictions Max            892.4516
Q Predictions Min            22.662163
V Predictions Mean           585.655
V Predictions Std            196.89925
V Predictions Max            889.00745
V Predictions Min            39.97147
Log Pis Mean                 -1.6227963
Log Pis Std                  2.7673147
Log Pis Max                  11.353903
Log Pis Min                  -9.460827
Policy mu Mean               0.019769918
Policy mu Std                0.46348047
Policy mu Max                3.2153873
Policy mu Min                -2.946716
Policy log std Mean          -0.90795314
Policy log std Std           0.16571061
Policy log std Max           -0.5361513
Policy log std Min           -1.7889826
Z mean eval                  1.2225977
Z variance eval              0.030850569
total_rewards                [2152.92987223   46.15774335 2363.87475023 2344.23965716  706.03499271
 2162.27084337 2271.53028075 2301.46907873 1302.97427667 1864.84409522]
total_rewards_mean           1751.6325590423498
total_rewards_std            764.4822150247534
total_rewards_max            2363.8747502325523
total_rewards_min            46.157743350806655
Number of train steps total  316000
Number of env steps total    259551
Number of rollouts total     0
Train Time (s)               175.39797320915386
(Previous) Eval Time (s)     30.361150757875293
Sample Time (s)              7.569716506171972
Epoch Time (s)               213.32884047320113
Total Train Time (s)         16560.925833434798
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:47:42.302582 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #78 | Epoch Duration: 213.41678190231323
2020-01-11 20:47:42.302707 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.225262
Z variance train             0.030876243
KL Divergence                22.315472
KL Loss                      2.231547
QF Loss                      413.7095
VF Loss                      66.43966
Policy Loss                  -611.8153
Q Predictions Mean           604.03345
Q Predictions Std            196.56036
Q Predictions Max            877.01324
Q Predictions Min            -24.149227
V Predictions Mean           615.171
V Predictions Std            190.25578
V Predictions Max            863.3842
V Predictions Min            283.08136
Log Pis Mean                 -1.5347713
Log Pis Std                  2.6527565
Log Pis Max                  11.661092
Log Pis Min                  -8.955042
Policy mu Mean               0.030472372
Policy mu Std                0.4690392
Policy mu Max                2.5814593
Policy mu Min                -2.0421
Policy log std Mean          -0.90829766
Policy log std Std           0.16182537
Policy log std Max           -0.4990343
Policy log std Min           -1.7210484
Z mean eval                  1.2619727
Z variance eval              0.019816672
total_rewards                [1960.20114088  141.37048204 1682.04700111 1769.1020081   671.86041961
  708.95462378  113.72107797  224.45312466  994.14134255  146.51586879]
total_rewards_mean           841.2367089496063
total_rewards_std            690.7745529175587
total_rewards_max            1960.201140877912
total_rewards_min            113.72107797257044
Number of train steps total  320000
Number of env steps total    264020
Number of rollouts total     0
Train Time (s)               175.03247046284378
(Previous) Eval Time (s)     17.30472564511001
Sample Time (s)              7.304961211979389
Epoch Time (s)               199.64215731993318
Total Train Time (s)         16760.667957072146
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:51:02.046471 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #79 | Epoch Duration: 199.7436740398407
2020-01-11 20:51:02.046599 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2604883
Z variance train             0.019900177
KL Divergence                23.545021
KL Loss                      2.3545022
QF Loss                      440.62115
VF Loss                      104.3251
Policy Loss                  -619.2239
Q Predictions Mean           612.364
Q Predictions Std            190.07675
Q Predictions Max            861.13434
Q Predictions Min            265.01044
V Predictions Mean           618.9512
V Predictions Std            186.8966
V Predictions Max            859.87634
V Predictions Min            291.84387
Log Pis Mean                 -1.0971241
Log Pis Std                  2.4998693
Log Pis Max                  9.976549
Log Pis Min                  -8.774374
Policy mu Mean               0.021915965
Policy mu Std                0.48873764
Policy mu Max                2.3153574
Policy mu Min                -2.1828578
Policy log std Mean          -0.9105706
Policy log std Std           0.15328725
Policy log std Max           -0.5024858
Policy log std Min           -1.5243826
Z mean eval                  1.1523885
Z variance eval              0.032942228
total_rewards                [ 800.62948326 2515.18225257  647.5690395  1397.67893294  938.47187012
  615.41083381  485.02711094  343.58918051 1401.0042498   831.81649851]
total_rewards_mean           997.6379451965668
total_rewards_std            604.5397472874881
total_rewards_max            2515.1822525692337
total_rewards_min            343.58918050779766
Number of train steps total  324000
Number of env steps total    267751
Number of rollouts total     0
Train Time (s)               175.00000315718353
(Previous) Eval Time (s)     20.75674787024036
Sample Time (s)              11.594019196927547
Epoch Time (s)               207.35077022435144
Total Train Time (s)         16968.196220400743
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:54:29.577497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #80 | Epoch Duration: 207.53077840805054
2020-01-11 20:54:29.577720 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1494515
Z variance train             0.033117086
KL Divergence                22.147383
KL Loss                      2.2147384
QF Loss                      371.92358
VF Loss                      112.89298
Policy Loss                  -600.51196
Q Predictions Mean           594.15314
Q Predictions Std            203.11424
Q Predictions Max            898.1937
Q Predictions Min            2.1001482
V Predictions Mean           602.5149
V Predictions Std            200.1001
V Predictions Max            911.415
V Predictions Min            4.972378
Log Pis Mean                 -1.1159863
Log Pis Std                  2.8425734
Log Pis Max                  17.771944
Log Pis Min                  -9.20348
Policy mu Mean               0.029056288
Policy mu Std                0.50222707
Policy mu Max                2.9874935
Policy mu Min                -2.9352849
Policy log std Mean          -0.9198969
Policy log std Std           0.1698424
Policy log std Max           -0.07210004
Policy log std Min           -1.628867
Z mean eval                  1.1907613
Z variance eval              0.03518185
total_rewards                [ 547.56317289  673.21343071  717.62532998  683.52775469 2223.81342522
 1838.59261075 1546.11616122 1905.60351467 1062.21661309  565.41142165]
total_rewards_mean           1176.3683434873196
total_rewards_std            607.6492695733305
total_rewards_max            2223.81342521907
total_rewards_min            547.5631728865874
Number of train steps total  328000
Number of env steps total    270218
Number of rollouts total     0
Train Time (s)               176.87639119988307
(Previous) Eval Time (s)     20.242925993632525
Sample Time (s)              7.325888291466981
Epoch Time (s)               204.44520548498258
Total Train Time (s)         17172.73817220982
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:57:54.119370 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #81 | Epoch Duration: 204.54149556159973
2020-01-11 20:57:54.119493 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1911523
Z variance train             0.035247676
KL Divergence                23.755447
KL Loss                      2.3755448
QF Loss                      457.66882
VF Loss                      90.26041
Policy Loss                  -613.4464
Q Predictions Mean           605.01746
Q Predictions Std            208.3159
Q Predictions Max            880.47473
Q Predictions Min            145.06114
V Predictions Mean           612.4762
V Predictions Std            204.30513
V Predictions Max            883.8514
V Predictions Min            152.75922
Log Pis Mean                 -1.5477383
Log Pis Std                  2.7989764
Log Pis Max                  13.8456545
Log Pis Min                  -8.3188305
Policy mu Mean               0.0043247114
Policy mu Std                0.5010642
Policy mu Max                3.1253672
Policy mu Min                -3.530135
Policy log std Mean          -0.9250669
Policy log std Std           0.16994329
Policy log std Max           -0.3921721
Policy log std Min           -1.677803
Z mean eval                  1.1828624
Z variance eval              0.042500146
total_rewards                [2307.6149537  2433.98049553  889.16690489   92.92238975  427.27216931
  238.38435002  775.19486671  928.25448262  666.76210317 2430.71248597]
total_rewards_mean           1119.0265201653294
total_rewards_std            870.7068172819194
total_rewards_max            2433.98049553264
total_rewards_min            92.92238975187269
Number of train steps total  332000
Number of env steps total    272691
Number of rollouts total     0
Train Time (s)               175.80999049777165
(Previous) Eval Time (s)     15.365968640893698
Sample Time (s)              6.951172523200512
Epoch Time (s)               198.12713166186586
Total Train Time (s)         17370.95788541576
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:01:12.340903 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #82 | Epoch Duration: 198.22130298614502
2020-01-11 21:01:12.341074 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1853193
Z variance train             0.041996386
KL Divergence                24.010551
KL Loss                      2.401055
QF Loss                      369.5835
VF Loss                      131.46158
Policy Loss                  -628.7774
Q Predictions Mean           624.88446
Q Predictions Std            212.93767
Q Predictions Max            909.40137
Q Predictions Min            154.89435
V Predictions Mean           623.81616
V Predictions Std            209.71101
V Predictions Max            892.738
V Predictions Min            168.24332
Log Pis Mean                 -1.243274
Log Pis Std                  2.8360426
Log Pis Max                  11.650839
Log Pis Min                  -9.269906
Policy mu Mean               0.04190403
Policy mu Std                0.4924828
Policy mu Max                3.1188998
Policy mu Min                -2.417335
Policy log std Mean          -0.92589134
Policy log std Std           0.16878504
Policy log std Max           -0.47749144
Policy log std Min           -1.7235932
Z mean eval                  1.1871641
Z variance eval              0.20566037
total_rewards                [ 407.81013455 2320.73291491  328.71484105 1962.07775374  240.86183725
  432.82121616   70.47336484 2193.91167271  109.60492385 2311.23778682]
total_rewards_mean           1037.8246445885704
total_rewards_std            956.8965407315841
total_rewards_max            2320.732914911213
total_rewards_min            70.47336484269596
Number of train steps total  336000
Number of env steps total    275198
Number of rollouts total     0
Train Time (s)               174.59395830286667
(Previous) Eval Time (s)     15.339128428138793
Sample Time (s)              7.5591247752308846
Epoch Time (s)               197.49221150623634
Total Train Time (s)         17568.539506024215
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:04:29.923201 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #83 | Epoch Duration: 197.5820004940033
2020-01-11 21:04:29.923331 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.188059
Z variance train             0.20471695
KL Divergence                19.993305
KL Loss                      1.9993305
QF Loss                      568.3055
VF Loss                      86.67241
Policy Loss                  -687.64374
Q Predictions Mean           678.0121
Q Predictions Std            228.64932
Q Predictions Max            992.5476
Q Predictions Min            13.978504
V Predictions Mean           684.89844
V Predictions Std            219.54988
V Predictions Max            999.06146
V Predictions Min            236.96193
Log Pis Mean                 -1.4631381
Log Pis Std                  2.6001043
Log Pis Max                  11.500764
Log Pis Min                  -7.4498277
Policy mu Mean               0.034317426
Policy mu Std                0.5090525
Policy mu Max                2.265212
Policy mu Min                -2.8632603
Policy log std Mean          -0.901261
Policy log std Std           0.16068606
Policy log std Max           -0.41401738
Policy log std Min           -1.840251
Z mean eval                  1.2917106
Z variance eval              0.033491716
total_rewards                [ 716.79866524 2372.95847492  447.09706703 1296.32586028  681.37261694
 1755.26351973  281.21245448  295.29483626 1897.59354735 1940.17061125]
total_rewards_mean           1168.4087653474157
total_rewards_std            738.2357189632572
total_rewards_max            2372.958474918658
total_rewards_min            281.21245448094504
Number of train steps total  340000
Number of env steps total    277509
Number of rollouts total     0
Train Time (s)               176.07121113687754
(Previous) Eval Time (s)     17.174139848910272
Sample Time (s)              6.802489028777927
Epoch Time (s)               200.04784001456574
Total Train Time (s)         17768.70167187834
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:07:50.086279 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #84 | Epoch Duration: 200.1628532409668
2020-01-11 21:07:50.086405 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #84 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2893205
Z variance train             0.033351038
KL Divergence                24.397875
KL Loss                      2.4397876
QF Loss                      394.3256
VF Loss                      121.053925
Policy Loss                  -614.31024
Q Predictions Mean           607.6929
Q Predictions Std            220.52327
Q Predictions Max            914.80664
Q Predictions Min            25.735884
V Predictions Mean           616.7634
V Predictions Std            215.3698
V Predictions Max            904.76447
V Predictions Min            28.559168
Log Pis Mean                 -1.0111804
Log Pis Std                  3.2327352
Log Pis Max                  13.446619
Log Pis Min                  -8.543209
Policy mu Mean               0.020831965
Policy mu Std                0.51916337
Policy mu Max                3.6961896
Policy mu Min                -3.5975978
Policy log std Mean          -0.92298096
Policy log std Std           0.17776193
Policy log std Max           -0.2983278
Policy log std Min           -1.8606799
Z mean eval                  1.1971433
Z variance eval              0.022827666
total_rewards                [428.17426063 617.74019841  89.06956296 745.14654274 138.94821955
 991.63910796 729.28501687 220.99223035 142.57100581 888.12526669]
total_rewards_mean           499.1691411960469
total_rewards_std            320.75793101086936
total_rewards_max            991.6391079619882
total_rewards_min            89.06956295658586
Number of train steps total  344000
Number of env steps total    280300
Number of rollouts total     0
Train Time (s)               176.45511474926025
(Previous) Eval Time (s)     9.026565900072455
Sample Time (s)              8.091884255874902
Epoch Time (s)               193.5735649052076
Total Train Time (s)         17962.364828885067
Epoch                        85
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:11:03.751441 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #85 | Epoch Duration: 193.6649296283722
2020-01-11 21:11:03.751620 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1954627
Z variance train             0.022645425
KL Divergence                23.898134
KL Loss                      2.3898134
QF Loss                      400.60825
VF Loss                      137.6415
Policy Loss                  -645.1635
Q Predictions Mean           639.4597
Q Predictions Std            222.86424
Q Predictions Max            945.5737
Q Predictions Min            6.683743
V Predictions Mean           638.1286
V Predictions Std            214.3402
V Predictions Max            937.8937
V Predictions Min            257.63077
Log Pis Mean                 -1.2462136
Log Pis Std                  3.1801414
Log Pis Max                  16.024542
Log Pis Min                  -8.1675205
Policy mu Mean               0.011620566
Policy mu Std                0.5303367
Policy mu Max                3.1097276
Policy mu Min                -2.8219733
Policy log std Mean          -0.91291654
Policy log std Std           0.1646747
Policy log std Max           -0.36231375
Policy log std Min           -1.7577863
Z mean eval                  1.2135721
Z variance eval              0.028766986
total_rewards                [2437.19488931  615.95395435   67.93117973  356.47577202  522.58565598
  378.05372649  202.05204658 2111.45505825 1037.7770474   683.74478662]
total_rewards_mean           841.322411673625
total_rewards_std            763.6982279397084
total_rewards_max            2437.194889311539
total_rewards_min            67.93117972601445
Number of train steps total  348000
Number of env steps total    283986
Number of rollouts total     0
Train Time (s)               177.43042706418782
(Previous) Eval Time (s)     15.898223462048918
Sample Time (s)              7.458348402753472
Epoch Time (s)               200.78699892899022
Total Train Time (s)         18163.24215919664
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:14:24.629451 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #86 | Epoch Duration: 200.87770628929138
2020-01-11 21:14:24.629588 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2126462
Z variance train             0.02911605
KL Divergence                23.983269
KL Loss                      2.3983269
QF Loss                      424.4073
VF Loss                      101.98239
Policy Loss                  -655.4887
Q Predictions Mean           641.8849
Q Predictions Std            228.95284
Q Predictions Max            933.0209
Q Predictions Min            -31.321901
V Predictions Mean           653.2393
V Predictions Std            213.38513
V Predictions Max            938.8029
V Predictions Min            46.18512
Log Pis Mean                 -1.1007175
Log Pis Std                  2.980113
Log Pis Max                  17.81341
Log Pis Min                  -10.266697
Policy mu Mean               0.018062722
Policy mu Std                0.51321477
Policy mu Max                2.8851986
Policy mu Min                -2.6309335
Policy log std Mean          -0.92409873
Policy log std Std           0.17510262
Policy log std Max           -0.3995641
Policy log std Min           -1.9012201
Z mean eval                  1.2228225
Z variance eval              0.044451706
total_rewards                [ 405.7279181   282.18432616  390.10052533  628.60550696   18.42241619
  547.19297285 1004.06794824  106.95192063  605.81957212  107.35914053]
total_rewards_mean           409.6432247101393
total_rewards_std            284.84816256585066
total_rewards_max            1004.067948244583
total_rewards_min            18.422416186447535
Number of train steps total  352000
Number of env steps total    286728
Number of rollouts total     0
Train Time (s)               176.01653485093266
(Previous) Eval Time (s)     8.411811131983995
Sample Time (s)              7.583551876246929
Epoch Time (s)               192.01189785916358
Total Train Time (s)         18355.339241624344
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:17:36.728424 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #87 | Epoch Duration: 192.09872722625732
2020-01-11 21:17:36.728595 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2213802
Z variance train             0.044698615
KL Divergence                22.499813
KL Loss                      2.2499814
QF Loss                      446.36127
VF Loss                      80.684784
Policy Loss                  -669.0514
Q Predictions Mean           664.69434
Q Predictions Std            234.63727
Q Predictions Max            977.386
Q Predictions Min            -1.6029341
V Predictions Mean           670.0084
V Predictions Std            228.52827
V Predictions Max            968.2302
V Predictions Min            155.30551
Log Pis Mean                 -0.7700334
Log Pis Std                  3.1469228
Log Pis Max                  15.870661
Log Pis Min                  -7.8134003
Policy mu Mean               0.041833
Policy mu Std                0.52984756
Policy mu Max                3.4414659
Policy mu Min                -2.7621975
Policy log std Mean          -0.9364538
Policy log std Std           0.18509352
Policy log std Max           -0.432181
Policy log std Min           -1.8876983
Z mean eval                  1.1568662
Z variance eval              0.051382355
total_rewards                [2028.9174105  2256.01313216   98.54060804  880.03298074  153.04760149
 1558.36208533  876.5569991   345.05881827  822.06664705  651.7463794 ]
total_rewards_mean           967.034266207807
total_rewards_std            712.644183505208
total_rewards_max            2256.0131321553667
total_rewards_min            98.54060803509245
Number of train steps total  356000
Number of env steps total    291358
Number of rollouts total     0
Train Time (s)               176.1212277431041
(Previous) Eval Time (s)     19.788247919641435
Sample Time (s)              7.493597589433193
Epoch Time (s)               203.40307325217873
Total Train Time (s)         18558.832065999508
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:21:00.221804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #88 | Epoch Duration: 203.493079662323
2020-01-11 21:21:00.221953 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #88 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1620892
Z variance train             0.05092911
KL Divergence                21.63155
KL Loss                      2.163155
QF Loss                      582.13196
VF Loss                      83.35746
Policy Loss                  -626.4093
Q Predictions Mean           618.82043
Q Predictions Std            223.16933
Q Predictions Max            916.994
Q Predictions Min            -19.095388
V Predictions Mean           626.52673
V Predictions Std            216.9392
V Predictions Max            916.9651
V Predictions Min            -30.931229
Log Pis Mean                 -1.097704
Log Pis Std                  2.9052062
Log Pis Max                  18.237003
Log Pis Min                  -6.894813
Policy mu Mean               0.027703756
Policy mu Std                0.52321124
Policy mu Max                3.0631013
Policy mu Min                -2.7884781
Policy log std Mean          -0.9114461
Policy log std Std           0.16554083
Policy log std Max           -0.2508527
Policy log std Min           -1.6378559
Z mean eval                  1.1612893
Z variance eval              0.08975898
total_rewards                [2477.64750129 2511.58188531  477.27709712 1035.9013542  2567.5431829
 1771.88162051 1946.14344772 2444.08798258 2774.0706085  1378.01261455]
total_rewards_mean           1938.4147294680406
total_rewards_std            725.2874245280882
total_rewards_max            2774.070608499208
total_rewards_min            477.27709712246326
Number of train steps total  360000
Number of env steps total    294115
Number of rollouts total     0
Train Time (s)               176.69660009397194
(Previous) Eval Time (s)     28.14263719599694
Sample Time (s)              7.988614191766828
Epoch Time (s)               212.8278514817357
Total Train Time (s)         18771.759400043637
Epoch                        89
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:24:33.150238 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #89 | Epoch Duration: 212.92818784713745
2020-01-11 21:24:33.150362 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1564109
Z variance train             0.09105225
KL Divergence                21.028646
KL Loss                      2.1028647
QF Loss                      538.7602
VF Loss                      95.047714
Policy Loss                  -662.1455
Q Predictions Mean           653.9827
Q Predictions Std            218.59207
Q Predictions Max            938.62933
Q Predictions Min            9.603387
V Predictions Mean           657.26843
V Predictions Std            212.07936
V Predictions Max            918.1398
V Predictions Min            17.305819
Log Pis Mean                 -1.0355301
Log Pis Std                  3.2205503
Log Pis Max                  19.31744
Log Pis Min                  -9.47623
Policy mu Mean               0.011103461
Policy mu Std                0.53623736
Policy mu Max                4.716685
Policy mu Min                -3.0264685
Policy log std Mean          -0.9308477
Policy log std Std           0.17785051
Policy log std Max           -0.43342036
Policy log std Min           -1.8633294
Z mean eval                  1.1548322
Z variance eval              0.06448859
total_rewards                [1811.89084783 1665.61884184 2498.00077404 1439.0453191   369.57798924
  609.15487592 2558.65163515 2235.28585042 2405.52698691 1357.37385079]
total_rewards_mean           1695.0126971237005
total_rewards_std            729.1979063208469
total_rewards_max            2558.651635145914
total_rewards_min            369.57798924019914
Number of train steps total  364000
Number of env steps total    296921
Number of rollouts total     0
Train Time (s)               175.8162501291372
(Previous) Eval Time (s)     21.43740161275491
Sample Time (s)              7.210605047643185
Epoch Time (s)               204.46425678953528
Total Train Time (s)         18976.32566003548
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:27:57.719336 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #90 | Epoch Duration: 204.56886529922485
2020-01-11 21:27:57.719526 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1577882
Z variance train             0.063725606
KL Divergence                22.296902
KL Loss                      2.2296903
QF Loss                      679.41437
VF Loss                      62.647552
Policy Loss                  -659.10016
Q Predictions Mean           652.1609
Q Predictions Std            225.61833
Q Predictions Max            950.6575
Q Predictions Min            58.711468
V Predictions Mean           659.25195
V Predictions Std            219.38974
V Predictions Max            950.6463
V Predictions Min            256.04608
Log Pis Mean                 -1.1996181
Log Pis Std                  2.8420908
Log Pis Max                  15.48965
Log Pis Min                  -7.1434507
Policy mu Mean               0.04204526
Policy mu Std                0.51062924
Policy mu Max                3.0526266
Policy mu Min                -3.2969742
Policy log std Mean          -0.911444
Policy log std Std           0.1779269
Policy log std Max           -0.46408546
Policy log std Min           -2.0117772
Z mean eval                  1.1328204
Z variance eval              0.07463403
total_rewards                [1251.6361729  2368.29602453 2561.67198433 2611.1160263   737.35561629
 2750.74679352 2397.22636231 2463.84406337  881.87780957 1871.62856278]
total_rewards_mean           1989.539941590368
total_rewards_std            719.7945964718176
total_rewards_max            2750.7467935158434
total_rewards_min            737.3556162933919
Number of train steps total  368000
Number of env steps total    299614
Number of rollouts total     0
Train Time (s)               177.70305638341233
(Previous) Eval Time (s)     30.864610550925136
Sample Time (s)              7.112826632335782
Epoch Time (s)               215.68049356667325
Total Train Time (s)         19192.099306758028
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:31:33.493664 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #91 | Epoch Duration: 215.77400422096252
2020-01-11 21:31:33.493803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #91 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1306077
Z variance train             0.074408755
KL Divergence                20.051937
KL Loss                      2.0051937
QF Loss                      390.15817
VF Loss                      76.31879
Policy Loss                  -644.8008
Q Predictions Mean           636.35187
Q Predictions Std            233.00096
Q Predictions Max            947.7299
Q Predictions Min            -24.9281
V Predictions Mean           644.57184
V Predictions Std            226.02519
V Predictions Max            934.6423
V Predictions Min            163.74217
Log Pis Mean                 -1.0620687
Log Pis Std                  2.8184896
Log Pis Max                  10.306917
Log Pis Min                  -7.9324455
Policy mu Mean               0.0613987
Policy mu Std                0.49855056
Policy mu Max                2.7015212
Policy mu Min                -2.5280716
Policy log std Mean          -0.9584213
Policy log std Std           0.18355612
Policy log std Max           -0.5139501
Policy log std Min           -2.0825362
Z mean eval                  1.1701496
Z variance eval              0.022474322
total_rewards                [ 110.27904517  324.27647492  501.0499883    29.60091935 2597.6357279
 2335.21160934 2523.82119825  704.13254851 2682.17062751  477.52982129]
total_rewards_mean           1228.5707960542743
total_rewards_std            1084.6131440829427
total_rewards_max            2682.170627507142
total_rewards_min            29.60091935270213
Number of train steps total  372000
Number of env steps total    302233
Number of rollouts total     0
Train Time (s)               175.6876543960534
(Previous) Eval Time (s)     24.392360873054713
Sample Time (s)              7.380528235808015
Epoch Time (s)               207.46054350491613
Total Train Time (s)         19399.782793590333
Epoch                        92
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:35:01.181893 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #92 | Epoch Duration: 207.6879653930664
2020-01-11 21:35:01.182132 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1678841
Z variance train             0.022587148
KL Divergence                23.151392
KL Loss                      2.3151393
QF Loss                      484.17773
VF Loss                      77.461395
Policy Loss                  -676.8707
Q Predictions Mean           669.4673
Q Predictions Std            235.29523
Q Predictions Max            984.2628
Q Predictions Min            -1.3043134
V Predictions Mean           677.4882
V Predictions Std            230.60904
V Predictions Max            979.6446
V Predictions Min            42.79377
Log Pis Mean                 -0.7960496
Log Pis Std                  2.873749
Log Pis Max                  16.639072
Log Pis Min                  -6.1071653
Policy mu Mean               0.03997254
Policy mu Std                0.52362806
Policy mu Max                3.9909587
Policy mu Min                -2.6796246
Policy log std Mean          -0.94576335
Policy log std Std           0.18867584
Policy log std Max           -0.438996
Policy log std Min           -1.898163
Z mean eval                  1.1961297
Z variance eval              0.035384726
total_rewards                [ 625.71150013  882.87034965  366.0770876  1350.1357991  1227.46687784
 2501.01987189 1414.26084563 1908.25079727  664.07633785 2229.94043794]
total_rewards_mean           1316.9809904895944
total_rewards_std            678.2644522917234
total_rewards_max            2501.0198718872025
total_rewards_min            366.07708759931785
Number of train steps total  376000
Number of env steps total    304844
Number of rollouts total     0
Train Time (s)               174.93909663893282
(Previous) Eval Time (s)     23.256242441013455
Sample Time (s)              7.752419201191515
Epoch Time (s)               205.9477582811378
Total Train Time (s)         19605.827848454937
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:38:27.226614 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #93 | Epoch Duration: 206.0443127155304
2020-01-11 21:38:27.226734 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #93 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1995056
Z variance train             0.03537392
KL Divergence                22.539389
KL Loss                      2.253939
QF Loss                      440.66138
VF Loss                      116.23189
Policy Loss                  -699.5266
Q Predictions Mean           693.38525
Q Predictions Std            221.88164
Q Predictions Max            967.38214
Q Predictions Min            242.18031
V Predictions Mean           698.79736
V Predictions Std            218.08174
V Predictions Max            962.82275
V Predictions Min            242.30777
Log Pis Mean                 -0.90084875
Log Pis Std                  2.7068262
Log Pis Max                  12.004034
Log Pis Min                  -6.9513445
Policy mu Mean               -0.009389677
Policy mu Std                0.50550103
Policy mu Max                2.380641
Policy mu Min                -1.9518828
Policy log std Mean          -0.94307625
Policy log std Std           0.19156183
Policy log std Max           -0.44295996
Policy log std Min           -1.9621744
Z mean eval                  1.1649706
Z variance eval              0.024615467
total_rewards                [2434.61244999 1237.68854454  382.88666561 1157.47809167 2461.0605949
 1492.77847634 2637.4294528  2461.84190283  259.85856971 2555.85973258]
total_rewards_mean           1708.1494480970389
total_rewards_std            875.7668085214127
total_rewards_max            2637.4294528020173
total_rewards_min            259.8585697087342
Number of train steps total  380000
Number of env steps total    307303
Number of rollouts total     0
Train Time (s)               176.00964540522546
(Previous) Eval Time (s)     24.072975954040885
Sample Time (s)              6.85748241469264
Epoch Time (s)               206.94010377395898
Total Train Time (s)         19812.857124378905
Epoch                        94
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:41:54.258203 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #94 | Epoch Duration: 207.03136253356934
2020-01-11 21:41:54.258380 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.16636
Z variance train             0.024875568
KL Divergence                22.506895
KL Loss                      2.2506895
QF Loss                      470.39117
VF Loss                      120.598595
Policy Loss                  -681.43866
Q Predictions Mean           671.6654
Q Predictions Std            245.91718
Q Predictions Max            988.22034
Q Predictions Min            26.00955
V Predictions Mean           679.86975
V Predictions Std            239.46971
V Predictions Max            991.1168
V Predictions Min            31.454838
Log Pis Mean                 -0.47826412
Log Pis Std                  3.1703682
Log Pis Max                  14.013635
Log Pis Min                  -7.927235
Policy mu Mean               0.04124005
Policy mu Std                0.5566742
Policy mu Max                2.501001
Policy mu Min                -3.0854912
Policy log std Mean          -0.95218897
Policy log std Std           0.20112804
Policy log std Max           -0.42915884
Policy log std Min           -1.8911402
Z mean eval                  1.2579393
Z variance eval              0.013957271
total_rewards                [2052.97266891  559.2454991   571.59377384 1168.71357501 1067.68049273
  827.87388373  985.28252827  684.25261773 1385.16450758  466.1939001 ]
total_rewards_mean           976.8973447001523
total_rewards_std            455.7517440773638
total_rewards_max            2052.972668912147
total_rewards_min            466.1939000969885
Number of train steps total  384000
Number of env steps total    310795
Number of rollouts total     0
Train Time (s)               174.4922374719754
(Previous) Eval Time (s)     22.999137959908694
Sample Time (s)              7.578006074298173
Epoch Time (s)               205.06938150618225
Total Train Time (s)         20018.01666660467
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:45:19.422304 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #95 | Epoch Duration: 205.16376161575317
2020-01-11 21:45:19.422552 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2595546
Z variance train             0.0139720095
KL Divergence                24.70175
KL Loss                      2.470175
QF Loss                      413.19684
VF Loss                      144.32101
Policy Loss                  -714.7681
Q Predictions Mean           705.44775
Q Predictions Std            249.76836
Q Predictions Max            1019.28723
Q Predictions Min            -37.97267
V Predictions Mean           716.0992
V Predictions Std            243.1514
V Predictions Max            1014.1921
V Predictions Min            19.660551
Log Pis Mean                 -0.42780888
Log Pis Std                  3.3245401
Log Pis Max                  23.896639
Log Pis Min                  -8.730358
Policy mu Mean               0.031294283
Policy mu Std                0.5572797
Policy mu Max                2.9010975
Policy mu Min                -4.8037667
Policy log std Mean          -0.96527225
Policy log std Std           0.1916794
Policy log std Max           -0.3725131
Policy log std Min           -1.9115198
Z mean eval                  1.2261593
Z variance eval              0.043210994
total_rewards                [1286.1784062  2621.82777451 2164.0165501  2558.72690742 1148.71382468
 2562.43211517  568.98327303 2466.39427143  206.16809716 1540.97386374]
total_rewards_mean           1712.4415083452968
total_rewards_std            845.1791401030332
total_rewards_max            2621.8277745094424
total_rewards_min            206.16809715804732
Number of train steps total  388000
Number of env steps total    313184
Number of rollouts total     0
Train Time (s)               177.60234988713637
(Previous) Eval Time (s)     22.446669067721814
Sample Time (s)              6.965817435178906
Epoch Time (s)               207.0148363900371
Total Train Time (s)         20225.126508680638
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:48:46.531352 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #96 | Epoch Duration: 207.10862612724304
2020-01-11 21:48:46.531478 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2303689
Z variance train             0.041665934
KL Divergence                21.529448
KL Loss                      2.1529448
QF Loss                      450.44696
VF Loss                      106.07989
Policy Loss                  -691.4066
Q Predictions Mean           684.047
Q Predictions Std            243.4
Q Predictions Max            1005.2495
Q Predictions Min            282.6591
V Predictions Mean           694.57043
V Predictions Std            239.55685
V Predictions Max            1001.6521
V Predictions Min            296.65005
Log Pis Mean                 -0.88302183
Log Pis Std                  3.2008073
Log Pis Max                  18.537876
Log Pis Min                  -7.706492
Policy mu Mean               0.029358905
Policy mu Std                0.53218645
Policy mu Max                2.8280842
Policy mu Min                -2.3770869
Policy log std Mean          -0.94321907
Policy log std Std           0.18623637
Policy log std Max           -0.4880215
Policy log std Min           -1.9353591
Z mean eval                  1.2219138
Z variance eval              0.02403275
total_rewards                [ 707.77608685  619.57920462 1866.00978632  221.48535645 1010.99510664
 2241.09698803  460.10231842  407.12987398  874.59512121  407.13759558]
total_rewards_mean           881.5907438094804
total_rewards_std            632.1870459652654
total_rewards_max            2241.096988032695
total_rewards_min            221.48535644955203
Number of train steps total  392000
Number of env steps total    315735
Number of rollouts total     0
Train Time (s)               176.4652595440857
(Previous) Eval Time (s)     29.447750967927277
Sample Time (s)              7.1275544026866555
Epoch Time (s)               213.04056491469964
Total Train Time (s)         20438.263557734434
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:52:19.669904 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #97 | Epoch Duration: 213.13832998275757
2020-01-11 21:52:19.670032 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2215874
Z variance train             0.023957053
KL Divergence                22.95528
KL Loss                      2.2955282
QF Loss                      425.53772
VF Loss                      190.01353
Policy Loss                  -664.99023
Q Predictions Mean           652.7096
Q Predictions Std            257.70316
Q Predictions Max            991.2242
Q Predictions Min            -38.207985
V Predictions Mean           668.9996
V Predictions Std            248.9421
V Predictions Max            995.05096
V Predictions Min            32.5005
Log Pis Mean                 -0.905901
Log Pis Std                  3.2497435
Log Pis Max                  18.482666
Log Pis Min                  -10.080822
Policy mu Mean               0.021963494
Policy mu Std                0.5414547
Policy mu Max                3.337075
Policy mu Min                -3.1391547
Policy log std Mean          -0.9413601
Policy log std Std           0.17984918
Policy log std Max           -0.39784658
Policy log std Min           -1.7266351
Z mean eval                  1.1562217
Z variance eval              0.037133858
total_rewards                [2490.06536731 2570.42028584 2485.17833114 2480.1349546  2346.67112818
 2517.04782463 1197.96352393 2428.52092623  453.07409064 2667.15209191]
total_rewards_mean           2163.6228524414228
total_rewards_std            693.9906538281653
total_rewards_max            2667.152091906572
total_rewards_min            453.0740906355131
Number of train steps total  396000
Number of env steps total    318095
Number of rollouts total     0
Train Time (s)               177.5904791019857
(Previous) Eval Time (s)     31.73968917876482
Sample Time (s)              6.963671869132668
Epoch Time (s)               216.29384014988318
Total Train Time (s)         20654.660428893752
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:55:56.067581 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #98 | Epoch Duration: 216.3974585533142
2020-01-11 21:55:56.067704 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1509466
Z variance train             0.036780383
KL Divergence                22.94756
KL Loss                      2.294756
QF Loss                      638.66504
VF Loss                      128.66261
Policy Loss                  -707.2738
Q Predictions Mean           699.5868
Q Predictions Std            254.677
Q Predictions Max            1029.697
Q Predictions Min            155.45715
V Predictions Mean           702.7265
V Predictions Std            247.4999
V Predictions Max            1027.5616
V Predictions Min            287.65942
Log Pis Mean                 -0.7922408
Log Pis Std                  3.0820084
Log Pis Max                  18.625483
Log Pis Min                  -13.397123
Policy mu Mean               0.025042202
Policy mu Std                0.5119034
Policy mu Max                3.4673977
Policy mu Min                -2.1901484
Policy log std Mean          -0.950636
Policy log std Std           0.1859598
Policy log std Max           -0.5337659
Policy log std Min           -1.9127688
Z mean eval                  1.1727755
Z variance eval              0.054053046
total_rewards                [ 184.99339044 2644.57844206  846.48130948 2653.51908959 1114.72201097
 2889.11453916  402.75546928  967.79425452 1368.24278047  777.91521895]
total_rewards_mean           1385.0116504927878
total_rewards_std            936.4189874336859
total_rewards_max            2889.1145391647315
total_rewards_min            184.99339044266367
Number of train steps total  400000
Number of env steps total    321807
Number of rollouts total     0
Train Time (s)               174.80790743092075
(Previous) Eval Time (s)     18.796418235171586
Sample Time (s)              6.976317051332444
Epoch Time (s)               200.58064271742478
Total Train Time (s)         20855.360438907053
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:59:16.769608 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #99 | Epoch Duration: 200.70181012153625
2020-01-11 21:59:16.769740 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1678805
Z variance train             0.053729616
KL Divergence                22.013252
KL Loss                      2.2013252
QF Loss                      567.0454
VF Loss                      63.044662
Policy Loss                  -720.7503
Q Predictions Mean           713.9881
Q Predictions Std            244.30612
Q Predictions Max            1019.14417
Q Predictions Min            272.87936
V Predictions Mean           722.6288
V Predictions Std            242.6634
V Predictions Max            1026.8356
V Predictions Min            264.507
Log Pis Mean                 -0.79835135
Log Pis Std                  2.7837722
Log Pis Max                  9.404641
Log Pis Min                  -8.410292
Policy mu Mean               0.0082464395
Policy mu Std                0.5275472
Policy mu Max                2.274774
Policy mu Min                -2.834159
Policy log std Mean          -0.9728091
Policy log std Std           0.18830037
Policy log std Max           -0.31289232
Policy log std Min           -1.7901385
Z mean eval                  1.190964
Z variance eval              0.034988087
total_rewards                [2900.49917383 1638.89534469  840.8812141  1130.19584913 1364.70888507
  774.94372371 2839.21962262 2595.39811216 2424.22329675 2371.06572606]
total_rewards_mean           1888.0030948103636
total_rewards_std            787.1962419542062
total_rewards_max            2900.499173830445
total_rewards_min            774.9437237062843
Number of train steps total  404000
Number of env steps total    324211
Number of rollouts total     0
Train Time (s)               176.30423003109172
(Previous) Eval Time (s)     28.148371044546366
Sample Time (s)              7.779732675291598
Epoch Time (s)               212.23233375092968
Total Train Time (s)         21067.679923834745
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:02:49.089849 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #100 | Epoch Duration: 212.3200159072876
2020-01-11 22:02:49.089986 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1913698
Z variance train             0.035183348
KL Divergence                22.625023
KL Loss                      2.2625024
QF Loss                      581.2489
VF Loss                      157.45906
Policy Loss                  -703.66406
Q Predictions Mean           692.3833
Q Predictions Std            265.70966
Q Predictions Max            1028.4408
Q Predictions Min            -19.57592
V Predictions Mean           704.9717
V Predictions Std            254.59839
V Predictions Max            1019.70526
V Predictions Min            35.73521
Log Pis Mean                 -0.55160916
Log Pis Std                  3.2721107
Log Pis Max                  14.460728
Log Pis Min                  -6.6241565
Policy mu Mean               0.025681708
Policy mu Std                0.56102735
Policy mu Max                3.011891
Policy mu Min                -2.4883115
Policy log std Mean          -0.9478738
Policy log std Std           0.19663568
Policy log std Max           -0.47895536
Policy log std Min           -1.8361323
Z mean eval                  1.2498765
Z variance eval              0.0505678
total_rewards                [ 897.74773251  278.51966237  646.81871489  650.51533766  790.94248033
  369.90854108   21.41072477 1232.85537291 1981.82345077  356.10277104]
total_rewards_mean           722.6644788336823
total_rewards_std            532.9048561906437
total_rewards_max            1981.8234507700931
total_rewards_min            21.410724765760353
Number of train steps total  408000
Number of env steps total    326759
Number of rollouts total     0
Train Time (s)               175.28316287416965
(Previous) Eval Time (s)     19.56729493709281
Sample Time (s)              7.2728519956581295
Epoch Time (s)               202.1233098069206
Total Train Time (s)         21269.898174784146
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:06:11.313289 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #101 | Epoch Duration: 202.22316694259644
2020-01-11 22:06:11.313588 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2490911
Z variance train             0.05110119
KL Divergence                21.095112
KL Loss                      2.1095111
QF Loss                      626.8867
VF Loss                      121.15556
Policy Loss                  -719.3469
Q Predictions Mean           713.16046
Q Predictions Std            254.78609
Q Predictions Max            1036.3673
Q Predictions Min            180.23825
V Predictions Mean           725.28394
V Predictions Std            246.79387
V Predictions Max            1033.8171
V Predictions Min            254.41919
Log Pis Mean                 -0.7389624
Log Pis Std                  3.232986
Log Pis Max                  16.463114
Log Pis Min                  -9.691876
Policy mu Mean               0.062167555
Policy mu Std                0.5583939
Policy mu Max                3.1438458
Policy mu Min                -2.2423294
Policy log std Mean          -0.95830303
Policy log std Std           0.19898501
Policy log std Max           -0.40218803
Policy log std Min           -1.789709
Z mean eval                  1.16974
Z variance eval              0.037801273
total_rewards                [ 751.28107709  427.09361755  920.06534895 2873.4889603   804.79888702
 1003.44934518  108.76572411 1823.25528514 1077.45016268 2715.30023161]
total_rewards_mean           1250.4948639650788
total_rewards_std            879.6233894984183
total_rewards_max            2873.4889603001916
total_rewards_min            108.76572411369068
Number of train steps total  412000
Number of env steps total    329442
Number of rollouts total     0
Train Time (s)               179.06339300377294
(Previous) Eval Time (s)     19.795003324281424
Sample Time (s)              7.729389226064086
Epoch Time (s)               206.58778555411845
Total Train Time (s)         21476.57508716313
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:09:37.989331 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #102 | Epoch Duration: 206.675546169281
2020-01-11 22:09:37.989454 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1673915
Z variance train             0.038055837
KL Divergence                23.34407
KL Loss                      2.334407
QF Loss                      461.29272
VF Loss                      140.53227
Policy Loss                  -730.68414
Q Predictions Mean           721.76483
Q Predictions Std            264.30832
Q Predictions Max            1044.4274
Q Predictions Min            1.5606754
V Predictions Mean           733.116
V Predictions Std            258.93173
V Predictions Max            1037.0736
V Predictions Min            30.514542
Log Pis Mean                 -0.59778476
Log Pis Std                  3.485631
Log Pis Max                  26.242556
Log Pis Min                  -6.829628
Policy mu Mean               0.046098128
Policy mu Std                0.5889537
Policy mu Max                5.263438
Policy mu Min                -3.7384284
Policy log std Mean          -0.9533818
Policy log std Std           0.18948455
Policy log std Max           -0.055297613
Policy log std Min           -1.8936533
Z mean eval                  1.2016466
Z variance eval              0.019840911
total_rewards                [1877.55153051 1596.91184549 1336.16796976  912.62797337 2289.47367723
 2653.16417678  131.41750375 1779.10031451  399.99235929  353.27045188]
total_rewards_mean           1332.9677802565643
total_rewards_std            816.9310300057264
total_rewards_max            2653.164176783665
total_rewards_min            131.4175037454197
Number of train steps total  416000
Number of env steps total    332316
Number of rollouts total     0
Train Time (s)               175.64896551566198
(Previous) Eval Time (s)     19.719395210966468
Sample Time (s)              7.809841839596629
Epoch Time (s)               203.17820256622508
Total Train Time (s)         21679.841817438137
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:13:01.257103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #103 | Epoch Duration: 203.2675597667694
2020-01-11 22:13:01.257222 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2022517
Z variance train             0.019889053
KL Divergence                25.339993
KL Loss                      2.5339992
QF Loss                      565.2312
VF Loss                      153.38884
Policy Loss                  -718.40436
Q Predictions Mean           711.33777
Q Predictions Std            274.12354
Q Predictions Max            1061.4564
Q Predictions Min            -39.39848
V Predictions Mean           718.77045
V Predictions Std            269.62454
V Predictions Max            1050.6779
V Predictions Min            -49.679497
Log Pis Mean                 -1.0417638
Log Pis Std                  3.038711
Log Pis Max                  17.169174
Log Pis Min                  -8.966219
Policy mu Mean               0.02799837
Policy mu Std                0.5041828
Policy mu Max                2.6182265
Policy mu Min                -2.6775784
Policy log std Mean          -0.9396281
Policy log std Std           0.19616723
Policy log std Max           -0.40844604
Policy log std Min           -1.9087899
Z mean eval                  1.2042778
Z variance eval              0.01998499
total_rewards                [ 225.57817404  184.44829204 1192.12789854 1588.76785782 1132.70852954
 1585.14188417 1324.04394061  321.61183633  210.19373236  661.70688566]
total_rewards_mean           842.6329031091179
total_rewards_std            553.554348454158
total_rewards_max            1588.7678578155062
total_rewards_min            184.44829203905908
Number of train steps total  420000
Number of env steps total    336135
Number of rollouts total     0
Train Time (s)               177.28553232178092
(Previous) Eval Time (s)     13.845067734830081
Sample Time (s)              7.7460957751609385
Epoch Time (s)               198.87669583177194
Total Train Time (s)         21878.802435590886
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:16:20.220051 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #104 | Epoch Duration: 198.96271347999573
2020-01-11 22:16:20.220193 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2026781
Z variance train             0.020070745
KL Divergence                25.41354
KL Loss                      2.541354
QF Loss                      834.7002
VF Loss                      141.61778
Policy Loss                  -706.3308
Q Predictions Mean           700.65094
Q Predictions Std            264.42053
Q Predictions Max            1083.3643
Q Predictions Min            0.42916816
V Predictions Mean           710.78284
V Predictions Std            261.5484
V Predictions Max            1077.8625
V Predictions Min            -33.815907
Log Pis Mean                 -0.684722
Log Pis Std                  2.8066096
Log Pis Max                  13.176479
Log Pis Min                  -8.329694
Policy mu Mean               0.034206964
Policy mu Std                0.5623154
Policy mu Max                3.3244536
Policy mu Min                -2.7766967
Policy log std Mean          -0.92194617
Policy log std Std           0.19461475
Policy log std Max           0.74117696
Policy log std Min           -1.961427
Z mean eval                  1.1755798
Z variance eval              0.01630237
total_rewards                [1996.30650961 2597.12403367 2977.61160908 2886.52801864 2860.91883821
  295.66708691 1665.76666228 2791.19845982  688.99642281 2781.49364185]
total_rewards_mean           2154.1611282889307
total_rewards_std            925.9412588213869
total_rewards_max            2977.6116090784053
total_rewards_min            295.667086912999
Number of train steps total  424000
Number of env steps total    338723
Number of rollouts total     0
Train Time (s)               179.3565356908366
(Previous) Eval Time (s)     23.11013937788084
Sample Time (s)              6.801810758654028
Epoch Time (s)               209.26848582737148
Total Train Time (s)         22088.172959427815
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:19:49.592178 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #105 | Epoch Duration: 209.37187838554382
2020-01-11 22:19:49.592363 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.181812
Z variance train             0.016336076
KL Divergence                23.67236
KL Loss                      2.367236
QF Loss                      469.2788
VF Loss                      306.979
Policy Loss                  -719.7693
Q Predictions Mean           707.8616
Q Predictions Std            272.365
Q Predictions Max            1078.7086
Q Predictions Min            -73.74563
V Predictions Mean           714.3257
V Predictions Std            258.8911
V Predictions Max            1074.6715
V Predictions Min            281.7581
Log Pis Mean                 -0.59145737
Log Pis Std                  3.1997585
Log Pis Max                  17.467087
Log Pis Min                  -7.9825687
Policy mu Mean               -0.002047561
Policy mu Std                0.536594
Policy mu Max                3.5969164
Policy mu Min                -2.9730327
Policy log std Mean          -0.9599588
Policy log std Std           0.2077439
Policy log std Max           -0.45624414
Policy log std Min           -2.175282
Z mean eval                  1.2222893
Z variance eval              0.019816432
total_rewards                [ 488.60271677  237.48472576  943.92448407  641.83708665   39.54506362
 2800.13690413 2706.50486979 2343.30389458 1077.85414396 1646.79750581]
total_rewards_mean           1292.5991395137294
total_rewards_std            970.6821498193782
total_rewards_max            2800.1369041308612
total_rewards_min            39.54506362051989
Number of train steps total  428000
Number of env steps total    341598
Number of rollouts total     0
Train Time (s)               176.97324891621247
(Previous) Eval Time (s)     18.56710399221629
Sample Time (s)              6.17773069627583
Epoch Time (s)               201.7180836047046
Total Train Time (s)         22289.983419388533
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:23:11.405728 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #106 | Epoch Duration: 201.81323409080505
2020-01-11 22:23:11.405870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #106 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.22657
Z variance train             0.019864839
KL Divergence                24.235708
KL Loss                      2.4235709
QF Loss                      499.4567
VF Loss                      98.81248
Policy Loss                  -731.11176
Q Predictions Mean           720.5967
Q Predictions Std            282.59537
Q Predictions Max            1064.119
Q Predictions Min            -46.978363
V Predictions Mean           727.749
V Predictions Std            274.19855
V Predictions Max            1061.839
V Predictions Min            24.539358
Log Pis Mean                 -0.7827785
Log Pis Std                  3.0676787
Log Pis Max                  16.004814
Log Pis Min                  -7.831414
Policy mu Mean               0.03354045
Policy mu Std                0.5367944
Policy mu Max                2.7648206
Policy mu Min                -2.3745744
Policy log std Mean          -0.9427891
Policy log std Std           0.19295454
Policy log std Max           -0.47086036
Policy log std Min           -1.9855795
Z mean eval                  1.23406
Z variance eval              0.009281956
total_rewards                [ 108.28377229  838.30559964 1067.29074839  264.27020631 2951.3648861
  507.57762854   52.73346958 2943.09189471 1060.90846529  188.83338937]
total_rewards_mean           998.2660060224582
total_rewards_std            1036.9197186652677
total_rewards_max            2951.3648861003444
total_rewards_min            52.7334695830543
Number of train steps total  432000
Number of env steps total    344051
Number of rollouts total     0
Train Time (s)               175.39371012011543
(Previous) Eval Time (s)     11.990963435266167
Sample Time (s)              6.789363511372358
Epoch Time (s)               194.17403706675395
Total Train Time (s)         22484.262044505682
Epoch                        107
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:26:25.689288 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #107 | Epoch Duration: 194.2832772731781
2020-01-11 22:26:25.689574 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.23297
Z variance train             0.009245911
KL Divergence                25.085499
KL Loss                      2.50855
QF Loss                      418.18536
VF Loss                      150.07701
Policy Loss                  -729.0304
Q Predictions Mean           723.1044
Q Predictions Std            277.06064
Q Predictions Max            1119.4684
Q Predictions Min            111.86462
V Predictions Mean           730.1497
V Predictions Std            271.76697
V Predictions Max            1116.4653
V Predictions Min            295.6428
Log Pis Mean                 -0.7846428
Log Pis Std                  3.416815
Log Pis Max                  16.188883
Log Pis Min                  -8.088499
Policy mu Mean               0.039460808
Policy mu Std                0.5483174
Policy mu Max                2.9418278
Policy mu Min                -3.56449
Policy log std Mean          -0.94534254
Policy log std Std           0.20044105
Policy log std Max           -0.47522736
Policy log std Min           -2.0988357
Z mean eval                  1.1846392
Z variance eval              0.015570748
total_rewards                [1424.37059665  803.03247432  998.22760973 1729.85338155 2802.58017607
 2882.36821782 1589.43468624 1287.7792362  2196.87635558  773.39620048]
total_rewards_mean           1648.791893464567
total_rewards_std            724.4987459200951
total_rewards_max            2882.368217819097
total_rewards_min            773.3962004752811
Number of train steps total  436000
Number of env steps total    347484
Number of rollouts total     0
Train Time (s)               177.65426232106984
(Previous) Eval Time (s)     26.710523538757116
Sample Time (s)              6.821703016292304
Epoch Time (s)               211.18648887611926
Total Train Time (s)         22695.58394266572
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:29:57.010479 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #108 | Epoch Duration: 211.32070970535278
2020-01-11 22:29:57.010601 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.194761
Z variance train             0.015706126
KL Divergence                24.844538
KL Loss                      2.484454
QF Loss                      685.12476
VF Loss                      149.04475
Policy Loss                  -758.5593
Q Predictions Mean           747.1553
Q Predictions Std            252.55971
Q Predictions Max            1094.8053
Q Predictions Min            39.754257
V Predictions Mean           765.73956
V Predictions Std            243.52287
V Predictions Max            1102.9789
V Predictions Min            243.31258
Log Pis Mean                 -0.33923596
Log Pis Std                  3.291582
Log Pis Max                  15.094027
Log Pis Min                  -8.15497
Policy mu Mean               0.018107735
Policy mu Std                0.58372146
Policy mu Max                3.373383
Policy mu Min                -2.7517543
Policy log std Mean          -0.9673618
Policy log std Std           0.19630425
Policy log std Max           -0.48010308
Policy log std Min           -1.9049723
Z mean eval                  1.1555321
Z variance eval              0.028318163
total_rewards                [2911.16340151 2917.89225296 1386.16699586  415.99385502  956.72871864
  205.68549883 2924.44768855 2695.45978799 2442.64372265  110.32215793]
total_rewards_mean           1696.6504079943047
total_rewards_std            1142.4300748914004
total_rewards_max            2924.44768855305
total_rewards_min            110.32215792517046
Number of train steps total  440000
Number of env steps total    350424
Number of rollouts total     0
Train Time (s)               175.97780896676704
(Previous) Eval Time (s)     21.899682998191565
Sample Time (s)              7.538719681557268
Epoch Time (s)               205.41621164651588
Total Train Time (s)         22901.483859216794
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:33:22.912588 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #109 | Epoch Duration: 205.9018850326538
2020-01-11 22:33:22.912753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.166399
Z variance train             0.02825209
KL Divergence                23.336607
KL Loss                      2.3336608
QF Loss                      549.1946
VF Loss                      122.115364
Policy Loss                  -714.98114
Q Predictions Mean           702.72754
Q Predictions Std            294.54034
Q Predictions Max            1067.1691
Q Predictions Min            -16.401579
V Predictions Mean           713.6102
V Predictions Std            283.61237
V Predictions Max            1063.9321
V Predictions Min            -52.0166
Log Pis Mean                 -0.6277802
Log Pis Std                  3.5520606
Log Pis Max                  21.557426
Log Pis Min                  -8.732589
Policy mu Mean               0.0230338
Policy mu Std                0.564627
Policy mu Max                2.736845
Policy mu Min                -2.8919985
Policy log std Mean          -0.9519802
Policy log std Std           0.20286468
Policy log std Max           -0.2521283
Policy log std Min           -2.2901685
Z mean eval                  1.1362108
Z variance eval              0.016608352
total_rewards                [1285.89203124 1879.48784886 1854.29129641  912.49192565 1716.25538864
 1738.89315199  206.11429621 2373.65531966  383.22516156 1395.90086972]
total_rewards_mean           1374.620728995801
total_rewards_std            655.9431778598527
total_rewards_max            2373.6553196615814
total_rewards_min            206.11429621129275
Number of train steps total  444000
Number of env steps total    353129
Number of rollouts total     0
Train Time (s)               174.95259717386216
(Previous) Eval Time (s)     26.19014495704323
Sample Time (s)              7.276986557524651
Epoch Time (s)               208.41972868843004
Total Train Time (s)         23109.999506069813
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:36:51.433193 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #110 | Epoch Duration: 208.5202989578247
2020-01-11 22:36:51.433400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1324732
Z variance train             0.01672849
KL Divergence                23.788174
KL Loss                      2.3788173
QF Loss                      517.2826
VF Loss                      133.88834
Policy Loss                  -744.2035
Q Predictions Mean           738.39575
Q Predictions Std            273.81485
Q Predictions Max            1092.6119
Q Predictions Min            251.40048
V Predictions Mean           743.7808
V Predictions Std            268.9051
V Predictions Max            1103.2325
V Predictions Min            261.96756
Log Pis Mean                 -1.202446
Log Pis Std                  2.7040732
Log Pis Max                  11.474341
Log Pis Min                  -7.53333
Policy mu Mean               0.016756326
Policy mu Std                0.51246905
Policy mu Max                2.6531165
Policy mu Min                -2.9699304
Policy log std Mean          -0.94175214
Policy log std Std           0.18039812
Policy log std Max           -0.47857827
Policy log std Min           -1.8234093
Z mean eval                  1.171849
Z variance eval              0.013953298
total_rewards                [2873.07753368 2772.34180098 2950.19099756  573.25328519 2943.75062277
 1101.50839403   96.80175779 1216.6515044  2942.86790242 2826.41558239]
total_rewards_mean           2029.6859381214733
total_rewards_std            1086.0085737764894
total_rewards_max            2950.19099756237
total_rewards_min            96.80175778762644
Number of train steps total  448000
Number of env steps total    355493
Number of rollouts total     0
Train Time (s)               177.3811043081805
(Previous) Eval Time (s)     23.957720236852765
Sample Time (s)              6.998994203750044
Epoch Time (s)               208.33781874878332
Total Train Time (s)         23318.455804450437
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:40:19.890571 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #111 | Epoch Duration: 208.45696902275085
2020-01-11 22:40:19.890852 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1690786
Z variance train             0.013964206
KL Divergence                24.549736
KL Loss                      2.4549737
QF Loss                      526.0508
VF Loss                      74.20221
Policy Loss                  -727.07794
Q Predictions Mean           721.613
Q Predictions Std            284.22034
Q Predictions Max            1080.1848
Q Predictions Min            269.50116
V Predictions Mean           730.2854
V Predictions Std            281.29785
V Predictions Max            1088.3855
V Predictions Min            281.7904
Log Pis Mean                 -0.97336024
Log Pis Std                  2.805199
Log Pis Max                  11.914437
Log Pis Min                  -8.782532
Policy mu Mean               0.0010243151
Policy mu Std                0.49856928
Policy mu Max                3.2670527
Policy mu Min                -2.2548776
Policy log std Mean          -0.93954045
Policy log std Std           0.19462933
Policy log std Max           -0.33390778
Policy log std Min           -1.9390255
Z mean eval                  1.1460218
Z variance eval              0.028479272
total_rewards                [1605.80960957 2500.88696323  118.71600259  746.24785829 2388.69866899
 2720.25590152  453.00867507 1219.25882651  538.77890506 2473.32007015]
total_rewards_mean           1476.4981480983158
total_rewards_std            938.5440304873041
total_rewards_max            2720.2559015217344
total_rewards_min            118.71600258580503
Number of train steps total  452000
Number of env steps total    357868
Number of rollouts total     0
Train Time (s)               176.9224393153563
(Previous) Eval Time (s)     25.76946402201429
Sample Time (s)              5.881583987735212
Epoch Time (s)               208.57348732510582
Total Train Time (s)         23527.1857286077
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:43:48.621723 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #112 | Epoch Duration: 208.73070073127747
2020-01-11 22:43:48.621904 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1459578
Z variance train             0.028520465
KL Divergence                22.447475
KL Loss                      2.2447476
QF Loss                      551.1234
VF Loss                      105.47392
Policy Loss                  -746.5718
Q Predictions Mean           738.56635
Q Predictions Std            267.20236
Q Predictions Max            1078.4136
Q Predictions Min            201.38187
V Predictions Mean           748.2378
V Predictions Std            263.43686
V Predictions Max            1083.6204
V Predictions Min            259.87872
Log Pis Mean                 -0.8924802
Log Pis Std                  2.6840115
Log Pis Max                  11.267689
Log Pis Min                  -8.255873
Policy mu Mean               0.028909352
Policy mu Std                0.50550616
Policy mu Max                2.3249438
Policy mu Min                -2.411571
Policy log std Mean          -0.9593924
Policy log std Std           0.18813166
Policy log std Max           -0.46299547
Policy log std Min           -1.8373965
Z mean eval                  1.238993
Z variance eval              0.033537805
total_rewards                [ 326.43055409 1988.31059436 1641.94130232 1374.45502866 1684.00074921
 3060.33305047 1246.87561091 2719.80979167 1468.30251969 3018.42696884]
total_rewards_mean           1852.88861702184
total_rewards_std            820.5757839513889
total_rewards_max            3060.33305046501
total_rewards_min            326.4305540922821
Number of train steps total  456000
Number of env steps total    360487
Number of rollouts total     0
Train Time (s)               176.3235868201591
(Previous) Eval Time (s)     23.371182527858764
Sample Time (s)              6.883031866047531
Epoch Time (s)               206.5778012140654
Total Train Time (s)         23733.849789570086
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:47:15.290049 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #113 | Epoch Duration: 206.66801714897156
2020-01-11 22:47:15.290205 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2433697
Z variance train             0.033815138
KL Divergence                22.057652
KL Loss                      2.2057652
QF Loss                      591.1249
VF Loss                      206.32841
Policy Loss                  -740.66986
Q Predictions Mean           735.6212
Q Predictions Std            278.2648
Q Predictions Max            1077.5679
Q Predictions Min            -44.04449
V Predictions Mean           738.2949
V Predictions Std            273.14886
V Predictions Max            1059.4824
V Predictions Min            92.685036
Log Pis Mean                 -0.6993253
Log Pis Std                  3.5425029
Log Pis Max                  19.767529
Log Pis Min                  -7.4150853
Policy mu Mean               0.023683827
Policy mu Std                0.58100563
Policy mu Max                4.0148087
Policy mu Min                -3.7829227
Policy log std Mean          -0.9577279
Policy log std Std           0.19205117
Policy log std Max           -0.4436124
Policy log std Min           -1.917184
Z mean eval                  1.2155735
Z variance eval              0.03226201
total_rewards                [2933.53249677 2477.65267745 1608.20643495 2913.17034487  712.52217595
 2917.74482233 1135.4912034  2799.63821123 2774.65772179 3005.64627423]
total_rewards_mean           2327.826236296886
total_rewards_std            806.8697116956316
total_rewards_max            3005.6462742318
total_rewards_min            712.5221759492808
Number of train steps total  460000
Number of env steps total    363735
Number of rollouts total     0
Train Time (s)               176.1811585733667
(Previous) Eval Time (s)     29.67091694707051
Sample Time (s)              6.769365021027625
Epoch Time (s)               212.62144054146484
Total Train Time (s)         23946.56451309845
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:50:48.006543 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #114 | Epoch Duration: 212.7161934375763
2020-01-11 22:50:48.006762 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2145246
Z variance train             0.03309446
KL Divergence                24.109713
KL Loss                      2.4109714
QF Loss                      684.03564
VF Loss                      81.88583
Policy Loss                  -762.7581
Q Predictions Mean           751.92896
Q Predictions Std            274.5853
Q Predictions Max            1080.3052
Q Predictions Min            13.478667
V Predictions Mean           761.36487
V Predictions Std            262.16794
V Predictions Max            1075.7788
V Predictions Min            16.51015
Log Pis Mean                 -0.39299363
Log Pis Std                  3.3548436
Log Pis Max                  15.039812
Log Pis Min                  -13.453844
Policy mu Mean               -0.00018292852
Policy mu Std                0.58219296
Policy mu Max                3.1237664
Policy mu Min                -3.0482028
Policy log std Mean          -0.9573569
Policy log std Std           0.19286263
Policy log std Max           -0.49213922
Policy log std Min           -2.0383377
Z mean eval                  1.1572526
Z variance eval              0.027946284
total_rewards                [2946.45055746 2918.57188038 1449.4957925  1627.03310089 2876.15819016
 1491.98128238  536.72628921  920.48296705 1543.60252329  381.63173439]
total_rewards_mean           1669.2134317722346
total_rewards_std            908.1399825390423
total_rewards_max            2946.4505574632512
total_rewards_min            381.6317343933937
Number of train steps total  464000
Number of env steps total    366372
Number of rollouts total     0
Train Time (s)               175.72541062068194
(Previous) Eval Time (s)     20.524942826945335
Sample Time (s)              7.539806367829442
Epoch Time (s)               203.79015981545672
Total Train Time (s)         24150.44512346387
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:54:11.888052 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #115 | Epoch Duration: 203.88117480278015
2020-01-11 22:54:11.888174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608074
Z variance train             0.028356325
KL Divergence                22.869936
KL Loss                      2.2869937
QF Loss                      482.02197
VF Loss                      152.21288
Policy Loss                  -755.02185
Q Predictions Mean           749.48706
Q Predictions Std            275.37433
Q Predictions Max            1100.4637
Q Predictions Min            -0.13868439
V Predictions Mean           761.0151
V Predictions Std            273.0398
V Predictions Max            1113.9979
V Predictions Min            43.767387
Log Pis Mean                 -0.49812436
Log Pis Std                  3.1902347
Log Pis Max                  22.144295
Log Pis Min                  -7.661493
Policy mu Mean               0.011077068
Policy mu Std                0.5601897
Policy mu Max                3.3817813
Policy mu Min                -4.343719
Policy log std Mean          -0.96595126
Policy log std Std           0.20840521
Policy log std Max           -0.5070704
Policy log std Min           -2.2618048
Z mean eval                  1.139195
Z variance eval              0.015855419
total_rewards                [ 962.02469379 3023.80305158 3060.41847457 1755.69835843 2041.68728859
 2897.39947291 2644.49595181 2757.94096996 1751.32287478 2895.37678206]
total_rewards_mean           2379.0167918488974
total_rewards_std            673.3239827374091
total_rewards_max            3060.418474568738
total_rewards_min            962.0246937919356
Number of train steps total  468000
Number of env steps total    369823
Number of rollouts total     0
Train Time (s)               176.00714247487485
(Previous) Eval Time (s)     27.460253903176636
Sample Time (s)              7.260799134150147
Epoch Time (s)               210.72819551220164
Total Train Time (s)         24361.26261470234
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:57:42.707597 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #116 | Epoch Duration: 210.81931495666504
2020-01-11 22:57:42.707780 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1409509
Z variance train             0.015716525
KL Divergence                23.132124
KL Loss                      2.3132124
QF Loss                      589.9525
VF Loss                      125.995026
Policy Loss                  -762.32697
Q Predictions Mean           754.98395
Q Predictions Std            284.2643
Q Predictions Max            1106.9843
Q Predictions Min            -7.4080286
V Predictions Mean           762.758
V Predictions Std            278.9364
V Predictions Max            1107.5823
V Predictions Min            75.217705
Log Pis Mean                 -0.7078495
Log Pis Std                  3.6977186
Log Pis Max                  26.83303
Log Pis Min                  -9.656571
Policy mu Mean               0.016331274
Policy mu Std                0.5567894
Policy mu Max                3.8236954
Policy mu Min                -3.604752
Policy log std Mean          -0.96870446
Policy log std Std           0.19241604
Policy log std Max           -0.49474713
Policy log std Min           -2.1328402
Z mean eval                  1.270342
Z variance eval              0.039886758
total_rewards                [ 577.63171527 2883.59968327 1966.76118814 1571.883753   2886.30263194
  378.78521695 2948.20880857 2883.21455882 2891.02339196  721.81338037]
total_rewards_mean           1970.9224328283938
total_rewards_std            1024.7211609732672
total_rewards_max            2948.2088085680098
total_rewards_min            378.7852169490496
Number of train steps total  472000
Number of env steps total    373237
Number of rollouts total     0
Train Time (s)               177.62969155609608
(Previous) Eval Time (s)     28.44587867008522
Sample Time (s)              6.800229701213539
Epoch Time (s)               212.87579992739484
Total Train Time (s)         24574.227565723006
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:01:15.674382 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #117 | Epoch Duration: 212.96646356582642
2020-01-11 23:01:15.674552 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2582359
Z variance train             0.04054473
KL Divergence                22.526117
KL Loss                      2.2526119
QF Loss                      598.2705
VF Loss                      175.76886
Policy Loss                  -777.1897
Q Predictions Mean           770.0903
Q Predictions Std            284.04404
Q Predictions Max            1159.2168
Q Predictions Min            234.37378
V Predictions Mean           776.3531
V Predictions Std            278.71133
V Predictions Max            1150.5902
V Predictions Min            283.213
Log Pis Mean                 -0.72048557
Log Pis Std                  3.0221043
Log Pis Max                  14.656419
Log Pis Min                  -8.409667
Policy mu Mean               0.003272988
Policy mu Std                0.52982813
Policy mu Max                2.3876026
Policy mu Min                -2.873462
Policy log std Mean          -0.9488133
Policy log std Std           0.19365247
Policy log std Max           -0.4505436
Policy log std Min           -1.985544
Z mean eval                  1.1701238
Z variance eval              0.0205634
total_rewards                [2085.03568313  773.89311409  918.05919149  824.02006859  100.45570096
 1938.01563472  458.83319028 1090.12021134   12.29392919  970.547085  ]
total_rewards_mean           917.1273808799655
total_rewards_std            645.2827660611448
total_rewards_max            2085.0356831348213
total_rewards_min            12.293929189345643
Number of train steps total  476000
Number of env steps total    375822
Number of rollouts total     0
Train Time (s)               175.4902988751419
(Previous) Eval Time (s)     16.791316564194858
Sample Time (s)              6.8913484662771225
Epoch Time (s)               199.17296390561387
Total Train Time (s)         24773.490400529
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:04:34.937986 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #118 | Epoch Duration: 199.26331329345703
2020-01-11 23:04:34.938109 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1763628
Z variance train             0.02088565
KL Divergence                23.35849
KL Loss                      2.335849
QF Loss                      571.0255
VF Loss                      115.914085
Policy Loss                  -753.8577
Q Predictions Mean           745.00446
Q Predictions Std            293.39755
Q Predictions Max            1100.0935
Q Predictions Min            -47.810215
V Predictions Mean           753.3748
V Predictions Std            282.86816
V Predictions Max            1098.4412
V Predictions Min            192.0362
Log Pis Mean                 -0.43085733
Log Pis Std                  3.3319116
Log Pis Max                  17.70538
Log Pis Min                  -6.1566763
Policy mu Mean               0.018612914
Policy mu Std                0.57510185
Policy mu Max                3.1375706
Policy mu Min                -3.1314116
Policy log std Mean          -0.960356
Policy log std Std           0.19719984
Policy log std Max           -0.38062733
Policy log std Min           -1.9578421
Z mean eval                  1.2328554
Z variance eval              0.030174294
total_rewards                [2407.06290443  906.90986951 1176.42583928  720.56023363 1306.86203779
 3155.27452482 2988.56375499   15.92884027  273.52445908  472.56416538]
total_rewards_mean           1342.36766291682
total_rewards_std            1067.410792381563
total_rewards_max            3155.274524816362
total_rewards_min            15.928840267513579
Number of train steps total  480000
Number of env steps total    378480
Number of rollouts total     0
Train Time (s)               177.1102107949555
(Previous) Eval Time (s)     24.30306106712669
Sample Time (s)              7.56685950094834
Epoch Time (s)               208.98013136303052
Total Train Time (s)         24982.565856725443
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:08:04.015590 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #119 | Epoch Duration: 209.07737708091736
2020-01-11 23:08:04.015769 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #119 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2448914
Z variance train             0.02982373
KL Divergence                22.814833
KL Loss                      2.2814834
QF Loss                      685.0094
VF Loss                      184.57718
Policy Loss                  -785.2241
Q Predictions Mean           775.14844
Q Predictions Std            280.00732
Q Predictions Max            1118.4999
Q Predictions Min            62.516064
V Predictions Mean           776.00195
V Predictions Std            269.45114
V Predictions Max            1100.1608
V Predictions Min            283.0223
Log Pis Mean                 -0.37231714
Log Pis Std                  2.9581091
Log Pis Max                  13.2378435
Log Pis Min                  -6.6616454
Policy mu Mean               0.0042175325
Policy mu Std                0.5442099
Policy mu Max                2.139174
Policy mu Min                -2.9626276
Policy log std Mean          -0.9779398
Policy log std Std           0.20886743
Policy log std Max           -0.43762583
Policy log std Min           -2.0388987
Z mean eval                  1.1683577
Z variance eval              0.014494887
total_rewards                [ 1.45116032e+03  3.66090262e+02  1.34264068e+03  4.74509789e+02
  2.02458318e+03 -1.43668984e+00  2.47503220e+02  2.59877088e+02
  1.24810468e+03  1.12781454e+03]
total_rewards_mean           854.0847083078952
total_rewards_std            634.8692016229938
total_rewards_max            2024.5831843797005
total_rewards_min            -1.4366898386034284
Number of train steps total  484000
Number of env steps total    382660
Number of rollouts total     0
Train Time (s)               176.8490974549204
(Previous) Eval Time (s)     10.912617356982082
Sample Time (s)              11.257778661791235
Epoch Time (s)               199.01949347369373
Total Train Time (s)         25181.678593056276
Epoch                        120
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:11:23.129104 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #120 | Epoch Duration: 199.11320781707764
2020-01-11 23:11:23.129240 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1713653
Z variance train             0.014363172
KL Divergence                23.542711
KL Loss                      2.3542712
QF Loss                      410.33356
VF Loss                      104.64484
Policy Loss                  -786.83154
Q Predictions Mean           781.9255
Q Predictions Std            280.5399
Q Predictions Max            1124.9695
Q Predictions Min            52.997673
V Predictions Mean           791.8605
V Predictions Std            277.25864
V Predictions Max            1137.1854
V Predictions Min            19.812479
Log Pis Mean                 -0.674384
Log Pis Std                  2.7265406
Log Pis Max                  14.09449
Log Pis Min                  -6.3308935
Policy mu Mean               0.030988388
Policy mu Std                0.5296664
Policy mu Max                2.9376223
Policy mu Min                -2.0023372
Policy log std Mean          -0.9575767
Policy log std Std           0.19191766
Policy log std Max           -0.40785518
Policy log std Min           -1.8661413
Z mean eval                  1.1664643
Z variance eval              0.03261345
total_rewards                [3203.54862225 3080.46394841 3025.43797918 3102.91330147  228.85578969
 2991.40116696 3163.44557714 2967.32438127  727.78566551 3095.46042001]
total_rewards_mean           2558.66368518744
total_rewards_std            1048.3574915040683
total_rewards_max            3203.548622247076
total_rewards_min            228.8557896931879
Number of train steps total  488000
Number of env steps total    385736
Number of rollouts total     0
Train Time (s)               177.72353002382442
(Previous) Eval Time (s)     23.683491555973887
Sample Time (s)              7.972619037143886
Epoch Time (s)               209.3796406169422
Total Train Time (s)         25391.15804634383
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:14:52.612204 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #121 | Epoch Duration: 209.48284029960632
2020-01-11 23:14:52.612421 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1743697
Z variance train             0.03210733
KL Divergence                21.771458
KL Loss                      2.1771457
QF Loss                      515.52
VF Loss                      185.15167
Policy Loss                  -754.6512
Q Predictions Mean           748.0266
Q Predictions Std            301.27448
Q Predictions Max            1145.9326
Q Predictions Min            -31.685938
V Predictions Mean           748.40955
V Predictions Std            296.22958
V Predictions Max            1137.9803
V Predictions Min            23.33647
Log Pis Mean                 -0.8515221
Log Pis Std                  3.1610723
Log Pis Max                  20.033342
Log Pis Min                  -8.146176
Policy mu Mean               0.020096112
Policy mu Std                0.5344629
Policy mu Max                3.9773493
Policy mu Min                -3.810333
Policy log std Mean          -0.96100175
Policy log std Std           0.19760899
Policy log std Max           -0.403832
Policy log std Min           -2.0719688
Z mean eval                  1.2279298
Z variance eval              0.010764448
total_rewards                [ 586.28632746 2878.90131956  518.95613736  599.34799189  439.39524032
 1401.1430045  2893.04238395 2931.69709885  728.83954201 3059.53824987]
total_rewards_mean           1603.7147295778748
total_rewards_std            1120.4517841571376
total_rewards_max            3059.5382498710705
total_rewards_min            439.39524032277535
Number of train steps total  492000
Number of env steps total    389473
Number of rollouts total     0
Train Time (s)               176.49356423597783
(Previous) Eval Time (s)     29.43385598389432
Sample Time (s)              7.057195904664695
Epoch Time (s)               212.98461612453684
Total Train Time (s)         25604.234620745294
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:18:25.693546 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #122 | Epoch Duration: 213.08092284202576
2020-01-11 23:18:25.693849 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2251432
Z variance train             0.010696641
KL Divergence                23.832434
KL Loss                      2.3832433
QF Loss                      531.62866
VF Loss                      149.39772
Policy Loss                  -751.0295
Q Predictions Mean           744.18976
Q Predictions Std            305.03088
Q Predictions Max            1140.2683
Q Predictions Min            47.55537
V Predictions Mean           757.9365
V Predictions Std            299.80356
V Predictions Max            1163.4441
V Predictions Min            25.202976
Log Pis Mean                 -0.47067603
Log Pis Std                  3.02303
Log Pis Max                  13.443053
Log Pis Min                  -11.282997
Policy mu Mean               0.029322408
Policy mu Std                0.5455458
Policy mu Max                3.123322
Policy mu Min                -2.8508778
Policy log std Mean          -0.9855476
Policy log std Std           0.21455386
Policy log std Max           -0.34658343
Policy log std Min           -2.2809587
Z mean eval                  1.141134
Z variance eval              0.019309124
total_rewards                [ 527.10006488 3287.36217052 3072.28422323  451.72608228 2247.27272435
 1244.89696441 3065.79348883  292.03478926 3107.22159674 2976.17689341]
total_rewards_mean           2027.186899791248
total_rewards_std            1192.876195983803
total_rewards_max            3287.3621705181854
total_rewards_min            292.03478926021774
Number of train steps total  496000
Number of env steps total    392395
Number of rollouts total     0
Train Time (s)               177.84945645090193
(Previous) Eval Time (s)     19.591387826018035
Sample Time (s)              7.015523703768849
Epoch Time (s)               204.4563679806888
Total Train Time (s)         25808.886049352586
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:21:50.349553 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #123 | Epoch Duration: 204.65549063682556
2020-01-11 23:21:50.349718 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1444304
Z variance train             0.019426178
KL Divergence                23.521065
KL Loss                      2.3521066
QF Loss                      644.72363
VF Loss                      202.99484
Policy Loss                  -748.2964
Q Predictions Mean           738.9188
Q Predictions Std            317.16403
Q Predictions Max            1126.3258
Q Predictions Min            236.68475
V Predictions Mean           758.45074
V Predictions Std            313.37997
V Predictions Max            1145.6323
V Predictions Min            286.626
Log Pis Mean                 -0.73370963
Log Pis Std                  2.768467
Log Pis Max                  11.9387245
Log Pis Min                  -7.154232
Policy mu Mean               0.046670504
Policy mu Std                0.5151849
Policy mu Max                2.7292697
Policy mu Min                -2.0333033
Policy log std Mean          -0.9516591
Policy log std Std           0.19884095
Policy log std Max           -0.47945592
Policy log std Min           -2.052714
Z mean eval                  1.1213007
Z variance eval              0.04262101
total_rewards                [ 479.12157412 3078.97559892  719.42106339 3313.09345089 1388.24302165
 2328.69452571 3008.91521976  457.36400048  837.49204863  321.56336828]
total_rewards_mean           1593.2883871832641
total_rewards_std            1150.4655447329076
total_rewards_max            3313.0934508891232
total_rewards_min            321.5633682814239
Number of train steps total  500000
Number of env steps total    395801
Number of rollouts total     0
Train Time (s)               175.93221304006875
(Previous) Eval Time (s)     19.222110576927662
Sample Time (s)              7.167019736487418
Epoch Time (s)               202.32134335348383
Total Train Time (s)         26011.293851254974
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:25:12.758610 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #124 | Epoch Duration: 202.4087724685669
2020-01-11 23:25:12.758734 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1248702
Z variance train             0.042415
KL Divergence                21.158974
KL Loss                      2.1158974
QF Loss                      600.7971
VF Loss                      125.65108
Policy Loss                  -796.37366
Q Predictions Mean           790.61334
Q Predictions Std            295.0437
Q Predictions Max            1144.8992
Q Predictions Min            110.990326
V Predictions Mean           795.1249
V Predictions Std            286.2785
V Predictions Max            1125.085
V Predictions Min            264.38217
Log Pis Mean                 -0.46963227
Log Pis Std                  3.3795319
Log Pis Max                  17.27166
Log Pis Min                  -11.8683605
Policy mu Mean               0.044228427
Policy mu Std                0.5483013
Policy mu Max                2.5591683
Policy mu Min                -2.5791242
Policy log std Mean          -0.9938905
Policy log std Std           0.21070944
Policy log std Max           -0.2860403
Policy log std Min           -1.8725331
Z mean eval                  1.1818256
Z variance eval              0.016065706
total_rewards                [2943.65732068 3082.56499257  110.17555382  594.0810691  3007.22892688
  867.14170137 2943.37325304 1342.6384155   822.28660575 2810.47418585]
total_rewards_mean           1852.3622024536344
total_rewards_std            1142.6436021439085
total_rewards_max            3082.564992566443
total_rewards_min            110.17555381530099
Number of train steps total  504000
Number of env steps total    401150
Number of rollouts total     0
Train Time (s)               176.29640393005684
(Previous) Eval Time (s)     21.103642512112856
Sample Time (s)              8.044671146664768
Epoch Time (s)               205.44471758883446
Total Train Time (s)         26216.83920236677
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:28:38.307195 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #125 | Epoch Duration: 205.54834723472595
2020-01-11 23:28:38.307400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #125 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1809599
Z variance train             0.016107315
KL Divergence                23.229996
KL Loss                      2.3229997
QF Loss                      986.4867
VF Loss                      171.62155
Policy Loss                  -798.2503
Q Predictions Mean           790.0873
Q Predictions Std            293.13364
Q Predictions Max            1141.3054
Q Predictions Min            264.8678
V Predictions Mean           799.4116
V Predictions Std            286.8357
V Predictions Max            1135.9622
V Predictions Min            265.55038
Log Pis Mean                 -0.28412414
Log Pis Std                  3.307835
Log Pis Max                  15.739468
Log Pis Min                  -7.705744
Policy mu Mean               0.018324656
Policy mu Std                0.57414764
Policy mu Max                2.5524871
Policy mu Min                -3.8523464
Policy log std Mean          -0.99136937
Policy log std Std           0.23280111
Policy log std Max           -0.40290225
Policy log std Min           -2.2619421
Z mean eval                  1.1249287
Z variance eval              0.019210333
total_rewards                [3385.60094511 2192.11969429 3082.63532068 3174.43800563 2668.313804
 2967.21523042  324.7070289  3006.54591921 3185.05853252 2998.8296746 ]
total_rewards_mean           2698.5464155364134
total_rewards_std            850.4379571439331
total_rewards_max            3385.600945113093
total_rewards_min            324.7070289037739
Number of train steps total  508000
Number of env steps total    404641
Number of rollouts total     0
Train Time (s)               178.19882911397144
(Previous) Eval Time (s)     24.69316043658182
Sample Time (s)              7.115487031172961
Epoch Time (s)               210.00747658172622
Total Train Time (s)         26426.94638236845
Epoch                        126
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:32:08.416673 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #126 | Epoch Duration: 210.109069108963
2020-01-11 23:32:08.416952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1297822
Z variance train             0.019114416
KL Divergence                22.818266
KL Loss                      2.2818267
QF Loss                      613.86646
VF Loss                      199.33575
Policy Loss                  -783.5556
Q Predictions Mean           775.8596
Q Predictions Std            311.50705
Q Predictions Max            1175.1089
Q Predictions Min            -65.70899
V Predictions Mean           781.4
V Predictions Std            303.9711
V Predictions Max            1167.8711
V Predictions Min            44.424644
Log Pis Mean                 -0.51631236
Log Pis Std                  3.60306
Log Pis Max                  29.151817
Log Pis Min                  -8.251527
Policy mu Mean               0.017709343
Policy mu Std                0.56263083
Policy mu Max                5.7872105
Policy mu Min                -3.4489527
Policy log std Mean          -0.9713131
Policy log std Std           0.20130858
Policy log std Max           -0.44027144
Policy log std Min           -2.0264153
Z mean eval                  1.1383312
Z variance eval              0.017912913
total_rewards                [ 318.96432647  846.71468166 1900.05288663  464.68009653  490.58042101
 2395.81859284 1357.47948243  721.61396534 1084.32138338 2330.61357984]
total_rewards_mean           1191.0839416127892
total_rewards_std            735.4990590453373
total_rewards_max            2395.8185928359226
total_rewards_min            318.9643264742669
Number of train steps total  512000
Number of env steps total    407549
Number of rollouts total     0
Train Time (s)               178.65286199189723
(Previous) Eval Time (s)     18.216598384082317
Sample Time (s)              7.017772633116692
Epoch Time (s)               203.88723300909624
Total Train Time (s)         26630.931726675946
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:35:32.404429 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #127 | Epoch Duration: 203.98728036880493
2020-01-11 23:35:32.404653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.134725
Z variance train             0.01790435
KL Divergence                22.900724
KL Loss                      2.2900724
QF Loss                      579.3484
VF Loss                      178.98338
Policy Loss                  -798.5519
Q Predictions Mean           791.1122
Q Predictions Std            290.74158
Q Predictions Max            1153.1936
Q Predictions Min            -10.751526
V Predictions Mean           806.3468
V Predictions Std            287.646
V Predictions Max            1164.7053
V Predictions Min            75.680954
Log Pis Mean                 -0.49764818
Log Pis Std                  2.972761
Log Pis Max                  17.927345
Log Pis Min                  -6.8427424
Policy mu Mean               0.03177167
Policy mu Std                0.58046895
Policy mu Max                3.1586041
Policy mu Min                -3.423465
Policy log std Mean          -0.9319067
Policy log std Std           0.20544444
Policy log std Max           -0.3862973
Policy log std Min           -1.8138274
Z mean eval                  1.1774492
Z variance eval              0.03305235
total_rewards                [3014.46387542 1351.1803913  2574.83216723 3229.63330887 1557.90853297
  156.57003668 1276.17722564 2796.23592423 3064.52486826 3115.69318932]
total_rewards_mean           2213.721951992069
total_rewards_std            998.2653777784419
total_rewards_max            3229.6333088657484
total_rewards_min            156.57003668433913
Number of train steps total  516000
Number of env steps total    410483
Number of rollouts total     0
Train Time (s)               176.74507250497118
(Previous) Eval Time (s)     28.180621813051403
Sample Time (s)              7.222621565684676
Epoch Time (s)               212.14831588370726
Total Train Time (s)         26843.168674374465
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:39:04.644939 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #128 | Epoch Duration: 212.24009037017822
2020-01-11 23:39:04.645161 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780379
Z variance train             0.032857846
KL Divergence                20.648249
KL Loss                      2.0648248
QF Loss                      526.708
VF Loss                      155.22327
Policy Loss                  -826.9648
Q Predictions Mean           817.58344
Q Predictions Std            292.00867
Q Predictions Max            1162.3402
Q Predictions Min            -18.71208
V Predictions Mean           818.4352
V Predictions Std            285.21
V Predictions Max            1157.0593
V Predictions Min            -8.275667
Log Pis Mean                 -0.48715088
Log Pis Std                  2.6852438
Log Pis Max                  14.113123
Log Pis Min                  -6.7415614
Policy mu Mean               0.0135023575
Policy mu Std                0.5330346
Policy mu Max                2.4525561
Policy mu Min                -2.5436485
Policy log std Mean          -0.97751427
Policy log std Std           0.19793612
Policy log std Max           -0.51493466
Policy log std Min           -2.0150688
Z mean eval                  1.1439307
Z variance eval              0.01835131
total_rewards                [3055.65087028 1201.49301979 2345.78909037 2142.57762356    9.64474586
 1597.38617207 1562.01223697 3358.44330182 3209.47950113  414.44535522]
total_rewards_mean           1889.6921917085704
total_rewards_std            1091.2318780912226
total_rewards_max            3358.4433018206696
total_rewards_min            9.644745860813835
Number of train steps total  520000
Number of env steps total    414645
Number of rollouts total     0
Train Time (s)               178.7823903337121
(Previous) Eval Time (s)     22.008152103051543
Sample Time (s)              7.361594071146101
Epoch Time (s)               208.15213650790974
Total Train Time (s)         27051.41961701354
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:42:32.895764 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #129 | Epoch Duration: 208.25047874450684
2020-01-11 23:42:32.895891 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1488239
Z variance train             0.018487912
KL Divergence                22.942928
KL Loss                      2.294293
QF Loss                      1094.5646
VF Loss                      134.90906
Policy Loss                  -804.40717
Q Predictions Mean           797.3855
Q Predictions Std            308.55374
Q Predictions Max            1202.3383
Q Predictions Min            -64.7208
V Predictions Mean           809.11523
V Predictions Std            303.1355
V Predictions Max            1203.1641
V Predictions Min            -23.424192
Log Pis Mean                 -0.6035924
Log Pis Std                  2.9720848
Log Pis Max                  18.954353
Log Pis Min                  -7.1204033
Policy mu Mean               0.005925363
Policy mu Std                0.5750552
Policy mu Max                6.1570783
Policy mu Min                -4.365731
Policy log std Mean          -0.9483185
Policy log std Std           0.20131749
Policy log std Max           0.71209675
Policy log std Min           -2.1017325
Z mean eval                  1.0954307
Z variance eval              0.016292602
total_rewards                [3011.82883766 3108.19924232 2921.68111231 3057.80960842  892.86443945
 3033.44647568 3035.23453024 3094.09890068 2952.56826644 3362.01451498]
total_rewards_mean           2846.974592818756
total_rewards_std            661.1878957533052
total_rewards_max            3362.0145149795812
total_rewards_min            892.8644394501873
Number of train steps total  524000
Number of env steps total    419373
Number of rollouts total     0
Train Time (s)               178.19883762206882
(Previous) Eval Time (s)     26.900230577215552
Sample Time (s)              6.829580519348383
Epoch Time (s)               211.92864871863276
Total Train Time (s)         27263.43578118412
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:46:04.914004 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #130 | Epoch Duration: 212.01800560951233
2020-01-11 23:46:04.914176 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0956156
Z variance train             0.016241696
KL Divergence                23.246351
KL Loss                      2.3246353
QF Loss                      1016.17285
VF Loss                      179.43343
Policy Loss                  -822.1841
Q Predictions Mean           811.59204
Q Predictions Std            305.9129
Q Predictions Max            1191.0228
Q Predictions Min            244.52277
V Predictions Mean           826.88525
V Predictions Std            302.78082
V Predictions Max            1199.2793
V Predictions Min            244.49286
Log Pis Mean                 -0.45592964
Log Pis Std                  3.2259798
Log Pis Max                  16.432041
Log Pis Min                  -8.11099
Policy mu Mean               0.005987745
Policy mu Std                0.5668842
Policy mu Max                3.1769047
Policy mu Min                -2.7332807
Policy log std Mean          -0.9891096
Policy log std Std           0.22157006
Policy log std Max           -0.45136258
Policy log std Min           -1.9968221
Z mean eval                  1.1833506
Z variance eval              0.04719109
total_rewards                [ 414.77397827  840.78112277  730.9150897  1844.85626643  709.81518482
 3270.74989186  122.38364222 2068.01730544 3300.98061712 3075.46992736]
total_rewards_mean           1637.8743025991002
total_rewards_std            1176.3784953129039
total_rewards_max            3300.980617124164
total_rewards_min            122.38364222043263
Number of train steps total  528000
Number of env steps total    422190
Number of rollouts total     0
Train Time (s)               179.8335616942495
(Previous) Eval Time (s)     16.939396711066365
Sample Time (s)              6.856834278907627
Epoch Time (s)               203.6297926842235
Total Train Time (s)         27467.161123511847
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:49:28.643033 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #131 | Epoch Duration: 203.72871685028076
2020-01-11 23:49:28.643225 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1834681
Z variance train             0.0474205
KL Divergence                21.445839
KL Loss                      2.144584
QF Loss                      487.83307
VF Loss                      136.84767
Policy Loss                  -792.4106
Q Predictions Mean           785.55347
Q Predictions Std            310.79898
Q Predictions Max            1189.6511
Q Predictions Min            -4.0507874
V Predictions Mean           786.2663
V Predictions Std            307.22745
V Predictions Max            1177.3817
V Predictions Min            63.133224
Log Pis Mean                 -0.43178794
Log Pis Std                  3.2579515
Log Pis Max                  23.030998
Log Pis Min                  -8.097929
Policy mu Mean               0.012473858
Policy mu Std                0.56717575
Policy mu Max                4.515112
Policy mu Min                -5.1120353
Policy log std Mean          -0.9624333
Policy log std Std           0.2165225
Policy log std Max           0.3104368
Policy log std Min           -2.4313483
Z mean eval                  1.1511028
Z variance eval              0.020033143
total_rewards                [1948.81338606 3174.19395907  648.15232855 2990.97814434 2859.02540571
 3082.77781149 2015.03741454 1394.74729275 3123.91583435 3128.12487311]
total_rewards_mean           2436.5766449960993
total_rewards_std            842.4744266134595
total_rewards_max            3174.1939590690654
total_rewards_min            648.1523285470769
Number of train steps total  532000
Number of env steps total    426635
Number of rollouts total     0
Train Time (s)               176.83636867674068
(Previous) Eval Time (s)     30.80692010000348
Sample Time (s)              8.068455317988992
Epoch Time (s)               215.71174409473315
Total Train Time (s)         27682.95984506514
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:53:04.443139 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #132 | Epoch Duration: 215.79978370666504
2020-01-11 23:53:04.443268 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1611379
Z variance train             0.02009717
KL Divergence                22.463821
KL Loss                      2.2463822
QF Loss                      756.40576
VF Loss                      139.41586
Policy Loss                  -821.0212
Q Predictions Mean           806.0845
Q Predictions Std            328.41452
Q Predictions Max            1205.2821
Q Predictions Min            7.2501006
V Predictions Mean           820.3806
V Predictions Std            315.99905
V Predictions Max            1197.8596
V Predictions Min            62.360786
Log Pis Mean                 -0.8294176
Log Pis Std                  3.1693146
Log Pis Max                  23.041664
Log Pis Min                  -6.9543805
Policy mu Mean               0.031887215
Policy mu Std                0.5530432
Policy mu Max                2.2334695
Policy mu Min                -2.6926975
Policy log std Mean          -0.9651766
Policy log std Std           0.2105597
Policy log std Max           -0.2204532
Policy log std Min           -1.9992249
Z mean eval                  1.1701913
Z variance eval              0.007124126
total_rewards                [3077.05492905 1581.43319782 3118.01784149 2262.98690961  796.47445769
 3191.90356991 1260.00108589 1169.90189983 3081.24274574 3173.99820825]
total_rewards_mean           2271.301484528488
total_rewards_std            925.8214357783568
total_rewards_max            3191.9035699055153
total_rewards_min            796.4744576905938
Number of train steps total  536000
Number of env steps total    429443
Number of rollouts total     0
Train Time (s)               177.1691637360491
(Previous) Eval Time (s)     29.68848987482488
Sample Time (s)              6.9515915075317025
Epoch Time (s)               213.80924511840567
Total Train Time (s)         27896.85891635809
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:56:38.344715 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #133 | Epoch Duration: 213.90134048461914
2020-01-11 23:56:38.344892 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1717128
Z variance train             0.007138759
KL Divergence                24.768637
KL Loss                      2.4768636
QF Loss                      521.8837
VF Loss                      138.58044
Policy Loss                  -832.1603
Q Predictions Mean           823.6333
Q Predictions Std            311.30377
Q Predictions Max            1217.1644
Q Predictions Min            -63.113575
V Predictions Mean           834.5827
V Predictions Std            301.91327
V Predictions Max            1219.1393
V Predictions Min            285.5156
Log Pis Mean                 -0.37820923
Log Pis Std                  3.2442975
Log Pis Max                  25.853125
Log Pis Min                  -8.948086
Policy mu Mean               0.016177477
Policy mu Std                0.5605665
Policy mu Max                3.9119542
Policy mu Min                -2.91538
Policy log std Mean          -0.9823256
Policy log std Std           0.19916369
Policy log std Max           -0.33029765
Policy log std Min           -2.1094577
Z mean eval                  1.249964
Z variance eval              0.0136660915
total_rewards                [2871.53816467 2115.1866566  2827.82894951 3306.07623483 1677.18140208
 3227.82859774 3128.47617174 1396.90585918 2916.39229195 3321.34507888]
total_rewards_mean           2678.875940719276
total_rewards_std            662.5662824194019
total_rewards_max            3321.345078878395
total_rewards_min            1396.9058591842547
Number of train steps total  540000
Number of env steps total    433698
Number of rollouts total     0
Train Time (s)               177.27745084883645
(Previous) Eval Time (s)     31.715773096308112
Sample Time (s)              5.885879828594625
Epoch Time (s)               214.8791037737392
Total Train Time (s)         28111.8341685012
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:00:13.320524 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #134 | Epoch Duration: 214.975501537323
2020-01-12 00:00:13.320659 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2582824
Z variance train             0.013595492
KL Divergence                23.608791
KL Loss                      2.3608792
QF Loss                      698.77466
VF Loss                      123.5945
Policy Loss                  -859.5316
Q Predictions Mean           853.89075
Q Predictions Std            287.49832
Q Predictions Max            1217.8502
Q Predictions Min            167.66898
V Predictions Mean           860.05145
V Predictions Std            284.30228
V Predictions Max            1221.0074
V Predictions Min            255.1193
Log Pis Mean                 -0.3219029
Log Pis Std                  3.1802683
Log Pis Max                  19.09077
Log Pis Min                  -6.9669614
Policy mu Mean               0.014519796
Policy mu Std                0.57425
Policy mu Max                2.352117
Policy mu Min                -2.8284945
Policy log std Mean          -0.9849808
Policy log std Std           0.20793599
Policy log std Max           -0.34702682
Policy log std Min           -2.2247455
Z mean eval                  1.2531445
Z variance eval              0.035025306
total_rewards                [3135.38656514 2708.95569983 3223.26219623 1375.71219432 1288.04048853
 3196.02775784 2739.76564673  500.91694264  705.30825928   76.23147498]
total_rewards_mean           1894.9607225519023
total_rewards_std            1169.4647499345137
total_rewards_max            3223.262196234528
total_rewards_min            76.23147498028774
Number of train steps total  544000
Number of env steps total    437966
Number of rollouts total     0
Train Time (s)               177.71112012397498
(Previous) Eval Time (s)     27.791458365041763
Sample Time (s)              6.957111186813563
Epoch Time (s)               212.4596896758303
Total Train Time (s)         28324.38195760781
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:03:45.869629 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #135 | Epoch Duration: 212.54887533187866
2020-01-12 00:03:45.869752 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2466909
Z variance train             0.035334487
KL Divergence                22.102413
KL Loss                      2.2102413
QF Loss                      529.25525
VF Loss                      259.17465
Policy Loss                  -824.846
Q Predictions Mean           814.9104
Q Predictions Std            327.3104
Q Predictions Max            1215.762
Q Predictions Min            -33.960247
V Predictions Mean           822.14465
V Predictions Std            317.63953
V Predictions Max            1200.6305
V Predictions Min            -61.684906
Log Pis Mean                 -0.29364872
Log Pis Std                  3.8682537
Log Pis Max                  25.122868
Log Pis Min                  -7.3120074
Policy mu Mean               0.047176525
Policy mu Std                0.6083213
Policy mu Max                3.646052
Policy mu Min                -4.373264
Policy log std Mean          -0.9746891
Policy log std Std           0.2105013
Policy log std Max           -0.37341404
Policy log std Min           -2.0708694
Z mean eval                  1.237201
Z variance eval              0.009803761
total_rewards                [3531.65258466 2583.74530837 2717.26058926 2568.28309911 3128.51372906
 1097.45982442  375.08481859 2830.57094909 2365.59798616 3047.97131161]
total_rewards_mean           2424.614020031518
total_rewards_std            914.9525238827703
total_rewards_max            3531.652584655853
total_rewards_min            375.0848185906439
Number of train steps total  548000
Number of env steps total    441799
Number of rollouts total     0
Train Time (s)               177.15927533898503
(Previous) Eval Time (s)     26.753671226091683
Sample Time (s)              7.409006806090474
Epoch Time (s)               211.32195337116718
Total Train Time (s)         28535.795532607473
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:07:17.285160 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #136 | Epoch Duration: 211.41531538963318
2020-01-12 00:07:17.285305 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2370722
Z variance train             0.009864083
KL Divergence                25.083233
KL Loss                      2.5083234
QF Loss                      621.72516
VF Loss                      188.27785
Policy Loss                  -826.3784
Q Predictions Mean           818.6697
Q Predictions Std            328.39636
Q Predictions Max            1198.766
Q Predictions Min            21.692066
V Predictions Mean           827.89404
V Predictions Std            321.08762
V Predictions Max            1200.5795
V Predictions Min            -21.114746
Log Pis Mean                 -0.28626668
Log Pis Std                  3.2734516
Log Pis Max                  24.92014
Log Pis Min                  -6.46878
Policy mu Mean               0.014934406
Policy mu Std                0.5827007
Policy mu Max                2.9607017
Policy mu Min                -4.028669
Policy log std Mean          -0.96950924
Policy log std Std           0.2085196
Policy log std Max           -0.44084212
Policy log std Min           -2.2324579
Z mean eval                  1.1818879
Z variance eval              0.008240288
total_rewards                [ 683.40365427 2511.5331105  1176.99812087  305.14979544 3333.30140111
 1642.79441131 3401.24120067 3260.67392422 3247.95647068 2809.61440501]
total_rewards_mean           2237.2666494087716
total_rewards_std            1124.8520650487376
total_rewards_max            3401.2412006675877
total_rewards_min            305.14979543917616
Number of train steps total  552000
Number of env steps total    444361
Number of rollouts total     0
Train Time (s)               177.84313727822155
(Previous) Eval Time (s)     23.34757238999009
Sample Time (s)              6.786525568924844
Epoch Time (s)               207.97723523713648
Total Train Time (s)         28743.865767048672
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:10:45.356481 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #137 | Epoch Duration: 208.0710825920105
2020-01-12 00:10:45.356606 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1833708
Z variance train             0.008236332
KL Divergence                25.908354
KL Loss                      2.5908353
QF Loss                      382.07745
VF Loss                      128.09062
Policy Loss                  -832.28503
Q Predictions Mean           824.11066
Q Predictions Std            318.36124
Q Predictions Max            1221.1309
Q Predictions Min            -73.57075
V Predictions Mean           834.18896
V Predictions Std            311.34415
V Predictions Max            1219.0634
V Predictions Min            52.478073
Log Pis Mean                 -0.29182634
Log Pis Std                  2.9693737
Log Pis Max                  11.442467
Log Pis Min                  -6.8079863
Policy mu Mean               0.021098617
Policy mu Std                0.5849288
Policy mu Max                2.679398
Policy mu Min                -4.189296
Policy log std Mean          -0.9717252
Policy log std Std           0.20170042
Policy log std Max           -0.3747459
Policy log std Min           -1.9419415
Z mean eval                  1.1812651
Z variance eval              0.013899255
total_rewards                [ 384.32194843 1024.6768569  1115.77909465 1002.17108324  688.64506527
  772.6693057  3300.6741735  3294.29564669 3207.52182679 1948.93425301]
total_rewards_mean           1673.9689254182067
total_rewards_std            1110.3999701803184
total_rewards_max            3300.6741735035903
total_rewards_min            384.3219484334082
Number of train steps total  556000
Number of env steps total    447649
Number of rollouts total     0
Train Time (s)               177.4592019240372
(Previous) Eval Time (s)     22.41123649897054
Sample Time (s)              6.926088770851493
Epoch Time (s)               206.79652719385922
Total Train Time (s)         28950.749348046724
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:14:12.241581 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #138 | Epoch Duration: 206.88488364219666
2020-01-12 00:14:12.241703 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1848336
Z variance train             0.013920781
KL Divergence                23.372517
KL Loss                      2.3372517
QF Loss                      736.426
VF Loss                      151.68518
Policy Loss                  -856.40906
Q Predictions Mean           844.0254
Q Predictions Std            320.605
Q Predictions Max            1246.8912
Q Predictions Min            31.719631
V Predictions Mean           857.9038
V Predictions Std            307.6026
V Predictions Max            1243.432
V Predictions Min            267.01715
Log Pis Mean                 -0.19346514
Log Pis Std                  3.2307615
Log Pis Max                  17.989632
Log Pis Min                  -7.600218
Policy mu Mean               0.029100258
Policy mu Std                0.5892055
Policy mu Max                3.040325
Policy mu Min                -2.85936
Policy log std Mean          -0.9780737
Policy log std Std           0.2017149
Policy log std Max           -0.39302915
Policy log std Min           -2.0240438
Z mean eval                  1.1889739
Z variance eval              0.0068118027
total_rewards                [2231.25279628  371.95172847 1124.92131231  527.10609538 2721.29628302
 1009.97381428 1222.08590685  397.76538549  490.09682392 1132.07635869]
total_rewards_mean           1122.8526504707497
total_rewards_std            751.7412312151424
total_rewards_max            2721.2962830247043
total_rewards_min            371.9517284717706
Number of train steps total  560000
Number of env steps total    450614
Number of rollouts total     0
Train Time (s)               174.99357599625364
(Previous) Eval Time (s)     14.640875370707363
Sample Time (s)              7.3479531379416585
Epoch Time (s)               196.98240450490266
Total Train Time (s)         29147.817964440677
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:17:29.311767 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #139 | Epoch Duration: 197.069970369339
2020-01-12 00:17:29.311889 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1874788
Z variance train             0.0068379105
KL Divergence                24.78225
KL Loss                      2.478225
QF Loss                      671.10986
VF Loss                      299.53745
Policy Loss                  -890.4122
Q Predictions Mean           882.976
Q Predictions Std            305.18457
Q Predictions Max            1290.147
Q Predictions Min            55.531174
V Predictions Mean           891.99664
V Predictions Std            295.6667
V Predictions Max            1277.3562
V Predictions Min            243.63995
Log Pis Mean                 -0.06966936
Log Pis Std                  3.5050662
Log Pis Max                  16.068094
Log Pis Min                  -8.10021
Policy mu Mean               0.021628316
Policy mu Std                0.61186945
Policy mu Max                3.219275
Policy mu Min                -3.325496
Policy log std Mean          -1.0130842
Policy log std Std           0.22845252
Policy log std Max           -0.4923457
Policy log std Min           -2.4350157
Z mean eval                  1.1925182
Z variance eval              0.037114546
total_rewards                [ 612.66736473 1463.58060941 3287.47104233  733.44320627 1928.97802084
  889.40019338 2592.23256562 3092.79081865 2976.09275446  642.33633357]
total_rewards_mean           1821.899290926486
total_rewards_std            1036.1660922797423
total_rewards_max            3287.4710423275983
total_rewards_min            612.6673647263556
Number of train steps total  564000
Number of env steps total    457100
Number of rollouts total     0
Train Time (s)               179.20040906593204
(Previous) Eval Time (s)     24.567594267893583
Sample Time (s)              9.048384649213403
Epoch Time (s)               212.81638798303902
Total Train Time (s)         29360.809927745722
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:21:02.308296 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #140 | Epoch Duration: 212.99628520011902
2020-01-12 00:21:02.308527 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1882622
Z variance train             0.037207115
KL Divergence                20.551332
KL Loss                      2.0551333
QF Loss                      542.1631
VF Loss                      170.89447
Policy Loss                  -868.4809
Q Predictions Mean           864.2723
Q Predictions Std            327.72137
Q Predictions Max            1273.3733
Q Predictions Min            241.75952
V Predictions Mean           871.6044
V Predictions Std            324.6852
V Predictions Max            1269.0083
V Predictions Min            250.97289
Log Pis Mean                 -0.23821113
Log Pis Std                  3.4436727
Log Pis Max                  19.149525
Log Pis Min                  -7.583073
Policy mu Mean               0.01097952
Policy mu Std                0.5951531
Policy mu Max                3.4872353
Policy mu Min                -3.2102196
Policy log std Mean          -0.9720504
Policy log std Std           0.2170473
Policy log std Max           -0.30929464
Policy log std Min           -1.8729647
Z mean eval                  1.2353947
Z variance eval              0.021913037
total_rewards                [ 501.06556387 2608.01490012 3132.02586219 3380.36228025  322.0774004
 1422.84577408 3129.81586951 1529.98662749 3305.30621012 3356.28642261]
total_rewards_mean           2268.778691062874
total_rewards_std            1151.964156330914
total_rewards_max            3380.3622802489226
total_rewards_min            322.0774003997414
Number of train steps total  568000
Number of env steps total    462761
Number of rollouts total     0
Train Time (s)               175.978071839083
(Previous) Eval Time (s)     22.833216205704957
Sample Time (s)              7.233347313012928
Epoch Time (s)               206.04463535780087
Total Train Time (s)         29566.959911921993
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:24:28.460850 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #141 | Epoch Duration: 206.15214157104492
2020-01-12 00:24:28.461056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2353003
Z variance train             0.022121556
KL Divergence                22.078234
KL Loss                      2.2078235
QF Loss                      457.51276
VF Loss                      94.83738
Policy Loss                  -854.3075
Q Predictions Mean           849.7501
Q Predictions Std            322.5282
Q Predictions Max            1232.5977
Q Predictions Min            261.7774
V Predictions Mean           852.4914
V Predictions Std            319.8331
V Predictions Max            1229.1438
V Predictions Min            275.83264
Log Pis Mean                 -0.64384127
Log Pis Std                  3.1289253
Log Pis Max                  12.128375
Log Pis Min                  -9.240784
Policy mu Mean               0.028653877
Policy mu Std                0.55238396
Policy mu Max                2.2381043
Policy mu Min                -3.319431
Policy log std Mean          -0.9643334
Policy log std Std           0.21113539
Policy log std Max           -0.075497866
Policy log std Min           -2.003331
Z mean eval                  1.1455189
Z variance eval              0.017447103
total_rewards                [3564.80699077 2377.10481845 2854.6236921   773.69605946 3568.84655679
 3413.7525642  2285.62479048 1566.1853731  3304.96631243 3450.51972569]
total_rewards_mean           2716.0126883472285
total_rewards_std            907.4683084041042
total_rewards_max            3568.846556793921
total_rewards_min            773.6960594597336
Number of train steps total  572000
Number of env steps total    468492
Number of rollouts total     0
Train Time (s)               175.8921536579728
(Previous) Eval Time (s)     32.085783309303224
Sample Time (s)              7.158892124891281
Epoch Time (s)               215.13682909216732
Total Train Time (s)         29782.184014522936
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:28:03.690027 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #142 | Epoch Duration: 215.22882986068726
2020-01-12 00:28:03.690153 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1473749
Z variance train             0.017380262
KL Divergence                23.062626
KL Loss                      2.3062627
QF Loss                      679.11316
VF Loss                      192.72165
Policy Loss                  -872.9815
Q Predictions Mean           862.6051
Q Predictions Std            331.7959
Q Predictions Max            1262.422
Q Predictions Min            -20.595772
V Predictions Mean           871.37866
V Predictions Std            326.07803
V Predictions Max            1265.9899
V Predictions Min            -7.2710176
Log Pis Mean                 -0.38482898
Log Pis Std                  3.2309492
Log Pis Max                  16.83564
Log Pis Min                  -8.862889
Policy mu Mean               0.03234017
Policy mu Std                0.58716375
Policy mu Max                2.9516523
Policy mu Min                -3.0595806
Policy log std Mean          -0.99093103
Policy log std Std           0.21524899
Policy log std Max           -0.18705076
Policy log std Min           -2.5621371
Z mean eval                  1.1771703
Z variance eval              0.10391377
total_rewards                [2591.82771447 3272.63605432 1686.5732934  1974.57366878 1817.60810823
 2818.57092276 1240.14273653 3336.58456381 3397.40646468 3220.68711663]
total_rewards_mean           2535.661064361169
total_rewards_std            755.6061136224523
total_rewards_max            3397.4064646815004
total_rewards_min            1240.1427365340535
Number of train steps total  576000
Number of env steps total    471938
Number of rollouts total     0
Train Time (s)               178.2631493518129
(Previous) Eval Time (s)     25.604275529272854
Sample Time (s)              7.080454838927835
Epoch Time (s)               210.9478797200136
Total Train Time (s)         29993.413455393165
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:31:34.921956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #143 | Epoch Duration: 211.2316825389862
2020-01-12 00:31:34.922193 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1745055
Z variance train             0.10327055
KL Divergence                18.057003
KL Loss                      1.8057003
QF Loss                      489.9684
VF Loss                      152.21463
Policy Loss                  -898.8252
Q Predictions Mean           890.52185
Q Predictions Std            346.6803
Q Predictions Max            1319.3518
Q Predictions Min            50.43988
V Predictions Mean           897.7455
V Predictions Std            343.08252
V Predictions Max            1306.3107
V Predictions Min            280.0872
Log Pis Mean                 -0.40800387
Log Pis Std                  3.380197
Log Pis Max                  23.983107
Log Pis Min                  -10.8928795
Policy mu Mean               0.025404876
Policy mu Std                0.5801965
Policy mu Max                4.013478
Policy mu Min                -2.5404048
Policy log std Mean          -0.99147165
Policy log std Std           0.21786521
Policy log std Max           -0.46898943
Policy log std Min           -2.298312
Z mean eval                  1.1250303
Z variance eval              0.011719449
total_rewards                [3101.8615284  1493.09309305 3119.37958053  504.26054184 1334.58127035
 3329.173555   3338.63432322 3411.34771987  974.55620917  467.12011289]
total_rewards_mean           2107.400793431472
total_rewards_std            1193.337156339894
total_rewards_max            3411.347719872333
total_rewards_min            467.1201128890385
Number of train steps total  580000
Number of env steps total    476310
Number of rollouts total     0
Train Time (s)               175.41910964017734
(Previous) Eval Time (s)     27.30117361806333
Sample Time (s)              7.341383485589176
Epoch Time (s)               210.06166674382985
Total Train Time (s)         30203.598328953143
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:35:05.112165 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #144 | Epoch Duration: 210.18976521492004
2020-01-12 00:35:05.112473 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1177187
Z variance train             0.011704983
KL Divergence                24.776127
KL Loss                      2.4776127
QF Loss                      481.76514
VF Loss                      228.11877
Policy Loss                  -835.34283
Q Predictions Mean           831.54895
Q Predictions Std            344.58154
Q Predictions Max            1287.0355
Q Predictions Min            156.40494
V Predictions Mean           844.2615
V Predictions Std            341.57343
V Predictions Max            1300.3678
V Predictions Min            283.5361
Log Pis Mean                 -0.4284857
Log Pis Std                  2.9830568
Log Pis Max                  10.731544
Log Pis Min                  -7.470704
Policy mu Mean               0.05187254
Policy mu Std                0.5570454
Policy mu Max                2.8363428
Policy mu Min                -2.5110538
Policy log std Mean          -0.95453453
Policy log std Std           0.2086195
Policy log std Max           -0.24703652
Policy log std Min           -2.0597868
Z mean eval                  1.2230308
Z variance eval              0.009950707
total_rewards                [1046.19183622 3540.69025087  615.41982509 1261.18368793 3223.83181289
  104.55226698   66.78106997 2567.22963132  413.70470223  276.11276727]
total_rewards_mean           1311.5697850772517
total_rewards_std            1250.788468200285
total_rewards_max            3540.6902508733097
total_rewards_min            66.78106996994529
Number of train steps total  584000
Number of env steps total    481675
Number of rollouts total     0
Train Time (s)               176.94025921821594
(Previous) Eval Time (s)     21.5008142166771
Sample Time (s)              6.840732962358743
Epoch Time (s)               205.28180639725178
Total Train Time (s)         30408.96850898955
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:38:30.481827 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #145 | Epoch Duration: 205.36914324760437
2020-01-12 00:38:30.481951 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2327749
Z variance train             0.009988295
KL Divergence                23.962627
KL Loss                      2.396263
QF Loss                      618.93835
VF Loss                      333.14578
Policy Loss                  -841.99347
Q Predictions Mean           830.24384
Q Predictions Std            344.9678
Q Predictions Max            1267.0217
Q Predictions Min            -11.124538
V Predictions Mean           842.0009
V Predictions Std            334.13492
V Predictions Max            1263.7821
V Predictions Min            217.71486
Log Pis Mean                 0.022680482
Log Pis Std                  3.911914
Log Pis Max                  27.195946
Log Pis Min                  -6.3885183
Policy mu Mean               -0.019191619
Policy mu Std                0.62582874
Policy mu Max                3.3271894
Policy mu Min                -4.0145183
Policy log std Mean          -0.9832089
Policy log std Std           0.2183732
Policy log std Max           -0.4217233
Policy log std Min           -2.0520186
Z mean eval                  1.1660974
Z variance eval              0.00848344
total_rewards                [3115.65703688 2284.64864611 3372.61487622 2875.22415643  274.72536816
 3055.08341211 3073.1474768  3290.15354039 3566.65984929  526.64693898]
total_rewards_mean           2543.456130135971
total_rewards_std            1120.422522827924
total_rewards_max            3566.659849291833
total_rewards_min            274.7253681585617
Number of train steps total  588000
Number of env steps total    487736
Number of rollouts total     0
Train Time (s)               176.10154802165926
(Previous) Eval Time (s)     26.961378308944404
Sample Time (s)              7.658277525100857
Epoch Time (s)               210.72120385570452
Total Train Time (s)         30619.779905821662
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:42:01.294269 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #146 | Epoch Duration: 210.8122274875641
2020-01-12 00:42:01.294393 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #146 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.168611
Z variance train             0.008450619
KL Divergence                24.381489
KL Loss                      2.438149
QF Loss                      650.39014
VF Loss                      236.67615
Policy Loss                  -834.8644
Q Predictions Mean           829.48315
Q Predictions Std            355.92166
Q Predictions Max            1306.3777
Q Predictions Min            138.60257
V Predictions Mean           832.1707
V Predictions Std            350.3847
V Predictions Max            1280.3815
V Predictions Min            221.35892
Log Pis Mean                 -0.39308587
Log Pis Std                  3.3763635
Log Pis Max                  13.312534
Log Pis Min                  -7.1223125
Policy mu Mean               0.03666695
Policy mu Std                0.5806873
Policy mu Max                3.1885207
Policy mu Min                -3.4207237
Policy log std Mean          -0.9719684
Policy log std Std           0.2169205
Policy log std Max           -0.4848187
Policy log std Min           -2.0385275
Z mean eval                  1.0977573
Z variance eval              0.013800886
total_rewards                [ 5.41175395e+02  2.34382362e+03  6.23378532e+02  7.09886371e+02
  3.44880717e+03  3.69061411e+01  3.41026651e+03 -7.22106863e-01
  3.21739782e+03  3.36232473e+03]
total_rewards_mean           1769.3244170918783
total_rewards_std            1433.7453713799177
total_rewards_max            3448.807171009005
total_rewards_min            -0.7221068630697489
Number of train steps total  592000
Number of env steps total    492571
Number of rollouts total     0
Train Time (s)               177.004126007203
(Previous) Eval Time (s)     17.884368750732392
Sample Time (s)              7.2550235339440405
Epoch Time (s)               202.14351829187945
Total Train Time (s)         30822.018685034476
Epoch                        147
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:45:23.538721 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #147 | Epoch Duration: 202.24419474601746
2020-01-12 00:45:23.539006 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0927942
Z variance train             0.013830388
KL Divergence                22.450012
KL Loss                      2.2450013
QF Loss                      611.2158
VF Loss                      173.72887
Policy Loss                  -865.05005
Q Predictions Mean           857.1388
Q Predictions Std            332.66302
Q Predictions Max            1263.8022
Q Predictions Min            6.487285
V Predictions Mean           870.7715
V Predictions Std            327.58545
V Predictions Max            1253.7311
V Predictions Min            233.8773
Log Pis Mean                 -0.26432866
Log Pis Std                  3.7290618
Log Pis Max                  20.83569
Log Pis Min                  -9.804665
Policy mu Mean               0.023876648
Policy mu Std                0.60736483
Policy mu Max                2.6900012
Policy mu Min                -3.1398044
Policy log std Mean          -0.9782666
Policy log std Std           0.21522872
Policy log std Max           -0.42077416
Policy log std Min           -1.9213955
Z mean eval                  1.1270914
Z variance eval              0.0058261952
total_rewards                [ 572.30958244 3217.72701488 3320.60516246  499.47881033 3339.81773366
 1354.45813227 1899.30902414  649.98829493  863.57018603 2552.7716472 ]
total_rewards_mean           1827.0035588341966
total_rewards_std            1133.9743610517871
total_rewards_max            3339.817733658103
total_rewards_min            499.4788103334902
Number of train steps total  596000
Number of env steps total    497065
Number of rollouts total     0
Train Time (s)               175.9495792929083
(Previous) Eval Time (s)     19.263726455159485
Sample Time (s)              7.473054511472583
Epoch Time (s)               202.68636025954038
Total Train Time (s)         31024.803162135184
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:48:46.324048 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #148 | Epoch Duration: 202.7848346233368
2020-01-12 00:48:46.324219 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1218672
Z variance train             0.005809589
KL Divergence                24.802313
KL Loss                      2.4802313
QF Loss                      918.38574
VF Loss                      139.24852
Policy Loss                  -892.1278
Q Predictions Mean           882.37476
Q Predictions Std            333.2269
Q Predictions Max            1272.3508
Q Predictions Min            45.003517
V Predictions Mean           890.7501
V Predictions Std            327.57184
V Predictions Max            1270.719
V Predictions Min            169.15074
Log Pis Mean                 -0.17456436
Log Pis Std                  3.5753596
Log Pis Max                  23.302765
Log Pis Min                  -8.137131
Policy mu Mean               0.03251721
Policy mu Std                0.5925676
Policy mu Max                4.190585
Policy mu Min                -3.2270691
Policy log std Mean          -0.9798593
Policy log std Std           0.2089869
Policy log std Max           -0.2658174
Policy log std Min           -1.9879167
Z mean eval                  1.2538154
Z variance eval              0.026344502
total_rewards                [  66.25582343 2611.48662986 2553.76468729 2862.75807032  989.80814145
 3740.77057497 2286.10691428  689.43395621  590.26660992 3378.61121103]
total_rewards_mean           1976.9262618757155
total_rewards_std            1220.5364677607602
total_rewards_max            3740.7705749655815
total_rewards_min            66.25582343421692
Number of train steps total  600000
Number of env steps total    499932
Number of rollouts total     0
Train Time (s)               177.74985497584566
(Previous) Eval Time (s)     19.580181705299765
Sample Time (s)              7.25075315264985
Epoch Time (s)               204.58078983379528
Total Train Time (s)         31229.504330145195
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:52:11.027051 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #149 | Epoch Duration: 204.70270037651062
2020-01-12 00:52:11.027210 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2542045
Z variance train             0.025429185
KL Divergence                24.452139
KL Loss                      2.445214
QF Loss                      639.69653
VF Loss                      110.10038
Policy Loss                  -882.781
Q Predictions Mean           871.4458
Q Predictions Std            348.03857
Q Predictions Max            1315.4785
Q Predictions Min            -62.459183
V Predictions Mean           878.7799
V Predictions Std            334.1187
V Predictions Max            1283.7634
V Predictions Min            46.806053
Log Pis Mean                 -0.5253404
Log Pis Std                  3.8057396
Log Pis Max                  21.34433
Log Pis Min                  -12.269778
Policy mu Mean               -0.0025126105
Policy mu Std                0.59019953
Policy mu Max                3.7565598
Policy mu Min                -3.3250203
Policy log std Mean          -0.95947963
Policy log std Std           0.21966586
Policy log std Max           -0.37499562
Policy log std Min           -2.1307938
Z mean eval                  1.2676015
Z variance eval              0.14104287
total_rewards                [3286.94432089 3308.76850254 2240.93582474 3595.75560444 2699.57302445
  302.44587934 3510.92763367  233.92672925 3446.84890862 3262.94878023]
total_rewards_mean           2588.907520817751
total_rewards_std            1223.3922888881868
total_rewards_max            3595.7556044376015
total_rewards_min            233.9267292522354
Number of train steps total  604000
Number of env steps total    505673
Number of rollouts total     0
Train Time (s)               176.9939711787738
(Previous) Eval Time (s)     25.55778505699709
Sample Time (s)              6.916154416278005
Epoch Time (s)               209.4679106520489
Total Train Time (s)         31439.08435650356
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:55:40.607936 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #150 | Epoch Duration: 209.5806121826172
2020-01-12 00:55:40.608080 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2786539
Z variance train             0.13618582
KL Divergence                19.490244
KL Loss                      1.9490244
QF Loss                      823.94617
VF Loss                      306.71918
Policy Loss                  -876.4478
Q Predictions Mean           868.22327
Q Predictions Std            327.98193
Q Predictions Max            1276.3381
Q Predictions Min            79.89647
V Predictions Mean           866.618
V Predictions Std            319.03094
V Predictions Max            1252.5055
V Predictions Min            144.0097
Log Pis Mean                 -0.13788837
Log Pis Std                  3.0507712
Log Pis Max                  11.893164
Log Pis Min                  -8.4437895
Policy mu Mean               -0.0015356573
Policy mu Std                0.54895824
Policy mu Max                1.943385
Policy mu Min                -3.9533968
Policy log std Mean          -1.0232934
Policy log std Std           0.22731435
Policy log std Max           -0.12080324
Policy log std Min           -2.0910769
Z mean eval                  1.1321194
Z variance eval              0.044912696
total_rewards                [1071.14521687 3264.09805236  174.29704799 3337.62096615  431.24712927
  787.9760725  3561.49389206  398.07405295  438.69668647 2736.07317446]
total_rewards_mean           1620.0722291085597
total_rewards_std            1343.6359008772642
total_rewards_max            3561.49389206276
total_rewards_min            174.29704799038993
Number of train steps total  608000
Number of env steps total    510297
Number of rollouts total     0
Train Time (s)               176.77614788804203
(Previous) Eval Time (s)     16.133760042954236
Sample Time (s)              7.702563099563122
Epoch Time (s)               200.6124710305594
Total Train Time (s)         31639.78547300957
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:59:01.310520 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #151 | Epoch Duration: 200.70234727859497
2020-01-12 00:59:01.310658 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.123694
Z variance train             0.04503245
KL Divergence                21.497938
KL Loss                      2.1497939
QF Loss                      588.4278
VF Loss                      163.96942
Policy Loss                  -891.80035
Q Predictions Mean           884.2358
Q Predictions Std            337.37732
Q Predictions Max            1283.1567
Q Predictions Min            7.8096094
V Predictions Mean           891.4148
V Predictions Std            328.08447
V Predictions Max            1269.5039
V Predictions Min            270.89206
Log Pis Mean                 -0.35138977
Log Pis Std                  3.65933
Log Pis Max                  24.847672
Log Pis Min                  -7.7838383
Policy mu Mean               0.01782398
Policy mu Std                0.5884798
Policy mu Max                3.464994
Policy mu Min                -3.3074434
Policy log std Mean          -0.9856113
Policy log std Std           0.21927856
Policy log std Max           -0.49024802
Policy log std Min           -2.2254245
Z mean eval                  1.1221159
Z variance eval              0.025464002
total_rewards                [ 842.70702268  503.79392626 1084.38750459  227.74150723 1120.70748146
 1221.67262781  789.81114044  103.68489504 2466.25285372 3257.68549188]
total_rewards_mean           1161.8444451101902
total_rewards_std            936.5276354788504
total_rewards_max            3257.68549188443
total_rewards_min            103.68489504464651
Number of train steps total  612000
Number of env steps total    515433
Number of rollouts total     0
Train Time (s)               176.71354894107208
(Previous) Eval Time (s)     15.173242898192257
Sample Time (s)              6.680220031179488
Epoch Time (s)               198.56701187044382
Total Train Time (s)         31838.44756631786
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:02:19.975702 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #152 | Epoch Duration: 198.66493487358093
2020-01-12 01:02:19.975897 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1173794
Z variance train             0.025347153
KL Divergence                24.151924
KL Loss                      2.4151924
QF Loss                      971.54443
VF Loss                      134.44601
Policy Loss                  -845.2832
Q Predictions Mean           839.4736
Q Predictions Std            372.54742
Q Predictions Max            1313.788
Q Predictions Min            46.52048
V Predictions Mean           845.55316
V Predictions Std            368.37543
V Predictions Max            1305.456
V Predictions Min            221.76996
Log Pis Mean                 -0.47190687
Log Pis Std                  3.1644344
Log Pis Max                  13.443732
Log Pis Min                  -7.85682
Policy mu Mean               -0.014264846
Policy mu Std                0.55816823
Policy mu Max                2.5524542
Policy mu Min                -3.9826074
Policy log std Mean          -0.9703367
Policy log std Std           0.2252695
Policy log std Max           -0.45980594
Policy log std Min           -2.3799624
Z mean eval                  1.1876339
Z variance eval              0.17323412
total_rewards                [3467.13316004   32.58795563  510.26395347 1879.83295881 3729.23324055
 1944.57992191  401.64496018  898.22168443  325.14379285 3462.61896998]
total_rewards_mean           1665.1260597859455
total_rewards_std            1372.6583242234233
total_rewards_max            3729.2332405506418
total_rewards_min            32.587955632297415
Number of train steps total  616000
Number of env steps total    521813
Number of rollouts total     0
Train Time (s)               177.11111492896453
(Previous) Eval Time (s)     18.815657565835863
Sample Time (s)              7.594373743515462
Epoch Time (s)               203.52114623831585
Total Train Time (s)         32042.06621518545
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:05:43.597529 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #153 | Epoch Duration: 203.62148714065552
2020-01-12 01:05:43.597656 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #153 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1860139
Z variance train             0.17320694
KL Divergence                21.889404
KL Loss                      2.1889405
QF Loss                      3328.0044
VF Loss                      986.1887
Policy Loss                  -704.0149
Q Predictions Mean           695.1029
Q Predictions Std            305.6391
Q Predictions Max            1111.2539
Q Predictions Min            -246.661
V Predictions Mean           716.8572
V Predictions Std            292.59302
V Predictions Max            1100.2343
V Predictions Min            -73.17321
Log Pis Mean                 0.57658803
Log Pis Std                  3.8631241
Log Pis Max                  20.7793
Log Pis Min                  -7.791691
Policy mu Mean               0.004341395
Policy mu Std                0.6635443
Policy mu Max                3.5479503
Policy mu Min                -3.209798
Policy log std Mean          -1.0473194
Policy log std Std           0.23518224
Policy log std Max           -0.24815261
Policy log std Min           -1.9516833
Z mean eval                  1.164041
Z variance eval              0.019179177
total_rewards                [2422.88436169 3458.14792343 2581.75081984 3635.74136579  918.780008
 3583.22737465 2865.07235357 3333.59127111 3717.21287002 2136.08961515]
total_rewards_mean           2865.2497963245123
total_rewards_std            836.7998656932156
total_rewards_max            3717.212870016745
total_rewards_min            918.7800079996834
Number of train steps total  620000
Number of env steps total    527727
Number of rollouts total     0
Train Time (s)               177.69145476818085
(Previous) Eval Time (s)     29.367425296921283
Sample Time (s)              7.655392742250115
Epoch Time (s)               214.71427280735224
Total Train Time (s)         32256.881923876237
Epoch                        154
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:09:18.414966 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #154 | Epoch Duration: 214.81722021102905
2020-01-12 01:09:18.415091 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1593617
Z variance train             0.01923683
KL Divergence                22.123474
KL Loss                      2.2123475
QF Loss                      814.50977
VF Loss                      242.59122
Policy Loss                  -839.5776
Q Predictions Mean           832.4549
Q Predictions Std            363.00916
Q Predictions Max            1290.4269
Q Predictions Min            204.67319
V Predictions Mean           834.69495
V Predictions Std            359.69965
V Predictions Max            1285.0187
V Predictions Min            281.13477
Log Pis Mean                 -0.48308215
Log Pis Std                  3.3285048
Log Pis Max                  14.491904
Log Pis Min                  -9.895229
Policy mu Mean               0.050897136
Policy mu Std                0.5536924
Policy mu Max                3.5527294
Policy mu Min                -2.6244538
Policy log std Mean          -0.97594094
Policy log std Std           0.2178257
Policy log std Max           -0.42577654
Policy log std Min           -1.954066
Z mean eval                  1.2005205
Z variance eval              0.048632514
total_rewards                [ 241.0033662  3611.19605251 1339.9300664  2177.82094394 3501.53931186
 3692.4215792  3035.16037794 2589.49160226  399.12380524 3577.799194  ]
total_rewards_mean           2416.548629956038
total_rewards_std            1265.402316381586
total_rewards_max            3692.4215791995443
total_rewards_min            241.00336620070524
Number of train steps total  624000
Number of env steps total    533411
Number of rollouts total     0
Train Time (s)               176.00941774016246
(Previous) Eval Time (s)     26.82709420705214
Sample Time (s)              6.9834724687971175
Epoch Time (s)               209.81998441601172
Total Train Time (s)         32466.789136926178
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:12:48.323551 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #155 | Epoch Duration: 209.90836930274963
2020-01-12 01:12:48.323673 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1983882
Z variance train             0.048836168
KL Divergence                21.440275
KL Loss                      2.1440275
QF Loss                      1040.5366
VF Loss                      116.330086
Policy Loss                  -909.9808
Q Predictions Mean           902.7523
Q Predictions Std            332.96353
Q Predictions Max            1318.5138
Q Predictions Min            83.58582
V Predictions Mean           906.60376
V Predictions Std            330.72513
V Predictions Max            1328.9325
V Predictions Min            70.14616
Log Pis Mean                 -0.030555144
Log Pis Std                  3.0713952
Log Pis Max                  16.685402
Log Pis Min                  -5.713971
Policy mu Mean               0.0025250688
Policy mu Std                0.5840779
Policy mu Max                1.8756083
Policy mu Min                -3.241064
Policy log std Mean          -1.0037225
Policy log std Std           0.2434295
Policy log std Max           -0.43631232
Policy log std Min           -2.3291059
Z mean eval                  1.175484
Z variance eval              0.0068756454
total_rewards                [1586.71215636 1134.47934683  482.99945231 2004.57179802 1644.53962165
 3135.44630651 2621.81743589 3337.33999171  839.52701413 1380.64039053]
total_rewards_mean           1816.8073513936404
total_rewards_std            905.9071911660511
total_rewards_max            3337.339991706229
total_rewards_min            482.99945231017807
Number of train steps total  628000
Number of env steps total    538397
Number of rollouts total     0
Train Time (s)               178.22675203485414
(Previous) Eval Time (s)     21.53359631029889
Sample Time (s)              7.365617896430194
Epoch Time (s)               207.12596624158323
Total Train Time (s)         32674.002798472997
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:16:15.538582 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #156 | Epoch Duration: 207.21481823921204
2020-01-12 01:16:15.538705 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1785489
Z variance train             0.0068623284
KL Divergence                25.378555
KL Loss                      2.5378556
QF Loss                      734.1378
VF Loss                      232.36261
Policy Loss                  -900.63116
Q Predictions Mean           900.58527
Q Predictions Std            331.62546
Q Predictions Max            1289.5708
Q Predictions Min            253.91435
V Predictions Mean           903.7551
V Predictions Std            327.7801
V Predictions Max            1291.2756
V Predictions Min            276.85052
Log Pis Mean                 -0.50196993
Log Pis Std                  2.6745734
Log Pis Max                  8.172687
Log Pis Min                  -7.1142006
Policy mu Mean               0.00021477928
Policy mu Std                0.5664752
Policy mu Max                2.510157
Policy mu Min                -2.548981
Policy log std Mean          -0.98270464
Policy log std Std           0.22198658
Policy log std Max           -0.456636
Policy log std Min           -2.0434532
Z mean eval                  1.1518195
Z variance eval              0.048428345
total_rewards                [3479.90131606  834.58384522  186.72756832 3639.56352458  100.96123624
  142.40951873 2429.40139306  677.9743198   379.52765628 3260.91596703]
total_rewards_mean           1513.1966345312896
total_rewards_std            1426.871430295481
total_rewards_max            3639.563524582844
total_rewards_min            100.96123623895434
Number of train steps total  632000
Number of env steps total    544668
Number of rollouts total     0
Train Time (s)               181.58916425099596
(Previous) Eval Time (s)     18.34869006415829
Sample Time (s)              7.769125518389046
Epoch Time (s)               207.7069798335433
Total Train Time (s)         32881.80365074845
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:19:43.340848 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #157 | Epoch Duration: 207.80204939842224
2020-01-12 01:19:43.340971 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1504076
Z variance train             0.048450984
KL Divergence                22.267508
KL Loss                      2.2267509
QF Loss                      1061.7777
VF Loss                      141.69653
Policy Loss                  -887.5386
Q Predictions Mean           882.39685
Q Predictions Std            352.64056
Q Predictions Max            1339.7446
Q Predictions Min            262.82428
V Predictions Mean           887.6903
V Predictions Std            349.26813
V Predictions Max            1334.9432
V Predictions Min            275.23938
Log Pis Mean                 -0.43014795
Log Pis Std                  3.0935757
Log Pis Max                  11.44217
Log Pis Min                  -7.2832217
Policy mu Mean               0.004063593
Policy mu Std                0.5540493
Policy mu Max                2.231289
Policy mu Min                -3.3205342
Policy log std Mean          -1.0032479
Policy log std Std           0.22559236
Policy log std Max           -0.43426013
Policy log std Min           -2.1562836
Z mean eval                  1.0988227
Z variance eval              0.012855599
total_rewards                [ 435.67397986 2680.44552916 2568.18945355  504.33893093 3433.53669299
  671.97263995 2730.36424711 1035.29696216 3653.25908456 3686.04398333]
total_rewards_mean           2139.9121503603174
total_rewards_std            1270.1569636930597
total_rewards_max            3686.0439833335267
total_rewards_min            435.67397986199876
Number of train steps total  636000
Number of env steps total    548368
Number of rollouts total     0
Train Time (s)               176.33930158335716
(Previous) Eval Time (s)     19.169369728770107
Sample Time (s)              8.135679010301828
Epoch Time (s)               203.6443503224291
Total Train Time (s)         33085.542448794
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:23:07.084707 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #158 | Epoch Duration: 203.74360537528992
2020-01-12 01:23:07.084978 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0999935
Z variance train             0.012826768
KL Divergence                25.589012
KL Loss                      2.5589013
QF Loss                      1024.047
VF Loss                      142.69205
Policy Loss                  -816.8456
Q Predictions Mean           811.5559
Q Predictions Std            376.9045
Q Predictions Max            1340.3251
Q Predictions Min            -30.788301
V Predictions Mean           816.3196
V Predictions Std            374.35986
V Predictions Max            1333.0504
V Predictions Min            -34.45807
Log Pis Mean                 -0.55301905
Log Pis Std                  3.8479483
Log Pis Max                  30.855114
Log Pis Min                  -6.823844
Policy mu Mean               0.0008912083
Policy mu Std                0.57117057
Policy mu Max                3.479762
Policy mu Min                -4.711364
Policy log std Mean          -0.96965396
Policy log std Std           0.23103383
Policy log std Max           -0.27404243
Policy log std Min           -2.1803787
Z mean eval                  1.2325575
Z variance eval              0.018570883
total_rewards                [3496.46517035  230.75493295 3769.61221543 2742.74065604 2646.05521617
 3639.64356695   54.35511626  919.86462539 3499.47602622 1124.72798345]
total_rewards_mean           2212.369550920971
total_rewards_std            1402.6543834172967
total_rewards_max            3769.612215429756
total_rewards_min            54.355116258392705
Number of train steps total  640000
Number of env steps total    552671
Number of rollouts total     0
Train Time (s)               176.95803102990612
(Previous) Eval Time (s)     24.334795537870377
Sample Time (s)              7.0103471227921546
Epoch Time (s)               208.30317369056866
Total Train Time (s)         33293.93660204951
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:26:35.479125 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #159 | Epoch Duration: 208.39396476745605
2020-01-12 01:26:35.479253 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2290443
Z variance train             0.018476065
KL Divergence                22.367462
KL Loss                      2.2367463
QF Loss                      719.86304
VF Loss                      201.0431
Policy Loss                  -892.4491
Q Predictions Mean           884.9099
Q Predictions Std            355.84225
Q Predictions Max            1337.287
Q Predictions Min            -69.07483
V Predictions Mean           898.2063
V Predictions Std            349.919
V Predictions Max            1331.0581
V Predictions Min            -15.220956
Log Pis Mean                 -0.22671863
Log Pis Std                  3.4418309
Log Pis Max                  23.28435
Log Pis Min                  -7.641236
Policy mu Mean               0.009878824
Policy mu Std                0.57955503
Policy mu Max                2.8098984
Policy mu Min                -3.5748546
Policy log std Mean          -1.0147443
Policy log std Std           0.23243496
Policy log std Max           -0.37922704
Policy log std Min           -2.5613472
Z mean eval                  1.0996085
Z variance eval              0.010734865
total_rewards                [ 733.86025942 3497.14269528 3533.15863083 1936.21552607 2417.25501558
 3313.75715001 3638.06868056 3701.79575214 3303.54957033 3790.14542605]
total_rewards_mean           2986.494870628241
total_rewards_std            940.7852120204551
total_rewards_max            3790.145426046611
total_rewards_min            733.8602594170463
Number of train steps total  644000
Number of env steps total    557601
Number of rollouts total     0
Train Time (s)               177.83108406234533
(Previous) Eval Time (s)     29.01923532318324
Sample Time (s)              14.724535159301013
Epoch Time (s)               221.57485454482958
Total Train Time (s)         33515.59891636623
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:30:17.142665 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #160 | Epoch Duration: 221.66332173347473
2020-01-12 01:30:17.142788 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1025083
Z variance train             0.010731841
KL Divergence                23.046576
KL Loss                      2.3046577
QF Loss                      683.92847
VF Loss                      149.05487
Policy Loss                  -881.2792
Q Predictions Mean           874.1985
Q Predictions Std            350.4258
Q Predictions Max            1304.6085
Q Predictions Min            214.46645
V Predictions Mean           881.66455
V Predictions Std            348.8255
V Predictions Max            1308.1533
V Predictions Min            227.05095
Log Pis Mean                 -0.35690317
Log Pis Std                  3.201184
Log Pis Max                  14.257017
Log Pis Min                  -7.385503
Policy mu Mean               0.07044194
Policy mu Std                0.5590504
Policy mu Max                2.6022112
Policy mu Min                -2.494753
Policy log std Mean          -0.99439967
Policy log std Std           0.23348533
Policy log std Max           -0.39987695
Policy log std Min           -2.1014585
Z mean eval                  1.1486863
Z variance eval              0.03401121
total_rewards                [3345.39074373 3576.77787923  800.4373004  3577.08251823  473.55562547
 3836.08380888 2008.98896839 3302.21452723 3427.98446417   30.32072775]
total_rewards_mean           2437.8836563474383
total_rewards_std            1400.7454955144344
total_rewards_max            3836.083808881591
total_rewards_min            30.32072774695646
Number of train steps total  648000
Number of env steps total    563540
Number of rollouts total     0
Train Time (s)               177.12473112065345
(Previous) Eval Time (s)     24.774680878967047
Sample Time (s)              6.979678693693131
Epoch Time (s)               208.87909069331363
Total Train Time (s)         33724.74935794948
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:33:46.297877 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #161 | Epoch Duration: 209.15497946739197
2020-01-12 01:33:46.298040 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1403439
Z variance train             0.033871997
KL Divergence                22.454815
KL Loss                      2.2454815
QF Loss                      571.92725
VF Loss                      189.31912
Policy Loss                  -874.6489
Q Predictions Mean           869.38367
Q Predictions Std            374.40356
Q Predictions Max            1371.6885
Q Predictions Min            12.638448
V Predictions Mean           869.42224
V Predictions Std            369.66238
V Predictions Max            1353.6967
V Predictions Min            -61.02011
Log Pis Mean                 -0.19027565
Log Pis Std                  3.6032784
Log Pis Max                  23.820305
Log Pis Min                  -9.052561
Policy mu Mean               0.039119188
Policy mu Std                0.5939603
Policy mu Max                4.458904
Policy mu Min                -3.255788
Policy log std Mean          -0.9791597
Policy log std Std           0.21405756
Policy log std Max           -0.2771765
Policy log std Min           -1.9100835
Z mean eval                  1.1579875
Z variance eval              0.02638565
total_rewards                [3663.79488203 3768.91023881 3806.99548478 3696.9418356  3562.72559486
 1221.48988012  364.26371619 1881.38550688 1718.730047   1967.1308293 ]
total_rewards_mean           2565.2368015571456
total_rewards_std            1211.00205400595
total_rewards_max            3806.9954847847666
total_rewards_min            364.2637161922762
Number of train steps total  652000
Number of env steps total    570543
Number of rollouts total     0
Train Time (s)               175.66204665321857
(Previous) Eval Time (s)     27.136749820783734
Sample Time (s)              7.4934530085884035
Epoch Time (s)               210.2922494825907
Total Train Time (s)         33935.13646802213
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:37:16.690772 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #162 | Epoch Duration: 210.39249682426453
2020-01-12 01:37:16.691203 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1541872
Z variance train             0.026369315
KL Divergence                21.333462
KL Loss                      2.1333463
QF Loss                      902.2572
VF Loss                      108.39244
Policy Loss                  -827.85834
Q Predictions Mean           813.7635
Q Predictions Std            368.88498
Q Predictions Max            1300.9546
Q Predictions Min            -44.86214
V Predictions Mean           829.73737
V Predictions Std            363.02133
V Predictions Max            1295.9806
V Predictions Min            17.285198
Log Pis Mean                 -0.56227285
Log Pis Std                  3.3009012
Log Pis Max                  17.403246
Log Pis Min                  -10.066312
Policy mu Mean               0.018569743
Policy mu Std                0.5616397
Policy mu Max                2.9446764
Policy mu Min                -4.056368
Policy log std Mean          -0.9822923
Policy log std Std           0.2433936
Policy log std Max           -0.35316086
Policy log std Min           -2.6616862
Z mean eval                  1.1075852
Z variance eval              0.011892239
total_rewards                [3431.68626025 3647.92585619 3564.37471152 3442.03342447 3558.46694654
 3465.90466821 3514.55188018 3548.71272517 3516.76504675 3577.35844202]
total_rewards_mean           3526.777996130671
total_rewards_std            63.492834402996046
total_rewards_max            3647.925856193196
total_rewards_min            3431.6862602471233
Number of train steps total  656000
Number of env steps total    577051
Number of rollouts total     0
Train Time (s)               177.1517041712068
(Previous) Eval Time (s)     33.63997592078522
Sample Time (s)              7.182276221457869
Epoch Time (s)               217.9739563134499
Total Train Time (s)         34153.469661490526
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:40:55.034336 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #163 | Epoch Duration: 218.3428919315338
2020-01-12 01:40:55.034475 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1050537
Z variance train             0.011867816
KL Divergence                22.39986
KL Loss                      2.2399862
QF Loss                      814.1072
VF Loss                      180.58426
Policy Loss                  -903.3839
Q Predictions Mean           897.40356
Q Predictions Std            373.47183
Q Predictions Max            1334.7197
Q Predictions Min            65.20954
V Predictions Mean           906.65894
V Predictions Std            365.53052
V Predictions Max            1324.0278
V Predictions Min            180.32564
Log Pis Mean                 -0.22740996
Log Pis Std                  3.2188716
Log Pis Max                  13.377317
Log Pis Min                  -8.5603895
Policy mu Mean               0.041881006
Policy mu Std                0.5688009
Policy mu Max                2.9957664
Policy mu Min                -2.9851243
Policy log std Mean          -0.9960214
Policy log std Std           0.23174737
Policy log std Max           -0.48654965
Policy log std Min           -2.1465807
Z mean eval                  1.2192394
Z variance eval              0.022010382
total_rewards                [1741.24659097 3426.817908   1112.18091404 2778.61359579  953.07057039
  680.28760187 2946.35781006 1336.53873304  331.37317373  343.69320709]
total_rewards_mean           1565.0180104985375
total_rewards_std            1063.309686669637
total_rewards_max            3426.81790800206
total_rewards_min            331.37317373030135
Number of train steps total  660000
Number of env steps total    584074
Number of rollouts total     0
Train Time (s)               176.9312271741219
(Previous) Eval Time (s)     16.00239465199411
Sample Time (s)              7.31129248579964
Epoch Time (s)               200.24491431191564
Total Train Time (s)         34353.8010600945
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:44:15.368619 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #164 | Epoch Duration: 200.33399176597595
2020-01-12 01:44:15.368848 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2205589
Z variance train             0.021879362
KL Divergence                21.48179
KL Loss                      2.148179
QF Loss                      543.0994
VF Loss                      144.54292
Policy Loss                  -934.05634
Q Predictions Mean           928.0479
Q Predictions Std            351.37357
Q Predictions Max            1343.677
Q Predictions Min            -14.427667
V Predictions Mean           934.1738
V Predictions Std            348.7603
V Predictions Max            1344.5188
V Predictions Min            142.7802
Log Pis Mean                 -0.062233355
Log Pis Std                  2.7988875
Log Pis Max                  12.184554
Log Pis Min                  -7.313629
Policy mu Mean               0.04143335
Policy mu Std                0.5804746
Policy mu Max                2.131385
Policy mu Min                -3.6491075
Policy log std Mean          -0.9973446
Policy log std Std           0.20675576
Policy log std Max           -0.40672278
Policy log std Min           -1.9525557
Z mean eval                  1.2799344
Z variance eval              0.049145255
total_rewards                [ 768.99525203 3834.51306089  207.03362794 3828.73002915 2147.25175936
 1018.57809839 3141.26935905 3539.99483581 2855.69941885 2643.83928787]
total_rewards_mean           2398.590472933298
total_rewards_std            1251.2694169380975
total_rewards_max            3834.513060889336
total_rewards_min            207.03362794381707
Number of train steps total  664000
Number of env steps total    589918
Number of rollouts total     0
Train Time (s)               176.0406689979136
(Previous) Eval Time (s)     21.744503845926374
Sample Time (s)              7.418747736606747
Epoch Time (s)               205.20392058044672
Total Train Time (s)         34559.09325894946
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:47:40.662529 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #165 | Epoch Duration: 205.29355669021606
2020-01-12 01:47:40.662657 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2927816
Z variance train             0.050757784
KL Divergence                19.913607
KL Loss                      1.9913607
QF Loss                      660.36127
VF Loss                      352.45245
Policy Loss                  -847.74255
Q Predictions Mean           843.06665
Q Predictions Std            370.7847
Q Predictions Max            1317.3278
Q Predictions Min            -31.154482
V Predictions Mean           852.2224
V Predictions Std            366.18076
V Predictions Max            1315.1313
V Predictions Min            -1.2178105
Log Pis Mean                 -0.24236293
Log Pis Std                  3.1817942
Log Pis Max                  16.942596
Log Pis Min                  -6.665079
Policy mu Mean               0.017889582
Policy mu Std                0.57134664
Policy mu Max                2.3899195
Policy mu Min                -3.3874881
Policy log std Mean          -0.9928302
Policy log std Std           0.23806898
Policy log std Max           -0.36823463
Policy log std Min           -2.0184608
Z mean eval                  1.1160326
Z variance eval              0.012782173
total_rewards                [3670.32989088 3673.70793362 3669.2872088  3720.44916473 3625.33803858
  420.36520127 3910.43772623 3636.79752149 1130.83398365 3860.64418258]
total_rewards_mean           3131.819085182711
total_rewards_std            1192.0954448697523
total_rewards_max            3910.4377262338903
total_rewards_min            420.36520126856055
Number of train steps total  668000
Number of env steps total    595083
Number of rollouts total     0
Train Time (s)               175.98060811078176
(Previous) Eval Time (s)     31.779312298167497
Sample Time (s)              7.083506639581174
Epoch Time (s)               214.84342704853043
Total Train Time (s)         34774.02421172988
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:51:15.595987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #166 | Epoch Duration: 214.93321323394775
2020-01-12 01:51:15.596162 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1116054
Z variance train             0.01281257
KL Divergence                22.152958
KL Loss                      2.2152958
QF Loss                      2258.0537
VF Loss                      497.3327
Policy Loss                  -930.96655
Q Predictions Mean           918.84033
Q Predictions Std            365.4812
Q Predictions Max            1359.0463
Q Predictions Min            15.812634
V Predictions Mean           939.86676
V Predictions Std            358.3646
V Predictions Max            1353.3853
V Predictions Min            280.11542
Log Pis Mean                 -0.16604197
Log Pis Std                  3.7601256
Log Pis Max                  31.883175
Log Pis Min                  -8.418712
Policy mu Mean               0.046361133
Policy mu Std                0.595609
Policy mu Max                3.5176954
Policy mu Min                -2.1403942
Policy log std Mean          -1.0009336
Policy log std Std           0.23323159
Policy log std Max           -0.41483146
Policy log std Min           -1.904189
Z mean eval                  1.1094614
Z variance eval              0.013320832
total_rewards                [3538.73058239 3906.27152482 1299.18269805 2459.13785375 1857.95497107
 4006.23560673 1560.32661839  371.65843255 4031.28276135 2256.21446882]
total_rewards_mean           2528.699551790851
total_rewards_std            1224.3367912322094
total_rewards_max            4031.282761353935
total_rewards_min            371.65843255154823
Number of train steps total  672000
Number of env steps total    603306
Number of rollouts total     0
Train Time (s)               176.65633792523295
(Previous) Eval Time (s)     22.327745490241796
Sample Time (s)              7.3061287282034755
Epoch Time (s)               206.29021214367822
Total Train Time (s)         34980.404794876
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:54:41.980684 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #167 | Epoch Duration: 206.3843252658844
2020-01-12 01:54:41.980989 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1062644
Z variance train             0.013364764
KL Divergence                22.531557
KL Loss                      2.2531557
QF Loss                      1105.8438
VF Loss                      181.79285
Policy Loss                  -911.79895
Q Predictions Mean           903.7875
Q Predictions Std            362.10492
Q Predictions Max            1338.8756
Q Predictions Min            161.20601
V Predictions Mean           911.0144
V Predictions Std            358.59808
V Predictions Max            1313.0505
V Predictions Min            268.64713
Log Pis Mean                 -0.6608778
Log Pis Std                  2.889624
Log Pis Max                  10.853202
Log Pis Min                  -8.063459
Policy mu Mean               0.046876326
Policy mu Std                0.5500434
Policy mu Max                2.1382408
Policy mu Min                -2.6948345
Policy log std Mean          -0.9928598
Policy log std Std           0.21787232
Policy log std Max           -0.43104488
Policy log std Min           -1.9678757
Z mean eval                  1.1085222
Z variance eval              0.014027523
total_rewards                [ 703.57432005 4035.32065928   81.88512509 3745.60502822 3801.52962958
 3438.30682467 1660.98936544 3214.69074662 2180.77041549 3194.56789299]
total_rewards_mean           2605.7240007433984
total_rewards_std            1313.1962309333558
total_rewards_max            4035.3206592802794
total_rewards_min            81.88512509230452
Number of train steps total  676000
Number of env steps total    608245
Number of rollouts total     0
Train Time (s)               178.0238703750074
(Previous) Eval Time (s)     26.805941806174815
Sample Time (s)              7.177041000686586
Epoch Time (s)               212.0068531818688
Total Train Time (s)         35192.50087262783
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:58:14.077560 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #168 | Epoch Duration: 212.09637475013733
2020-01-12 01:58:14.077701 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1038886
Z variance train             0.01404766
KL Divergence                21.519167
KL Loss                      2.1519167
QF Loss                      946.1135
VF Loss                      76.327446
Policy Loss                  -903.381
Q Predictions Mean           894.1747
Q Predictions Std            364.38382
Q Predictions Max            1331.3768
Q Predictions Min            -16.66983
V Predictions Mean           903.1116
V Predictions Std            358.04556
V Predictions Max            1316.1708
V Predictions Min            14.524913
Log Pis Mean                 -0.3626566
Log Pis Std                  3.2855444
Log Pis Max                  16.234188
Log Pis Min                  -7.114147
Policy mu Mean               0.041936457
Policy mu Std                0.58623
Policy mu Max                2.6549776
Policy mu Min                -3.2392278
Policy log std Mean          -0.984732
Policy log std Std           0.23493434
Policy log std Max           -0.4154821
Policy log std Min           -2.082373
Z mean eval                  1.1202896
Z variance eval              0.009401472
total_rewards                [3828.86584171 3767.34175986  507.10245466 2975.76415806 1854.23113714
 1395.40919401  785.25737536 4172.36960729 2072.53098968 1791.33601558]
total_rewards_mean           2315.020853334911
total_rewards_std            1236.4098801587481
total_rewards_max            4172.369607294863
total_rewards_min            507.1024546612249
Number of train steps total  680000
Number of env steps total    616448
Number of rollouts total     0
Train Time (s)               178.9765185811557
(Previous) Eval Time (s)     22.15882653929293
Sample Time (s)              7.971619222313166
Epoch Time (s)               209.10696434276178
Total Train Time (s)         35401.702842523344
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:01:43.282310 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #169 | Epoch Duration: 209.20449423789978
2020-01-12 02:01:43.282483 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1207293
Z variance train             0.00944466
KL Divergence                23.785847
KL Loss                      2.3785846
QF Loss                      946.0197
VF Loss                      126.89458
Policy Loss                  -916.02515
Q Predictions Mean           910.25024
Q Predictions Std            369.4946
Q Predictions Max            1376.244
Q Predictions Min            31.334515
V Predictions Mean           917.63916
V Predictions Std            366.36786
V Predictions Max            1372.4567
V Predictions Min            119.53312
Log Pis Mean                 -0.6440097
Log Pis Std                  3.0124605
Log Pis Max                  12.372391
Log Pis Min                  -6.761744
Policy mu Mean               0.012657552
Policy mu Std                0.54354405
Policy mu Max                2.4021523
Policy mu Min                -2.393299
Policy log std Mean          -0.988961
Policy log std Std           0.2444101
Policy log std Max           -0.40293634
Policy log std Min           -2.676107
Z mean eval                  1.1735557
Z variance eval              0.0048159356
total_rewards                [3928.3462573  1125.82268899 3761.46724846    8.41545231 4025.59725263
 3846.79615064 3385.49503707 3605.57009166 3892.75362854 3549.22079901]
total_rewards_mean           3112.9484606615283
total_rewards_std            1309.9271669644847
total_rewards_max            4025.59725263109
total_rewards_min            8.415452311099253
Number of train steps total  684000
Number of env steps total    623376
Number of rollouts total     0
Train Time (s)               176.91405703499913
(Previous) Eval Time (s)     30.311716821044683
Sample Time (s)              7.289375579915941
Epoch Time (s)               214.51514943595976
Total Train Time (s)         35616.30486842152
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:05:17.885378 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #170 | Epoch Duration: 214.60276460647583
2020-01-12 02:05:17.885516 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1706868
Z variance train             0.004824524
KL Divergence                24.381208
KL Loss                      2.4381208
QF Loss                      736.9925
VF Loss                      354.43283
Policy Loss                  -874.9055
Q Predictions Mean           867.1734
Q Predictions Std            392.34045
Q Predictions Max            1370.3403
Q Predictions Min            3.7269807
V Predictions Mean           878.26025
V Predictions Std            382.84512
V Predictions Max            1368.8923
V Predictions Min            76.06292
Log Pis Mean                 -0.38311547
Log Pis Std                  3.173913
Log Pis Max                  15.823215
Log Pis Min                  -9.054661
Policy mu Mean               0.024755789
Policy mu Std                0.571765
Policy mu Max                3.9936767
Policy mu Min                -2.5677438
Policy log std Mean          -0.9945142
Policy log std Std           0.22883977
Policy log std Max           -0.1655367
Policy log std Min           -2.0630379
Z mean eval                  1.0934044
Z variance eval              0.00964597
total_rewards                [3540.33251522 3786.28749052 3902.29161483 3174.29390847 3707.43487683
  447.57042313 3773.63522431 3806.86005556 1716.79638177 3887.95915335]
total_rewards_mean           3174.3461643978562
total_rewards_std            1102.3034229422612
total_rewards_max            3902.2916148340846
total_rewards_min            447.57042312793817
Number of train steps total  688000
Number of env steps total    627866
Number of rollouts total     0
Train Time (s)               178.20684975013137
(Previous) Eval Time (s)     30.14477870799601
Sample Time (s)              6.862330742646009
Epoch Time (s)               215.2139592007734
Total Train Time (s)         35831.70866880566
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:08:53.293737 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #171 | Epoch Duration: 215.40807557106018
2020-01-12 02:08:53.293960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.093456
Z variance train             0.009654154
KL Divergence                22.585403
KL Loss                      2.2585404
QF Loss                      800.6028
VF Loss                      97.18507
Policy Loss                  -938.0803
Q Predictions Mean           928.4044
Q Predictions Std            365.7869
Q Predictions Max            1368.9597
Q Predictions Min            -31.113653
V Predictions Mean           935.3149
V Predictions Std            356.28186
V Predictions Max            1368.2264
V Predictions Min            8.403383
Log Pis Mean                 -0.1751404
Log Pis Std                  3.244929
Log Pis Max                  19.803782
Log Pis Min                  -8.888834
Policy mu Mean               0.042849146
Policy mu Std                0.5888429
Policy mu Max                4.0350394
Policy mu Min                -3.5686274
Policy log std Mean          -1.0088267
Policy log std Std           0.23731625
Policy log std Max           -0.28913713
Policy log std Min           -2.1049788
Z mean eval                  1.1570013
Z variance eval              0.039064948
total_rewards                [ 333.88718289 3767.42464053 3649.00253541 4052.96050911 3929.78393467
 3414.0907596  3860.73023956 3712.32023055  713.42350883 3757.97148906]
total_rewards_mean           3119.159503021059
total_rewards_std            1310.4280671689858
total_rewards_max            4052.9605091096555
total_rewards_min            333.8871828915807
Number of train steps total  692000
Number of env steps total    632474
Number of rollouts total     0
Train Time (s)               177.44351030979306
(Previous) Eval Time (s)     28.395719461143017
Sample Time (s)              7.295862480066717
Epoch Time (s)               213.1350922510028
Total Train Time (s)         36044.93289561197
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:12:26.519116 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #172 | Epoch Duration: 213.22503781318665
2020-01-12 02:12:26.519243 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608003
Z variance train             0.038983207
KL Divergence                21.219337
KL Loss                      2.1219337
QF Loss                      789.978
VF Loss                      772.7547
Policy Loss                  -868.30225
Q Predictions Mean           856.38635
Q Predictions Std            404.72586
Q Predictions Max            1421.5156
Q Predictions Min            -11.126043
V Predictions Mean           869.2739
V Predictions Std            392.03958
V Predictions Max            1412.0393
V Predictions Min            220.23604
Log Pis Mean                 -0.392697
Log Pis Std                  3.3620791
Log Pis Max                  16.94818
Log Pis Min                  -8.72931
Policy mu Mean               0.002484628
Policy mu Std                0.5701551
Policy mu Max                2.221043
Policy mu Min                -2.2233222
Policy log std Mean          -0.99047524
Policy log std Std           0.25566813
Policy log std Max           -0.46049652
Policy log std Min           -2.4196274
Z mean eval                  1.1686294
Z variance eval              0.014969995
total_rewards                [3872.71812961 4113.95803812 3805.2335644   584.01636216 1865.13532521
 3529.22246714 3853.37029707 3751.51449877 3651.53584422 3702.22437348]
total_rewards_mean           3272.892890019276
total_rewards_std            1073.3983121089082
total_rewards_max            4113.9580381234855
total_rewards_min            584.0163621604569
Number of train steps total  696000
Number of env steps total    641127
Number of rollouts total     0
Train Time (s)               178.13990148808807
(Previous) Eval Time (s)     30.50993756391108
Sample Time (s)              7.825238142162561
Epoch Time (s)               216.4750771941617
Total Train Time (s)         36261.50162990205
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:16:03.089571 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #173 | Epoch Duration: 216.5702362060547
2020-01-12 02:16:03.089695 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1693349
Z variance train             0.014964481
KL Divergence                22.299454
KL Loss                      2.2299454
QF Loss                      1163.5469
VF Loss                      190.73662
Policy Loss                  -901.7456
Q Predictions Mean           896.1101
Q Predictions Std            382.3424
Q Predictions Max            1365.1085
Q Predictions Min            225.92027
V Predictions Mean           906.60144
V Predictions Std            379.84195
V Predictions Max            1370.8904
V Predictions Min            239.48024
Log Pis Mean                 -0.27209637
Log Pis Std                  3.3312259
Log Pis Max                  17.13239
Log Pis Min                  -8.201603
Policy mu Mean               0.0073253345
Policy mu Std                0.58555734
Policy mu Max                3.0233579
Policy mu Min                -2.9788108
Policy log std Mean          -0.9894186
Policy log std Std           0.23562181
Policy log std Max           -0.3422643
Policy log std Min           -2.1203706
Z mean eval                  1.2321455
Z variance eval              0.019483248
total_rewards                [ 561.7424749  1252.19717092 1401.79610629 1055.22673205  762.67488388
  249.8239274  3709.98461655 3928.03488392  823.89298632 3034.14774442]
total_rewards_mean           1677.952152664182
total_rewards_std            1285.6607228086452
total_rewards_max            3928.034883919928
total_rewards_min            249.823927399613
Number of train steps total  700000
Number of env steps total    645920
Number of rollouts total     0
Train Time (s)               177.41943244216964
(Previous) Eval Time (s)     14.823090488091111
Sample Time (s)              7.124491955619305
Epoch Time (s)               199.36701488588005
Total Train Time (s)         36460.959292465355
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:19:22.552446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #174 | Epoch Duration: 199.46262311935425
2020-01-12 02:19:22.552698 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2319931
Z variance train             0.01948604
KL Divergence                22.131182
KL Loss                      2.2131183
QF Loss                      1072.362
VF Loss                      168.32068
Policy Loss                  -964.21967
Q Predictions Mean           955.3055
Q Predictions Std            376.39386
Q Predictions Max            1415.3729
Q Predictions Min            -72.14891
V Predictions Mean           962.3843
V Predictions Std            369.95392
V Predictions Max            1420.7842
V Predictions Min            -55.160923
Log Pis Mean                 0.31125003
Log Pis Std                  3.9902337
Log Pis Max                  27.164265
Log Pis Min                  -9.410793
Policy mu Mean               0.0067608785
Policy mu Std                0.6194145
Policy mu Max                2.897421
Policy mu Min                -4.0520606
Policy log std Mean          -1.0132277
Policy log std Std           0.24472636
Policy log std Max           -0.097866595
Policy log std Min           -2.670737
Z mean eval                  1.1260784
Z variance eval              0.0071182973
total_rewards                [3701.35874953 1938.44192923 3858.81359813 2573.15642477 4136.16127004
  532.9019324  2669.81090998 3577.51745639 1301.83567716 1256.54882311]
total_rewards_mean           2554.6546770741297
total_rewards_std            1195.7680347201574
total_rewards_max            4136.161270038097
total_rewards_min            532.9019323965618
Number of train steps total  704000
Number of env steps total    651490
Number of rollouts total     0
Train Time (s)               176.7342578889802
(Previous) Eval Time (s)     25.109641628805548
Sample Time (s)              6.814346620347351
Epoch Time (s)               208.6582461381331
Total Train Time (s)         36669.76787834242
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:22:51.363713 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #175 | Epoch Duration: 208.81083154678345
2020-01-12 02:22:51.363913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1255739
Z variance train             0.0071485178
KL Divergence                24.200016
KL Loss                      2.4200017
QF Loss                      903.7958
VF Loss                      138.98787
Policy Loss                  -940.6836
Q Predictions Mean           935.6767
Q Predictions Std            381.87552
Q Predictions Max            1386.993
Q Predictions Min            -52.274845
V Predictions Mean           943.14526
V Predictions Std            373.28207
V Predictions Max            1388.7975
V Predictions Min            264.7602
Log Pis Mean                 0.08290119
Log Pis Std                  4.1089025
Log Pis Max                  27.88197
Log Pis Min                  -9.470961
Policy mu Mean               0.02303322
Policy mu Std                0.6054752
Policy mu Max                3.3676476
Policy mu Min                -3.9335592
Policy log std Mean          -1.0264907
Policy log std Std           0.24802598
Policy log std Max           -0.2789861
Policy log std Min           -2.1835792
Z mean eval                  1.0702891
Z variance eval              0.03328877
total_rewards                [1.18264305e+03 4.11854589e+03 1.70105740e+03 3.02906531e+00
 2.06383267e+03 2.53935348e+03 3.73188258e+03 3.75980363e+03
 1.97696243e+02 3.86248556e+03]
total_rewards_mean           2316.0329570433364
total_rewards_std            1460.933076094374
total_rewards_max            4118.5458882271205
total_rewards_min            3.029065314807842
Number of train steps total  708000
Number of env steps total    656396
Number of rollouts total     0
Train Time (s)               176.6757125160657
(Previous) Eval Time (s)     20.22408211696893
Sample Time (s)              8.217542513739318
Epoch Time (s)               205.11733714677393
Total Train Time (s)         36874.98007032368
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:26:16.576457 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #176 | Epoch Duration: 205.2123885154724
2020-01-12 02:26:16.576586 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #176 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0738142
Z variance train             0.033048324
KL Divergence                20.305084
KL Loss                      2.0305085
QF Loss                      1437.3677
VF Loss                      157.97842
Policy Loss                  -890.5314
Q Predictions Mean           877.88794
Q Predictions Std            406.38974
Q Predictions Max            1396.8857
Q Predictions Min            -11.513621
V Predictions Mean           886.57104
V Predictions Std            395.70547
V Predictions Max            1388.3463
V Predictions Min            273.58362
Log Pis Mean                 -0.063947394
Log Pis Std                  4.1304717
Log Pis Max                  35.590942
Log Pis Min                  -7.1240664
Policy mu Mean               0.00089444546
Policy mu Std                0.6063135
Policy mu Max                3.659352
Policy mu Min                -5.281305
Policy log std Mean          -1.0091127
Policy log std Std           0.2399907
Policy log std Max           -0.0058068037
Policy log std Min           -2.3556752
Z mean eval                  1.4253088
Z variance eval              0.0070960307
total_rewards                [3540.596065    584.44900068  701.04811144 2836.73412454  243.9051825
  412.87803876  707.27300972 1103.20932768 1837.68785846 1031.31075551]
total_rewards_mean           1299.909147428143
total_rewards_std            1044.3301511273835
total_rewards_max            3540.596064995842
total_rewards_min            243.90518249782542
Number of train steps total  712000
Number of env steps total    662138
Number of rollouts total     0
Train Time (s)               186.79290319699794
(Previous) Eval Time (s)     14.870377195999026
Sample Time (s)              7.018464943394065
Epoch Time (s)               208.68174533639103
Total Train Time (s)         37083.7565164133
Epoch                        177
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:29:45.355558 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #177 | Epoch Duration: 208.7788565158844
2020-01-12 02:29:45.355750 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4232544
Z variance train             0.0070631043
KL Divergence                24.096739
KL Loss                      2.409674
QF Loss                      657.64685
VF Loss                      159.21533
Policy Loss                  -894.314
Q Predictions Mean           889.4083
Q Predictions Std            400.35693
Q Predictions Max            1407.3475
Q Predictions Min            15.217031
V Predictions Mean           892.3478
V Predictions Std            401.16318
V Predictions Max            1398.8262
V Predictions Min            -33.311676
Log Pis Mean                 -0.25995126
Log Pis Std                  3.223375
Log Pis Max                  16.509514
Log Pis Min                  -11.015241
Policy mu Mean               0.005836328
Policy mu Std                0.5883722
Policy mu Max                2.4537995
Policy mu Min                -2.552379
Policy log std Mean          -0.9817974
Policy log std Std           0.23777835
Policy log std Max           0.17288643
Policy log std Min           -2.4008768
Z mean eval                  1.2151928
Z variance eval              0.01703535
total_rewards                [ 611.46535004 3385.0528711  3154.51323578 2982.7378406  3235.43339994
 3203.69273962 3178.32716903  444.71810648 3412.03751055 3270.45238262]
total_rewards_mean           2687.843060576315
total_rewards_std            1086.4723381378144
total_rewards_max            3412.037510546347
total_rewards_min            444.71810648212653
Number of train steps total  716000
Number of env steps total    667949
Number of rollouts total     0
Train Time (s)               191.14543518191203
(Previous) Eval Time (s)     31.255904017947614
Sample Time (s)              6.775274985935539
Epoch Time (s)               229.1766141857952
Total Train Time (s)         37313.05082945898
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:33:34.652073 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #178 | Epoch Duration: 229.2961814403534
2020-01-12 02:33:34.652244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #178 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2111162
Z variance train             0.017089646
KL Divergence                21.65699
KL Loss                      2.165699
QF Loss                      1562.081
VF Loss                      282.81055
Policy Loss                  -913.34784
Q Predictions Mean           901.1897
Q Predictions Std            408.84064
Q Predictions Max            1423.5562
Q Predictions Min            -35.49936
V Predictions Mean           923.46747
V Predictions Std            400.27182
V Predictions Max            1426.6519
V Predictions Min            257.1062
Log Pis Mean                 0.15042843
Log Pis Std                  4.3321366
Log Pis Max                  24.437792
Log Pis Min                  -8.554503
Policy mu Mean               0.011132408
Policy mu Std                0.6275628
Policy mu Max                3.202368
Policy mu Min                -3.7360806
Policy log std Mean          -1.0066649
Policy log std Std           0.25645456
Policy log std Max           -0.32170874
Policy log std Min           -2.3554919
Z mean eval                  1.2122315
Z variance eval              0.010042671
total_rewards                [2.83005389e+02 5.95826313e+02 8.17344335e+02 5.18065198e+02
 7.22900672e-02 3.82036282e+03 3.00232876e+03 2.37398259e+03
 9.12107188e+02 3.15541641e+03]
total_rewards_mean           1547.8511284522897
total_rewards_std            1320.8576300329144
total_rewards_max            3820.362819092939
total_rewards_min            0.07229006717435893
Number of train steps total  720000
Number of env steps total    674496
Number of rollouts total     0
Train Time (s)               189.20492292521521
(Previous) Eval Time (s)     20.935189691837877
Sample Time (s)              6.760439567733556
Epoch Time (s)               216.90055218478665
Total Train Time (s)         37530.04037357308
Epoch                        179
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:37:11.643397 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #179 | Epoch Duration: 216.99103498458862
2020-01-12 02:37:11.643529 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2116386
Z variance train             0.010003297
KL Divergence                22.243364
KL Loss                      2.2243364
QF Loss                      1109.832
VF Loss                      177.40758
Policy Loss                  -933.77704
Q Predictions Mean           930.6704
Q Predictions Std            387.9702
Q Predictions Max            1416.387
Q Predictions Min            223.51512
V Predictions Mean           937.07104
V Predictions Std            383.7424
V Predictions Max            1414.1486
V Predictions Min            253.47241
Log Pis Mean                 -0.08600369
Log Pis Std                  3.0058548
Log Pis Max                  10.108527
Log Pis Min                  -6.2940283
Policy mu Mean               0.027556635
Policy mu Std                0.57752687
Policy mu Max                2.5635386
Policy mu Min                -2.7892945
Policy log std Mean          -1.0127423
Policy log std Std           0.23856626
Policy log std Max           -0.42319185
Policy log std Min           -2.164517
Z mean eval                  1.3996528
Z variance eval              0.016408082
total_rewards                [3854.43930501 3946.55953493  613.64381269 3528.50656067  108.42083972
 4291.53174682 3961.51519979 2931.59951968 3841.14258579 1500.11765461]
total_rewards_mean           2857.7476759721635
total_rewards_std            1459.9089552978508
total_rewards_max            4291.531746817624
total_rewards_min            108.42083971826402
Number of train steps total  724000
Number of env steps total    681898
Number of rollouts total     0
Train Time (s)               191.65455228090286
(Previous) Eval Time (s)     29.308459486812353
Sample Time (s)              13.217495947610587
Epoch Time (s)               234.1805077153258
Total Train Time (s)         37764.38088807091
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:41:05.985821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #180 | Epoch Duration: 234.34218454360962
2020-01-12 02:41:05.985998 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4069366
Z variance train             0.016404558
KL Divergence                22.08453
KL Loss                      2.208453
QF Loss                      1142.7047
VF Loss                      229.4101
Policy Loss                  -950.3873
Q Predictions Mean           939.0382
Q Predictions Std            387.6919
Q Predictions Max            1421.1608
Q Predictions Min            20.658138
V Predictions Mean           947.636
V Predictions Std            380.98016
V Predictions Max            1404.1997
V Predictions Min            -28.15502
Log Pis Mean                 0.2194064
Log Pis Std                  3.6551828
Log Pis Max                  19.771027
Log Pis Min                  -8.929423
Policy mu Mean               -0.0011926864
Policy mu Std                0.6321152
Policy mu Max                2.463662
Policy mu Min                -4.648127
Policy log std Mean          -1.0086405
Policy log std Std           0.2568921
Policy log std Max           -0.18329358
Policy log std Min           -2.4075463
Z mean eval                  1.1873158
Z variance eval              0.014219415
total_rewards                [3680.77219211 3625.76014941 3631.07604619 2643.01329683 3844.52041937
 3816.90763187  575.70016832 3758.12448138 3729.05720123 3611.04789601]
total_rewards_mean           3291.597948272761
total_rewards_std            962.6976963150254
total_rewards_max            3844.52041937101
total_rewards_min            575.7001683151825
Number of train steps total  728000
Number of env steps total    688295
Number of rollouts total     0
Train Time (s)               206.71897319098935
(Previous) Eval Time (s)     46.73313430696726
Sample Time (s)              10.338844144251198
Epoch Time (s)               263.7909516422078
Total Train Time (s)         38028.30778558506
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:45:29.915417 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #181 | Epoch Duration: 263.929265499115
2020-01-12 02:45:29.915635 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1846756
Z variance train             0.014379883
KL Divergence                22.27024
KL Loss                      2.227024
QF Loss                      3387.834
VF Loss                      186.52864
Policy Loss                  -950.38513
Q Predictions Mean           942.626
Q Predictions Std            401.60916
Q Predictions Max            1416.6376
Q Predictions Min            -49.89666
V Predictions Mean           952.4915
V Predictions Std            393.15204
V Predictions Max            1405.9346
V Predictions Min            5.77126
Log Pis Mean                 0.761907
Log Pis Std                  4.276921
Log Pis Max                  27.60096
Log Pis Min                  -7.5817614
Policy mu Mean               0.062612705
Policy mu Std                0.6608086
Policy mu Max                3.4848258
Policy mu Min                -3.9337175
Policy log std Mean          -1.039269
Policy log std Std           0.28824362
Policy log std Max           -0.433424
Policy log std Min           -2.4398174
Z mean eval                  1.120359
Z variance eval              0.04113862
total_rewards                [3996.07474641 4099.52827753 1300.21730247 4002.74295966 1034.08979124
 3598.34070889 3975.97384891 4004.62769179  284.72038453 2733.38589675]
total_rewards_mean           2902.970160816979
total_rewards_std            1401.0773310025052
total_rewards_max            4099.528277527039
total_rewards_min            284.7203845278951
Number of train steps total  732000
Number of env steps total    693851
Number of rollouts total     0
Train Time (s)               209.5759990797378
(Previous) Eval Time (s)     37.73916006879881
Sample Time (s)              10.90257425326854
Epoch Time (s)               258.21773340180516
Total Train Time (s)         38286.62198717706
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:49:48.231594 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #182 | Epoch Duration: 258.315789937973
2020-01-12 02:49:48.231778 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1228714
Z variance train             0.043281265
KL Divergence                21.31632
KL Loss                      2.131632
QF Loss                      836.1167
VF Loss                      164.3447
Policy Loss                  -872.9455
Q Predictions Mean           864.3189
Q Predictions Std            402.06775
Q Predictions Max            1401.5906
Q Predictions Min            -22.390545
V Predictions Mean           874.1932
V Predictions Std            396.95697
V Predictions Max            1402.3374
V Predictions Min            12.89401
Log Pis Mean                 -0.18291907
Log Pis Std                  3.3068388
Log Pis Max                  18.321314
Log Pis Min                  -6.9381166
Policy mu Mean               0.035027795
Policy mu Std                0.5823909
Policy mu Max                3.4179716
Policy mu Min                -3.3410656
Policy log std Mean          -1.0083138
Policy log std Std           0.22043116
Policy log std Max           -0.5108392
Policy log std Min           -2.1546202
Z mean eval                  1.1445472
Z variance eval              0.009339681
total_rewards                [3735.64990404  223.8049713  3623.81117492 1172.45672348 1054.07737892
 3916.10880723 2843.10520182 1543.35746073 1950.46838904 3956.51054048]
total_rewards_mean           2401.9350551942666
total_rewards_std            1311.0835336259406
total_rewards_max            3956.5105404839446
total_rewards_min            223.80497129975055
Number of train steps total  736000
Number of env steps total    699998
Number of rollouts total     0
Train Time (s)               201.65515229012817
(Previous) Eval Time (s)     28.14195701200515
Sample Time (s)              10.379239918198436
Epoch Time (s)               240.17634922033176
Total Train Time (s)         38526.88737681741
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:53:48.499345 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #183 | Epoch Duration: 240.2674310207367
2020-01-12 02:53:48.499522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1454608
Z variance train             0.009388595
KL Divergence                22.367973
KL Loss                      2.2367973
QF Loss                      937.64374
VF Loss                      167.49106
Policy Loss                  -940.99744
Q Predictions Mean           933.8323
Q Predictions Std            405.60263
Q Predictions Max            1473.8064
Q Predictions Min            5.9335833
V Predictions Mean           938.61536
V Predictions Std            399.77808
V Predictions Max            1463.3221
V Predictions Min            253.98227
Log Pis Mean                 -0.1633139
Log Pis Std                  2.8683321
Log Pis Max                  14.343901
Log Pis Min                  -7.976499
Policy mu Mean               -0.0028719828
Policy mu Std                0.565001
Policy mu Max                2.2827897
Policy mu Min                -2.4199305
Policy log std Mean          -0.9874716
Policy log std Std           0.22983827
Policy log std Max           -0.30789965
Policy log std Min           -2.1697457
Z mean eval                  1.1793643
Z variance eval              0.009509182
total_rewards                [2392.33631806 4261.73794795 4112.91906477 3915.89340392 3853.56535658
  588.96624881 4173.99154688 1707.98146934 1077.36917116 3780.9869044 ]
total_rewards_mean           2986.574743185808
total_rewards_std            1339.1251042521624
total_rewards_max            4261.737947945874
total_rewards_min            588.9662488089415
Number of train steps total  740000
Number of env steps total    707479
Number of rollouts total     0
Train Time (s)               198.67104471288621
(Previous) Eval Time (s)     35.28230664599687
Sample Time (s)              11.517541947774589
Epoch Time (s)               245.47089330665767
Total Train Time (s)         38772.448028829414
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:57:54.064565 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #184 | Epoch Duration: 245.56483364105225
2020-01-12 02:57:54.064887 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1751589
Z variance train             0.009552775
KL Divergence                22.401175
KL Loss                      2.2401175
QF Loss                      1721.6726
VF Loss                      170.46379
Policy Loss                  -962.9676
Q Predictions Mean           956.3966
Q Predictions Std            396.1205
Q Predictions Max            1474.8083
Q Predictions Min            -46.87975
V Predictions Mean           958.2196
V Predictions Std            391.35406
V Predictions Max            1490.9681
V Predictions Min            -24.383383
Log Pis Mean                 0.18124296
Log Pis Std                  3.756125
Log Pis Max                  28.624886
Log Pis Min                  -8.903673
Policy mu Mean               0.01886837
Policy mu Std                0.6221915
Policy mu Max                3.7838275
Policy mu Min                -3.0307457
Policy log std Mean          -0.9926706
Policy log std Std           0.23047386
Policy log std Max           -0.23489004
Policy log std Min           -2.0655196
Z mean eval                  1.0808071
Z variance eval              0.045505404
total_rewards                [3758.784009    672.73353259 3986.57314808 1768.04361086 4030.19872359
 1054.57760599  826.21165248 1437.28186018  272.36478287 2598.26541542]
total_rewards_mean           2040.5034341058204
total_rewards_std            1374.4611643833796
total_rewards_max            4030.19872358765
total_rewards_min            272.36478287014796
Number of train steps total  744000
Number of env steps total    713759
Number of rollouts total     0
Train Time (s)               197.4788368330337
(Previous) Eval Time (s)     25.870020017027855
Sample Time (s)              13.063629070296884
Epoch Time (s)               236.41248592035845
Total Train Time (s)         39008.99175330484
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:01:50.610026 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #185 | Epoch Duration: 236.5449526309967
2020-01-12 03:01:50.610229 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0787116
Z variance train             0.04598067
KL Divergence                22.28902
KL Loss                      2.228902
QF Loss                      698.6307
VF Loss                      173.15196
Policy Loss                  -953.3138
Q Predictions Mean           947.2394
Q Predictions Std            403.287
Q Predictions Max            1496.604
Q Predictions Min            255.08072
V Predictions Mean           949.46924
V Predictions Std            401.49368
V Predictions Max            1479.4861
V Predictions Min            258.43973
Log Pis Mean                 0.013588786
Log Pis Std                  3.3800774
Log Pis Max                  12.089596
Log Pis Min                  -7.909747
Policy mu Mean               0.007635601
Policy mu Std                0.60034513
Policy mu Max                3.148126
Policy mu Min                -3.6405115
Policy log std Mean          -0.9853445
Policy log std Std           0.23547305
Policy log std Max           -0.38001162
Policy log std Min           -2.3034253
Z mean eval                  1.089791
Z variance eval              0.009973039
total_rewards                [4276.92879385 3663.12953873 3494.7850102  1567.04855412 3874.95367183
 1179.42486087  736.6740526  3975.95033892  236.54370239 4045.96331609]
total_rewards_mean           2705.140183958821
total_rewards_std            1496.1590160081134
total_rewards_max            4276.928793852325
total_rewards_min            236.54370238563718
Number of train steps total  748000
Number of env steps total    717956
Number of rollouts total     0
Train Time (s)               198.76898890919983
(Previous) Eval Time (s)     35.53814146714285
Sample Time (s)              10.798912254627794
Epoch Time (s)               245.10604263097048
Total Train Time (s)         39254.18952999823
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:05:55.809872 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #186 | Epoch Duration: 245.19949078559875
2020-01-12 03:05:55.810056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #186 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.092605
Z variance train             0.010049326
KL Divergence                21.855185
KL Loss                      2.1855185
QF Loss                      696.6899
VF Loss                      275.1379
Policy Loss                  -971.4796
Q Predictions Mean           960.3427
Q Predictions Std            404.1325
Q Predictions Max            1445.975
Q Predictions Min            215.29193
V Predictions Mean           962.91516
V Predictions Std            396.4111
V Predictions Max            1441.0138
V Predictions Min            279.04883
Log Pis Mean                 -0.10089269
Log Pis Std                  3.5995078
Log Pis Max                  21.456612
Log Pis Min                  -9.112461
Policy mu Mean               0.010539103
Policy mu Std                0.60400647
Policy mu Max                2.799099
Policy mu Min                -3.315736
Policy log std Mean          -1.0029323
Policy log std Std           0.23491398
Policy log std Max           -0.40925366
Policy log std Min           -2.3193157
Z mean eval                  1.2194941
Z variance eval              0.009925382
total_rewards                [3840.06066263 3627.41246914 3693.60498237    5.17327116  508.1765584
 3931.62464144 1257.83394842 1110.66166039 3910.1548942  3264.31356721]
total_rewards_mean           2514.901665536563
total_rewards_std            1509.182342607918
total_rewards_max            3931.6246414427364
total_rewards_min            5.173271159717877
Number of train steps total  752000
Number of env steps total    723076
Number of rollouts total     0
Train Time (s)               202.57038447074592
(Previous) Eval Time (s)     35.40716932527721
Sample Time (s)              8.656706204172224
Epoch Time (s)               246.63426000019535
Total Train Time (s)         39500.911301507615
Epoch                        187
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:10:02.537922 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #187 | Epoch Duration: 246.72762393951416
2020-01-12 03:10:02.538358 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2162522
Z variance train             0.009958309
KL Divergence                23.211737
KL Loss                      2.3211737
QF Loss                      569.71136
VF Loss                      165.37756
Policy Loss                  -938.3002
Q Predictions Mean           932.84753
Q Predictions Std            433.18448
Q Predictions Max            1516.4385
Q Predictions Min            243.17668
V Predictions Mean           942.4727
V Predictions Std            432.14597
V Predictions Max            1536.81
V Predictions Min            268.9549
Log Pis Mean                 -0.52188
Log Pis Std                  3.172914
Log Pis Max                  10.2569065
Log Pis Min                  -7.5081253
Policy mu Mean               0.030468842
Policy mu Std                0.55362886
Policy mu Max                2.5198002
Policy mu Min                -3.0185509
Policy log std Mean          -0.99954355
Policy log std Std           0.25437635
Policy log std Max           -0.32605475
Policy log std Min           -2.3027806
Z mean eval                  1.1299313
Z variance eval              0.009601356
total_rewards                [4017.86850422 3903.88334041  470.12524646 3891.49107238 4247.41245115
 3578.95250585 4011.58435427 1416.27904955 3994.07729205 4165.21383971]
total_rewards_mean           3369.688765604119
total_rewards_std            1242.980204523547
total_rewards_max            4247.4124511506025
total_rewards_min            470.1252464585825
Number of train steps total  756000
Number of env steps total    730765
Number of rollouts total     0
Train Time (s)               201.86881758505479
(Previous) Eval Time (s)     40.90430040797219
Sample Time (s)              10.536001692991704
Epoch Time (s)               253.30911968601868
Total Train Time (s)         39754.32418659376
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:14:15.951308 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #188 | Epoch Duration: 253.41272115707397
2020-01-12 03:14:15.951462 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #188 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1411562
Z variance train             0.0096513815
KL Divergence                22.881016
KL Loss                      2.2881017
QF Loss                      546.0255
VF Loss                      135.47456
Policy Loss                  -947.0522
Q Predictions Mean           942.0758
Q Predictions Std            426.74258
Q Predictions Max            1522.9806
Q Predictions Min            159.1602
V Predictions Mean           940.19165
V Predictions Std            425.23282
V Predictions Max            1516.6012
V Predictions Min            255.76234
Log Pis Mean                 -0.35341614
Log Pis Std                  2.9884708
Log Pis Max                  10.419227
Log Pis Min                  -8.845036
Policy mu Mean               0.04945263
Policy mu Std                0.53928053
Policy mu Max                2.7693183
Policy mu Min                -1.7597568
Policy log std Mean          -0.9974977
Policy log std Std           0.21946105
Policy log std Max           -0.45154476
Policy log std Min           -2.211176
Z mean eval                  1.0764194
Z variance eval              0.013230299
total_rewards                [1.51966639e+03 4.07591359e+03 4.39660138e+03 3.95221547e+00
 2.99687059e+02 3.86078908e+03 4.04243385e+03 1.38477486e+03
 5.16410413e+02 3.44109204e+03]
total_rewards_mean           2354.132088040401
total_rewards_std            1679.1476898543592
total_rewards_max            4396.601378761715
total_rewards_min            3.9522154737103063
Number of train steps total  760000
Number of env steps total    736183
Number of rollouts total     0
Train Time (s)               199.5965822688304
(Previous) Eval Time (s)     39.34238578611985
Sample Time (s)              11.243201535195112
Epoch Time (s)               250.18216959014535
Total Train Time (s)         40004.58938612603
Epoch                        189
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:18:26.218511 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #189 | Epoch Duration: 250.2669277191162
2020-01-12 03:18:26.218652 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784537
Z variance train             0.013216034
KL Divergence                22.324902
KL Loss                      2.2324903
QF Loss                      1478.8231
VF Loss                      143.95984
Policy Loss                  -973.7303
Q Predictions Mean           965.96893
Q Predictions Std            418.65164
Q Predictions Max            1458.8046
Q Predictions Min            12.103828
V Predictions Mean           974.214
V Predictions Std            413.10074
V Predictions Max            1467.7344
V Predictions Min            -10.651585
Log Pis Mean                 0.045204423
Log Pis Std                  3.2628567
Log Pis Max                  12.115493
Log Pis Min                  -6.102949
Policy mu Mean               0.007281827
Policy mu Std                0.5966623
Policy mu Max                2.4896598
Policy mu Min                -3.0549738
Policy log std Mean          -0.9976353
Policy log std Std           0.23543838
Policy log std Max           -0.2215513
Policy log std Min           -2.2964783
Z mean eval                  1.0959646
Z variance eval              0.014433475
total_rewards                [1134.94418116  508.69292844 2508.21982392 3843.21054483  936.18774569
 2177.69070014 3934.93476617  518.92173514 3800.16828463 3910.4955205 ]
total_rewards_mean           2327.3466230607573
total_rewards_std            1398.1383192398741
total_rewards_max            3934.934766172688
total_rewards_min            508.6929284351761
Number of train steps total  764000
Number of env steps total    745800
Number of rollouts total     0
Train Time (s)               200.29432345507666
(Previous) Eval Time (s)     33.329800189007074
Sample Time (s)              10.82977485889569
Epoch Time (s)               244.45389850297943
Total Train Time (s)         40249.177268658765
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:22:30.812198 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #190 | Epoch Duration: 244.59339570999146
2020-01-12 03:22:30.812494 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0887089
Z variance train             0.014462585
KL Divergence                21.261417
KL Loss                      2.1261418
QF Loss                      955.9348
VF Loss                      248.59845
Policy Loss                  -925.2238
Q Predictions Mean           913.6076
Q Predictions Std            426.1913
Q Predictions Max            1490.314
Q Predictions Min            -15.51355
V Predictions Mean           921.58325
V Predictions Std            421.81528
V Predictions Max            1461.5265
V Predictions Min            114.31743
Log Pis Mean                 -0.032441735
Log Pis Std                  3.5722253
Log Pis Max                  19.69177
Log Pis Min                  -7.492729
Policy mu Mean               -0.0007984047
Policy mu Std                0.61594236
Policy mu Max                4.0101547
Policy mu Min                -3.38079
Policy log std Mean          -0.9843904
Policy log std Std           0.25912037
Policy log std Max           0.047516704
Policy log std Min           -2.236511
Z mean eval                  1.1700766
Z variance eval              0.008011098
total_rewards                [4338.53367044 4127.04292907 4480.70518836  256.21433601 3815.33256293
  448.23068823 4263.27927874 4133.65870227 1650.6989999  2355.06874834]
total_rewards_mean           2986.8765104304607
total_rewards_std            1583.5063442269254
total_rewards_max            4480.705188358954
total_rewards_min            256.2143360088835
Number of train steps total  768000
Number of env steps total    750973
Number of rollouts total     0
Train Time (s)               204.56968812877312
(Previous) Eval Time (s)     33.26150540495291
Sample Time (s)              10.998410479631275
Epoch Time (s)               248.8296040133573
Total Train Time (s)         40498.109128268436
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:26:39.745503 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #191 | Epoch Duration: 248.93278765678406
2020-01-12 03:26:39.745714 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1669681
Z variance train             0.007966936
KL Divergence                23.15596
KL Loss                      2.315596
QF Loss                      620.85315
VF Loss                      363.79416
Policy Loss                  -922.9359
Q Predictions Mean           917.03143
Q Predictions Std            420.5542
Q Predictions Max            1446.058
Q Predictions Min            -33.158356
V Predictions Mean           917.635
V Predictions Std            413.47934
V Predictions Max            1427.7761
V Predictions Min            254.47284
Log Pis Mean                 -0.39813012
Log Pis Std                  3.3388417
Log Pis Max                  16.433067
Log Pis Min                  -10.950134
Policy mu Mean               0.02244616
Policy mu Std                0.5554002
Policy mu Max                2.8881457
Policy mu Min                -2.5853438
Policy log std Mean          -0.9901135
Policy log std Std           0.2341473
Policy log std Max           -0.503491
Policy log std Min           -2.0971296
Z mean eval                  1.2430811
Z variance eval              0.025660519
total_rewards                [1955.19297722 4123.95243327 3446.60251859 4110.04002477 2885.79992788
 1661.62907211 4231.80219499 4201.16184507 4074.89910419 4407.11955566]
total_rewards_mean           3509.8199653746365
total_rewards_std            953.2663758476423
total_rewards_max            4407.119555659828
total_rewards_min            1661.629072108131
Number of train steps total  772000
Number of env steps total    757352
Number of rollouts total     0
Train Time (s)               199.9443119377829
(Previous) Eval Time (s)     45.07746467599645
Sample Time (s)              10.248423532117158
Epoch Time (s)               255.27020014589652
Total Train Time (s)         40753.4684366663
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:30:55.107298 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #192 | Epoch Duration: 255.3613681793213
2020-01-12 03:30:55.107601 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2404258
Z variance train             0.026055146
KL Divergence                21.542273
KL Loss                      2.1542273
QF Loss                      2167.0833
VF Loss                      199.58443
Policy Loss                  -923.4315
Q Predictions Mean           914.01624
Q Predictions Std            417.0599
Q Predictions Max            1451.457
Q Predictions Min            213.66316
V Predictions Mean           925.83795
V Predictions Std            418.40012
V Predictions Max            1452.4076
V Predictions Min            218.13914
Log Pis Mean                 -0.2239558
Log Pis Std                  3.8238957
Log Pis Max                  25.667362
Log Pis Min                  -8.749931
Policy mu Mean               0.03273034
Policy mu Std                0.593489
Policy mu Max                3.480336
Policy mu Min                -3.4059598
Policy log std Mean          -0.9854156
Policy log std Std           0.2452326
Policy log std Max           -0.30749917
Policy log std Min           -2.3303132
Z mean eval                  1.0818161
Z variance eval              0.011530178
total_rewards                [2902.74949728 3133.96646871 4464.28596697 4289.59700717 4606.00756581
 1429.73398601 4234.86064131 4181.26102678 2902.46665846 4282.88002987]
total_rewards_mean           3642.7808848367013
total_rewards_std            965.5813713300516
total_rewards_max            4606.0075658135665
total_rewards_min            1429.7339860109857
Number of train steps total  776000
Number of env steps total    762042
Number of rollouts total     0
Train Time (s)               198.17083641514182
(Previous) Eval Time (s)     46.470027648843825
Sample Time (s)              9.510627978947014
Epoch Time (s)               254.15149204293266
Total Train Time (s)         41007.72892396804
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:35:09.369638 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #193 | Epoch Duration: 254.2618625164032
2020-01-12 03:35:09.369816 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0814211
Z variance train             0.011558457
KL Divergence                22.988596
KL Loss                      2.2988596
QF Loss                      703.68146
VF Loss                      129.9031
Policy Loss                  -958.9659
Q Predictions Mean           951.3629
Q Predictions Std            427.61377
Q Predictions Max            1517.0243
Q Predictions Min            -39.102165
V Predictions Mean           956.62286
V Predictions Std            425.0372
V Predictions Max            1509.514
V Predictions Min            75.220665
Log Pis Mean                 -0.06702268
Log Pis Std                  3.5079277
Log Pis Max                  17.133533
Log Pis Min                  -7.154191
Policy mu Mean               0.034034617
Policy mu Std                0.59377915
Policy mu Max                2.5005352
Policy mu Min                -2.7629743
Policy log std Mean          -0.98492694
Policy log std Std           0.24293225
Policy log std Max           -0.37679785
Policy log std Min           -2.2736442
Z mean eval                  1.0670621
Z variance eval              0.0054605016
total_rewards                [3778.66569848 4365.73193004 4455.6879238  4316.26741399 4402.66761593
 4268.76282154 4221.48551261 4189.39265841 2602.22879736 4274.03533631]
total_rewards_mean           4087.4925708475116
total_rewards_std            525.5507163142747
total_rewards_max            4455.687923804184
total_rewards_min            2602.2287973616644
Number of train steps total  780000
Number of env steps total    767626
Number of rollouts total     0
Train Time (s)               198.13574994774535
(Previous) Eval Time (s)     45.32134324219078
Sample Time (s)              9.547655879054219
Epoch Time (s)               253.00474906899035
Total Train Time (s)         41260.823866909835
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:39:22.468490 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #194 | Epoch Duration: 253.09852623939514
2020-01-12 03:39:22.468700 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628916
Z variance train             0.0054655373
KL Divergence                23.134369
KL Loss                      2.313437
QF Loss                      1686.4467
VF Loss                      207.94006
Policy Loss                  -958.5617
Q Predictions Mean           954.00024
Q Predictions Std            419.56595
Q Predictions Max            1487.3856
Q Predictions Min            -16.517061
V Predictions Mean           964.31274
V Predictions Std            416.39572
V Predictions Max            1491.4297
V Predictions Min            107.009
Log Pis Mean                 -0.23642883
Log Pis Std                  3.391665
Log Pis Max                  18.576
Log Pis Min                  -8.347821
Policy mu Mean               0.009751854
Policy mu Std                0.567537
Policy mu Max                3.11756
Policy mu Min                -2.555726
Policy log std Mean          -1.0235869
Policy log std Std           0.24755934
Policy log std Max           -0.16346419
Policy log std Min           -2.3789413
Z mean eval                  1.3449625
Z variance eval              0.064746946
total_rewards                [4317.68898035 3933.21447384 4068.21563534 4028.16294188 1610.25465501
 3975.17298641 4009.54165667 3884.31908276 1383.26673581  984.97068143]
total_rewards_mean           3219.480782950403
total_rewards_std            1252.2538767041813
total_rewards_max            4317.688980351703
total_rewards_min            984.9706814273418
Number of train steps total  784000
Number of env steps total    772480
Number of rollouts total     0
Train Time (s)               199.48192246770486
(Previous) Eval Time (s)     36.84494389407337
Sample Time (s)              8.307274500839412
Epoch Time (s)               244.63414086261764
Total Train Time (s)         41505.560912574176
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:43:27.206823 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #195 | Epoch Duration: 244.73797583580017
2020-01-12 03:43:27.206962 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3403938
Z variance train             0.064639375
KL Divergence                21.80258
KL Loss                      2.180258
QF Loss                      3791.346
VF Loss                      147.59544
Policy Loss                  -849.6975
Q Predictions Mean           840.57355
Q Predictions Std            400.80917
Q Predictions Max            1351.0365
Q Predictions Min            7.400708
V Predictions Mean           849.2775
V Predictions Std            393.18335
V Predictions Max            1354.0631
V Predictions Min            -2.2935023
Log Pis Mean                 0.06577924
Log Pis Std                  3.6999931
Log Pis Max                  26.612972
Log Pis Min                  -7.541718
Policy mu Mean               0.023897221
Policy mu Std                0.62019616
Policy mu Max                3.4037998
Policy mu Min                -6.0763807
Policy log std Mean          -1.0079513
Policy log std Std           0.23478366
Policy log std Max           -0.40793645
Policy log std Min           -2.124847
Z mean eval                  1.2094805
Z variance eval              0.0089422725
total_rewards                [3934.32615536 3821.38975964 4184.93615711 4070.14584195 4033.66913548
 1899.34271646 3960.66429358  385.14770971  787.29847324 4083.51818594]
total_rewards_mean           3116.0438428475845
total_rewards_std            1416.7772236639203
total_rewards_max            4184.936157114899
total_rewards_min            385.14770970815937
Number of train steps total  788000
Number of env steps total    779296
Number of rollouts total     0
Train Time (s)               201.05900978017598
(Previous) Eval Time (s)     36.10945133725181
Sample Time (s)              10.136087040882558
Epoch Time (s)               247.30454815831035
Total Train Time (s)         41752.955835162196
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:47:34.603894 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #196 | Epoch Duration: 247.3967878818512
2020-01-12 03:47:34.604110 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2080268
Z variance train             0.008983428
KL Divergence                22.565172
KL Loss                      2.2565172
QF Loss                      743.9226
VF Loss                      123.00324
Policy Loss                  -1041.4425
Q Predictions Mean           1035.6549
Q Predictions Std            397.33987
Q Predictions Max            1519.7128
Q Predictions Min            132.49103
V Predictions Mean           1041.439
V Predictions Std            390.00095
V Predictions Max            1508.3485
V Predictions Min            274.46896
Log Pis Mean                 -0.028593615
Log Pis Std                  3.1465378
Log Pis Max                  12.796833
Log Pis Min                  -6.935728
Policy mu Mean               0.01702641
Policy mu Std                0.5574908
Policy mu Max                2.4307902
Policy mu Min                -2.9051
Policy log std Mean          -1.0401614
Policy log std Std           0.24445762
Policy log std Max           -0.39273584
Policy log std Min           -2.286127
Z mean eval                  1.091121
Z variance eval              0.005427711
total_rewards                [3940.97858882 4152.29849606 4001.63093758 3794.36450237 4200.63917086
 2250.32841281 3872.98201603 3888.03601033 4013.81293346 4134.38466089]
total_rewards_mean           3824.945572920472
total_rewards_std            539.5417249540125
total_rewards_max            4200.639170863349
total_rewards_min            2250.32841281254
Number of train steps total  792000
Number of env steps total    788005
Number of rollouts total     0
Train Time (s)               198.55358172627166
(Previous) Eval Time (s)     48.733599516097456
Sample Time (s)              9.306859790347517
Epoch Time (s)               256.59404103271663
Total Train Time (s)         42009.64412149647
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:51:51.294741 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #197 | Epoch Duration: 256.69050550460815
2020-01-12 03:51:51.294924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0925472
Z variance train             0.0054230257
KL Divergence                23.7477
KL Loss                      2.37477
QF Loss                      720.0431
VF Loss                      306.89783
Policy Loss                  -1001.44055
Q Predictions Mean           993.00085
Q Predictions Std            412.10754
Q Predictions Max            1536.0264
Q Predictions Min            -36.19245
V Predictions Mean           1004.51636
V Predictions Std            403.4467
V Predictions Max            1540.8896
V Predictions Min            162.1797
Log Pis Mean                 0.4528361
Log Pis Std                  3.8946478
Log Pis Max                  23.614033
Log Pis Min                  -9.413801
Policy mu Mean               0.02291659
Policy mu Std                0.64696896
Policy mu Max                3.3223925
Policy mu Min                -3.399362
Policy log std Mean          -1.0204976
Policy log std Std           0.25357905
Policy log std Max           -0.066972196
Policy log std Min           -2.3319583
Z mean eval                  1.2149093
Z variance eval              0.008227152
total_rewards                [ 844.32528746 4082.16970169 3876.84789414 3982.5817775   876.69681224
 4206.55120571 4055.32154371  217.58800249 4272.68150975  740.71456895]
total_rewards_mean           2715.5478303639866
total_rewards_std            1681.8743932949503
total_rewards_max            4272.681509751716
total_rewards_min            217.58800248613784
Number of train steps total  796000
Number of env steps total    793235
Number of rollouts total     0
Train Time (s)               202.09100268781185
(Previous) Eval Time (s)     38.31256190594286
Sample Time (s)              10.174250763840973
Epoch Time (s)               250.57781535759568
Total Train Time (s)         42260.31427497463
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:56:01.966481 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #198 | Epoch Duration: 250.67142629623413
2020-01-12 03:56:01.966618 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.215969
Z variance train             0.008147821
KL Divergence                24.241045
KL Loss                      2.4241045
QF Loss                      1168.2649
VF Loss                      171.18338
Policy Loss                  -976.3485
Q Predictions Mean           969.9428
Q Predictions Std            435.8993
Q Predictions Max            1525.1304
Q Predictions Min            4.728926
V Predictions Mean           977.23865
V Predictions Std            429.7268
V Predictions Max            1516.5388
V Predictions Min            266.9841
Log Pis Mean                 0.05147423
Log Pis Std                  3.598341
Log Pis Max                  22.734661
Log Pis Min                  -7.2078133
Policy mu Mean               0.019150175
Policy mu Std                0.58195746
Policy mu Max                3.2755613
Policy mu Min                -4.0503364
Policy log std Mean          -1.01955
Policy log std Std           0.25617644
Policy log std Max           -0.4355334
Policy log std Min           -2.2103953
Z mean eval                  1.1139601
Z variance eval              0.0049054497
total_rewards                [2902.29022272  334.47910477 1488.76395199 3225.650529    720.11137288
 1919.70989021  383.56339084   25.87287995  194.99439324  324.25155253]
total_rewards_mean           1151.968728812249
total_rewards_std            1112.694178204958
total_rewards_max            3225.650528995314
total_rewards_min            25.872879951128574
Number of train steps total  800000
Number of env steps total    798781
Number of rollouts total     0
Train Time (s)               201.7544347741641
(Previous) Eval Time (s)     21.154964790679514
Sample Time (s)              9.457555141299963
Epoch Time (s)               232.3669547061436
Total Train Time (s)         42492.792428711895
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:59:54.447932 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #199 | Epoch Duration: 232.4811987876892
2020-01-12 03:59:54.448157 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1124709
Z variance train             0.0048889862
KL Divergence                24.975212
KL Loss                      2.4975212
QF Loss                      748.43884
VF Loss                      184.15236
Policy Loss                  -951.14557
Q Predictions Mean           943.1853
Q Predictions Std            436.72937
Q Predictions Max            1487.3695
Q Predictions Min            93.01305
V Predictions Mean           953.9364
V Predictions Std            432.71484
V Predictions Max            1486.7822
V Predictions Min            258.4493
Log Pis Mean                 -0.23205829
Log Pis Std                  3.1822896
Log Pis Max                  14.39978
Log Pis Min                  -6.761893
Policy mu Mean               0.006019324
Policy mu Std                0.59104645
Policy mu Max                2.3840642
Policy mu Min                -3.4771054
Policy log std Mean          -0.96782553
Policy log std Std           0.22784087
Policy log std Max           -0.45476663
Policy log std Min           -2.4276977
Z mean eval                  1.0831479
Z variance eval              0.030835673
total_rewards                [4113.82532919 2355.38179766  648.60097611 4337.44729884 4176.60014056
 1755.89082431 3091.5450461  2501.23005424 4224.94481311 2960.85148689]
total_rewards_mean           3016.631776699992
total_rewards_std            1168.8706457435385
total_rewards_max            4337.447298837211
total_rewards_min            648.6009761067847
Number of train steps total  804000
Number of env steps total    808922
Number of rollouts total     0
Train Time (s)               202.291891687084
(Previous) Eval Time (s)     42.37133534997702
Sample Time (s)              20.12650796631351
Epoch Time (s)               264.7897350033745
Total Train Time (s)         42757.668591275346
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:04:19.327014 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #200 | Epoch Duration: 264.87861800193787
2020-01-12 04:04:19.327327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0805945
Z variance train             0.030780965
KL Divergence                22.178146
KL Loss                      2.2178147
QF Loss                      805.0061
VF Loss                      120.47319
Policy Loss                  -1000.83636
Q Predictions Mean           996.0235
Q Predictions Std            435.4099
Q Predictions Max            1545.6415
Q Predictions Min            251.07333
V Predictions Mean           1002.1911
V Predictions Std            432.99054
V Predictions Max            1544.4453
V Predictions Min            272.68362
Log Pis Mean                 -0.02906134
Log Pis Std                  3.0514097
Log Pis Max                  9.238232
Log Pis Min                  -7.143975
Policy mu Mean               0.042225838
Policy mu Std                0.57067055
Policy mu Max                2.8375642
Policy mu Min                -2.3656828
Policy log std Mean          -1.020786
Policy log std Std           0.23580272
Policy log std Max           -0.17239863
Policy log std Min           -2.1201758
Z mean eval                  1.1775938
Z variance eval              0.018586809
total_rewards                [4081.24514996 4206.05325758 1562.28711663 3976.00049274 4308.74427228
 4253.82803901  838.14626984 3974.05701584 1688.10451107 1667.08523918]
total_rewards_mean           3055.555136412674
total_rewards_std            1342.2895952541062
total_rewards_max            4308.744272279467
total_rewards_min            838.1462698352423
Number of train steps total  808000
Number of env steps total    817738
Number of rollouts total     0
Train Time (s)               202.61356815788895
(Previous) Eval Time (s)     38.79938604682684
Sample Time (s)              10.28187317866832
Epoch Time (s)               251.6948273833841
Total Train Time (s)         43009.454745220486
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:08:31.114890 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #201 | Epoch Duration: 251.78738284111023
2020-01-12 04:08:31.115070 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1762191
Z variance train             0.018624898
KL Divergence                21.810513
KL Loss                      2.1810513
QF Loss                      1264.6226
VF Loss                      113.086044
Policy Loss                  -995.637
Q Predictions Mean           987.11835
Q Predictions Std            431.65344
Q Predictions Max            1513.288
Q Predictions Min            34.155712
V Predictions Mean           993.9852
V Predictions Std            426.27518
V Predictions Max            1512.4524
V Predictions Min            205.59892
Log Pis Mean                 -0.23457459
Log Pis Std                  2.8857057
Log Pis Max                  8.099999
Log Pis Min                  -7.955237
Policy mu Mean               0.012593347
Policy mu Std                0.56906813
Policy mu Max                2.3416638
Policy mu Min                -2.50691
Policy log std Mean          -1.0070384
Policy log std Std           0.22984475
Policy log std Max           -0.3927828
Policy log std Min           -1.9328437
Z mean eval                  1.1252755
Z variance eval              0.017910175
total_rewards                [4158.36708164  418.87720279 4083.73039847 1687.70940496 2126.03108663
 2427.46723924 1015.70893403  408.10919693 4423.34535028 4298.74415731]
total_rewards_mean           2504.8090052273556
total_rewards_std            1546.2218121929832
total_rewards_max            4423.345350275685
total_rewards_min            408.1091969253453
Number of train steps total  812000
Number of env steps total    825542
Number of rollouts total     0
Train Time (s)               203.06976569024846
(Previous) Eval Time (s)     29.596449449192733
Sample Time (s)              10.057827404234558
Epoch Time (s)               242.72404254367575
Total Train Time (s)         43252.30049324501
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:12:33.967291 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #202 | Epoch Duration: 242.85200190544128
2020-01-12 04:12:33.967552 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #202 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203518
Z variance train             0.017626908
KL Divergence                21.966572
KL Loss                      2.1966572
QF Loss                      714.819
VF Loss                      113.95715
Policy Loss                  -1014.6725
Q Predictions Mean           1007.6481
Q Predictions Std            468.49512
Q Predictions Max            1629.1417
Q Predictions Min            -7.5483847
V Predictions Mean           1017.2146
V Predictions Std            468.32227
V Predictions Max            1631.8392
V Predictions Min            43.6305
Log Pis Mean                 0.22578248
Log Pis Std                  3.2707531
Log Pis Max                  18.445866
Log Pis Min                  -6.045045
Policy mu Mean               0.049400944
Policy mu Std                0.6046463
Policy mu Max                2.876
Policy mu Min                -4.224647
Policy log std Mean          -0.9838906
Policy log std Std           0.22961535
Policy log std Max           0.02450794
Policy log std Min           -2.1908803
Z mean eval                  1.1232972
Z variance eval              0.00813025
total_rewards                [  64.42330014 4101.05335548 4201.12207188 1328.36823519 4079.5147887
 3030.13705776 1151.9572045  3456.94877884 4393.55981701 4034.05531173]
total_rewards_mean           2984.113992122291
total_rewards_std            1478.7175701143967
total_rewards_max            4393.559817005708
total_rewards_min            64.42330013673234
Number of train steps total  816000
Number of env steps total    833528
Number of rollouts total     0
Train Time (s)               203.42596539389342
(Previous) Eval Time (s)     36.03072472475469
Sample Time (s)              11.031026981770992
Epoch Time (s)               250.4877171004191
Total Train Time (s)         43502.84749566624
Epoch                        203
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:16:44.551587 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #203 | Epoch Duration: 250.5838499069214
2020-01-12 04:16:44.551771 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.126566
Z variance train             0.0081513375
KL Divergence                22.579441
KL Loss                      2.257944
QF Loss                      1847.5688
VF Loss                      1058.8384
Policy Loss                  -1003.279
Q Predictions Mean           994.54565
Q Predictions Std            420.77917
Q Predictions Max            1534.0585
Q Predictions Min            6.6480675
V Predictions Mean           1009.3143
V Predictions Std            419.08295
V Predictions Max            1536.899
V Predictions Min            -60.21905
Log Pis Mean                 0.18692902
Log Pis Std                  3.5746539
Log Pis Max                  15.539197
Log Pis Min                  -9.184461
Policy mu Mean               0.005626874
Policy mu Std                0.64497703
Policy mu Max                2.4909704
Policy mu Min                -3.3533726
Policy log std Mean          -1.0308197
Policy log std Std           0.26294824
Policy log std Max           0.6590919
Policy log std Min           -2.4994402
Z mean eval                  1.0901358
Z variance eval              0.04395732
total_rewards                [4387.45957614 4076.60885427 4372.32575767 4275.1530924  4258.31710649
 4195.28302746 4268.46485223 4339.73293337 4260.88138028 4422.02954873]
total_rewards_mean           4285.625612904078
total_rewards_std            96.45345618762234
total_rewards_max            4422.029548727759
total_rewards_min            4076.608854266936
Number of train steps total  820000
Number of env steps total    839688
Number of rollouts total     0
Train Time (s)               200.8278440157883
(Previous) Eval Time (s)     47.68979923892766
Sample Time (s)              10.037765165325254
Epoch Time (s)               258.5554084200412
Total Train Time (s)         43761.49440444494
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:21:03.201414 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #204 | Epoch Duration: 258.6494483947754
2020-01-12 04:21:03.201687 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #204 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0883006
Z variance train             0.044483006
KL Divergence                19.230225
KL Loss                      1.9230225
QF Loss                      649.07745
VF Loss                      151.33871
Policy Loss                  -935.362
Q Predictions Mean           928.39636
Q Predictions Std            447.3862
Q Predictions Max            1533.654
Q Predictions Min            -43.070198
V Predictions Mean           934.60876
V Predictions Std            444.26053
V Predictions Max            1531.0991
V Predictions Min            269.4535
Log Pis Mean                 -0.49162632
Log Pis Std                  3.3773823
Log Pis Max                  16.79023
Log Pis Min                  -10.882807
Policy mu Mean               -0.0005112444
Policy mu Std                0.550761
Policy mu Max                3.0578055
Policy mu Min                -2.7303991
Policy log std Mean          -1.0050018
Policy log std Std           0.2550661
Policy log std Max           -0.3228162
Policy log std Min           -2.3928585
Z mean eval                  1.1458772
Z variance eval              0.01823304
total_rewards                [4330.82302606 4293.96067424 4454.10051258 4276.06683596 4472.0891822
 4014.73901699 3121.56458453 4217.43655987 4284.95220345 3879.43398246]
total_rewards_mean           4134.516657834886
total_rewards_std            378.82402349910785
total_rewards_max            4472.089182199153
total_rewards_min            3121.5645845261415
Number of train steps total  824000
Number of env steps total    847918
Number of rollouts total     0
Train Time (s)               202.43796688318253
(Previous) Eval Time (s)     43.678285947069526
Sample Time (s)              9.01493758102879
Epoch Time (s)               255.13119041128084
Total Train Time (s)         44016.71118337661
Epoch                        205
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:25:18.419913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #205 | Epoch Duration: 255.2180619239807
2020-01-12 04:25:18.420119 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1405497
Z variance train             0.018064747
KL Divergence                20.695518
KL Loss                      2.069552
QF Loss                      1411.7197
VF Loss                      641.8423
Policy Loss                  -1001.6877
Q Predictions Mean           993.81165
Q Predictions Std            438.5947
Q Predictions Max            1564.9891
Q Predictions Min            -68.95339
V Predictions Mean           1002.6765
V Predictions Std            427.23706
V Predictions Max            1544.1538
V Predictions Min            -22.32632
Log Pis Mean                 0.2126839
Log Pis Std                  3.6246433
Log Pis Max                  23.558638
Log Pis Min                  -7.387541
Policy mu Mean               0.019410139
Policy mu Std                0.64348555
Policy mu Max                4.1293793
Policy mu Min                -3.2618394
Policy log std Mean          -1.0131507
Policy log std Std           0.26589522
Policy log std Max           -0.42674226
Policy log std Min           -2.5249877
Z mean eval                  1.0907815
Z variance eval              0.008310962
total_rewards                [4296.73037434 4476.74474535 3930.60214418 4479.0865815  4246.47233119
 4189.52759483 1234.79305754 4062.78054335 4245.6113736  4050.65264722]
total_rewards_mean           3921.3001393092322
total_rewards_std            910.9121027577604
total_rewards_max            4479.086581495195
total_rewards_min            1234.7930575414355
Number of train steps total  828000
Number of env steps total    857414
Number of rollouts total     0
Train Time (s)               201.01402056682855
(Previous) Eval Time (s)     48.67439597193152
Sample Time (s)              11.013419910799712
Epoch Time (s)               260.7018364495598
Total Train Time (s)         44277.52194000641
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:29:39.233399 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #206 | Epoch Duration: 260.8131351470947
2020-01-12 04:29:39.233615 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0959275
Z variance train             0.008301018
KL Divergence                23.12256
KL Loss                      2.312256
QF Loss                      767.2389
VF Loss                      140.32306
Policy Loss                  -1024.0408
Q Predictions Mean           1013.2454
Q Predictions Std            435.22275
Q Predictions Max            1592.9033
Q Predictions Min            1.9290392
V Predictions Mean           1023.1748
V Predictions Std            434.27396
V Predictions Max            1597.8752
V Predictions Min            16.59378
Log Pis Mean                 0.001791276
Log Pis Std                  3.3357022
Log Pis Max                  20.978142
Log Pis Min                  -7.5122614
Policy mu Mean               0.03225402
Policy mu Std                0.6041916
Policy mu Max                5.15706
Policy mu Min                -3.4306896
Policy log std Mean          -1.0189503
Policy log std Std           0.24446402
Policy log std Max           -0.34699547
Policy log std Min           -2.1364694
Z mean eval                  1.0756378
Z variance eval              0.008507059
total_rewards                [4235.7619386  4377.68142457  931.05306793 4583.39170386 4358.3953506
 4290.18076058 4223.25145469 4391.86199396 4217.18801262 1448.62034245]
total_rewards_mean           3705.738604985435
total_rewards_std            1267.433167524185
total_rewards_max            4583.391703859515
total_rewards_min            931.0530679339558
Number of train steps total  832000
Number of env steps total    865998
Number of rollouts total     0
Train Time (s)               206.45232300600037
(Previous) Eval Time (s)     46.00155514432117
Sample Time (s)              10.872809197288007
Epoch Time (s)               263.32668734760955
Total Train Time (s)         44541.02588229487
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:34:02.745152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #207 | Epoch Duration: 263.5113823413849
2020-01-12 04:34:02.745353 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0751358
Z variance train             0.008551283
KL Divergence                23.937263
KL Loss                      2.3937263
QF Loss                      660.34717
VF Loss                      146.70512
Policy Loss                  -973.51465
Q Predictions Mean           968.13
Q Predictions Std            444.75308
Q Predictions Max            1556.4736
Q Predictions Min            -21.377808
V Predictions Mean           970.72925
V Predictions Std            438.58447
V Predictions Max            1553.1125
V Predictions Min            232.69229
Log Pis Mean                 0.04752621
Log Pis Std                  3.67449
Log Pis Max                  24.092882
Log Pis Min                  -7.1902137
Policy mu Mean               0.047757663
Policy mu Std                0.6126026
Policy mu Max                3.4022462
Policy mu Min                -3.0315762
Policy log std Mean          -0.9924451
Policy log std Std           0.24615395
Policy log std Max           -0.34844726
Policy log std Min           -2.171999
Z mean eval                  1.0609218
Z variance eval              0.011043485
total_rewards                [3317.00920001 1539.95427219 4398.63582914 4141.66212716 4271.12487231
   71.08062461 4348.05557013 2377.61718756 4340.6589135  4643.96707711]
total_rewards_mean           3344.9765673716697
total_rewards_std            1456.0443002142629
total_rewards_max            4643.967077109151
total_rewards_min            71.08062461020931
Number of train steps total  836000
Number of env steps total    875072
Number of rollouts total     0
Train Time (s)               205.37851955275983
(Previous) Eval Time (s)     41.84534236602485
Sample Time (s)              10.536700931377709
Epoch Time (s)               257.7605628501624
Total Train Time (s)         44798.932436257135
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:38:20.654181 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #208 | Epoch Duration: 257.90867805480957
2020-01-12 04:38:20.654390 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0616748
Z variance train             0.011075007
KL Divergence                23.77297
KL Loss                      2.3772972
QF Loss                      572.0205
VF Loss                      155.0869
Policy Loss                  -1053.5979
Q Predictions Mean           1049.4283
Q Predictions Std            413.61087
Q Predictions Max            1585.508
Q Predictions Min            256.3982
V Predictions Mean           1046.7615
V Predictions Std            412.3134
V Predictions Max            1566.7753
V Predictions Min            251.62424
Log Pis Mean                 0.06711359
Log Pis Std                  2.960723
Log Pis Max                  9.493292
Log Pis Min                  -6.4452653
Policy mu Mean               0.003030764
Policy mu Std                0.5743273
Policy mu Max                2.0490935
Policy mu Min                -2.7422278
Policy log std Mean          -1.0371088
Policy log std Std           0.24427164
Policy log std Max           -0.39227456
Policy log std Min           -2.4542031
Z mean eval                  1.1074181
Z variance eval              0.008989976
total_rewards                [3757.74952428 4218.13249888 1553.11230952 4177.99964408 4074.41639717
    8.45256785  579.00149359  135.63850406 4305.22945825 1398.96146465]
total_rewards_mean           2420.8693862318905
total_rewards_std            1749.9071721042992
total_rewards_max            4305.229458249382
total_rewards_min            8.452567850110945
Number of train steps total  840000
Number of env steps total    883867
Number of rollouts total     0
Train Time (s)               205.54892200790346
(Previous) Eval Time (s)     30.56918438896537
Sample Time (s)              10.226212279405445
Epoch Time (s)               246.34431867627427
Total Train Time (s)         45045.365993167274
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:42:27.090864 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #209 | Epoch Duration: 246.4362759590149
2020-01-12 04:42:27.091162 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #209 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1073405
Z variance train             0.008991847
KL Divergence                22.837877
KL Loss                      2.2837877
QF Loss                      1280.7043
VF Loss                      316.42267
Policy Loss                  -987.3376
Q Predictions Mean           978.92175
Q Predictions Std            436.90308
Q Predictions Max            1555.2686
Q Predictions Min            230.3491
V Predictions Mean           986.21594
V Predictions Std            433.0945
V Predictions Max            1546.3889
V Predictions Min            227.34589
Log Pis Mean                 0.08353792
Log Pis Std                  3.4092457
Log Pis Max                  18.056087
Log Pis Min                  -8.836494
Policy mu Mean               0.042647902
Policy mu Std                0.5903807
Policy mu Max                3.2628944
Policy mu Min                -2.6540358
Policy log std Mean          -1.0181243
Policy log std Std           0.24961235
Policy log std Max           -0.35758466
Policy log std Min           -2.628148
Z mean eval                  1.2169425
Z variance eval              0.019074976
total_rewards                [495.69039711  44.50370986 279.76901282  -3.01727325 305.83548624
 301.28156747  49.40786147  28.57613546 267.56959426 193.18207898]
total_rewards_mean           196.27985704275503
total_rewards_std            154.00908898207643
total_rewards_max            495.6903971081427
total_rewards_min            -3.017273246004625
Number of train steps total  844000
Number of env steps total    889989
Number of rollouts total     0
Train Time (s)               204.04257826693356
(Previous) Eval Time (s)     11.310318551026285
Sample Time (s)              10.018163693137467
Epoch Time (s)               225.3710605110973
Total Train Time (s)         45270.82816301985
Epoch                        210
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:46:12.561320 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #210 | Epoch Duration: 225.46998286247253
2020-01-12 04:46:12.561498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2171797
Z variance train             0.018714625
KL Divergence                21.931581
KL Loss                      2.1931581
QF Loss                      2005.2443
VF Loss                      410.82104
Policy Loss                  -1028.7341
Q Predictions Mean           1020.68054
Q Predictions Std            414.85736
Q Predictions Max            1618.569
Q Predictions Min            251.92545
V Predictions Mean           1032.87
V Predictions Std            414.75003
V Predictions Max            1603.9565
V Predictions Min            270.1253
Log Pis Mean                 0.14646918
Log Pis Std                  3.8739102
Log Pis Max                  34.213154
Log Pis Min                  -8.297794
Policy mu Mean               0.042713962
Policy mu Std                0.6769335
Policy mu Max                3.87936
Policy mu Min                -6.48065
Policy log std Mean          -0.96896005
Policy log std Std           0.23167212
Policy log std Max           0.06373584
Policy log std Min           -1.9723791
Z mean eval                  1.097008
Z variance eval              0.011795339
total_rewards                [4358.4856438  4224.90340167 4133.04248921 4442.27738831 4101.61035889
 4259.30365988 4318.33393389 2865.86207081 3642.64842274  550.48610954]
total_rewards_mean           3689.695347874248
total_rewards_std            1136.728988676821
total_rewards_max            4442.277388314046
total_rewards_min            550.4861095352584
Number of train steps total  848000
Number of env steps total    896136
Number of rollouts total     0
Train Time (s)               202.81142619531602
(Previous) Eval Time (s)     45.041252282913774
Sample Time (s)              9.471636774484068
Epoch Time (s)               257.32431525271386
Total Train Time (s)         45528.245331084356
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:50:29.975091 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #211 | Epoch Duration: 257.4134533405304
2020-01-12 04:50:29.975282 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1008747
Z variance train             0.0118227275
KL Divergence                21.284819
KL Loss                      2.1284819
QF Loss                      1205.9005
VF Loss                      107.76449
Policy Loss                  -1018.32794
Q Predictions Mean           1011.82336
Q Predictions Std            444.31323
Q Predictions Max            1562.1334
Q Predictions Min            260.2445
V Predictions Mean           1019.874
V Predictions Std            444.85468
V Predictions Max            1566.1576
V Predictions Min            263.78586
Log Pis Mean                 -0.057303432
Log Pis Std                  3.6551037
Log Pis Max                  21.362072
Log Pis Min                  -11.768448
Policy mu Mean               0.043241046
Policy mu Std                0.6072081
Policy mu Max                2.7575085
Policy mu Min                -3.947633
Policy log std Mean          -0.99961627
Policy log std Std           0.24536
Policy log std Max           0.12437451
Policy log std Min           -2.2982013
Z mean eval                  1.1154597
Z variance eval              0.010472023
total_rewards                [ 837.36532592 3921.45141764 4027.76453152 2048.73423901 1278.05377802
 3951.71796961 4030.38359507 3940.63519545 3823.47419128 4015.98790842]
total_rewards_mean           3187.5568151939847
total_rewards_std            1210.916360547177
total_rewards_max            4030.3835950690745
total_rewards_min            837.3653259171762
Number of train steps total  852000
Number of env steps total    904701
Number of rollouts total     0
Train Time (s)               204.63354357006028
(Previous) Eval Time (s)     38.55477775912732
Sample Time (s)              10.312967689707875
Epoch Time (s)               253.50128901889548
Total Train Time (s)         45781.854577702936
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:54:43.586768 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #212 | Epoch Duration: 253.61134266853333
2020-01-12 04:54:43.586967 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1115785
Z variance train             0.01054292
KL Divergence                21.342451
KL Loss                      2.1342452
QF Loss                      1469.7224
VF Loss                      140.92561
Policy Loss                  -1013.5593
Q Predictions Mean           1007.64764
Q Predictions Std            428.9654
Q Predictions Max            1562.7859
Q Predictions Min            209.16904
V Predictions Mean           1011.5989
V Predictions Std            427.96634
V Predictions Max            1562.9441
V Predictions Min            210.74388
Log Pis Mean                 0.3508381
Log Pis Std                  3.4594216
Log Pis Max                  16.363071
Log Pis Min                  -10.694624
Policy mu Mean               0.021777688
Policy mu Std                0.61321574
Policy mu Max                2.4874074
Policy mu Min                -3.315232
Policy log std Mean          -1.0385113
Policy log std Std           0.26299548
Policy log std Max           -0.39194417
Policy log std Min           -2.2238524
Z mean eval                  1.1579823
Z variance eval              0.003737995
total_rewards                [2631.60742875 4662.67397339  972.76515893 4550.32751263 1188.89913101
 3288.05662771 4281.98810265 4597.78708195 4385.02317827 4313.22206553]
total_rewards_mean           3487.2350260827634
total_rewards_std            1350.6197114633064
total_rewards_max            4662.673973391336
total_rewards_min            972.7651589299861
Number of train steps total  856000
Number of env steps total    911606
Number of rollouts total     0
Train Time (s)               199.2328704278916
(Previous) Eval Time (s)     38.98539330903441
Sample Time (s)              10.248023234307766
Epoch Time (s)               248.46628697123379
Total Train Time (s)         46030.406586348545
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:58:52.143805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #213 | Epoch Duration: 248.55666828155518
2020-01-12 04:58:52.144085 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #213 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.153847
Z variance train             0.0037440688
KL Divergence                24.768639
KL Loss                      2.4768639
QF Loss                      837.84375
VF Loss                      334.24014
Policy Loss                  -1011.5968
Q Predictions Mean           1002.22906
Q Predictions Std            427.7038
Q Predictions Max            1571.7783
Q Predictions Min            -56.320286
V Predictions Mean           1012.9717
V Predictions Std            423.48608
V Predictions Max            1568.55
V Predictions Min            260.41327
Log Pis Mean                 0.38395327
Log Pis Std                  3.6215339
Log Pis Max                  19.550737
Log Pis Min                  -7.626154
Policy mu Mean               0.024925683
Policy mu Std                0.63775367
Policy mu Max                3.434728
Policy mu Min                -3.0435798
Policy log std Mean          -1.0096605
Policy log std Std           0.24470344
Policy log std Max           -0.38204247
Policy log std Min           -2.2795744
Z mean eval                  1.1515275
Z variance eval              0.0040217945
total_rewards                [ 4.12297647e+03  1.90956072e+03  5.11821148e+02  1.93914422e+03
 -3.04089261e-01  4.06864700e+03  3.84147733e+03  4.01174472e+03
  3.76893835e+02  4.09939540e+03]
total_rewards_mean           2488.1356762362902
total_rewards_std            1646.5549145160992
total_rewards_max            4122.976474449612
total_rewards_min            -0.3040892613555466
Number of train steps total  860000
Number of env steps total    919759
Number of rollouts total     0
Train Time (s)               199.14890589891002
(Previous) Eval Time (s)     35.52008660836145
Sample Time (s)              11.276456259656698
Epoch Time (s)               245.94544876692817
Total Train Time (s)         46276.44324671896
Epoch                        214
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:02:58.183045 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #214 | Epoch Duration: 246.03870677947998
2020-01-12 05:02:58.183326 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.146471
Z variance train             0.00403482
KL Divergence                25.849503
KL Loss                      2.5849502
QF Loss                      794.0232
VF Loss                      351.5377
Policy Loss                  -1019.1362
Q Predictions Mean           1008.81573
Q Predictions Std            445.60443
Q Predictions Max            1623.296
Q Predictions Min            -2.1182706
V Predictions Mean           1010.22375
V Predictions Std            438.2412
V Predictions Max            1619.0619
V Predictions Min            82.59781
Log Pis Mean                 0.20751819
Log Pis Std                  3.3801398
Log Pis Max                  12.1266575
Log Pis Min                  -7.5099072
Policy mu Mean               0.03653471
Policy mu Std                0.5954603
Policy mu Max                3.2701557
Policy mu Min                -3.0754352
Policy log std Mean          -1.025783
Policy log std Std           0.27019534
Policy log std Max           -0.4445312
Policy log std Min           -2.41654
Z mean eval                  1.0924314
Z variance eval              0.007276149
total_rewards                [4073.15951757 3978.25713169 3971.23429769 4004.42358477 4139.38754322
 3909.70652177 4337.72087299 4046.81012016 3753.72011277 4061.96223336]
total_rewards_mean           4027.638193600093
total_rewards_std            143.99822208802678
total_rewards_max            4337.720872992331
total_rewards_min            3753.7201127736157
Number of train steps total  864000
Number of env steps total    926206
Number of rollouts total     0
Train Time (s)               203.73669560113922
(Previous) Eval Time (s)     44.27774130506441
Sample Time (s)              11.296959072351456
Epoch Time (s)               259.3113959785551
Total Train Time (s)         46535.85109985387
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:07:17.601616 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #215 | Epoch Duration: 259.418092250824
2020-01-12 05:07:17.601940 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0961888
Z variance train             0.007269252
KL Divergence                25.399847
KL Loss                      2.5399847
QF Loss                      867.73425
VF Loss                      122.30329
Policy Loss                  -1036.0203
Q Predictions Mean           1026.1699
Q Predictions Std            433.69467
Q Predictions Max            1581.5757
Q Predictions Min            158.55072
V Predictions Mean           1036.677
V Predictions Std            427.4563
V Predictions Max            1570.6138
V Predictions Min            250.5197
Log Pis Mean                 0.45320103
Log Pis Std                  3.4424996
Log Pis Max                  15.054305
Log Pis Min                  -6.87384
Policy mu Mean               0.01083613
Policy mu Std                0.6066134
Policy mu Max                2.186657
Policy mu Min                -2.374423
Policy log std Mean          -1.0354235
Policy log std Std           0.2527386
Policy log std Max           -0.38463497
Policy log std Min           -2.424407
Z mean eval                  1.1687495
Z variance eval              0.011184109
total_rewards                [4288.41469239 4401.19063055 4118.85042359 4048.40622229 4280.52674626
 4277.37633158 3241.50235    1148.69992513 4198.58989631 4107.82884834]
total_rewards_mean           3811.138606643817
total_rewards_std            938.9274720417848
total_rewards_max            4401.190630547426
total_rewards_min            1148.6999251253892
Number of train steps total  868000
Number of env steps total    933649
Number of rollouts total     0
Train Time (s)               210.54989353567362
(Previous) Eval Time (s)     46.31152827292681
Sample Time (s)              8.947393306531012
Epoch Time (s)               265.80881511513144
Total Train Time (s)         46801.75102801202
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:11:43.505176 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #216 | Epoch Duration: 265.9029724597931
2020-01-12 05:11:43.505493 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1751037
Z variance train             0.011141726
KL Divergence                25.012154
KL Loss                      2.5012155
QF Loss                      821.29016
VF Loss                      282.88013
Policy Loss                  -1041.264
Q Predictions Mean           1032.5583
Q Predictions Std            450.5162
Q Predictions Max            1673.1411
Q Predictions Min            -22.051094
V Predictions Mean           1038.9851
V Predictions Std            440.80725
V Predictions Max            1627.5278
V Predictions Min            -8.81496
Log Pis Mean                 0.35207903
Log Pis Std                  3.4540668
Log Pis Max                  14.2189245
Log Pis Min                  -6.0721607
Policy mu Mean               0.05757387
Policy mu Std                0.58848286
Policy mu Max                2.8583746
Policy mu Min                -2.264017
Policy log std Mean          -1.0646837
Policy log std Std           0.2777624
Policy log std Max           -0.43533218
Policy log std Min           -2.5847592
Z mean eval                  1.0433466
Z variance eval              0.0022597897
total_rewards                [3878.30395252 3804.54213726 2140.41506434 1361.64612647 3263.60370117
 4014.07016288 3953.12580707 3657.13253363  886.66308927 3908.08317301]
total_rewards_mean           3086.758574762565
total_rewards_std            1117.8296015928759
total_rewards_max            4014.070162876254
total_rewards_min            886.6630892681346
Number of train steps total  872000
Number of env steps total    941956
Number of rollouts total     0
Train Time (s)               205.88646198716015
(Previous) Eval Time (s)     38.07712853793055
Sample Time (s)              10.393806212581694
Epoch Time (s)               254.3573967376724
Total Train Time (s)         47056.20264265267
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:15:57.968345 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #217 | Epoch Duration: 254.46258854866028
2020-01-12 05:15:57.968632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0464721
Z variance train             0.0022544146
KL Divergence                25.578644
KL Loss                      2.5578644
QF Loss                      968.00195
VF Loss                      375.08478
Policy Loss                  -1010.94257
Q Predictions Mean           1009.4453
Q Predictions Std            462.34473
Q Predictions Max            1579.1543
Q Predictions Min            -42.092342
V Predictions Mean           1013.1034
V Predictions Std            462.48663
V Predictions Max            1573.2135
V Predictions Min            -78.02317
Log Pis Mean                 0.3345937
Log Pis Std                  3.7682695
Log Pis Max                  14.976695
Log Pis Min                  -7.408698
Policy mu Mean               0.04212544
Policy mu Std                0.6276446
Policy mu Max                3.0239017
Policy mu Min                -3.2974644
Policy log std Mean          -1.0232579
Policy log std Std           0.2804563
Policy log std Max           -0.24457079
Policy log std Min           -2.5381336
Z mean eval                  1.0521082
Z variance eval              0.014571768
total_rewards                [4250.9289888  4093.149665   4192.93806672 2814.92176203 1840.76334399
 4347.89298786 2716.04246334  357.18675294 2133.27143624 4225.46991067]
total_rewards_mean           3097.2565377592246
total_rewards_std            1288.4603271735184
total_rewards_max            4347.892987863853
total_rewards_min            357.18675293572755
Number of train steps total  876000
Number of env steps total    948122
Number of rollouts total     0
Train Time (s)               205.68100190302357
(Previous) Eval Time (s)     34.74765460006893
Sample Time (s)              9.939169162418693
Epoch Time (s)               250.3678256655112
Total Train Time (s)         47306.77685732953
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:20:08.544852 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #218 | Epoch Duration: 250.57599687576294
2020-01-12 05:20:08.545071 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495751
Z variance train             0.014579368
KL Divergence                22.212502
KL Loss                      2.2212503
QF Loss                      968.45026
VF Loss                      242.5328
Policy Loss                  -1021.77563
Q Predictions Mean           1014.6462
Q Predictions Std            424.51578
Q Predictions Max            1612.322
Q Predictions Min            234.53094
V Predictions Mean           1021.70984
V Predictions Std            422.18372
V Predictions Max            1609.4727
V Predictions Min            205.94539
Log Pis Mean                 -0.04304814
Log Pis Std                  3.8332062
Log Pis Max                  27.269688
Log Pis Min                  -8.119073
Policy mu Mean               0.057688512
Policy mu Std                0.62670887
Policy mu Max                2.7351356
Policy mu Min                -4.9267693
Policy log std Mean          -1.0000843
Policy log std Std           0.23656622
Policy log std Max           -0.31506097
Policy log std Min           -2.1690147
Z mean eval                  1.0740663
Z variance eval              0.0053976476
total_rewards                [2904.52586513 4426.67111768 4407.77815122 4691.02338593 3418.6037692
  766.5840985  1524.73210008 4483.56742672 4359.24342816 4442.56143282]
total_rewards_mean           3542.529077544211
total_rewards_std            1319.5384336487812
total_rewards_max            4691.023385934558
total_rewards_min            766.5840984973913
Number of train steps total  880000
Number of env steps total    954435
Number of rollouts total     0
Train Time (s)               206.49325689207762
(Previous) Eval Time (s)     39.64892674004659
Sample Time (s)              10.528263337910175
Epoch Time (s)               256.6704469700344
Total Train Time (s)         47563.5420734887
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:24:25.312505 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #219 | Epoch Duration: 256.76728796958923
2020-01-12 05:24:25.312681 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0735888
Z variance train             0.005417513
KL Divergence                23.03165
KL Loss                      2.3031652
QF Loss                      849.0764
VF Loss                      137.97649
Policy Loss                  -988.3533
Q Predictions Mean           981.54486
Q Predictions Std            453.4113
Q Predictions Max            1590.8374
Q Predictions Min            150.77333
V Predictions Mean           992.8242
V Predictions Std            453.8717
V Predictions Max            1604.551
V Predictions Min            264.9234
Log Pis Mean                 -0.51283604
Log Pis Std                  3.198673
Log Pis Max                  23.13584
Log Pis Min                  -7.719927
Policy mu Mean               0.04164612
Policy mu Std                0.57146215
Policy mu Max                2.5355122
Policy mu Min                -3.9603188
Policy log std Mean          -0.9805764
Policy log std Std           0.23623653
Policy log std Max           -0.28768438
Policy log std Min           -2.2894652
Z mean eval                  1.1385696
Z variance eval              0.0046539498
total_rewards                [4131.37070902 2510.69833026  338.69012402 4182.41872676 4439.08218185
 3645.04873969  393.9269545  4040.90963851 1490.59375051 1923.89916174]
total_rewards_mean           2709.663831686005
total_rewards_std            1515.1107034504478
total_rewards_max            4439.082181852646
total_rewards_min            338.6901240217013
Number of train steps total  884000
Number of env steps total    963410
Number of rollouts total     0
Train Time (s)               209.88929771492258
(Previous) Eval Time (s)     29.711060812231153
Sample Time (s)              18.94624820444733
Epoch Time (s)               258.54660673160106
Total Train Time (s)         47822.17700816365
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:28:43.963178 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #220 | Epoch Duration: 258.65035820007324
2020-01-12 05:28:43.963365 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1461933
Z variance train             0.00459686
KL Divergence                24.271244
KL Loss                      2.4271245
QF Loss                      1011.0226
VF Loss                      329.2812
Policy Loss                  -1052.4373
Q Predictions Mean           1040.1566
Q Predictions Std            451.31177
Q Predictions Max            1629.8865
Q Predictions Min            184.50337
V Predictions Mean           1045.5614
V Predictions Std            446.61005
V Predictions Max            1626.1022
V Predictions Min            208.5603
Log Pis Mean                 0.31010002
Log Pis Std                  3.889551
Log Pis Max                  29.600441
Log Pis Min                  -7.5050325
Policy mu Mean               0.0453081
Policy mu Std                0.652374
Policy mu Max                3.4699097
Policy mu Min                -3.3075354
Policy log std Mean          -1.0060699
Policy log std Std           0.27337158
Policy log std Max           -0.3099956
Policy log std Min           -2.4379342
Z mean eval                  1.1231073
Z variance eval              0.01834666
total_rewards                [1142.50521184 4812.30898286 3665.65250617 1693.97823284  590.1757388
 2391.28058506  300.01996366 1481.61163086   87.44006838 3749.82986473]
total_rewards_mean           1991.4802785203124
total_rewards_std            1533.9770037394603
total_rewards_max            4812.308982864723
total_rewards_min            87.44006837840155
Number of train steps total  888000
Number of env steps total    971698
Number of rollouts total     0
Train Time (s)               209.07385327108204
(Previous) Eval Time (s)     23.39549088012427
Sample Time (s)              10.012084239628166
Epoch Time (s)               242.48142839083448
Total Train Time (s)         48064.80925513152
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:32:46.584943 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #221 | Epoch Duration: 242.62142634391785
2020-01-12 05:32:46.585148 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1195333
Z variance train             0.018665452
KL Divergence                23.786781
KL Loss                      2.378678
QF Loss                      729.4973
VF Loss                      372.2865
Policy Loss                  -1009.41797
Q Predictions Mean           1002.9402
Q Predictions Std            464.30176
Q Predictions Max            1620.2988
Q Predictions Min            33.6437
V Predictions Mean           1018.56396
V Predictions Std            457.25247
V Predictions Max            1622.987
V Predictions Min            124.62377
Log Pis Mean                 0.0087222755
Log Pis Std                  3.907423
Log Pis Max                  31.298904
Log Pis Min                  -6.3894753
Policy mu Mean               0.06692888
Policy mu Std                0.6127277
Policy mu Max                3.4367518
Policy mu Min                -2.9937072
Policy log std Mean          -1.0218246
Policy log std Std           0.26601982
Policy log std Max           -0.400828
Policy log std Min           -2.540533
Z mean eval                  1.1588279
Z variance eval              0.007914303
total_rewards                [3666.88111388 4550.51734844 3996.41575238 4373.91337706 4257.99421382
 4512.18873713 4133.22589969 4297.1283511  4213.65741204 4269.31974509]
total_rewards_mean           4227.124195063111
total_rewards_std            243.1301981984001
total_rewards_max            4550.517348435567
total_rewards_min            3666.8811138830483
Number of train steps total  892000
Number of env steps total    981309
Number of rollouts total     0
Train Time (s)               204.82119309296831
(Previous) Eval Time (s)     45.596233684103936
Sample Time (s)              9.916075279004872
Epoch Time (s)               260.3335020560771
Total Train Time (s)         48325.22959463252
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:37:07.007575 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #222 | Epoch Duration: 260.4222643375397
2020-01-12 05:37:07.007754 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1554269
Z variance train             0.0079140235
KL Divergence                23.953678
KL Loss                      2.3953679
QF Loss                      1229.1243
VF Loss                      141.92311
Policy Loss                  -1035.3713
Q Predictions Mean           1024.6704
Q Predictions Std            443.43027
Q Predictions Max            1622.0609
Q Predictions Min            58.611782
V Predictions Mean           1038.3873
V Predictions Std            436.82346
V Predictions Max            1604.4719
V Predictions Min            167.75261
Log Pis Mean                 0.41758797
Log Pis Std                  3.4446263
Log Pis Max                  17.119938
Log Pis Min                  -6.5315056
Policy mu Mean               0.06804933
Policy mu Std                0.64360917
Policy mu Max                4.495658
Policy mu Min                -3.688927
Policy log std Mean          -1.0054765
Policy log std Std           0.2556917
Policy log std Max           -0.3971638
Policy log std Min           -2.3702111
Z mean eval                  1.0802388
Z variance eval              0.0052996166
total_rewards                [4400.36998697 2533.5162211  4532.80268677 4516.83622021 4210.82926113
 4526.06062521 4436.74380352 3004.72389997 4517.42976752 4422.39124675]
total_rewards_mean           4110.170371915223
total_rewards_std            684.7737164129987
total_rewards_max            4532.802686769267
total_rewards_min            2533.51622110363
Number of train steps total  896000
Number of env steps total    991166
Number of rollouts total     0
Train Time (s)               207.52251394093037
(Previous) Eval Time (s)     46.46736854221672
Sample Time (s)              11.38107355684042
Epoch Time (s)               265.3709560399875
Total Train Time (s)         48590.70657584071
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:41:32.487789 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #223 | Epoch Duration: 265.47983598709106
2020-01-12 05:41:32.488088 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0796385
Z variance train             0.005318365
KL Divergence                25.61446
KL Loss                      2.561446
QF Loss                      997.70667
VF Loss                      257.9181
Policy Loss                  -1104.2643
Q Predictions Mean           1096.708
Q Predictions Std            423.2136
Q Predictions Max            1658.1288
Q Predictions Min            197.93192
V Predictions Mean           1104.4669
V Predictions Std            419.60983
V Predictions Max            1669.7811
V Predictions Min            259.01285
Log Pis Mean                 0.58248097
Log Pis Std                  3.2822008
Log Pis Max                  20.92744
Log Pis Min                  -6.960273
Policy mu Mean               0.05169171
Policy mu Std                0.6565684
Policy mu Max                3.9908235
Policy mu Min                -2.232233
Policy log std Mean          -1.0076356
Policy log std Std           0.25251618
Policy log std Max           -0.36727965
Policy log std Min           -2.231968
Z mean eval                  1.3445133
Z variance eval              0.022270137
total_rewards                [4193.52882187 4194.12060585  512.55699313 4223.9657479  1394.75763802
 4249.63903993  738.4802953  3953.61481409 4185.90299187 3983.01353275]
total_rewards_mean           3162.9580480702057
total_rewards_std            1510.1417665570534
total_rewards_max            4249.639039933179
total_rewards_min            512.5569931264445
Number of train steps total  900000
Number of env steps total    1001167
Number of rollouts total     0
Train Time (s)               209.9396660523489
(Previous) Eval Time (s)     35.14909166842699
Sample Time (s)              10.426339489873499
Epoch Time (s)               255.5150972106494
Total Train Time (s)         48846.325924427714
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:45:48.109664 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #224 | Epoch Duration: 255.62140369415283
2020-01-12 05:45:48.109861 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3379835
Z variance train             0.022147695
KL Divergence                24.838125
KL Loss                      2.4838126
QF Loss                      862.88196
VF Loss                      262.0074
Policy Loss                  -1045.3136
Q Predictions Mean           1031.9104
Q Predictions Std            461.784
Q Predictions Max            1649.146
Q Predictions Min            -47.80325
V Predictions Mean           1043.8014
V Predictions Std            449.51077
V Predictions Max            1638.9116
V Predictions Min            251.00145
Log Pis Mean                 0.5608292
Log Pis Std                  4.089122
Log Pis Max                  22.335602
Log Pis Min                  -6.8701663
Policy mu Mean               0.043867484
Policy mu Std                0.65217453
Policy mu Max                3.9250886
Policy mu Min                -3.795669
Policy log std Mean          -1.0323727
Policy log std Std           0.26781443
Policy log std Max           -0.37757063
Policy log std Min           -2.476798
Z mean eval                  1.0723964
Z variance eval              0.021203572
total_rewards                [4068.17216244 4332.30573644  396.70377375 4081.36840649 4110.98428647
 4425.40086544 4391.21770016 4267.58777265 4273.87647845 4304.17254272]
total_rewards_mean           3865.178972500829
total_rewards_std            1162.2882231903916
total_rewards_max            4425.400865441531
total_rewards_min            396.703773749958
Number of train steps total  904000
Number of env steps total    1010158
Number of rollouts total     0
Train Time (s)               206.13236469775438
(Previous) Eval Time (s)     44.35319565190002
Sample Time (s)              10.821984516922385
Epoch Time (s)               261.3075448665768
Total Train Time (s)         49107.74018364493
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:09.529834 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #225 | Epoch Duration: 261.4198257923126
2020-01-12 05:50:09.530017 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0739233
Z variance train             0.021381527
KL Divergence                21.488922
KL Loss                      2.1488922
QF Loss                      815.4199
VF Loss                      422.84717
Policy Loss                  -970.82855
Q Predictions Mean           962.5729
Q Predictions Std            483.2363
Q Predictions Max            1660.401
Q Predictions Min            91.09644
V Predictions Mean           972.47925
V Predictions Std            481.51215
V Predictions Max            1670.6226
V Predictions Min            262.1994
Log Pis Mean                 -0.026040256
Log Pis Std                  3.712411
Log Pis Max                  20.032293
Log Pis Min                  -13.461827
Policy mu Mean               0.045094773
Policy mu Std                0.57206255
Policy mu Max                3.3849225
Policy mu Min                -4.2192793
Policy log std Mean          -1.013922
Policy log std Std           0.25297722
Policy log std Max           -0.20457226
Policy log std Min           -2.5141072
Z mean eval                  1.0284373
Z variance eval              0.0115217175
total_rewards                [4505.08516264 4420.57689872 4253.83521963 4368.23849711 4718.75249947
 4546.97077292 2472.19637792 4117.96154341 4765.85997049 4693.448212  ]
total_rewards_mean           4286.29251543234
total_rewards_std            635.8998936326944
total_rewards_max            4765.859970493647
total_rewards_min            2472.1963779238827
Number of train steps total  908000
Number of env steps total    1020090
Number of rollouts total     0
Train Time (s)               204.24854559917003
(Previous) Eval Time (s)     40.855059375055134
Sample Time (s)              9.468322264961898
Epoch Time (s)               254.57192723918706
Total Train Time (s)         49362.40231927205
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:54:24.192022 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #226 | Epoch Duration: 254.6618492603302
2020-01-12 05:54:24.192211 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0281047
Z variance train             0.01148701
KL Divergence                21.221697
KL Loss                      2.1221697
QF Loss                      904.23083
VF Loss                      110.921974
Policy Loss                  -1070.9828
Q Predictions Mean           1069.4552
Q Predictions Std            452.2914
Q Predictions Max            1645.5898
Q Predictions Min            235.26524
V Predictions Mean           1070.031
V Predictions Std            451.3463
V Predictions Max            1640.8944
V Predictions Min            237.08353
Log Pis Mean                 -0.053078666
Log Pis Std                  3.145508
Log Pis Max                  10.548838
Log Pis Min                  -8.206226
Policy mu Mean               0.06363485
Policy mu Std                0.57326585
Policy mu Max                2.8579042
Policy mu Min                -2.3863502
Policy log std Mean          -1.0357661
Policy log std Std           0.25738448
Policy log std Max           -0.37389374
Policy log std Min           -2.194736
Z mean eval                  1.0770484
Z variance eval              0.0105329435
total_rewards                [4635.24313834 2158.13892339  343.79664777 4353.35076548 4217.20413825
 4500.49663191 2904.15277017  884.2101142  4551.22176151 4657.91946024]
total_rewards_mean           3320.573435126571
total_rewards_std            1568.9444522499696
total_rewards_max            4657.919460242085
total_rewards_min            343.79664776686616
Number of train steps total  912000
Number of env steps total    1030033
Number of rollouts total     0
Train Time (s)               212.01527740294114
(Previous) Eval Time (s)     35.38067054282874
Sample Time (s)              11.711617507506162
Epoch Time (s)               259.10756545327604
Total Train Time (s)         49621.62579903519
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:58:43.418796 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #227 | Epoch Duration: 259.22638273239136
2020-01-12 05:58:43.419078 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0802013
Z variance train             0.010561393
KL Divergence                21.720366
KL Loss                      2.1720366
QF Loss                      1099.4983
VF Loss                      202.88965
Policy Loss                  -1055.187
Q Predictions Mean           1052.8999
Q Predictions Std            465.97467
Q Predictions Max            1622.4818
Q Predictions Min            164.56366
V Predictions Mean           1053.9211
V Predictions Std            465.1022
V Predictions Max            1613.0828
V Predictions Min            156.9315
Log Pis Mean                 0.043703884
Log Pis Std                  3.659933
Log Pis Max                  18.874084
Log Pis Min                  -8.052155
Policy mu Mean               0.020314902
Policy mu Std                0.6321726
Policy mu Max                4.8186994
Policy mu Min                -5.3599577
Policy log std Mean          -1.0243336
Policy log std Std           0.25060353
Policy log std Max           0.005711913
Policy log std Min           -2.573178
Z mean eval                  1.1224719
Z variance eval              0.0069737956
total_rewards                [1763.61686297 4092.83338997   47.41561658 4660.70451241 3994.66825483
 4311.31388494 4303.36364692 1842.09525842 3903.60199715 1679.10663379]
total_rewards_mean           3059.872005799826
total_rewards_std            1499.0810722093752
total_rewards_max            4660.704512414456
total_rewards_min            47.41561658344263
Number of train steps total  916000
Number of env steps total    1037010
Number of rollouts total     0
Train Time (s)               209.5931744147092
(Previous) Eval Time (s)     30.868337919935584
Sample Time (s)              10.882208828348666
Epoch Time (s)               251.34372116299346
Total Train Time (s)         49873.05677899346
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:02:54.851787 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #228 | Epoch Duration: 251.43254351615906
2020-01-12 06:02:54.852003 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1266556
Z variance train             0.00700664
KL Divergence                22.679573
KL Loss                      2.2679574
QF Loss                      859.7546
VF Loss                      158.09224
Policy Loss                  -1034.7334
Q Predictions Mean           1025.8372
Q Predictions Std            458.95197
Q Predictions Max            1663.0524
Q Predictions Min            7.3792906
V Predictions Mean           1029.0796
V Predictions Std            452.13824
V Predictions Max            1638.8085
V Predictions Min            248.97795
Log Pis Mean                 -0.025154889
Log Pis Std                  3.7789981
Log Pis Max                  27.896376
Log Pis Min                  -7.801692
Policy mu Mean               0.049216505
Policy mu Std                0.59611195
Policy mu Max                3.2827609
Policy mu Min                -4.972883
Policy log std Mean          -1.0236614
Policy log std Std           0.25877765
Policy log std Max           -0.08162701
Policy log std Min           -2.318546
Z mean eval                  1.12371
Z variance eval              0.0131494375
total_rewards                [4227.38013151 1022.18915123 4143.47847299 4558.04638297 3408.03758327
 4269.22853533 1674.4026523  3177.62301393 3140.08045988 3659.51895711]
total_rewards_mean           3327.998534051375
total_rewards_std            1099.9182108062837
total_rewards_max            4558.046382969844
total_rewards_min            1022.1891512291659
Number of train steps total  920000
Number of env steps total    1048174
Number of rollouts total     0
Train Time (s)               202.61176841985434
(Previous) Eval Time (s)     36.883470313157886
Sample Time (s)              10.089407454244792
Epoch Time (s)               249.58464618725702
Total Train Time (s)         50122.74193739984
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:07:04.540596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #229 | Epoch Duration: 249.68843722343445
2020-01-12 06:07:04.540805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1243107
Z variance train             0.0131869
KL Divergence                20.899117
KL Loss                      2.0899117
QF Loss                      824.02905
VF Loss                      113.967865
Policy Loss                  -1067.162
Q Predictions Mean           1062.1312
Q Predictions Std            457.49408
Q Predictions Max            1643.6047
Q Predictions Min            254.74017
V Predictions Mean           1070.85
V Predictions Std            458.9363
V Predictions Max            1639.1858
V Predictions Min            239.39995
Log Pis Mean                 0.21729326
Log Pis Std                  3.4783459
Log Pis Max                  13.642759
Log Pis Min                  -9.413133
Policy mu Mean               0.011962475
Policy mu Std                0.6008244
Policy mu Max                2.4401221
Policy mu Min                -2.966458
Policy log std Mean          -1.0207783
Policy log std Std           0.25637078
Policy log std Max           0.15718472
Policy log std Min           -2.2876618
Z mean eval                  1.2288837
Z variance eval              0.012946015
total_rewards                [4688.15305643 4671.74547619 3445.65822915 4289.75935776 1654.65263152
 4738.66153554   53.22470982  460.63274642 3537.62885588 1734.85305397]
total_rewards_mean           2927.496965268184
total_rewards_std            1711.973508990874
total_rewards_max            4738.661535540308
total_rewards_min            53.224709823476466
Number of train steps total  924000
Number of env steps total    1055244
Number of rollouts total     0
Train Time (s)               207.34677034942433
(Previous) Eval Time (s)     32.675231316592544
Sample Time (s)              9.763061898294836
Epoch Time (s)               249.7850635643117
Total Train Time (s)         50372.61693414347
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:11:14.419492 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #230 | Epoch Duration: 249.87851977348328
2020-01-12 06:11:14.419735 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2256613
Z variance train             0.013049079
KL Divergence                23.570759
KL Loss                      2.357076
QF Loss                      1218.4313
VF Loss                      222.20128
Policy Loss                  -1079.337
Q Predictions Mean           1066.402
Q Predictions Std            480.09357
Q Predictions Max            1696.3812
Q Predictions Min            -48.224194
V Predictions Mean           1068.1504
V Predictions Std            473.33105
V Predictions Max            1655.7228
V Predictions Min            -26.864155
Log Pis Mean                 -0.21015729
Log Pis Std                  3.6485615
Log Pis Max                  12.013443
Log Pis Min                  -8.361048
Policy mu Mean               0.03307284
Policy mu Std                0.57248497
Policy mu Max                2.6483083
Policy mu Min                -2.574845
Policy log std Mean          -1.054879
Policy log std Std           0.29055846
Policy log std Max           -0.3200271
Policy log std Min           -2.552537
Z mean eval                  1.1642087
Z variance eval              0.016612824
total_rewards                [1393.95357874  876.64472656  423.69200903 3518.56669503  987.93257695
 2113.97820016    5.75321467 1788.91816849 2651.54441472 4582.07376056]
total_rewards_mean           1834.3057344888523
total_rewards_std            1352.6243912162506
total_rewards_max            4582.073760556785
total_rewards_min            5.753214669749417
Number of train steps total  928000
Number of env steps total    1065185
Number of rollouts total     0
Train Time (s)               207.85020830389112
(Previous) Eval Time (s)     21.538431871216744
Sample Time (s)              11.09742520423606
Epoch Time (s)               240.48606537934393
Total Train Time (s)         50613.22039171308
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:15:15.025104 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #231 | Epoch Duration: 240.60520243644714
2020-01-12 06:15:15.025269 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.154978
Z variance train             0.01670067
KL Divergence                20.681538
KL Loss                      2.0681539
QF Loss                      15100.12
VF Loss                      373.6317
Policy Loss                  -1033.7362
Q Predictions Mean           1028.391
Q Predictions Std            463.13864
Q Predictions Max            1615.6959
Q Predictions Min            243.84474
V Predictions Mean           1034.8386
V Predictions Std            462.23718
V Predictions Max            1608.9161
V Predictions Min            246.26608
Log Pis Mean                 -0.20454124
Log Pis Std                  3.7295754
Log Pis Max                  29.611221
Log Pis Min                  -8.20463
Policy mu Mean               0.082387686
Policy mu Std                0.6004749
Policy mu Max                3.152226
Policy mu Min                -5.4762254
Policy log std Mean          -0.9917958
Policy log std Std           0.23830669
Policy log std Max           -0.29566473
Policy log std Min           -2.3399258
Z mean eval                  1.2399298
Z variance eval              0.008124217
total_rewards                [4.14513859e+03 4.41969613e+03 4.42150434e+03 4.19001543e+03
 4.32434968e+03 3.05699806e+00 4.28909200e+03 9.14479227e+02
 4.16779318e+03 4.36608401e+03]
total_rewards_mean           3524.1209586962214
total_rewards_std            1548.9775323121228
total_rewards_max            4421.504336293312
total_rewards_min            3.056998063492823
Number of train steps total  932000
Number of env steps total    1073696
Number of rollouts total     0
Train Time (s)               204.59201650461182
(Previous) Eval Time (s)     42.07166320923716
Sample Time (s)              10.312647738028318
Epoch Time (s)               256.9763274518773
Total Train Time (s)         50870.29703039955
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:19:32.103115 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #232 | Epoch Duration: 257.0777292251587
2020-01-12 06:19:32.103232 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2372901
Z variance train             0.008107947
KL Divergence                24.036526
KL Loss                      2.4036527
QF Loss                      1138.4669
VF Loss                      127.26243
Policy Loss                  -1088.9086
Q Predictions Mean           1083.1862
Q Predictions Std            474.98492
Q Predictions Max            1714.3342
Q Predictions Min            236.60725
V Predictions Mean           1085.6362
V Predictions Std            474.65137
V Predictions Max            1726.0715
V Predictions Min            221.90567
Log Pis Mean                 0.2084252
Log Pis Std                  4.2485623
Log Pis Max                  31.248018
Log Pis Min                  -10.462289
Policy mu Mean               0.02123025
Policy mu Std                0.65758413
Policy mu Max                5.336017
Policy mu Min                -4.0474625
Policy log std Mean          -1.034178
Policy log std Std           0.27926627
Policy log std Max           -0.18907619
Policy log std Min           -2.3924317
Z mean eval                  1.1197246
Z variance eval              0.024493586
total_rewards                [3541.79657501 1051.371649     25.51820039 4426.98521077  260.57249999
  100.5538786  2180.39712568 4717.62163933 3268.76823796 3311.87851085]
total_rewards_mean           2288.546352756584
total_rewards_std            1720.9180748274227
total_rewards_max            4717.621639330618
total_rewards_min            25.51820038787583
Number of train steps total  936000
Number of env steps total    1082226
Number of rollouts total     0
Train Time (s)               202.6937891417183
(Previous) Eval Time (s)     26.882614394184202
Sample Time (s)              9.619185937102884
Epoch Time (s)               239.19558947300538
Total Train Time (s)         51109.810189243406
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:23:31.631446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #233 | Epoch Duration: 239.52810406684875
2020-01-12 06:23:31.631641 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1180613
Z variance train             0.024216257
KL Divergence                21.941586
KL Loss                      2.1941586
QF Loss                      821.6654
VF Loss                      215.04109
Policy Loss                  -1034.6815
Q Predictions Mean           1027.4424
Q Predictions Std            484.52304
Q Predictions Max            1661.1934
Q Predictions Min            213.83183
V Predictions Mean           1041.3215
V Predictions Std            484.0267
V Predictions Max            1663.7933
V Predictions Min            256.8251
Log Pis Mean                 0.07223189
Log Pis Std                  3.649014
Log Pis Max                  23.043442
Log Pis Min                  -7.9621196
Policy mu Mean               0.070710674
Policy mu Std                0.62417054
Policy mu Max                5.062669
Policy mu Min                -2.8860564
Policy log std Mean          -1.0122007
Policy log std Std           0.26791266
Policy log std Max           -0.2958845
Policy log std Min           -2.2528439
Z mean eval                  1.144723
Z variance eval              0.009869931
total_rewards                [4282.41582035 4370.26715154 1559.24279315 4340.67889758 4651.90751025
 4051.54693968 4337.39449478   60.0597412  4722.31299047 4533.88463458]
total_rewards_mean           3690.9710973589636
total_rewards_std            1490.1878848874385
total_rewards_max            4722.312990467597
total_rewards_min            60.05974119873201
Number of train steps total  940000
Number of env steps total    1092663
Number of rollouts total     0
Train Time (s)               196.5734019759111
(Previous) Eval Time (s)     39.86942503321916
Sample Time (s)              10.238363190554082
Epoch Time (s)               246.68119019968435
Total Train Time (s)         51356.59801640129
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:27:38.412544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #234 | Epoch Duration: 246.78073859214783
2020-01-12 06:27:38.412722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1475207
Z variance train             0.009830517
KL Divergence                23.260603
KL Loss                      2.3260603
QF Loss                      706.6415
VF Loss                      219.13254
Policy Loss                  -1073.7043
Q Predictions Mean           1067.3011
Q Predictions Std            442.63083
Q Predictions Max            1669.113
Q Predictions Min            112.236755
V Predictions Mean           1074.7119
V Predictions Std            443.03394
V Predictions Max            1656.9294
V Predictions Min            152.06583
Log Pis Mean                 -0.040166616
Log Pis Std                  2.839037
Log Pis Max                  9.8781395
Log Pis Min                  -7.3072667
Policy mu Mean               0.016864236
Policy mu Std                0.57227325
Policy mu Max                2.922759
Policy mu Min                -2.0493996
Policy log std Mean          -1.0136241
Policy log std Std           0.24962065
Policy log std Max           -0.450625
Policy log std Min           -2.1116507
Z mean eval                  1.1148401
Z variance eval              0.009779643
total_rewards                [4064.69469616  680.70866464 1932.0072748  4095.39958276 3874.78963374
 3216.4207359  2482.31804537    9.89900237 3842.78083058 4609.45864239]
total_rewards_mean           2880.847710871153
total_rewards_std            1484.3400281484285
total_rewards_max            4609.458642388962
total_rewards_min            9.899002369396541
Number of train steps total  944000
Number of env steps total    1100639
Number of rollouts total     0
Train Time (s)               201.23089620377868
(Previous) Eval Time (s)     32.84587798221037
Sample Time (s)              10.018345633521676
Epoch Time (s)               244.09511981951073
Total Train Time (s)         51600.7794560031
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:31:42.596638 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #235 | Epoch Duration: 244.18376803398132
2020-01-12 06:31:42.596829 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1167371
Z variance train             0.009778484
KL Divergence                24.112709
KL Loss                      2.4112709
QF Loss                      5929.5776
VF Loss                      176.84183
Policy Loss                  -1097.6195
Q Predictions Mean           1093.8584
Q Predictions Std            465.34155
Q Predictions Max            1701.3385
Q Predictions Min            -2.902762
V Predictions Mean           1101.6864
V Predictions Std            459.97775
V Predictions Max            1688.3759
V Predictions Min            255.93645
Log Pis Mean                 0.5319326
Log Pis Std                  3.4412794
Log Pis Max                  19.683107
Log Pis Min                  -6.3986936
Policy mu Mean               0.02293138
Policy mu Std                0.6328191
Policy mu Max                2.994973
Policy mu Min                -2.7119675
Policy log std Mean          -1.0264534
Policy log std Std           0.25859943
Policy log std Max           -0.36181867
Policy log std Min           -2.337363
Z mean eval                  1.1331346
Z variance eval              0.020174047
total_rewards                [4336.58871648 4617.13243911 4445.6488372  4882.72767868 4357.55326975
 4361.79419394 1368.27200237 4119.24862519 3506.64650148 4611.60625816]
total_rewards_mean           4060.7218522351495
total_rewards_std            961.8469616315499
total_rewards_max            4882.727678680813
total_rewards_min            1368.27200236918
Number of train steps total  948000
Number of env steps total    1107861
Number of rollouts total     0
Train Time (s)               196.72556409798563
(Previous) Eval Time (s)     44.0888209156692
Sample Time (s)              10.099351519253105
Epoch Time (s)               250.91373653290793
Total Train Time (s)         51851.785546117
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:35:53.606102 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #236 | Epoch Duration: 251.00908637046814
2020-01-12 06:35:53.606375 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1249996
Z variance train             0.020211268
KL Divergence                21.100382
KL Loss                      2.1100383
QF Loss                      1351.0857
VF Loss                      105.025215
Policy Loss                  -1147.8096
Q Predictions Mean           1139.8638
Q Predictions Std            440.74222
Q Predictions Max            1699.7817
Q Predictions Min            16.72886
V Predictions Mean           1144.7793
V Predictions Std            431.72604
V Predictions Max            1678.0475
V Predictions Min            245.47733
Log Pis Mean                 0.54120135
Log Pis Std                  3.7849681
Log Pis Max                  34.791317
Log Pis Min                  -8.01747
Policy mu Mean               0.06140277
Policy mu Std                0.6191475
Policy mu Max                4.1563587
Policy mu Min                -3.6622083
Policy log std Mean          -1.0354879
Policy log std Std           0.261569
Policy log std Max           -0.41689605
Policy log std Min           -2.498847
Z mean eval                  1.1616056
Z variance eval              0.010972376
total_rewards                [4219.04014231   76.67324279 4421.01820373 1150.47030592 2704.23035975
  575.41137336 1954.82109015 3864.44011899 2168.62168629  325.41156234]
total_rewards_mean           2146.0138085623225
total_rewards_std            1543.6776037675556
total_rewards_max            4421.0182037291515
total_rewards_min            76.67324279079423
Number of train steps total  952000
Number of env steps total    1115624
Number of rollouts total     0
Train Time (s)               205.06101271882653
(Previous) Eval Time (s)     25.318789375945926
Sample Time (s)              11.816135651897639
Epoch Time (s)               242.1959377466701
Total Train Time (s)         52094.07094560424
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:39:55.893441 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #237 | Epoch Duration: 242.2869050502777
2020-01-12 06:39:55.893642 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1630704
Z variance train             0.010930245
KL Divergence                22.018913
KL Loss                      2.2018914
QF Loss                      909.66956
VF Loss                      156.1431
Policy Loss                  -1101.3162
Q Predictions Mean           1095.3375
Q Predictions Std            454.45697
Q Predictions Max            1715.0359
Q Predictions Min            261.1181
V Predictions Mean           1102.2241
V Predictions Std            453.66428
V Predictions Max            1717.9438
V Predictions Min            268.0743
Log Pis Mean                 0.24383992
Log Pis Std                  3.603893
Log Pis Max                  14.91312
Log Pis Min                  -7.9873495
Policy mu Mean               0.014326986
Policy mu Std                0.6144307
Policy mu Max                2.995329
Policy mu Min                -2.917903
Policy log std Mean          -1.0317011
Policy log std Std           0.27641672
Policy log std Max           -0.39233732
Policy log std Min           -2.7540765
Z mean eval                  1.1538651
Z variance eval              0.04432351
total_rewards                [4168.13928872  282.67683027 4115.87050978 2401.17738078  559.84578971
 4372.61278957 1557.81742611 3274.63411676 4487.28559196 1512.59173011]
total_rewards_mean           2673.265145378133
total_rewards_std            1539.5690366542126
total_rewards_max            4487.285591961429
total_rewards_min            282.67683026811
Number of train steps total  956000
Number of env steps total    1123455
Number of rollouts total     0
Train Time (s)               206.4838808919303
(Previous) Eval Time (s)     29.019734231289476
Sample Time (s)              11.239954297896475
Epoch Time (s)               246.74356942111626
Total Train Time (s)         52340.9008469414
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:44:02.726348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #238 | Epoch Duration: 246.8325707912445
2020-01-12 06:44:02.726534 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1557252
Z variance train             0.0442798
KL Divergence                19.280272
KL Loss                      1.9280272
QF Loss                      927.8065
VF Loss                      165.83243
Policy Loss                  -1120.0234
Q Predictions Mean           1109.9994
Q Predictions Std            452.0508
Q Predictions Max            1669.5421
Q Predictions Min            14.934278
V Predictions Mean           1124.2737
V Predictions Std            448.63574
V Predictions Max            1661.4581
V Predictions Min            265.16983
Log Pis Mean                 0.21481258
Log Pis Std                  3.3707418
Log Pis Max                  13.947289
Log Pis Min                  -9.068313
Policy mu Mean               0.040488116
Policy mu Std                0.60623145
Policy mu Max                2.2572732
Policy mu Min                -2.4553127
Policy log std Mean          -1.0278518
Policy log std Std           0.26677933
Policy log std Max           -0.3521868
Policy log std Min           -2.6136026
Z mean eval                  1.1607476
Z variance eval              0.009782381
total_rewards                [4414.08097973 4497.12811903 4559.23114287 2276.58766223 4829.33609152
 4557.24316907 4517.93403289 4919.07561105 4410.69730013 4504.73958606]
total_rewards_mean           4348.605369459113
total_rewards_std            708.5859306380321
total_rewards_max            4919.075611048049
total_rewards_min            2276.587662231162
Number of train steps total  960000
Number of env steps total    1134376
Number of rollouts total     0
Train Time (s)               201.93430977500975
(Previous) Eval Time (s)     45.107870884705335
Sample Time (s)              10.587782994378358
Epoch Time (s)               257.62996365409344
Total Train Time (s)         52598.619302511215
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:48:20.447441 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #239 | Epoch Duration: 257.7207553386688
2020-01-12 06:48:20.447660 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1629721
Z variance train             0.009891714
KL Divergence                22.382141
KL Loss                      2.2382143
QF Loss                      1133.3704
VF Loss                      262.06656
Policy Loss                  -1083.7275
Q Predictions Mean           1075.0491
Q Predictions Std            471.4797
Q Predictions Max            1664.699
Q Predictions Min            245.96149
V Predictions Mean           1079.8167
V Predictions Std            467.8978
V Predictions Max            1641.7115
V Predictions Min            269.06335
Log Pis Mean                 0.06507139
Log Pis Std                  3.7780638
Log Pis Max                  23.200941
Log Pis Min                  -8.461031
Policy mu Mean               0.084186256
Policy mu Std                0.60921013
Policy mu Max                3.5266716
Policy mu Min                -3.426755
Policy log std Mean          -1.0043856
Policy log std Std           0.27658516
Policy log std Max           -0.22730386
Policy log std Min           -2.6668334
Z mean eval                  1.0637232
Z variance eval              0.009829046
total_rewards                [2233.21954295 4389.88293907 4351.57071251 4419.79451656 3380.43164427
 4428.55217109    7.76374546 4485.58485411 4381.63997236 4305.60921421]
total_rewards_mean           3638.404931259081
total_rewards_std            1387.305023704711
total_rewards_max            4485.584854106102
total_rewards_min            7.763745455182079
Number of train steps total  964000
Number of env steps total    1143988
Number of rollouts total     0
Train Time (s)               200.22284121299163
(Previous) Eval Time (s)     39.76543629495427
Sample Time (s)              18.540232257451862
Epoch Time (s)               258.52850976539776
Total Train Time (s)         52857.23792037973
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:52:39.068791 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #240 | Epoch Duration: 258.6209795475006
2020-01-12 06:52:39.068987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0641634
Z variance train             0.009872627
KL Divergence                22.264904
KL Loss                      2.2264905
QF Loss                      878.1836
VF Loss                      159.49715
Policy Loss                  -1098.4218
Q Predictions Mean           1097.7518
Q Predictions Std            476.91714
Q Predictions Max            1725.9607
Q Predictions Min            40.032276
V Predictions Mean           1101.1099
V Predictions Std            477.25574
V Predictions Max            1701.8517
V Predictions Min            -45.298172
Log Pis Mean                 0.24727179
Log Pis Std                  3.064199
Log Pis Max                  9.301492
Log Pis Min                  -7.847801
Policy mu Mean               0.05090035
Policy mu Std                0.6139295
Policy mu Max                2.2369611
Policy mu Min                -2.582176
Policy log std Mean          -1.0210274
Policy log std Std           0.2832546
Policy log std Max           -0.13999504
Policy log std Min           -2.49445
Z mean eval                  1.0991573
Z variance eval              0.0028070093
total_rewards                [4302.04117408 4324.16421603 4526.55258401 4551.18762414 2793.4768625
 4509.23595392  865.37806042 4430.16659137 4492.06527664 4552.7845178 ]
total_rewards_mean           3934.7052860901886
total_rewards_std            1140.5419339950797
total_rewards_max            4552.784517795343
total_rewards_min            865.3780604175347
Number of train steps total  968000
Number of env steps total    1153755
Number of rollouts total     0
Train Time (s)               205.78020419413224
(Previous) Eval Time (s)     42.741784579120576
Sample Time (s)              9.382668339181691
Epoch Time (s)               257.9046571124345
Total Train Time (s)         53115.230379344895
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:57.063795 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #241 | Epoch Duration: 257.99466037750244
2020-01-12 06:56:57.063987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.100769
Z variance train             0.002810246
KL Divergence                24.732876
KL Loss                      2.4732876
QF Loss                      1685.1012
VF Loss                      219.56285
Policy Loss                  -1110.3153
Q Predictions Mean           1101.818
Q Predictions Std            469.50677
Q Predictions Max            1704.0986
Q Predictions Min            -81.6518
V Predictions Mean           1115.6147
V Predictions Std            466.89743
V Predictions Max            1702.0751
V Predictions Min            -16.084936
Log Pis Mean                 0.1927292
Log Pis Std                  3.5398645
Log Pis Max                  17.870098
Log Pis Min                  -9.12834
Policy mu Mean               0.005937976
Policy mu Std                0.614149
Policy mu Max                2.7098227
Policy mu Min                -4.0356045
Policy log std Mean          -1.0396494
Policy log std Std           0.29175273
Policy log std Max           -0.009461701
Policy log std Min           -2.6457353
Z mean eval                  1.1954328
Z variance eval              0.006929965
total_rewards                [4347.30852114 3409.8872075  4083.15906548 4496.63575883 2186.21358722
 4449.80641478 4396.0569352   636.03594412 3944.07458305 3647.49517971]
total_rewards_mean           3559.6673197028567
total_rewards_std            1177.9702737407042
total_rewards_max            4496.635758826608
total_rewards_min            636.0359441243041
Number of train steps total  972000
Number of env steps total    1163222
Number of rollouts total     0
Train Time (s)               206.79935753298923
(Previous) Eval Time (s)     38.26738868188113
Sample Time (s)              9.604248392861336
Epoch Time (s)               254.6709946077317
Total Train Time (s)         53369.988554204814
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:01:11.824604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #242 | Epoch Duration: 254.7604615688324
2020-01-12 07:01:11.824782 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1923225
Z variance train             0.0069493665
KL Divergence                22.83741
KL Loss                      2.283741
QF Loss                      1734.7479
VF Loss                      84.603195
Policy Loss                  -1115.3048
Q Predictions Mean           1111.7927
Q Predictions Std            466.58487
Q Predictions Max            1744.9172
Q Predictions Min            267.40048
V Predictions Mean           1117.0728
V Predictions Std            467.4303
V Predictions Max            1744.8612
V Predictions Min            271.57632
Log Pis Mean                 0.47980756
Log Pis Std                  3.7520864
Log Pis Max                  20.687813
Log Pis Min                  -7.3616357
Policy mu Mean               0.10530209
Policy mu Std                0.6366168
Policy mu Max                4.8814545
Policy mu Min                -3.0154936
Policy log std Mean          -1.0400627
Policy log std Std           0.3022436
Policy log std Max           -0.42758816
Policy log std Min           -2.555519
Z mean eval                  1.265772
Z variance eval              0.017020535
total_rewards                [ 769.68066977 2730.32077484  143.46367534  469.55914937  837.24374085
 4382.91850889 4576.77602334  513.36165946 4365.83776492 2345.88375195]
total_rewards_mean           2113.5045718716583
total_rewards_std            1711.846733799257
total_rewards_max            4576.7760233362005
total_rewards_min            143.46367533825244
Number of train steps total  976000
Number of env steps total    1171894
Number of rollouts total     0
Train Time (s)               208.08455553883687
(Previous) Eval Time (s)     25.463075910694897
Sample Time (s)              11.43853793758899
Epoch Time (s)               244.98616938712075
Total Train Time (s)         53615.06847767392
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:05:16.907574 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #243 | Epoch Duration: 245.08264255523682
2020-01-12 07:05:16.907775 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2648176
Z variance train             0.016889557
KL Divergence                22.17376
KL Loss                      2.217376
QF Loss                      1058.2491
VF Loss                      189.56125
Policy Loss                  -1079.6628
Q Predictions Mean           1073.2793
Q Predictions Std            491.08752
Q Predictions Max            1721.5848
Q Predictions Min            274.0011
V Predictions Mean           1075.992
V Predictions Std            488.71725
V Predictions Max            1730.7991
V Predictions Min            271.1007
Log Pis Mean                 -0.08501991
Log Pis Std                  3.386814
Log Pis Max                  16.117126
Log Pis Min                  -9.497987
Policy mu Mean               0.034807824
Policy mu Std                0.5760155
Policy mu Max                3.1122935
Policy mu Min                -2.2521229
Policy log std Mean          -1.0230111
Policy log std Std           0.2937758
Policy log std Max           -0.41253942
Policy log std Min           -2.7176957
Z mean eval                  1.1036476
Z variance eval              0.041169412
total_rewards                [2104.32077164 4056.72964352 4518.58794217 4293.56992165 4462.48657375
 4457.57050394  808.41287801 4496.96912529 2906.54362274 4131.78740941]
total_rewards_mean           3623.6978392115366
total_rewards_std            1208.5275179219561
total_rewards_max            4518.587942167437
total_rewards_min            808.4128780107062
Number of train steps total  980000
Number of env steps total    1181106
Number of rollouts total     0
Train Time (s)               209.95148723991588
(Previous) Eval Time (s)     40.37563296081498
Sample Time (s)              11.243634230457246
Epoch Time (s)               261.5707544311881
Total Train Time (s)         53876.73245903244
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:09:38.576914 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #244 | Epoch Duration: 261.6689703464508
2020-01-12 07:09:38.577172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056788
Z variance train             0.045150444
KL Divergence                22.577515
KL Loss                      2.2577515
QF Loss                      1152.5745
VF Loss                      1402.865
Policy Loss                  -1133.8632
Q Predictions Mean           1128.398
Q Predictions Std            461.57562
Q Predictions Max            1734.2317
Q Predictions Min            115.079384
V Predictions Mean           1143.0588
V Predictions Std            460.43185
V Predictions Max            1705.238
V Predictions Min            256.40292
Log Pis Mean                 0.22097874
Log Pis Std                  3.6055033
Log Pis Max                  15.607505
Log Pis Min                  -8.733779
Policy mu Mean               0.036764346
Policy mu Std                0.61018836
Policy mu Max                2.8794794
Policy mu Min                -3.2434545
Policy log std Mean          -1.0457953
Policy log std Std           0.29930916
Policy log std Max           -0.20830709
Policy log std Min           -2.6081114
Z mean eval                  1.0972213
Z variance eval              0.013652533
total_rewards                [1.48093833e+03 4.46948018e+03 4.64083617e+03 3.91797840e+03
 6.73530870e+02 1.99936046e+03 2.42177821e+00 4.52269183e+03
 2.04178140e+03 2.00510760e+03]
total_rewards_mean           2575.412700855025
total_rewards_std            1607.0159237715338
total_rewards_max            4640.836174921822
total_rewards_min            2.42177821170998
Number of train steps total  984000
Number of env steps total    1191104
Number of rollouts total     0
Train Time (s)               205.67030625930056
(Previous) Eval Time (s)     25.78913045907393
Sample Time (s)              8.859480550512671
Epoch Time (s)               240.31891726888716
Total Train Time (s)         54117.14900553273
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:13:38.996400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #245 | Epoch Duration: 240.41904091835022
2020-01-12 07:13:38.996590 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1029983
Z variance train             0.014071843
KL Divergence                21.591957
KL Loss                      2.1591957
QF Loss                      1164.7856
VF Loss                      295.13
Policy Loss                  -1128.2251
Q Predictions Mean           1125.1599
Q Predictions Std            496.71918
Q Predictions Max            1765.4473
Q Predictions Min            271.37595
V Predictions Mean           1138.3525
V Predictions Std            496.97305
V Predictions Max            1766.2006
V Predictions Min            275.98178
Log Pis Mean                 0.03473012
Log Pis Std                  3.60471
Log Pis Max                  13.290888
Log Pis Min                  -8.166042
Policy mu Mean               0.025588386
Policy mu Std                0.5686287
Policy mu Max                3.1847076
Policy mu Min                -2.2272112
Policy log std Mean          -1.0557324
Policy log std Std           0.33521193
Policy log std Max           -0.38672388
Policy log std Min           -2.5868685
Z mean eval                  1.0705843
Z variance eval              0.008295215
total_rewards                [2315.52112588 4462.02641479 1802.35356212 4792.21320445 4700.01064644
 4436.38825533  817.89362388 4583.80701063 4326.90429394 4403.58462193]
total_rewards_mean           3664.070275939059
total_rewards_std            1371.0043585272656
total_rewards_max            4792.213204452105
total_rewards_min            817.893623881429
Number of train steps total  988000
Number of env steps total    1201804
Number of rollouts total     0
Train Time (s)               209.38299635285512
(Previous) Eval Time (s)     38.43087355885655
Sample Time (s)              9.526558931916952
Epoch Time (s)               257.3404288436286
Total Train Time (s)         54374.64707683539
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:17:56.497095 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #246 | Epoch Duration: 257.5003607273102
2020-01-12 07:17:56.497288 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0736173
Z variance train             0.00841635
KL Divergence                22.201847
KL Loss                      2.2201848
QF Loss                      1406.939
VF Loss                      214.48415
Policy Loss                  -1184.5115
Q Predictions Mean           1181.183
Q Predictions Std            422.0604
Q Predictions Max            1735.264
Q Predictions Min            261.84882
V Predictions Mean           1179.0842
V Predictions Std            416.35635
V Predictions Max            1700.0944
V Predictions Min            270.27106
Log Pis Mean                 0.4630452
Log Pis Std                  3.404699
Log Pis Max                  28.584152
Log Pis Min                  -6.7614326
Policy mu Mean               0.06965703
Policy mu Std                0.6237634
Policy mu Max                4.865986
Policy mu Min                -2.7797053
Policy log std Mean          -1.0418874
Policy log std Std           0.28099698
Policy log std Max           -0.29990035
Policy log std Min           -2.4984522
Z mean eval                  1.1189744
Z variance eval              0.019722339
total_rewards                [4675.74700949 4451.87250948 4457.16253599 4211.60814152 3148.65781902
 3905.3020023  2137.78742401 4319.12313242 4644.37622116 4818.48165135]
total_rewards_mean           4077.0118446735514
total_rewards_std            790.1803296087164
total_rewards_max            4818.481651346345
total_rewards_min            2137.787424011686
Number of train steps total  992000
Number of env steps total    1211902
Number of rollouts total     0
Train Time (s)               208.8817151361145
(Previous) Eval Time (s)     45.813691357616335
Sample Time (s)              9.922547108959407
Epoch Time (s)               264.61795360269025
Total Train Time (s)         54639.359534661286
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:22:21.212903 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #247 | Epoch Duration: 264.71547627449036
2020-01-12 07:22:21.213078 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1160271
Z variance train             0.019726887
KL Divergence                20.895739
KL Loss                      2.0895739
QF Loss                      2026.8903
VF Loss                      180.58473
Policy Loss                  -1153.361
Q Predictions Mean           1144.3724
Q Predictions Std            454.35614
Q Predictions Max            1738.0607
Q Predictions Min            119.01305
V Predictions Mean           1151.3198
V Predictions Std            448.33124
V Predictions Max            1721.721
V Predictions Min            271.9228
Log Pis Mean                 0.14688885
Log Pis Std                  3.2733154
Log Pis Max                  16.700342
Log Pis Min                  -8.202532
Policy mu Mean               0.066454805
Policy mu Std                0.6167675
Policy mu Max                3.161909
Policy mu Min                -3.9554212
Policy log std Mean          -1.0130285
Policy log std Std           0.2905471
Policy log std Max           -0.3505336
Policy log std Min           -2.4370182
Z mean eval                  1.1088917
Z variance eval              0.00891586
total_rewards                [4447.55459896 4166.65203253 1547.75773167 4464.76991312 3197.66093592
 4464.80364474 4693.1661023  4536.80808188 4492.93132592 4383.16404978]
total_rewards_mean           4039.526841680496
total_rewards_std            919.792697663581
total_rewards_max            4693.166102297847
total_rewards_min            1547.7577316688876
Number of train steps total  996000
Number of env steps total    1221519
Number of rollouts total     0
Train Time (s)               203.343771382235
(Previous) Eval Time (s)     39.39555989112705
Sample Time (s)              9.828709272202104
Epoch Time (s)               252.56804054556414
Total Train Time (s)         54892.01291025942
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:26:33.869330 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #248 | Epoch Duration: 252.65610885620117
2020-01-12 07:26:33.869536 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1028075
Z variance train             0.008871724
KL Divergence                22.78828
KL Loss                      2.2788281
QF Loss                      1006.0065
VF Loss                      439.48605
Policy Loss                  -1112.339
Q Predictions Mean           1106.179
Q Predictions Std            463.41998
Q Predictions Max            1717.5125
Q Predictions Min            256.23828
V Predictions Mean           1112.0211
V Predictions Std            459.0587
V Predictions Max            1723.4764
V Predictions Min            267.7637
Log Pis Mean                 0.27890098
Log Pis Std                  3.6458411
Log Pis Max                  11.934576
Log Pis Min                  -7.549387
Policy mu Mean               0.09277331
Policy mu Std                0.63805425
Policy mu Max                2.449023
Policy mu Min                -3.0664668
Policy log std Mean          -1.0124741
Policy log std Std           0.30301628
Policy log std Max           -0.25203174
Policy log std Min           -2.4753022
Z mean eval                  1.0476681
Z variance eval              0.0073914044
total_rewards                [4624.22580756 4140.88328008 4317.30885156 4228.64112577 3422.54908669
 1491.3358579  4438.26007653 4411.28079379 3480.4346876  4273.63295942]
total_rewards_mean           3882.8552526898334
total_rewards_std            880.8025285153592
total_rewards_max            4624.225807562352
total_rewards_min            1491.3358578954615
Number of train steps total  1000000
Number of env steps total    1231358
Number of rollouts total     0
Train Time (s)               205.0469808857888
(Previous) Eval Time (s)     42.61560795037076
Sample Time (s)              10.190800115466118
Epoch Time (s)               257.8533889516257
Total Train Time (s)         55149.95256325975
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:30:51.811141 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #249 | Epoch Duration: 257.9414505958557
2020-01-12 07:30:51.811339 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0506809
Z variance train             0.007452724
KL Divergence                21.737827
KL Loss                      2.1737828
QF Loss                      6157.833
VF Loss                      151.66927
Policy Loss                  -1206.2582
Q Predictions Mean           1201.3013
Q Predictions Std            462.368
Q Predictions Max            1727.8314
Q Predictions Min            270.6692
V Predictions Mean           1199.6619
V Predictions Std            459.27698
V Predictions Max            1724.5486
V Predictions Min            275.67786
Log Pis Mean                 0.6561688
Log Pis Std                  3.383737
Log Pis Max                  13.343252
Log Pis Min                  -9.456864
Policy mu Mean               0.05251374
Policy mu Std                0.63768816
Policy mu Max                2.5321944
Policy mu Min                -2.8353043
Policy log std Mean          -1.0276816
Policy log std Std           0.28792095
Policy log std Max           0.012010694
Policy log std Min           -2.4408946
Z mean eval                  1.1641204
Z variance eval              0.033654235
total_rewards                [4686.40915836 4596.35773228 4792.74426883 4293.25342545 4751.4323703
 4412.09136619 4618.64866849 3393.26362266 3897.10583786 4692.07568518]
total_rewards_mean           4413.338213561302
total_rewards_std            425.1631930692933
total_rewards_max            4792.744268832367
total_rewards_min            3393.2636226563336
Number of train steps total  1004000
Number of env steps total    1240812
Number of rollouts total     0
Train Time (s)               206.4301377022639
(Previous) Eval Time (s)     45.16155333723873
Sample Time (s)              10.871979194227606
Epoch Time (s)               262.4636702337302
Total Train Time (s)         55412.5126962862
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:35:14.377474 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #250 | Epoch Duration: 262.56598687171936
2020-01-12 07:35:14.377665 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.162034
Z variance train             0.034702506
KL Divergence                19.712088
KL Loss                      1.9712088
QF Loss                      1156.9163
VF Loss                      229.29028
Policy Loss                  -1184.5978
Q Predictions Mean           1172.8887
Q Predictions Std            486.78433
Q Predictions Max            1752.1661
Q Predictions Min            21.076359
V Predictions Mean           1181.3103
V Predictions Std            481.65128
V Predictions Max            1744.5248
V Predictions Min            285.92224
Log Pis Mean                 0.54229486
Log Pis Std                  3.4151838
Log Pis Max                  14.488945
Log Pis Min                  -6.609483
Policy mu Mean               0.040846933
Policy mu Std                0.6147062
Policy mu Max                4.47345
Policy mu Min                -2.6954386
Policy log std Mean          -1.068799
Policy log std Std           0.30631194
Policy log std Max           -0.2893769
Policy log std Min           -2.5863075
Z mean eval                  1.0923645
Z variance eval              0.007864196
total_rewards                [2679.5770484  1310.02682531  282.88841929 2192.58053162 4412.97746488
 2306.19099084 4633.81596242 4548.20048112  589.29702107 4435.63349229]
total_rewards_mean           2739.1188237238966
total_rewards_std            1604.0386473135507
total_rewards_max            4633.815962420112
total_rewards_min            282.8884192873353
Number of train steps total  1008000
Number of env steps total    1249804
Number of rollouts total     0
Train Time (s)               204.93598068412393
(Previous) Eval Time (s)     35.05036341911182
Sample Time (s)              10.501764650922269
Epoch Time (s)               250.48810875415802
Total Train Time (s)         55663.093090646435
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:39:24.960376 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #251 | Epoch Duration: 250.58257055282593
2020-01-12 07:39:24.960553 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0969214
Z variance train             0.00790965
KL Divergence                22.669502
KL Loss                      2.2669504
QF Loss                      849.6217
VF Loss                      90.16083
Policy Loss                  -1132.0391
Q Predictions Mean           1124.2848
Q Predictions Std            480.50064
Q Predictions Max            1759.2661
Q Predictions Min            75.25178
V Predictions Mean           1130.8792
V Predictions Std            479.24167
V Predictions Max            1755.7354
V Predictions Min            120.20775
Log Pis Mean                 0.087866694
Log Pis Std                  3.3169227
Log Pis Max                  18.656998
Log Pis Min                  -6.447641
Policy mu Mean               0.049524143
Policy mu Std                0.62668484
Policy mu Max                2.8840973
Policy mu Min                -3.4266348
Policy log std Mean          -0.9865296
Policy log std Std           0.2790911
Policy log std Max           -0.4096173
Policy log std Min           -2.5433507
Z mean eval                  1.1299063
Z variance eval              0.0053152246
total_rewards                [4676.6549677  3824.62688566 3760.22006354 4531.02275298 4506.08331005
 3418.96341862 4548.99693545 2829.29458835 4193.90943681 1161.91730251]
total_rewards_mean           3745.1689661655487
total_rewards_std            1026.4840762360498
total_rewards_max            4676.654967695626
total_rewards_min            1161.917302513777
Number of train steps total  1012000
Number of env steps total    1259573
Number of rollouts total     0
Train Time (s)               202.6533069619909
(Previous) Eval Time (s)     35.92753188405186
Sample Time (s)              10.987025055103004
Epoch Time (s)               249.56786390114576
Total Train Time (s)         55912.760481962934
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:43:34.630908 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #252 | Epoch Duration: 249.67021775245667
2020-01-12 07:43:34.631088 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1268215
Z variance train             0.0053304574
KL Divergence                23.81974
KL Loss                      2.381974
QF Loss                      703.5579
VF Loss                      119.50527
Policy Loss                  -1160.9423
Q Predictions Mean           1153.9928
Q Predictions Std            493.42758
Q Predictions Max            1788.4769
Q Predictions Min            231.60194
V Predictions Mean           1163.4772
V Predictions Std            496.2874
V Predictions Max            1802.7881
V Predictions Min            217.95139
Log Pis Mean                 -0.029062152
Log Pis Std                  3.4131105
Log Pis Max                  14.671966
Log Pis Min                  -6.805313
Policy mu Mean               0.023634102
Policy mu Std                0.607403
Policy mu Max                2.4516447
Policy mu Min                -2.8603234
Policy log std Mean          -0.9945164
Policy log std Std           0.29782578
Policy log std Max           -0.03492999
Policy log std Min           -2.6040964
Z mean eval                  1.2388729
Z variance eval              0.006995082
total_rewards                [ 466.77214817 4829.74632703 4288.82700388 4958.13916062 4322.96702069
 4714.67761775 4605.20739217 4798.10178807 4670.10728647 4641.76359986]
total_rewards_mean           4229.630934470545
total_rewards_std            1269.8639528593815
total_rewards_max            4958.139160618951
total_rewards_min            466.77214816758266
Number of train steps total  1016000
Number of env steps total    1266787
Number of rollouts total     0
Train Time (s)               205.01119702821597
(Previous) Eval Time (s)     46.21688077924773
Sample Time (s)              9.659145665355027
Epoch Time (s)               260.88722347281873
Total Train Time (s)         56173.738370677456
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:47:55.612169 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #253 | Epoch Duration: 260.98094367980957
2020-01-12 07:47:55.612360 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2436143
Z variance train             0.0070045865
KL Divergence                23.925858
KL Loss                      2.3925858
QF Loss                      795.54224
VF Loss                      173.24635
Policy Loss                  -1211.3798
Q Predictions Mean           1212.3881
Q Predictions Std            471.24716
Q Predictions Max            1802.7867
Q Predictions Min            290.38248
V Predictions Mean           1219.0326
V Predictions Std            472.19666
V Predictions Max            1805.5002
V Predictions Min            293.4376
Log Pis Mean                 0.29206592
Log Pis Std                  3.0295482
Log Pis Max                  9.767315
Log Pis Min                  -7.605887
Policy mu Mean               0.062403474
Policy mu Std                0.6081914
Policy mu Max                2.4830768
Policy mu Min                -1.9725623
Policy log std Mean          -1.0438704
Policy log std Std           0.29189903
Policy log std Max           -0.2987044
Policy log std Min           -2.5946953
Z mean eval                  1.1446661
Z variance eval              0.012403786
total_rewards                [2632.5913927  2160.87962574 1821.65349801 4736.07364138 4481.48570956
 4377.23601165 2406.83933775 3108.22852535 3410.24907414 1455.5304181 ]
total_rewards_mean           3059.0767234379864
total_rewards_std            1105.2369057522274
total_rewards_max            4736.073641380776
total_rewards_min            1455.5304180974379
Number of train steps total  1020000
Number of env steps total    1276483
Number of rollouts total     0
Train Time (s)               203.38631245307624
(Previous) Eval Time (s)     35.973050110042095
Sample Time (s)              10.702263887505978
Epoch Time (s)               250.06162645062432
Total Train Time (s)         56423.91729263868
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:52:05.797808 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #254 | Epoch Duration: 250.18527388572693
2020-01-12 07:52:05.798119 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1514531
Z variance train             0.012467929
KL Divergence                20.915747
KL Loss                      2.0915747
QF Loss                      1045.5371
VF Loss                      178.2869
Policy Loss                  -1194.8157
Q Predictions Mean           1189.2864
Q Predictions Std            481.2347
Q Predictions Max            1773.1572
Q Predictions Min            11.120186
V Predictions Mean           1186.4358
V Predictions Std            478.28326
V Predictions Max            1760.9783
V Predictions Min            79.28879
Log Pis Mean                 0.2681674
Log Pis Std                  3.2076323
Log Pis Max                  11.006282
Log Pis Min                  -6.17043
Policy mu Mean               0.08429977
Policy mu Std                0.6285681
Policy mu Max                2.850778
Policy mu Min                -2.2182593
Policy log std Mean          -0.9967222
Policy log std Std           0.2938218
Policy log std Max           -0.328897
Policy log std Min           -2.5200603
Z mean eval                  1.0072111
Z variance eval              0.013708455
total_rewards                [4500.81304421 4700.78974493 4792.71447237 4701.79842018 1937.46971351
 4968.60250378 4886.62435329 1404.36324217 4513.48442525 4878.39297005]
total_rewards_mean           4128.505288974657
total_rewards_std            1242.9238317959375
total_rewards_max            4968.602503782471
total_rewards_min            1404.3632421657026
Number of train steps total  1024000
Number of env steps total    1283744
Number of rollouts total     0
Train Time (s)               205.03500522393733
(Previous) Eval Time (s)     38.14827364915982
Sample Time (s)              8.852579989936203
Epoch Time (s)               252.03585886303335
Total Train Time (s)         56676.04369874671
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:17.926002 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #255 | Epoch Duration: 252.12766218185425
2020-01-12 07:56:17.926189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0151837
Z variance train             0.013929081
KL Divergence                22.76729
KL Loss                      2.276729
QF Loss                      686.2882
VF Loss                      138.62926
Policy Loss                  -1175.1924
Q Predictions Mean           1170.6094
Q Predictions Std            506.65494
Q Predictions Max            1796.1658
Q Predictions Min            296.83115
V Predictions Mean           1170.4385
V Predictions Std            506.62445
V Predictions Max            1780.0116
V Predictions Min            293.41376
Log Pis Mean                 0.032802135
Log Pis Std                  3.361684
Log Pis Max                  12.255741
Log Pis Min                  -7.744258
Policy mu Mean               0.02067281
Policy mu Std                0.60389775
Policy mu Max                2.220683
Policy mu Min                -3.039512
Policy log std Mean          -1.0183389
Policy log std Std           0.28958628
Policy log std Max           -0.4267503
Policy log std Min           -2.3396523
Z mean eval                  1.1134851
Z variance eval              0.04911812
total_rewards                [4538.76128931 4509.2464964   343.05118331 2819.23135641 4482.5108529
 4693.93567872  635.36330589 4388.49953349 3591.43493716 4587.66721204]
total_rewards_mean           3458.9701845641625
total_rewards_std            1583.9288471866587
total_rewards_max            4693.9356787162
total_rewards_min            343.05118331136225
Number of train steps total  1028000
Number of env steps total    1294402
Number of rollouts total     0
Train Time (s)               201.56904132431373
(Previous) Eval Time (s)     34.65157083282247
Sample Time (s)              9.179657359607518
Epoch Time (s)               245.40026951674372
Total Train Time (s)         56921.553356990684
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:00:23.438859 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #256 | Epoch Duration: 245.51252698898315
2020-01-12 08:00:23.439041 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1199517
Z variance train             0.049005877
KL Divergence                20.065443
KL Loss                      2.0065444
QF Loss                      2211.1548
VF Loss                      426.4283
Policy Loss                  -1182.683
Q Predictions Mean           1173.5983
Q Predictions Std            476.2886
Q Predictions Max            1737.4917
Q Predictions Min            299.70676
V Predictions Mean           1169.3809
V Predictions Std            472.73264
V Predictions Max            1725.886
V Predictions Min            280.94168
Log Pis Mean                 0.45909047
Log Pis Std                  3.4559731
Log Pis Max                  19.015522
Log Pis Min                  -7.6945667
Policy mu Mean               0.101521626
Policy mu Std                0.6587979
Policy mu Max                3.1381948
Policy mu Min                -2.9278035
Policy log std Mean          -0.9826423
Policy log std Std           0.30626878
Policy log std Max           -0.23690975
Policy log std Min           -2.3760228
Z mean eval                  1.1010594
Z variance eval              0.0054817554
total_rewards                [ 913.45254734  725.11362759 4736.75414467 1328.17902834 3368.04199279
 1193.17571405 3333.02537222 1826.68955372   16.37355908 4360.61408873]
total_rewards_mean           2180.141962851274
total_rewards_std            1557.54121092137
total_rewards_max            4736.754144666447
total_rewards_min            16.373559075771936
Number of train steps total  1032000
Number of env steps total    1304118
Number of rollouts total     0
Train Time (s)               207.97922582225874
(Previous) Eval Time (s)     24.845712670125067
Sample Time (s)              11.428056525066495
Epoch Time (s)               244.2529950174503
Total Train Time (s)         57165.90794543084
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:04:27.799012 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #257 | Epoch Duration: 244.3598062992096
2020-01-12 08:04:27.799284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1017357
Z variance train             0.0055042338
KL Divergence                25.309748
KL Loss                      2.5309749
QF Loss                      1931.4424
VF Loss                      270.39877
Policy Loss                  -1172.824
Q Predictions Mean           1165.7241
Q Predictions Std            498.75674
Q Predictions Max            1782.6011
Q Predictions Min            301.55966
V Predictions Mean           1175.4521
V Predictions Std            499.41364
V Predictions Max            1797.6183
V Predictions Min            302.6555
Log Pis Mean                 0.15185368
Log Pis Std                  3.2718723
Log Pis Max                  11.513151
Log Pis Min                  -8.341597
Policy mu Mean               0.09724651
Policy mu Std                0.65609986
Policy mu Max                2.7785933
Policy mu Min                -2.3377373
Policy log std Mean          -0.9540282
Policy log std Std           0.29049525
Policy log std Max           -0.3484882
Policy log std Min           -2.770502
Z mean eval                  1.254989
Z variance eval              0.21529368
total_rewards                [4401.95129523  695.3398069  3041.00156454 4450.56688377 4335.73911514
 4288.07651856 4399.47611685 4050.30612832 4133.5973717  1927.2420921 ]
total_rewards_mean           3572.329689311503
total_rewards_std            1226.7032125196417
total_rewards_max            4450.566883772899
total_rewards_min            695.3398069006109
Number of train steps total  1036000
Number of env steps total    1312906
Number of rollouts total     0
Train Time (s)               204.78461353713647
(Previous) Eval Time (s)     31.77246316615492
Sample Time (s)              10.137015966698527
Epoch Time (s)               246.6940926699899
Total Train Time (s)         57412.707603838295
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:08:34.600992 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #258 | Epoch Duration: 246.8015055656433
2020-01-12 08:08:34.601186 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2531744
Z variance train             0.22419958
KL Divergence                18.652096
KL Loss                      1.8652096
QF Loss                      839.22046
VF Loss                      321.5907
Policy Loss                  -1175.6161
Q Predictions Mean           1170.1829
Q Predictions Std            472.15735
Q Predictions Max            1746.0209
Q Predictions Min            284.19034
V Predictions Mean           1180.2576
V Predictions Std            473.85663
V Predictions Max            1749.7568
V Predictions Min            257.3588
Log Pis Mean                 0.3915822
Log Pis Std                  3.377618
Log Pis Max                  11.718649
Log Pis Min                  -6.337677
Policy mu Mean               0.05638656
Policy mu Std                0.62978035
Policy mu Max                2.9365659
Policy mu Min                -2.939085
Policy log std Mean          -1.0409248
Policy log std Std           0.30353326
Policy log std Max           -0.3676933
Policy log std Min           -2.3688817
Z mean eval                  1.1071794
Z variance eval              0.013597941
total_rewards                [4498.70042118 3839.06731409 4361.75244659 2524.34701679 4376.60831527
  477.50060425 1244.913863   4646.09228514 3248.67648276  590.45655532]
total_rewards_mean           2980.8115304400885
total_rewards_std            1579.329314683531
total_rewards_max            4646.092285135216
total_rewards_min            477.5006042539569
Number of train steps total  1040000
Number of env steps total    1323355
Number of rollouts total     0
Train Time (s)               191.38767786091194
(Previous) Eval Time (s)     22.717355526052415
Sample Time (s)              6.909194024745375
Epoch Time (s)               221.01422741170973
Total Train Time (s)         57633.89016946638
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:12:15.789436 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #259 | Epoch Duration: 221.18808698654175
2020-01-12 08:12:15.789698 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1084125
Z variance train             0.013433576
KL Divergence                22.10033
KL Loss                      2.2100332
QF Loss                      1100.8387
VF Loss                      317.55978
Policy Loss                  -1248.3656
Q Predictions Mean           1241.2877
Q Predictions Std            458.3784
Q Predictions Max            1863.144
Q Predictions Min            213.91508
V Predictions Mean           1243.5594
V Predictions Std            457.02664
V Predictions Max            1848.8938
V Predictions Min            231.25586
Log Pis Mean                 0.41398662
Log Pis Std                  3.4529371
Log Pis Max                  14.498819
Log Pis Min                  -9.632272
Policy mu Mean               0.056932613
Policy mu Std                0.6184704
Policy mu Max                2.266222
Policy mu Min                -2.343651
Policy log std Mean          -1.0182346
Policy log std Std           0.30110204
Policy log std Max           -0.17836237
Policy log std Min           -2.659377
Z mean eval                  1.1765558
Z variance eval              0.0036518641
total_rewards                [4683.51694673  811.66499678 4664.37986603 2699.97259194 4743.37670958
 4825.90039885 4701.314511   2667.06354511 4796.98562933 2549.29240773]
total_rewards_mean           3714.346760307064
total_rewards_std            1348.7472073280392
total_rewards_max            4825.9003988533
total_rewards_min            811.6649967817635
Number of train steps total  1044000
Number of env steps total    1332261
Number of rollouts total     0
Train Time (s)               190.31243553897366
(Previous) Eval Time (s)     26.665934342890978
Sample Time (s)              14.164164553862065
Epoch Time (s)               231.1425344357267
Total Train Time (s)         57865.124878083356
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:16:07.025305 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #260 | Epoch Duration: 231.2354335784912
2020-01-12 08:16:07.025455 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1763724
Z variance train             0.0036940612
KL Divergence                24.307293
KL Loss                      2.4307294
QF Loss                      1159.1797
VF Loss                      274.78046
Policy Loss                  -1256.9757
Q Predictions Mean           1248.4995
Q Predictions Std            472.47678
Q Predictions Max            1819.832
Q Predictions Min            233.19783
V Predictions Mean           1256.8455
V Predictions Std            468.88647
V Predictions Max            1825.8987
V Predictions Min            223.27419
Log Pis Mean                 0.4977135
Log Pis Std                  3.2670414
Log Pis Max                  13.251034
Log Pis Min                  -6.801889
Policy mu Mean               0.08001721
Policy mu Std                0.6018174
Policy mu Max                2.469914
Policy mu Min                -2.8132129
Policy log std Mean          -1.0430555
Policy log std Std           0.3117018
Policy log std Max           -0.29818463
Policy log std Min           -2.6954722
Z mean eval                  1.1241932
Z variance eval              0.007244514
total_rewards                [4396.98690264 4447.56729417 4555.68778361  104.54407779 4279.10284019
 4446.34311949 4075.59360865 4692.74859822 4520.09484365 4256.17853029]
total_rewards_mean           3977.4847598695465
total_rewards_std            1301.3482682793872
total_rewards_max            4692.748598218303
total_rewards_min            104.54407778819946
Number of train steps total  1048000
Number of env steps total    1339751
Number of rollouts total     0
Train Time (s)               190.63154207961634
(Previous) Eval Time (s)     30.545450059697032
Sample Time (s)              7.076645150780678
Epoch Time (s)               228.25363729009405
Total Train Time (s)         58093.4686406008
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:19:55.370914 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #261 | Epoch Duration: 228.34534883499146
2020-01-12 08:19:55.371063 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1305006
Z variance train             0.0072800457
KL Divergence                21.976965
KL Loss                      2.1976964
QF Loss                      1463.8584
VF Loss                      123.25629
Policy Loss                  -1215.6224
Q Predictions Mean           1209.821
Q Predictions Std            486.41412
Q Predictions Max            1850.4072
Q Predictions Min            307.54514
V Predictions Mean           1213.2471
V Predictions Std            489.17712
V Predictions Max            1818.9982
V Predictions Min            259.8016
Log Pis Mean                 0.47542703
Log Pis Std                  3.395725
Log Pis Max                  16.794521
Log Pis Min                  -5.6684017
Policy mu Mean               0.006644048
Policy mu Std                0.65447146
Policy mu Max                2.3630638
Policy mu Min                -5.0465474
Policy log std Mean          -1.0049335
Policy log std Std           0.33504614
Policy log std Max           1.2410755
Policy log std Min           -2.4459796
Z mean eval                  1.0967957
Z variance eval              0.0061757243
total_rewards                [2299.85611996 4770.40047265 4662.18049827 4532.52138594 1600.14067989
 4696.41261264  488.12984603 3889.20252951 4855.16950651 4781.66047626]
total_rewards_mean           3657.567412765767
total_rewards_std            1515.4404870559488
total_rewards_max            4855.169506514762
total_rewards_min            488.12984602985784
Number of train steps total  1052000
Number of env steps total    1346991
Number of rollouts total     0
Train Time (s)               195.11411596089602
(Previous) Eval Time (s)     23.86993220867589
Sample Time (s)              6.8862319230102
Epoch Time (s)               225.8702800925821
Total Train Time (s)         58319.42909145076
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:23:41.339003 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #262 | Epoch Duration: 225.96777987480164
2020-01-12 08:23:41.339341 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861044
Z variance train             0.0062557547
KL Divergence                22.01976
KL Loss                      2.201976
QF Loss                      1931.2172
VF Loss                      292.33856
Policy Loss                  -1231.4941
Q Predictions Mean           1231.4441
Q Predictions Std            466.14777
Q Predictions Max            1801.7869
Q Predictions Min            311.89334
V Predictions Mean           1229.0994
V Predictions Std            464.36172
V Predictions Max            1790.7041
V Predictions Min            304.66855
Log Pis Mean                 0.2827418
Log Pis Std                  3.3906
Log Pis Max                  13.183819
Log Pis Min                  -6.955979
Policy mu Mean               0.06916307
Policy mu Std                0.6445927
Policy mu Max                3.7218115
Policy mu Min                -3.299896
Policy log std Mean          -1.0201625
Policy log std Std           0.3067398
Policy log std Max           -0.07114041
Policy log std Min           -2.5041747
Z mean eval                  1.1954277
Z variance eval              0.01143142
total_rewards                [3740.29539673  106.09199741   46.46323129 4804.86024917 1534.4234932
 4681.31684374 2956.79497861 4605.45265529 4644.2731657  4911.18842899]
total_rewards_mean           3203.1160440135723
total_rewards_std            1854.762536681813
total_rewards_max            4911.188428990979
total_rewards_min            46.463231292824595
Number of train steps total  1056000
Number of env steps total    1355435
Number of rollouts total     0
Train Time (s)               191.12419517710805
(Previous) Eval Time (s)     22.529204088263214
Sample Time (s)              7.286414481699467
Epoch Time (s)               220.93981374707073
Total Train Time (s)         58540.50400039228
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:27:22.415688 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #263 | Epoch Duration: 221.07610535621643
2020-01-12 08:27:22.415889 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.192005
Z variance train             0.011451183
KL Divergence                24.329891
KL Loss                      2.4329891
QF Loss                      1997.1936
VF Loss                      125.94804
Policy Loss                  -1148.4358
Q Predictions Mean           1146.5774
Q Predictions Std            497.4724
Q Predictions Max            1820.9125
Q Predictions Min            42.76577
V Predictions Mean           1151.467
V Predictions Std            498.4194
V Predictions Max            1812.9325
V Predictions Min            -78.52112
Log Pis Mean                 0.16024391
Log Pis Std                  3.3960795
Log Pis Max                  12.441995
Log Pis Min                  -6.416204
Policy mu Mean               0.10206823
Policy mu Std                0.64217275
Policy mu Max                3.063392
Policy mu Min                -2.8909307
Policy log std Mean          -0.96064806
Policy log std Std           0.3052154
Policy log std Max           -0.19639677
Policy log std Min           -2.2872095
Z mean eval                  1.0839069
Z variance eval              0.021270756
total_rewards                [ 390.92276725 5003.63478323 4880.49486827 4779.78960183 4856.80648908
 4648.3601529  4087.08431977 4885.8661968  4627.21220795 4594.61061622]
total_rewards_mean           4275.478200328486
total_rewards_std            1317.2307953199206
total_rewards_max            5003.634783230494
total_rewards_min            390.9227672462024
Number of train steps total  1060000
Number of env steps total    1365425
Number of rollouts total     0
Train Time (s)               190.08662203606218
(Previous) Eval Time (s)     29.858948060311377
Sample Time (s)              5.9182915217243135
Epoch Time (s)               225.86386161809787
Total Train Time (s)         58766.4565241714
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:31:08.371025 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #264 | Epoch Duration: 225.954936504364
2020-01-12 08:31:08.371174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0922537
Z variance train             0.021265214
KL Divergence                20.80736
KL Loss                      2.080736
QF Loss                      482.86966
VF Loss                      106.92426
Policy Loss                  -1189.6965
Q Predictions Mean           1184.5027
Q Predictions Std            496.6644
Q Predictions Max            1816.4238
Q Predictions Min            -68.75158
V Predictions Mean           1188.0659
V Predictions Std            494.93146
V Predictions Max            1806.1915
V Predictions Min            99.277306
Log Pis Mean                 0.4804484
Log Pis Std                  3.4600525
Log Pis Max                  13.872038
Log Pis Min                  -7.8101044
Policy mu Mean               0.10432176
Policy mu Std                0.64087284
Policy mu Max                3.1783118
Policy mu Min                -2.2644591
Policy log std Mean          -0.99036926
Policy log std Std           0.31423473
Policy log std Max           -0.24206883
Policy log std Min           -2.6157846
Z mean eval                  1.2523428
Z variance eval              0.02372478
total_rewards                [1051.49712499  366.48845938  176.03796853 1137.39080658  413.98456937
 1014.75643136 2565.08039308 4355.71449545 4754.43192016 1450.27940641]
total_rewards_mean           1728.566157531412
total_rewards_std            1553.9025344581164
total_rewards_max            4754.43192016144
total_rewards_min            176.0379685302462
Number of train steps total  1064000
Number of env steps total    1374160
Number of rollouts total     0
Train Time (s)               191.71711549302563
(Previous) Eval Time (s)     12.411362200044096
Sample Time (s)              6.780859001912177
Epoch Time (s)               210.9093366949819
Total Train Time (s)         58977.47020056937
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:34:39.387869 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #265 | Epoch Duration: 211.0165753364563
2020-01-12 08:34:39.388076 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2514769
Z variance train             0.023670506
KL Divergence                19.182318
KL Loss                      1.9182318
QF Loss                      939.6266
VF Loss                      237.62717
Policy Loss                  -1229.773
Q Predictions Mean           1222.5603
Q Predictions Std            492.46075
Q Predictions Max            1841.1125
Q Predictions Min            306.0101
V Predictions Mean           1231.1316
V Predictions Std            490.36035
V Predictions Max            1825.1606
V Predictions Min            301.37332
Log Pis Mean                 0.2784173
Log Pis Std                  3.4881291
Log Pis Max                  14.1966095
Log Pis Min                  -7.4031982
Policy mu Mean               0.05287347
Policy mu Std                0.63945466
Policy mu Max                2.8243725
Policy mu Min                -3.194557
Policy log std Mean          -0.99182045
Policy log std Std           0.31524947
Policy log std Max           -0.06316042
Policy log std Min           -2.5261245
Z mean eval                  1.125141
Z variance eval              0.028429922
total_rewards                [4485.45175316  814.26945625 2583.72524898 2025.6080786  3209.95503221
   46.66312715 1844.54007335 2374.1721909   209.2786215  2116.72390772]
total_rewards_mean           1971.038748982337
total_rewards_std            1287.6500689664354
total_rewards_max            4485.451753156839
total_rewards_min            46.663127152949855
Number of train steps total  1068000
Number of env steps total    1382882
Number of rollouts total     0
Train Time (s)               190.00688455905765
(Previous) Eval Time (s)     18.42773381015286
Sample Time (s)              7.295184757560492
Epoch Time (s)               215.729803126771
Total Train Time (s)         59193.29150507646
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:38:15.210717 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #266 | Epoch Duration: 215.82250833511353
2020-01-12 08:38:15.210858 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1246387
Z variance train             0.028805112
KL Divergence                20.05981
KL Loss                      2.0059812
QF Loss                      1265.2601
VF Loss                      587.25726
Policy Loss                  -1197.8276
Q Predictions Mean           1191.4888
Q Predictions Std            469.23447
Q Predictions Max            1787.31
Q Predictions Min            -26.336485
V Predictions Mean           1194.8335
V Predictions Std            464.45358
V Predictions Max            1766.7809
V Predictions Min            223.87807
Log Pis Mean                 0.41309315
Log Pis Std                  3.437281
Log Pis Max                  14.662872
Log Pis Min                  -7.401065
Policy mu Mean               0.055384547
Policy mu Std                0.6547324
Policy mu Max                2.993112
Policy mu Min                -5.669241
Policy log std Mean          -1.0106986
Policy log std Std           0.34268227
Policy log std Max           0.98845154
Policy log std Min           -2.5935512
Z mean eval                  1.0807555
Z variance eval              0.01775091
total_rewards                [4561.52130328 3176.48976442 4582.47874809 1253.36443789 2270.20467174
 4758.46276908 2468.1998565  1457.31503582 3416.62634366 4467.76129367]
total_rewards_mean           3241.242422414286
total_rewards_std            1267.196696528391
total_rewards_max            4758.462769077014
total_rewards_min            1253.3644378917425
Number of train steps total  1072000
Number of env steps total    1391792
Number of rollouts total     0
Train Time (s)               191.0717604169622
(Previous) Eval Time (s)     25.871524527668953
Sample Time (s)              7.717199406120926
Epoch Time (s)               224.66048435075209
Total Train Time (s)         59418.121325616725
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:42:00.044165 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #267 | Epoch Duration: 224.83318328857422
2020-01-12 08:42:00.044379 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0846934
Z variance train             0.01769359
KL Divergence                21.70707
KL Loss                      2.170707
QF Loss                      854.0604
VF Loss                      164.57437
Policy Loss                  -1265.9099
Q Predictions Mean           1256.137
Q Predictions Std            474.0361
Q Predictions Max            1858.61
Q Predictions Min            -61.49466
V Predictions Mean           1261.6672
V Predictions Std            467.38965
V Predictions Max            1869.3824
V Predictions Min            338.3732
Log Pis Mean                 0.6381006
Log Pis Std                  3.5287507
Log Pis Max                  10.443319
Log Pis Min                  -8.309488
Policy mu Mean               0.047817625
Policy mu Std                0.65269285
Policy mu Max                3.5632389
Policy mu Min                -2.3830848
Policy log std Mean          -1.0188032
Policy log std Std           0.33517006
Policy log std Max           -0.16245508
Policy log std Min           -2.8512387
Z mean eval                  1.040788
Z variance eval              0.24039781
total_rewards                [4600.17364344 4893.26742661 4735.90801345 4822.6272358  4479.78692034
 4788.35696036 4661.93086034 4882.02690631 4684.71556168 4697.24774753]
total_rewards_mean           4724.604127586282
total_rewards_std            121.94908321066366
total_rewards_max            4893.267426614189
total_rewards_min            4479.786920341224
Number of train steps total  1076000
Number of env steps total    1401521
Number of rollouts total     0
Train Time (s)               191.0786514999345
(Previous) Eval Time (s)     33.34706400800496
Sample Time (s)              7.6721084411256015
Epoch Time (s)               232.09782394906506
Total Train Time (s)         59650.31179610966
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:45:52.237253 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #268 | Epoch Duration: 232.19272208213806
2020-01-12 08:45:52.237454 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0428556
Z variance train             0.24254242
KL Divergence                19.155165
KL Loss                      1.9155165
QF Loss                      635.21204
VF Loss                      184.1437
Policy Loss                  -1187.4058
Q Predictions Mean           1180.4841
Q Predictions Std            498.70337
Q Predictions Max            1806.0588
Q Predictions Min            333.3028
V Predictions Mean           1181.4929
V Predictions Std            493.6535
V Predictions Max            1784.051
V Predictions Min            339.4486
Log Pis Mean                 0.21342745
Log Pis Std                  3.3685625
Log Pis Max                  11.361394
Log Pis Min                  -6.9725637
Policy mu Mean               0.08686357
Policy mu Std                0.6588343
Policy mu Max                2.5434992
Policy mu Min                -2.3833
Policy log std Mean          -0.9684701
Policy log std Std           0.32449016
Policy log std Max           -0.14222217
Policy log std Min           -2.456573
Z mean eval                  1.1585468
Z variance eval              0.04298402
total_rewards                [4187.71674355 4565.60055692 4633.28985641 4082.08401136 4352.68902852
 4224.90060655 4550.52379433 4336.38249383 4143.08111688 4386.22673522]
total_rewards_mean           4346.249494356304
total_rewards_std            180.24733853040382
total_rewards_max            4633.289856406876
total_rewards_min            4082.084011359119
Number of train steps total  1080000
Number of env steps total    1410977
Number of rollouts total     0
Train Time (s)               190.57466640602797
(Previous) Eval Time (s)     33.107953254599124
Sample Time (s)              7.4039497072808444
Epoch Time (s)               231.08656936790794
Total Train Time (s)         59881.49727315828
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:49:43.424517 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #269 | Epoch Duration: 231.18692564964294
2020-01-12 08:49:43.424673 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1601262
Z variance train             0.041217554
KL Divergence                20.26301
KL Loss                      2.0263011
QF Loss                      928.64954
VF Loss                      207.83594
Policy Loss                  -1187.0452
Q Predictions Mean           1180.9932
Q Predictions Std            497.0325
Q Predictions Max            1809.401
Q Predictions Min            331.06973
V Predictions Mean           1177.9965
V Predictions Std            494.7513
V Predictions Max            1805.9957
V Predictions Min            331.42764
Log Pis Mean                 0.029374838
Log Pis Std                  3.4169798
Log Pis Max                  12.678644
Log Pis Min                  -7.9420815
Policy mu Mean               0.04695302
Policy mu Std                0.62087655
Policy mu Max                2.5808568
Policy mu Min                -2.6349828
Policy log std Mean          -0.97738814
Policy log std Std           0.32467932
Policy log std Max           -0.2738729
Policy log std Min           -2.5916686
Z mean eval                  1.1198208
Z variance eval              0.008226405
total_rewards                [4562.80057132 1738.96441599 4104.71702046 4998.134893   4725.18641983
 3125.70395344 4684.31595331  215.64942962 4474.37084819 1441.91451839]
total_rewards_mean           3407.1758023541743
total_rewards_std            1605.3216356229386
total_rewards_max            4998.134892998736
total_rewards_min            215.64942961895338
Number of train steps total  1084000
Number of env steps total    1420515
Number of rollouts total     0
Train Time (s)               191.08958682091907
(Previous) Eval Time (s)     25.793891292065382
Sample Time (s)              6.916648718994111
Epoch Time (s)               223.80012683197856
Total Train Time (s)         60105.38891440816
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:53:27.318220 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #270 | Epoch Duration: 223.89343190193176
2020-01-12 08:53:27.318362 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1193223
Z variance train             0.008220606
KL Divergence                22.283688
KL Loss                      2.2283688
QF Loss                      838.99066
VF Loss                      147.92049
Policy Loss                  -1266.2275
Q Predictions Mean           1261.8296
Q Predictions Std            470.09744
Q Predictions Max            1849.1976
Q Predictions Min            339.5436
V Predictions Mean           1266.2772
V Predictions Std            469.92798
V Predictions Max            1833.4525
V Predictions Min            346.91345
Log Pis Mean                 0.2111556
Log Pis Std                  3.5043197
Log Pis Max                  20.730732
Log Pis Min                  -7.6525545
Policy mu Mean               0.052773148
Policy mu Std                0.6613998
Policy mu Max                3.1212778
Policy mu Min                -4.224115
Policy log std Mean          -0.97282857
Policy log std Std           0.3322768
Policy log std Max           -0.21293205
Policy log std Min           -2.6299345
Z mean eval                  1.083881
Z variance eval              0.006614849
total_rewards                [4560.8670847  2859.68922921 2683.25247169 2466.82552539 2741.23292069
  798.83140346 4277.94558    4800.47157357 4637.51892242 3120.79513811]
total_rewards_mean           3294.7429849246605
total_rewards_std            1202.2840340374312
total_rewards_max            4800.471573570033
total_rewards_min            798.8314034625902
Number of train steps total  1088000
Number of env steps total    1431206
Number of rollouts total     0
Train Time (s)               191.92778295418248
(Previous) Eval Time (s)     24.918567900080234
Sample Time (s)              7.243383083026856
Epoch Time (s)               224.08973393728957
Total Train Time (s)         60329.57883564336
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:57:11.514068 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #271 | Epoch Duration: 224.19556832313538
2020-01-12 08:57:11.514336 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0856817
Z variance train             0.0066372575
KL Divergence                22.52625
KL Loss                      2.2526252
QF Loss                      850.4674
VF Loss                      113.283005
Policy Loss                  -1194.4448
Q Predictions Mean           1187.7603
Q Predictions Std            515.6716
Q Predictions Max            1849.1793
Q Predictions Min            322.70975
V Predictions Mean           1192.1439
V Predictions Std            520.41833
V Predictions Max            1855.974
V Predictions Min            292.95297
Log Pis Mean                 0.061394855
Log Pis Std                  3.6728523
Log Pis Max                  19.7016
Log Pis Min                  -9.243628
Policy mu Mean               -0.020978332
Policy mu Std                0.65159833
Policy mu Max                2.7535713
Policy mu Min                -2.6704533
Policy log std Mean          -0.94943583
Policy log std Std           0.3412415
Policy log std Max           -0.16503167
Policy log std Min           -2.9589925
Z mean eval                  1.226407
Z variance eval              0.0068869144
total_rewards                [4443.72503317 4982.47781613 4887.1068046  4481.84266605  450.67695684
 4472.52162229  750.39566523 4124.10793652 4543.22394098 4939.1577023 ]
total_rewards_mean           3807.523614411133
total_rewards_std            1624.322169777233
total_rewards_max            4982.477816129659
total_rewards_min            450.6769568427519
Number of train steps total  1092000
Number of env steps total    1442178
Number of rollouts total     0
Train Time (s)               190.32806800073013
(Previous) Eval Time (s)     23.583037363830954
Sample Time (s)              7.115869947243482
Epoch Time (s)               221.02697531180456
Total Train Time (s)         60550.739988635294
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:00:52.682442 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #272 | Epoch Duration: 221.16787266731262
2020-01-12 09:00:52.682784 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2184246
Z variance train             0.006859326
KL Divergence                23.107899
KL Loss                      2.3107898
QF Loss                      18459.809
VF Loss                      310.2096
Policy Loss                  -1223.1483
Q Predictions Mean           1223.2738
Q Predictions Std            516.8211
Q Predictions Max            1834.381
Q Predictions Min            123.00251
V Predictions Mean           1231.4518
V Predictions Std            518.8258
V Predictions Max            1839.5924
V Predictions Min            23.401512
Log Pis Mean                 0.17494275
Log Pis Std                  4.0482116
Log Pis Max                  32.480484
Log Pis Min                  -8.061303
Policy mu Mean               0.013667094
Policy mu Std                0.66805786
Policy mu Max                3.4728236
Policy mu Min                -5.293891
Policy log std Mean          -0.98286057
Policy log std Std           0.32388583
Policy log std Max           -0.30668724
Policy log std Min           -2.5176072
Z mean eval                  1.0816973
Z variance eval              0.002785722
total_rewards                [3264.68285412 4549.88014337 4809.04229794  473.72167422 4796.6102244
  188.95046945 2098.81564249 4733.14934527 4829.23477434 4503.50466489]
total_rewards_mean           3424.759209048967
total_rewards_std            1757.13037729825
total_rewards_max            4829.234774337484
total_rewards_min            188.95046944721616
Number of train steps total  1096000
Number of env steps total    1452112
Number of rollouts total     0
Train Time (s)               190.86240052478388
(Previous) Eval Time (s)     25.301176514010876
Sample Time (s)              6.822882505599409
Epoch Time (s)               222.98645954439417
Total Train Time (s)         60773.8170107021
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:04:35.759783 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #273 | Epoch Duration: 223.07677459716797
2020-01-12 09:04:35.759925 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0982586
Z variance train             0.0027773695
KL Divergence                24.692013
KL Loss                      2.4692013
QF Loss                      1008.70636
VF Loss                      129.83237
Policy Loss                  -1270.8151
Q Predictions Mean           1262.1987
Q Predictions Std            463.49576
Q Predictions Max            1868.7802
Q Predictions Min            366.30838
V Predictions Mean           1270.3899
V Predictions Std            464.82208
V Predictions Max            1869.3119
V Predictions Min            363.05444
Log Pis Mean                 0.680413
Log Pis Std                  3.459022
Log Pis Max                  12.831841
Log Pis Min                  -7.0480003
Policy mu Mean               0.070315115
Policy mu Std                0.6765446
Policy mu Max                2.684966
Policy mu Min                -2.61147
Policy log std Mean          -0.9869951
Policy log std Std           0.30022982
Policy log std Max           -0.3468256
Policy log std Min           -2.599774
Z mean eval                  1.0536122
Z variance eval              0.013963302
total_rewards                [4714.56884669 2134.41903469 4835.74851871 2958.42305029 1346.17396295
 4700.01407003 2026.69501765  356.33737808 4008.218964   3973.31890675]
total_rewards_mean           3105.391774984541
total_rewards_std            1499.1638323348132
total_rewards_max            4835.748518713379
total_rewards_min            356.3373780847018
Number of train steps total  1100000
Number of env steps total    1460595
Number of rollouts total     0
Train Time (s)               190.87188351387158
(Previous) Eval Time (s)     21.916249536909163
Sample Time (s)              7.058673327323049
Epoch Time (s)               219.8468063781038
Total Train Time (s)         60993.75244331779
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:08:15.698961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #274 | Epoch Duration: 219.93889451026917
2020-01-12 09:08:15.699111 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.059416
Z variance train             0.013879372
KL Divergence                22.43627
KL Loss                      2.243627
QF Loss                      628.21533
VF Loss                      162.65063
Policy Loss                  -1191.9751
Q Predictions Mean           1187.5524
Q Predictions Std            526.0239
Q Predictions Max            1897.1022
Q Predictions Min            361.3753
V Predictions Mean           1193.7356
V Predictions Std            525.2948
V Predictions Max            1896.0461
V Predictions Min            363.1106
Log Pis Mean                 -0.09487256
Log Pis Std                  3.3886874
Log Pis Max                  10.685485
Log Pis Min                  -6.678931
Policy mu Mean               0.069429256
Policy mu Std                0.608412
Policy mu Max                2.3104224
Policy mu Min                -3.3717132
Policy log std Mean          -0.9732619
Policy log std Std           0.33692867
Policy log std Max           -0.059449553
Policy log std Min           -2.57194
Z mean eval                  1.1089406
Z variance eval              0.0071244887
total_rewards                [4802.83591811 4732.64983836 4768.37953597  964.55639011 1882.99603326
 2660.49363782  554.12881949 4852.92471699 4454.58888184 4843.4826556 ]
total_rewards_mean           3451.70364275428
total_rewards_std            1666.582229003121
total_rewards_max            4852.924716991376
total_rewards_min            554.1288194933109
Number of train steps total  1104000
Number of env steps total    1468088
Number of rollouts total     0
Train Time (s)               190.5399233289063
(Previous) Eval Time (s)     26.888148919213563
Sample Time (s)              7.00315005145967
Epoch Time (s)               224.43122229957953
Total Train Time (s)         61218.2724256753
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:12:00.222132 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #275 | Epoch Duration: 224.5228989124298
2020-01-12 09:12:00.222316 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1124738
Z variance train             0.007112111
KL Divergence                24.496632
KL Loss                      2.4496632
QF Loss                      17068.52
VF Loss                      150.51569
Policy Loss                  -1284.9435
Q Predictions Mean           1278.8325
Q Predictions Std            501.79718
Q Predictions Max            1913.0652
Q Predictions Min            -95.17675
V Predictions Mean           1288.5525
V Predictions Std            499.13824
V Predictions Max            1886.6039
V Predictions Min            -26.400158
Log Pis Mean                 0.6757711
Log Pis Std                  3.8486004
Log Pis Max                  18.816118
Log Pis Min                  -8.357401
Policy mu Mean               0.023760624
Policy mu Std                0.67354107
Policy mu Max                3.1111135
Policy mu Min                -2.3907769
Policy log std Mean          -0.9908937
Policy log std Std           0.3330279
Policy log std Max           -0.21383357
Policy log std Min           -2.7387512
Z mean eval                  1.0640709
Z variance eval              0.010202473
total_rewards                [2544.91284044 1074.39692067 1575.31304337 2399.75363816 2816.11274236
  446.78678393 4771.53525123  709.43554075 4440.09234812 4401.27650049]
total_rewards_mean           2517.9615609511793
total_rewards_std            1515.1450866016955
total_rewards_max            4771.535251230098
total_rewards_min            446.78678392545214
Number of train steps total  1108000
Number of env steps total    1476032
Number of rollouts total     0
Train Time (s)               191.19512578705326
(Previous) Eval Time (s)     18.218746596947312
Sample Time (s)              6.970804885495454
Epoch Time (s)               216.38467726949602
Total Train Time (s)         61434.7496971041
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:15:36.704439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #276 | Epoch Duration: 216.48197054862976
2020-01-12 09:15:36.704653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0619274
Z variance train             0.010220855
KL Divergence                22.436268
KL Loss                      2.2436268
QF Loss                      613.8031
VF Loss                      281.87726
Policy Loss                  -1241.6873
Q Predictions Mean           1237.8423
Q Predictions Std            504.6859
Q Predictions Max            1905.4264
Q Predictions Min            298.185
V Predictions Mean           1250.969
V Predictions Std            503.87958
V Predictions Max            1917.635
V Predictions Min            293.84973
Log Pis Mean                 0.013653487
Log Pis Std                  3.2434683
Log Pis Max                  12.999817
Log Pis Min                  -8.254541
Policy mu Mean               0.04947575
Policy mu Std                0.64713866
Policy mu Max                2.4616475
Policy mu Min                -2.8629076
Policy log std Mean          -0.9486178
Policy log std Std           0.32690337
Policy log std Max           -0.16235614
Policy log std Min           -2.499669
Z mean eval                  1.1207345
Z variance eval              0.0173886
total_rewards                [ 188.03390611 1628.52378793 4994.10911674 2319.98814894 2767.7527517
  581.34286748  870.74927464  737.54744232 4742.79995796 1028.75495804]
total_rewards_mean           1985.96022118546
total_rewards_std            1625.5344018349192
total_rewards_max            4994.109116737697
total_rewards_min            188.03390611062952
Number of train steps total  1112000
Number of env steps total    1486638
Number of rollouts total     0
Train Time (s)               191.43173006596044
(Previous) Eval Time (s)     16.011371104046702
Sample Time (s)              7.1948663531802595
Epoch Time (s)               214.6379675231874
Total Train Time (s)         61649.491028940305
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:19:11.452736 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #277 | Epoch Duration: 214.74792861938477
2020-01-12 09:19:11.452883 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.118784
Z variance train             0.017484123
KL Divergence                21.460178
KL Loss                      2.1460178
QF Loss                      925.0867
VF Loss                      242.63208
Policy Loss                  -1314.9495
Q Predictions Mean           1307.96
Q Predictions Std            494.60425
Q Predictions Max            1948.8369
Q Predictions Min            279.85565
V Predictions Mean           1313.9729
V Predictions Std            495.66135
V Predictions Max            1917.0457
V Predictions Min            370.2586
Log Pis Mean                 0.7080916
Log Pis Std                  3.8081515
Log Pis Max                  26.159122
Log Pis Min                  -6.870446
Policy mu Mean               0.074367315
Policy mu Std                0.7121515
Policy mu Max                3.1980128
Policy mu Min                -3.396954
Policy log std Mean          -0.9720074
Policy log std Std           0.32924685
Policy log std Max           -0.013024569
Policy log std Min           -2.7133098
Z mean eval                  1.0120647
Z variance eval              0.021060769
total_rewards                [ 555.20803553  762.82334843 1896.37436459 3138.27801078 4086.26378018
 2181.46716604 3379.04783195 4706.67805952 2213.62086049 1718.84437986]
total_rewards_mean           2463.86058373543
total_rewards_std            1284.9422892401974
total_rewards_max            4706.678059518039
total_rewards_min            555.2080355252665
Number of train steps total  1116000
Number of env steps total    1495005
Number of rollouts total     0
Train Time (s)               193.16232260502875
(Previous) Eval Time (s)     17.886529597919434
Sample Time (s)              7.018170098774135
Epoch Time (s)               218.06702230172232
Total Train Time (s)         61867.656728613656
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:22:49.621322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #278 | Epoch Duration: 218.16831755638123
2020-01-12 09:22:49.621512 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0158455
Z variance train             0.020945543
KL Divergence                21.303185
KL Loss                      2.1303184
QF Loss                      910.21344
VF Loss                      146.50755
Policy Loss                  -1251.6592
Q Predictions Mean           1244.4954
Q Predictions Std            482.87616
Q Predictions Max            1896.0304
Q Predictions Min            320.72897
V Predictions Mean           1250.9934
V Predictions Std            480.2028
V Predictions Max            1884.9556
V Predictions Min            359.01685
Log Pis Mean                 0.19318388
Log Pis Std                  3.5573962
Log Pis Max                  15.871703
Log Pis Min                  -7.7511663
Policy mu Mean               0.0694698
Policy mu Std                0.64250237
Policy mu Max                2.94445
Policy mu Min                -2.6694992
Policy log std Mean          -0.9686812
Policy log std Std           0.31723207
Policy log std Max           -0.13630128
Policy log std Min           -2.7443461
Z mean eval                  1.0525854
Z variance eval              0.022385385
total_rewards                [4801.61029599 4593.10670387 4126.41598846 3324.71709376 4694.58021336
 4595.00237066 3533.46604322 4874.89634184 1584.3769675  4678.18489829]
total_rewards_mean           4080.635691695158
total_rewards_std            975.5028402695715
total_rewards_max            4874.896341844266
total_rewards_min            1584.3769675009346
Number of train steps total  1120000
Number of env steps total    1504643
Number of rollouts total     0
Train Time (s)               190.5538366441615
(Previous) Eval Time (s)     29.007805251982063
Sample Time (s)              6.343071037437767
Epoch Time (s)               225.90471293358132
Total Train Time (s)         62093.652391037904
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:26:35.622842 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #279 | Epoch Duration: 226.00116276741028
2020-01-12 09:26:35.623114 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0514934
Z variance train             0.022372305
KL Divergence                21.145504
KL Loss                      2.1145504
QF Loss                      458.48108
VF Loss                      107.9207
Policy Loss                  -1277.2356
Q Predictions Mean           1269.4965
Q Predictions Std            527.49274
Q Predictions Max            1966.4381
Q Predictions Min            360.17194
V Predictions Mean           1277.4633
V Predictions Std            524.967
V Predictions Max            1968.0853
V Predictions Min            384.88025
Log Pis Mean                 0.1359014
Log Pis Std                  3.4810908
Log Pis Max                  11.361597
Log Pis Min                  -7.259847
Policy mu Mean               0.09083255
Policy mu Std                0.6613109
Policy mu Max                2.6217365
Policy mu Min                -2.4973693
Policy log std Mean          -0.9438784
Policy log std Std           0.3411597
Policy log std Max           -0.2715513
Policy log std Min           -2.6053822
Z mean eval                  1.1671948
Z variance eval              0.034692843
total_rewards                [4819.8311245  4984.99341776 3386.46786358 3477.54113661 4918.50107741
 4528.67433832 4814.82817492 4990.89125849 3944.13830203 4820.87952698]
total_rewards_mean           4468.674622060061
total_rewards_std            595.0694070064565
total_rewards_max            4990.8912584912905
total_rewards_min            3386.4678635831856
Number of train steps total  1124000
Number of env steps total    1512793
Number of rollouts total     0
Train Time (s)               190.88732750015333
(Previous) Eval Time (s)     31.014863195829093
Sample Time (s)              16.387491940986365
Epoch Time (s)               238.2896826369688
Total Train Time (s)         62332.03609449137
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:30:34.007491 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #280 | Epoch Duration: 238.38419151306152
2020-01-12 09:30:34.007648 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1668874
Z variance train             0.034413822
KL Divergence                20.519423
KL Loss                      2.0519423
QF Loss                      588.27905
VF Loss                      94.45342
Policy Loss                  -1332.9418
Q Predictions Mean           1323.4939
Q Predictions Std            476.48206
Q Predictions Max            1918.609
Q Predictions Min            262.67868
V Predictions Mean           1331.2198
V Predictions Std            474.33902
V Predictions Max            1918.0302
V Predictions Min            344.78198
Log Pis Mean                 0.8572695
Log Pis Std                  3.3994763
Log Pis Max                  17.428112
Log Pis Min                  -7.6768827
Policy mu Mean               0.06519389
Policy mu Std                0.67777723
Policy mu Max                2.6290708
Policy mu Min                -2.13882
Policy log std Mean          -1.0068033
Policy log std Std           0.33557418
Policy log std Max           -0.22784579
Policy log std Min           -3.2957015
Z mean eval                  1.1676844
Z variance eval              0.019725796
total_rewards                [ 363.35183843 1576.57383496  330.42448946 1797.36284185 1813.15868323
 4579.57162093 1849.82076799 1616.44666472 2546.01778567  754.68452427]
total_rewards_mean           1722.7413051522217
total_rewards_std            1167.2805888404048
total_rewards_max            4579.5716209323855
total_rewards_min            330.42448945893386
Number of train steps total  1128000
Number of env steps total    1520018
Number of rollouts total     0
Train Time (s)               188.5869783088565
(Previous) Eval Time (s)     14.744009260088205
Sample Time (s)              6.882295386865735
Epoch Time (s)               210.21328295581043
Total Train Time (s)         62542.33879413735
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:34:04.312625 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #281 | Epoch Duration: 210.30486726760864
2020-01-12 09:34:04.312778 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1620743
Z variance train             0.019038275
KL Divergence                21.510641
KL Loss                      2.1510642
QF Loss                      605.09875
VF Loss                      190.11475
Policy Loss                  -1358.8687
Q Predictions Mean           1352.386
Q Predictions Std            460.6056
Q Predictions Max            1921.6111
Q Predictions Min            376.6445
V Predictions Mean           1351.5603
V Predictions Std            459.52332
V Predictions Max            1910.524
V Predictions Min            374.7355
Log Pis Mean                 0.9355435
Log Pis Std                  3.905995
Log Pis Max                  23.35063
Log Pis Min                  -11.179415
Policy mu Mean               0.044853948
Policy mu Std                0.71202034
Policy mu Max                5.574054
Policy mu Min                -4.998518
Policy log std Mean          -1.0170426
Policy log std Std           0.33577985
Policy log std Max           -0.29897183
Policy log std Min           -2.6312943
Z mean eval                  1.0609941
Z variance eval              0.019893473
total_rewards                [5097.35096276 3520.69685445 4638.03512732 3055.00474781 4840.61991785
 4627.15853025 4992.96019541 5150.54561934 4954.92636331 4882.41050156]
total_rewards_mean           4575.9708820044525
total_rewards_std            672.0727947760264
total_rewards_max            5150.545619335474
total_rewards_min            3055.004747809233
Number of train steps total  1132000
Number of env steps total    1531146
Number of rollouts total     0
Train Time (s)               190.93161687767133
(Previous) Eval Time (s)     30.946172336116433
Sample Time (s)              7.196481653954834
Epoch Time (s)               229.0742708677426
Total Train Time (s)         62771.50728174439
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:37:53.482750 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #282 | Epoch Duration: 229.1698660850525
2020-01-12 09:37:53.482915 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0720268
Z variance train             0.019799601
KL Divergence                19.438185
KL Loss                      1.9438184
QF Loss                      415.3504
VF Loss                      104.86337
Policy Loss                  -1245.4409
Q Predictions Mean           1239.4093
Q Predictions Std            472.50266
Q Predictions Max            1885.8807
Q Predictions Min            350.63745
V Predictions Mean           1248.2854
V Predictions Std            472.94864
V Predictions Max            1875.2432
V Predictions Min            359.685
Log Pis Mean                 -0.002486512
Log Pis Std                  3.6601732
Log Pis Max                  13.652653
Log Pis Min                  -8.143827
Policy mu Mean               0.09029324
Policy mu Std                0.6580023
Policy mu Max                2.9630413
Policy mu Min                -2.7856853
Policy log std Mean          -0.9505172
Policy log std Std           0.29780075
Policy log std Max           -0.12216389
Policy log std Min           -2.491786
Z mean eval                  1.0750496
Z variance eval              0.05361087
total_rewards                [5004.24609812 2070.70671224 3570.85165324 4817.59589985 4989.01991437
  670.94025861 4983.21375703 3088.24093041 4919.56762017 3763.48797955]
total_rewards_mean           3787.787082359351
total_rewards_std            1410.4370436244756
total_rewards_max            5004.246098116377
total_rewards_min            670.9402586083979
Number of train steps total  1136000
Number of env steps total    1540352
Number of rollouts total     0
Train Time (s)               191.1764083430171
(Previous) Eval Time (s)     25.841766103636473
Sample Time (s)              6.839067691005766
Epoch Time (s)               223.85724213765934
Total Train Time (s)         62995.46090379171
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:41:37.438530 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #283 | Epoch Duration: 223.95550775527954
2020-01-12 09:41:37.438685 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0754641
Z variance train             0.053470206
KL Divergence                18.500103
KL Loss                      1.8500103
QF Loss                      752.72375
VF Loss                      235.27167
Policy Loss                  -1305.296
Q Predictions Mean           1297.8472
Q Predictions Std            484.73972
Q Predictions Max            1875.0791
Q Predictions Min            0.41094494
V Predictions Mean           1310.8417
V Predictions Std            486.80774
V Predictions Max            1887.7047
V Predictions Min            145.9408
Log Pis Mean                 0.71256256
Log Pis Std                  3.8201816
Log Pis Max                  17.052725
Log Pis Min                  -9.728748
Policy mu Mean               0.061326016
Policy mu Std                0.6826109
Policy mu Max                2.3911352
Policy mu Min                -2.94738
Policy log std Mean          -1.0101365
Policy log std Std           0.34575614
Policy log std Max           -0.044767976
Policy log std Min           -3.2665808
Z mean eval                  1.1791744
Z variance eval              0.018352773
total_rewards                [4631.7917573  2188.23158924 2034.06352823  719.21079284 3911.57293092
 2575.66220804 4727.54237069 2481.62903338 4587.79789829 4682.92998978]
total_rewards_mean           3254.0432098716033
total_rewards_std            1357.5293672726284
total_rewards_max            4727.542370694831
total_rewards_min            719.2107928355096
Number of train steps total  1140000
Number of env steps total    1550309
Number of rollouts total     0
Train Time (s)               190.12584917759523
(Previous) Eval Time (s)     26.23319894913584
Sample Time (s)              6.989931867923588
Epoch Time (s)               223.34897999465466
Total Train Time (s)         63218.89848839911
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:45:20.878107 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #284 | Epoch Duration: 223.4393150806427
2020-01-12 09:45:20.878252 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1805421
Z variance train             0.01833194
KL Divergence                22.42128
KL Loss                      2.2421281
QF Loss                      710.63837
VF Loss                      189.50229
Policy Loss                  -1301.7487
Q Predictions Mean           1296.156
Q Predictions Std            505.75702
Q Predictions Max            1898.6544
Q Predictions Min            356.28665
V Predictions Mean           1298.4883
V Predictions Std            506.04083
V Predictions Max            1897.4872
V Predictions Min            366.576
Log Pis Mean                 0.67176104
Log Pis Std                  3.6650274
Log Pis Max                  16.641945
Log Pis Min                  -8.449995
Policy mu Mean               0.016676556
Policy mu Std                0.6585264
Policy mu Max                2.3213973
Policy mu Min                -3.288842
Policy log std Mean          -1.0011854
Policy log std Std           0.36354342
Policy log std Max           -0.33123732
Policy log std Min           -2.595064
Z mean eval                  1.1195295
Z variance eval              0.025300289
total_rewards                [4503.59344968 2306.32869884 2708.00663899 2201.7399985  1023.0875126
 4769.03030296 4833.60351211 1318.17999452 1250.7791856  4570.95403141]
total_rewards_mean           2948.5303325201357
total_rewards_std            1489.7618136669169
total_rewards_max            4833.603512113459
total_rewards_min            1023.0875125964758
Number of train steps total  1144000
Number of env steps total    1561213
Number of rollouts total     0
Train Time (s)               189.24146189028397
(Previous) Eval Time (s)     22.814867519773543
Sample Time (s)              7.287711368873715
Epoch Time (s)               219.34404077893123
Total Train Time (s)         63438.345366138965
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:49:00.326904 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #285 | Epoch Duration: 219.44854044914246
2020-01-12 09:49:00.327065 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1135659
Z variance train             0.025293287
KL Divergence                20.205988
KL Loss                      2.020599
QF Loss                      652.5525
VF Loss                      113.30526
Policy Loss                  -1302.7128
Q Predictions Mean           1296.1637
Q Predictions Std            487.65805
Q Predictions Max            1924.078
Q Predictions Min            362.18146
V Predictions Mean           1302.5726
V Predictions Std            489.2416
V Predictions Max            1928.118
V Predictions Min            358.67163
Log Pis Mean                 0.6697848
Log Pis Std                  3.5970023
Log Pis Max                  24.676262
Log Pis Min                  -7.175985
Policy mu Mean               0.1381751
Policy mu Std                0.6506136
Policy mu Max                3.3927028
Policy mu Min                -4.5324636
Policy log std Mean          -1.0080612
Policy log std Std           0.3217924
Policy log std Max           0.31893814
Policy log std Min           -2.6338143
Z mean eval                  1.0251482
Z variance eval              0.007736637
total_rewards                [4711.25736836 1942.01233635 3544.12878375 2650.42753598 4858.36482077
 4003.40239583 4447.81932178 4598.98413972 4454.59399097 2716.19129092]
total_rewards_mean           3792.718198441874
total_rewards_std            974.251179174227
total_rewards_max            4858.364820772104
total_rewards_min            1942.0123363468426
Number of train steps total  1148000
Number of env steps total    1571690
Number of rollouts total     0
Train Time (s)               191.4848111611791
(Previous) Eval Time (s)     24.82924807490781
Sample Time (s)              7.498717804905027
Epoch Time (s)               223.81277704099193
Total Train Time (s)         63662.25248311134
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:52:44.238418 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #286 | Epoch Duration: 223.91120648384094
2020-01-12 09:52:44.238700 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0276892
Z variance train             0.007743535
KL Divergence                21.811089
KL Loss                      2.181109
QF Loss                      18552.527
VF Loss                      180.49738
Policy Loss                  -1293.526
Q Predictions Mean           1289.7782
Q Predictions Std            508.39108
Q Predictions Max            1980.3281
Q Predictions Min            333.56583
V Predictions Mean           1286.7861
V Predictions Std            507.19406
V Predictions Max            1963.1028
V Predictions Min            249.86765
Log Pis Mean                 1.0209507
Log Pis Std                  4.0580034
Log Pis Max                  19.185272
Log Pis Min                  -7.330629
Policy mu Mean               0.08413148
Policy mu Std                0.7191613
Policy mu Max                3.6193755
Policy mu Min                -3.4497416
Policy log std Mean          -0.988772
Policy log std Std           0.34802234
Policy log std Max           0.1036886
Policy log std Min           -3.1739779
Z mean eval                  1.0818278
Z variance eval              0.01925325
total_rewards                [  67.03197441 4709.12367697 4454.63406795  627.81213918  914.91492631
 1705.51106563  680.79698775  833.25924399  966.41492469  212.61554659]
total_rewards_mean           1517.21145534807
total_rewards_std            1590.023642924626
total_rewards_max            4709.123676974937
total_rewards_min            67.03197441468807
Number of train steps total  1152000
Number of env steps total    1579889
Number of rollouts total     0
Train Time (s)               191.067573397886
(Previous) Eval Time (s)     12.281003419309855
Sample Time (s)              7.036578799597919
Epoch Time (s)               210.38515561679378
Total Train Time (s)         63872.72532188706
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:56:14.711839 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #287 | Epoch Duration: 210.47295260429382
2020-01-12 09:56:14.711983 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0847172
Z variance train             0.019274876
KL Divergence                21.822466
KL Loss                      2.1822467
QF Loss                      718.72284
VF Loss                      95.65581
Policy Loss                  -1355.6198
Q Predictions Mean           1347.4269
Q Predictions Std            471.0733
Q Predictions Max            1946.809
Q Predictions Min            368.7126
V Predictions Mean           1353.6714
V Predictions Std            470.81116
V Predictions Max            1950.1719
V Predictions Min            370.90857
Log Pis Mean                 0.6755869
Log Pis Std                  3.5565765
Log Pis Max                  14.96907
Log Pis Min                  -6.9651394
Policy mu Mean               0.07408493
Policy mu Std                0.68863887
Policy mu Max                2.965127
Policy mu Min                -2.7221255
Policy log std Mean          -1.0040482
Policy log std Std           0.33003512
Policy log std Max           -0.25993562
Policy log std Min           -2.623621
Z mean eval                  1.0592563
Z variance eval              0.006237391
total_rewards                [ 296.4484618  4695.54046921 4727.18608438 4662.1068781  4451.68505048
 2391.35399638 4615.08984352 2297.66979588 4930.17792107 4566.62612659]
total_rewards_mean           3763.3884627405178
total_rewards_std            1478.5711543754712
total_rewards_max            4930.177921066366
total_rewards_min            296.4484618023501
Number of train steps total  1156000
Number of env steps total    1591540
Number of rollouts total     0
Train Time (s)               189.91610434185714
(Previous) Eval Time (s)     28.635265935678035
Sample Time (s)              6.694540600292385
Epoch Time (s)               225.24591087782755
Total Train Time (s)         64098.05771110207
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:00:00.047642 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #288 | Epoch Duration: 225.3355507850647
2020-01-12 10:00:00.047793 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0563254
Z variance train             0.006216785
KL Divergence                23.405151
KL Loss                      2.3405151
QF Loss                      753.1822
VF Loss                      183.70996
Policy Loss                  -1301.1017
Q Predictions Mean           1295.0546
Q Predictions Std            504.91272
Q Predictions Max            1917.1029
Q Predictions Min            -20.68887
V Predictions Mean           1297.0824
V Predictions Std            503.40808
V Predictions Max            1909.7347
V Predictions Min            -96.43881
Log Pis Mean                 0.7915751
Log Pis Std                  4.1920037
Log Pis Max                  31.552877
Log Pis Min                  -6.662611
Policy mu Mean               0.0864943
Policy mu Std                0.7103197
Policy mu Max                4.699757
Policy mu Min                -8.442023
Policy log std Mean          -1.0220037
Policy log std Std           0.37457252
Policy log std Max           2.0
Policy log std Min           -2.6061587
Z mean eval                  1.2094743
Z variance eval              0.6457143
total_rewards                [ 843.41809017 1238.55597757 1628.72448968   30.28263023 1662.12336211
  650.97160724 2520.50438368   65.39739425 4591.7001003  4364.92218296]
total_rewards_mean           1759.6600218186497
total_rewards_std            1536.713841529138
total_rewards_max            4591.700100297068
total_rewards_min            30.28263023002326
Number of train steps total  1160000
Number of env steps total    1600958
Number of rollouts total     0
Train Time (s)               190.451931911055
(Previous) Eval Time (s)     13.921316797845066
Sample Time (s)              7.388729095924646
Epoch Time (s)               211.7619778048247
Total Train Time (s)         64309.90827253135
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:03:31.899532 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #289 | Epoch Duration: 211.85163164138794
2020-01-12 10:03:31.899674 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2024195
Z variance train             0.6434886
KL Divergence                18.674042
KL Loss                      1.8674042
QF Loss                      2870.3013
VF Loss                      1395.1162
Policy Loss                  -1211.3666
Q Predictions Mean           1205.3011
Q Predictions Std            432.85953
Q Predictions Max            1792.0051
Q Predictions Min            319.677
V Predictions Mean           1217.1697
V Predictions Std            430.0971
V Predictions Max            1780.3446
V Predictions Min            330.70743
Log Pis Mean                 0.82082057
Log Pis Std                  3.5948017
Log Pis Max                  13.920698
Log Pis Min                  -8.0323715
Policy mu Mean               0.08490494
Policy mu Std                0.68996215
Policy mu Max                3.7607992
Policy mu Min                -3.093246
Policy log std Mean          -1.0071784
Policy log std Std           0.33141795
Policy log std Max           -0.11483902
Policy log std Min           -2.937593
Z mean eval                  1.0764503
Z variance eval              0.016941171
total_rewards                [1943.03682569 2159.86388846 4996.01187601 5324.48191998 4614.75506978
  344.57396554  393.38220662 2233.39013572 2691.95512281 1049.76650669]
total_rewards_mean           2575.1217517303803
total_rewards_std            1741.9596687120797
total_rewards_max            5324.481919982056
total_rewards_min            344.5739655355617
Number of train steps total  1164000
Number of env steps total    1610845
Number of rollouts total     0
Train Time (s)               192.44011347182095
(Previous) Eval Time (s)     17.38133616093546
Sample Time (s)              7.498815116006881
Epoch Time (s)               217.3202647487633
Total Train Time (s)         64527.33740208112
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:07:09.336522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #290 | Epoch Duration: 217.4367311000824
2020-01-12 10:07:09.336715 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0766848
Z variance train             0.016956612
KL Divergence                22.105293
KL Loss                      2.2105293
QF Loss                      633.0935
VF Loss                      143.97398
Policy Loss                  -1337.7017
Q Predictions Mean           1328.802
Q Predictions Std            489.29602
Q Predictions Max            1979.3611
Q Predictions Min            365.43054
V Predictions Mean           1339.8538
V Predictions Std            488.15958
V Predictions Max            1979.4902
V Predictions Min            375.44757
Log Pis Mean                 0.536698
Log Pis Std                  3.4089367
Log Pis Max                  12.328581
Log Pis Min                  -7.5076838
Policy mu Mean               0.064792074
Policy mu Std                0.64873934
Policy mu Max                2.9442081
Policy mu Min                -2.2021592
Policy log std Mean          -1.0211561
Policy log std Std           0.32645354
Policy log std Max           -0.24553907
Policy log std Min           -2.737811
Z mean eval                  1.1315618
Z variance eval              0.010274047
total_rewards                [4728.15346339 4496.72918197 4666.1913926  4788.81959475 2423.03609378
 3778.96344858 3031.17221429 4815.03811499 4757.02576098 1982.40744233]
total_rewards_mean           3946.7536707644954
total_rewards_std            1029.4171852408226
total_rewards_max            4815.038114986792
total_rewards_min            1982.4074423284426
Number of train steps total  1168000
Number of env steps total    1620408
Number of rollouts total     0
Train Time (s)               191.71392926806584
(Previous) Eval Time (s)     29.82192956795916
Sample Time (s)              6.899513215292245
Epoch Time (s)               228.43537205131724
Total Train Time (s)         64755.863440814894
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:10:57.863467 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #291 | Epoch Duration: 228.526620388031
2020-01-12 10:10:57.863612 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1402254
Z variance train             0.010265726
KL Divergence                23.270576
KL Loss                      2.3270576
QF Loss                      2438.6948
VF Loss                      600.05444
Policy Loss                  -1276.3295
Q Predictions Mean           1270.8782
Q Predictions Std            520.4776
Q Predictions Max            1955.2882
Q Predictions Min            -114.61478
V Predictions Mean           1283.1304
V Predictions Std            520.27435
V Predictions Max            1963.9872
V Predictions Min            19.66459
Log Pis Mean                 0.5536518
Log Pis Std                  3.9239078
Log Pis Max                  20.140182
Log Pis Min                  -8.337959
Policy mu Mean               0.114431605
Policy mu Std                0.7113262
Policy mu Max                3.572859
Policy mu Min                -4.1783247
Policy log std Mean          -0.96318734
Policy log std Std           0.34301883
Policy log std Max           0.049200654
Policy log std Min           -2.6175544
Z mean eval                  1.1344389
Z variance eval              0.06662611
total_rewards                [ 274.46917584 1511.59880186 4664.96346592 3195.3891752  3180.40243618
  741.05188811 4941.89848699 1647.30889335 4808.79020218 1379.46782784]
total_rewards_mean           2634.5340353472707
total_rewards_std            1665.9070817719328
total_rewards_max            4941.898486992458
total_rewards_min            274.4691758420917
Number of train steps total  1172000
Number of env steps total    1630116
Number of rollouts total     0
Train Time (s)               191.14637397695333
(Previous) Eval Time (s)     18.841148443054408
Sample Time (s)              6.9174345512874424
Epoch Time (s)               216.90495697129518
Total Train Time (s)         64972.85757028684
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:14:34.859506 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #292 | Epoch Duration: 216.9957628250122
2020-01-12 10:14:34.859654 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1306212
Z variance train             0.06676569
KL Divergence                20.138824
KL Loss                      2.0138824
QF Loss                      1232.3567
VF Loss                      148.49872
Policy Loss                  -1336.6365
Q Predictions Mean           1331.6967
Q Predictions Std            473.0444
Q Predictions Max            1957.2584
Q Predictions Min            241.86082
V Predictions Mean           1342.2937
V Predictions Std            472.3615
V Predictions Max            1958.8253
V Predictions Min            323.40793
Log Pis Mean                 0.44514406
Log Pis Std                  3.6957893
Log Pis Max                  17.505222
Log Pis Min                  -9.272253
Policy mu Mean               0.064803556
Policy mu Std                0.67618144
Policy mu Max                2.9850132
Policy mu Min                -4.3343225
Policy log std Mean          -0.9732647
Policy log std Std           0.31763032
Policy log std Max           -0.25834465
Policy log std Min           -2.798047
Z mean eval                  1.1412545
Z variance eval              0.0102274
total_rewards                [ 630.77083912 4771.65259373 1904.88244342 3536.66857807 4575.96325644
 4935.6174188  4639.38201354 1735.55371543  699.65716874 4662.56257733]
total_rewards_mean           3209.2710604622002
total_rewards_std            1684.449934635425
total_rewards_max            4935.617418796308
total_rewards_min            630.7708391170022
Number of train steps total  1176000
Number of env steps total    1639517
Number of rollouts total     0
Train Time (s)               190.51100747706369
(Previous) Eval Time (s)     22.01758149592206
Sample Time (s)              7.202946074306965
Epoch Time (s)               219.7315350472927
Total Train Time (s)         65192.681671833154
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:18:14.689284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #293 | Epoch Duration: 219.82950472831726
2020-01-12 10:18:14.689478 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1453044
Z variance train             0.010280785
KL Divergence                23.39128
KL Loss                      2.339128
QF Loss                      838.8353
VF Loss                      180.60449
Policy Loss                  -1323.2709
Q Predictions Mean           1312.3389
Q Predictions Std            472.8642
Q Predictions Max            1904.3348
Q Predictions Min            407.71545
V Predictions Mean           1328.9475
V Predictions Std            470.52945
V Predictions Max            1913.5573
V Predictions Min            415.58957
Log Pis Mean                 0.26796454
Log Pis Std                  3.435877
Log Pis Max                  10.739
Log Pis Min                  -8.655983
Policy mu Mean               0.0974772
Policy mu Std                0.67893624
Policy mu Max                2.5038736
Policy mu Min                -2.3400211
Policy log std Mean          -0.97966236
Policy log std Std           0.3467771
Policy log std Max           -0.12726462
Policy log std Min           -2.3949652
Z mean eval                  1.0391428
Z variance eval              0.026855772
total_rewards                [4844.5715827  3848.02995589 5049.59110519 4731.65173814 4743.20802172
 4658.88952432 4867.04939234 4809.14673188 4690.19000373 4860.93022565]
total_rewards_mean           4710.325828156058
total_rewards_std            306.31254155546316
total_rewards_max            5049.591105193522
total_rewards_min            3848.02995588804
Number of train steps total  1180000
Number of env steps total    1650050
Number of rollouts total     0
Train Time (s)               190.8031149143353
(Previous) Eval Time (s)     32.789211203344166
Sample Time (s)              7.772037720773369
Epoch Time (s)               231.36436383845285
Total Train Time (s)         65424.138962173834
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:22:06.148195 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #294 | Epoch Duration: 231.4585840702057
2020-01-12 10:22:06.148337 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.038317
Z variance train             0.0268695
KL Divergence                19.557354
KL Loss                      1.9557354
QF Loss                      3371.223
VF Loss                      608.39246
Policy Loss                  -1275.3445
Q Predictions Mean           1269.1311
Q Predictions Std            473.91058
Q Predictions Max            1908.2025
Q Predictions Min            415.1993
V Predictions Mean           1274.1635
V Predictions Std            475.3127
V Predictions Max            1897.5298
V Predictions Min            404.85324
Log Pis Mean                 0.5361991
Log Pis Std                  3.3000233
Log Pis Max                  11.09534
Log Pis Min                  -7.4984097
Policy mu Mean               0.054052815
Policy mu Std                0.6583102
Policy mu Max                2.4569728
Policy mu Min                -2.7352123
Policy log std Mean          -1.001493
Policy log std Std           0.33707157
Policy log std Max           -0.20648289
Policy log std Min           -2.6659775
Z mean eval                  1.0496769
Z variance eval              0.03390851
total_rewards                [4881.56381171 5279.52228078 5032.58350219    9.57999927 4299.11569981
  181.72287892 4723.49193859 1519.71285197 1008.81203548  668.9494508 ]
total_rewards_mean           2760.5054449518766
total_rewards_std            2131.3756935361803
total_rewards_max            5279.522280776492
total_rewards_min            9.579999268308578
Number of train steps total  1184000
Number of env steps total    1659546
Number of rollouts total     0
Train Time (s)               192.79912632424384
(Previous) Eval Time (s)     18.671239385847002
Sample Time (s)              6.841168630402535
Epoch Time (s)               218.31153434049338
Total Train Time (s)         65642.56112885475
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:25:44.572305 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #295 | Epoch Duration: 218.42385816574097
2020-01-12 10:25:44.572452 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0522746
Z variance train             0.032975025
KL Divergence                20.140688
KL Loss                      2.0140688
QF Loss                      655.0858
VF Loss                      162.05531
Policy Loss                  -1269.2067
Q Predictions Mean           1262.0647
Q Predictions Std            477.54938
Q Predictions Max            1898.6398
Q Predictions Min            247.36221
V Predictions Mean           1269.5977
V Predictions Std            478.3604
V Predictions Max            1899.8154
V Predictions Min            315.11304
Log Pis Mean                 0.6065827
Log Pis Std                  3.3774261
Log Pis Max                  17.924446
Log Pis Min                  -6.50965
Policy mu Mean               0.086026
Policy mu Std                0.6615868
Policy mu Max                2.794984
Policy mu Min                -3.4094584
Policy log std Mean          -0.9811569
Policy log std Std           0.3491687
Policy log std Max           0.42067593
Policy log std Min           -2.6868992
Z mean eval                  1.0844359
Z variance eval              0.017955853
total_rewards                [4821.42912285 5054.16818522 4673.74488886 5169.2181864  4888.33472592
 4994.38266897 4882.23140018 5093.69146598 2985.820998   4952.19332895]
total_rewards_mean           4751.521497132204
total_rewards_std            603.8902243270471
total_rewards_max            5169.218186404392
total_rewards_min            2985.820997999561
Number of train steps total  1188000
Number of env steps total    1668291
Number of rollouts total     0
Train Time (s)               191.93280081823468
(Previous) Eval Time (s)     32.14501179382205
Sample Time (s)              7.556684435810894
Epoch Time (s)               231.63449704786763
Total Train Time (s)         65874.2966014063
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:29:36.309886 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #296 | Epoch Duration: 231.73730993270874
2020-01-12 10:29:36.310037 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.100955
Z variance train             0.018065717
KL Divergence                19.546104
KL Loss                      1.9546105
QF Loss                      2716.1313
VF Loss                      423.80347
Policy Loss                  -1321.3193
Q Predictions Mean           1306.6418
Q Predictions Std            455.58176
Q Predictions Max            1909.5577
Q Predictions Min            248.55852
V Predictions Mean           1308.4458
V Predictions Std            452.45004
V Predictions Max            1878.7457
V Predictions Min            390.74152
Log Pis Mean                 0.9955171
Log Pis Std                  4.0585337
Log Pis Max                  25.930706
Log Pis Min                  -7.3994775
Policy mu Mean               0.014146293
Policy mu Std                0.69661
Policy mu Max                2.3856509
Policy mu Min                -5.241709
Policy log std Mean          -1.0334463
Policy log std Std           0.35269868
Policy log std Max           -0.1972512
Policy log std Min           -3.198367
Z mean eval                  1.199918
Z variance eval              0.012950768
total_rewards                [4972.85439    4804.95467601 1682.54101498 4697.07003364 4953.04675072
 4902.27685731 5037.539966   4416.83966559 4979.4084067  4984.20343564]
total_rewards_mean           4543.073519659421
total_rewards_std            969.6481501079176
total_rewards_max            5037.5399660014
total_rewards_min            1682.5410149784614
Number of train steps total  1192000
Number of env steps total    1677773
Number of rollouts total     0
Train Time (s)               188.04696495691314
(Previous) Eval Time (s)     31.217847123742104
Sample Time (s)              6.932096158154309
Epoch Time (s)               226.19690823880956
Total Train Time (s)         66100.58432938298
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:22.599504 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #297 | Epoch Duration: 226.2893590927124
2020-01-12 10:33:22.599648 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2005022
Z variance train             0.012916761
KL Divergence                20.805828
KL Loss                      2.0805829
QF Loss                      593.2583
VF Loss                      110.90248
Policy Loss                  -1351.006
Q Predictions Mean           1341.8557
Q Predictions Std            496.20074
Q Predictions Max            1969.5662
Q Predictions Min            0.56563973
V Predictions Mean           1354.9026
V Predictions Std            494.2598
V Predictions Max            1980.5485
V Predictions Min            256.30536
Log Pis Mean                 0.57076776
Log Pis Std                  3.6416008
Log Pis Max                  15.143188
Log Pis Min                  -8.151436
Policy mu Mean               0.07724313
Policy mu Std                0.71312475
Policy mu Max                2.5315819
Policy mu Min                -3.5086956
Policy log std Mean          -0.9872297
Policy log std Std           0.3386604
Policy log std Max           -0.28351414
Policy log std Min           -2.7253823
Z mean eval                  1.2282832
Z variance eval              0.04621465
total_rewards                [1929.70247054 3928.80156117 4907.35576648 4825.92669438 5055.61132158
 4822.59004196 1863.07678512 4715.84048555 4664.86225229 3901.86699115]
total_rewards_mean           4061.5634370216926
total_rewards_std            1143.6896375429262
total_rewards_max            5055.611321577637
total_rewards_min            1863.0767851196222
Number of train steps total  1196000
Number of env steps total    1686123
Number of rollouts total     0
Train Time (s)               189.58754708059132
(Previous) Eval Time (s)     28.081211179029197
Sample Time (s)              7.47515186900273
Epoch Time (s)               225.14391012862325
Total Train Time (s)         66325.81723500509
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:37:07.835278 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #298 | Epoch Duration: 225.2355146408081
2020-01-12 10:37:07.835435 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #298 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2261169
Z variance train             0.045710176
KL Divergence                20.384174
KL Loss                      2.0384176
QF Loss                      839.3977
VF Loss                      104.80663
Policy Loss                  -1326.7599
Q Predictions Mean           1317.0669
Q Predictions Std            483.9216
Q Predictions Max            1942.0352
Q Predictions Min            411.76285
V Predictions Mean           1329.6165
V Predictions Std            483.21674
V Predictions Max            1939.9158
V Predictions Min            429.1737
Log Pis Mean                 0.71384346
Log Pis Std                  3.9559388
Log Pis Max                  22.501534
Log Pis Min                  -9.866856
Policy mu Mean               0.04956641
Policy mu Std                0.69559836
Policy mu Max                2.4786441
Policy mu Min                -2.8377583
Policy log std Mean          -0.9729783
Policy log std Std           0.35238266
Policy log std Max           0.14634562
Policy log std Min           -2.665291
Z mean eval                  1.1256673
Z variance eval              0.03235783
total_rewards                [ 2.87195929e+03  4.51431624e+03  1.31512354e+03  4.43296197e+03
  4.55068320e+03  1.32161011e+03  2.09663605e+03  4.91886358e+03
 -2.00360494e+00  2.69940738e+03]
total_rewards_mean           2871.9557746909263
total_rewards_std            1608.100742873171
total_rewards_max            4918.863581259527
total_rewards_min            -2.0036049398860163
Number of train steps total  1200000
Number of env steps total    1696148
Number of rollouts total     0
Train Time (s)               190.58420722698793
(Previous) Eval Time (s)     21.357324603945017
Sample Time (s)              7.2368821003474295
Epoch Time (s)               219.17841393128037
Total Train Time (s)         66545.08646945516
Epoch                        299
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:40:47.106460 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #299 | Epoch Duration: 219.27091479301453
2020-01-12 10:40:47.106627 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1309102
Z variance train             0.032465395
KL Divergence                19.609512
KL Loss                      1.9609512
QF Loss                      794.1915
VF Loss                      826.5895
Policy Loss                  -1279.0988
Q Predictions Mean           1266.2642
Q Predictions Std            493.23602
Q Predictions Max            1892.8433
Q Predictions Min            -5.8129253
V Predictions Mean           1280.0596
V Predictions Std            486.4891
V Predictions Max            1912.2152
V Predictions Min            394.98715
Log Pis Mean                 0.6655306
Log Pis Std                  4.2311835
Log Pis Max                  25.982626
Log Pis Min                  -7.886673
Policy mu Mean               0.074723266
Policy mu Std                0.71123177
Policy mu Max                2.6821644
Policy mu Min                -3.6011055
Policy log std Mean          -0.9779991
Policy log std Std           0.34815228
Policy log std Max           0.115327
Policy log std Min           -2.3094306
Z mean eval                  1.1030753
Z variance eval              0.007754533
total_rewards                [5.04297123e+03 4.95040352e+03 2.20742708e+01 4.80699219e+03
 4.53765033e+03 4.57603534e+03 4.99714703e+03 4.88440711e+03
 4.35277853e+00 4.74007832e+03]
total_rewards_mean           3856.211211797523
total_rewards_std            1927.944722927147
total_rewards_max            5042.9712288969085
total_rewards_min            4.352778531104479
Number of train steps total  1204000
Number of env steps total    1707133
Number of rollouts total     0
Train Time (s)               191.1105435229838
(Previous) Eval Time (s)     26.76240045996383
Sample Time (s)              16.989281716756523
Epoch Time (s)               234.86222569970414
Total Train Time (s)         66780.0402795882
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:44:42.068481 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #300 | Epoch Duration: 234.96168732643127
2020-01-12 10:44:42.068821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1012018
Z variance train             0.007746283
KL Divergence                22.815048
KL Loss                      2.2815049
QF Loss                      801.5073
VF Loss                      114.63406
Policy Loss                  -1312.3351
Q Predictions Mean           1304.7415
Q Predictions Std            483.9363
Q Predictions Max            1966.261
Q Predictions Min            418.54507
V Predictions Mean           1316.3489
V Predictions Std            480.1965
V Predictions Max            1974.4607
V Predictions Min            431.4566
Log Pis Mean                 0.61696994
Log Pis Std                  3.6791933
Log Pis Max                  13.193848
Log Pis Min                  -7.7797127
Policy mu Mean               0.07148162
Policy mu Std                0.67421305
Policy mu Max                2.69357
Policy mu Min                -2.81997
Policy log std Mean          -0.98681027
Policy log std Std           0.3712748
Policy log std Max           -0.16938758
Policy log std Min           -2.7038784
Z mean eval                  1.0389919
Z variance eval              0.008097177
total_rewards                [4998.04766456 4886.02651278 4866.96453599 4872.80346436  564.9174455
 5058.37688496 4773.09893102 4911.51470465 4982.27722407 4627.57510183]
total_rewards_mean           4454.160246971257
total_rewards_std            1301.5050545793288
total_rewards_max            5058.3768849574735
total_rewards_min            564.9174455043518
Number of train steps total  1208000
Number of env steps total    1716103
Number of rollouts total     0
Train Time (s)               192.21296765096486
(Previous) Eval Time (s)     26.173668759875
Sample Time (s)              7.411375977098942
Epoch Time (s)               225.7980123879388
Total Train Time (s)         67005.92709585885
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:48:27.957503 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #301 | Epoch Duration: 225.8884425163269
2020-01-12 10:48:27.957697 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0359585
Z variance train             0.008301057
KL Divergence                21.893974
KL Loss                      2.1893976
QF Loss                      9320.027
VF Loss                      2970.9778
Policy Loss                  -1388.056
Q Predictions Mean           1379.7634
Q Predictions Std            500.53168
Q Predictions Max            1959.3861
Q Predictions Min            99.67456
V Predictions Mean           1388.834
V Predictions Std            491.3679
V Predictions Max            1955.2981
V Predictions Min            386.2972
Log Pis Mean                 0.33139205
Log Pis Std                  3.3315935
Log Pis Max                  12.6528225
Log Pis Min                  -8.281412
Policy mu Mean               0.0260939
Policy mu Std                0.6444896
Policy mu Max                2.4354002
Policy mu Min                -2.9142296
Policy log std Mean          -0.9988534
Policy log std Std           0.36037913
Policy log std Max           -0.23550212
Policy log std Min           -2.8296409
Z mean eval                  1.1467607
Z variance eval              0.00781815
total_rewards                [1046.06142406 4026.94295812 3951.39415273 1673.16218196 4027.03511392
 3963.26471857  517.69821576 4420.86371229 4864.12468553 4580.21327523]
total_rewards_mean           3307.0760438155316
total_rewards_std            1507.6661095478864
total_rewards_max            4864.124685525627
total_rewards_min            517.6982157566504
Number of train steps total  1212000
Number of env steps total    1725746
Number of rollouts total     0
Train Time (s)               190.6827044119127
(Previous) Eval Time (s)     30.891864746809006
Sample Time (s)              6.946590991690755
Epoch Time (s)               228.52116015041247
Total Train Time (s)         67234.54398560245
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:16.577243 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #302 | Epoch Duration: 228.61940479278564
2020-01-12 10:52:16.577431 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.147198
Z variance train             0.007844808
KL Divergence                23.86359
KL Loss                      2.386359
QF Loss                      535.11475
VF Loss                      110.26188
Policy Loss                  -1375.8959
Q Predictions Mean           1370.2788
Q Predictions Std            461.86255
Q Predictions Max            1980.634
Q Predictions Min            416.71307
V Predictions Mean           1375.0532
V Predictions Std            462.0876
V Predictions Max            1979.7361
V Predictions Min            415.60205
Log Pis Mean                 0.37832612
Log Pis Std                  3.197591
Log Pis Max                  9.782644
Log Pis Min                  -8.012703
Policy mu Mean               0.09321412
Policy mu Std                0.6685149
Policy mu Max                2.2907178
Policy mu Min                -3.0758448
Policy log std Mean          -0.96059483
Policy log std Std           0.32580814
Policy log std Max           -0.08951962
Policy log std Min           -2.493794
Z mean eval                  1.123303
Z variance eval              0.022281628
total_rewards                [5013.356293   5144.20578702 5061.82321938 4939.73810824 4980.74495169
 4869.29048258 5151.00888706 5008.40096617 1744.57804439 4940.42358668]
total_rewards_mean           4685.3570326209065
total_rewards_std            983.8738125166864
total_rewards_max            5151.008887064724
total_rewards_min            1744.578044386753
Number of train steps total  1216000
Number of env steps total    1735642
Number of rollouts total     0
Train Time (s)               191.5224334266968
(Previous) Eval Time (s)     31.191385879181325
Sample Time (s)              6.105509530287236
Epoch Time (s)               228.81932883616537
Total Train Time (s)         67463.45784584107
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:56:05.495604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #303 | Epoch Duration: 228.91803765296936
2020-01-12 10:56:05.495754 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1189816
Z variance train             0.021982381
KL Divergence                23.276758
KL Loss                      2.3276758
QF Loss                      2287.5557
VF Loss                      352.49588
Policy Loss                  -1313.7422
Q Predictions Mean           1308.0293
Q Predictions Std            486.35263
Q Predictions Max            1949.2095
Q Predictions Min            106.6847
V Predictions Mean           1328.8245
V Predictions Std            491.8355
V Predictions Max            1968.6205
V Predictions Min            -48.1232
Log Pis Mean                 0.51799953
Log Pis Std                  3.4919748
Log Pis Max                  15.130505
Log Pis Min                  -7.8065815
Policy mu Mean               0.07631102
Policy mu Std                0.67371726
Policy mu Max                2.5824924
Policy mu Min                -2.645354
Policy log std Mean          -0.9648564
Policy log std Std           0.3497392
Policy log std Max           -0.073780775
Policy log std Min           -2.9007075
Z mean eval                  0.97742283
Z variance eval              0.06329489
total_rewards                [4885.29865578 2093.85203068 1396.0955445  4794.7581102  4907.69809804
 2548.24179347 4729.90216885 4961.37106969 5078.52913376 5130.80403438]
total_rewards_mean           4052.655063936115
total_rewards_std            1364.984952080751
total_rewards_max            5130.804034382696
total_rewards_min            1396.0955445011732
Number of train steps total  1220000
Number of env steps total    1745194
Number of rollouts total     0
Train Time (s)               191.39638466807082
(Previous) Eval Time (s)     27.870831322390586
Sample Time (s)              6.941988582722843
Epoch Time (s)               226.20920457318425
Total Train Time (s)         67689.76968577364
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:59:51.809024 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #304 | Epoch Duration: 226.31316447257996
2020-01-12 10:59:51.809163 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.978659
Z variance train             0.06283864
KL Divergence                17.658718
KL Loss                      1.7658719
QF Loss                      725.9236
VF Loss                      74.47256
Policy Loss                  -1361.023
Q Predictions Mean           1353.4017
Q Predictions Std            458.6939
Q Predictions Max            1968.6957
Q Predictions Min            420.57892
V Predictions Mean           1361.8315
V Predictions Std            458.69104
V Predictions Max            1965.9451
V Predictions Min            429.66388
Log Pis Mean                 0.9442079
Log Pis Std                  3.3206244
Log Pis Max                  12.734713
Log Pis Min                  -6.9907446
Policy mu Mean               0.110846914
Policy mu Std                0.6998827
Policy mu Max                3.148875
Policy mu Min                -2.5087829
Policy log std Mean          -0.9944416
Policy log std Std           0.31683877
Policy log std Max           0.37391365
Policy log std Min           -2.3939142
Z mean eval                  1.0461996
Z variance eval              0.0268365
total_rewards                [3785.53594203 5218.83965921 4877.01828873 2445.89108324 5248.15187429
 1448.07707951 5200.8073217  3530.18898019 4987.39253691  201.96352574]
total_rewards_mean           3694.386629155108
total_rewards_std            1700.4371384995334
total_rewards_max            5248.151874294024
total_rewards_min            201.9635257395609
Number of train steps total  1224000
Number of env steps total    1754169
Number of rollouts total     0
Train Time (s)               192.29479590710253
(Previous) Eval Time (s)     23.672788565047085
Sample Time (s)              7.011250195093453
Epoch Time (s)               222.97883466724306
Total Train Time (s)         67912.83879979327
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:03:34.881608 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #305 | Epoch Duration: 223.07231974601746
2020-01-12 11:03:34.881798 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0452292
Z variance train             0.026718691
KL Divergence                21.157413
KL Loss                      2.1157415
QF Loss                      636.58813
VF Loss                      478.9215
Policy Loss                  -1349.4718
Q Predictions Mean           1342.8289
Q Predictions Std            490.16364
Q Predictions Max            1971.0858
Q Predictions Min            420.42444
V Predictions Mean           1365.0834
V Predictions Std            498.2546
V Predictions Max            1977.9454
V Predictions Min            426.69897
Log Pis Mean                 0.4695744
Log Pis Std                  3.4682255
Log Pis Max                  16.277895
Log Pis Min                  -7.3855586
Policy mu Mean               0.079227224
Policy mu Std                0.65890604
Policy mu Max                3.221675
Policy mu Min                -3.059952
Policy log std Mean          -1.0093589
Policy log std Std           0.32729098
Policy log std Max           -0.23693502
Policy log std Min           -2.6653912
Z mean eval                  1.0181453
Z variance eval              0.21610685
total_rewards                [5153.03432285 4315.22781393 5118.14393925 5017.10896616 5009.05327295
 5092.41103118 5063.04550892 2259.42156317 3080.96764022 5248.46679511]
total_rewards_mean           4535.688085375164
total_rewards_std            980.7402932728434
total_rewards_max            5248.466795113415
total_rewards_min            2259.421563167005
Number of train steps total  1228000
Number of env steps total    1762874
Number of rollouts total     0
Train Time (s)               188.77077213674784
(Previous) Eval Time (s)     29.83440081309527
Sample Time (s)              7.157683816272765
Epoch Time (s)               225.76285676611587
Total Train Time (s)         68138.69074599352
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:07:20.743917 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #306 | Epoch Duration: 225.86196613311768
2020-01-12 11:07:20.744142 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0094962
Z variance train             0.22024277
KL Divergence                15.386667
KL Loss                      1.5386667
QF Loss                      563.13654
VF Loss                      217.35117
Policy Loss                  -1431.4526
Q Predictions Mean           1422.7959
Q Predictions Std            486.48132
Q Predictions Max            2017.0078
Q Predictions Min            432.3172
V Predictions Mean           1439.9741
V Predictions Std            487.1452
V Predictions Max            2021.1609
V Predictions Min            451.76056
Log Pis Mean                 0.620608
Log Pis Std                  3.4658296
Log Pis Max                  10.740228
Log Pis Min                  -6.9924946
Policy mu Mean               0.014150666
Policy mu Std                0.65956414
Policy mu Max                2.9300888
Policy mu Min                -2.7009234
Policy log std Mean          -1.0347939
Policy log std Std           0.35075948
Policy log std Max           -0.25109935
Policy log std Min           -2.6643286
Z mean eval                  1.1468749
Z variance eval              0.09695911
total_rewards                [4777.0215134  2711.52104088 4816.78296207 4919.36070225 2026.77456082
 4972.63796981  643.43473645 4715.54900237 4787.54347811 4830.20702315]
total_rewards_mean           3920.083298931045
total_rewards_std            1471.0569195592905
total_rewards_max            4972.6379698104365
total_rewards_min            643.4347364534189
Number of train steps total  1232000
Number of env steps total    1773273
Number of rollouts total     0
Train Time (s)               191.17769672628492
(Previous) Eval Time (s)     29.54555449495092
Sample Time (s)              7.0199042479507625
Epoch Time (s)               227.7431554691866
Total Train Time (s)         68366.52261107927
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:11:08.580174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #307 | Epoch Duration: 227.8358714580536
2020-01-12 11:11:08.580391 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1631534
Z variance train             0.09717882
KL Divergence                17.96973
KL Loss                      1.7969731
QF Loss                      4866.508
VF Loss                      960.701
Policy Loss                  -1316.4182
Q Predictions Mean           1311.5839
Q Predictions Std            420.2831
Q Predictions Max            1865.5319
Q Predictions Min            233.16994
V Predictions Mean           1319.6382
V Predictions Std            417.56564
V Predictions Max            1875.8229
V Predictions Min            355.73373
Log Pis Mean                 1.36467
Log Pis Std                  4.206948
Log Pis Max                  38.41809
Log Pis Min                  -8.859957
Policy mu Mean               0.0287603
Policy mu Std                0.71761864
Policy mu Max                4.3443155
Policy mu Min                -5.3607574
Policy log std Mean          -1.0565735
Policy log std Std           0.39266163
Policy log std Max           0.62090373
Policy log std Min           -2.7391143
Z mean eval                  1.1223978
Z variance eval              0.02307853
total_rewards                [3018.06326389 4920.77782941  126.26446476 2052.46873965   82.23229343
 4771.42642282 -196.11188126 3723.87156063 4856.4765438  4879.92599035]
total_rewards_mean           2823.5395227475096
total_rewards_std            2047.085005773602
total_rewards_max            4920.777829405942
total_rewards_min            -196.1118812602502
Number of train steps total  1236000
Number of env steps total    1784038
Number of rollouts total     0
Train Time (s)               192.12836319487542
(Previous) Eval Time (s)     23.092169316019863
Sample Time (s)              7.158243005629629
Epoch Time (s)               222.3787755165249
Total Train Time (s)         68588.99278190127
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:14:51.051501 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #308 | Epoch Duration: 222.47097444534302
2020-01-12 11:14:51.051643 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.124142
Z variance train             0.023060242
KL Divergence                19.556812
KL Loss                      1.9556812
QF Loss                      588.0257
VF Loss                      96.69861
Policy Loss                  -1420.34
Q Predictions Mean           1410.4014
Q Predictions Std            463.6574
Q Predictions Max            1992.671
Q Predictions Min            101.969894
V Predictions Mean           1420.7183
V Predictions Std            455.61642
V Predictions Max            1963.7272
V Predictions Min            442.153
Log Pis Mean                 0.82614946
Log Pis Std                  3.530412
Log Pis Max                  16.843918
Log Pis Min                  -11.201131
Policy mu Mean               0.077495314
Policy mu Std                0.67796546
Policy mu Max                2.7144415
Policy mu Min                -2.7392395
Policy log std Mean          -1.0177512
Policy log std Std           0.3435513
Policy log std Max           -0.17744958
Policy log std Min           -2.5862577
Z mean eval                  1.0804622
Z variance eval              0.014965884
total_rewards                [4844.60378787 3481.73460706 4875.55756807 4587.75848892 1454.48922384
 4172.99626789 1128.17411035  655.37217184  240.07783594  606.71863819]
total_rewards_mean           2604.7482699971556
total_rewards_std            1849.9077523301332
total_rewards_max            4875.557568069811
total_rewards_min            240.07783594107667
Number of train steps total  1240000
Number of env steps total    1794072
Number of rollouts total     0
Train Time (s)               192.0737627381459
(Previous) Eval Time (s)     21.638274157885462
Sample Time (s)              7.054861848708242
Epoch Time (s)               220.7668987447396
Total Train Time (s)         68809.85035356507
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:18:31.911632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #309 | Epoch Duration: 220.8598816394806
2020-01-12 11:18:31.911772 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0775468
Z variance train             0.014963165
KL Divergence                19.554321
KL Loss                      1.9554322
QF Loss                      869.1603
VF Loss                      180.84636
Policy Loss                  -1393.2698
Q Predictions Mean           1388.571
Q Predictions Std            465.62375
Q Predictions Max            1960.9215
Q Predictions Min            426.78488
V Predictions Mean           1400.0471
V Predictions Std            467.80875
V Predictions Max            1975.5607
V Predictions Min            429.93127
Log Pis Mean                 0.6645622
Log Pis Std                  3.2210352
Log Pis Max                  11.480232
Log Pis Min                  -7.0448728
Policy mu Mean               0.12083921
Policy mu Std                0.67614424
Policy mu Max                2.8898535
Policy mu Min                -2.3044088
Policy log std Mean          -0.99282193
Policy log std Std           0.3365678
Policy log std Max           -0.17803228
Policy log std Min           -2.4854188
Z mean eval                  1.0980334
Z variance eval              0.020317364
total_rewards                [4139.03024836 3547.34739902 4053.18588679 4885.43823955 4857.79757997
 5026.96297338   47.72721973 2363.99064652 1648.9895272  4894.39802612]
total_rewards_mean           3546.4867746650402
total_rewards_std            1592.7638051443357
total_rewards_max            5026.962973381203
total_rewards_min            47.72721972976994
Number of train steps total  1244000
Number of env steps total    1804622
Number of rollouts total     0
Train Time (s)               191.56814275868237
(Previous) Eval Time (s)     24.791530093178153
Sample Time (s)              7.738412632606924
Epoch Time (s)               224.09808548446745
Total Train Time (s)         69034.03932244191
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:22:16.102501 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #310 | Epoch Duration: 224.19059586524963
2020-01-12 11:22:16.102653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0996687
Z variance train             0.020508993
KL Divergence                20.55671
KL Loss                      2.055671
QF Loss                      805.59607
VF Loss                      2254.697
Policy Loss                  -1396.7372
Q Predictions Mean           1387.1704
Q Predictions Std            497.00815
Q Predictions Max            2045.1996
Q Predictions Min            -100.16322
V Predictions Mean           1405.6663
V Predictions Std            487.53354
V Predictions Max            2060.1428
V Predictions Min            354.59058
Log Pis Mean                 0.74347526
Log Pis Std                  3.8825665
Log Pis Max                  17.912674
Log Pis Min                  -8.2988615
Policy mu Mean               0.108763665
Policy mu Std                0.7166674
Policy mu Max                3.2017024
Policy mu Min                -3.991491
Policy log std Mean          -0.99846077
Policy log std Std           0.35444802
Policy log std Max           -0.039634466
Policy log std Min           -2.6574407
Z mean eval                  1.1089966
Z variance eval              0.021346295
total_rewards                [4751.11898432 1300.75655473  227.41040566 1454.83330489 3915.3742784
 5296.93581944 5183.5646713  2195.88327529 5071.86564472 5210.10746354]
total_rewards_mean           3460.785040230119
total_rewards_std            1860.4030607360357
total_rewards_max            5296.93581944416
total_rewards_min            227.4104056590639
Number of train steps total  1248000
Number of env steps total    1815892
Number of rollouts total     0
Train Time (s)               191.55636645201594
(Previous) Eval Time (s)     22.76523822871968
Sample Time (s)              7.249096584971994
Epoch Time (s)               221.5707012657076
Total Train Time (s)         69255.70012672199
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:25:57.765462 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #311 | Epoch Duration: 221.66269969940186
2020-01-12 11:25:57.765610 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1082661
Z variance train             0.021386618
KL Divergence                19.190674
KL Loss                      1.9190674
QF Loss                      1803.6238
VF Loss                      142.53888
Policy Loss                  -1436.4536
Q Predictions Mean           1427.4155
Q Predictions Std            470.15988
Q Predictions Max            1999.5481
Q Predictions Min            427.9171
V Predictions Mean           1433.6995
V Predictions Std            469.25815
V Predictions Max            1992.4424
V Predictions Min            422.72043
Log Pis Mean                 1.3683858
Log Pis Std                  3.7820477
Log Pis Max                  18.05394
Log Pis Min                  -8.741494
Policy mu Mean               0.1372113
Policy mu Std                0.71432227
Policy mu Max                3.6399603
Policy mu Min                -2.6993098
Policy log std Mean          -1.0177716
Policy log std Std           0.36320397
Policy log std Max           -0.085585475
Policy log std Min           -2.7946897
Z mean eval                  1.0157577
Z variance eval              0.03448596
total_rewards                [2036.64172443 5025.30375804 5034.80565068 4781.72594579 4996.74272756
 5194.20445004 4894.25770981   68.9538803  5030.25092826  655.72897205]
total_rewards_mean           3771.8615746951737
total_rewards_std            1923.1608553703106
total_rewards_max            5194.2044500422
total_rewards_min            68.95388029903856
Number of train steps total  1252000
Number of env steps total    1825318
Number of rollouts total     0
Train Time (s)               192.30473832413554
(Previous) Eval Time (s)     23.46927329013124
Sample Time (s)              6.767865506000817
Epoch Time (s)               222.5418771202676
Total Train Time (s)         69478.3399969032
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:29:40.410723 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #312 | Epoch Duration: 222.64497661590576
2020-01-12 11:29:40.410914 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0128105
Z variance train             0.03408893
KL Divergence                17.949364
KL Loss                      1.7949364
QF Loss                      678.90076
VF Loss                      105.92413
Policy Loss                  -1415.2406
Q Predictions Mean           1406.593
Q Predictions Std            484.37454
Q Predictions Max            2020.8787
Q Predictions Min            433.63834
V Predictions Mean           1419.4982
V Predictions Std            486.9583
V Predictions Max            2016.3275
V Predictions Min            435.69797
Log Pis Mean                 0.9077535
Log Pis Std                  3.8581917
Log Pis Max                  13.51096
Log Pis Min                  -9.136816
Policy mu Mean               0.06363836
Policy mu Std                0.71825296
Policy mu Max                2.935342
Policy mu Min                -2.473804
Policy log std Mean          -0.9966428
Policy log std Std           0.34602487
Policy log std Max           -0.16459858
Policy log std Min           -2.5853324
Z mean eval                  1.085664
Z variance eval              0.06599905
total_rewards                [5037.63300916 3303.9938133  4807.36576758 1595.77191512  919.60182473
 4881.01544826 5152.09946831 4983.23118548 2116.05696759 5161.78543755]
total_rewards_mean           3795.8554837073934
total_rewards_std            1582.2330373445989
total_rewards_max            5161.785437550926
total_rewards_min            919.6018247253302
Number of train steps total  1256000
Number of env steps total    1834148
Number of rollouts total     0
Train Time (s)               190.9977387036197
(Previous) Eval Time (s)     30.566145255230367
Sample Time (s)              5.8579832231625915
Epoch Time (s)               227.42186718201265
Total Train Time (s)         69705.84951556288
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:33:27.923367 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #313 | Epoch Duration: 227.51232194900513
2020-01-12 11:33:27.923509 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0860734
Z variance train             0.06577482
KL Divergence                16.959778
KL Loss                      1.6959778
QF Loss                      773.4078
VF Loss                      174.38564
Policy Loss                  -1528.7358
Q Predictions Mean           1524.817
Q Predictions Std            480.69208
Q Predictions Max            2093.2996
Q Predictions Min            465.61884
V Predictions Mean           1519.7035
V Predictions Std            476.69128
V Predictions Max            2083.4175
V Predictions Min            460.68997
Log Pis Mean                 1.1755507
Log Pis Std                  3.6296306
Log Pis Max                  11.805493
Log Pis Min                  -6.5300684
Policy mu Mean               0.074785784
Policy mu Std                0.713276
Policy mu Max                2.8032093
Policy mu Min                -2.3621082
Policy log std Mean          -1.016893
Policy log std Std           0.33759516
Policy log std Max           -0.2103535
Policy log std Min           -2.5975535
Z mean eval                  0.9816934
Z variance eval              0.047569107
total_rewards                [ 756.35470648 4901.57102431 2598.14996403 4412.48513273 3028.11307737
 4947.87887176 4969.76674844 5084.40862923 2878.95055977 4882.13849206]
total_rewards_mean           3845.9817206197995
total_rewards_std            1386.5974412310125
total_rewards_max            5084.408629226502
total_rewards_min            756.3547064837667
Number of train steps total  1260000
Number of env steps total    1843306
Number of rollouts total     0
Train Time (s)               193.45946315396577
(Previous) Eval Time (s)     29.18557873694226
Sample Time (s)              6.774715943727642
Epoch Time (s)               229.41975783463567
Total Train Time (s)         69935.36540560378
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:17.441393 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #314 | Epoch Duration: 229.5177767276764
2020-01-12 11:37:17.441543 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9846732
Z variance train             0.047301352
KL Divergence                18.273584
KL Loss                      1.8273585
QF Loss                      858.73083
VF Loss                      121.21408
Policy Loss                  -1392.7333
Q Predictions Mean           1384.4193
Q Predictions Std            517.9042
Q Predictions Max            2059.364
Q Predictions Min            -8.639834
V Predictions Mean           1393.9502
V Predictions Std            517.2697
V Predictions Max            2059.0903
V Predictions Min            83.97858
Log Pis Mean                 0.621789
Log Pis Std                  3.452126
Log Pis Max                  14.803882
Log Pis Min                  -6.8586206
Policy mu Mean               0.08492567
Policy mu Std                0.6613642
Policy mu Max                2.9282753
Policy mu Min                -2.9089036
Policy log std Mean          -1.0060295
Policy log std Std           0.36431175
Policy log std Max           0.04747224
Policy log std Min           -2.8227324
Z mean eval                  1.083688
Z variance eval              0.10836079
total_rewards                [3694.51634923 1225.07531044 4973.2330229  3244.16660621 4736.37830988
  202.78860821 4963.9267419  4701.48492759 5072.26116114 1233.78684503]
total_rewards_mean           3404.7617882516583
total_rewards_std            1759.3433745409475
total_rewards_max            5072.261161144196
total_rewards_min            202.78860821402796
Number of train steps total  1264000
Number of env steps total    1854564
Number of rollouts total     0
Train Time (s)               190.80804336816072
(Previous) Eval Time (s)     19.669874605257064
Sample Time (s)              6.818141372408718
Epoch Time (s)               217.2960593458265
Total Train Time (s)         70152.78827360505
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:54.867683 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #315 | Epoch Duration: 217.42601943016052
2020-01-12 11:40:54.867875 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0772899
Z variance train             0.10629849
KL Divergence                16.051361
KL Loss                      1.6051362
QF Loss                      587.82056
VF Loss                      168.13292
Policy Loss                  -1390.502
Q Predictions Mean           1382.0532
Q Predictions Std            463.9462
Q Predictions Max            1975.6925
Q Predictions Min            385.64105
V Predictions Mean           1393.833
V Predictions Std            467.85715
V Predictions Max            1982.516
V Predictions Min            396.45975
Log Pis Mean                 1.3150004
Log Pis Std                  3.8359313
Log Pis Max                  13.131046
Log Pis Min                  -5.9192944
Policy mu Mean               0.118852876
Policy mu Std                0.745587
Policy mu Max                2.4828153
Policy mu Min                -3.052089
Policy log std Mean          -1.018316
Policy log std Std           0.36536655
Policy log std Max           -0.23252285
Policy log std Min           -2.6311002
Z mean eval                  1.1371214
Z variance eval              0.032698713
total_rewards                [5317.19073371  407.99597292 5216.90036693 4745.80203074 1915.41925361
  453.1286137  1824.20653112 1673.32298207  257.90051363  744.92862146]
total_rewards_mean           2255.6795619898417
total_rewards_std            1947.308104958748
total_rewards_max            5317.190733706391
total_rewards_min            257.9005136316234
Number of train steps total  1268000
Number of env steps total    1865100
Number of rollouts total     0
Train Time (s)               192.36150192422792
(Previous) Eval Time (s)     15.348153576254845
Sample Time (s)              7.114649870432913
Epoch Time (s)               214.82430537091568
Total Train Time (s)         70367.70265429327
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:44:29.787418 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #316 | Epoch Duration: 214.9193775653839
2020-01-12 11:44:29.787608 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1319808
Z variance train             0.032890595
KL Divergence                18.847088
KL Loss                      1.8847088
QF Loss                      1320.9524
VF Loss                      992.1325
Policy Loss                  -1416.4177
Q Predictions Mean           1406.3218
Q Predictions Std            455.81836
Q Predictions Max            1992.3257
Q Predictions Min            417.60083
V Predictions Mean           1410.8967
V Predictions Std            451.7424
V Predictions Max            1979.3618
V Predictions Min            419.6473
Log Pis Mean                 0.9953512
Log Pis Std                  3.637892
Log Pis Max                  20.556156
Log Pis Min                  -10.734171
Policy mu Mean               0.16375957
Policy mu Std                0.7126342
Policy mu Max                3.8942173
Policy mu Min                -3.4110768
Policy log std Mean          -1.0141473
Policy log std Std           0.33455598
Policy log std Max           -0.21583718
Policy log std Min           -3.345294
Z mean eval                  1.1466024
Z variance eval              0.08397541
total_rewards                [3061.50278802 4923.35784501 4255.47732428 4806.36789117 4916.52853386
 5353.79050358  -64.82572688 4554.69730818  930.13382522  535.20281562]
total_rewards_mean           3327.2233108064675
total_rewards_std            1971.1607815006532
total_rewards_max            5353.790503577193
total_rewards_min            -64.82572688409265
Number of train steps total  1272000
Number of env steps total    1875164
Number of rollouts total     0
Train Time (s)               191.05996515601873
(Previous) Eval Time (s)     26.570194536820054
Sample Time (s)              7.46673485962674
Epoch Time (s)               225.09689455246553
Total Train Time (s)         70592.96475613816
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:48:15.053924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #317 | Epoch Duration: 225.26616549491882
2020-01-12 11:48:15.054107 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1369555
Z variance train             0.08440204
KL Divergence                16.290312
KL Loss                      1.6290312
QF Loss                      1532.8602
VF Loss                      115.658806
Policy Loss                  -1495.9806
Q Predictions Mean           1486.6742
Q Predictions Std            475.47473
Q Predictions Max            2057.0728
Q Predictions Min            58.982746
V Predictions Mean           1494.2402
V Predictions Std            470.56412
V Predictions Max            2043.7368
V Predictions Min            230.91649
Log Pis Mean                 1.1712928
Log Pis Std                  3.721207
Log Pis Max                  14.392826
Log Pis Min                  -8.962714
Policy mu Mean               0.114587784
Policy mu Std                0.7147182
Policy mu Max                2.7246313
Policy mu Min                -2.9379811
Policy log std Mean          -1.0599272
Policy log std Std           0.36762685
Policy log std Max           -0.18675852
Policy log std Min           -2.8489926
Z mean eval                  1.0678198
Z variance eval              0.049189962
total_rewards                [5490.79058048 5173.54831861 5083.84085704  319.98756337 2657.12970623
 5049.78660237 3060.10301406  750.50621229 5294.98181654 3832.53134464]
total_rewards_mean           3671.3206015638216
total_rewards_std            1824.5428383907724
total_rewards_max            5490.79058048076
total_rewards_min            319.9875633665319
Number of train steps total  1276000
Number of env steps total    1885105
Number of rollouts total     0
Train Time (s)               190.6144059416838
(Previous) Eval Time (s)     25.69891839288175
Sample Time (s)              6.984469484072179
Epoch Time (s)               223.29779381863773
Total Train Time (s)         70816.35178664932
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:51:58.443910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #318 | Epoch Duration: 223.38965773582458
2020-01-12 11:51:58.444123 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637577
Z variance train             0.04907205
KL Divergence                19.732456
KL Loss                      1.9732456
QF Loss                      591.21106
VF Loss                      149.19366
Policy Loss                  -1461.0791
Q Predictions Mean           1450.5889
Q Predictions Std            454.29044
Q Predictions Max            2080.906
Q Predictions Min            416.79648
V Predictions Mean           1456.3414
V Predictions Std            453.86932
V Predictions Max            2066.5857
V Predictions Min            414.96262
Log Pis Mean                 1.2810596
Log Pis Std                  3.5922687
Log Pis Max                  19.550209
Log Pis Min                  -7.9835587
Policy mu Mean               0.0823168
Policy mu Std                0.7106173
Policy mu Max                3.3097217
Policy mu Min                -2.9726946
Policy log std Mean          -1.0535718
Policy log std Std           0.3307322
Policy log std Max           -0.3623448
Policy log std Min           -2.440626
Z mean eval                  1.192577
Z variance eval              0.03070654
total_rewards                [ 906.74345418  469.1798112  1101.12098318 2819.01015226 2684.59853618
  937.63871652 2451.96126359 1484.8560387  3277.40699516 1859.11690357]
total_rewards_mean           1799.1632854534867
total_rewards_std            912.8292938931644
total_rewards_max            3277.406995162277
total_rewards_min            469.17981119650995
Number of train steps total  1280000
Number of env steps total    1896364
Number of rollouts total     0
Train Time (s)               191.02349130576476
(Previous) Eval Time (s)     17.30528951389715
Sample Time (s)              7.53930219868198
Epoch Time (s)               215.8680830183439
Total Train Time (s)         71032.52440566244
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:55:34.621069 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #319 | Epoch Duration: 216.17681241035461
2020-01-12 11:55:34.621310 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1888146
Z variance train             0.03076747
KL Divergence                20.766716
KL Loss                      2.0766716
QF Loss                      3036.8674
VF Loss                      107.05387
Policy Loss                  -1422.629
Q Predictions Mean           1415.4727
Q Predictions Std            476.70685
Q Predictions Max            2042.772
Q Predictions Min            433.4027
V Predictions Mean           1421.3655
V Predictions Std            478.2444
V Predictions Max            2035.3136
V Predictions Min            432.42218
Log Pis Mean                 0.8647965
Log Pis Std                  3.6864257
Log Pis Max                  25.480715
Log Pis Min                  -8.465404
Policy mu Mean               0.054217905
Policy mu Std                0.6946128
Policy mu Max                2.9987204
Policy mu Min                -4.0659127
Policy log std Mean          -1.0182589
Policy log std Std           0.34473708
Policy log std Max           -0.23760688
Policy log std Min           -2.363181
Z mean eval                  1.1185998
Z variance eval              0.1336405
total_rewards                [1294.36873838 2396.40075619 5009.25218866 4857.03638381 -305.08411348
 1615.48543646 4999.03814531  275.57904496 4795.72899451  571.28385603]
total_rewards_mean           2550.908943082325
total_rewards_std            2052.4314875847754
total_rewards_max            5009.252188662219
total_rewards_min            -305.08411347757686
Number of train steps total  1284000
Number of env steps total    1906751
Number of rollouts total     0
Train Time (s)               193.88581786397845
(Previous) Eval Time (s)     21.06967557501048
Sample Time (s)              16.242449811194092
Epoch Time (s)               231.19794325018302
Total Train Time (s)         71263.8141742968
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:59:25.912353 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #320 | Epoch Duration: 231.29088926315308
2020-01-12 11:59:25.912501 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1131351
Z variance train             0.13492626
KL Divergence                17.414028
KL Loss                      1.7414029
QF Loss                      496.9603
VF Loss                      130.0424
Policy Loss                  -1476.0159
Q Predictions Mean           1471.2173
Q Predictions Std            461.07886
Q Predictions Max            2068.2515
Q Predictions Min            408.0693
V Predictions Mean           1482.3403
V Predictions Std            461.70764
V Predictions Max            2071.8582
V Predictions Min            412.92688
Log Pis Mean                 1.5361474
Log Pis Std                  3.6856363
Log Pis Max                  23.392765
Log Pis Min                  -7.1741323
Policy mu Mean               0.11101735
Policy mu Std                0.72047275
Policy mu Max                2.680003
Policy mu Min                -2.6479497
Policy log std Mean          -1.0460596
Policy log std Std           0.34795392
Policy log std Max           -0.27141434
Policy log std Min           -2.6893501
Z mean eval                  1.0755026
Z variance eval              0.024784537
total_rewards                [3497.01960774 4822.24237725 2584.85945732 1079.29355004   31.84765024
  263.22648034   95.94977046 3830.85796036 2896.86348632  194.6860637 ]
total_rewards_mean           1929.6846403777188
total_rewards_std            1711.0644288140236
total_rewards_max            4822.24237725497
total_rewards_min            31.847650243944628
Number of train steps total  1288000
Number of env steps total    1917040
Number of rollouts total     0
Train Time (s)               191.23453361773863
(Previous) Eval Time (s)     13.978228567168117
Sample Time (s)              8.480542671866715
Epoch Time (s)               213.69330485677347
Total Train Time (s)         71477.59809761867
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:02:59.698452 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #321 | Epoch Duration: 213.7858464717865
2020-01-12 12:02:59.698597 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0711854
Z variance train             0.024736285
KL Divergence                18.635706
KL Loss                      1.8635706
QF Loss                      422.02518
VF Loss                      106.81667
Policy Loss                  -1449.9736
Q Predictions Mean           1442.3173
Q Predictions Std            478.22205
Q Predictions Max            2014.0734
Q Predictions Min            397.30505
V Predictions Mean           1445.4198
V Predictions Std            476.17725
V Predictions Max            2007.5863
V Predictions Min            398.03842
Log Pis Mean                 0.93515515
Log Pis Std                  3.417315
Log Pis Max                  10.4999695
Log Pis Min                  -7.0403285
Policy mu Mean               0.05769398
Policy mu Std                0.7186487
Policy mu Max                2.721141
Policy mu Min                -3.1388516
Policy log std Mean          -1.0101027
Policy log std Std           0.3380662
Policy log std Max           -0.2509296
Policy log std Min           -2.3112516
Z mean eval                  1.1329263
Z variance eval              0.017680751
total_rewards                [3204.28339171 2910.08770036 1536.90785717 4910.57879059  164.88583787
 2787.09597871  882.93034393 -148.03216716  351.64336343 1638.3494868 ]
total_rewards_mean           1823.8730583402826
total_rewards_std            1528.1098099789845
total_rewards_max            4910.578790585459
total_rewards_min            -148.03216716140975
Number of train steps total  1292000
Number of env steps total    1927583
Number of rollouts total     0
Train Time (s)               190.86200742935762
(Previous) Eval Time (s)     19.377624281216413
Sample Time (s)              7.056477786973119
Epoch Time (s)               217.29610949754715
Total Train Time (s)         71694.98327973206
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:37.085736 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #322 | Epoch Duration: 217.38703060150146
2020-01-12 12:06:37.085882 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1294804
Z variance train             0.01764433
KL Divergence                19.951721
KL Loss                      1.9951721
QF Loss                      1003.0064
VF Loss                      235.3566
Policy Loss                  -1485.359
Q Predictions Mean           1478.5322
Q Predictions Std            442.9479
Q Predictions Max            2047.0273
Q Predictions Min            -148.14551
V Predictions Mean           1482.3137
V Predictions Std            440.01456
V Predictions Max            2043.0863
V Predictions Min            14.322649
Log Pis Mean                 1.4831896
Log Pis Std                  3.6259859
Log Pis Max                  25.298807
Log Pis Min                  -8.67108
Policy mu Mean               0.074623615
Policy mu Std                0.70674574
Policy mu Max                2.7728631
Policy mu Min                -2.9764411
Policy log std Mean          -1.0932517
Policy log std Std           0.3518815
Policy log std Max           -0.28715765
Policy log std Min           -3.0601125
Z mean eval                  1.1131582
Z variance eval              0.09838524
total_rewards                [ 175.9511495   936.83448465 3206.79938711 2449.96611194 2022.26359118
 4765.32079588 4841.54573249 4475.44601708   86.01913577 1021.27771796]
total_rewards_mean           2398.142412356526
total_rewards_std            1760.7403425391587
total_rewards_max            4841.545732490098
total_rewards_min            86.01913576557956
Number of train steps total  1296000
Number of env steps total    1939159
Number of rollouts total     0
Train Time (s)               191.8382857083343
(Previous) Eval Time (s)     17.31059694290161
Sample Time (s)              7.665163967292756
Epoch Time (s)               216.81404661852866
Total Train Time (s)         71912.02988011995
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:10:14.137357 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #323 | Epoch Duration: 217.05130124092102
2020-01-12 12:10:14.137754 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1092283
Z variance train             0.09845294
KL Divergence                18.959185
KL Loss                      1.8959185
QF Loss                      20500.469
VF Loss                      247.61246
Policy Loss                  -1483.3342
Q Predictions Mean           1477.2048
Q Predictions Std            447.78156
Q Predictions Max            2040.4468
Q Predictions Min            425.51837
V Predictions Mean           1495.0239
V Predictions Std            453.67517
V Predictions Max            2043.2701
V Predictions Min            418.73502
Log Pis Mean                 1.2651201
Log Pis Std                  3.524205
Log Pis Max                  10.2394705
Log Pis Min                  -7.9331803
Policy mu Mean               0.10512817
Policy mu Std                0.73044866
Policy mu Max                2.6162593
Policy mu Min                -2.5346239
Policy log std Mean          -1.0220745
Policy log std Std           0.34187865
Policy log std Max           0.116675496
Policy log std Min           -2.6814098
Z mean eval                  1.0857934
Z variance eval              0.03590817
total_rewards                [5214.65184634 4902.59513697 4506.75839972 5037.76658004 5065.99451009
 4998.80516894  691.95684448 4914.92096997 4844.31058965  882.96140002]
total_rewards_mean           4106.072144621967
total_rewards_std            1668.96026337979
total_rewards_max            5214.651846336626
total_rewards_min            691.9568444844635
Number of train steps total  1300000
Number of env steps total    1949773
Number of rollouts total     0
Train Time (s)               190.99293370405212
(Previous) Eval Time (s)     30.784425573423505
Sample Time (s)              6.058876403141767
Epoch Time (s)               227.8362356806174
Total Train Time (s)         72139.96268104343
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:02.077007 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #324 | Epoch Duration: 227.93900179862976
2020-01-12 12:14:02.077171 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0828577
Z variance train             0.035842996
KL Divergence                17.22903
KL Loss                      1.7229031
QF Loss                      635.9257
VF Loss                      104.47496
Policy Loss                  -1445.7753
Q Predictions Mean           1439.8275
Q Predictions Std            475.4338
Q Predictions Max            1996.0216
Q Predictions Min            422.44354
V Predictions Mean           1450.6838
V Predictions Std            476.09085
V Predictions Max            1990.955
V Predictions Min            422.8765
Log Pis Mean                 1.0009859
Log Pis Std                  3.661859
Log Pis Max                  12.049227
Log Pis Min                  -6.781363
Policy mu Mean               0.05879994
Policy mu Std                0.7007797
Policy mu Max                2.676772
Policy mu Min                -3.0044498
Policy log std Mean          -1.044353
Policy log std Std           0.37725225
Policy log std Max           -0.09076464
Policy log std Min           -2.503944
Z mean eval                  1.351894
Z variance eval              0.28477257
total_rewards                [5021.73950138 1447.01885299 5072.80238065 5053.25555962 5151.05213867
 5081.77803419 5015.55905598 1314.87332796 5298.44336141 5199.54514187]
total_rewards_mean           4365.606735470846
total_rewards_std            1494.8755001560905
total_rewards_max            5298.443361409957
total_rewards_min            1314.873327959355
Number of train steps total  1304000
Number of env steps total    1961773
Number of rollouts total     0
Train Time (s)               190.8714225050062
(Previous) Eval Time (s)     24.397912353277206
Sample Time (s)              7.057345715817064
Epoch Time (s)               222.32668057410046
Total Train Time (s)         72362.38308783202
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:17:44.504151 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #325 | Epoch Duration: 222.42682313919067
2020-01-12 12:17:44.504453 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3544772
Z variance train             0.2846668
KL Divergence                17.882679
KL Loss                      1.788268
QF Loss                      1107.8796
VF Loss                      160.24362
Policy Loss                  -1433.2639
Q Predictions Mean           1423.2986
Q Predictions Std            464.45984
Q Predictions Max            2002.2068
Q Predictions Min            412.5355
V Predictions Mean           1430.3795
V Predictions Std            464.74643
V Predictions Max            2000.2389
V Predictions Min            421.0949
Log Pis Mean                 1.0836685
Log Pis Std                  3.5031507
Log Pis Max                  12.020017
Log Pis Min                  -7.5405655
Policy mu Mean               0.09197864
Policy mu Std                0.6856112
Policy mu Max                3.7645884
Policy mu Min                -2.1832225
Policy log std Mean          -1.0538692
Policy log std Std           0.3713611
Policy log std Max           -0.035003662
Policy log std Min           -2.4146264
Z mean eval                  1.1391332
Z variance eval              0.01782241
total_rewards                [5239.95277057 5248.24599325 1844.13473847 5098.2317416  5022.10744635
 5325.7933625  5124.50588252 5039.34609339 5094.00683681 5083.74483315]
total_rewards_mean           4812.006969861026
total_rewards_std            993.7029235119362
total_rewards_max            5325.793362497349
total_rewards_min            1844.1347384720348
Number of train steps total  1308000
Number of env steps total    1973601
Number of rollouts total     0
Train Time (s)               192.76457176497206
(Previous) Eval Time (s)     31.227470891084522
Sample Time (s)              7.029180646874011
Epoch Time (s)               231.0212233029306
Total Train Time (s)         72593.49634194188
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:21:35.624878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #326 | Epoch Duration: 231.12016916275024
2020-01-12 12:21:35.625224 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1379303
Z variance train             0.017839154
KL Divergence                17.512976
KL Loss                      1.7512976
QF Loss                      873.4545
VF Loss                      167.83636
Policy Loss                  -1488.3365
Q Predictions Mean           1478.4049
Q Predictions Std            424.33493
Q Predictions Max            2023.8595
Q Predictions Min            411.54437
V Predictions Mean           1490.4841
V Predictions Std            426.24026
V Predictions Max            2024.1353
V Predictions Min            415.53918
Log Pis Mean                 1.4640368
Log Pis Std                  3.346972
Log Pis Max                  13.434756
Log Pis Min                  -6.817328
Policy mu Mean               0.0761763
Policy mu Std                0.68074656
Policy mu Max                2.4884074
Policy mu Min                -3.025991
Policy log std Mean          -1.0974488
Policy log std Std           0.3547261
Policy log std Max           -0.21729958
Policy log std Min           -2.540338
Z mean eval                  1.2315199
Z variance eval              0.1825884
total_rewards                [1091.7806576  2276.69410873 2323.55023673 5055.42007311 3405.01815551
 1887.2647269  4854.46497043 4802.94417698 5030.45838185 4981.25948059]
total_rewards_mean           3570.8854968430883
total_rewards_std            1474.0326937070872
total_rewards_max            5055.420073113182
total_rewards_min            1091.7806576000244
Number of train steps total  1312000
Number of env steps total    1981223
Number of rollouts total     0
Train Time (s)               191.90683231921867
(Previous) Eval Time (s)     29.309429343789816
Sample Time (s)              6.769468183629215
Epoch Time (s)               227.9857298466377
Total Train Time (s)         72821.80241772253
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:23.933578 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #327 | Epoch Duration: 228.30803966522217
2020-01-12 12:25:23.933797 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2257367
Z variance train             0.18096665
KL Divergence                15.1569
KL Loss                      1.5156901
QF Loss                      2114.7983
VF Loss                      197.05698
Policy Loss                  -1335.0634
Q Predictions Mean           1326.2981
Q Predictions Std            426.02527
Q Predictions Max            1918.7935
Q Predictions Min            441.73306
V Predictions Mean           1327.693
V Predictions Std            423.3628
V Predictions Max            1892.108
V Predictions Min            445.63864
Log Pis Mean                 1.4115858
Log Pis Std                  3.491917
Log Pis Max                  17.225782
Log Pis Min                  -7.670909
Policy mu Mean               0.078966334
Policy mu Std                0.7527708
Policy mu Max                3.512815
Policy mu Min                -4.655194
Policy log std Mean          -1.0445025
Policy log std Std           0.35144237
Policy log std Max           0.8259858
Policy log std Min           -2.5934954
Z mean eval                  1.0645826
Z variance eval              0.035645604
total_rewards                [4666.01459017 4740.16429345 2607.37637818 2054.34608936 1593.21695004
 4812.39429076   68.75891716 1004.61019872 5045.64986901  884.50902946]
total_rewards_mean           2747.704060632833
total_rewards_std            1808.6793633021691
total_rewards_max            5045.649869008835
total_rewards_min            68.75891716478044
Number of train steps total  1316000
Number of env steps total    1992769
Number of rollouts total     0
Train Time (s)               193.95539322216064
(Previous) Eval Time (s)     23.7395835169591
Sample Time (s)              7.022550595924258
Epoch Time (s)               224.717527335044
Total Train Time (s)         73046.60994747095
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:29:08.743159 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #328 | Epoch Duration: 224.80922269821167
2020-01-12 12:29:08.743303 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0638397
Z variance train             0.035293348
KL Divergence                17.970678
KL Loss                      1.7970679
QF Loss                      600.4989
VF Loss                      111.77677
Policy Loss                  -1458.5312
Q Predictions Mean           1450.3303
Q Predictions Std            411.17322
Q Predictions Max            2043.6625
Q Predictions Min            523.94073
V Predictions Mean           1452.486
V Predictions Std            407.90378
V Predictions Max            2019.4095
V Predictions Min            526.3765
Log Pis Mean                 1.5056653
Log Pis Std                  3.2686324
Log Pis Max                  12.55835
Log Pis Min                  -9.029041
Policy mu Mean               0.08631557
Policy mu Std                0.7458401
Policy mu Max                2.859908
Policy mu Min                -2.5589473
Policy log std Mean          -1.031232
Policy log std Std           0.32879707
Policy log std Max           -0.28516167
Policy log std Min           -2.4726896
Z mean eval                  1.1053612
Z variance eval              0.03384732
total_rewards                [4374.57539015 2516.0799712  4155.47060588 3406.256956   5278.38680529
 1112.33362073 5010.88970768 4597.72318477 3531.72215793 4953.70715302]
total_rewards_mean           3893.7145552658076
total_rewards_std            1228.290020656626
total_rewards_max            5278.386805291264
total_rewards_min            1112.333620732514
Number of train steps total  1320000
Number of env steps total    2004815
Number of rollouts total     0
Train Time (s)               197.34163727192208
(Previous) Eval Time (s)     26.378952583298087
Sample Time (s)              7.025486724451184
Epoch Time (s)               230.74607657967135
Total Train Time (s)         73277.48824258288
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:32:59.627335 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #329 | Epoch Duration: 230.88392090797424
2020-01-12 12:32:59.627497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1050789
Z variance train             0.033673055
KL Divergence                19.589851
KL Loss                      1.9589852
QF Loss                      770.3082
VF Loss                      141.88045
Policy Loss                  -1493.6979
Q Predictions Mean           1485.4487
Q Predictions Std            400.63492
Q Predictions Max            2053.0806
Q Predictions Min            605.3819
V Predictions Mean           1499.1372
V Predictions Std            397.67316
V Predictions Max            2068.802
V Predictions Min            621.7846
Log Pis Mean                 1.6259573
Log Pis Std                  3.3568053
Log Pis Max                  11.072006
Log Pis Min                  -10.127528
Policy mu Mean               0.07556671
Policy mu Std                0.7853757
Policy mu Max                2.5958853
Policy mu Min                -2.4233732
Policy log std Mean          -1.0167873
Policy log std Std           0.32902905
Policy log std Max           -0.20843899
Policy log std Min           -2.5101273
Z mean eval                  1.0827166
Z variance eval              0.06674357
total_rewards                [4478.9186823  4857.49249705 5077.4637409  -157.2659422    70.36575277
 2562.46547761    5.54994896 4987.07333241  456.34951807 5070.00534612]
total_rewards_mean           2740.841835398346
total_rewards_std            2273.6424048599615
total_rewards_max            5077.463740903868
total_rewards_min            -157.2659421983582
Number of train steps total  1324000
Number of env steps total    2015390
Number of rollouts total     0
Train Time (s)               191.30301788076758
(Previous) Eval Time (s)     25.388700152747333
Sample Time (s)              7.0105963526293635
Epoch Time (s)               223.70231438614428
Total Train Time (s)         73501.2785128355
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:36:43.422837 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #330 | Epoch Duration: 223.7952103614807
2020-01-12 12:36:43.423028 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0809853
Z variance train             0.06695075
KL Divergence                20.715382
KL Loss                      2.0715382
QF Loss                      20371.828
VF Loss                      176.7136
Policy Loss                  -1602.6176
Q Predictions Mean           1592.9832
Q Predictions Std            297.6072
Q Predictions Max            2073.462
Q Predictions Min            718.7928
V Predictions Mean           1607.7344
V Predictions Std            294.82834
V Predictions Max            2092.1282
V Predictions Min            737.4291
Log Pis Mean                 2.360498
Log Pis Std                  3.6329508
Log Pis Max                  15.519595
Log Pis Min                  -9.314973
Policy mu Mean               0.0960384
Policy mu Std                0.86531633
Policy mu Max                4.1684284
Policy mu Min                -3.3485346
Policy log std Mean          -1.0635023
Policy log std Std           0.33768907
Policy log std Max           0.091531515
Policy log std Min           -2.6877005
Z mean eval                  1.2554972
Z variance eval              0.05779209
total_rewards                [-1458.46130115  1115.54700153  1309.61190342   103.26622372
  1096.34061357  4936.11996021 -1542.73134549  2658.39346196
  3521.39096241  -485.39055004]
total_rewards_mean           1125.4086930138476
total_rewards_std            2002.0482403944818
total_rewards_max            4936.119960209359
total_rewards_min            -1542.731345490897
Number of train steps total  1328000
Number of env steps total    2023622
Number of rollouts total     0
Train Time (s)               188.70793611602858
(Previous) Eval Time (s)     28.00614556716755
Sample Time (s)              7.000734204892069
Epoch Time (s)               223.7148158880882
Total Train Time (s)         73725.08925131476
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:40:27.241352 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #331 | Epoch Duration: 223.81814289093018
2020-01-12 12:40:27.241659 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2508013
Z variance train             0.05717495
KL Divergence                25.350395
KL Loss                      2.5350397
QF Loss                      1150.5758
VF Loss                      295.83505
Policy Loss                  -1754.4089
Q Predictions Mean           1733.425
Q Predictions Std            260.13635
Q Predictions Max            2492.9048
Q Predictions Min            975.37915
V Predictions Mean           1760.9299
V Predictions Std            251.24258
V Predictions Max            2523.973
V Predictions Min            1002.0569
Log Pis Mean                 4.013308
Log Pis Std                  5.137227
Log Pis Max                  18.943684
Log Pis Min                  -5.5807366
Policy mu Mean               0.118932456
Policy mu Std                1.0763478
Policy mu Max                3.4467633
Policy mu Min                -3.5566492
Policy log std Mean          -0.9840896
Policy log std Std           0.33240873
Policy log std Max           -0.06714344
Policy log std Min           -2.380564
Z mean eval                  1.3943542
Z variance eval              0.49753562
total_rewards                [-1386.47896424 -1352.54729981 -1442.80201221 -1543.20505146
 -1356.35988466 -1349.33101266 -1495.60166752 -1535.49074861
 -1343.02986135 -1518.92098069]
total_rewards_mean           -1432.376748319631
total_rewards_std            79.78017419161758
total_rewards_max            -1343.0298613516827
total_rewards_min            -1543.205051462971
Number of train steps total  1332000
Number of env steps total    2035144
Number of rollouts total     0
Train Time (s)               191.77788326889277
(Previous) Eval Time (s)     29.467636081855744
Sample Time (s)              7.524795635137707
Epoch Time (s)               228.77031498588622
Total Train Time (s)         73953.9504954433
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:44:16.107401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #332 | Epoch Duration: 228.86551451683044
2020-01-12 12:44:16.107607 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #332 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3968372
Z variance train             0.49706906
KL Divergence                21.32359
KL Loss                      2.132359
QF Loss                      1447.5225
VF Loss                      1118.118
Policy Loss                  -2001.0365
Q Predictions Mean           1966.0623
Q Predictions Std            383.34494
Q Predictions Max            3172.392
Q Predictions Min            -61.053955
V Predictions Mean           1999.917
V Predictions Std            413.46396
V Predictions Max            3349.45
V Predictions Min            270.92398
Log Pis Mean                 5.6465354
Log Pis Std                  5.137642
Log Pis Max                  18.258165
Log Pis Min                  -3.9815586
Policy mu Mean               0.2733838
Policy mu Std                1.2069484
Policy mu Max                3.748865
Policy mu Min                -2.89296
Policy log std Mean          -0.97305703
Policy log std Std           0.3186077
Policy log std Max           0.5292889
Policy log std Min           -3.370294
Z mean eval                  1.3833777
Z variance eval              0.57257646
total_rewards                [-1588.79653917 -1070.75864984  -902.82741375 -1034.3484495
 -1406.84360792 -1048.88198793 -2230.19581636 -1309.03516305
 -1651.85610892 -1005.63999799]
total_rewards_mean           -1324.9183734415083
total_rewards_std            388.37286587883
total_rewards_max            -902.8274137485625
total_rewards_min            -2230.1958163562845
Number of train steps total  1336000
Number of env steps total    2045055
Number of rollouts total     0
Train Time (s)               191.52980061806738
(Previous) Eval Time (s)     34.019575376063585
Sample Time (s)              7.3996439152397215
Epoch Time (s)               232.9490199093707
Total Train Time (s)         74187.01135006268
Epoch                        333
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:48:09.171500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #333 | Epoch Duration: 233.06375002861023
2020-01-12 12:48:09.171642 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #333 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3875864
Z variance train             0.57922256
KL Divergence                24.598549
KL Loss                      2.4598548
QF Loss                      4178.09
VF Loss                      1031.8826
Policy Loss                  -2674.6233
Q Predictions Mean           2627.2583
Q Predictions Std            1027.7802
Q Predictions Max            6322.5767
Q Predictions Min            2026.419
V Predictions Mean           2677.736
V Predictions Std            1082.6317
V Predictions Max            6490.0186
V Predictions Min            1941.8218
Log Pis Mean                 6.104901
Log Pis Std                  5.695863
Log Pis Max                  27.817951
Log Pis Min                  -3.5793567
Policy mu Mean               -0.10680413
Policy mu Std                1.314131
Policy mu Max                3.5808492
Policy mu Min                -4.452521
Policy log std Mean          -0.91536343
Policy log std Std           0.3068331
Policy log std Max           0.057516575
Policy log std Min           -2.4140897
Z mean eval                  2.209611
Z variance eval              0.4454649
total_rewards                [-2374.62752774   -39.70780286 -2634.70650615 -2636.53502159
 -2596.05260866 -2096.1663112  -2590.86147853 -2615.27997174
 -2607.35609243 -2504.09031102]
total_rewards_mean           -2269.538363192914
total_rewards_std            760.2508164974804
total_rewards_max            -39.70780286224379
total_rewards_min            -2636.5350215933117
Number of train steps total  1340000
Number of env steps total    2055484
Number of rollouts total     0
Train Time (s)               192.2292064074427
(Previous) Eval Time (s)     26.638419188093394
Sample Time (s)              6.910242098849267
Epoch Time (s)               225.77786769438535
Total Train Time (s)         74412.88906977326
Epoch                        334
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:51:55.055031 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #334 | Epoch Duration: 225.8832504749298
2020-01-12 12:51:55.055289 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2144225
Z variance train             0.44452876
KL Divergence                47.781612
KL Loss                      4.7781615
QF Loss                      343156.94
VF Loss                      10316.019
Policy Loss                  -5185.9043
Q Predictions Mean           5035.388
Q Predictions Std            1588.8104
Q Predictions Max            10174.1
Q Predictions Min            2867.3237
V Predictions Mean           5180.5654
V Predictions Std            1644.1637
V Predictions Max            10537.364
V Predictions Min            3549.256
Log Pis Mean                 16.525852
Log Pis Std                  6.090106
Log Pis Max                  37.83558
Log Pis Min                  0.1147064
Policy mu Mean               0.33689827
Policy mu Std                2.1708524
Policy mu Max                6.0686827
Policy mu Min                -8.060695
Policy log std Mean          -0.75550556
Policy log std Std           0.37492734
Policy log std Max           1.5000309
Policy log std Min           -2.7658267
Z mean eval                  2.7132
Z variance eval              0.07644089
total_rewards                [-1678.00324375 -1377.51484249 -1791.03088554 -1340.81326914
 -1732.42936873 -1741.25902527 -2127.85084252  -667.49083209
 -1687.8731104  -1687.58127852]
total_rewards_mean           -1583.1846698441911
total_rewards_std            368.4441386073692
total_rewards_max            -667.4908320864336
total_rewards_min            -2127.850842521645
Number of train steps total  1344000
Number of env steps total    2066978
Number of rollouts total     0
Train Time (s)               191.54820148600265
(Previous) Eval Time (s)     32.29225838929415
Sample Time (s)              6.969058190938085
Epoch Time (s)               230.8095180662349
Total Train Time (s)         74643.78790486744
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:55:45.955553 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #335 | Epoch Duration: 230.90008544921875
2020-01-12 12:55:45.955699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #335 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7134356
Z variance train             0.07667319
KL Divergence                65.69968
KL Loss                      6.5699677
QF Loss                      49578.105
VF Loss                      8392.67
Policy Loss                  -7704.2974
Q Predictions Mean           7549.596
Q Predictions Std            2147.9736
Q Predictions Max            14885.983
Q Predictions Min            550.16235
V Predictions Mean           7722.323
V Predictions Std            2144.5098
V Predictions Max            14772.636
V Predictions Min            2997.8442
Log Pis Mean                 13.812703
Log Pis Std                  5.4663124
Log Pis Max                  50.59066
Log Pis Min                  1.9645144
Policy mu Mean               0.32012722
Policy mu Std                1.8847231
Policy mu Max                6.3325424
Policy mu Min                -7.7190256
Policy log std Mean          -0.9719063
Policy log std Std           0.4468775
Policy log std Max           0.6562053
Policy log std Min           -3.1076345
Z mean eval                  2.9209104
Z variance eval              3.0819547
total_rewards                [-1575.23829038 -1542.34415248 -1396.47836186 -1124.10200783
   -58.93231287   -30.3101529    -21.59155031 -1460.0239615
   -49.53541263 -2119.53331675]
total_rewards_mean           -937.8089519517325
total_rewards_std            768.7980954538283
total_rewards_max            -21.59155030786791
total_rewards_min            -2119.5333167531567
Number of train steps total  1348000
Number of env steps total    2078254
Number of rollouts total     0
Train Time (s)               190.9749686238356
(Previous) Eval Time (s)     20.946724604349583
Sample Time (s)              7.265372046269476
Epoch Time (s)               219.18706527445465
Total Train Time (s)         74863.07273111632
Epoch                        336
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:25.242607 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #336 | Epoch Duration: 219.28680205345154
2020-01-12 12:59:25.242753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.927947
Z variance train             3.0806735
KL Divergence                84.61528
KL Loss                      8.461528
QF Loss                      45664.9
VF Loss                      5255.5654
Policy Loss                  -9878.71
Q Predictions Mean           9727.397
Q Predictions Std            2493.1707
Q Predictions Max            18253.906
Q Predictions Min            7707.226
V Predictions Mean           9879.875
V Predictions Std            2511.1143
V Predictions Max            18759.537
V Predictions Min            7903.9116
Log Pis Mean                 13.823193
Log Pis Std                  5.395984
Log Pis Max                  32.864246
Log Pis Min                  -5.1471705
Policy mu Mean               0.06337731
Policy mu Std                1.8982099
Policy mu Max                4.3183393
Policy mu Min                -5.3799534
Policy log std Mean          -1.0756183
Policy log std Std           0.46836746
Policy log std Max           0.32762825
Policy log std Min           -2.808146
Z mean eval                  2.6973462
Z variance eval              0.07696416
total_rewards                [-1037.12118628    -8.17136436 -1570.14104632 -1506.86749719
  -118.87676456 -1485.99287039 -1576.08652257 -1264.94455088
   -41.95453356 -1420.79800278]
total_rewards_mean           -1003.0954338886746
total_rewards_std            638.47805582963
total_rewards_max            -8.171364363069486
total_rewards_min            -1576.0865225703155
Number of train steps total  1352000
Number of env steps total    2089134
Number of rollouts total     0
Train Time (s)               192.25205477001145
(Previous) Eval Time (s)     24.629089965950698
Sample Time (s)              7.17359835607931
Epoch Time (s)               224.05474309204146
Total Train Time (s)         75087.28350034636
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:03:09.458149 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #337 | Epoch Duration: 224.21528029441833
2020-01-12 13:03:09.458319 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6943004
Z variance train             0.07663427
KL Divergence                77.93076
KL Loss                      7.7930765
QF Loss                      45649.0
VF Loss                      6943.954
Policy Loss                  -9991.434
Q Predictions Mean           9861.168
Q Predictions Std            2131.3494
Q Predictions Max            17118.89
Q Predictions Min            7960.6206
V Predictions Mean           9972.532
V Predictions Std            2147.249
V Predictions Max            17086.463
V Predictions Min            8035.782
Log Pis Mean                 13.915754
Log Pis Std                  5.5216784
Log Pis Max                  41.459354
Log Pis Min                  3.0148005
Policy mu Mean               0.8372183
Policy mu Std                1.6089364
Policy mu Max                5.2750564
Policy mu Min                -5.0524507
Policy log std Mean          -1.1637162
Policy log std Std           0.5245246
Policy log std Max           0.3381586
Policy log std Min           -2.7868085
Z mean eval                  2.5436676
Z variance eval              0.13785842
total_rewards                [  -16.97195616 -1206.46707446  -102.20350806 -1103.68596087
 -1180.55234867 -1237.40766641  -846.29416613 -1173.21836604
  -883.17207265 -1121.74523469]
total_rewards_mean           -887.1718354133936
total_rewards_std            432.379747808806
total_rewards_max            -16.97195615619929
total_rewards_min            -1237.407666408114
Number of train steps total  1356000
Number of env steps total    2099564
Number of rollouts total     0
Train Time (s)               191.34723683726043
(Previous) Eval Time (s)     23.95188790699467
Sample Time (s)              7.562480799853802
Epoch Time (s)               222.8616055441089
Total Train Time (s)         75310.23421481717
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:06:52.417663 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #338 | Epoch Duration: 222.9591896533966
2020-01-12 13:06:52.417958 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #338 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5478969
Z variance train             0.13883764
KL Divergence                77.046074
KL Loss                      7.7046075
QF Loss                      44722.73
VF Loss                      8312.393
Policy Loss                  -10480.875
Q Predictions Mean           10356.967
Q Predictions Std            2240.3828
Q Predictions Max            16901.105
Q Predictions Min            7865.248
V Predictions Mean           10446.749
V Predictions Std            2274.7153
V Predictions Max            16983.498
V Predictions Min            7835.866
Log Pis Mean                 11.084315
Log Pis Std                  4.7999887
Log Pis Max                  35.409588
Log Pis Min                  -3.102686
Policy mu Mean               0.075924754
Policy mu Std                1.5517002
Policy mu Max                4.644501
Policy mu Min                -6.128401
Policy log std Mean          -1.3235078
Policy log std Std           0.5284687
Policy log std Max           0.6239859
Policy log std Min           -3.5840807
Z mean eval                  2.5304446
Z variance eval              0.028375989
total_rewards                [-1169.01433362 -1145.86372602 -1157.2170706  -1136.63449523
 -1242.34202646 -1162.09885237 -1118.01427928 -1185.81592523
  -885.35929624 -1122.044368  ]
total_rewards_mean           -1132.4404373051234
total_rewards_std            89.06262538717453
total_rewards_max            -885.3592962379186
total_rewards_min            -1242.3420264616507
Number of train steps total  1360000
Number of env steps total    2110166
Number of rollouts total     0
Train Time (s)               191.56501116603613
(Previous) Eval Time (s)     34.01140014687553
Sample Time (s)              7.649018801748753
Epoch Time (s)               233.2254301146604
Total Train Time (s)         75543.55262996396
Epoch                        339
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:10:45.750376 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #339 | Epoch Duration: 233.33221673965454
2020-01-12 13:10:45.750516 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.528179
Z variance train             0.02847876
KL Divergence                78.02941
KL Loss                      7.8029413
QF Loss                      20794.992
VF Loss                      4014.5562
Policy Loss                  -9918.59
Q Predictions Mean           9836.859
Q Predictions Std            1604.8438
Q Predictions Max            15379.726
Q Predictions Min            8324.834
V Predictions Mean           9880.906
V Predictions Std            1622.2266
V Predictions Max            15457.015
V Predictions Min            8333.416
Log Pis Mean                 8.96843
Log Pis Std                  4.0894356
Log Pis Max                  38.389397
Log Pis Min                  -3.4234571
Policy mu Mean               0.29522055
Policy mu Std                1.2491704
Policy mu Max                4.514146
Policy mu Min                -4.2881756
Policy log std Mean          -1.4088125
Policy log std Std           0.45069876
Policy log std Max           0.00967145
Policy log std Min           -2.8018012
Z mean eval                  2.2695403
Z variance eval              0.16213432
total_rewards                [-1844.80251338 -1858.249018     -18.99160223 -1479.98529179
 -2134.42013631 -1671.67567543 -1763.16926881 -1865.61495063
 -1634.99540726 -1565.93094766]
total_rewards_mean           -1583.7834811513285
total_rewards_std            550.2985853792958
total_rewards_max            -18.991602232536636
total_rewards_min            -2134.4201363137695
Number of train steps total  1364000
Number of env steps total    2121030
Number of rollouts total     0
Train Time (s)               190.8033595350571
(Previous) Eval Time (s)     30.992639168631285
Sample Time (s)              19.564364524558187
Epoch Time (s)               241.36036322824657
Total Train Time (s)         75785.0211172956
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:14:47.208252 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #340 | Epoch Duration: 241.45762515068054
2020-01-12 13:14:47.208401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.276094
Z variance train             0.16202466
KL Divergence                66.07743
KL Loss                      6.6077433
QF Loss                      705863.06
VF Loss                      4775.1763
Policy Loss                  -9615.225
Q Predictions Mean           9498.434
Q Predictions Std            1975.5802
Q Predictions Max            15612.034
Q Predictions Min            7422.6626
V Predictions Mean           9606.215
V Predictions Std            1991.4019
V Predictions Max            15833.777
V Predictions Min            7505.043
Log Pis Mean                 11.039213
Log Pis Std                  5.0447006
Log Pis Max                  31.249004
Log Pis Min                  -2.0324059
Policy mu Mean               0.4229812
Policy mu Std                1.4796911
Policy mu Max                5.795521
Policy mu Min                -3.3966134
Policy log std Mean          -1.2625284
Policy log std Std           0.48043653
Policy log std Max           0.07022405
Policy log std Min           -2.7084055
Z mean eval                  2.1736057
Z variance eval              0.027127322
total_rewards                [ -409.80022445   -16.91380498    -8.41558486  -203.33069695
  -418.06220841   -21.44765296 -1368.51198242   -20.26715529
  -761.90694888  -760.12877554]
total_rewards_mean           -398.87850347416594
total_rewards_std            427.2429823285217
total_rewards_max            -8.415584862371396
total_rewards_min            -1368.5119824153398
Number of train steps total  1368000
Number of env steps total    2130543
Number of rollouts total     0
Train Time (s)               191.2230151151307
(Previous) Eval Time (s)     20.816932004876435
Sample Time (s)              7.125646800734103
Epoch Time (s)               219.16559392074123
Total Train Time (s)         76004.48106194334
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:18:26.675435 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #341 | Epoch Duration: 219.46688389778137
2020-01-12 13:18:26.675736 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1679087
Z variance train             0.027410496
KL Divergence                65.04122
KL Loss                      6.5041223
QF Loss                      608052.2
VF Loss                      7238.795
Policy Loss                  -8729.468
Q Predictions Mean           8644.495
Q Predictions Std            1601.2708
Q Predictions Max            14992.683
Q Predictions Min            4460.5444
V Predictions Mean           8769.973
V Predictions Std            1631.3344
V Predictions Max            15381.404
V Predictions Min            7008.5713
Log Pis Mean                 8.461872
Log Pis Std                  5.528612
Log Pis Max                  62.76093
Log Pis Min                  -3.356337
Policy mu Mean               0.1724943
Policy mu Std                1.261517
Policy mu Max                5.5979433
Policy mu Min                -5.813779
Policy log std Mean          -1.3836539
Policy log std Std           0.43978286
Policy log std Max           0.17516267
Policy log std Min           -3.0037315
Z mean eval                  2.2562976
Z variance eval              0.9706179
total_rewards                [ -770.22180412  -896.00100775 -1299.71642763  -116.43949369
   -13.25345489   -15.42259554   -15.58450438 -1192.24421729
    -8.9320027    -31.50872606]
total_rewards_mean           -435.9324234069445
total_rewards_std            512.0239100923382
total_rewards_max            -8.93200270410274
total_rewards_min            -1299.7164276337364
Number of train steps total  1372000
Number of env steps total    2142201
Number of rollouts total     0
Train Time (s)               193.64799280185252
(Previous) Eval Time (s)     14.578355500008911
Sample Time (s)              7.1803592457436025
Epoch Time (s)               215.40670754760504
Total Train Time (s)         76219.97872568388
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:22:02.174935 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #342 | Epoch Duration: 215.49900794029236
2020-01-12 13:22:02.175093 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.249676
Z variance train             0.9668993
KL Divergence                54.2174
KL Loss                      5.42174
QF Loss                      47847.254
VF Loss                      3323.2803
Policy Loss                  -8583.882
Q Predictions Mean           8519.243
Q Predictions Std            1491.1134
Q Predictions Max            13984.113
Q Predictions Min            6925.1543
V Predictions Mean           8563.08
V Predictions Std            1517.5232
V Predictions Max            14198.651
V Predictions Min            6967.3794
Log Pis Mean                 7.5850024
Log Pis Std                  4.17503
Log Pis Max                  25.265713
Log Pis Min                  -2.3994985
Policy mu Mean               0.20591722
Policy mu Std                1.1787033
Policy mu Max                4.0907097
Policy mu Min                -2.9973419
Policy log std Mean          -1.323467
Policy log std Std           0.42187524
Policy log std Max           0.11046541
Policy log std Min           -3.3984518
Z mean eval                  2.128436
Z variance eval              0.2310226
total_rewards                [ -598.75876318   -21.33865449  -703.37919103  -874.73636444
  -949.47782984   -61.79824669  -780.56494193  -857.72548927
   -31.57932468 -1090.17788806]
total_rewards_mean           -596.9536693608064
total_rewards_std            386.66826249291984
total_rewards_max            -21.33865448700603
total_rewards_min            -1090.1778880556737
Number of train steps total  1376000
Number of env steps total    2152883
Number of rollouts total     0
Train Time (s)               189.95051311794668
(Previous) Eval Time (s)     24.16298356372863
Sample Time (s)              7.206746486015618
Epoch Time (s)               221.32024316769093
Total Train Time (s)         76441.38682137476
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:43.586736 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #343 | Epoch Duration: 221.41152620315552
2020-01-12 13:25:43.586924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #343 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1192775
Z variance train             0.23103404
KL Divergence                48.983036
KL Loss                      4.8983035
QF Loss                      12973.714
VF Loss                      2976.0461
Policy Loss                  -7554.5474
Q Predictions Mean           7508.752
Q Predictions Std            1254.0088
Q Predictions Max            11947.972
Q Predictions Min            5832.6904
V Predictions Mean           7555.254
V Predictions Std            1235.0605
V Predictions Max            11907.317
V Predictions Min            5901.6216
Log Pis Mean                 8.087396
Log Pis Std                  4.358099
Log Pis Max                  18.618393
Log Pis Min                  -5.3627763
Policy mu Mean               0.19209863
Policy mu Std                1.2153854
Policy mu Max                4.4178705
Policy mu Min                -3.61815
Policy log std Mean          -1.3442471
Policy log std Std           0.45274526
Policy log std Max           0.15488517
Policy log std Min           -2.759334
Z mean eval                  1.9719976
Z variance eval              0.046758395
total_rewards                [ 8.46298891e+00 -1.34164388e+01 -3.84185322e+02 -4.47009401e+02
 -4.45899231e+02 -5.59709277e+02 -4.48219832e-01 -1.58429024e+02
 -3.85664429e+02 -1.84284441e+01]
total_rewards_mean           -240.47267977306848
total_rewards_std            213.4651041113887
total_rewards_max            8.462988909296914
total_rewards_min            -559.7092771239002
Number of train steps total  1380000
Number of env steps total    2163825
Number of rollouts total     0
Train Time (s)               192.1623526159674
(Previous) Eval Time (s)     21.352292549796402
Sample Time (s)              7.717926133424044
Epoch Time (s)               221.23257129918784
Total Train Time (s)         76662.71014405647
Epoch                        344
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:29:24.912206 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #344 | Epoch Duration: 221.32515358924866
2020-01-12 13:29:24.912348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9731572
Z variance train             0.046250653
KL Divergence                48.98781
KL Loss                      4.898781
QF Loss                      14254.5625
VF Loss                      2187.5364
Policy Loss                  -6824.7197
Q Predictions Mean           6781.778
Q Predictions Std            861.2003
Q Predictions Max            9924.203
Q Predictions Min            5512.3853
V Predictions Mean           6812.42
V Predictions Std            861.3777
V Predictions Max            9931.773
V Predictions Min            5596.6763
Log Pis Mean                 6.901027
Log Pis Std                  3.9166677
Log Pis Max                  20.353697
Log Pis Min                  -2.9008572
Policy mu Mean               0.23497614
Policy mu Std                1.0669755
Policy mu Max                4.119575
Policy mu Min                -4.235034
Policy log std Mean          -1.4122689
Policy log std Std           0.40682858
Policy log std Max           0.15921867
Policy log std Min           -3.0000563
Z mean eval                  1.7863958
Z variance eval              0.023419254
total_rewards                [-941.56482574 -144.90766265   22.42089932   -2.36416956  -60.69269051
  -27.48636404   19.82827185 -407.23432224 -123.55033005  -85.9552133 ]
total_rewards_mean           -175.15064069201986
total_rewards_std            281.88621953851214
total_rewards_max            22.42089932013723
total_rewards_min            -941.5648257413023
Number of train steps total  1384000
Number of env steps total    2176011
Number of rollouts total     0
Train Time (s)               192.56057320768014
(Previous) Eval Time (s)     27.34367229556665
Sample Time (s)              7.285067760385573
Epoch Time (s)               227.18931326363236
Total Train Time (s)         76889.99172703736
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:33:12.196321 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #345 | Epoch Duration: 227.28383922576904
2020-01-12 13:33:12.196470 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7887466
Z variance train             0.023431456
KL Divergence                46.309956
KL Loss                      4.6309958
QF Loss                      7770.2217
VF Loss                      1813.5449
Policy Loss                  -5893.5615
Q Predictions Mean           5878.081
Q Predictions Std            780.6135
Q Predictions Max            8463.737
Q Predictions Min            4566.95
V Predictions Mean           5915.4062
V Predictions Std            780.80914
V Predictions Max            8489.951
V Predictions Min            4606.9844
Log Pis Mean                 5.262334
Log Pis Std                  3.5876954
Log Pis Max                  15.08795
Log Pis Min                  -3.5119734
Policy mu Mean               0.15729819
Policy mu Std                0.81125146
Policy mu Max                3.079515
Policy mu Min                -2.504922
Policy log std Mean          -1.4727285
Policy log std Std           0.3621519
Policy log std Max           -0.111738324
Policy log std Min           -3.1782758
Z mean eval                  2.1543908
Z variance eval              1.8573315
total_rewards                [ -426.18495967  -978.42017879 -1029.79781512  -443.01899232
  -977.21661847  -953.12197052 -1017.09633159  -995.12696638
  -953.54049395  -855.16195423]
total_rewards_mean           -862.8686281053551
total_rewards_std            218.85251167266767
total_rewards_max            -426.18495967215057
total_rewards_min            -1029.7978151208804
Number of train steps total  1388000
Number of env steps total    2185591
Number of rollouts total     0
Train Time (s)               192.24067729711533
(Previous) Eval Time (s)     34.24128295481205
Sample Time (s)              7.1739066038280725
Epoch Time (s)               233.65586685575545
Total Train Time (s)         77123.86498212023
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:37:06.073150 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #346 | Epoch Duration: 233.8765470981598
2020-01-12 13:37:06.073369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.159903
Z variance train             1.8554621
KL Divergence                38.226418
KL Loss                      3.8226418
QF Loss                      196449.22
VF Loss                      2375.018
Policy Loss                  -5057.301
Q Predictions Mean           5036.7266
Q Predictions Std            724.04285
Q Predictions Max            7430.2915
Q Predictions Min            3995.9258
V Predictions Mean           5058.7095
V Predictions Std            733.3937
V Predictions Max            7534.118
V Predictions Min            3975.4766
Log Pis Mean                 4.721232
Log Pis Std                  3.5823205
Log Pis Max                  19.718426
Log Pis Min                  -3.8579762
Policy mu Mean               -0.08832672
Policy mu Std                0.9309385
Policy mu Max                3.9277909
Policy mu Min                -4.1525517
Policy log std Mean          -1.29481
Policy log std Std           0.3730634
Policy log std Max           -0.053176045
Policy log std Min           -2.8737543
Z mean eval                  1.6034043
Z variance eval              0.2044293
total_rewards                [-1174.83481348  -720.49935595 -1196.43621274 -1224.77499795
 -1294.75653334 -1790.20412706 -1242.67980296  -506.82568301
 -1004.07744823 -1184.1682188 ]
total_rewards_mean           -1133.9257193504675
total_rewards_std            326.4645084589075
total_rewards_max            -506.82568301036457
total_rewards_min            -1790.2041270553175
Number of train steps total  1392000
Number of env steps total    2197613
Number of rollouts total     0
Train Time (s)               191.3779927273281
(Previous) Eval Time (s)     27.738689504098147
Sample Time (s)              6.993675099685788
Epoch Time (s)               226.11035733111203
Total Train Time (s)         77350.06942462875
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:40:52.285247 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #347 | Epoch Duration: 226.21169066429138
2020-01-12 13:40:52.285559 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6128254
Z variance train             0.20501237
KL Divergence                33.468575
KL Loss                      3.3468575
QF Loss                      8704.434
VF Loss                      2273.0452
Policy Loss                  -4917.092
Q Predictions Mean           4868.6055
Q Predictions Std            607.2116
Q Predictions Max            7088.407
Q Predictions Min            3766.6472
V Predictions Mean           4887.3
V Predictions Std            604.84515
V Predictions Max            7026.029
V Predictions Min            3779.9392
Log Pis Mean                 7.087247
Log Pis Std                  3.7474315
Log Pis Max                  21.099825
Log Pis Min                  -4.9152417
Policy mu Mean               -0.21477935
Policy mu Std                1.2019856
Policy mu Max                3.8278344
Policy mu Min                -3.8279018
Policy log std Mean          -1.2108281
Policy log std Std           0.41623276
Policy log std Max           -0.047819495
Policy log std Min           -2.969943
Z mean eval                  1.5693681
Z variance eval              0.27057952
total_rewards                [  43.93143313 -806.87967078 -400.84255242 -308.91071264  219.69874423
  329.62632523 -589.85820095    6.39340193 -796.05285523   16.04340638]
total_rewards_mean           -228.68506811023735
total_rewards_std            390.5085037356175
total_rewards_max            329.6263252318017
total_rewards_min            -806.8796707807817
Number of train steps total  1396000
Number of env steps total    2209609
Number of rollouts total     0
Train Time (s)               192.7673316230066
(Previous) Eval Time (s)     27.377580804750323
Sample Time (s)              7.045246290974319
Epoch Time (s)               227.19015871873125
Total Train Time (s)         77577.3596479022
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:44:39.581193 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #348 | Epoch Duration: 227.29539155960083
2020-01-12 13:44:39.581399 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5668535
Z variance train             0.26955122
KL Divergence                26.637236
KL Loss                      2.6637237
QF Loss                      8144.008
VF Loss                      1134.4259
Policy Loss                  -4469.8237
Q Predictions Mean           4428.2812
Q Predictions Std            541.2936
Q Predictions Max            5832.123
Q Predictions Min            3158.7463
V Predictions Mean           4473.573
V Predictions Std            539.81854
V Predictions Max            5888.1104
V Predictions Min            3265.4517
Log Pis Mean                 6.585436
Log Pis Std                  3.5805025
Log Pis Max                  18.496984
Log Pis Min                  -3.0579603
Policy mu Mean               -0.13902739
Policy mu Std                1.1928554
Policy mu Max                3.747808
Policy mu Min                -3.660254
Policy log std Mean          -1.2166543
Policy log std Std           0.40916544
Policy log std Max           -0.030291557
Policy log std Min           -2.5794592
Z mean eval                  1.4937048
Z variance eval              0.18278566
total_rewards                [ -63.06902217  145.55645165  220.05442     361.62878564 -108.21890764
 -130.61360562   47.04890404  -73.77472091 -169.71439827   46.08954671]
total_rewards_mean           27.498745342501696
total_rewards_std            162.52897484551355
total_rewards_max            361.6287856390814
total_rewards_min            -169.71439827359956
Number of train steps total  1400000
Number of env steps total    2221240
Number of rollouts total     0
Train Time (s)               193.3857778669335
(Previous) Eval Time (s)     28.057910177856684
Sample Time (s)              7.5271907155402005
Epoch Time (s)               228.97087876033038
Total Train Time (s)         77806.42347244453
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:48:28.650054 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #349 | Epoch Duration: 229.068514585495
2020-01-12 13:48:28.650200 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4919285
Z variance train             0.18060835
KL Divergence                28.375607
KL Loss                      2.8375607
QF Loss                      3111.715
VF Loss                      789.72626
Policy Loss                  -4170.6963
Q Predictions Mean           4144.1187
Q Predictions Std            389.41022
Q Predictions Max            5134.9507
Q Predictions Min            2862.9287
V Predictions Mean           4165.466
V Predictions Std            381.81213
V Predictions Max            5229.0674
V Predictions Min            2870.9968
Log Pis Mean                 4.724861
Log Pis Std                  3.0971806
Log Pis Max                  16.003984
Log Pis Min                  -6.4545255
Policy mu Mean               0.09624983
Policy mu Std                0.89626795
Policy mu Max                3.2354822
Policy mu Min                -3.2802014
Policy log std Mean          -1.341027
Policy log std Std           0.34484306
Policy log std Max           -0.17181265
Policy log std Min           -2.6145465
Z mean eval                  1.5632023
Z variance eval              0.21026519
total_rewards                [ 155.19145859  474.28107982  240.18080108  159.57528822 -498.5940855
  459.7781515   571.22172652 1689.88340489  198.4092029   712.96441701]
total_rewards_mean           416.289144504455
total_rewards_std            528.0992490407557
total_rewards_max            1689.8834048897338
total_rewards_min            -498.59408549544855
Number of train steps total  1404000
Number of env steps total    2230108
Number of rollouts total     0
Train Time (s)               191.10641704127192
(Previous) Eval Time (s)     23.166247567161918
Sample Time (s)              7.0453599081374705
Epoch Time (s)               221.3180245165713
Total Train Time (s)         78027.83628684469
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:52:10.066759 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #350 | Epoch Duration: 221.41643357276917
2020-01-12 13:52:10.066910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5636222
Z variance train             0.20991631
KL Divergence                26.859735
KL Loss                      2.6859736
QF Loss                      3181.8281
VF Loss                      1217.8049
Policy Loss                  -3818.2412
Q Predictions Mean           3798.5222
Q Predictions Std            415.98938
Q Predictions Max            4458.7217
Q Predictions Min            -98.04225
V Predictions Mean           3794.1675
V Predictions Std            393.38736
V Predictions Max            4429.1343
V Predictions Min            356.0556
Log Pis Mean                 4.2443275
Log Pis Std                  2.9757473
Log Pis Max                  20.262388
Log Pis Min                  -5.805393
Policy mu Mean               0.008854213
Policy mu Std                0.8215014
Policy mu Max                5.1193953
Policy mu Min                -5.3053913
Policy log std Mean          -1.3798355
Policy log std Std           0.33387217
Policy log std Max           0.07587612
Policy log std Min           -2.7178822
Z mean eval                  1.5308859
Z variance eval              0.36859947
total_rewards                [ 177.85136858   53.17405197  208.62562475   13.31231203  686.80620699
   13.14804911  169.36197343  866.30675605  198.63324648 1026.43213882]
total_rewards_mean           341.36517282229926
total_rewards_std            354.531135291257
total_rewards_max            1026.4321388241492
total_rewards_min            13.148049109224637
Number of train steps total  1408000
Number of env steps total    2240251
Number of rollouts total     0
Train Time (s)               190.92803991539404
(Previous) Eval Time (s)     8.289985090959817
Sample Time (s)              7.315648679621518
Epoch Time (s)               206.53367368597537
Total Train Time (s)         78234.46145465039
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:55:36.694120 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #351 | Epoch Duration: 206.62710165977478
2020-01-12 13:55:36.694276 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5370483
Z variance train             0.37345356
KL Divergence                23.659153
KL Loss                      2.3659153
QF Loss                      1927.272
VF Loss                      434.19077
Policy Loss                  -3280.1555
Q Predictions Mean           3274.3242
Q Predictions Std            301.92056
Q Predictions Max            3779.6497
Q Predictions Min            2058.1812
V Predictions Mean           3282.0486
V Predictions Std            297.49734
V Predictions Max            3769.1492
V Predictions Min            2042.9124
Log Pis Mean                 3.5714784
Log Pis Std                  2.8408208
Log Pis Max                  14.001846
Log Pis Min                  -4.8965616
Policy mu Mean               0.13503712
Policy mu Std                0.7832944
Policy mu Max                2.889267
Policy mu Min                -2.612176
Policy log std Mean          -1.2861902
Policy log std Std           0.31026444
Policy log std Max           -0.2874539
Policy log std Min           -2.3583086
Z mean eval                  1.440747
Z variance eval              0.38965946
total_rewards                [  22.46645469  773.11359444  569.16452055  742.13702973  306.04176667
 1324.47533655  440.33366985   42.18358506  347.42838817  447.40431103]
total_rewards_mean           501.4748656743642
total_rewards_std            363.67586708301474
total_rewards_max            1324.4753365521428
total_rewards_min            22.46645469223711
Number of train steps total  1412000
Number of env steps total    2252169
Number of rollouts total     0
Train Time (s)               193.35091627202928
(Previous) Eval Time (s)     11.39974056603387
Sample Time (s)              7.353874082211405
Epoch Time (s)               212.10453092027456
Total Train Time (s)         78446.94528278755
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:09.184955 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #352 | Epoch Duration: 212.490562915802
2020-01-12 13:59:09.185133 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4418422
Z variance train             0.38874227
KL Divergence                20.547268
KL Loss                      2.0547268
QF Loss                      1890.1392
VF Loss                      341.5791
Policy Loss                  -2831.8142
Q Predictions Mean           2823.544
Q Predictions Std            262.44217
Q Predictions Max            3323.326
Q Predictions Min            1771.3275
V Predictions Mean           2828.609
V Predictions Std            259.49542
V Predictions Max            3316.6306
V Predictions Min            1768.132
Log Pis Mean                 2.4477959
Log Pis Std                  3.2018087
Log Pis Max                  14.970166
Log Pis Min                  -5.377278
Policy mu Mean               0.13120507
Policy mu Std                0.7572797
Policy mu Max                2.8252244
Policy mu Min                -2.634047
Policy log std Mean          -1.2211742
Policy log std Std           0.28519705
Policy log std Max           -0.42389703
Policy log std Min           -2.2822266
Z mean eval                  1.3071725
Z variance eval              0.06467296
total_rewards                [ 497.47635227 2862.01197916 1765.35271192  878.75075451 1005.14643639
 1253.20817622  253.44267715  195.3611034  1670.75036847 -380.10542281]
total_rewards_mean           1000.1395136688068
total_rewards_std            891.2695482828592
total_rewards_max            2862.011979155165
total_rewards_min            -380.10542280559054
Number of train steps total  1416000
Number of env steps total    2263320
Number of rollouts total     0
Train Time (s)               190.9182293061167
(Previous) Eval Time (s)     15.306590488180518
Sample Time (s)              6.946032448671758
Epoch Time (s)               213.17085224296898
Total Train Time (s)         78660.20299938181
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:42.446056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #353 | Epoch Duration: 213.26079273223877
2020-01-12 14:02:42.446241 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.308764
Z variance train             0.064496055
KL Divergence                20.573175
KL Loss                      2.0573175
QF Loss                      1286.5459
VF Loss                      398.0852
Policy Loss                  -2531.4795
Q Predictions Mean           2523.2822
Q Predictions Std            286.00748
Q Predictions Max            3021.8364
Q Predictions Min            1396.9382
V Predictions Mean           2519.7432
V Predictions Std            277.66748
V Predictions Max            2996.199
V Predictions Min            1426.5845
Log Pis Mean                 2.561958
Log Pis Std                  2.758035
Log Pis Max                  14.77988
Log Pis Min                  -6.630309
Policy mu Mean               0.082285784
Policy mu Std                0.76692325
Policy mu Max                2.9502366
Policy mu Min                -2.4847996
Policy log std Mean          -1.1769685
Policy log std Std           0.273772
Policy log std Max           -0.051125765
Policy log std Min           -2.3092604
Z mean eval                  1.2624918
Z variance eval              0.2508099
total_rewards                [1347.67457847 3632.02145951  203.65058725 3851.4637685  1147.54319762
  235.22877485  920.1010297   141.82318842 -395.87566917  781.88037862]
total_rewards_mean           1186.5511293768018
total_rewards_std            1371.530521270555
total_rewards_max            3851.4637684993627
total_rewards_min            -395.8756691738702
Number of train steps total  1420000
Number of env steps total    2274147
Number of rollouts total     0
Train Time (s)               191.30413632839918
(Previous) Eval Time (s)     27.257358982227743
Sample Time (s)              6.8403022340498865
Epoch Time (s)               225.4017975446768
Total Train Time (s)         78885.74348875135
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:06:27.994476 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #354 | Epoch Duration: 225.54805183410645
2020-01-12 14:06:27.994797 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.263797
Z variance train             0.25419885
KL Divergence                16.78699
KL Loss                      1.6786989
QF Loss                      2515.9775
VF Loss                      1397.3181
Policy Loss                  -2273.764
Q Predictions Mean           2268.205
Q Predictions Std            268.8811
Q Predictions Max            2804.2842
Q Predictions Min            495.14368
V Predictions Mean           2273.1355
V Predictions Std            250.98906
V Predictions Max            2794.293
V Predictions Min            1112.9004
Log Pis Mean                 2.7292864
Log Pis Std                  2.8853886
Log Pis Max                  11.209705
Log Pis Min                  -7.23797
Policy mu Mean               0.13528271
Policy mu Std                0.7484703
Policy mu Max                2.7501369
Policy mu Min                -2.957464
Policy log std Mean          -1.1982511
Policy log std Std           0.2877203
Policy log std Max           -0.3964665
Policy log std Min           -2.8463504
Z mean eval                  1.0593386
Z variance eval              0.10753685
total_rewards                [  86.16835649 1301.42551877 1211.38352651 1609.88325224  700.56768474
 2097.01072825 -237.83593663  482.62377638 3717.40636955 3430.01080026]
total_rewards_mean           1439.8644076564738
total_rewards_std            1256.5841515887175
total_rewards_max            3717.4063695548975
total_rewards_min            -237.83593663412796
Number of train steps total  1424000
Number of env steps total    2284405
Number of rollouts total     0
Train Time (s)               192.39005979942158
(Previous) Eval Time (s)     27.397322494070977
Sample Time (s)              7.184234958142042
Epoch Time (s)               226.9716172516346
Total Train Time (s)         79112.80734540103
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:10:15.059566 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #355 | Epoch Duration: 227.06454873085022
2020-01-12 14:10:15.059728 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0558031
Z variance train             0.10694845
KL Divergence                16.654783
KL Loss                      1.6654783
QF Loss                      1996.3986
VF Loss                      280.28525
Policy Loss                  -2065.2266
Q Predictions Mean           2052.7173
Q Predictions Std            269.18106
Q Predictions Max            2555.8284
Q Predictions Min            1136.0466
V Predictions Mean           2056.3135
V Predictions Std            263.37622
V Predictions Max            2559.9028
V Predictions Min            1141.0452
Log Pis Mean                 2.2934504
Log Pis Std                  2.8590295
Log Pis Max                  14.037829
Log Pis Min                  -7.362175
Policy mu Mean               0.03957849
Policy mu Std                0.7597986
Policy mu Max                2.369096
Policy mu Min                -2.5975845
Policy log std Mean          -1.1682124
Policy log std Std           0.28028637
Policy log std Max           -0.11170435
Policy log std Min           -2.4416502
Z mean eval                  1.190277
Z variance eval              0.30139732
total_rewards                [3882.48434566  264.41950933 1857.7699022  3951.84954037 3934.21870489
 1257.13300257 3730.6928585  3093.37521    1483.41810531   97.89583305]
total_rewards_mean           2355.3257011878527
total_rewards_std            1466.0166114776243
total_rewards_max            3951.849540369504
total_rewards_min            97.8958330513155
Number of train steps total  1428000
Number of env steps total    2294872
Number of rollouts total     0
Train Time (s)               190.75219936482608
(Previous) Eval Time (s)     29.768638424109668
Sample Time (s)              7.545270883943886
Epoch Time (s)               228.06610867287964
Total Train Time (s)         79340.96660385933
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:14:03.223070 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #356 | Epoch Duration: 228.1632330417633
2020-01-12 14:14:03.223207 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1921432
Z variance train             0.29657617
KL Divergence                15.779803
KL Loss                      1.5779804
QF Loss                      1175.5088
VF Loss                      389.74954
Policy Loss                  -1958.7323
Q Predictions Mean           1946.1768
Q Predictions Std            344.27866
Q Predictions Max            2515.0103
Q Predictions Min            -52.01838
V Predictions Mean           1946.7542
V Predictions Std            339.5824
V Predictions Max            2503.8179
V Predictions Min            50.268303
Log Pis Mean                 2.5920384
Log Pis Std                  3.4538703
Log Pis Max                  32.3379
Log Pis Min                  -5.346292
Policy mu Mean               0.05578003
Policy mu Std                0.77492005
Policy mu Max                4.538285
Policy mu Min                -3.6874318
Policy log std Mean          -1.1738636
Policy log std Std           0.3131967
Policy log std Max           1.4022101
Policy log std Min           -4.0311003
Z mean eval                  1.2218927
Z variance eval              0.05076601
total_rewards                [ 224.4368095  -103.36405382  682.08995768 2436.25386787 3839.29360086
 2623.09904832 2892.00319739 3971.37371824 1557.08238419 2698.09449172]
total_rewards_mean           2082.0363021954954
total_rewards_std            1362.843318343101
total_rewards_max            3971.3737182353634
total_rewards_min            -103.36405381716844
Number of train steps total  1432000
Number of env steps total    2303305
Number of rollouts total     0
Train Time (s)               192.2960235932842
(Previous) Eval Time (s)     26.828204839024693
Sample Time (s)              7.596249125432223
Epoch Time (s)               226.7204775577411
Total Train Time (s)         79567.78466908447
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:17:50.048838 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #357 | Epoch Duration: 226.82548213005066
2020-01-12 14:17:50.049132 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2275693
Z variance train             0.05090301
KL Divergence                18.219074
KL Loss                      1.8219074
QF Loss                      2638.342
VF Loss                      160.90309
Policy Loss                  -1822.0632
Q Predictions Mean           1811.6024
Q Predictions Std            305.82068
Q Predictions Max            2355.533
Q Predictions Min            903.819
V Predictions Mean           1826.3838
V Predictions Std            305.10083
V Predictions Max            2359.8638
V Predictions Min            900.1377
Log Pis Mean                 1.8940604
Log Pis Std                  2.941434
Log Pis Max                  15.722559
Log Pis Min                  -6.7144732
Policy mu Mean               0.12719122
Policy mu Std                0.72220373
Policy mu Max                2.553028
Policy mu Min                -3.661146
Policy log std Mean          -1.1570356
Policy log std Std           0.26953223
Policy log std Max           -0.31417012
Policy log std Min           -2.219714
Z mean eval                  1.0805129
Z variance eval              0.22208059
total_rewards                [1453.78446748 -139.15162042  295.70817287    4.24775833 3780.59711367
 2575.79741406   17.64169895 3165.76176221 3731.29578734  991.32671758]
total_rewards_mean           1587.700927206608
total_rewards_std            1512.2061370108067
total_rewards_max            3780.597113671874
total_rewards_min            -139.1516204158001
Number of train steps total  1436000
Number of env steps total    2314449
Number of rollouts total     0
Train Time (s)               191.65826802980155
(Previous) Eval Time (s)     20.863011532928795
Sample Time (s)              7.352131174411625
Epoch Time (s)               219.87341073714197
Total Train Time (s)         79787.74825532362
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:21:30.015409 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #358 | Epoch Duration: 219.9660506248474
2020-01-12 14:21:30.015604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0843289
Z variance train             0.22056064
KL Divergence                15.069584
KL Loss                      1.5069584
QF Loss                      1213.0664
VF Loss                      116.16318
Policy Loss                  -1732.8334
Q Predictions Mean           1726.3772
Q Predictions Std            324.07986
Q Predictions Max            2266.919
Q Predictions Min            792.98364
V Predictions Mean           1733.3412
V Predictions Std            323.00595
V Predictions Max            2282.1047
V Predictions Min            800.34406
Log Pis Mean                 1.7698861
Log Pis Std                  2.8707645
Log Pis Max                  11.668754
Log Pis Min                  -6.3222427
Policy mu Mean               0.10188588
Policy mu Std                0.7163657
Policy mu Max                2.4588802
Policy mu Min                -2.7564116
Policy log std Mean          -1.124857
Policy log std Std           0.2580734
Policy log std Max           -0.2289871
Policy log std Min           -2.1922202
Z mean eval                  1.0622886
Z variance eval              0.09450709
total_rewards                [1943.54003626 3615.48388201 1912.17797523 2818.84572001 1270.92689496
  402.0278975  2580.24037522 1400.60666069 3164.53801688 2040.96993647]
total_rewards_mean           2114.935739523115
total_rewards_std            910.930058187475
total_rewards_max            3615.4838820055843
total_rewards_min            402.02789750392134
Number of train steps total  1440000
Number of env steps total    2324879
Number of rollouts total     0
Train Time (s)               192.08937544887885
(Previous) Eval Time (s)     21.568036003038287
Sample Time (s)              7.042645651847124
Epoch Time (s)               220.70005710376427
Total Train Time (s)         80008.5370730604
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:10.806857 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #359 | Epoch Duration: 220.79111695289612
2020-01-12 14:25:10.807022 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623778
Z variance train             0.094200425
KL Divergence                14.351008
KL Loss                      1.4351009
QF Loss                      748.1414
VF Loss                      1000.8052
Policy Loss                  -1626.3307
Q Predictions Mean           1613.3507
Q Predictions Std            391.88107
Q Predictions Max            2219.176
Q Predictions Min            -24.583149
V Predictions Mean           1628.4633
V Predictions Std            380.6679
V Predictions Max            2205.7153
V Predictions Min            702.7368
Log Pis Mean                 1.7517831
Log Pis Std                  3.1006382
Log Pis Max                  17.192745
Log Pis Min                  -7.108755
Policy mu Mean               0.072450906
Policy mu Std                0.69521606
Policy mu Max                2.7633917
Policy mu Min                -4.1513667
Policy log std Mean          -1.1471491
Policy log std Std           0.2841591
Policy log std Max           0.5133563
Policy log std Min           -2.466682
Z mean eval                  0.9804436
Z variance eval              0.17042542
total_rewards                [7.90868448e+02 8.33255999e+01 1.14715094e+03 2.78355135e+03
 3.17570653e+00 1.90373735e+02 1.40118556e+01 2.35593686e+03
 1.63837082e+03 3.74194988e+03]
total_rewards_mean           1274.8715193131043
total_rewards_std            1253.6702296414926
total_rewards_max            3741.9498779875735
total_rewards_min            3.1757065334509527
Number of train steps total  1444000
Number of env steps total    2335050
Number of rollouts total     0
Train Time (s)               191.5942566767335
(Previous) Eval Time (s)     25.581546315923333
Sample Time (s)              19.517241842113435
Epoch Time (s)               236.69304483477026
Total Train Time (s)         80245.34271185659
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:29:07.622902 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #360 | Epoch Duration: 236.81576681137085
2020-01-12 14:29:07.623067 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9808013
Z variance train             0.17076218
KL Divergence                13.908878
KL Loss                      1.3908879
QF Loss                      642.78845
VF Loss                      145.25053
Policy Loss                  -1530.6785
Q Predictions Mean           1521.9373
Q Predictions Std            334.23862
Q Predictions Max            2070.308
Q Predictions Min            583.59894
V Predictions Mean           1533.637
V Predictions Std            332.92017
V Predictions Max            2076.0732
V Predictions Min            607.62897
Log Pis Mean                 1.3949075
Log Pis Std                  2.8189278
Log Pis Max                  10.459838
Log Pis Min                  -5.766073
Policy mu Mean               0.12562376
Policy mu Std                0.6787509
Policy mu Max                2.713665
Policy mu Min                -2.3439684
Policy log std Mean          -1.1289165
Policy log std Std           0.28630257
Policy log std Max           0.07391095
Policy log std Min           -2.3185773
Z mean eval                  0.9369047
Z variance eval              0.19416013
total_rewards                [4120.67834003 3866.57379015 2698.5888776    11.42878242   40.14400058
 2313.55180616  869.08002167  102.80990236 3832.29462952 1063.24300709]
total_rewards_mean           1891.8393157582602
total_rewards_std            1592.4605714999548
total_rewards_max            4120.678340034693
total_rewards_min            11.428782419655121
Number of train steps total  1448000
Number of env steps total    2344924
Number of rollouts total     0
Train Time (s)               191.42786298086867
(Previous) Eval Time (s)     22.073265759274364
Sample Time (s)              7.123017759528011
Epoch Time (s)               220.62414649967104
Total Train Time (s)         80466.16826154804
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:32:48.456924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #361 | Epoch Duration: 220.83373475074768
2020-01-12 14:32:48.457093 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9446303
Z variance train             0.19426963
KL Divergence                14.113352
KL Loss                      1.4113352
QF Loss                      1463.2225
VF Loss                      400.62366
Policy Loss                  -1570.5878
Q Predictions Mean           1563.4338
Q Predictions Std            386.91833
Q Predictions Max            2146.4565
Q Predictions Min            595.0348
V Predictions Mean           1554.3564
V Predictions Std            382.5961
V Predictions Max            2126.8896
V Predictions Min            570.2288
Log Pis Mean                 1.3859429
Log Pis Std                  3.0095804
Log Pis Max                  11.475161
Log Pis Min                  -5.8957987
Policy mu Mean               0.14212357
Policy mu Std                0.6498893
Policy mu Max                2.7858105
Policy mu Min                -2.211153
Policy log std Mean          -1.1458658
Policy log std Std           0.295702
Policy log std Max           0.24786937
Policy log std Min           -2.3997033
Z mean eval                  0.96685916
Z variance eval              0.09791323
total_rewards                [4300.99055118 3259.95831242 2935.18986865 1049.14719065 3886.98720152
  835.87564315 2299.94249725  374.33853919 1469.9607492  4047.03313133]
total_rewards_mean           2445.942368454653
total_rewards_std            1370.8406476756365
total_rewards_max            4300.990551181709
total_rewards_min            374.3385391932899
Number of train steps total  1452000
Number of env steps total    2354147
Number of rollouts total     0
Train Time (s)               190.5596514879726
(Previous) Eval Time (s)     25.558574106078595
Sample Time (s)              7.422010400798172
Epoch Time (s)               223.54023599484935
Total Train Time (s)         80689.80241191387
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:32.097465 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #362 | Epoch Duration: 223.64022636413574
2020-01-12 14:36:32.097700 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9649967
Z variance train             0.098064356
KL Divergence                14.433104
KL Loss                      1.4433104
QF Loss                      875.03577
VF Loss                      223.6181
Policy Loss                  -1443.882
Q Predictions Mean           1436.5779
Q Predictions Std            359.35498
Q Predictions Max            2014.841
Q Predictions Min            515.4018
V Predictions Mean           1438.553
V Predictions Std            359.66742
V Predictions Max            1992.3829
V Predictions Min            512.12225
Log Pis Mean                 1.6536268
Log Pis Std                  2.9037836
Log Pis Max                  12.980017
Log Pis Min                  -6.8470287
Policy mu Mean               0.09631364
Policy mu Std                0.67250836
Policy mu Max                2.5657847
Policy mu Min                -2.4263234
Policy log std Mean          -1.1660744
Policy log std Std           0.29743576
Policy log std Max           -0.023717284
Policy log std Min           -2.3301332
Z mean eval                  0.98991334
Z variance eval              0.15164597
total_rewards                [2314.09127147 1693.50421538 1691.5079516   336.43437926 4230.22309884
  470.28644    3106.23273919 1271.51949064 3902.0444607  4097.81629101]
total_rewards_mean           2311.366033808522
total_rewards_std            1384.6545610544172
total_rewards_max            4230.223098838545
total_rewards_min            336.4343792610013
Number of train steps total  1456000
Number of env steps total    2363176
Number of rollouts total     0
Train Time (s)               191.215651222039
(Previous) Eval Time (s)     25.887885860167444
Sample Time (s)              7.131356425583363
Epoch Time (s)               224.23489350778982
Total Train Time (s)         80914.1255675396
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:40:16.423829 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #363 | Epoch Duration: 224.32596468925476
2020-01-12 14:40:16.423987 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99856395
Z variance train             0.14955816
KL Divergence                16.169413
KL Loss                      1.6169413
QF Loss                      8482.465
VF Loss                      186.28864
Policy Loss                  -1466.3148
Q Predictions Mean           1457.3723
Q Predictions Std            385.36667
Q Predictions Max            2027.4678
Q Predictions Min            478.52838
V Predictions Mean           1473.79
V Predictions Std            388.1272
V Predictions Max            2028.4532
V Predictions Min            489.28067
Log Pis Mean                 1.7274702
Log Pis Std                  3.0411053
Log Pis Max                  17.176043
Log Pis Min                  -6.658938
Policy mu Mean               0.098316096
Policy mu Std                0.6826928
Policy mu Max                4.03776
Policy mu Min                -2.7486663
Policy log std Mean          -1.1368165
Policy log std Std           0.30421156
Policy log std Max           0.010197997
Policy log std Min           -2.6425085
Z mean eval                  1.0893224
Z variance eval              0.07023732
total_rewards                [3747.97620227 3166.7738935  2617.47064851 3493.31616256  814.05153281
 4217.08303602  533.24016213 3832.66462513  298.63836348 3101.36059084]
total_rewards_mean           2582.2575217236044
total_rewards_std            1399.1929332396674
total_rewards_max            4217.083036021798
total_rewards_min            298.6383634787262
Number of train steps total  1460000
Number of env steps total    2373705
Number of rollouts total     0
Train Time (s)               191.62469143792987
(Previous) Eval Time (s)     19.421042295638472
Sample Time (s)              6.871582568157464
Epoch Time (s)               217.9173163017258
Total Train Time (s)         81132.14227580931
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:43:54.443093 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #364 | Epoch Duration: 218.01899766921997
2020-01-12 14:43:54.443234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0880988
Z variance train             0.070327334
KL Divergence                14.161745
KL Loss                      1.4161745
QF Loss                      664.34045
VF Loss                      125.06351
Policy Loss                  -1508.7362
Q Predictions Mean           1502.0359
Q Predictions Std            386.66742
Q Predictions Max            2120.853
Q Predictions Min            465.15897
V Predictions Mean           1504.315
V Predictions Std            386.54703
V Predictions Max            2109.1467
V Predictions Min            477.73434
Log Pis Mean                 1.201798
Log Pis Std                  3.1072824
Log Pis Max                  11.4080515
Log Pis Min                  -8.023298
Policy mu Mean               0.10230136
Policy mu Std                0.67750955
Policy mu Max                2.2841985
Policy mu Min                -2.475565
Policy log std Mean          -1.1345079
Policy log std Std           0.29186326
Policy log std Max           -0.23217237
Policy log std Min           -2.362679
Z mean eval                  0.95852005
Z variance eval              0.07735669
total_rewards                [1122.00916606 1570.08126729 1523.40855306 3370.21651575  407.73592579
 2890.99259815 4482.17682442 4324.8284703   565.73832317 4052.37990178]
total_rewards_mean           2430.956754576207
total_rewards_std            1495.5823347532087
total_rewards_max            4482.176824422545
total_rewards_min            407.7359257857244
Number of train steps total  1464000
Number of env steps total    2384458
Number of rollouts total     0
Train Time (s)               192.37389791291207
(Previous) Eval Time (s)     24.301822312176228
Sample Time (s)              6.816701625939459
Epoch Time (s)               223.49242185102776
Total Train Time (s)         81355.72948484542
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:47:38.034687 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #365 | Epoch Duration: 223.59133076667786
2020-01-12 14:47:38.034879 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96193
Z variance train             0.07734032
KL Divergence                13.567064
KL Loss                      1.3567065
QF Loss                      1118.7849
VF Loss                      179.05357
Policy Loss                  -1409.3466
Q Predictions Mean           1401.6335
Q Predictions Std            355.0916
Q Predictions Max            1968.2874
Q Predictions Min            411.40558
V Predictions Mean           1406.3718
V Predictions Std            355.94513
V Predictions Max            1927.5692
V Predictions Min            406.4691
Log Pis Mean                 1.4470011
Log Pis Std                  2.904815
Log Pis Max                  12.215115
Log Pis Min                  -8.820967
Policy mu Mean               0.08395219
Policy mu Std                0.6484718
Policy mu Max                2.2410083
Policy mu Min                -2.2706494
Policy log std Mean          -1.1492037
Policy log std Std           0.29291505
Policy log std Max           -0.05176902
Policy log std Min           -2.4806478
Z mean eval                  1.1393381
Z variance eval              0.08213075
total_rewards                [4665.66659597 3105.69925205 2246.78582861 4586.648871   2033.83909396
 4439.56708196 4184.76225476 2969.07880374 4805.29979271 4424.60885463]
total_rewards_mean           3746.19564293769
total_rewards_std            1000.0690038188399
total_rewards_max            4805.2997927065235
total_rewards_min            2033.8390939594071
Number of train steps total  1468000
Number of env steps total    2394377
Number of rollouts total     0
Train Time (s)               191.8883420843631
(Previous) Eval Time (s)     24.06349445786327
Sample Time (s)              7.052802748512477
Epoch Time (s)               223.00463929073885
Total Train Time (s)         81578.82444457337
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:51:21.132527 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #366 | Epoch Duration: 223.0975112915039
2020-01-12 14:51:21.132697 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1372435
Z variance train             0.08214834
KL Divergence                15.691517
KL Loss                      1.5691518
QF Loss                      1060.7909
VF Loss                      467.29416
Policy Loss                  -1480.6558
Q Predictions Mean           1471.7314
Q Predictions Std            377.8419
Q Predictions Max            2015.2507
Q Predictions Min            435.5975
V Predictions Mean           1478.3474
V Predictions Std            377.9864
V Predictions Max            2025.7557
V Predictions Min            429.06125
Log Pis Mean                 1.6084915
Log Pis Std                  3.0632887
Log Pis Max                  12.82319
Log Pis Min                  -7.0991936
Policy mu Mean               0.050033927
Policy mu Std                0.6933461
Policy mu Max                2.3830972
Policy mu Min                -2.4882803
Policy log std Mean          -1.151598
Policy log std Std           0.3013853
Policy log std Max           -0.21871734
Policy log std Min           -2.2314706
Z mean eval                  1.0086687
Z variance eval              0.057230674
total_rewards                [1877.03258876 4605.11831526 4374.27222319 2340.27793586 2324.24217437
 2964.22167391 2581.80707797 4389.41795419  671.60648448  463.6792715 ]
total_rewards_mean           2659.1675699498123
total_rewards_std            1393.459220940166
total_rewards_max            4605.118315261911
total_rewards_min            463.67927149648824
Number of train steps total  1472000
Number of env steps total    2403030
Number of rollouts total     0
Train Time (s)               192.5220665410161
(Previous) Eval Time (s)     21.804535589646548
Sample Time (s)              6.977850554976612
Epoch Time (s)               221.30445268563926
Total Train Time (s)         81800.21918751206
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:55:02.529402 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #367 | Epoch Duration: 221.3965766429901
2020-01-12 14:55:02.529544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0074531
Z variance train             0.057234682
KL Divergence                14.016961
KL Loss                      1.4016961
QF Loss                      535.1155
VF Loss                      145.36395
Policy Loss                  -1473.0367
Q Predictions Mean           1467.1838
Q Predictions Std            362.92078
Q Predictions Max            2013.0515
Q Predictions Min            403.49185
V Predictions Mean           1466.1573
V Predictions Std            361.59927
V Predictions Max            1999.7789
V Predictions Min            406.10764
Log Pis Mean                 1.6255679
Log Pis Std                  2.8705912
Log Pis Max                  12.5379505
Log Pis Min                  -4.9934087
Policy mu Mean               0.13645646
Policy mu Std                0.6321629
Policy mu Max                2.5550117
Policy mu Min                -2.419461
Policy log std Mean          -1.1724362
Policy log std Std           0.29679328
Policy log std Max           -0.35348415
Policy log std Min           -2.3390028
Z mean eval                  1.1968048
Z variance eval              0.06134569
total_rewards                [2301.16814849 2038.95554833 1663.33847205 1161.74920107 1429.61244022
 1047.63701353 4370.31614788 1586.70801413 1221.66063535 4521.45362712]
total_rewards_mean           2134.259924817482
total_rewards_std            1212.9738081972855
total_rewards_max            4521.4536271240095
total_rewards_min            1047.6370135261982
Number of train steps total  1476000
Number of env steps total    2415277
Number of rollouts total     0
Train Time (s)               191.39837449835613
(Previous) Eval Time (s)     17.956122128292918
Sample Time (s)              7.637097439263016
Epoch Time (s)               216.99159406591207
Total Train Time (s)         82017.30031756498
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:58:39.613993 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #368 | Epoch Duration: 217.0843391418457
2020-01-12 14:58:39.614137 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2032478
Z variance train             0.06148214
KL Divergence                14.607037
KL Loss                      1.4607037
QF Loss                      640.2456
VF Loss                      340.97192
Policy Loss                  -1380.0065
Q Predictions Mean           1376.0024
Q Predictions Std            442.1129
Q Predictions Max            2004.1572
Q Predictions Min            328.26883
V Predictions Mean           1387.4796
V Predictions Std            441.7885
V Predictions Max            1996.9967
V Predictions Min            363.457
Log Pis Mean                 1.4760573
Log Pis Std                  3.0157702
Log Pis Max                  20.41463
Log Pis Min                  -5.494934
Policy mu Mean               0.047007114
Policy mu Std                0.6839555
Policy mu Max                2.7106295
Policy mu Min                -2.577902
Policy log std Mean          -1.0889006
Policy log std Std           0.34192604
Policy log std Max           -0.04722798
Policy log std Min           -3.4963746
Z mean eval                  0.9312792
Z variance eval              0.026296044
total_rewards                [1098.25886972 1691.45832341  392.25357775  545.16037077 2551.80533663
 1249.19163112 1268.50310042 4090.84145368 2596.78210785 3127.16109485]
total_rewards_mean           1861.1415866187467
total_rewards_std            1132.1870163735132
total_rewards_max            4090.8414536796413
total_rewards_min            392.2535777455671
Number of train steps total  1480000
Number of env steps total    2426982
Number of rollouts total     0
Train Time (s)               192.60994566511363
(Previous) Eval Time (s)     17.370564700104296
Sample Time (s)              6.963540258351713
Epoch Time (s)               216.94405062356964
Total Train Time (s)         82234.33312708652
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:02:16.649433 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #369 | Epoch Duration: 217.0351905822754
2020-01-12 15:02:16.649574 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.929543
Z variance train             0.026424449
KL Divergence                15.757816
KL Loss                      1.5757817
QF Loss                      833.9044
VF Loss                      157.66603
Policy Loss                  -1421.6407
Q Predictions Mean           1413.5068
Q Predictions Std            423.102
Q Predictions Max            2023.4473
Q Predictions Min            379.26624
V Predictions Mean           1416.7776
V Predictions Std            421.1425
V Predictions Max            2005.0436
V Predictions Min            383.40277
Log Pis Mean                 1.3530018
Log Pis Std                  3.1070876
Log Pis Max                  11.496176
Log Pis Min                  -10.419608
Policy mu Mean               0.086823754
Policy mu Std                0.6548635
Policy mu Max                2.548922
Policy mu Min                -2.4291682
Policy log std Mean          -1.1373087
Policy log std Std           0.29427567
Policy log std Max           -0.31051803
Policy log std Min           -2.6089969
Z mean eval                  0.96185446
Z variance eval              0.43159008
total_rewards                [ 539.28420481  425.814368    500.08838983  139.92313837  137.72302655
  426.95029602  382.71720715 2880.58666932  852.44390387 1497.3554075 ]
total_rewards_mean           778.2886611421247
total_rewards_std            793.6447469906341
total_rewards_max            2880.5866693202406
total_rewards_min            137.72302654762967
Number of train steps total  1484000
Number of env steps total    2438297
Number of rollouts total     0
Train Time (s)               192.82420443138108
(Previous) Eval Time (s)     13.511486167088151
Sample Time (s)              7.5485910987481475
Epoch Time (s)               213.88428169721738
Total Train Time (s)         82448.31933958083
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:05:50.637995 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #370 | Epoch Duration: 213.98831272125244
2020-01-12 15:05:50.638139 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9656679
Z variance train             0.43713865
KL Divergence                15.837242
KL Loss                      1.5837243
QF Loss                      13863.818
VF Loss                      483.59427
Policy Loss                  -1140.2793
Q Predictions Mean           1133.1782
Q Predictions Std            347.9212
Q Predictions Max            1729.888
Q Predictions Min            -165.86766
V Predictions Mean           1134.0725
V Predictions Std            343.9726
V Predictions Max            1696.4777
V Predictions Min            1.7652497
Log Pis Mean                 1.6610022
Log Pis Std                  3.4854307
Log Pis Max                  26.468903
Log Pis Min                  -8.68657
Policy mu Mean               0.10618332
Policy mu Std                0.65855104
Policy mu Max                4.7935753
Policy mu Min                -3.907825
Policy log std Mean          -1.1946774
Policy log std Std           0.30857334
Policy log std Max           -0.36343646
Policy log std Min           -2.989119
Z mean eval                  1.0596162
Z variance eval              0.0583286
total_rewards                [ 466.79174932  424.60809981  937.5879275  1278.60010974 4914.64327392
  408.83918828  386.69070771 2909.40609476 4457.7936171   162.81191309]
total_rewards_mean           1634.7772681217798
total_rewards_std            1703.5428361378695
total_rewards_max            4914.643273923868
total_rewards_min            162.81191308513465
Number of train steps total  1488000
Number of env steps total    2450276
Number of rollouts total     0
Train Time (s)               190.89875197736546
(Previous) Eval Time (s)     23.222502117976546
Sample Time (s)              7.6334114242345095
Epoch Time (s)               221.75466551957652
Total Train Time (s)         82670.24715723284
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:09:32.571368 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #371 | Epoch Duration: 221.9331178665161
2020-01-12 15:09:32.571527 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0562954
Z variance train             0.058345713
KL Divergence                15.146297
KL Loss                      1.5146297
QF Loss                      654.0504
VF Loss                      107.129456
Policy Loss                  -1434.5878
Q Predictions Mean           1422.4988
Q Predictions Std            440.1216
Q Predictions Max            2003.4
Q Predictions Min            268.9477
V Predictions Mean           1435.8372
V Predictions Std            433.20258
V Predictions Max            2002.2625
V Predictions Min            350.4666
Log Pis Mean                 1.485278
Log Pis Std                  2.9581676
Log Pis Max                  10.205615
Log Pis Min                  -8.81397
Policy mu Mean               0.07384114
Policy mu Std                0.6789343
Policy mu Max                2.7328062
Policy mu Min                -2.4859266
Policy log std Mean          -1.121854
Policy log std Std           0.29494897
Policy log std Max           -0.25888252
Policy log std Min           -2.2732666
Z mean eval                  0.9998418
Z variance eval              0.42749533
total_rewards                [3017.03305284    9.08368826 1823.95813503  963.66110589 1018.99963573
 4510.86330562    7.19588119 2799.77268056 2992.10218203  651.02059738]
total_rewards_mean           1779.3690264526504
total_rewards_std            1424.7114018890495
total_rewards_max            4510.863305621664
total_rewards_min            7.195881188560569
Number of train steps total  1492000
Number of env steps total    2459949
Number of rollouts total     0
Train Time (s)               190.98767066001892
(Previous) Eval Time (s)     12.74348665960133
Sample Time (s)              8.07796260388568
Epoch Time (s)               211.80911992350593
Total Train Time (s)         82882.14724184154
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:13:04.475712 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #372 | Epoch Duration: 211.9040699005127
2020-01-12 15:13:04.475859 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9956573
Z variance train             0.42740554
KL Divergence                13.528099
KL Loss                      1.3528099
QF Loss                      674.8788
VF Loss                      214.26462
Policy Loss                  -1433.7418
Q Predictions Mean           1424.2458
Q Predictions Std            436.0029
Q Predictions Max            1986.3966
Q Predictions Min            109.02814
V Predictions Mean           1445.617
V Predictions Std            431.0335
V Predictions Max            1994.881
V Predictions Min            338.20596
Log Pis Mean                 1.2454507
Log Pis Std                  3.0004644
Log Pis Max                  9.092169
Log Pis Min                  -7.8820415
Policy mu Mean               0.09537247
Policy mu Std                0.66433656
Policy mu Max                3.9345436
Policy mu Min                -2.3145509
Policy log std Mean          -1.1121621
Policy log std Std           0.29001153
Policy log std Max           -0.10003507
Policy log std Min           -2.225453
Z mean eval                  0.96596134
Z variance eval              0.070443034
total_rewards                [4771.44758072 4814.05023099 4526.44503808 4306.55695388 4513.00738122
 1499.88047438  511.20620653 4579.31064599 4707.32926903 4630.89953549]
total_rewards_mean           3886.0133316307065
total_rewards_std            1463.5028930266024
total_rewards_max            4814.050230988479
total_rewards_min            511.20620653152866
Number of train steps total  1496000
Number of env steps total    2469156
Number of rollouts total     0
Train Time (s)               191.3414126522839
(Previous) Eval Time (s)     28.027102985884994
Sample Time (s)              7.151491872500628
Epoch Time (s)               226.52000751066953
Total Train Time (s)         83108.99163877452
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:16:51.322788 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #373 | Epoch Duration: 226.8468086719513
2020-01-12 15:16:51.322960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9649005
Z variance train             0.070446305
KL Divergence                14.360392
KL Loss                      1.4360392
QF Loss                      1409.5505
VF Loss                      2003.529
Policy Loss                  -1402.2162
Q Predictions Mean           1396.2205
Q Predictions Std            428.44644
Q Predictions Max            1963.7433
Q Predictions Min            159.65933
V Predictions Mean           1411.2639
V Predictions Std            426.27176
V Predictions Max            1964.8278
V Predictions Min            323.2872
Log Pis Mean                 1.1905391
Log Pis Std                  3.2592442
Log Pis Max                  13.126769
Log Pis Min                  -8.489618
Policy mu Mean               0.097525045
Policy mu Std                0.66785324
Policy mu Max                2.383643
Policy mu Min                -2.9005587
Policy log std Mean          -1.1072164
Policy log std Std           0.3235563
Policy log std Max           -0.2562282
Policy log std Min           -2.7734547
Z mean eval                  1.7505211
Z variance eval              0.01776963
total_rewards                [2309.45403887 3977.80548075 4592.46065006 4605.28358484 4865.07026251
 1791.72718473 4625.29729031 4640.68546553 3402.05633311  691.0215163 ]
total_rewards_mean           3550.0861806998864
total_rewards_std            1388.6956766140277
total_rewards_max            4865.07026251252
total_rewards_min            691.0215162974561
Number of train steps total  1500000
Number of env steps total    2478896
Number of rollouts total     0
Train Time (s)               191.34307635435835
(Previous) Eval Time (s)     25.77183589199558
Sample Time (s)              6.838379426859319
Epoch Time (s)               223.95329167321324
Total Train Time (s)         83333.03238387033
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:20:35.367319 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #374 | Epoch Duration: 224.04422640800476
2020-01-12 15:20:35.367526 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7474798
Z variance train             0.017846558
KL Divergence                20.4522
KL Loss                      2.0452201
QF Loss                      864.9454
VF Loss                      185.88145
Policy Loss                  -1405.9904
Q Predictions Mean           1398.5044
Q Predictions Std            448.1968
Q Predictions Max            2047.2483
Q Predictions Min            351.98267
V Predictions Mean           1408.2411
V Predictions Std            450.48444
V Predictions Max            2036.3701
V Predictions Min            360.77756
Log Pis Mean                 1.1901729
Log Pis Std                  3.4495947
Log Pis Max                  15.720144
Log Pis Min                  -9.012967
Policy mu Mean               0.08337734
Policy mu Std                0.6721254
Policy mu Max                2.3041785
Policy mu Min                -2.6328669
Policy log std Mean          -1.1014504
Policy log std Std           0.32610524
Policy log std Max           0.02159357
Policy log std Min           -3.1888957
Z mean eval                  0.91592807
Z variance eval              0.043661218
total_rewards                [4563.9511624  4708.31982319 4769.84932047 1570.69019844 3177.80187254
 2315.00705419 4882.78948851 5182.21658708 4810.24745844 1036.3336144 ]
total_rewards_mean           3701.72065796651
total_rewards_std            1468.2046870898776
total_rewards_max            5182.216587082291
total_rewards_min            1036.333614396446
Number of train steps total  1504000
Number of env steps total    2489230
Number of rollouts total     0
Train Time (s)               191.40734378434718
(Previous) Eval Time (s)     30.356316761579365
Sample Time (s)              7.227688261773437
Epoch Time (s)               228.99134880769998
Total Train Time (s)         83562.11581868352
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:24:24.453014 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #375 | Epoch Duration: 229.08535027503967
2020-01-12 15:24:24.453185 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9210817
Z variance train             0.04384993
KL Divergence                15.90345
KL Loss                      1.590345
QF Loss                      508.70386
VF Loss                      144.1592
Policy Loss                  -1398.9108
Q Predictions Mean           1391.3566
Q Predictions Std            425.26068
Q Predictions Max            1970.854
Q Predictions Min            329.50302
V Predictions Mean           1396.4543
V Predictions Std            420.3487
V Predictions Max            1955.546
V Predictions Min            336.39868
Log Pis Mean                 1.3122219
Log Pis Std                  3.0075963
Log Pis Max                  10.347193
Log Pis Min                  -8.87538
Policy mu Mean               0.1108298
Policy mu Std                0.59754777
Policy mu Max                2.2452486
Policy mu Min                -2.1442642
Policy log std Mean          -1.1690694
Policy log std Std           0.2880846
Policy log std Max           -0.44241774
Policy log std Min           -2.2375367
Z mean eval                  0.9184039
Z variance eval              0.08201433
total_rewards                [4776.90727277 1972.48699488 1631.72141709 4678.37343068 1836.98030306
 4314.55258399 4716.4854294  2050.61002424  877.14563076 2115.44037196]
total_rewards_mean           2897.0703458823036
total_rewards_std            1449.6083686122481
total_rewards_max            4776.90727276515
total_rewards_min            877.1456307559032
Number of train steps total  1508000
Number of env steps total    2501410
Number of rollouts total     0
Train Time (s)               190.68538721185178
(Previous) Eval Time (s)     22.740388243459165
Sample Time (s)              7.93213301198557
Epoch Time (s)               221.3579084672965
Total Train Time (s)         83783.57084614784
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:28:05.910212 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #376 | Epoch Duration: 221.45691561698914
2020-01-12 15:28:05.910355 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91923296
Z variance train             0.08181384
KL Divergence                14.644127
KL Loss                      1.4644127
QF Loss                      518.3375
VF Loss                      119.41142
Policy Loss                  -1371.9174
Q Predictions Mean           1362.4165
Q Predictions Std            429.63763
Q Predictions Max            1954.789
Q Predictions Min            337.43243
V Predictions Mean           1374.5415
V Predictions Std            429.70206
V Predictions Max            1942.0394
V Predictions Min            345.46863
Log Pis Mean                 0.99761784
Log Pis Std                  3.1924398
Log Pis Max                  13.703693
Log Pis Min                  -9.584118
Policy mu Mean               0.061903816
Policy mu Std                0.6812672
Policy mu Max                2.4358068
Policy mu Min                -3.3046699
Policy log std Mean          -1.0711529
Policy log std Std           0.32965326
Policy log std Max           -0.08891761
Policy log std Min           -2.584909
Z mean eval                  0.88015187
Z variance eval              0.26377064
total_rewards                [4886.93452106 4645.20702743 4954.49004539 1089.89834716  826.62298904
 1319.48660981 4196.63207231 4804.33047631 4938.73903904 1013.01256733]
total_rewards_mean           3267.535369488606
total_rewards_std            1815.5454762120637
total_rewards_max            4954.490045387146
total_rewards_min            826.6229890423665
Number of train steps total  1512000
Number of env steps total    2512762
Number of rollouts total     0
Train Time (s)               191.87772810598835
(Previous) Eval Time (s)     23.178101879078895
Sample Time (s)              7.920232094358653
Epoch Time (s)               222.9760620794259
Total Train Time (s)         84006.63638931233
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:31:48.978351 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #377 | Epoch Duration: 223.06788682937622
2020-01-12 15:31:48.978502 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8832197
Z variance train             0.26127058
KL Divergence                12.18335
KL Loss                      1.218335
QF Loss                      18750.46
VF Loss                      1181.4657
Policy Loss                  -1415.1887
Q Predictions Mean           1410.4
Q Predictions Std            395.50656
Q Predictions Max            1972.6738
Q Predictions Min            349.81296
V Predictions Mean           1420.6882
V Predictions Std            396.29773
V Predictions Max            1958.9121
V Predictions Min            351.86316
Log Pis Mean                 1.8068192
Log Pis Std                  3.4854236
Log Pis Max                  12.070314
Log Pis Min                  -8.736876
Policy mu Mean               0.08683101
Policy mu Std                0.70662177
Policy mu Max                2.6414278
Policy mu Min                -3.3622177
Policy log std Mean          -1.1432798
Policy log std Std           0.32575443
Policy log std Max           -0.18931043
Policy log std Min           -2.352203
Z mean eval                  0.897524
Z variance eval              0.16790678
total_rewards                [ 237.63201649 4877.73230538 4429.33615562 4823.96287411 2422.98114185
 4115.27488925 1285.65321631 4386.60994429 4967.58207071 4768.39823505]
total_rewards_mean           3631.516284906341
total_rewards_std            1611.6867597089933
total_rewards_max            4967.582070714616
total_rewards_min            237.6320164857714
Number of train steps total  1516000
Number of env steps total    2522785
Number of rollouts total     0
Train Time (s)               191.57642345968634
(Previous) Eval Time (s)     27.50366286514327
Sample Time (s)              7.991950777359307
Epoch Time (s)               227.07203710218892
Total Train Time (s)         84233.79951885715
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:35:36.149446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #378 | Epoch Duration: 227.1708219051361
2020-01-12 15:35:36.149658 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89620227
Z variance train             0.16755432
KL Divergence                10.6224
KL Loss                      1.06224
QF Loss                      658.1997
VF Loss                      296.60684
Policy Loss                  -1283.5433
Q Predictions Mean           1276.0223
Q Predictions Std            366.78247
Q Predictions Max            1835.6742
Q Predictions Min            294.5951
V Predictions Mean           1272.3679
V Predictions Std            366.0514
V Predictions Max            1795.7253
V Predictions Min            291.40857
Log Pis Mean                 1.7386937
Log Pis Std                  3.1985269
Log Pis Max                  12.781879
Log Pis Min                  -7.6733084
Policy mu Mean               0.064632066
Policy mu Std                0.67235833
Policy mu Max                2.5190468
Policy mu Min                -2.2954993
Policy log std Mean          -1.169344
Policy log std Std           0.32207015
Policy log std Max           -0.28234386
Policy log std Min           -2.4825253
Z mean eval                  0.874393
Z variance eval              0.032571774
total_rewards                [4781.6023638  4843.88320534  463.49604439 5053.61950584 4704.27826713
   62.25665019 5265.83787799  405.1826355  5012.17461709 5030.52644975]
total_rewards_mean           3562.285761702784
total_rewards_std            2136.292303723606
total_rewards_max            5265.837877986953
total_rewards_min            62.25665018986401
Number of train steps total  1520000
Number of env steps total    2533031
Number of rollouts total     0
Train Time (s)               193.1230907216668
(Previous) Eval Time (s)     27.118975083809346
Sample Time (s)              7.441752023994923
Epoch Time (s)               227.68381782947108
Total Train Time (s)         84461.57144324528
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:39:23.924094 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #379 | Epoch Duration: 227.77429962158203
2020-01-12 15:39:23.924246 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8736442
Z variance train             0.03235345
KL Divergence                16.651058
KL Loss                      1.6651058
QF Loss                      511.95868
VF Loss                      153.81114
Policy Loss                  -1372.7329
Q Predictions Mean           1364.3427
Q Predictions Std            415.37268
Q Predictions Max            1964.7031
Q Predictions Min            249.52484
V Predictions Mean           1366.3193
V Predictions Std            416.01672
V Predictions Max            1963.4529
V Predictions Min            272.23923
Log Pis Mean                 1.759604
Log Pis Std                  3.346461
Log Pis Max                  15.752968
Log Pis Min                  -7.115976
Policy mu Mean               0.07913457
Policy mu Std                0.6935871
Policy mu Max                2.3177373
Policy mu Min                -2.5736752
Policy log std Mean          -1.1393496
Policy log std Std           0.33499426
Policy log std Max           -0.28770924
Policy log std Min           -2.545392
Z mean eval                  0.967947
Z variance eval              0.25838068
total_rewards                [4541.15581666 4253.87947867 4502.94584639  103.41157502 5042.56054866
 4566.57363809  722.85870465 5125.44271443 4902.58229693 4791.07978157]
total_rewards_mean           3855.2490401068694
total_rewards_std            1744.6721314771098
total_rewards_max            5125.442714428289
total_rewards_min            103.4115750182035
Number of train steps total  1524000
Number of env steps total    2545044
Number of rollouts total     0
Train Time (s)               192.7826383379288
(Previous) Eval Time (s)     27.67081524292007
Sample Time (s)              18.523111808113754
Epoch Time (s)               238.97656538896263
Total Train Time (s)         84700.6343721808
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:43:22.989306 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #380 | Epoch Duration: 239.06495070457458
2020-01-12 15:43:22.989449 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9751809
Z variance train             0.2602458
KL Divergence                13.696405
KL Loss                      1.3696406
QF Loss                      441.89227
VF Loss                      205.62234
Policy Loss                  -1434.2383
Q Predictions Mean           1424.9896
Q Predictions Std            378.3964
Q Predictions Max            1977.501
Q Predictions Min            360.54767
V Predictions Mean           1424.6921
V Predictions Std            375.4842
V Predictions Max            1967.6932
V Predictions Min            361.5492
Log Pis Mean                 1.7201113
Log Pis Std                  2.9709606
Log Pis Max                  16.786139
Log Pis Min                  -5.334279
Policy mu Mean               0.07741242
Policy mu Std                0.662073
Policy mu Max                2.7640088
Policy mu Min                -2.0993223
Policy log std Mean          -1.1658975
Policy log std Std           0.31016263
Policy log std Max           -0.063337564
Policy log std Min           -2.5786552
Z mean eval                  1.0912161
Z variance eval              0.12809189
total_rewards                [4754.89720776  628.03203237 4874.76512522 2254.5195571   714.39918952
 4558.84053354 4639.39497768 4897.05441757  389.54874818 1420.60879115]
total_rewards_mean           2913.20605800851
total_rewards_std            1896.058234595349
total_rewards_max            4897.054417570411
total_rewards_min            389.54874818069277
Number of train steps total  1528000
Number of env steps total    2555729
Number of rollouts total     0
Train Time (s)               190.14616851182655
(Previous) Eval Time (s)     20.641733886674047
Sample Time (s)              7.103428389877081
Epoch Time (s)               217.89133078837767
Total Train Time (s)         84918.61409646831
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:47:00.971437 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #381 | Epoch Duration: 217.98186111450195
2020-01-12 15:47:00.971587 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0903857
Z variance train             0.12772563
KL Divergence                14.857626
KL Loss                      1.4857626
QF Loss                      602.6268
VF Loss                      201.02338
Policy Loss                  -1480.3706
Q Predictions Mean           1469.2986
Q Predictions Std            385.96454
Q Predictions Max            2028.5942
Q Predictions Min            379.92456
V Predictions Mean           1473.0167
V Predictions Std            384.93503
V Predictions Max            2020.2623
V Predictions Min            367.5101
Log Pis Mean                 1.810659
Log Pis Std                  3.5768943
Log Pis Max                  25.97344
Log Pis Min                  -6.573939
Policy mu Mean               0.12295103
Policy mu Std                0.68391275
Policy mu Max                3.9455376
Policy mu Min                -4.5633163
Policy log std Mean          -1.1748234
Policy log std Std           0.30995324
Policy log std Max           -0.061798096
Policy log std Min           -2.7793665
Z mean eval                  0.94338846
Z variance eval              0.03469203
total_rewards                [2860.65153628 5122.4091326  4925.16604961 5072.2869299  1855.39281578
  695.88410587 1813.78969529 4908.09861628 4810.14268558 1195.33110079]
total_rewards_mean           3325.9152667989206
total_rewards_std            1722.2928206804115
total_rewards_max            5122.409132599099
total_rewards_min            695.8841058745451
Number of train steps total  1532000
Number of env steps total    2567035
Number of rollouts total     0
Train Time (s)               194.40072158211842
(Previous) Eval Time (s)     24.203677435871214
Sample Time (s)              6.842719689942896
Epoch Time (s)               225.44711870793253
Total Train Time (s)         85144.14629737288
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:50:46.506053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #382 | Epoch Duration: 225.5343565940857
2020-01-12 15:50:46.506201 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.944437
Z variance train             0.034389727
KL Divergence                14.892692
KL Loss                      1.4892691
QF Loss                      16545.746
VF Loss                      221.14851
Policy Loss                  -1415.1713
Q Predictions Mean           1404.2922
Q Predictions Std            403.5161
Q Predictions Max            1996.3097
Q Predictions Min            72.773994
V Predictions Mean           1413.7996
V Predictions Std            406.45486
V Predictions Max            1983.8306
V Predictions Min            -112.12484
Log Pis Mean                 1.7539538
Log Pis Std                  3.7263653
Log Pis Max                  21.533012
Log Pis Min                  -7.67724
Policy mu Mean               0.11560868
Policy mu Std                0.7282277
Policy mu Max                3.6259146
Policy mu Min                -3.7721744
Policy log std Mean          -1.1396899
Policy log std Std           0.3146746
Policy log std Max           0.5938039
Policy log std Min           -2.9285688
Z mean eval                  1.0694679
Z variance eval              0.020846058
total_rewards                [4723.03026204 5070.34220339 4836.78174673  926.27408262  977.64753703
 1332.61397145 4623.70511089 1197.21775925 4702.97634627 1591.59455154]
total_rewards_mean           2998.2183571211763
total_rewards_std            1804.701826802257
total_rewards_max            5070.342203390032
total_rewards_min            926.2740826211614
Number of train steps total  1536000
Number of env steps total    2579541
Number of rollouts total     0
Train Time (s)               193.22052027797326
(Previous) Eval Time (s)     26.372129891067743
Sample Time (s)              8.376242471393198
Epoch Time (s)               227.9688926404342
Total Train Time (s)         85372.20728270477
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:54:34.569612 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #383 | Epoch Duration: 228.06330132484436
2020-01-12 15:54:34.569762 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0657326
Z variance train             0.020913845
KL Divergence                15.728201
KL Loss                      1.5728201
QF Loss                      1876.4641
VF Loss                      160.26808
Policy Loss                  -1443.8114
Q Predictions Mean           1436.5874
Q Predictions Std            375.39426
Q Predictions Max            1991.581
Q Predictions Min            -228.3243
V Predictions Mean           1449.8833
V Predictions Std            372.87854
V Predictions Max            1998.078
V Predictions Min            -50.10498
Log Pis Mean                 1.4605606
Log Pis Std                  3.682495
Log Pis Max                  31.025253
Log Pis Min                  -8.219395
Policy mu Mean               0.14469127
Policy mu Std                0.70119923
Policy mu Max                3.1245863
Policy mu Min                -4.173765
Policy log std Mean          -1.12187
Policy log std Std           0.31041503
Policy log std Max           -0.08170235
Policy log std Min           -3.9190657
Z mean eval                  1.212111
Z variance eval              0.042921018
total_rewards                [  23.74225455 5071.03070588 1568.33690442 4607.73682231  908.71152718
 2477.90821434   92.54313609 1993.71910747 4072.07117277  185.80275909]
total_rewards_mean           2100.1602604090526
total_rewards_std            1812.888754482323
total_rewards_max            5071.030705876316
total_rewards_min            23.742254547856163
Number of train steps total  1540000
Number of env steps total    2588265
Number of rollouts total     0
Train Time (s)               192.64124985598028
(Previous) Eval Time (s)     15.442184607032686
Sample Time (s)              7.103134226985276
Epoch Time (s)               215.18656868999824
Total Train Time (s)         85587.49917015014
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:58:09.868018 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #384 | Epoch Duration: 215.29811787605286
2020-01-12 15:58:09.868240 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2121422
Z variance train             0.04284794
KL Divergence                14.824123
KL Loss                      1.4824123
QF Loss                      950.21313
VF Loss                      102.40807
Policy Loss                  -1435.1108
Q Predictions Mean           1427.8875
Q Predictions Std            399.4631
Q Predictions Max            1968.3789
Q Predictions Min            372.3942
V Predictions Mean           1431.0939
V Predictions Std            397.93262
V Predictions Max            1965.7722
V Predictions Min            374.70416
Log Pis Mean                 1.4762249
Log Pis Std                  3.054519
Log Pis Max                  11.461573
Log Pis Min                  -6.1202745
Policy mu Mean               0.08787722
Policy mu Std                0.66778743
Policy mu Max                2.7796397
Policy mu Min                -2.9528313
Policy log std Mean          -1.1589922
Policy log std Std           0.30054542
Policy log std Max           -0.36466634
Policy log std Min           -2.5554528
Z mean eval                  0.9547542
Z variance eval              0.020956505
total_rewards                [4948.03993013   81.76255928 2234.90766229 5253.1851628  5166.42847385
 5088.20305072 4714.73004311 1578.98077958  191.88305894 2396.568827  ]
total_rewards_mean           3165.468954770008
total_rewards_std            1999.065487599822
total_rewards_max            5253.18516280469
total_rewards_min            81.76255927514126
Number of train steps total  1544000
Number of env steps total    2600027
Number of rollouts total     0
Train Time (s)               197.87693832162768
(Previous) Eval Time (s)     31.80638459371403
Sample Time (s)              7.620447928085923
Epoch Time (s)               237.30377084342763
Total Train Time (s)         85824.88805799419
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:02:07.261039 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #385 | Epoch Duration: 237.3926498889923
2020-01-12 16:02:07.261221 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9554558
Z variance train             0.021065066
KL Divergence                16.032436
KL Loss                      1.6032437
QF Loss                      579.5276
VF Loss                      310.02673
Policy Loss                  -1453.0524
Q Predictions Mean           1445.2356
Q Predictions Std            395.7386
Q Predictions Max            2040.6252
Q Predictions Min            380.75165
V Predictions Mean           1446.4954
V Predictions Std            394.58276
V Predictions Max            2023.0035
V Predictions Min            388.59427
Log Pis Mean                 1.6206628
Log Pis Std                  3.2318923
Log Pis Max                  16.11296
Log Pis Min                  -6.777271
Policy mu Mean               0.108127296
Policy mu Std                0.6549234
Policy mu Max                2.6769125
Policy mu Min                -2.4515636
Policy log std Mean          -1.1600096
Policy log std Std           0.3324109
Policy log std Max           -0.40783298
Policy log std Min           -3.2403913
Z mean eval                  0.8590204
Z variance eval              0.03978718
total_rewards                [4639.77474699 5073.04085228 4724.76036593 4843.02581305  438.35182174
 4664.09001903 4753.28546403 4668.10836414 4646.14159192 4990.11856443]
total_rewards_mean           4344.069760355154
total_rewards_std            1309.6126645404258
total_rewards_max            5073.040852282489
total_rewards_min            438.35182173637656
Number of train steps total  1548000
Number of env steps total    2608817
Number of rollouts total     0
Train Time (s)               209.5225139479153
(Previous) Eval Time (s)     39.28507107403129
Sample Time (s)              11.736136950086802
Epoch Time (s)               260.5437219720334
Total Train Time (s)         86085.51555228373
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:06:27.891383 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #386 | Epoch Duration: 260.63003373146057
2020-01-12 16:06:27.891524 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8517563
Z variance train             0.040028743
KL Divergence                14.8321085
KL Loss                      1.4832109
QF Loss                      589.3977
VF Loss                      145.64566
Policy Loss                  -1405.0123
Q Predictions Mean           1399.0154
Q Predictions Std            380.25394
Q Predictions Max            1981.6074
Q Predictions Min            372.67014
V Predictions Mean           1410.6401
V Predictions Std            382.5032
V Predictions Max            1985.4738
V Predictions Min            377.28134
Log Pis Mean                 1.1937023
Log Pis Std                  3.195239
Log Pis Max                  10.405939
Log Pis Min                  -10.085156
Policy mu Mean               0.13264439
Policy mu Std                0.66726977
Policy mu Max                2.7788906
Policy mu Min                -2.3332732
Policy log std Mean          -1.1243712
Policy log std Std           0.32442352
Policy log std Max           -0.13554001
Policy log std Min           -2.562132
Z mean eval                  1.0171161
Z variance eval              0.0447175
total_rewards                [4809.45875907 4760.0509462  5224.70232094 5159.95871334 1559.82057766
  513.59861002 4862.41705279 1091.15607619 5092.92777426 5021.72622534]
total_rewards_mean           3809.5817055794323
total_rewards_std            1823.9718105577808
total_rewards_max            5224.702320936969
total_rewards_min            513.5986100163076
Number of train steps total  1552000
Number of env steps total    2618448
Number of rollouts total     0
Train Time (s)               210.22666461812332
(Previous) Eval Time (s)     36.5291432980448
Sample Time (s)              9.899062099866569
Epoch Time (s)               256.6548700160347
Total Train Time (s)         86342.28687512595
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:10:44.666753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #387 | Epoch Duration: 256.7751076221466
2020-01-12 16:10:44.666954 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.017543
Z variance train             0.044617657
KL Divergence                13.902449
KL Loss                      1.3902448
QF Loss                      518.5054
VF Loss                      132.16748
Policy Loss                  -1459.7838
Q Predictions Mean           1451.6526
Q Predictions Std            375.03757
Q Predictions Max            1970.425
Q Predictions Min            349.19986
V Predictions Mean           1463.0247
V Predictions Std            375.02893
V Predictions Max            1958.9116
V Predictions Min            360.3623
Log Pis Mean                 2.0005965
Log Pis Std                  2.9869373
Log Pis Max                  11.70216
Log Pis Min                  -7.7526608
Policy mu Mean               0.09726017
Policy mu Std                0.7148545
Policy mu Max                2.7425764
Policy mu Min                -2.3379252
Policy log std Mean          -1.1503798
Policy log std Std           0.3253636
Policy log std Max           -0.103673816
Policy log std Min           -2.42309
Z mean eval                  0.92477787
Z variance eval              0.05922842
total_rewards                [1580.15859899  240.24414443  882.87095258 3161.14665345 1986.54836271
 1477.41619869  954.16379428 1329.64956278 1274.5295236  4703.89010855]
total_rewards_mean           1759.0617900070658
total_rewards_std            1222.3944170075047
total_rewards_max            4703.89010854985
total_rewards_min            240.24414443406437
Number of train steps total  1556000
Number of env steps total    2629059
Number of rollouts total     0
Train Time (s)               210.9743534210138
(Previous) Eval Time (s)     24.414131911005825
Sample Time (s)              10.19482587557286
Epoch Time (s)               245.5833112075925
Total Train Time (s)         86588.10274577979
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:14:50.487349 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #388 | Epoch Duration: 245.82024693489075
2020-01-12 16:14:50.487534 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9262761
Z variance train             0.059426617
KL Divergence                12.888693
KL Loss                      1.2888693
QF Loss                      607.2881
VF Loss                      226.83301
Policy Loss                  -1362.5682
Q Predictions Mean           1355.1139
Q Predictions Std            422.6353
Q Predictions Max            1950.5175
Q Predictions Min            364.7252
V Predictions Mean           1358.4451
V Predictions Std            419.1368
V Predictions Max            1936.8263
V Predictions Min            360.24298
Log Pis Mean                 0.9638554
Log Pis Std                  3.1020362
Log Pis Max                  11.071003
Log Pis Min                  -6.994441
Policy mu Mean               0.16066271
Policy mu Std                0.63875943
Policy mu Max                2.8518822
Policy mu Min                -2.6864908
Policy log std Mean          -1.1002502
Policy log std Std           0.3088435
Policy log std Max           -0.20969844
Policy log std Min           -2.4520583
Z mean eval                  0.88593006
Z variance eval              0.1329545
total_rewards                [3595.81124809 5000.77827014 5178.37619818 1159.31008883 5209.37012461
 5101.33532466 4975.96827145 4995.69541043 5009.70182056 5021.8684151 ]
total_rewards_mean           4524.821517204686
total_rewards_std            1206.3080417895035
total_rewards_max            5209.370124609059
total_rewards_min            1159.3100888326906
Number of train steps total  1560000
Number of env steps total    2641059
Number of rollouts total     0
Train Time (s)               213.01446747593582
(Previous) Eval Time (s)     39.11375277303159
Sample Time (s)              8.318360947538167
Epoch Time (s)               260.4465811965056
Total Train Time (s)         86848.64554033894
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:19:11.065378 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #389 | Epoch Duration: 260.57768177986145
2020-01-12 16:19:11.065639 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8765628
Z variance train             0.13408361
KL Divergence                11.356043
KL Loss                      1.1356043
QF Loss                      818.22144
VF Loss                      168.62915
Policy Loss                  -1405.942
Q Predictions Mean           1392.1462
Q Predictions Std            415.10446
Q Predictions Max            1969.258
Q Predictions Min            4.955119
V Predictions Mean           1411.887
V Predictions Std            405.25684
V Predictions Max            1950.8705
V Predictions Min            359.8007
Log Pis Mean                 2.1693132
Log Pis Std                  3.601739
Log Pis Max                  18.387169
Log Pis Min                  -7.9726076
Policy mu Mean               0.08573309
Policy mu Std                0.70898175
Policy mu Max                3.2826436
Policy mu Min                -2.8041968
Policy log std Mean          -1.173727
Policy log std Std           0.34232074
Policy log std Max           -0.24541998
Policy log std Min           -2.4207299
Z mean eval                  0.8985122
Z variance eval              0.396367
total_rewards                [ 319.54992985 1079.84293943 1677.76948674 4991.08169893 5121.18760197
 5019.47903234 1833.65471743 4983.5638139  1682.72375352  160.93010892]
total_rewards_mean           2686.9783083037105
total_rewards_std            1981.7377088271037
total_rewards_max            5121.187601969934
total_rewards_min            160.93010892428904
Number of train steps total  1564000
Number of env steps total    2653146
Number of rollouts total     0
Train Time (s)               210.15352705912665
(Previous) Eval Time (s)     33.73565061716363
Sample Time (s)              10.063279026187956
Epoch Time (s)               253.95245670247823
Total Train Time (s)         87102.85453363415
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:23:25.275917 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #390 | Epoch Duration: 254.2100851535797
2020-01-12 16:23:25.276145 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90251935
Z variance train             0.39535302
KL Divergence                10.216501
KL Loss                      1.0216502
QF Loss                      526.01575
VF Loss                      129.87268
Policy Loss                  -1410.6783
Q Predictions Mean           1404.3958
Q Predictions Std            395.83084
Q Predictions Max            1960.3677
Q Predictions Min            345.8043
V Predictions Mean           1415.8052
V Predictions Std            394.72137
V Predictions Max            1957.7928
V Predictions Min            357.5616
Log Pis Mean                 1.6563723
Log Pis Std                  3.1044204
Log Pis Max                  11.973169
Log Pis Min                  -8.097829
Policy mu Mean               0.095358714
Policy mu Std                0.6378093
Policy mu Max                2.3624175
Policy mu Min                -2.545426
Policy log std Mean          -1.1972816
Policy log std Std           0.32911602
Policy log std Max           -0.25470948
Policy log std Min           -2.671099
Z mean eval                  0.924558
Z variance eval              0.07943496
total_rewards                [4900.56281697 4834.70217182 5295.29645394 5006.01274547 2717.43341625
 5061.09941342 4212.23202625  328.4988638   368.7133348  5149.95624206]
total_rewards_mean           3787.4507484772316
total_rewards_std            1858.7721227710533
total_rewards_max            5295.296453938623
total_rewards_min            328.4988637960343
Number of train steps total  1568000
Number of env steps total    2665147
Number of rollouts total     0
Train Time (s)               215.61307109799236
(Previous) Eval Time (s)     39.789495090954006
Sample Time (s)              9.428638853132725
Epoch Time (s)               264.8312050420791
Total Train Time (s)         87367.7738531814
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:50.202124 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #391 | Epoch Duration: 264.9258191585541
2020-01-12 16:27:50.202342 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9234663
Z variance train             0.079067096
KL Divergence                13.21904
KL Loss                      1.3219041
QF Loss                      467.63495
VF Loss                      97.21223
Policy Loss                  -1431.5588
Q Predictions Mean           1424.7378
Q Predictions Std            401.92188
Q Predictions Max            1987.1274
Q Predictions Min            340.1388
V Predictions Mean           1435.4722
V Predictions Std            402.05298
V Predictions Max            2012.7472
V Predictions Min            347.41873
Log Pis Mean                 1.5643471
Log Pis Std                  3.0710864
Log Pis Max                  10.495043
Log Pis Min                  -9.171139
Policy mu Mean               0.09293868
Policy mu Std                0.66868216
Policy mu Max                2.5933433
Policy mu Min                -2.6117842
Policy log std Mean          -1.1255829
Policy log std Std           0.31935143
Policy log std Max           -0.1932081
Policy log std Min           -2.610558
Z mean eval                  0.93039465
Z variance eval              0.06334006
total_rewards                [3927.85336539  834.11397845 1392.64025848 4772.60780802  857.02248796
 5084.99855043 4953.96011622 3310.96392207 4885.65699261  643.4716186 ]
total_rewards_mean           3066.32890982425
total_rewards_std            1822.0011316700684
total_rewards_max            5084.998550433626
total_rewards_min            643.4716185984513
Number of train steps total  1572000
Number of env steps total    2675716
Number of rollouts total     0
Train Time (s)               215.49869164219126
(Previous) Eval Time (s)     31.813187344931066
Sample Time (s)              9.99643738148734
Epoch Time (s)               257.30831636860967
Total Train Time (s)         87625.24355498701
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:32:07.678089 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #392 | Epoch Duration: 257.47556161880493
2020-01-12 16:32:07.678349 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9315999
Z variance train             0.06300713
KL Divergence                13.223024
KL Loss                      1.3223025
QF Loss                      1639.2018
VF Loss                      145.6351
Policy Loss                  -1498.173
Q Predictions Mean           1489.228
Q Predictions Std            363.73334
Q Predictions Max            2012.1997
Q Predictions Min            348.87125
V Predictions Mean           1495.8816
V Predictions Std            360.276
V Predictions Max            2017.9514
V Predictions Min            351.5511
Log Pis Mean                 1.2522334
Log Pis Std                  3.1344883
Log Pis Max                  12.076688
Log Pis Min                  -7.3910146
Policy mu Mean               0.124080345
Policy mu Std                0.66000545
Policy mu Max                2.8207138
Policy mu Min                -2.918925
Policy log std Mean          -1.145529
Policy log std Std           0.31721446
Policy log std Max           -0.2337029
Policy log std Min           -2.5195193
Z mean eval                  0.79201806
Z variance eval              0.04557332
total_rewards                [5175.74180688 5293.05507811 5095.49699161 1350.91396817 3749.91598152
 5059.17523295 3060.92843824 5153.37903462 4958.5231007  5182.90731735]
total_rewards_mean           4408.00369501483
total_rewards_std            1237.8218605560683
total_rewards_max            5293.055078111405
total_rewards_min            1350.9139681702563
Number of train steps total  1576000
Number of env steps total    2685999
Number of rollouts total     0
Train Time (s)               216.3373365481384
(Previous) Eval Time (s)     38.37380296597257
Sample Time (s)              11.996310531627387
Epoch Time (s)               266.70745004573837
Total Train Time (s)         87892.03711169306
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:36:34.474896 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #393 | Epoch Duration: 266.79634499549866
2020-01-12 16:36:34.475082 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79170614
Z variance train             0.04559401
KL Divergence                14.146858
KL Loss                      1.4146858
QF Loss                      1272.63
VF Loss                      123.93464
Policy Loss                  -1432.135
Q Predictions Mean           1418.5836
Q Predictions Std            415.896
Q Predictions Max            1988.58
Q Predictions Min            343.59802
V Predictions Mean           1435.5369
V Predictions Std            414.27435
V Predictions Max            1990.6306
V Predictions Min            347.80823
Log Pis Mean                 1.4515035
Log Pis Std                  3.0743358
Log Pis Max                  10.14571
Log Pis Min                  -10.399664
Policy mu Mean               0.12528986
Policy mu Std                0.65041316
Policy mu Max                2.854613
Policy mu Min                -2.6537657
Policy log std Mean          -1.1494893
Policy log std Std           0.32593033
Policy log std Max           0.02185285
Policy log std Min           -2.586273
Z mean eval                  0.9550727
Z variance eval              0.09847565
total_rewards                [ 779.7922605  2124.89323189 1962.0915925   712.86218033 4620.75365791
 3990.59360181 3256.91209473 4862.17387499 3004.70963533 4896.8880812 ]
total_rewards_mean           3021.167021118229
total_rewards_std            1507.9432066471056
total_rewards_max            4896.888081196521
total_rewards_min            712.8621803296928
Number of train steps total  1580000
Number of env steps total    2698108
Number of rollouts total     0
Train Time (s)               211.5636215461418
(Previous) Eval Time (s)     27.568244784604758
Sample Time (s)              10.609820540063083
Epoch Time (s)               249.74168687080964
Total Train Time (s)         88141.86617404968
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:40:44.307901 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #394 | Epoch Duration: 249.83268189430237
2020-01-12 16:40:44.308098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9555646
Z variance train             0.09832829
KL Divergence                12.765958
KL Loss                      1.2765958
QF Loss                      807.92737
VF Loss                      539.49585
Policy Loss                  -1442.4686
Q Predictions Mean           1438.1045
Q Predictions Std            396.23233
Q Predictions Max            1996.5006
Q Predictions Min            305.77634
V Predictions Mean           1462.469
V Predictions Std            395.3263
V Predictions Max            2026.4218
V Predictions Min            343.6593
Log Pis Mean                 1.5114739
Log Pis Std                  3.128525
Log Pis Max                  10.954291
Log Pis Min                  -8.657984
Policy mu Mean               0.08939929
Policy mu Std                0.6372563
Policy mu Max                2.5999124
Policy mu Min                -2.4932847
Policy log std Mean          -1.2075005
Policy log std Std           0.32071492
Policy log std Max           -0.26473594
Policy log std Min           -2.5715456
Z mean eval                  1.149925
Z variance eval              0.04791003
total_rewards                [2943.02797666 1914.04885801  557.41080733  873.03805572 4835.05274444
 2570.64473188 4543.72958434 5194.26105781 4729.34801494  187.62033085]
total_rewards_mean           2834.818216197563
total_rewards_std            1817.9567006539892
total_rewards_max            5194.261057805441
total_rewards_min            187.62033085300143
Number of train steps total  1584000
Number of env steps total    2708473
Number of rollouts total     0
Train Time (s)               213.3044247785583
(Previous) Eval Time (s)     34.05710174376145
Sample Time (s)              9.003564045764506
Epoch Time (s)               256.36509056808427
Total Train Time (s)         88398.33914300567
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:45:00.785830 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #395 | Epoch Duration: 256.4775695800781
2020-01-12 16:45:00.786052 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.145931
Z variance train             0.04803268
KL Divergence                14.570045
KL Loss                      1.4570045
QF Loss                      602.386
VF Loss                      368.22977
Policy Loss                  -1407.4283
Q Predictions Mean           1397.1545
Q Predictions Std            407.24368
Q Predictions Max            1981.9596
Q Predictions Min            322.53854
V Predictions Mean           1391.7925
V Predictions Std            405.31326
V Predictions Max            1956.8911
V Predictions Min            320.4617
Log Pis Mean                 1.5593175
Log Pis Std                  3.112558
Log Pis Max                  10.774813
Log Pis Min                  -6.9919214
Policy mu Mean               0.07438339
Policy mu Std                0.66668355
Policy mu Max                2.3930423
Policy mu Min                -2.339067
Policy log std Mean          -1.1547751
Policy log std Std           0.33416423
Policy log std Max           -0.32427692
Policy log std Min           -2.6095295
Z mean eval                  0.90009385
Z variance eval              0.09291114
total_rewards                [4552.0390338  5199.79951375 1054.00077438 4170.66715898 5049.42837984
 5028.40798213 5093.34337418 4170.31750279 1932.33830687 5032.20401352]
total_rewards_mean           4128.254604023898
total_rewards_std            1378.8333090177232
total_rewards_max            5199.799513754892
total_rewards_min            1054.0007743765077
Number of train steps total  1588000
Number of env steps total    2719830
Number of rollouts total     0
Train Time (s)               212.57710103318095
(Previous) Eval Time (s)     38.54812631336972
Sample Time (s)              8.616278051864356
Epoch Time (s)               259.74150539841503
Total Train Time (s)         88658.23606079305
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:49:20.691057 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #396 | Epoch Duration: 259.9048001766205
2020-01-12 16:49:20.691369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89974415
Z variance train             0.09174095
KL Divergence                11.5923
KL Loss                      1.1592301
QF Loss                      380.16623
VF Loss                      103.32207
Policy Loss                  -1544.5691
Q Predictions Mean           1537.9792
Q Predictions Std            311.06165
Q Predictions Max            2021.649
Q Predictions Min            340.7989
V Predictions Mean           1551.3779
V Predictions Std            310.06528
V Predictions Max            2009.3644
V Predictions Min            355.42978
Log Pis Mean                 1.9147177
Log Pis Std                  2.863199
Log Pis Max                  11.732319
Log Pis Min                  -5.568814
Policy mu Mean               0.09937158
Policy mu Std                0.6969309
Policy mu Max                2.7260034
Policy mu Min                -3.023262
Policy log std Mean          -1.1618396
Policy log std Std           0.31621662
Policy log std Max           -0.13043272
Policy log std Min           -2.732898
Z mean eval                  0.9432516
Z variance eval              0.026885945
total_rewards                [ 142.64213028 5141.21697509 4690.52283976  385.70490993 2392.33644231
  777.05441761 4740.32470912 4654.81545581  329.68583418 2418.99156199]
total_rewards_mean           2567.3295276074323
total_rewards_std            1977.7691457733167
total_rewards_max            5141.216975089579
total_rewards_min            142.6421302756685
Number of train steps total  1592000
Number of env steps total    2731067
Number of rollouts total     0
Train Time (s)               210.0766116939485
(Previous) Eval Time (s)     25.059641003143042
Sample Time (s)              9.936463600955904
Epoch Time (s)               245.07271629804745
Total Train Time (s)         88903.41593911499
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:53:25.876389 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #397 | Epoch Duration: 245.18479776382446
2020-01-12 16:53:25.876570 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.946112
Z variance train             0.02705788
KL Divergence                15.74005
KL Loss                      1.574005
QF Loss                      1510.2019
VF Loss                      181.95839
Policy Loss                  -1474.6768
Q Predictions Mean           1466.742
Q Predictions Std            410.07678
Q Predictions Max            2012.957
Q Predictions Min            68.64862
V Predictions Mean           1464.6406
V Predictions Std            410.0253
V Predictions Max            2004.7393
V Predictions Min            15.963173
Log Pis Mean                 1.3934405
Log Pis Std                  2.977786
Log Pis Max                  19.224686
Log Pis Min                  -7.4761524
Policy mu Mean               0.107526824
Policy mu Std                0.6632579
Policy mu Max                2.855272
Policy mu Min                -2.1010866
Policy log std Mean          -1.1317546
Policy log std Std           0.33678806
Policy log std Max           -0.11953533
Policy log std Min           -3.4820094
Z mean eval                  0.904267
Z variance eval              0.028025934
total_rewards                [4811.0819753  4591.58761215 4749.01603579 4796.02329481 5107.20240462
 2787.55178066  432.77753477 5127.65529913 4598.50760458 5443.54322202]
total_rewards_mean           4244.494676382931
total_rewards_std            1440.1170209218496
total_rewards_max            5443.543222016741
total_rewards_min            432.7775347712327
Number of train steps total  1596000
Number of env steps total    2743411
Number of rollouts total     0
Train Time (s)               213.15786947030574
(Previous) Eval Time (s)     43.46438070200384
Sample Time (s)              11.158162841573358
Epoch Time (s)               267.78041301388294
Total Train Time (s)         89171.29560005292
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:57:53.765467 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #398 | Epoch Duration: 267.88874530792236
2020-01-12 16:57:53.765708 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90322226
Z variance train             0.027784992
KL Divergence                15.948944
KL Loss                      1.5948944
QF Loss                      823.30444
VF Loss                      83.67596
Policy Loss                  -1497.5492
Q Predictions Mean           1490.3164
Q Predictions Std            371.3835
Q Predictions Max            2040.9188
Q Predictions Min            325.36475
V Predictions Mean           1501.341
V Predictions Std            370.82068
V Predictions Max            2020.1157
V Predictions Min            324.24997
Log Pis Mean                 1.4991038
Log Pis Std                  2.8320446
Log Pis Max                  10.857112
Log Pis Min                  -10.709217
Policy mu Mean               0.106885
Policy mu Std                0.67456174
Policy mu Max                2.651316
Policy mu Min                -2.2915335
Policy log std Mean          -1.1178908
Policy log std Std           0.30797338
Policy log std Max           -0.2801261
Policy log std Min           -2.6429079
Z mean eval                  0.9534993
Z variance eval              0.23873572
total_rewards                [5161.86031493 5234.56247873 5266.78668173 2244.40131967 5053.6955967
 4911.8471942  1584.46781634 4818.57195854 4920.31514266 4937.44502019]
total_rewards_mean           4413.395352368873
total_rewards_std            1265.873634312272
total_rewards_max            5266.786681734333
total_rewards_min            1584.467816338727
Number of train steps total  1600000
Number of env steps total    2753085
Number of rollouts total     0
Train Time (s)               212.474938291125
(Previous) Eval Time (s)     41.45514067122713
Sample Time (s)              10.0018704184331
Epoch Time (s)               263.9319493807852
Total Train Time (s)         89435.31892134435
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:02:17.791644 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #399 | Epoch Duration: 264.02577471733093
2020-01-12 17:02:17.791812 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9533941
Z variance train             0.23723897
KL Divergence                10.362501
KL Loss                      1.0362501
QF Loss                      563.8552
VF Loss                      106.86221
Policy Loss                  -1468.8691
Q Predictions Mean           1462.09
Q Predictions Std            376.64963
Q Predictions Max            1987.6614
Q Predictions Min            306.73627
V Predictions Mean           1467.2056
V Predictions Std            376.78607
V Predictions Max            1951.6814
V Predictions Min            294.17346
Log Pis Mean                 1.4090389
Log Pis Std                  3.4725838
Log Pis Max                  12.502274
Log Pis Min                  -9.588588
Policy mu Mean               0.086646676
Policy mu Std                0.66701895
Policy mu Max                2.4316447
Policy mu Min                -2.5593832
Policy log std Mean          -1.1779752
Policy log std Std           0.3484515
Policy log std Max           -0.17593288
Policy log std Min           -2.6292372
Z mean eval                  0.903628
Z variance eval              0.12457113
total_rewards                [1181.93926025  904.30575048 4881.26919448  665.03117006  295.75470049
 4803.49287391 4932.9503709  5114.23921154 1855.78954915 5057.64403967]
total_rewards_mean           2969.2416120940966
total_rewards_std            2024.6980513524436
total_rewards_max            5114.239211543027
total_rewards_min            295.7547004947641
Number of train steps total  1604000
Number of env steps total    2763774
Number of rollouts total     0
Train Time (s)               209.76335718017071
(Previous) Eval Time (s)     24.82640435313806
Sample Time (s)              20.65490038273856
Epoch Time (s)               255.24466191604733
Total Train Time (s)         89690.65885409992
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:06:33.135441 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #400 | Epoch Duration: 255.34349822998047
2020-01-12 17:06:33.135616 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9055716
Z variance train             0.123824045
KL Divergence                13.314156
KL Loss                      1.3314155
QF Loss                      533.78906
VF Loss                      164.68633
Policy Loss                  -1489.4567
Q Predictions Mean           1480.7073
Q Predictions Std            384.99652
Q Predictions Max            2063.826
Q Predictions Min            311.20258
V Predictions Mean           1487.0698
V Predictions Std            384.6871
V Predictions Max            2065.4841
V Predictions Min            314.4559
Log Pis Mean                 1.7430881
Log Pis Std                  3.1676855
Log Pis Max                  10.897394
Log Pis Min                  -6.9338617
Policy mu Mean               0.0509722
Policy mu Std                0.7184215
Policy mu Max                2.4387395
Policy mu Min                -2.8332815
Policy log std Mean          -1.1263845
Policy log std Std           0.325596
Policy log std Max           -0.2797433
Policy log std Min           -2.591996
Z mean eval                  0.9156636
Z variance eval              0.34260997
total_rewards                [4932.82037434 2978.31856785 4930.32926776  882.01358874 2881.58271901
  244.25964223 5133.69423224 1967.40305563 1943.05496113 2774.82661353]
total_rewards_mean           2866.830302245694
total_rewards_std            1617.5855924015493
total_rewards_max            5133.694232238836
total_rewards_min            244.25964222778273
Number of train steps total  1608000
Number of env steps total    2773884
Number of rollouts total     0
Train Time (s)               207.00083080818877
(Previous) Eval Time (s)     26.879794859327376
Sample Time (s)              9.173111881595105
Epoch Time (s)               243.05373754911125
Total Train Time (s)         89933.81358106667
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:10:36.294122 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #401 | Epoch Duration: 243.15836906433105
2020-01-12 17:10:36.294301 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.914303
Z variance train             0.33975583
KL Divergence                10.292378
KL Loss                      1.0292379
QF Loss                      746.1188
VF Loss                      142.26428
Policy Loss                  -1485.4688
Q Predictions Mean           1476.0469
Q Predictions Std            372.41675
Q Predictions Max            2013.2388
Q Predictions Min            310.86633
V Predictions Mean           1484.9229
V Predictions Std            370.58145
V Predictions Max            2011.8195
V Predictions Min            326.91965
Log Pis Mean                 1.9513979
Log Pis Std                  3.2998326
Log Pis Max                  16.066956
Log Pis Min                  -8.832552
Policy mu Mean               0.1079261
Policy mu Std                0.691962
Policy mu Max                2.4913003
Policy mu Min                -2.4258883
Policy log std Mean          -1.1717951
Policy log std Std           0.3468321
Policy log std Max           -0.0855602
Policy log std Min           -2.5260987
Z mean eval                  0.97243834
Z variance eval              0.12376116
total_rewards                [4770.49385435 4869.53790561  247.27663338 4759.43771511 4737.14928801
 5275.27089493 2095.51917429 5275.55410706 2102.60344073 3650.52409828]
total_rewards_mean           3778.33671117646
total_rewards_std            1632.9153883502665
total_rewards_max            5275.554107062624
total_rewards_min            247.27663337718337
Number of train steps total  1612000
Number of env steps total    2784088
Number of rollouts total     0
Train Time (s)               210.51502394722775
(Previous) Eval Time (s)     36.670108006335795
Sample Time (s)              9.394137284718454
Epoch Time (s)               256.579269238282
Total Train Time (s)         90190.48733517947
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:14:52.971750 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #402 | Epoch Duration: 256.6773045063019
2020-01-12 17:14:52.971935 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97057456
Z variance train             0.12395181
KL Divergence                12.335256
KL Loss                      1.2335256
QF Loss                      958.56
VF Loss                      103.07024
Policy Loss                  -1436.2349
Q Predictions Mean           1424.856
Q Predictions Std            402.57034
Q Predictions Max            2032.6531
Q Predictions Min            349.39426
V Predictions Mean           1435.7858
V Predictions Std            401.92825
V Predictions Max            2043.3943
V Predictions Min            343.47958
Log Pis Mean                 1.8858821
Log Pis Std                  3.416677
Log Pis Max                  13.655287
Log Pis Min                  -7.40788
Policy mu Mean               0.1034367
Policy mu Std                0.6795791
Policy mu Max                2.8895028
Policy mu Min                -2.9621532
Policy log std Mean          -1.1781114
Policy log std Std           0.36295262
Policy log std Max           0.04951191
Policy log std Min           -2.4756804
Z mean eval                  0.98930675
Z variance eval              0.16357853
total_rewards                [4948.92330164 5015.20267637 4601.71009469 3111.47845701 5095.89753632
  848.60934597  426.41036738 4691.30709281 1326.51576528 5075.04050135]
total_rewards_mean           3514.1095138830888
total_rewards_std            1827.72138708449
total_rewards_max            5095.8975363157915
total_rewards_min            426.410367382755
Number of train steps total  1616000
Number of env steps total    2794125
Number of rollouts total     0
Train Time (s)               207.81039140326902
(Previous) Eval Time (s)     31.843411370180547
Sample Time (s)              8.835292106959969
Epoch Time (s)               248.48909488040954
Total Train Time (s)         90439.0714503699
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:19:01.564839 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #403 | Epoch Duration: 248.59274554252625
2020-01-12 17:19:01.565018 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99586093
Z variance train             0.16456978
KL Divergence                11.648939
KL Loss                      1.164894
QF Loss                      2559.3013
VF Loss                      687.4723
Policy Loss                  -1452.1624
Q Predictions Mean           1443.2534
Q Predictions Std            354.51022
Q Predictions Max            1946.6593
Q Predictions Min            386.86923
V Predictions Mean           1442.2659
V Predictions Std            353.8331
V Predictions Max            1932.6595
V Predictions Min            390.82584
Log Pis Mean                 2.037801
Log Pis Std                  3.3214555
Log Pis Max                  24.171953
Log Pis Min                  -5.311714
Policy mu Mean               0.096466385
Policy mu Std                0.75533843
Policy mu Max                4.4984274
Policy mu Min                -4.353745
Policy log std Mean          -1.1274874
Policy log std Std           0.34206858
Policy log std Max           0.8713213
Policy log std Min           -2.42394
Z mean eval                  1.0372415
Z variance eval              0.16258284
total_rewards                [5029.97993049 4896.67134362 4448.06571733 5287.25546335 4992.74497873
 5049.746868   5146.92277876 4917.33250935 2550.34237644 5284.28763596]
total_rewards_mean           4760.334960203902
total_rewards_std            770.5140481415261
total_rewards_max            5287.255463350394
total_rewards_min            2550.3423764392446
Number of train steps total  1620000
Number of env steps total    2805274
Number of rollouts total     0
Train Time (s)               208.77515736361966
(Previous) Eval Time (s)     44.72330411616713
Sample Time (s)              9.0093565848656
Epoch Time (s)               262.5078180646524
Total Train Time (s)         90701.69008043362
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:23:24.189037 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #404 | Epoch Duration: 262.62387442588806
2020-01-12 17:23:24.189220 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0328057
Z variance train             0.16126478
KL Divergence                11.23639
KL Loss                      1.123639
QF Loss                      463.16214
VF Loss                      119.66963
Policy Loss                  -1505.5765
Q Predictions Mean           1496.644
Q Predictions Std            332.28275
Q Predictions Max            2041.2542
Q Predictions Min            340.60846
V Predictions Mean           1502.8789
V Predictions Std            327.60596
V Predictions Max            2038.6746
V Predictions Min            343.98624
Log Pis Mean                 1.9454017
Log Pis Std                  3.072862
Log Pis Max                  13.662124
Log Pis Min                  -10.799454
Policy mu Mean               0.09774786
Policy mu Std                0.6625267
Policy mu Max                2.8972535
Policy mu Min                -2.9941134
Policy log std Mean          -1.2281219
Policy log std Std           0.31660986
Policy log std Max           -0.3878318
Policy log std Min           -2.4167378
Z mean eval                  0.8604641
Z variance eval              0.6199249
total_rewards                [5187.66398406  782.86002422  677.84346233   26.57183196 2759.73855805
 2429.41916671 4730.49824021 5087.93389506 1005.95439641 5018.04191597]
total_rewards_mean           2770.652547497652
total_rewards_std            1979.78175809431
total_rewards_max            5187.663984063727
total_rewards_min            26.571831957051447
Number of train steps total  1624000
Number of env steps total    2815579
Number of rollouts total     0
Train Time (s)               206.21899524098262
(Previous) Eval Time (s)     23.52779122395441
Sample Time (s)              8.839058512821794
Epoch Time (s)               238.58584497775882
Total Train Time (s)         90940.37314891862
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:27:22.881562 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #405 | Epoch Duration: 238.6921408176422
2020-01-12 17:27:22.881951 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #405 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85933846
Z variance train             0.61697847
KL Divergence                8.217929
KL Loss                      0.8217929
QF Loss                      677.7324
VF Loss                      145.72809
Policy Loss                  -1582.0148
Q Predictions Mean           1573.9185
Q Predictions Std            238.8905
Q Predictions Max            2040.4581
Q Predictions Min            362.91156
V Predictions Mean           1579.8723
V Predictions Std            234.50978
V Predictions Max            2026.4833
V Predictions Min            373.03778
Log Pis Mean                 2.2726617
Log Pis Std                  3.0608041
Log Pis Max                  19.245396
Log Pis Min                  -5.3605084
Policy mu Mean               0.1079529
Policy mu Std                0.7321286
Policy mu Max                2.9774942
Policy mu Min                -2.4681492
Policy log std Mean          -1.1833389
Policy log std Std           0.31560063
Policy log std Max           -0.118745565
Policy log std Min           -2.4917254
Z mean eval                  1.0670431
Z variance eval              0.17433667
total_rewards                [ 5121.27089622 -1217.18685044  4889.89309193  5246.74220607
  4417.70962688  5193.67445716  5196.2170904   -308.13547817
  4554.2284058   4535.15554789]
total_rewards_mean           3762.95689937353
total_rewards_std            2290.0772003791976
total_rewards_max            5246.742206068551
total_rewards_min            -1217.1868504408174
Number of train steps total  1628000
Number of env steps total    2826561
Number of rollouts total     0
Train Time (s)               204.8703816481866
(Previous) Eval Time (s)     43.0036521339789
Sample Time (s)              10.30657868925482
Epoch Time (s)               258.1806124714203
Total Train Time (s)         91198.6433140086
Epoch                        406
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:31:41.157701 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #406 | Epoch Duration: 258.2754228115082
2020-01-12 17:31:41.158053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #406 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0502346
Z variance train             0.17538661
KL Divergence                12.729446
KL Loss                      1.2729447
QF Loss                      612.147
VF Loss                      327.44406
Policy Loss                  -1549.941
Q Predictions Mean           1544.2617
Q Predictions Std            295.15112
Q Predictions Max            2037.1729
Q Predictions Min            384.9893
V Predictions Mean           1563.8204
V Predictions Std            292.5242
V Predictions Max            2024.7842
V Predictions Min            399.37457
Log Pis Mean                 2.2153022
Log Pis Std                  2.7821288
Log Pis Max                  12.486635
Log Pis Min                  -5.6257744
Policy mu Mean               0.083196
Policy mu Std                0.7299843
Policy mu Max                2.3595185
Policy mu Min                -2.4715037
Policy log std Mean          -1.1476212
Policy log std Std           0.29424074
Policy log std Max           0.15776634
Policy log std Min           -2.4073257
Z mean eval                  0.9959918
Z variance eval              0.13849768
total_rewards                [ 1.41086620e+03  2.22680529e+01 -2.48010582e+00  8.55229942e+02
  4.68281543e+03  3.86403519e+01  7.20127542e+02  8.53476121e+02
  2.86251187e+03  2.21541705e+03]
total_rewards_mean           1365.8872458060112
total_rewards_std            1426.3691506098041
total_rewards_max            4682.815430323072
total_rewards_min            -2.4801058150384527
Number of train steps total  1632000
Number of env steps total    2835809
Number of rollouts total     0
Train Time (s)               204.86276666773483
(Previous) Eval Time (s)     20.203516706824303
Sample Time (s)              9.448289731517434
Epoch Time (s)               234.51457310607657
Total Train Time (s)         91433.25990010612
Epoch                        407
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:35:35.775197 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #407 | Epoch Duration: 234.61689162254333
2020-01-12 17:35:35.775387 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9946722
Z variance train             0.13908134
KL Divergence                13.018722
KL Loss                      1.3018721
QF Loss                      639.5265
VF Loss                      135.33984
Policy Loss                  -1556.4618
Q Predictions Mean           1547.7207
Q Predictions Std            328.83002
Q Predictions Max            2050.2346
Q Predictions Min            -50.911377
V Predictions Mean           1558.7142
V Predictions Std            323.95822
V Predictions Max            2066.3936
V Predictions Min            75.43163
Log Pis Mean                 2.0390296
Log Pis Std                  3.2725742
Log Pis Max                  29.752773
Log Pis Min                  -5.373603
Policy mu Mean               0.106747955
Policy mu Std                0.7301445
Policy mu Max                5.1645546
Policy mu Min                -4.7818274
Policy log std Mean          -1.2064669
Policy log std Std           0.31352854
Policy log std Max           1.4079834
Policy log std Min           -2.0706525
Z mean eval                  0.9287276
Z variance eval              0.2188237
total_rewards                [5152.17442372 3469.70009187 4867.53338759 5296.07416906 4147.1334125
 4990.69295893 3156.19705276 4977.7794817  1825.74501202 1015.29572648]
total_rewards_mean           3889.8325716617496
total_rewards_std            1422.2095121504278
total_rewards_max            5296.074169058947
total_rewards_min            1015.2957264802874
Number of train steps total  1636000
Number of env steps total    2846266
Number of rollouts total     0
Train Time (s)               205.758582029026
(Previous) Eval Time (s)     39.247261920012534
Sample Time (s)              9.84397830395028
Epoch Time (s)               254.84982225298882
Total Train Time (s)         91688.19833626412
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:50.719864 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #408 | Epoch Duration: 254.94432711601257
2020-01-12 17:39:50.720079 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93062115
Z variance train             0.22101358
KL Divergence                11.204578
KL Loss                      1.1204579
QF Loss                      507.70044
VF Loss                      126.43148
Policy Loss                  -1526.1892
Q Predictions Mean           1519.0778
Q Predictions Std            255.00104
Q Predictions Max            2052.8376
Q Predictions Min            378.1936
V Predictions Mean           1527.355
V Predictions Std            251.2916
V Predictions Max            2045.0002
V Predictions Min            384.53775
Log Pis Mean                 1.8783286
Log Pis Std                  2.5834641
Log Pis Max                  9.641165
Log Pis Min                  -4.767956
Policy mu Mean               0.11472516
Policy mu Std                0.7264908
Policy mu Max                2.5783107
Policy mu Min                -2.9829252
Policy log std Mean          -1.165601
Policy log std Std           0.3030513
Policy log std Max           -0.17041326
Policy log std Min           -2.580367
Z mean eval                  0.8546575
Z variance eval              0.15507042
total_rewards                [5058.97914574 4955.18537302 4871.4788942  5049.34272207 4965.81398685
 4929.65933077 3994.70926337 4576.63932567 5197.19051532 1086.85128638]
total_rewards_mean           4468.584984337771
total_rewards_std            1172.5185394612458
total_rewards_max            5197.190515315837
total_rewards_min            1086.8512863752064
Number of train steps total  1640000
Number of env steps total    2858266
Number of rollouts total     0
Train Time (s)               207.14013101998717
(Previous) Eval Time (s)     44.677297323942184
Sample Time (s)              8.926831444259733
Epoch Time (s)               260.7442597881891
Total Train Time (s)         91949.02836320829
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:44:11.554029 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #409 | Epoch Duration: 260.8337984085083
2020-01-12 17:44:11.554226 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84496784
Z variance train             0.15521999
KL Divergence                11.656708
KL Loss                      1.1656708
QF Loss                      685.24054
VF Loss                      669.9313
Policy Loss                  -1510.6974
Q Predictions Mean           1506.405
Q Predictions Std            237.22113
Q Predictions Max            1968.6259
Q Predictions Min            361.36786
V Predictions Mean           1532.6172
V Predictions Std            238.94453
V Predictions Max            2002.3208
V Predictions Min            371.56613
Log Pis Mean                 1.7394049
Log Pis Std                  2.8023562
Log Pis Max                  11.871692
Log Pis Min                  -8.353659
Policy mu Mean               0.085624665
Policy mu Std                0.68523806
Policy mu Max                2.5274005
Policy mu Min                -2.4930363
Policy log std Mean          -1.185472
Policy log std Std           0.28596714
Policy log std Max           -0.21104228
Policy log std Min           -2.4363365
Z mean eval                  0.887993
Z variance eval              0.2594041
total_rewards                [ 327.33424972 3823.94171075  551.3782938  4838.06332404 3309.16549305
 4797.02194769 3050.94538831 1887.08335816 1380.47497733 1261.02340589]
total_rewards_mean           2522.6432148734584
total_rewards_std            1585.2603305573316
total_rewards_max            4838.063324035938
total_rewards_min            327.3342497228711
Number of train steps total  1644000
Number of env steps total    2869249
Number of rollouts total     0
Train Time (s)               205.49455198599026
(Previous) Eval Time (s)     23.019783454947174
Sample Time (s)              9.868889102246612
Epoch Time (s)               238.38322454318404
Total Train Time (s)         92187.49902462121
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:10.026975 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #410 | Epoch Duration: 238.4726161956787
2020-01-12 17:48:10.027113 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88473195
Z variance train             0.25690416
KL Divergence                9.094069
KL Loss                      0.90940684
QF Loss                      637.1113
VF Loss                      107.35843
Policy Loss                  -1418.2782
Q Predictions Mean           1408.5265
Q Predictions Std            269.0047
Q Predictions Max            1912.3455
Q Predictions Min            347.77936
V Predictions Mean           1419.9941
V Predictions Std            266.73917
V Predictions Max            1906.4968
V Predictions Min            347.42438
Log Pis Mean                 2.4920979
Log Pis Std                  2.9597082
Log Pis Max                  12.953316
Log Pis Min                  -6.070952
Policy mu Mean               0.17043304
Policy mu Std                0.7145153
Policy mu Max                3.2679832
Policy mu Min                -2.7378948
Policy log std Mean          -1.2228616
Policy log std Std           0.29230326
Policy log std Max           -0.29450405
Policy log std Min           -2.3644564
Z mean eval                  1.0647877
Z variance eval              0.15352216
total_rewards                [2858.55202063 4892.79315744 4622.97124622  614.5295282  3353.42088173
 5060.28605877 2521.85866902 2713.8274136  2289.74099706 3698.08511621]
total_rewards_mean           3262.6065088883493
total_rewards_std            1300.36711149041
total_rewards_max            5060.28605877281
total_rewards_min            614.5295282013884
Number of train steps total  1648000
Number of env steps total    2877822
Number of rollouts total     0
Train Time (s)               203.88395765889436
(Previous) Eval Time (s)     31.86740109976381
Sample Time (s)              10.33552239369601
Epoch Time (s)               246.08688115235418
Total Train Time (s)         92433.67428585421
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:52:16.206274 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #411 | Epoch Duration: 246.17903900146484
2020-01-12 17:52:16.206461 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0649351
Z variance train             0.15437973
KL Divergence                11.546539
KL Loss                      1.1546539
QF Loss                      529.99255
VF Loss                      208.67633
Policy Loss                  -1565.7378
Q Predictions Mean           1556.1348
Q Predictions Std            246.90489
Q Predictions Max            2021.0338
Q Predictions Min            467.9769
V Predictions Mean           1554.9613
V Predictions Std            248.21391
V Predictions Max            2022.3978
V Predictions Min            457.70163
Log Pis Mean                 2.3127513
Log Pis Std                  2.6980424
Log Pis Max                  12.006344
Log Pis Min                  -4.28769
Policy mu Mean               0.14014104
Policy mu Std                0.75702304
Policy mu Max                2.7121556
Policy mu Min                -2.3896167
Policy log std Mean          -1.153518
Policy log std Std           0.3149465
Policy log std Max           -0.069072604
Policy log std Min           -2.5325458
Z mean eval                  0.98738176
Z variance eval              0.32278964
total_rewards                [ 417.52536525 4857.46872075 5017.68408574 4483.81790855 3580.48573364
 4851.17397811 4858.18545748 5238.91253056 4991.96812407 5122.62115682]
total_rewards_mean           4341.984306096578
total_rewards_std            1381.512216591883
total_rewards_max            5238.912530564087
total_rewards_min            417.5253652526545
Number of train steps total  1652000
Number of env steps total    2888423
Number of rollouts total     0
Train Time (s)               204.2589826369658
(Previous) Eval Time (s)     44.59433620981872
Sample Time (s)              9.073032083455473
Epoch Time (s)               257.92635093024
Total Train Time (s)         92691.6870177635
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:56:34.223059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #412 | Epoch Duration: 258.0164592266083
2020-01-12 17:56:34.223242 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9851295
Z variance train             0.32535654
KL Divergence                10.059013
KL Loss                      1.0059013
QF Loss                      542.21106
VF Loss                      193.01376
Policy Loss                  -1573.8488
Q Predictions Mean           1562.9794
Q Predictions Std            223.10587
Q Predictions Max            1988.6416
Q Predictions Min            503.9134
V Predictions Mean           1563.8772
V Predictions Std            220.9747
V Predictions Max            1962.6309
V Predictions Min            505.60648
Log Pis Mean                 1.9924839
Log Pis Std                  2.9200413
Log Pis Max                  12.761683
Log Pis Min                  -5.1085315
Policy mu Mean               0.050368115
Policy mu Std                0.7197646
Policy mu Max                2.7597513
Policy mu Min                -2.495108
Policy log std Mean          -1.1867888
Policy log std Std           0.29461458
Policy log std Max           -0.20621622
Policy log std Min           -2.5966487
Z mean eval                  0.90697825
Z variance eval              0.25259548
total_rewards                [3708.62174216  681.47574711 4678.63359106 5147.77480803 2813.67702361
  449.97559259   86.12810426  722.140336   5231.43999791 5118.59584312]
total_rewards_mean           2863.846278586587
total_rewards_std            2068.996764123437
total_rewards_max            5231.439997913175
total_rewards_min            86.12810425874915
Number of train steps total  1656000
Number of env steps total    2899381
Number of rollouts total     0
Train Time (s)               209.37804962694645
(Previous) Eval Time (s)     30.75850853510201
Sample Time (s)              8.49743734067306
Epoch Time (s)               248.63399550272152
Total Train Time (s)         92940.41465052497
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:00:42.952962 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #413 | Epoch Duration: 248.72958898544312
2020-01-12 18:00:42.953099 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90866077
Z variance train             0.25351325
KL Divergence                11.32547
KL Loss                      1.132547
QF Loss                      681.0081
VF Loss                      231.94086
Policy Loss                  -1572.647
Q Predictions Mean           1564.3313
Q Predictions Std            228.26384
Q Predictions Max            2038.3268
Q Predictions Min            474.34747
V Predictions Mean           1582.637
V Predictions Std            224.59485
V Predictions Max            2050.2017
V Predictions Min            507.23566
Log Pis Mean                 1.9395397
Log Pis Std                  2.9633145
Log Pis Max                  13.510365
Log Pis Min                  -9.316092
Policy mu Mean               0.09825532
Policy mu Std                0.7277274
Policy mu Max                2.5616553
Policy mu Min                -2.4704888
Policy log std Mean          -1.154554
Policy log std Std           0.31153893
Policy log std Max           -0.23668861
Policy log std Min           -2.7415977
Z mean eval                  0.9812521
Z variance eval              0.085618466
total_rewards                [4816.63337346 4773.16162151 4996.33053837 5031.01373182 4938.63786956
 5156.53033652 4026.23217129 5205.97977737 4722.67673665 5152.80871698]
total_rewards_mean           4882.000487351955
total_rewards_std            326.4954276775878
total_rewards_max            5205.979777370626
total_rewards_min            4026.2321712889016
Number of train steps total  1660000
Number of env steps total    2909822
Number of rollouts total     0
Train Time (s)               205.29721704078838
(Previous) Eval Time (s)     43.686753775924444
Sample Time (s)              10.156364017631859
Epoch Time (s)               259.1403348343447
Total Train Time (s)         93199.68156877765
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:02.224431 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #414 | Epoch Duration: 259.27120447158813
2020-01-12 18:05:02.224646 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97869366
Z variance train             0.08618595
KL Divergence                13.28511
KL Loss                      1.3285111
QF Loss                      577.59314
VF Loss                      152.65038
Policy Loss                  -1572.9678
Q Predictions Mean           1565.746
Q Predictions Std            251.13222
Q Predictions Max            2068.461
Q Predictions Min            536.6296
V Predictions Mean           1581.2512
V Predictions Std            249.95247
V Predictions Max            2078.1643
V Predictions Min            543.1773
Log Pis Mean                 1.8557918
Log Pis Std                  2.681449
Log Pis Max                  11.957375
Log Pis Min                  -6.104152
Policy mu Mean               -0.028573412
Policy mu Std                0.7062432
Policy mu Max                2.4882653
Policy mu Min                -2.9375648
Policy log std Mean          -1.175757
Policy log std Std           0.29724458
Policy log std Max           -0.28148615
Policy log std Min           -2.5736835
Z mean eval                  0.8933438
Z variance eval              0.18318862
total_rewards                [1792.73115481 4052.07935312 2551.44761071 5107.19388265 2855.9230271
   26.28968023 1251.46346273 2573.28895092  365.98161035 3505.57406358]
total_rewards_mean           2408.197279619783
total_rewards_std            1516.5870014195823
total_rewards_max            5107.193882652522
total_rewards_min            26.28968022891524
Number of train steps total  1664000
Number of env steps total    2919571
Number of rollouts total     0
Train Time (s)               203.87804583786055
(Previous) Eval Time (s)     22.464672302361578
Sample Time (s)              10.373964596074075
Epoch Time (s)               236.7166827362962
Total Train Time (s)         93436.5043758275
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:08:59.051166 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #415 | Epoch Duration: 236.82637071609497
2020-01-12 18:08:59.051356 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8932904
Z variance train             0.18250409
KL Divergence                11.493264
KL Loss                      1.1493264
QF Loss                      488.86575
VF Loss                      106.219475
Policy Loss                  -1486.9001
Q Predictions Mean           1479.0969
Q Predictions Std            237.2852
Q Predictions Max            1958.8936
Q Predictions Min            491.23682
V Predictions Mean           1487.323
V Predictions Std            234.76227
V Predictions Max            1959.2462
V Predictions Min            488.3161
Log Pis Mean                 1.6459523
Log Pis Std                  2.831013
Log Pis Max                  10.595966
Log Pis Min                  -6.190611
Policy mu Mean               0.10242897
Policy mu Std                0.67827845
Policy mu Max                2.49009
Policy mu Min                -2.4714756
Policy log std Mean          -1.1707244
Policy log std Std           0.28168237
Policy log std Max           -0.2407285
Policy log std Min           -2.3873854
Z mean eval                  0.8692129
Z variance eval              0.15787742
total_rewards                [4871.54054646 5156.85069643 5331.96242829 5269.78048247 2804.33239536
 4944.03808888 5305.17176769 5112.96023402 5294.27991351 5193.44800819]
total_rewards_mean           4928.436456131749
total_rewards_std            722.9710722958689
total_rewards_max            5331.962428293788
total_rewards_min            2804.3323953638082
Number of train steps total  1668000
Number of env steps total    2928948
Number of rollouts total     0
Train Time (s)               204.00660911621526
(Previous) Eval Time (s)     48.31944741634652
Sample Time (s)              10.076676019001752
Epoch Time (s)               262.40273255156353
Total Train Time (s)         93698.9934390327
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:13:21.544237 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #416 | Epoch Duration: 262.49273109436035
2020-01-12 18:13:21.544432 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86257553
Z variance train             0.15719281
KL Divergence                10.75396
KL Loss                      1.075396
QF Loss                      531.5238
VF Loss                      116.88615
Policy Loss                  -1497.5679
Q Predictions Mean           1492.4531
Q Predictions Std            266.87372
Q Predictions Max            1974.0929
Q Predictions Min            459.76022
V Predictions Mean           1502.6605
V Predictions Std            266.40652
V Predictions Max            1976.5532
V Predictions Min            478.7791
Log Pis Mean                 1.7266672
Log Pis Std                  2.670171
Log Pis Max                  9.148619
Log Pis Min                  -7.410149
Policy mu Mean               0.07370883
Policy mu Std                0.6766022
Policy mu Max                2.4657362
Policy mu Min                -2.9341912
Policy log std Mean          -1.1938779
Policy log std Std           0.29263985
Policy log std Max           -0.34327257
Policy log std Min           -2.4680758
Z mean eval                  0.9018396
Z variance eval              0.27525705
total_rewards                [4919.28946198 5111.58454639 4831.41900496 1749.38072042 4661.11272666
 4616.33841545 4477.71253908 5277.04825797 2908.11379696 5192.18088612]
total_rewards_mean           4374.418035597933
total_rewards_std            1082.8150680880585
total_rewards_max            5277.048257971592
total_rewards_min            1749.3807204211844
Number of train steps total  1672000
Number of env steps total    2940130
Number of rollouts total     0
Train Time (s)               209.65815354092047
(Previous) Eval Time (s)     45.82207556581125
Sample Time (s)              9.77714062249288
Epoch Time (s)               265.2573697292246
Total Train Time (s)         93964.34214806231
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:17:46.896924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #417 | Epoch Duration: 265.35234928131104
2020-01-12 18:17:46.897096 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90584147
Z variance train             0.27195945
KL Divergence                10.299743
KL Loss                      1.0299743
QF Loss                      495.05316
VF Loss                      108.65336
Policy Loss                  -1513.7292
Q Predictions Mean           1504.3163
Q Predictions Std            250.0221
Q Predictions Max            1969.5964
Q Predictions Min            481.749
V Predictions Mean           1509.0798
V Predictions Std            249.29962
V Predictions Max            1968.3917
V Predictions Min            467.38266
Log Pis Mean                 2.0203543
Log Pis Std                  2.904574
Log Pis Max                  12.691061
Log Pis Min                  -4.3594055
Policy mu Mean               0.07062282
Policy mu Std                0.68456596
Policy mu Max                2.8269267
Policy mu Min                -2.845316
Policy log std Mean          -1.2169292
Policy log std Std           0.30099303
Policy log std Max           -0.04795313
Policy log std Min           -2.5500417
Z mean eval                  0.9438308
Z variance eval              0.20162138
total_rewards                [4965.57055819 4959.86770028 5154.85615027 5215.98383184 5118.1352932
 5288.32024866 5178.39871032 2573.14589038 4977.36575356 5230.22972365]
total_rewards_mean           4866.18738603482
total_rewards_std            772.4258405524382
total_rewards_max            5288.32024865532
total_rewards_min            2573.145890383378
Number of train steps total  1676000
Number of env steps total    2952268
Number of rollouts total     0
Train Time (s)               207.50850730016828
(Previous) Eval Time (s)     42.62649818882346
Sample Time (s)              10.746088159736246
Epoch Time (s)               260.881093648728
Total Train Time (s)         94225.31117630098
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:22:07.870070 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #418 | Epoch Duration: 260.9728150367737
2020-01-12 18:22:07.870262 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9448676
Z variance train             0.20282927
KL Divergence                10.252438
KL Loss                      1.0252438
QF Loss                      474.9672
VF Loss                      121.41838
Policy Loss                  -1629.9343
Q Predictions Mean           1623.4849
Q Predictions Std            331.07544
Q Predictions Max            2182.4954
Q Predictions Min            524.9727
V Predictions Mean           1635.1477
V Predictions Std            335.0557
V Predictions Max            2181.2178
V Predictions Min            519.89764
Log Pis Mean                 1.7925783
Log Pis Std                  2.8605711
Log Pis Max                  14.403607
Log Pis Min                  -6.245899
Policy mu Mean               0.08930051
Policy mu Std                0.69952464
Policy mu Max                2.8350432
Policy mu Min                -2.9929633
Policy log std Mean          -1.1330779
Policy log std Std           0.30368325
Policy log std Max           -0.2888682
Policy log std Min           -2.470724
Z mean eval                  0.9698247
Z variance eval              0.3636871
total_rewards                [5092.15813863 5232.2008128  5304.26026053 5128.67515258 3154.43389772
 5137.46378616 4819.64405623 5062.18807173 5047.34357085 5068.76113294]
total_rewards_mean           4904.712888016148
total_rewards_std            595.7450179497085
total_rewards_max            5304.2602605313
total_rewards_min            3154.4338977205707
Number of train steps total  1680000
Number of env steps total    2962784
Number of rollouts total     0
Train Time (s)               206.75040448782966
(Previous) Eval Time (s)     42.015979959163815
Sample Time (s)              10.094532776158303
Epoch Time (s)               258.8609172231518
Total Train Time (s)         94484.26072562346
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:26:26.823552 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #419 | Epoch Duration: 258.95314359664917
2020-01-12 18:26:26.823779 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0037522
Z variance train             0.35653892
KL Divergence                9.994785
KL Loss                      0.9994785
QF Loss                      755.7438
VF Loss                      168.14749
Policy Loss                  -1524.9773
Q Predictions Mean           1518.2302
Q Predictions Std            299.0492
Q Predictions Max            1986.6628
Q Predictions Min            420.3311
V Predictions Mean           1516.9355
V Predictions Std            295.73938
V Predictions Max            1972.6567
V Predictions Min            430.49588
Log Pis Mean                 2.2433474
Log Pis Std                  2.9189856
Log Pis Max                  14.114816
Log Pis Min                  -5.676824
Policy mu Mean               0.05352898
Policy mu Std                0.6698637
Policy mu Max                3.216119
Policy mu Min                -2.6614723
Policy log std Mean          -1.2432103
Policy log std Std           0.30162418
Policy log std Max           -0.18170786
Policy log std Min           -2.6575594
Z mean eval                  0.9579361
Z variance eval              0.15206853
total_rewards                [1770.35942594 2545.61787052 1009.50886224 5087.41680565 1155.36428421
 4148.43211247 1011.16179339 5083.11973311  420.01582167 1707.16603486]
total_rewards_mean           2393.8162744070687
total_rewards_std            1664.5550863975984
total_rewards_max            5087.416805648103
total_rewards_min            420.01582167214457
Number of train steps total  1684000
Number of env steps total    2974508
Number of rollouts total     0
Train Time (s)               208.09272777102888
(Previous) Eval Time (s)     25.02475003199652
Sample Time (s)              18.78696675505489
Epoch Time (s)               251.90444455808029
Total Train Time (s)         94736.26231498038
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:30:38.833095 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #420 | Epoch Duration: 252.009135723114
2020-01-12 18:30:38.833389 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96223384
Z variance train             0.1518646
KL Divergence                11.711954
KL Loss                      1.1711954
QF Loss                      405.47656
VF Loss                      180.17525
Policy Loss                  -1480.456
Q Predictions Mean           1474.1863
Q Predictions Std            373.64243
Q Predictions Max            2025.5469
Q Predictions Min            424.0648
V Predictions Mean           1470.9641
V Predictions Std            371.54648
V Predictions Max            1999.28
V Predictions Min            421.28906
Log Pis Mean                 1.7534561
Log Pis Std                  3.1644084
Log Pis Max                  12.834515
Log Pis Min                  -6.3605685
Policy mu Mean               0.11019187
Policy mu Std                0.6899782
Policy mu Max                2.6741855
Policy mu Min                -2.6490033
Policy log std Mean          -1.1477162
Policy log std Std           0.3291527
Policy log std Max           -0.029321074
Policy log std Min           -2.5124226
Z mean eval                  1.0652767
Z variance eval              0.104148865
total_rewards                [4411.26915753  977.30461857  477.09207167 4799.85230858  651.13101233
 5004.72260304  142.22742508 4014.41034174 1939.0245016   104.5793424 ]
total_rewards_mean           2252.1613382547375
total_rewards_std            1957.9582173512397
total_rewards_max            5004.722603037145
total_rewards_min            104.579342399927
Number of train steps total  1688000
Number of env steps total    2984994
Number of rollouts total     0
Train Time (s)               208.40963621996343
(Previous) Eval Time (s)     21.809214618057013
Sample Time (s)              8.839687457773834
Epoch Time (s)               239.05853829579428
Total Train Time (s)         94975.41300442163
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:37.988274 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #421 | Epoch Duration: 239.15466713905334
2020-01-12 18:34:37.988484 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0634344
Z variance train             0.10446347
KL Divergence                12.634409
KL Loss                      1.263441
QF Loss                      3169.297
VF Loss                      116.41399
Policy Loss                  -1576.339
Q Predictions Mean           1569.394
Q Predictions Std            358.28235
Q Predictions Max            2143.5535
Q Predictions Min            462.99213
V Predictions Mean           1577.1177
V Predictions Std            355.85226
V Predictions Max            2149.5105
V Predictions Min            469.92532
Log Pis Mean                 1.1923633
Log Pis Std                  2.9994192
Log Pis Max                  12.625841
Log Pis Min                  -6.5939007
Policy mu Mean               0.080852404
Policy mu Std                0.6735571
Policy mu Max                2.7972357
Policy mu Min                -2.6364093
Policy log std Mean          -1.1188458
Policy log std Std           0.3081758
Policy log std Max           0.09385276
Policy log std Min           -2.1745138
Z mean eval                  0.84973174
Z variance eval              0.25454378
total_rewards                [4827.63711091 5031.03343664  722.58939182 5249.11125254 4975.61351944
 5291.06082338 4946.52472395  715.88034789 5179.17628044 4716.58307725]
total_rewards_mean           4165.52099642523
total_rewards_std            1731.4646714962214
total_rewards_max            5291.060823383821
total_rewards_min            715.8803478920514
Number of train steps total  1692000
Number of env steps total    2994520
Number of rollouts total     0
Train Time (s)               207.1853730659932
(Previous) Eval Time (s)     36.246323669329286
Sample Time (s)              9.542895081918687
Epoch Time (s)               252.97459181724116
Total Train Time (s)         95228.71062303195
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:38:51.292637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #422 | Epoch Duration: 253.30396032333374
2020-01-12 18:38:51.292877 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8504035
Z variance train             0.25391412
KL Divergence                10.314364
KL Loss                      1.0314364
QF Loss                      417.47467
VF Loss                      95.44312
Policy Loss                  -1512.875
Q Predictions Mean           1506.925
Q Predictions Std            318.2992
Q Predictions Max            1981.4952
Q Predictions Min            347.1193
V Predictions Mean           1511.3091
V Predictions Std            318.02026
V Predictions Max            1984.1779
V Predictions Min            362.6505
Log Pis Mean                 1.8962848
Log Pis Std                  3.0890782
Log Pis Max                  12.114471
Log Pis Min                  -6.4618683
Policy mu Mean               0.104387425
Policy mu Std                0.6483945
Policy mu Max                2.718139
Policy mu Min                -2.3825102
Policy log std Mean          -1.2009068
Policy log std Std           0.32703406
Policy log std Max           0.046611667
Policy log std Min           -2.6906893
Z mean eval                  0.9129518
Z variance eval              0.31317917
total_rewards                [5143.63316004  581.45187487 4904.31197774 4965.3360208  4874.68372078
 5123.66309847 2272.92587575 4755.02043849 5064.0269307  4948.09393487]
total_rewards_mean           4263.3147032504585
total_rewards_std            1471.809845981901
total_rewards_max            5143.633160044643
total_rewards_min            581.4518748673884
Number of train steps total  1696000
Number of env steps total    3006452
Number of rollouts total     0
Train Time (s)               208.58008484402671
(Previous) Eval Time (s)     44.80583681585267
Sample Time (s)              9.970865356270224
Epoch Time (s)               263.3567870161496
Total Train Time (s)         95492.17834231118
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:43:14.766853 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #423 | Epoch Duration: 263.4738006591797
2020-01-12 18:43:14.767101 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91396844
Z variance train             0.31164104
KL Divergence                9.875576
KL Loss                      0.9875576
QF Loss                      741.66797
VF Loss                      126.850914
Policy Loss                  -1520.9736
Q Predictions Mean           1515.2992
Q Predictions Std            339.44315
Q Predictions Max            2020.8372
Q Predictions Min            323.03207
V Predictions Mean           1522.4489
V Predictions Std            339.5584
V Predictions Max            2021.7216
V Predictions Min            331.70355
Log Pis Mean                 1.660099
Log Pis Std                  2.9466827
Log Pis Max                  10.444415
Log Pis Min                  -8.111516
Policy mu Mean               0.091545254
Policy mu Std                0.7088115
Policy mu Max                2.5929394
Policy mu Min                -2.5066564
Policy log std Mean          -1.1323094
Policy log std Std           0.32605228
Policy log std Max           -0.12537777
Policy log std Min           -2.68183
Z mean eval                  1.1450177
Z variance eval              0.21819928
total_rewards                [4988.5836942   478.2067412  4741.16191862 4772.12992702 4854.84977391
 4644.87892838 4890.46473756 4840.79856618 4640.7686424  4878.37184941]
total_rewards_mean           4373.021477888281
total_rewards_std            1302.4211710195273
total_rewards_max            4988.583694202262
total_rewards_min            478.20674119953287
Number of train steps total  1700000
Number of env steps total    3017740
Number of rollouts total     0
Train Time (s)               201.47488322667778
(Previous) Eval Time (s)     42.152337837964296
Sample Time (s)              10.054169314913452
Epoch Time (s)               253.68139037955552
Total Train Time (s)         95746.05944322608
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:47:28.675192 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #424 | Epoch Duration: 253.90785241127014
2020-01-12 18:47:28.675561 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1408695
Z variance train             0.21748981
KL Divergence                10.4246235
KL Loss                      1.0424623
QF Loss                      20958.508
VF Loss                      322.3593
Policy Loss                  -1554.4724
Q Predictions Mean           1548.3186
Q Predictions Std            348.49677
Q Predictions Max            2073.9832
Q Predictions Min            369.27744
V Predictions Mean           1568.3899
V Predictions Std            349.43402
V Predictions Max            2102.9253
V Predictions Min            380.22855
Log Pis Mean                 2.1629372
Log Pis Std                  2.932943
Log Pis Max                  12.176332
Log Pis Min                  -8.805031
Policy mu Mean               0.14723991
Policy mu Std                0.7501059
Policy mu Max                2.5531259
Policy mu Min                -2.5281227
Policy log std Mean          -1.1186844
Policy log std Std           0.3274829
Policy log std Max           -0.22576082
Policy log std Min           -2.7045727
Z mean eval                  1.2720301
Z variance eval              0.095452026
total_rewards                [3324.69397297 5332.24820428 5164.28913744 5095.1051498   260.28807891
 3208.48843749  115.83097349 4993.14245278 2618.36108441 5379.48967642]
total_rewards_mean           3549.19371679908
total_rewards_std            1930.0372941392272
total_rewards_max            5379.489676416763
total_rewards_min            115.83097348753766
Number of train steps total  1704000
Number of env steps total    3027958
Number of rollouts total     0
Train Time (s)               200.97883694712073
(Previous) Eval Time (s)     32.058706656098366
Sample Time (s)              10.19384285621345
Epoch Time (s)               243.23138645943254
Total Train Time (s)         95989.39049428469
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:51:32.008846 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #425 | Epoch Duration: 243.33301401138306
2020-01-12 18:51:32.009054 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.302821
Z variance train             0.09306993
KL Divergence                12.623396
KL Loss                      1.2623396
QF Loss                      562.7307
VF Loss                      198.06209
Policy Loss                  -1469.2767
Q Predictions Mean           1462.4448
Q Predictions Std            360.75253
Q Predictions Max            1983.1304
Q Predictions Min            286.67728
V Predictions Mean           1460.3921
V Predictions Std            357.177
V Predictions Max            1987.439
V Predictions Min            295.68185
Log Pis Mean                 1.6490116
Log Pis Std                  2.9244568
Log Pis Max                  11.587092
Log Pis Min                  -7.3441715
Policy mu Mean               0.06453798
Policy mu Std                0.68858457
Policy mu Max                2.3316112
Policy mu Min                -2.8789494
Policy log std Mean          -1.150568
Policy log std Std           0.3042951
Policy log std Max           -0.23332632
Policy log std Min           -2.2312534
Z mean eval                  0.90707684
Z variance eval              0.07769356
total_rewards                [4976.02225642 5207.3749968  5085.76841429  706.18085858 4745.8506082
  363.43423878 4899.4222426   663.97779769 1092.34745023 5111.57449538]
total_rewards_mean           3285.195335897788
total_rewards_std            2115.1360172510917
total_rewards_max            5207.374996804048
total_rewards_min            363.43423878075293
Number of train steps total  1708000
Number of env steps total    3039958
Number of rollouts total     0
Train Time (s)               206.7114064451307
(Previous) Eval Time (s)     38.068808008916676
Sample Time (s)              9.106661179568619
Epoch Time (s)               253.886875633616
Total Train Time (s)         96243.36783929588
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:55:45.990157 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #426 | Epoch Duration: 253.9809422492981
2020-01-12 18:55:45.990345 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9003832
Z variance train             0.07775155
KL Divergence                13.164253
KL Loss                      1.3164253
QF Loss                      566.67566
VF Loss                      537.3021
Policy Loss                  -1514.4587
Q Predictions Mean           1509.5166
Q Predictions Std            332.38446
Q Predictions Max            2009.0123
Q Predictions Min            309.07007
V Predictions Mean           1532.5632
V Predictions Std            332.94955
V Predictions Max            2033.1669
V Predictions Min            322.37393
Log Pis Mean                 2.0306382
Log Pis Std                  3.0666704
Log Pis Max                  14.303915
Log Pis Min                  -6.4378586
Policy mu Mean               0.10595718
Policy mu Std                0.679901
Policy mu Max                3.032064
Policy mu Min                -2.7206635
Policy log std Mean          -1.1809268
Policy log std Std           0.3192427
Policy log std Max           -0.10055566
Policy log std Min           -2.5386794
Z mean eval                  0.9502984
Z variance eval              0.032827683
total_rewards                [4892.23830301 2741.24468867 5155.86813933 4006.23551825 4629.85061573
 3108.08214663 2618.26345804   18.69943447 5400.73043021 5290.5438402 ]
total_rewards_mean           3786.1756574538244
total_rewards_std            1607.4558820412808
total_rewards_max            5400.730430211437
total_rewards_min            18.699434468604498
Number of train steps total  1712000
Number of env steps total    3051666
Number of rollouts total     0
Train Time (s)               208.31038887193426
(Previous) Eval Time (s)     33.28861968545243
Sample Time (s)              10.534793538041413
Epoch Time (s)               252.1338020954281
Total Train Time (s)         96495.59470801195
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:59:58.220961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #427 | Epoch Duration: 252.23047351837158
2020-01-12 18:59:58.221143 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94627905
Z variance train             0.032995977
KL Divergence                15.341167
KL Loss                      1.5341167
QF Loss                      23663.195
VF Loss                      81.689865
Policy Loss                  -1492.8125
Q Predictions Mean           1486.3823
Q Predictions Std            380.58786
Q Predictions Max            1982.603
Q Predictions Min            298.3269
V Predictions Mean           1491.6493
V Predictions Std            380.2416
V Predictions Max            1983.9523
V Predictions Min            288.3569
Log Pis Mean                 1.7180464
Log Pis Std                  2.8322854
Log Pis Max                  11.368597
Log Pis Min                  -6.1265535
Policy mu Mean               0.11191755
Policy mu Std                0.66302145
Policy mu Max                2.5993814
Policy mu Min                -2.7791653
Policy log std Mean          -1.1861017
Policy log std Std           0.31246358
Policy log std Max           0.13549566
Policy log std Min           -2.405644
Z mean eval                  1.0012614
Z variance eval              0.097904846
total_rewards                [5139.93266015 5080.08899823 5191.62525269 5284.91704182 5358.83730999
 5149.15758709 5332.68267987 1430.30545786 5176.17388735 5119.63943391]
total_rewards_mean           4826.336030896989
total_rewards_std            1135.432144022972
total_rewards_max            5358.837309985864
total_rewards_min            1430.305457857135
Number of train steps total  1716000
Number of env steps total    3062505
Number of rollouts total     0
Train Time (s)               199.79132141312584
(Previous) Eval Time (s)     41.923505143262446
Sample Time (s)              9.478313217870891
Epoch Time (s)               251.19313977425918
Total Train Time (s)         96747.10637924075
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:04:09.737986 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #428 | Epoch Duration: 251.516672372818
2020-01-12 19:04:09.738237 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0055501
Z variance train             0.09794238
KL Divergence                13.758226
KL Loss                      1.3758227
QF Loss                      2073.1777
VF Loss                      292.7712
Policy Loss                  -1503.2069
Q Predictions Mean           1493.0537
Q Predictions Std            322.77737
Q Predictions Max            2006.2379
Q Predictions Min            304.60077
V Predictions Mean           1510.8052
V Predictions Std            319.34048
V Predictions Max            2003.7068
V Predictions Min            306.61295
Log Pis Mean                 1.7902851
Log Pis Std                  2.9350786
Log Pis Max                  14.460154
Log Pis Min                  -6.9206543
Policy mu Mean               0.14206177
Policy mu Std                0.6658315
Policy mu Max                2.9466357
Policy mu Min                -2.4726782
Policy log std Mean          -1.199589
Policy log std Std           0.33768082
Policy log std Max           0.023545027
Policy log std Min           -2.4629877
Z mean eval                  0.90053874
Z variance eval              0.6810883
total_rewards                [2079.59895635 2852.14492771  148.94750153 4651.14148966 1073.64080499
 5087.60480616 2001.41295392 1283.36172427 4840.03981587 4894.79056397]
total_rewards_mean           2891.268354441749
total_rewards_std            1749.1282543740795
total_rewards_max            5087.604806164012
total_rewards_min            148.94750152836792
Number of train steps total  1720000
Number of env steps total    3073805
Number of rollouts total     0
Train Time (s)               206.49249507300556
(Previous) Eval Time (s)     27.325000821147114
Sample Time (s)              9.406361686531454
Epoch Time (s)               243.22385758068413
Total Train Time (s)         96990.41421204386
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:13.049852 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #429 | Epoch Duration: 243.3114354610443
2020-01-12 19:08:13.050072 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88812435
Z variance train             0.68314373
KL Divergence                10.192292
KL Loss                      1.0192293
QF Loss                      429.73114
VF Loss                      186.2965
Policy Loss                  -1651.9789
Q Predictions Mean           1643.6101
Q Predictions Std            343.9045
Q Predictions Max            2124.8694
Q Predictions Min            343.67252
V Predictions Mean           1660.3217
V Predictions Std            344.04544
V Predictions Max            2113.0085
V Predictions Min            347.90967
Log Pis Mean                 1.915312
Log Pis Std                  3.3562744
Log Pis Max                  26.415058
Log Pis Min                  -6.066463
Policy mu Mean               0.17143546
Policy mu Std                0.74007565
Policy mu Max                2.901154
Policy mu Min                -4.3738217
Policy log std Mean          -1.1317946
Policy log std Std           0.31176552
Policy log std Max           -0.23872006
Policy log std Min           -2.6375048
Z mean eval                  0.8929127
Z variance eval              0.121445015
total_rewards                [5241.61726864 5185.38191107 5077.80105018 5289.95383568 2164.59054628
 5131.25267395 5062.31952065 5153.15403821 5266.83728588 5077.56427145]
total_rewards_mean           4865.0472401983825
total_rewards_std            903.4423824447528
total_rewards_max            5289.953835684856
total_rewards_min            2164.590546282498
Number of train steps total  1724000
Number of env steps total    3085534
Number of rollouts total     0
Train Time (s)               207.43649662286043
(Previous) Eval Time (s)     40.954294831026345
Sample Time (s)              11.07676895847544
Epoch Time (s)               259.4675604123622
Total Train Time (s)         97249.96792928595
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:12:32.608184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #430 | Epoch Duration: 259.5579454898834
2020-01-12 19:12:32.608372 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.893171
Z variance train             0.12104075
KL Divergence                11.494812
KL Loss                      1.1494812
QF Loss                      390.9886
VF Loss                      124.655174
Policy Loss                  -1586.6191
Q Predictions Mean           1579.2131
Q Predictions Std            277.17413
Q Predictions Max            2089.3745
Q Predictions Min            371.1356
V Predictions Mean           1582.326
V Predictions Std            274.53375
V Predictions Max            2071.1187
V Predictions Min            357.7448
Log Pis Mean                 1.9747425
Log Pis Std                  2.8195415
Log Pis Max                  12.271246
Log Pis Min                  -8.606589
Policy mu Mean               0.118615344
Policy mu Std                0.6761648
Policy mu Max                2.5650089
Policy mu Min                -2.3143148
Policy log std Mean          -1.197787
Policy log std Std           0.29943222
Policy log std Max           -0.11576128
Policy log std Min           -2.6050987
Z mean eval                  0.93882036
Z variance eval              0.43314546
total_rewards                [5042.19226413 4708.64192608 5217.23702603 4941.6375744  5312.44592183
 4780.87771343 5132.64175427 5045.5492277  5384.20166538 5211.81961372]
total_rewards_mean           5077.724468695536
total_rewards_std            208.48044233215026
total_rewards_max            5384.201665381358
total_rewards_min            4708.641926076037
Number of train steps total  1728000
Number of env steps total    3096745
Number of rollouts total     0
Train Time (s)               203.4901043730788
(Previous) Eval Time (s)     44.067720412276685
Sample Time (s)              9.70765367290005
Epoch Time (s)               257.26547845825553
Total Train Time (s)         97507.32281177863
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:16:49.966822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #431 | Epoch Duration: 257.35829496383667
2020-01-12 19:16:49.967009 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93810827
Z variance train             0.43214375
KL Divergence                12.367323
KL Loss                      1.2367324
QF Loss                      634.40344
VF Loss                      101.7246
Policy Loss                  -1429.2572
Q Predictions Mean           1419.8003
Q Predictions Std            323.3081
Q Predictions Max            1943.0219
Q Predictions Min            358.6978
V Predictions Mean           1428.4607
V Predictions Std            320.46957
V Predictions Max            1946.8252
V Predictions Min            364.61926
Log Pis Mean                 2.1391654
Log Pis Std                  2.7227645
Log Pis Max                  12.501831
Log Pis Min                  -6.2968154
Policy mu Mean               0.101838216
Policy mu Std                0.6924238
Policy mu Max                2.6816752
Policy mu Min                -2.6229994
Policy log std Mean          -1.2171364
Policy log std Std           0.33503887
Policy log std Max           -0.24591959
Policy log std Min           -2.5977712
Z mean eval                  0.9555067
Z variance eval              0.124555945
total_rewards                [5138.02288819   65.06303893 5257.58783306 5137.66948898  846.84183716
 5303.75461831 5250.81450342 5459.11696042 5071.19782689 5323.476229  ]
total_rewards_mean           4285.354522437055
total_rewards_std            1925.4913091145986
total_rewards_max            5459.11696042262
total_rewards_min            65.06303893136692
Number of train steps total  1732000
Number of env steps total    3107927
Number of rollouts total     0
Train Time (s)               201.55530168302357
(Previous) Eval Time (s)     40.10741873178631
Sample Time (s)              8.84616702562198
Epoch Time (s)               250.50888744043186
Total Train Time (s)         97757.94038067665
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:21:00.590343 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #432 | Epoch Duration: 250.6231815814972
2020-01-12 19:21:00.590569 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95903045
Z variance train             0.124799654
KL Divergence                12.8451185
KL Loss                      1.2845119
QF Loss                      532.8773
VF Loss                      2343.5686
Policy Loss                  -1579.192
Q Predictions Mean           1574.0894
Q Predictions Std            297.35074
Q Predictions Max            2047.9901
Q Predictions Min            118.33668
V Predictions Mean           1578.8904
V Predictions Std            280.38446
V Predictions Max            2046.9633
V Predictions Min            452.7093
Log Pis Mean                 1.9897615
Log Pis Std                  3.3967688
Log Pis Max                  19.162424
Log Pis Min                  -7.85472
Policy mu Mean               0.045536906
Policy mu Std                0.7163256
Policy mu Max                2.8661618
Policy mu Min                -5.0976267
Policy log std Mean          -1.1800649
Policy log std Std           0.3420289
Policy log std Max           0.4878899
Policy log std Min           -3.3789387
Z mean eval                  1.2092427
Z variance eval              0.2518428
total_rewards                [4784.89675261 4906.01050329 1247.62046415 3421.2043263  5048.40917943
 2690.69848101 5124.74672456 2024.25574406 1754.71804674  392.36201945]
total_rewards_mean           3139.4922241605045
total_rewards_std            1672.7574494106286
total_rewards_max            5124.746724560259
total_rewards_min            392.362019445937
Number of train steps total  1736000
Number of env steps total    3118719
Number of rollouts total     0
Train Time (s)               200.7240398270078
(Previous) Eval Time (s)     37.56659420579672
Sample Time (s)              10.006235821638256
Epoch Time (s)               248.29686985444278
Total Train Time (s)         98006.33204375999
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:25:08.988765 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #433 | Epoch Duration: 248.39795994758606
2020-01-12 19:25:08.989117 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2087214
Z variance train             0.25241888
KL Divergence                10.485001
KL Loss                      1.0485001
QF Loss                      412.115
VF Loss                      108.099075
Policy Loss                  -1463.0511
Q Predictions Mean           1457.1353
Q Predictions Std            274.50912
Q Predictions Max            1944.0013
Q Predictions Min            409.97568
V Predictions Mean           1466.6244
V Predictions Std            273.3056
V Predictions Max            1919.4249
V Predictions Min            407.72662
Log Pis Mean                 2.0271907
Log Pis Std                  2.8508894
Log Pis Max                  11.379879
Log Pis Min                  -6.5273447
Policy mu Mean               0.07779065
Policy mu Std                0.6751119
Policy mu Max                2.999801
Policy mu Min                -2.759488
Policy log std Mean          -1.23999
Policy log std Std           0.32846352
Policy log std Max           -0.10535276
Policy log std Min           -2.5993786
Z mean eval                  0.98456967
Z variance eval              0.3217663
total_rewards                [5274.50605858 4694.12729843 5347.28580343 5379.9436284  5269.63468149
 5373.23935672 5037.52220607 4301.47955991 4761.48083296 5120.15320569]
total_rewards_mean           5055.93726316813
total_rewards_std            342.82121982155587
total_rewards_max            5379.943628399478
total_rewards_min            4301.47955991227
Number of train steps total  1740000
Number of env steps total    3128329
Number of rollouts total     0
Train Time (s)               207.2767501147464
(Previous) Eval Time (s)     46.775989818852395
Sample Time (s)              10.913035458419472
Epoch Time (s)               264.96577539201826
Total Train Time (s)         98271.39258856932
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:29:34.050730 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #434 | Epoch Duration: 265.0613443851471
2020-01-12 19:29:34.050929 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.981558
Z variance train             0.32019144
KL Divergence                9.43833
KL Loss                      0.943833
QF Loss                      3224.213
VF Loss                      148.69629
Policy Loss                  -1477.007
Q Predictions Mean           1471.2771
Q Predictions Std            300.5764
Q Predictions Max            1965.1218
Q Predictions Min            415.06635
V Predictions Mean           1471.8682
V Predictions Std            298.41022
V Predictions Max            1951.4298
V Predictions Min            404.0783
Log Pis Mean                 1.9018728
Log Pis Std                  2.6222262
Log Pis Max                  12.654652
Log Pis Min                  -6.2552605
Policy mu Mean               0.1020858
Policy mu Std                0.6219419
Policy mu Max                2.1511993
Policy mu Min                -2.2826009
Policy log std Mean          -1.2498009
Policy log std Std           0.29583544
Policy log std Max           -0.33640778
Policy log std Min           -2.671445
Z mean eval                  0.93125665
Z variance eval              0.6348937
total_rewards                [2055.24066828 2737.005552   5085.40895704 1438.79457842 5373.49907344
 5247.97875155 5227.66096588 5258.30178262 2928.86411326 5234.63157494]
total_rewards_mean           4058.7386017436775
total_rewards_std            1492.8730730441189
total_rewards_max            5373.499073438326
total_rewards_min            1438.794578423578
Number of train steps total  1744000
Number of env steps total    3138077
Number of rollouts total     0
Train Time (s)               198.93682325305417
(Previous) Eval Time (s)     37.50444342195988
Sample Time (s)              9.403509964700788
Epoch Time (s)               245.84477663971484
Total Train Time (s)         98517.32333354745
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:33:39.985831 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #435 | Epoch Duration: 245.93475580215454
2020-01-12 19:33:39.986016 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9339547
Z variance train             0.6317921
KL Divergence                7.737462
KL Loss                      0.7737462
QF Loss                      939.92365
VF Loss                      220.47893
Policy Loss                  -1524.6339
Q Predictions Mean           1516.1113
Q Predictions Std            337.9076
Q Predictions Max            2026.1747
Q Predictions Min            407.14462
V Predictions Mean           1527.5254
V Predictions Std            336.04495
V Predictions Max            2025.9874
V Predictions Min            425.0758
Log Pis Mean                 1.5322866
Log Pis Std                  2.781205
Log Pis Max                  11.667093
Log Pis Min                  -10.976551
Policy mu Mean               0.11000197
Policy mu Std                0.6708303
Policy mu Max                2.7014055
Policy mu Min                -2.206488
Policy log std Mean          -1.1726836
Policy log std Std           0.31016725
Policy log std Max           -0.075350404
Policy log std Min           -2.7271912
Z mean eval                  0.9054812
Z variance eval              0.16758305
total_rewards                [5062.82518251 3157.7405814  5141.20050031 5114.53447767 2105.83055695
 5384.48123774 5244.21923861 5233.76835456 5489.07081832 5124.07534152]
total_rewards_mean           4705.774628957965
total_rewards_std            1070.4277196651594
total_rewards_max            5489.0708183185125
total_rewards_min            2105.830556948771
Number of train steps total  1748000
Number of env steps total    3150099
Number of rollouts total     0
Train Time (s)               209.16667294222862
(Previous) Eval Time (s)     38.61346409935504
Sample Time (s)              9.57956761913374
Epoch Time (s)               257.3597046607174
Total Train Time (s)         98774.77206394961
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:37:57.468189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #436 | Epoch Duration: 257.4820137023926
2020-01-12 19:37:57.468427 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9090277
Z variance train             0.16738419
KL Divergence                9.918543
KL Loss                      0.9918543
QF Loss                      769.7148
VF Loss                      229.79451
Policy Loss                  -1504.4974
Q Predictions Mean           1495.6511
Q Predictions Std            336.46362
Q Predictions Max            1996.7172
Q Predictions Min            23.728245
V Predictions Mean           1491.6763
V Predictions Std            330.4059
V Predictions Max            1982.8728
V Predictions Min            402.27847
Log Pis Mean                 1.8635992
Log Pis Std                  2.7671778
Log Pis Max                  15.863698
Log Pis Min                  -5.9478607
Policy mu Mean               0.06277834
Policy mu Std                0.6797184
Policy mu Max                3.1024718
Policy mu Min                -3.2094517
Policy log std Mean          -1.2052974
Policy log std Std           0.30700904
Policy log std Max           -0.17318356
Policy log std Min           -2.8848443
Z mean eval                  0.9762211
Z variance eval              0.17710622
total_rewards                [5196.42302749 5142.98858158 5186.13153766 4106.06380665 2543.79012874
 4845.5933799  5694.85764231  352.72813087 5365.01692636 5222.20820094]
total_rewards_mean           4365.5801362503
total_rewards_std            1587.0505385108286
total_rewards_max            5694.857642309976
total_rewards_min            352.7281308685138
Number of train steps total  1752000
Number of env steps total    3159644
Number of rollouts total     0
Train Time (s)               206.67942837579176
(Previous) Eval Time (s)     38.92831961112097
Sample Time (s)              9.005634515080601
Epoch Time (s)               254.61338250199333
Total Train Time (s)         99029.49907788634
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:42:12.202121 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #437 | Epoch Duration: 254.73350954055786
2020-01-12 19:42:12.202344 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97155416
Z variance train             0.17526679
KL Divergence                10.866056
KL Loss                      1.0866057
QF Loss                      533.5806
VF Loss                      102.63513
Policy Loss                  -1613.56
Q Predictions Mean           1609.4257
Q Predictions Std            285.54697
Q Predictions Max            2087.9346
Q Predictions Min            416.18457
V Predictions Mean           1618.0205
V Predictions Std            285.2976
V Predictions Max            2090.4275
V Predictions Min            435.69482
Log Pis Mean                 1.7804182
Log Pis Std                  2.7143579
Log Pis Max                  10.6575
Log Pis Min                  -5.3812466
Policy mu Mean               0.06890063
Policy mu Std                0.69972205
Policy mu Max                3.0188272
Policy mu Min                -2.4435742
Policy log std Mean          -1.15824
Policy log std Std           0.29295486
Policy log std Max           0.10236132
Policy log std Min           -2.5527797
Z mean eval                  1.0255533
Z variance eval              0.22106516
total_rewards                [5320.61717736 4489.84616677 4317.35770782 1096.97282504 5243.54199215
 5138.12775403 5211.27398451 5308.01709955 5044.12656783 3329.64666531]
total_rewards_mean           4449.952794037744
total_rewards_std            1266.7709056058738
total_rewards_max            5320.617177361628
total_rewards_min            1096.9728250370704
Number of train steps total  1756000
Number of env steps total    3170873
Number of rollouts total     0
Train Time (s)               204.26630818890408
(Previous) Eval Time (s)     37.02680559735745
Sample Time (s)              9.578075510449708
Epoch Time (s)               250.87118929671124
Total Train Time (s)         99280.4668685901
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:46:23.177961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #438 | Epoch Duration: 250.97545313835144
2020-01-12 19:46:23.178152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0256876
Z variance train             0.22109361
KL Divergence                10.103712
KL Loss                      1.0103712
QF Loss                      494.95
VF Loss                      97.99943
Policy Loss                  -1596.9971
Q Predictions Mean           1590.0989
Q Predictions Std            298.76434
Q Predictions Max            2060.273
Q Predictions Min            455.5613
V Predictions Mean           1598.8792
V Predictions Std            296.2754
V Predictions Max            2057.5376
V Predictions Min            463.7951
Log Pis Mean                 1.9207408
Log Pis Std                  3.1925197
Log Pis Max                  18.948112
Log Pis Min                  -7.413909
Policy mu Mean               0.07934119
Policy mu Std                0.7109889
Policy mu Max                2.7678072
Policy mu Min                -3.1166582
Policy log std Mean          -1.1824806
Policy log std Std           0.31923354
Policy log std Max           -0.021415591
Policy log std Min           -2.4531736
Z mean eval                  0.9571066
Z variance eval              0.15783212
total_rewards                [1841.42739779 4685.81082863 4948.52450656 2201.58688623 1322.09185014
 2289.31718801 4814.9126601  -192.49771149  173.71472265 4675.42737263]
total_rewards_mean           2676.031570125793
total_rewards_std            1875.3731685197044
total_rewards_max            4948.524506563923
total_rewards_min            -192.4977114859526
Number of train steps total  1760000
Number of env steps total    3182589
Number of rollouts total     0
Train Time (s)               203.88512769993395
(Previous) Eval Time (s)     33.249613808933645
Sample Time (s)              10.151605006307364
Epoch Time (s)               247.28634651517496
Total Train Time (s)         99527.84622771246
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:50:30.562391 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #439 | Epoch Duration: 247.38409423828125
2020-01-12 19:50:30.562568 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94818723
Z variance train             0.15939793
KL Divergence                10.164502
KL Loss                      1.0164503
QF Loss                      385.52747
VF Loss                      201.58646
Policy Loss                  -1652.9337
Q Predictions Mean           1645.4243
Q Predictions Std            275.92505
Q Predictions Max            2102.921
Q Predictions Min            444.984
V Predictions Mean           1662.8313
V Predictions Std            276.43387
V Predictions Max            2123.3032
V Predictions Min            465.68845
Log Pis Mean                 1.821597
Log Pis Std                  2.8473623
Log Pis Max                  13.717312
Log Pis Min                  -6.4164915
Policy mu Mean               0.07366719
Policy mu Std                0.6950033
Policy mu Max                2.7613733
Policy mu Min                -2.6140757
Policy log std Mean          -1.1632432
Policy log std Std           0.3026082
Policy log std Max           -0.2709973
Policy log std Min           -2.8519711
Z mean eval                  0.816905
Z variance eval              0.40471095
total_rewards                [3220.57123237 4896.05480174 1313.3070458  5048.50936666 2418.40595283
 4814.24865097 2761.33534388 5098.33552729 5132.90169585 2372.85295404]
total_rewards_mean           3707.6522571432956
total_rewards_std            1367.8299501116735
total_rewards_max            5132.901695849474
total_rewards_min            1313.3070457968997
Number of train steps total  1764000
Number of env steps total    3192753
Number of rollouts total     0
Train Time (s)               197.40968730673194
(Previous) Eval Time (s)     21.324953520670533
Sample Time (s)              18.078263302333653
Epoch Time (s)               236.81290412973613
Total Train Time (s)         99764.74869993003
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:54:27.469319 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #440 | Epoch Duration: 236.90660691261292
2020-01-12 19:54:27.469513 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8163848
Z variance train             0.40305313
KL Divergence                8.375407
KL Loss                      0.83754075
QF Loss                      1228.4315
VF Loss                      409.1728
Policy Loss                  -1258.7631
Q Predictions Mean           1252.1895
Q Predictions Std            289.47083
Q Predictions Max            1749.5245
Q Predictions Min            -230.50288
V Predictions Mean           1255.2411
V Predictions Std            278.64484
V Predictions Max            1747.1461
V Predictions Min            301.06308
Log Pis Mean                 1.9304831
Log Pis Std                  3.2692268
Log Pis Max                  17.353693
Log Pis Min                  -9.779679
Policy mu Mean               0.12731536
Policy mu Std                0.6419499
Policy mu Max                2.6845434
Policy mu Min                -2.4901485
Policy log std Mean          -1.2321122
Policy log std Std           0.34250066
Policy log std Max           -0.10191977
Policy log std Min           -2.5235252
Z mean eval                  1.0333266
Z variance eval              0.066192225
total_rewards                [4984.99234454 4794.61985731 2729.06385808 5170.75998785 4968.63290442
 5011.80018669 4986.28572042 5002.85186739  893.74656744 5161.19348115]
total_rewards_mean           4370.39467752777
total_rewards_std            1347.3421054244936
total_rewards_max            5170.759987845875
total_rewards_min            893.7465674366617
Number of train steps total  1768000
Number of env steps total    3203910
Number of rollouts total     0
Train Time (s)               192.13116435008124
(Previous) Eval Time (s)     32.60766010778025
Sample Time (s)              6.923570337705314
Epoch Time (s)               231.6623947955668
Total Train Time (s)         99996.51814878453
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:19.241184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #441 | Epoch Duration: 231.77153754234314
2020-01-12 19:58:19.241322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0319798
Z variance train             0.066394985
KL Divergence                11.423335
KL Loss                      1.1423335
QF Loss                      568.0174
VF Loss                      97.805176
Policy Loss                  -1557.5234
Q Predictions Mean           1549.8237
Q Predictions Std            304.82812
Q Predictions Max            2035.4711
Q Predictions Min            416.0405
V Predictions Mean           1559.9983
V Predictions Std            304.87546
V Predictions Max            2029.7482
V Predictions Min            410.79086
Log Pis Mean                 1.6977183
Log Pis Std                  2.673595
Log Pis Max                  11.392445
Log Pis Min                  -5.90055
Policy mu Mean               0.062709704
Policy mu Std                0.668695
Policy mu Max                2.5546863
Policy mu Min                -2.0697045
Policy log std Mean          -1.1852859
Policy log std Std           0.31747878
Policy log std Max           -0.23800087
Policy log std Min           -2.620495
Z mean eval                  0.9318911
Z variance eval              0.091909476
total_rewards                [5152.17278179 4292.00542336 1818.89380365 4419.62699821  246.70633664
 3270.57011624  329.0914926  5118.20710155 5112.0140693  5200.45989949]
total_rewards_mean           3495.9748022828753
total_rewards_std            1892.8439786562424
total_rewards_max            5200.459899485188
total_rewards_min            246.7063366427911
Number of train steps total  1772000
Number of env steps total    3214332
Number of rollouts total     0
Train Time (s)               194.83701926004142
(Previous) Eval Time (s)     23.17459687916562
Sample Time (s)              6.848882263991982
Epoch Time (s)               224.86049840319902
Total Train Time (s)         100221.46840255056
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:02:04.195532 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #442 | Epoch Duration: 224.95408463478088
2020-01-12 20:02:04.195723 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9323249
Z variance train             0.0920386
KL Divergence                12.373957
KL Loss                      1.2373956
QF Loss                      533.65826
VF Loss                      69.67241
Policy Loss                  -1604.0365
Q Predictions Mean           1596.9788
Q Predictions Std            326.28018
Q Predictions Max            2070.289
Q Predictions Min            424.85727
V Predictions Mean           1603.7847
V Predictions Std            326.67194
V Predictions Max            2070.319
V Predictions Min            409.97382
Log Pis Mean                 2.1689248
Log Pis Std                  3.0144842
Log Pis Max                  12.220856
Log Pis Min                  -6.449832
Policy mu Mean               0.08805066
Policy mu Std                0.69124025
Policy mu Max                2.6151016
Policy mu Min                -2.3103075
Policy log std Mean          -1.1968927
Policy log std Std           0.31491157
Policy log std Max           -0.2456919
Policy log std Min           -2.6262226
Z mean eval                  0.838823
Z variance eval              0.23046836
total_rewards                [5095.523552   1928.68336542  569.29318749   54.13279801 5202.69241782
 5154.84820975 4087.75470459  112.17416569 5202.05814206 5171.01628054]
total_rewards_mean           3257.8176823380295
total_rewards_std            2191.826924918216
total_rewards_max            5202.692417817985
total_rewards_min            54.132798012248884
Number of train steps total  1776000
Number of env steps total    3224940
Number of rollouts total     0
Train Time (s)               192.04316974198446
(Previous) Eval Time (s)     18.496782650239766
Sample Time (s)              6.9004525686614215
Epoch Time (s)               217.44040496088564
Total Train Time (s)         100439.009246659
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:05:41.743425 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #443 | Epoch Duration: 217.54754304885864
2020-01-12 20:05:41.743663 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8370023
Z variance train             0.23236477
KL Divergence                11.376915
KL Loss                      1.1376915
QF Loss                      363.11298
VF Loss                      92.35589
Policy Loss                  -1596.7854
Q Predictions Mean           1587.7683
Q Predictions Std            264.9222
Q Predictions Max            2060.0032
Q Predictions Min            411.72427
V Predictions Mean           1597.1594
V Predictions Std            263.82346
V Predictions Max            2051.4045
V Predictions Min            407.49265
Log Pis Mean                 1.7480693
Log Pis Std                  2.567383
Log Pis Max                  9.736983
Log Pis Min                  -5.1682854
Policy mu Mean               0.15041374
Policy mu Std                0.68906283
Policy mu Max                2.5557876
Policy mu Min                -2.3810987
Policy log std Mean          -1.1529143
Policy log std Std           0.30559596
Policy log std Max           -0.103385925
Policy log std Min           -2.2784545
Z mean eval                  1.170509
Z variance eval              0.06485602
total_rewards                [3100.57388008 5358.66975742 1227.13655493 5176.29171874 5122.19824211
  633.23867249 1260.80420245 5082.1330878  2156.36959852 5217.86490331]
total_rewards_mean           3433.5280617858853
total_rewards_std            1861.968434953123
total_rewards_max            5358.669757420248
total_rewards_min            633.2386724929968
Number of train steps total  1780000
Number of env steps total    3236339
Number of rollouts total     0
Train Time (s)               192.2427293569781
(Previous) Eval Time (s)     22.72322159167379
Sample Time (s)              6.972655814606696
Epoch Time (s)               221.93860676325858
Total Train Time (s)         100661.0632995367
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:09:23.801265 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #444 | Epoch Duration: 222.05742692947388
2020-01-12 20:09:23.801453 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608444
Z variance train             0.064696744
KL Divergence                14.495939
KL Loss                      1.4495939
QF Loss                      337.934
VF Loss                      91.423355
Policy Loss                  -1589.4092
Q Predictions Mean           1580.4207
Q Predictions Std            324.98624
Q Predictions Max            2076.298
Q Predictions Min            402.1997
V Predictions Mean           1591.0804
V Predictions Std            325.19193
V Predictions Max            2081.0818
V Predictions Min            387.71222
Log Pis Mean                 1.6719844
Log Pis Std                  2.9187748
Log Pis Max                  12.223591
Log Pis Min                  -7.505795
Policy mu Mean               0.05359567
Policy mu Std                0.7009269
Policy mu Max                2.7559836
Policy mu Min                -2.5485353
Policy log std Mean          -1.1599653
Policy log std Std           0.314256
Policy log std Max           -0.27811706
Policy log std Min           -2.7238564
Z mean eval                  0.98733205
Z variance eval              0.07552461
total_rewards                [2424.43247984 2996.45723454 5259.87674044 5225.02665433 2090.9204395
  896.84851682 5083.95915483 5088.08717604 4004.06855769  730.90626501]
total_rewards_mean           3380.058321904048
total_rewards_std            1704.530416403694
total_rewards_max            5259.876740443062
total_rewards_min            730.9062650053589
Number of train steps total  1784000
Number of env steps total    3248111
Number of rollouts total     0
Train Time (s)               192.6803536801599
(Previous) Eval Time (s)     18.568439847789705
Sample Time (s)              6.897568568587303
Epoch Time (s)               218.1463620965369
Total Train Time (s)         100879.33079049969
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:13:02.074523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #445 | Epoch Duration: 218.2728774547577
2020-01-12 20:13:02.074852 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9881255
Z variance train             0.07568714
KL Divergence                12.455371
KL Loss                      1.2455372
QF Loss                      664.06287
VF Loss                      221.98135
Policy Loss                  -1529.4707
Q Predictions Mean           1520.0381
Q Predictions Std            330.23083
Q Predictions Max            2034.6816
Q Predictions Min            375.01117
V Predictions Mean           1521.6582
V Predictions Std            327.32242
V Predictions Max            2020.0337
V Predictions Min            383.92743
Log Pis Mean                 1.689255
Log Pis Std                  2.897521
Log Pis Max                  18.14386
Log Pis Min                  -7.334915
Policy mu Mean               0.07302502
Policy mu Std                0.6877437
Policy mu Max                3.4007428
Policy mu Min                -2.6427045
Policy log std Mean          -1.1596347
Policy log std Std           0.3195797
Policy log std Max           0.17592311
Policy log std Min           -2.3533807
Z mean eval                  0.88245994
Z variance eval              0.059254695
total_rewards                [5133.36130342   14.18100182 5367.89221052 4992.8810017  5320.20299809
 5193.63230305   59.24679838 5428.62759099 5288.8390388  5084.58006414]
total_rewards_mean           4188.344431092627
total_rewards_std            2079.641629477904
total_rewards_max            5428.627590992899
total_rewards_min            14.181001824983616
Number of train steps total  1788000
Number of env steps total    3260111
Number of rollouts total     0
Train Time (s)               191.3798458110541
(Previous) Eval Time (s)     26.7503163209185
Sample Time (s)              5.927389334421605
Epoch Time (s)               224.05755146639422
Total Train Time (s)         101103.48088271217
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:16:46.229653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #446 | Epoch Duration: 224.15455746650696
2020-01-12 20:16:46.229864 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88331634
Z variance train             0.059590615
KL Divergence                13.909703
KL Loss                      1.3909703
QF Loss                      1671.9884
VF Loss                      298.73587
Policy Loss                  -1608.3892
Q Predictions Mean           1599.9392
Q Predictions Std            347.62787
Q Predictions Max            2074.8481
Q Predictions Min            408.90784
V Predictions Mean           1604.636
V Predictions Std            340.20517
V Predictions Max            2068.309
V Predictions Min            396.016
Log Pis Mean                 1.7212396
Log Pis Std                  3.1479285
Log Pis Max                  17.36316
Log Pis Min                  -7.332361
Policy mu Mean               0.06664997
Policy mu Std                0.6843868
Policy mu Max                2.581094
Policy mu Min                -2.375503
Policy log std Mean          -1.1928514
Policy log std Std           0.34107924
Policy log std Max           -0.047658563
Policy log std Min           -3.5092638
Z mean eval                  0.83758724
Z variance eval              0.109646186
total_rewards                [3712.9559915   893.70345807 4376.26671933 4485.32431966  113.02748752
 4889.29458659 5464.62652993  196.3806659  5038.23672509 5473.71572356]
total_rewards_mean           3464.3532207142516
total_rewards_std            2073.6740029132475
total_rewards_max            5473.715723556968
total_rewards_min            113.02748752312604
Number of train steps total  1792000
Number of env steps total    3271179
Number of rollouts total     0
Train Time (s)               192.16885332996026
(Previous) Eval Time (s)     23.26720786932856
Sample Time (s)              7.409317379817367
Epoch Time (s)               222.84537857910618
Total Train Time (s)         101326.417470288
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:20:29.187359 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #447 | Epoch Duration: 222.957350730896
2020-01-12 20:20:29.187499 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8304777
Z variance train             0.1101826
KL Divergence                12.3972225
KL Loss                      1.2397223
QF Loss                      379.84006
VF Loss                      237.53914
Policy Loss                  -1615.9359
Q Predictions Mean           1611.4757
Q Predictions Std            282.09283
Q Predictions Max            2090.8892
Q Predictions Min            389.16394
V Predictions Mean           1628.2537
V Predictions Std            283.9164
V Predictions Max            2099.1404
V Predictions Min            389.8354
Log Pis Mean                 1.9888182
Log Pis Std                  2.8694627
Log Pis Max                  12.458681
Log Pis Min                  -5.9857187
Policy mu Mean               0.12449565
Policy mu Std                0.6900378
Policy mu Max                3.1729853
Policy mu Min                -2.907253
Policy log std Mean          -1.1850061
Policy log std Std           0.30077842
Policy log std Max           0.008328199
Policy log std Min           -2.5771961
Z mean eval                  0.95114815
Z variance eval              0.10935521
total_rewards                [ 365.30468483 4753.95191447 5236.67050077 4900.45383969 4718.99452258
 5323.1152815   636.81800182 4715.79971164 5128.51386184 5094.42806381]
total_rewards_mean           4087.4050382946225
total_rewards_std            1805.6991453755636
total_rewards_max            5323.11528149525
total_rewards_min            365.3046848287532
Number of train steps total  1796000
Number of env steps total    3281886
Number of rollouts total     0
Train Time (s)               193.4810869898647
(Previous) Eval Time (s)     23.817434502765536
Sample Time (s)              6.858266689348966
Epoch Time (s)               224.1567881819792
Total Train Time (s)         101550.68296596454
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:13.440032 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #448 | Epoch Duration: 224.2523729801178
2020-01-12 20:24:13.440265 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9452046
Z variance train             0.109075405
KL Divergence                13.471153
KL Loss                      1.3471154
QF Loss                      454.2157
VF Loss                      302.3424
Policy Loss                  -1611.1332
Q Predictions Mean           1605.824
Q Predictions Std            302.65588
Q Predictions Max            2092.8318
Q Predictions Min            386.56317
V Predictions Mean           1623.4689
V Predictions Std            300.27374
V Predictions Max            2086.3777
V Predictions Min            382.2367
Log Pis Mean                 2.010445
Log Pis Std                  2.6614149
Log Pis Max                  13.391203
Log Pis Min                  -7.286105
Policy mu Mean               0.13886428
Policy mu Std                0.6636012
Policy mu Max                2.6994538
Policy mu Min                -2.673234
Policy log std Mean          -1.2375278
Policy log std Std           0.3150281
Policy log std Max           -0.097785115
Policy log std Min           -2.7108302
Z mean eval                  0.9099935
Z variance eval              0.32975775
total_rewards                [1403.88724807 5307.46723049 1997.84766787 4702.98108008 4752.86041479
 5450.2895086    44.60708311 4976.80735483  666.87010024   94.49651626]
total_rewards_mean           2939.8114204327867
total_rewards_std            2175.872392527836
total_rewards_max            5450.289508602821
total_rewards_min            44.60708310754639
Number of train steps total  1800000
Number of env steps total    3292914
Number of rollouts total     0
Train Time (s)               192.8384551089257
(Previous) Eval Time (s)     19.33356093009934
Sample Time (s)              6.889912587124854
Epoch Time (s)               219.0619286261499
Total Train Time (s)         101769.8360726717
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:52.595686 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #449 | Epoch Duration: 219.15528535842896
2020-01-12 20:27:52.595828 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9070803
Z variance train             0.32976562
KL Divergence                8.784528
KL Loss                      0.8784528
QF Loss                      459.01678
VF Loss                      102.2126
Policy Loss                  -1693.576
Q Predictions Mean           1684.0553
Q Predictions Std            338.12033
Q Predictions Max            2180.5989
Q Predictions Min            414.27582
V Predictions Mean           1692.5464
V Predictions Std            337.42966
V Predictions Max            2172.5293
V Predictions Min            430.04553
Log Pis Mean                 2.183505
Log Pis Std                  2.7536361
Log Pis Max                  17.795938
Log Pis Min                  -5.7019153
Policy mu Mean               0.13406764
Policy mu Std                0.7015074
Policy mu Max                3.70368
Policy mu Min                -3.0446582
Policy log std Mean          -1.1935735
Policy log std Std           0.31370068
Policy log std Max           0.0742147
Policy log std Min           -2.7609646
Z mean eval                  1.0340521
Z variance eval              0.066898376
total_rewards                [5359.45730635 5280.27812929 4803.51577095 4987.96528586 4708.11392776
  453.51217359 5409.79054639 3895.81710397 2702.08533837  805.19755076]
total_rewards_mean           3840.573313330287
total_rewards_std            1783.9139673422658
total_rewards_max            5409.790546394234
total_rewards_min            453.5121735863647
Number of train steps total  1804000
Number of env steps total    3303785
Number of rollouts total     0
Train Time (s)               193.26853356603533
(Previous) Eval Time (s)     27.977983916178346
Sample Time (s)              6.734706314280629
Epoch Time (s)               227.9812237964943
Total Train Time (s)         101997.90605127439
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:31:40.669960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #450 | Epoch Duration: 228.07401371002197
2020-01-12 20:31:40.670158 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0294558
Z variance train             0.066844836
KL Divergence                12.6663
KL Loss                      1.26663
QF Loss                      310.46896
VF Loss                      172.61578
Policy Loss                  -1627.6802
Q Predictions Mean           1619.925
Q Predictions Std            299.8824
Q Predictions Max            2099.7195
Q Predictions Min            399.22763
V Predictions Mean           1634.9531
V Predictions Std            296.45197
V Predictions Max            2095.3977
V Predictions Min            409.9769
Log Pis Mean                 1.9153771
Log Pis Std                  2.8805923
Log Pis Max                  11.665289
Log Pis Min                  -4.991656
Policy mu Mean               0.08692023
Policy mu Std                0.7147801
Policy mu Max                3.0264752
Policy mu Min                -2.6828568
Policy log std Mean          -1.1631134
Policy log std Std           0.32356167
Policy log std Max           -0.07145417
Policy log std Min           -2.6931062
Z mean eval                  0.96435916
Z variance eval              0.11032635
total_rewards                [2953.95921819 3645.85059601 5433.49824618 4753.99432071 1832.20494358
 4985.39594716 5065.03990216 5036.11247438 5057.1489197  5175.6006499 ]
total_rewards_mean           4393.880521796842
total_rewards_std            1125.5847137824921
total_rewards_max            5433.498246176892
total_rewards_min            1832.204943582255
Number of train steps total  1808000
Number of env steps total    3314306
Number of rollouts total     0
Train Time (s)               191.13438164489344
(Previous) Eval Time (s)     30.003476764075458
Sample Time (s)              6.97196626663208
Epoch Time (s)               228.10982467560098
Total Train Time (s)         102226.30985494656
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:35:29.077446 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #451 | Epoch Duration: 228.4071478843689
2020-01-12 20:35:29.077598 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96151733
Z variance train             0.11153994
KL Divergence                11.517828
KL Loss                      1.1517829
QF Loss                      347.93494
VF Loss                      118.83704
Policy Loss                  -1614.0837
Q Predictions Mean           1607.3013
Q Predictions Std            324.55756
Q Predictions Max            2108.0657
Q Predictions Min            406.89417
V Predictions Mean           1620.5906
V Predictions Std            325.98233
V Predictions Max            2113.7825
V Predictions Min            414.93225
Log Pis Mean                 1.629782
Log Pis Std                  2.6661477
Log Pis Max                  11.632427
Log Pis Min                  -7.7187843
Policy mu Mean               0.13729964
Policy mu Std                0.6858455
Policy mu Max                2.1458795
Policy mu Min                -2.4697258
Policy log std Mean          -1.1763299
Policy log std Std           0.31240472
Policy log std Max           -0.2505132
Policy log std Min           -2.5407062
Z mean eval                  0.9487673
Z variance eval              0.1410404
total_rewards                [4987.49855862 4781.94272493 5209.07508768 5444.02197912 5241.18104264
 5363.43196259 1067.60620389 3122.82631576  929.3297536  4623.59922987]
total_rewards_mean           4077.0512858689654
total_rewards_std            1663.1300842761539
total_rewards_max            5444.021979115621
total_rewards_min            929.3297535955948
Number of train steps total  1812000
Number of env steps total    3325583
Number of rollouts total     0
Train Time (s)               191.77749493066221
(Previous) Eval Time (s)     25.17970433505252
Sample Time (s)              6.930576997809112
Epoch Time (s)               223.88777626352385
Total Train Time (s)         102450.43171568215
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:39:13.205634 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #452 | Epoch Duration: 224.1278600692749
2020-01-12 20:39:13.206013 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94857204
Z variance train             0.14047727
KL Divergence                11.447222
KL Loss                      1.1447222
QF Loss                      7244.009
VF Loss                      160.26953
Policy Loss                  -1609.4761
Q Predictions Mean           1600.9943
Q Predictions Std            329.14554
Q Predictions Max            2105.6013
Q Predictions Min            194.09761
V Predictions Mean           1610.3542
V Predictions Std            328.56787
V Predictions Max            2096.3936
V Predictions Min            66.919365
Log Pis Mean                 2.2858582
Log Pis Std                  3.4642951
Log Pis Max                  27.925838
Log Pis Min                  -8.680215
Policy mu Mean               0.0986408
Policy mu Std                0.72582316
Policy mu Max                3.1871114
Policy mu Min                -2.7656019
Policy log std Mean          -1.232588
Policy log std Std           0.35266912
Policy log std Max           -0.19442093
Policy log std Min           -3.405467
Z mean eval                  0.90741885
Z variance eval              0.24599853
total_rewards                [ 232.80578163 5202.20190671 5314.78100737 5210.96322744 3092.79148261
 2530.17205037 3177.52696129 4157.16568291 5127.87468833 5658.56642765]
total_rewards_mean           3970.4849216319826
total_rewards_std            1628.8320875635309
total_rewards_max            5658.566427652311
total_rewards_min            232.80578163341278
Number of train steps total  1816000
Number of env steps total    3335622
Number of rollouts total     0
Train Time (s)               190.9206516109407
(Previous) Eval Time (s)     25.811888969969004
Sample Time (s)              7.3376788310706615
Epoch Time (s)               224.07021941198036
Total Train Time (s)         102674.5949189011
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:42:57.370596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #453 | Epoch Duration: 224.16432070732117
2020-01-12 20:42:57.370744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9104142
Z variance train             0.24464095
KL Divergence                10.274517
KL Loss                      1.0274518
QF Loss                      405.23706
VF Loss                      226.24496
Policy Loss                  -1622.3582
Q Predictions Mean           1613.6084
Q Predictions Std            306.07666
Q Predictions Max            2088.5608
Q Predictions Min            482.23575
V Predictions Mean           1610.6958
V Predictions Std            305.8265
V Predictions Max            2059.1213
V Predictions Min            472.0314
Log Pis Mean                 1.9280168
Log Pis Std                  3.0996993
Log Pis Max                  12.532244
Log Pis Min                  -8.302793
Policy mu Mean               0.09217866
Policy mu Std                0.7323366
Policy mu Max                2.7423756
Policy mu Min                -2.6592922
Policy log std Mean          -1.1596663
Policy log std Std           0.325731
Policy log std Max           0.052102685
Policy log std Min           -2.6921277
Z mean eval                  0.8622471
Z variance eval              0.29385948
total_rewards                [5209.47920318 2536.56423319 5211.51750249 3430.67846839 5174.93282675
  140.17990977 5353.30673866 5099.19426135 5561.0549224  5277.91201516]
total_rewards_mean           4299.48200813673
total_rewards_std            1669.9637163235966
total_rewards_max            5561.054922404611
total_rewards_min            140.17990977242266
Number of train steps total  1820000
Number of env steps total    3345049
Number of rollouts total     0
Train Time (s)               192.53216636134312
(Previous) Eval Time (s)     23.582219702657312
Sample Time (s)              7.414344537071884
Epoch Time (s)               223.5287306010723
Total Train Time (s)         102898.21744681243
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:46:40.999791 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #454 | Epoch Duration: 223.62891697883606
2020-01-12 20:46:41.000002 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8631592
Z variance train             0.29389095
KL Divergence                9.214388
KL Loss                      0.9214388
QF Loss                      18694.852
VF Loss                      97.50534
Policy Loss                  -1503.0475
Q Predictions Mean           1497.4417
Q Predictions Std            280.8703
Q Predictions Max            1947.1765
Q Predictions Min            426.76047
V Predictions Mean           1505.757
V Predictions Std            280.7984
V Predictions Max            1959.9233
V Predictions Min            437.3236
Log Pis Mean                 1.7305536
Log Pis Std                  2.8417478
Log Pis Max                  13.65377
Log Pis Min                  -7.3860626
Policy mu Mean               0.13301873
Policy mu Std                0.63234293
Policy mu Max                2.5617363
Policy mu Min                -2.93349
Policy log std Mean          -1.2185957
Policy log std Std           0.31453016
Policy log std Max           -0.17917371
Policy log std Min           -2.624769
Z mean eval                  0.9104276
Z variance eval              0.03815535
total_rewards                [4992.66685534  820.90747492  422.36879158 2213.13297786 4493.1373642
  424.9748621  3114.05166909 3945.81861634 3348.60737133 3281.83968482]
total_rewards_mean           2705.750566758341
total_rewards_std            1583.838233262632
total_rewards_max            4992.666855339407
total_rewards_min            422.3687915753721
Number of train steps total  1824000
Number of env steps total    3356020
Number of rollouts total     0
Train Time (s)               191.07252871291712
(Previous) Eval Time (s)     18.594017905648798
Sample Time (s)              7.508019851986319
Epoch Time (s)               217.17456647055224
Total Train Time (s)         103115.49584700167
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:50:18.282825 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #455 | Epoch Duration: 217.2826840877533
2020-01-12 20:50:18.282967 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9103216
Z variance train             0.03806808
KL Divergence                13.228582
KL Loss                      1.3228582
QF Loss                      421.09338
VF Loss                      78.05513
Policy Loss                  -1663.4811
Q Predictions Mean           1654.7585
Q Predictions Std            260.5067
Q Predictions Max            2133.6438
Q Predictions Min            479.01794
V Predictions Mean           1664.2986
V Predictions Std            256.80142
V Predictions Max            2133.4888
V Predictions Min            488.42914
Log Pis Mean                 2.2468057
Log Pis Std                  3.1366272
Log Pis Max                  13.181254
Log Pis Min                  -6.7729006
Policy mu Mean               0.028210219
Policy mu Std                0.72646767
Policy mu Max                2.677508
Policy mu Min                -2.531365
Policy log std Mean          -1.1734715
Policy log std Std           0.3285854
Policy log std Max           -0.19923794
Policy log std Min           -2.5495472
Z mean eval                  1.083769
Z variance eval              0.15733209
total_rewards                [4375.10258959 5352.75063724 4848.26702132 5541.56791704 4921.92946803
  529.73101765 5209.60206706 5244.09586767 4404.17677108 1545.3060929 ]
total_rewards_mean           4197.252944957809
total_rewards_std            1636.155587374339
total_rewards_max            5541.567917043169
total_rewards_min            529.7310176477263
Number of train steps total  1828000
Number of env steps total    3368105
Number of rollouts total     0
Train Time (s)               192.6536097866483
(Previous) Eval Time (s)     26.35981874819845
Sample Time (s)              7.809300795663148
Epoch Time (s)               226.8227293305099
Total Train Time (s)         103342.58169227885
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:54:05.377372 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #456 | Epoch Duration: 227.09427499771118
2020-01-12 20:54:05.377572 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0808924
Z variance train             0.15347487
KL Divergence                10.459546
KL Loss                      1.0459546
QF Loss                      448.25928
VF Loss                      208.0966
Policy Loss                  -1564.0651
Q Predictions Mean           1552.1865
Q Predictions Std            277.64438
Q Predictions Max            2002.0339
Q Predictions Min            444.47372
V Predictions Mean           1554.0254
V Predictions Std            272.43423
V Predictions Max            1981.6721
V Predictions Min            445.8169
Log Pis Mean                 2.0498188
Log Pis Std                  2.8028798
Log Pis Max                  14.221583
Log Pis Min                  -5.6404333
Policy mu Mean               0.09102946
Policy mu Std                0.6498754
Policy mu Max                2.8758757
Policy mu Min                -2.7261944
Policy log std Mean          -1.2282329
Policy log std Std           0.30542174
Policy log std Max           -0.2886517
Policy log std Min           -2.8158746
Z mean eval                  0.86100566
Z variance eval              0.1335625
total_rewards                [3612.41924682 1877.55107193 4252.35796636 5063.07962497 5264.27771157
 5075.72329083 5043.53516093 5219.05914657 5006.38202068  421.71208287]
total_rewards_mean           4083.6097323520817
total_rewards_std            1578.8136054024822
total_rewards_max            5264.277711567305
total_rewards_min            421.7120828664285
Number of train steps total  1832000
Number of env steps total    3378413
Number of rollouts total     0
Train Time (s)               191.9477936211042
(Previous) Eval Time (s)     26.78195609804243
Sample Time (s)              6.362521818373352
Epoch Time (s)               225.09227153752
Total Train Time (s)         103567.76525822142
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:57:50.569324 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #457 | Epoch Duration: 225.1916115283966
2020-01-12 20:57:50.569471 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86163634
Z variance train             0.13251948
KL Divergence                11.536813
KL Loss                      1.1536813
QF Loss                      375.42493
VF Loss                      131.33408
Policy Loss                  -1686.497
Q Predictions Mean           1677.5454
Q Predictions Std            268.17758
Q Predictions Max            2133.934
Q Predictions Min            489.944
V Predictions Mean           1690.7445
V Predictions Std            268.2917
V Predictions Max            2130.3958
V Predictions Min            488.834
Log Pis Mean                 2.1026478
Log Pis Std                  2.8853707
Log Pis Max                  13.802368
Log Pis Min                  -4.7690973
Policy mu Mean               0.09485674
Policy mu Std                0.72398365
Policy mu Max                4.539757
Policy mu Min                -3.1142843
Policy log std Mean          -1.1665965
Policy log std Std           0.32351902
Policy log std Max           0.0083242655
Policy log std Min           -2.6931157
Z mean eval                  0.90002286
Z variance eval              0.1041799
total_rewards                [5451.67634528 5472.32166692 5397.6112253  1933.34606229  396.39227592
  461.7893587  5151.62917719 3222.95261849 5437.8903529  4847.26392907]
total_rewards_mean           3777.287301205736
total_rewards_std            2005.5877411423082
total_rewards_max            5472.321666915221
total_rewards_min            396.3922759205417
Number of train steps total  1836000
Number of env steps total    3390549
Number of rollouts total     0
Train Time (s)               192.7721193288453
(Previous) Eval Time (s)     27.319653091952205
Sample Time (s)              7.6769214435480535
Epoch Time (s)               227.76869386434555
Total Train Time (s)         103795.62761412468
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:38.437430 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #458 | Epoch Duration: 227.86783695220947
2020-01-12 21:01:38.437629 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89482355
Z variance train             0.10447093
KL Divergence                11.489006
KL Loss                      1.1489006
QF Loss                      1023.5316
VF Loss                      134.85497
Policy Loss                  -1647.2137
Q Predictions Mean           1639.3063
Q Predictions Std            306.3141
Q Predictions Max            2135.966
Q Predictions Min            464.20334
V Predictions Mean           1654.0044
V Predictions Std            304.92685
V Predictions Max            2140.7424
V Predictions Min            476.36478
Log Pis Mean                 2.296261
Log Pis Std                  2.9149525
Log Pis Max                  13.300684
Log Pis Min                  -5.450454
Policy mu Mean               0.06159846
Policy mu Std                0.72322094
Policy mu Max                2.9849696
Policy mu Min                -2.7403584
Policy log std Mean          -1.1992333
Policy log std Std           0.33844045
Policy log std Max           -0.16395617
Policy log std Min           -2.8008814
Z mean eval                  0.9164754
Z variance eval              0.06459238
total_rewards                [4554.30895564 1383.33834471 5147.39559789 5047.48185879 1426.92954384
 5038.93873535  181.14009812 1410.62602598 4114.15324179 5167.50126565]
total_rewards_mean           3347.181366776137
total_rewards_std            1888.6745040874605
total_rewards_max            5167.501265649231
total_rewards_min            181.14009811771763
Number of train steps total  1840000
Number of env steps total    3401720
Number of rollouts total     0
Train Time (s)               191.32080595800653
(Previous) Eval Time (s)     22.421196767129004
Sample Time (s)              6.210063000675291
Epoch Time (s)               219.95206572581083
Total Train Time (s)         104015.762324112
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:05:18.578913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #459 | Epoch Duration: 220.14112448692322
2020-01-12 21:05:18.579119 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9193047
Z variance train             0.06503181
KL Divergence                12.047752
KL Loss                      1.2047752
QF Loss                      1667.6089
VF Loss                      279.00854
Policy Loss                  -1628.4062
Q Predictions Mean           1618.6948
Q Predictions Std            321.00815
Q Predictions Max            2107.6294
Q Predictions Min            477.71188
V Predictions Mean           1616.8673
V Predictions Std            316.63776
V Predictions Max            2097.3386
V Predictions Min            474.9211
Log Pis Mean                 2.173408
Log Pis Std                  3.2849147
Log Pis Max                  17.417353
Log Pis Min                  -5.974184
Policy mu Mean               0.07741493
Policy mu Std                0.73274976
Policy mu Max                2.8619878
Policy mu Min                -2.6509223
Policy log std Mean          -1.1935956
Policy log std Std           0.32410592
Policy log std Max           -0.07121825
Policy log std Min           -2.483252
Z mean eval                  0.8982299
Z variance eval              0.4446865
total_rewards                [5189.89307556 5259.54859427 4582.55920111 5041.24080529 5328.17276615
  617.50546985 5006.2469408   392.54843375 3921.98211047 4966.05457681]
total_rewards_mean           4030.5751974057844
total_rewards_std            1805.1985345513945
total_rewards_max            5328.172766152181
total_rewards_min            392.54843374713164
Number of train steps total  1844000
Number of env steps total    3412900
Number of rollouts total     0
Train Time (s)               195.1311348732561
(Previous) Eval Time (s)     25.981264016591012
Sample Time (s)              16.136975825298578
Epoch Time (s)               237.24937471514568
Total Train Time (s)         104253.16876557982
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:09:15.991323 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #460 | Epoch Duration: 237.41204500198364
2020-01-12 21:09:15.991532 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9018691
Z variance train             0.44559518
KL Divergence                7.3272676
KL Loss                      0.73272675
QF Loss                      531.42914
VF Loss                      185.46219
Policy Loss                  -1582.8044
Q Predictions Mean           1577.44
Q Predictions Std            300.68527
Q Predictions Max            2065.0798
Q Predictions Min            383.50403
V Predictions Mean           1592.926
V Predictions Std            300.83887
V Predictions Max            2069.1746
V Predictions Min            385.8295
Log Pis Mean                 1.6571488
Log Pis Std                  2.9206054
Log Pis Max                  13.162195
Log Pis Min                  -7.2095237
Policy mu Mean               0.022225317
Policy mu Std                0.70492625
Policy mu Max                2.4934626
Policy mu Min                -2.7236378
Policy log std Mean          -1.1444327
Policy log std Std           0.30597973
Policy log std Max           -0.21528804
Policy log std Min           -2.6147647
Z mean eval                  0.83943415
Z variance eval              0.11113329
total_rewards                [ 689.96618058 5266.14223198 4959.25577211 5369.3087491  5356.57068489
 5111.31816537 4849.41517553 4806.25289874 2787.92703941 5403.89082285]
total_rewards_mean           4460.004772055802
total_rewards_std            1453.4602330323992
total_rewards_max            5403.890822848614
total_rewards_min            689.9661805797713
Number of train steps total  1848000
Number of env steps total    3424889
Number of rollouts total     0
Train Time (s)               191.80894538294524
(Previous) Eval Time (s)     29.331263870932162
Sample Time (s)              6.990961028728634
Epoch Time (s)               228.13117028260604
Total Train Time (s)         104481.3968834104
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:13:04.228662 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #461 | Epoch Duration: 228.23698258399963
2020-01-12 21:13:04.228817 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8407928
Z variance train             0.11088737
KL Divergence                10.531733
KL Loss                      1.0531733
QF Loss                      675.3116
VF Loss                      117.66782
Policy Loss                  -1665.2496
Q Predictions Mean           1655.7839
Q Predictions Std            310.31757
Q Predictions Max            2131.0852
Q Predictions Min            487.7831
V Predictions Mean           1660.7458
V Predictions Std            306.40796
V Predictions Max            2102.6265
V Predictions Min            483.5076
Log Pis Mean                 2.106071
Log Pis Std                  2.8557706
Log Pis Max                  11.912407
Log Pis Min                  -4.241203
Policy mu Mean               0.06659494
Policy mu Std                0.70378625
Policy mu Max                2.466541
Policy mu Min                -2.6333742
Policy log std Mean          -1.211649
Policy log std Std           0.3250105
Policy log std Max           -0.31030917
Policy log std Min           -2.624492
Z mean eval                  0.9627129
Z variance eval              0.10652778
total_rewards                [5051.46860755 5129.88127467 5392.92447376 5391.37150898 5265.03452805
 5019.7454061  5546.76753656 5111.8284601  5133.54089082  260.46572143]
total_rewards_mean           4730.302840801813
total_rewards_std            1498.7603463951737
total_rewards_max            5546.767536556585
total_rewards_min            260.4657214340088
Number of train steps total  1852000
Number of env steps total    3434818
Number of rollouts total     0
Train Time (s)               193.25008600391448
(Previous) Eval Time (s)     30.369810015894473
Sample Time (s)              6.881769233383238
Epoch Time (s)               230.5016652531922
Total Train Time (s)         104711.98763098102
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:16:54.823656 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #462 | Epoch Duration: 230.5947048664093
2020-01-12 21:16:54.823800 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9643197
Z variance train             0.106646374
KL Divergence                12.680773
KL Loss                      1.2680773
QF Loss                      22591.918
VF Loss                      153.2992
Policy Loss                  -1685.8224
Q Predictions Mean           1678.2483
Q Predictions Std            307.16125
Q Predictions Max            2198.8245
Q Predictions Min            529.274
V Predictions Mean           1687.9279
V Predictions Std            304.18387
V Predictions Max            2180.4397
V Predictions Min            529.8377
Log Pis Mean                 2.2167785
Log Pis Std                  2.7946794
Log Pis Max                  11.829054
Log Pis Min                  -5.4597607
Policy mu Mean               0.055289812
Policy mu Std                0.7270872
Policy mu Max                2.7217197
Policy mu Min                -2.4609015
Policy log std Mean          -1.1927397
Policy log std Std           0.32242852
Policy log std Max           -0.32147503
Policy log std Min           -2.3438194
Z mean eval                  0.89988565
Z variance eval              0.38785738
total_rewards                [5135.48987298 2522.26602786 5180.93114356 5011.04507128 1438.57656418
 5304.0120018  5301.03444179 2129.91889125 1401.30816999 4821.49471018]
total_rewards_mean           3824.60768948667
total_rewards_std            1626.6992622133125
total_rewards_max            5304.012001803105
total_rewards_min            1401.3081699853944
Number of train steps total  1856000
Number of env steps total    3444471
Number of rollouts total     0
Train Time (s)               193.37095345696434
(Previous) Eval Time (s)     24.571270974818617
Sample Time (s)              7.022144477348775
Epoch Time (s)               224.96436890913174
Total Train Time (s)         104937.04282720154
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:20:39.881575 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #463 | Epoch Duration: 225.05766654014587
2020-01-12 21:20:39.881717 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88386977
Z variance train             0.3839962
KL Divergence                9.239411
KL Loss                      0.92394114
QF Loss                      2137.1187
VF Loss                      95.88411
Policy Loss                  -1615.9719
Q Predictions Mean           1608.582
Q Predictions Std            264.55515
Q Predictions Max            2057.774
Q Predictions Min            542.97455
V Predictions Mean           1619.949
V Predictions Std            257.48077
V Predictions Max            2065.0867
V Predictions Min            548.88354
Log Pis Mean                 1.7681856
Log Pis Std                  2.6911128
Log Pis Max                  11.483316
Log Pis Min                  -7.202899
Policy mu Mean               0.110450685
Policy mu Std                0.6816068
Policy mu Max                2.4636319
Policy mu Min                -2.4094713
Policy log std Mean          -1.2044358
Policy log std Std           0.29787546
Policy log std Max           -0.07253206
Policy log std Min           -2.8955445
Z mean eval                  0.89993894
Z variance eval              0.1748555
total_rewards                [2935.20221843 2684.18292189 2470.97441914 5341.35340763 5349.05633967
 5373.07193793 4350.998908   5248.9390528  5137.37962073 5671.00903797]
total_rewards_mean           4456.216786418698
total_rewards_std            1199.800470063642
total_rewards_max            5671.009037966158
total_rewards_min            2470.974419136497
Number of train steps total  1860000
Number of env steps total    3455079
Number of rollouts total     0
Train Time (s)               190.76480192504823
(Previous) Eval Time (s)     29.755461174994707
Sample Time (s)              7.277619450353086
Epoch Time (s)               227.79788255039603
Total Train Time (s)         105164.93087516678
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:24:27.772341 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #464 | Epoch Duration: 227.89051008224487
2020-01-12 21:24:27.772487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.898975
Z variance train             0.1744787
KL Divergence                12.248347
KL Loss                      1.2248348
QF Loss                      575.0449
VF Loss                      157.92133
Policy Loss                  -1638.2487
Q Predictions Mean           1629.7007
Q Predictions Std            307.84726
Q Predictions Max            2132.7869
Q Predictions Min            512.1221
V Predictions Mean           1644.1422
V Predictions Std            306.65662
V Predictions Max            2146.3848
V Predictions Min            532.3318
Log Pis Mean                 2.0125089
Log Pis Std                  2.8980086
Log Pis Max                  13.956081
Log Pis Min                  -6.1507773
Policy mu Mean               0.106288895
Policy mu Std                0.72445387
Policy mu Max                2.7586415
Policy mu Min                -3.0147054
Policy log std Mean          -1.1771789
Policy log std Std           0.31362087
Policy log std Max           -0.02085638
Policy log std Min           -2.688388
Z mean eval                  0.9531454
Z variance eval              0.19093162
total_rewards                [5304.4461415  5221.32122256 5127.64894894 3966.60265509 4848.70860058
 5239.95581075 3846.29535964 5054.66286821 5391.42284366 5336.66019114]
total_rewards_mean           4933.7724642064295
total_rewards_std            535.0753433061512
total_rewards_max            5391.422843661986
total_rewards_min            3846.2953596362518
Number of train steps total  1864000
Number of env steps total    3465737
Number of rollouts total     0
Train Time (s)               192.5745422267355
(Previous) Eval Time (s)     31.590726471040398
Sample Time (s)              6.938261231873184
Epoch Time (s)               231.10352992964908
Total Train Time (s)         105396.12476721965
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:28:18.969130 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #465 | Epoch Duration: 231.1965355873108
2020-01-12 21:28:18.969278 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9519248
Z variance train             0.19079635
KL Divergence                12.390711
KL Loss                      1.2390711
QF Loss                      21199.408
VF Loss                      96.884926
Policy Loss                  -1710.5232
Q Predictions Mean           1704.9279
Q Predictions Std            246.49269
Q Predictions Max            2146.6143
Q Predictions Min            591.76544
V Predictions Mean           1714.1252
V Predictions Std            244.28542
V Predictions Max            2145.4094
V Predictions Min            604.88544
Log Pis Mean                 2.134136
Log Pis Std                  2.5104005
Log Pis Max                  10.006184
Log Pis Min                  -5.18634
Policy mu Mean               0.073397934
Policy mu Std                0.7122526
Policy mu Max                2.8592403
Policy mu Min                -2.4694219
Policy log std Mean          -1.1756675
Policy log std Std           0.31933302
Policy log std Max           -0.19549906
Policy log std Min           -2.5350778
Z mean eval                  0.94714737
Z variance eval              0.17731453
total_rewards                [2251.68796885 5413.04226393 5162.56915319 5206.78336813 3126.97637576
 5239.1666459  5267.95489641 5271.0712572  5210.42193259 5047.30074417]
total_rewards_mean           4719.697460612343
total_rewards_std            1037.5224465977133
total_rewards_max            5413.042263930239
total_rewards_min            2251.6879688534436
Number of train steps total  1868000
Number of env steps total    3476224
Number of rollouts total     0
Train Time (s)               192.72777957795188
(Previous) Eval Time (s)     31.632719560991973
Sample Time (s)              6.381154983770102
Epoch Time (s)               230.74165412271395
Total Train Time (s)         105626.9698531609
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:32:09.816994 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #466 | Epoch Duration: 230.8476002216339
2020-01-12 21:32:09.817141 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94754297
Z variance train             0.17773812
KL Divergence                12.716257
KL Loss                      1.2716258
QF Loss                      576.72406
VF Loss                      289.29205
Policy Loss                  -1620.5986
Q Predictions Mean           1613.3779
Q Predictions Std            318.32767
Q Predictions Max            2092.6025
Q Predictions Min            553.0537
V Predictions Mean           1634.0112
V Predictions Std            319.12915
V Predictions Max            2124.8523
V Predictions Min            567.015
Log Pis Mean                 2.2656484
Log Pis Std                  3.0929577
Log Pis Max                  14.877705
Log Pis Min                  -6.86023
Policy mu Mean               0.038360797
Policy mu Std                0.77306634
Policy mu Max                2.6170063
Policy mu Min                -3.0595973
Policy log std Mean          -1.1541969
Policy log std Std           0.34618387
Policy log std Max           -0.061110377
Policy log std Min           -2.8895998
Z mean eval                  1.1368085
Z variance eval              0.16539717
total_rewards                [4954.05865787 3666.95025381 5172.57547799 5382.88648204 4601.51770217
 4661.61287886 4704.61887219 5327.65668757 5194.01647877 5559.19219397]
total_rewards_mean           4922.50856852413
total_rewards_std            520.9326800848568
total_rewards_max            5559.192193974616
total_rewards_min            3666.9502538073893
Number of train steps total  1872000
Number of env steps total    3485413
Number of rollouts total     0
Train Time (s)               192.21813486982137
(Previous) Eval Time (s)     33.76056191883981
Sample Time (s)              7.080714470241219
Epoch Time (s)               233.0594112589024
Total Train Time (s)         105860.2475280636
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:03.097935 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #467 | Epoch Duration: 233.28068280220032
2020-01-12 21:36:03.098080 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1359422
Z variance train             0.16500106
KL Divergence                11.873016
KL Loss                      1.1873016
QF Loss                      463.4638
VF Loss                      252.018
Policy Loss                  -1671.3368
Q Predictions Mean           1666.3673
Q Predictions Std            233.52266
Q Predictions Max            2077.204
Q Predictions Min            595.92847
V Predictions Mean           1683.7378
V Predictions Std            231.9734
V Predictions Max            2091.6436
V Predictions Min            610.18524
Log Pis Mean                 2.1021411
Log Pis Std                  2.7932122
Log Pis Max                  12.230089
Log Pis Min                  -8.265783
Policy mu Mean               0.09061178
Policy mu Std                0.7437177
Policy mu Max                2.6738312
Policy mu Min                -2.446469
Policy log std Mean          -1.1724048
Policy log std Std           0.301607
Policy log std Max           -0.21168983
Policy log std Min           -2.532722
Z mean eval                  0.8767642
Z variance eval              0.24664731
total_rewards                [1059.38983476 5204.63683747 1452.15845127 5379.37281358 2270.75760899
 1390.46633008 3055.52100269  181.46125636 2871.15175799 5407.99724684]
total_rewards_mean           2827.2913140052547
total_rewards_std            1824.0072884491765
total_rewards_max            5407.997246844708
total_rewards_min            181.46125636380268
Number of train steps total  1876000
Number of env steps total    3495952
Number of rollouts total     0
Train Time (s)               190.97718002833426
(Previous) Eval Time (s)     18.44998202007264
Sample Time (s)              7.474799838848412
Epoch Time (s)               216.9019618872553
Total Train Time (s)         106077.2395175458
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:39:40.092609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #468 | Epoch Duration: 216.9944167137146
2020-01-12 21:39:40.092771 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8755274
Z variance train             0.24664907
KL Divergence                11.075718
KL Loss                      1.1075718
QF Loss                      21195.076
VF Loss                      119.29872
Policy Loss                  -1669.9797
Q Predictions Mean           1662.5007
Q Predictions Std            228.12952
Q Predictions Max            2095.368
Q Predictions Min            685.7927
V Predictions Mean           1669.6682
V Predictions Std            222.88307
V Predictions Max            2105.7268
V Predictions Min            693.4709
Log Pis Mean                 2.16944
Log Pis Std                  2.9554372
Log Pis Max                  15.723895
Log Pis Min                  -5.811693
Policy mu Mean               0.08768397
Policy mu Std                0.74443203
Policy mu Max                2.654487
Policy mu Min                -2.8300188
Policy log std Mean          -1.1512424
Policy log std Std           0.31200746
Policy log std Max           -0.24738765
Policy log std Min           -2.624647
Z mean eval                  0.8938325
Z variance eval              0.22691588
total_rewards                [4248.13176758  205.82311986 5350.95400991 5212.41594525  533.6972669
 3634.85893372 3552.50985392  782.07835762 5126.53371696 5398.24846096]
total_rewards_mean           3404.5251432682467
total_rewards_std            2003.3596886282858
total_rewards_max            5398.248460961888
total_rewards_min            205.82311985676031
Number of train steps total  1880000
Number of env steps total    3506173
Number of rollouts total     0
Train Time (s)               193.2902363287285
(Previous) Eval Time (s)     18.52489089500159
Sample Time (s)              6.701260907575488
Epoch Time (s)               218.51638813130558
Total Train Time (s)         106295.85013535898
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:43:18.709971 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #469 | Epoch Duration: 218.61707735061646
2020-01-12 21:43:18.710161 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8995514
Z variance train             0.22668406
KL Divergence                9.997179
KL Loss                      0.9997179
QF Loss                      401.32288
VF Loss                      90.57835
Policy Loss                  -1749.8499
Q Predictions Mean           1739.1431
Q Predictions Std            239.55733
Q Predictions Max            2187.0935
Q Predictions Min            659.2489
V Predictions Mean           1750.662
V Predictions Std            233.00175
V Predictions Max            2181.2102
V Predictions Min            671.62476
Log Pis Mean                 1.9849244
Log Pis Std                  2.8131697
Log Pis Max                  11.948555
Log Pis Min                  -6.1375604
Policy mu Mean               0.110688284
Policy mu Std                0.7049887
Policy mu Max                2.522891
Policy mu Min                -2.498393
Policy log std Mean          -1.177053
Policy log std Std           0.3000341
Policy log std Max           -0.052133083
Policy log std Min           -2.7233117
Z mean eval                  1.2256217
Z variance eval              0.1700439
total_rewards                [1160.71775621 3061.04575503 2678.8653357  1962.56898019  172.24290421
  783.78229706 3101.87828697 4676.3686289  2578.62986669    9.94429943]
total_rewards_mean           2018.6044110389262
total_rewards_std            1406.4533862314906
total_rewards_max            4676.368628903271
total_rewards_min            9.944299425251408
Number of train steps total  1884000
Number of env steps total    3515954
Number of rollouts total     0
Train Time (s)               193.6887260582298
(Previous) Eval Time (s)     13.623209623154253
Sample Time (s)              7.310360805597156
Epoch Time (s)               214.6222964869812
Total Train Time (s)         106510.56790175661
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:46:53.431401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #470 | Epoch Duration: 214.72110605239868
2020-01-12 21:46:53.431545 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2263849
Z variance train             0.17018893
KL Divergence                12.097108
KL Loss                      1.2097108
QF Loss                      381.29578
VF Loss                      370.29858
Policy Loss                  -1726.2043
Q Predictions Mean           1715.3999
Q Predictions Std            197.27834
Q Predictions Max            2141.1062
Q Predictions Min            705.8696
V Predictions Mean           1711.3302
V Predictions Std            189.41713
V Predictions Max            2126.9387
V Predictions Min            679.7873
Log Pis Mean                 2.3038037
Log Pis Std                  2.815138
Log Pis Max                  10.70147
Log Pis Min                  -5.7296333
Policy mu Mean               0.1203728
Policy mu Std                0.7703346
Policy mu Max                2.8713007
Policy mu Min                -2.4770696
Policy log std Mean          -1.1540384
Policy log std Std           0.29529417
Policy log std Max           -0.1311351
Policy log std Min           -2.584002
Z mean eval                  1.0232533
Z variance eval              0.10673292
total_rewards                [3398.53536457 5636.13056744 5100.78019333 1619.98210376 2600.50056589
 5160.20490525 5629.7743883  4855.00111552 5396.66866554 5406.57910198]
total_rewards_mean           4480.415697158662
total_rewards_std            1350.1076410804928
total_rewards_max            5636.130567442222
total_rewards_min            1619.982103759467
Number of train steps total  1888000
Number of env steps total    3528052
Number of rollouts total     0
Train Time (s)               191.55988733144477
(Previous) Eval Time (s)     29.72928251326084
Sample Time (s)              7.464955307543278
Epoch Time (s)               228.7541251522489
Total Train Time (s)         106739.44384737685
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:42.311874 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #471 | Epoch Duration: 228.88021111488342
2020-01-12 21:50:42.312048 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0242869
Z variance train             0.10726456
KL Divergence                13.950374
KL Loss                      1.3950374
QF Loss                      22854.629
VF Loss                      283.857
Policy Loss                  -1796.5776
Q Predictions Mean           1789.4958
Q Predictions Std            181.55307
Q Predictions Max            2269.9187
Q Predictions Min            822.2176
V Predictions Mean           1805.0684
V Predictions Std            177.51459
V Predictions Max            2267.463
V Predictions Min            801.69385
Log Pis Mean                 2.1950245
Log Pis Std                  3.2663255
Log Pis Max                  14.659677
Log Pis Min                  -6.4668856
Policy mu Mean               0.12816006
Policy mu Std                0.7127225
Policy mu Max                2.8062773
Policy mu Min                -3.2728508
Policy log std Mean          -1.2384253
Policy log std Std           0.3110301
Policy log std Max           0.94593847
Policy log std Min           -2.7453673
Z mean eval                  1.1328248
Z variance eval              0.24849033
total_rewards                [1746.95672309 5028.76052292 2370.92678296 1397.63956834 4719.53527036
 5327.46027677 5218.06602585 2711.05360566 5603.65420769 5172.38265161]
total_rewards_mean           3929.643563525527
total_rewards_std            1577.4139800479584
total_rewards_max            5603.654207693495
total_rewards_min            1397.6395683418382
Number of train steps total  1892000
Number of env steps total    3537821
Number of rollouts total     0
Train Time (s)               192.09102977020666
(Previous) Eval Time (s)     23.019424445927143
Sample Time (s)              6.979640674777329
Epoch Time (s)               222.09009489091113
Total Train Time (s)         106961.62872108165
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:54:24.504529 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #472 | Epoch Duration: 222.1923520565033
2020-01-12 21:54:24.504719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.13092
Z variance train             0.24855371
KL Divergence                14.26981
KL Loss                      1.426981
QF Loss                      1489.547
VF Loss                      222.59123
Policy Loss                  -1834.1495
Q Predictions Mean           1819.7861
Q Predictions Std            317.86017
Q Predictions Max            3261.8687
Q Predictions Min            892.75507
V Predictions Mean           1834.9156
V Predictions Std            331.91394
V Predictions Max            3410.1533
V Predictions Min            916.6215
Log Pis Mean                 3.2443495
Log Pis Std                  3.516983
Log Pis Max                  15.540142
Log Pis Min                  -5.9428706
Policy mu Mean               0.17860138
Policy mu Std                0.8303965
Policy mu Max                3.1682782
Policy mu Min                -2.7512016
Policy log std Mean          -1.1974013
Policy log std Std           0.32911804
Policy log std Max           -0.26559377
Policy log std Min           -2.8144164
Z mean eval                  1.2855619
Z variance eval              0.16647653
total_rewards                [-331.87177698 1007.44569521   68.00433212 3926.34676006 1608.77906293
 2688.06421797  174.28070725 5258.60481522   49.55978041 5038.58763525]
total_rewards_mean           1948.780122943539
total_rewards_std            2036.061116704551
total_rewards_max            5258.604815224458
total_rewards_min            -331.871776982864
Number of train steps total  1896000
Number of env steps total    3548336
Number of rollouts total     0
Train Time (s)               192.33194223605096
(Previous) Eval Time (s)     17.390301597304642
Sample Time (s)              7.480499892961234
Epoch Time (s)               217.20274372631684
Total Train Time (s)         107178.9215268786
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:58:01.804497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #473 | Epoch Duration: 217.29962992668152
2020-01-12 21:58:01.804697 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2859657
Z variance train             0.16699693
KL Divergence                14.521285
KL Loss                      1.4521285
QF Loss                      7033.463
VF Loss                      375.95914
Policy Loss                  -1984.2197
Q Predictions Mean           1968.9998
Q Predictions Std            621.8842
Q Predictions Max            5133.639
Q Predictions Min            1185.1964
V Predictions Mean           1979.2649
V Predictions Std            655.1706
V Predictions Max            5323.4854
V Predictions Min            1189.1276
Log Pis Mean                 2.4711044
Log Pis Std                  3.7415912
Log Pis Max                  15.358172
Log Pis Min                  -10.641034
Policy mu Mean               0.14453915
Policy mu Std                0.8061499
Policy mu Max                3.3832543
Policy mu Min                -3.0526028
Policy log std Mean          -1.1763489
Policy log std Std           0.32546332
Policy log std Max           0.0506171
Policy log std Min           -2.488727
Z mean eval                  7.0817213
Z variance eval              0.41632175
total_rewards                [-2638.17724039 -2704.16735675 -2679.17256458 -2702.17098487
 -2660.74031583 -2648.55157582 -2700.64083647 -2698.04799789
 -2633.89627006 -2692.8022018 ]
total_rewards_mean           -2675.8367344452327
total_rewards_std            26.558006766595827
total_rewards_max            -2633.896270056642
total_rewards_min            -2704.1673567519756
Number of train steps total  1900000
Number of env steps total    3559161
Number of rollouts total     0
Train Time (s)               194.79262802004814
(Previous) Eval Time (s)     34.13264257181436
Sample Time (s)              7.393041409086436
Epoch Time (s)               236.31831200094894
Total Train Time (s)         107415.32986970153
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:01:58.216408 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #474 | Epoch Duration: 236.41156363487244
2020-01-12 22:01:58.216564 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.082528
Z variance train             0.4166921
KL Divergence                140.60498
KL Loss                      14.060498
QF Loss                      37393.094
VF Loss                      9250.22
Policy Loss                  -7324.227
Q Predictions Mean           6995.285
Q Predictions Std            957.98627
Q Predictions Max            11598.407
Q Predictions Min            4698.8516
V Predictions Mean           7387.5273
V Predictions Std            1003.3229
V Predictions Max            12109.495
V Predictions Min            4843.029
Log Pis Mean                 19.368252
Log Pis Std                  4.6518984
Log Pis Max                  32.244244
Log Pis Min                  4.3579664
Policy mu Mean               1.1062758
Policy mu Std                1.929888
Policy mu Max                4.972339
Policy mu Min                -4.0531387
Policy log std Mean          -1.0562627
Policy log std Std           0.5067823
Policy log std Max           0.2395277
Policy log std Min           -3.4122062
Z mean eval                  6.711847
Z variance eval              2.762814
total_rewards                [-1141.80602352 -1466.03113881 -1426.89770612 -1519.41687816
 -1148.79055209 -1466.37836826 -1541.16599238 -1478.98609413
 -1137.16660708 -1149.84230979]
total_rewards_mean           -1347.6481670339037
total_rewards_std            168.5052377183845
total_rewards_max            -1137.166607082849
total_rewards_min            -1541.1659923843035
Number of train steps total  1904000
Number of env steps total    3569568
Number of rollouts total     0
Train Time (s)               192.34240853507072
(Previous) Eval Time (s)     34.12636945908889
Sample Time (s)              7.107728527393192
Epoch Time (s)               233.5765065215528
Total Train Time (s)         107649.06329741795
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:05:51.952827 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #475 | Epoch Duration: 233.7361307144165
2020-01-12 22:05:51.952998 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.7192
Z variance train             2.7620006
KL Divergence                139.04396
KL Loss                      13.904396
QF Loss                      12620.813
VF Loss                      2185.1965
Policy Loss                  -8823.048
Q Predictions Mean           8711.88
Q Predictions Std            868.57965
Q Predictions Max            14011.156
Q Predictions Min            4335.577
V Predictions Mean           8814.93
V Predictions Std            851.9007
V Predictions Max            14282.281
V Predictions Min            7634.58
Log Pis Mean                 10.0160885
Log Pis Std                  4.6000113
Log Pis Max                  28.531275
Log Pis Min                  -2.3882983
Policy mu Mean               -0.38008332
Policy mu Std                1.4513102
Policy mu Max                3.7033002
Policy mu Min                -3.8505821
Policy log std Mean          -1.224905
Policy log std Std           0.45335612
Policy log std Max           0.09994042
Policy log std Min           -2.6792192
Z mean eval                  7.869643
Z variance eval              1.9469675
total_rewards                [-2807.37766736 -2834.9327491  -2828.34476326 -2850.29434595
 -2817.45182433 -2748.10543372 -2828.86885999 -2793.55972962
 -2762.74681924 -2833.84960739]
total_rewards_mean           -2810.5531799976893
total_rewards_std            31.464382138754026
total_rewards_max            -2748.105433715577
total_rewards_min            -2850.2943459543512
Number of train steps total  1908000
Number of env steps total    3578664
Number of rollouts total     0
Train Time (s)               190.35358148859814
(Previous) Eval Time (s)     34.06000537099317
Sample Time (s)              6.935582289472222
Epoch Time (s)               231.34916914906353
Total Train Time (s)         107880.50331915682
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:09:43.397457 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #476 | Epoch Duration: 231.44429731369019
2020-01-12 22:09:43.397653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.8633475
Z variance train             1.9547958
KL Divergence                190.176
KL Loss                      19.0176
QF Loss                      2771589.5
VF Loss                      13105.092
Policy Loss                  -13274.64
Q Predictions Mean           12868.592
Q Predictions Std            1402.5411
Q Predictions Max            19123.03
Q Predictions Min            9985.446
V Predictions Mean           13329.979
V Predictions Std            1385.7775
V Predictions Max            19486.809
V Predictions Min            10439.997
Log Pis Mean                 19.09674
Log Pis Std                  5.776405
Log Pis Max                  33.30847
Log Pis Min                  4.963119
Policy mu Mean               -1.140568
Policy mu Std                1.894934
Policy mu Max                4.803259
Policy mu Min                -5.9763165
Policy log std Mean          -1.095052
Policy log std Std           0.5515539
Policy log std Max           0.40470755
Policy log std Min           -2.7713113
Z mean eval                  7.6701
Z variance eval              1.983036
total_rewards                [-2354.82808596 -2713.52497802 -2718.09938196 -2716.40590756
 -2718.8348719  -2540.47712806 -2719.9343475  -1894.25280895
 -2604.43158316 -2686.212559  ]
total_rewards_mean           -2566.7001652066638
total_rewards_std            250.39698203780998
total_rewards_max            -1894.2528089528485
total_rewards_min            -2719.9343475021697
Number of train steps total  1912000
Number of env steps total    3590664
Number of rollouts total     0
Train Time (s)               193.92810281924903
(Previous) Eval Time (s)     34.07293193181977
Sample Time (s)              6.070232850499451
Epoch Time (s)               234.07126760156825
Total Train Time (s)         108114.6828789385
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:37.585219 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #477 | Epoch Duration: 234.18742775917053
2020-01-12 22:13:37.585369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.6681185
Z variance train             1.9785824
KL Divergence                184.3566
KL Loss                      18.43566
QF Loss                      19743.283
VF Loss                      5594.353
Policy Loss                  -15776.392
Q Predictions Mean           15548.332
Q Predictions Std            1366.8708
Q Predictions Max            23143.059
Q Predictions Min            14281.875
V Predictions Mean           15777.723
V Predictions Std            1396.1888
V Predictions Max            23439.414
V Predictions Min            14410.958
Log Pis Mean                 16.744825
Log Pis Std                  5.647607
Log Pis Max                  32.622005
Log Pis Min                  4.051792
Policy mu Mean               -0.63629293
Policy mu Std                1.999712
Policy mu Max                5.471601
Policy mu Min                -6.266605
Policy log std Mean          -1.0451442
Policy log std Std           0.46723127
Policy log std Max           0.66972136
Policy log std Min           -2.5059876
Z mean eval                  7.387211
Z variance eval              0.45459658
total_rewards                [-1508.5139787  -1621.74049934 -1742.80975474 -1607.24165399
 -1880.8323147  -1869.62094897 -2002.59896564 -1906.54285824
 -2283.14496662 -2003.77107612]
total_rewards_mean           -1842.6817017055787
total_rewards_std            218.55895064864995
total_rewards_max            -1508.5139786953903
total_rewards_min            -2283.1449666198773
Number of train steps total  1916000
Number of env steps total    3601664
Number of rollouts total     0
Train Time (s)               192.4585155379027
(Previous) Eval Time (s)     34.85268179513514
Sample Time (s)              7.018824423663318
Epoch Time (s)               234.33002175670117
Total Train Time (s)         108349.10562464828
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:17:32.013171 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #478 | Epoch Duration: 234.42768263816833
2020-01-12 22:17:32.013355 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #478 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.389634
Z variance train             0.45212713
KL Divergence                185.05017
KL Loss                      18.505018
QF Loss                      11555.392
VF Loss                      7265.372
Policy Loss                  -16195.012
Q Predictions Mean           15985.78
Q Predictions Std            1679.143
Q Predictions Max            23999.553
Q Predictions Min            15023.233
V Predictions Mean           16137.837
V Predictions Std            1713.0741
V Predictions Max            24335.281
V Predictions Min            15162.518
Log Pis Mean                 16.672043
Log Pis Std                  6.4101915
Log Pis Max                  35.4028
Log Pis Min                  2.8387332
Policy mu Mean               -0.94259775
Policy mu Std                1.8688085
Policy mu Max                5.7067204
Policy mu Min                -5.666545
Policy log std Mean          -1.0188491
Policy log std Std           0.45947546
Policy log std Max           0.306777
Policy log std Min           -2.4867551
Z mean eval                  6.0372925
Z variance eval              1.1343406
total_rewards                [-2208.00187187   -77.36254705 -1543.41142854 -1564.4378353
 -2228.19924081 -1409.72701799 -1985.2697395  -1359.70560795
 -1800.52653126 -1913.13515692]
total_rewards_mean           -1608.9776977192976
total_rewards_std            588.8148104305508
total_rewards_max            -77.36254705351993
total_rewards_min            -2228.1992408088945
Number of train steps total  1920000
Number of env steps total    3610272
Number of rollouts total     0
Train Time (s)               193.32666691299528
(Previous) Eval Time (s)     26.648248208221048
Sample Time (s)              7.2693606577813625
Epoch Time (s)               227.2442757789977
Total Train Time (s)         108576.44288372993
Epoch                        479
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:21:19.359385 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #479 | Epoch Duration: 227.34585452079773
2020-01-12 22:21:19.359687 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.04069
Z variance train             1.1331133
KL Divergence                150.27373
KL Loss                      15.027373
QF Loss                      33148.953
VF Loss                      10207.8545
Policy Loss                  -16195.165
Q Predictions Mean           16006.488
Q Predictions Std            1669.5756
Q Predictions Max            23663.871
Q Predictions Min            12637.182
V Predictions Mean           16124.262
V Predictions Std            1723.0345
V Predictions Max            23966.986
V Predictions Min            13713.4795
Log Pis Mean                 17.28032
Log Pis Std                  7.5468483
Log Pis Max                  48.281765
Log Pis Min                  1.713846
Policy mu Mean               0.06291442
Policy mu Std                2.1988673
Policy mu Max                5.9157267
Policy mu Min                -6.664985
Policy log std Mean          -0.96021616
Policy log std Std           0.4619756
Policy log std Max           0.40158105
Policy log std Min           -3.1728275
Z mean eval                  5.0873528
Z variance eval              1.84265
total_rewards                [ -123.20678334 -1178.90361376 -2075.46861799   -78.02989684
 -1465.1296588    -69.87015346  -836.6473019  -1318.53033181
  -778.54837685 -1153.50517895]
total_rewards_mean           -907.7839913703889
total_rewards_std            632.8217769052661
total_rewards_max            -69.87015346382024
total_rewards_min            -2075.468617986399
Number of train steps total  1924000
Number of env steps total    3619779
Number of rollouts total     0
Train Time (s)               193.18964122608304
(Previous) Eval Time (s)     20.775962460786104
Sample Time (s)              18.35832578409463
Epoch Time (s)               232.32392947096378
Total Train Time (s)         108808.86037520878
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:11.781180 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #480 | Epoch Duration: 232.4212737083435
2020-01-12 22:25:11.781376 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.091055
Z variance train             1.8437617
KL Divergence                123.45717
KL Loss                      12.345717
QF Loss                      24416.078
VF Loss                      7815.623
Policy Loss                  -14621.114
Q Predictions Mean           14555.685
Q Predictions Std            1870.1006
Q Predictions Max            22717.77
Q Predictions Min            13674.765
V Predictions Mean           14608.416
V Predictions Std            1951.0117
V Predictions Max            23180.229
V Predictions Min            12966.82
Log Pis Mean                 12.149821
Log Pis Std                  6.1545987
Log Pis Max                  37.087532
Log Pis Min                  -1.8133326
Policy mu Mean               -0.21756238
Policy mu Std                1.7623882
Policy mu Max                4.293898
Policy mu Min                -6.2387676
Policy log std Mean          -1.0469229
Policy log std Std           0.46053696
Policy log std Max           0.79019177
Policy log std Min           -2.6610339
Z mean eval                  3.7982132
Z variance eval              1.2564846
total_rewards                [-2186.92679783 -2193.90770562 -1655.27585814 -1435.63821294
 -1925.50492467 -2105.74787944 -1959.72743042 -1128.99406661
 -1752.6502814  -1189.27915688]
total_rewards_mean           -1753.3652313957948
total_rewards_std            373.7712148834206
total_rewards_max            -1128.994066607451
total_rewards_min            -2193.9077056241576
Number of train steps total  1928000
Number of env steps total    3631669
Number of rollouts total     0
Train Time (s)               191.07340064039454
(Previous) Eval Time (s)     34.36025951197371
Sample Time (s)              7.541357412002981
Epoch Time (s)               232.97501756437123
Total Train Time (s)         109042.40519051393
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:29:05.332191 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #481 | Epoch Duration: 233.55065727233887
2020-01-12 22:29:05.332401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7950046
Z variance train             1.2546619
KL Divergence                96.33048
KL Loss                      9.633048
QF Loss                      1270032.2
VF Loss                      5922.7944
Policy Loss                  -9916.138
Q Predictions Mean           9843.227
Q Predictions Std            1279.054
Q Predictions Max            18475.746
Q Predictions Min            8903.166
V Predictions Mean           9935.027
V Predictions Std            1302.7059
V Predictions Max            18584.295
V Predictions Min            7696.6514
Log Pis Mean                 9.847241
Log Pis Std                  4.979617
Log Pis Max                  31.341034
Log Pis Min                  -0.8438245
Policy mu Mean               0.3426282
Policy mu Std                1.4047292
Policy mu Max                3.8412583
Policy mu Min                -4.499233
Policy log std Mean          -1.2704793
Policy log std Std           0.40915248
Policy log std Max           0.0075039864
Policy log std Min           -3.1433673
Z mean eval                  3.1270502
Z variance eval              0.4232587
total_rewards                [ -674.42111351 -1596.39275733  -417.32037831  -299.72797119
 -1696.23397139 -1686.84290209 -2008.18457555 -1562.23452651
 -1744.38067477  -987.50884488]
total_rewards_mean           -1267.3247715531738
total_rewards_std            584.8294099554028
total_rewards_max            -299.72797119465207
total_rewards_min            -2008.1845755484683
Number of train steps total  1932000
Number of env steps total    3642265
Number of rollouts total     0
Train Time (s)               190.70799470692873
(Previous) Eval Time (s)     34.21820593625307
Sample Time (s)              6.331792375538498
Epoch Time (s)               231.2579930187203
Total Train Time (s)         109273.92856070725
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:32:56.866763 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #482 | Epoch Duration: 231.53416275978088
2020-01-12 22:32:56.867172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1241596
Z variance train             0.4222003
KL Divergence                77.83484
KL Loss                      7.783484
QF Loss                      618740.9
VF Loss                      2492.9883
Policy Loss                  -9252.961
Q Predictions Mean           9185.138
Q Predictions Std            1435.1445
Q Predictions Max            19682.854
Q Predictions Min            8560.317
V Predictions Mean           9277.797
V Predictions Std            1465.6915
V Predictions Max            20066.322
V Predictions Min            8678.752
Log Pis Mean                 11.043566
Log Pis Std                  5.366695
Log Pis Max                  32.14028
Log Pis Min                  -1.9627686
Policy mu Mean               -0.15730508
Policy mu Std                1.6508344
Policy mu Max                3.9139717
Policy mu Min                -7.35797
Policy log std Mean          -1.0678303
Policy log std Std           0.4704859
Policy log std Max           1.0175524
Policy log std Min           -2.963254
Z mean eval                  2.501409
Z variance eval              0.58749837
total_rewards                [-1567.87189586 -1020.05958744 -1176.80325035 -1185.57775655
   -51.40059772 -1521.52599153 -1248.15924319 -1642.24254388
 -1670.86899549 -1622.84922891]
total_rewards_mean           -1270.735909092469
total_rewards_std            462.5467649404067
total_rewards_max            -51.40059771678794
total_rewards_min            -1670.8689954915192
Number of train steps total  1936000
Number of env steps total    3653926
Number of rollouts total     0
Train Time (s)               191.31520018912852
(Previous) Eval Time (s)     26.754596094135195
Sample Time (s)              6.279538661241531
Epoch Time (s)               224.34933494450524
Total Train Time (s)         109498.37055331422
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:36:41.312150 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #483 | Epoch Duration: 224.44469666481018
2020-01-12 22:36:41.312327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #483 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5003772
Z variance train             0.58437
KL Divergence                68.145096
KL Loss                      6.81451
QF Loss                      42228.285
VF Loss                      5041.8164
Policy Loss                  -8245.691
Q Predictions Mean           8190.3706
Q Predictions Std            1499.3468
Q Predictions Max            19005.088
Q Predictions Min            7234.702
V Predictions Mean           8207.513
V Predictions Std            1496.1785
V Predictions Max            19279.57
V Predictions Min            7102.4146
Log Pis Mean                 10.072063
Log Pis Std                  3.9705036
Log Pis Max                  23.010555
Log Pis Min                  -0.90378416
Policy mu Mean               -0.22937831
Policy mu Std                1.4618325
Policy mu Max                4.2462134
Policy mu Min                -5.6294994
Policy log std Mean          -1.201436
Policy log std Std           0.49178916
Policy log std Max           0.073286414
Policy log std Min           -2.8064876
Z mean eval                  2.3021333
Z variance eval              0.24524398
total_rewards                [-1638.58268183  -983.97134743  -179.65283354   -35.3476772
  -747.2352147   -783.07188035  -467.16334037   -32.30938486
   -21.34675056 -1024.12847381]
total_rewards_mean           -591.2809584642698
total_rewards_std            512.9023329694638
total_rewards_max            -21.346750555834404
total_rewards_min            -1638.5826818271723
Number of train steps total  1940000
Number of env steps total    3665778
Number of rollouts total     0
Train Time (s)               192.59826960973442
(Previous) Eval Time (s)     21.929991906974465
Sample Time (s)              6.991859504953027
Epoch Time (s)               221.5201210216619
Total Train Time (s)         109719.99768583896
Epoch                        484
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:40:22.942346 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #484 | Epoch Duration: 221.62987995147705
2020-01-12 22:40:22.942488 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.298612
Z variance train             0.24615288
KL Divergence                59.93619
KL Loss                      5.9936194
QF Loss                      8704.931
VF Loss                      7303.7197
Policy Loss                  -7588.124
Q Predictions Mean           7524.093
Q Predictions Std            2055.4705
Q Predictions Max            18233.033
Q Predictions Min            -522.3152
V Predictions Mean           7617.0615
V Predictions Std            2015.9568
V Predictions Max            18235.97
V Predictions Min            4376.092
Log Pis Mean                 8.449198
Log Pis Std                  5.272344
Log Pis Max                  33.06332
Log Pis Min                  -2.9924636
Policy mu Mean               0.16303605
Policy mu Std                1.4248549
Policy mu Max                9.233324
Policy mu Min                -10.269586
Policy log std Mean          -1.1810384
Policy log std Std           0.48031646
Policy log std Max           2.0
Policy log std Min           -3.1299253
Z mean eval                  2.1792862
Z variance eval              0.3399302
total_rewards                [-2268.29750474 -1646.00851575   -12.66726408 -1254.32598129
 -1428.26333015   -19.8722944     -9.09911324   -21.79643438
 -1739.36967023 -1905.40209075]
total_rewards_mean           -1030.5102199004518
total_rewards_std            866.3343177758317
total_rewards_max            -9.09911323790179
total_rewards_min            -2268.2975047370705
Number of train steps total  1944000
Number of env steps total    3677818
Number of rollouts total     0
Train Time (s)               192.4316537110135
(Previous) Eval Time (s)     20.931834443006665
Sample Time (s)              7.251983164809644
Epoch Time (s)               220.6154713188298
Total Train Time (s)         109940.70865407214
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:44:03.661793 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #485 | Epoch Duration: 220.7191870212555
2020-01-12 22:44:03.661967 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #485 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1813114
Z variance train             0.34018072
KL Divergence                58.08651
KL Loss                      5.808651
QF Loss                      84163.29
VF Loss                      3032.809
Policy Loss                  -7404.2397
Q Predictions Mean           7317.5264
Q Predictions Std            1440.4586
Q Predictions Max            17364.12
Q Predictions Min            6408.813
V Predictions Mean           7380.33
V Predictions Std            1445.6262
V Predictions Max            17463.338
V Predictions Min            6693.908
Log Pis Mean                 11.48778
Log Pis Std                  4.7514095
Log Pis Max                  30.54947
Log Pis Min                  -3.8450022
Policy mu Mean               0.16316438
Policy mu Std                1.7523712
Policy mu Max                5.197636
Policy mu Min                -5.640527
Policy log std Mean          -0.95577824
Policy log std Std           0.4605126
Policy log std Max           0.2086525
Policy log std Min           -2.9566312
Z mean eval                  2.2665505
Z variance eval              0.5849084
total_rewards                [ -827.97447237 -1106.64693523 -1108.59569054 -1170.00051605
 -1090.37567054   -11.92185028   -11.41522601  -800.62481712
 -1015.86581228  -973.16361184]
total_rewards_mean           -811.6584602269567
total_rewards_std            415.86327329878543
total_rewards_max            -11.415226012710317
total_rewards_min            -1170.0005160530811
Number of train steps total  1948000
Number of env steps total    3689328
Number of rollouts total     0
Train Time (s)               192.57205240800977
(Previous) Eval Time (s)     23.86636437335983
Sample Time (s)              6.004629735834897
Epoch Time (s)               222.4430465172045
Total Train Time (s)         110163.24197337637
Epoch                        486
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:47:46.202961 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #486 | Epoch Duration: 222.5408489704132
2020-01-12 22:47:46.203151 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2662506
Z variance train             0.58596337
KL Divergence                55.990562
KL Loss                      5.5990562
QF Loss                      9966.205
VF Loss                      2226.0298
Policy Loss                  -8161.965
Q Predictions Mean           8086.718
Q Predictions Std            1741.1085
Q Predictions Max            17465.908
Q Predictions Min            6925.391
V Predictions Mean           8171.855
V Predictions Std            1748.9813
V Predictions Max            17813.574
V Predictions Min            6909.44
Log Pis Mean                 10.412842
Log Pis Std                  4.3178525
Log Pis Max                  25.340355
Log Pis Min                  -4.816386
Policy mu Mean               0.42215416
Policy mu Std                1.4844639
Policy mu Max                4.216679
Policy mu Min                -4.1007166
Policy log std Mean          -1.1578844
Policy log std Std           0.4713298
Policy log std Max           0.1792711
Policy log std Min           -3.0643373
Z mean eval                  2.187345
Z variance eval              0.24732597
total_rewards                [  -22.75410791  -496.54583603  -947.5818762     -9.87355619
  -574.41961275  -681.48969175  -709.63114917 -1106.89417491
 -1091.03176842   -67.51131921]
total_rewards_mean           -570.7733092558977
total_rewards_std            400.6679400794003
total_rewards_max            -9.873556188910143
total_rewards_min            -1106.8941749145163
Number of train steps total  1952000
Number of env steps total    3699338
Number of rollouts total     0
Train Time (s)               193.09656236693263
(Previous) Eval Time (s)     24.051502974238247
Sample Time (s)              7.1464251303114
Epoch Time (s)               224.29449047148228
Total Train Time (s)         110387.64335758798
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:51:30.608792 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #487 | Epoch Duration: 224.40550208091736
2020-01-12 22:51:30.608948 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1799111
Z variance train             0.24726863
KL Divergence                56.917885
KL Loss                      5.6917887
QF Loss                      55890.062
VF Loss                      5483.059
Policy Loss                  -8053.135
Q Predictions Mean           7872.911
Q Predictions Std            1455.2405
Q Predictions Max            17399.59
Q Predictions Min            6929.853
V Predictions Mean           8077.3433
V Predictions Std            1480.3694
V Predictions Max            17687.582
V Predictions Min            7023.7285
Log Pis Mean                 15.183472
Log Pis Std                  4.668253
Log Pis Max                  28.86473
Log Pis Min                  -1.0658143
Policy mu Mean               0.42843816
Policy mu Std                1.9597659
Policy mu Max                5.5246105
Policy mu Min                -6.047495
Policy log std Mean          -1.0364401
Policy log std Std           0.49068078
Policy log std Max           0.3090701
Policy log std Min           -3.1179667
Z mean eval                  2.3564863
Z variance eval              0.62454283
total_rewards                [-332.20094937 -893.0692352  -317.75028696  -47.07050168  -64.8143733
 -893.77293319 -612.30897814 -655.30892577 -906.51724893 -616.58652066]
total_rewards_mean           -533.9399953199691
total_rewards_std            311.372335420067
total_rewards_max            -47.070501676458576
total_rewards_min            -906.5172489328244
Number of train steps total  1956000
Number of env steps total    3709484
Number of rollouts total     0
Train Time (s)               194.1041777380742
(Previous) Eval Time (s)     30.65496509615332
Sample Time (s)              7.0793699636124074
Epoch Time (s)               231.83851279783994
Total Train Time (s)         110619.5726774605
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:55:22.540804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #488 | Epoch Duration: 231.93174171447754
2020-01-12 22:55:22.540965 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3551252
Z variance train             0.6274895
KL Divergence                59.009544
KL Loss                      5.9009547
QF Loss                      1477163.8
VF Loss                      8550.312
Policy Loss                  -10037.859
Q Predictions Mean           9971.08
Q Predictions Std            1604.6274
Q Predictions Max            18102.477
Q Predictions Min            8154.335
V Predictions Mean           10049.143
V Predictions Std            1616.8019
V Predictions Max            18267.594
V Predictions Min            8274.885
Log Pis Mean                 10.758965
Log Pis Std                  4.664095
Log Pis Max                  33.387108
Log Pis Min                  -0.9636178
Policy mu Mean               -0.094422325
Policy mu Std                1.4003683
Policy mu Max                4.572974
Policy mu Min                -4.6177793
Policy log std Mean          -1.4425719
Policy log std Std           0.505971
Policy log std Max           0.29561806
Policy log std Min           -3.1467614
Z mean eval                  2.173562
Z variance eval              0.5770923
total_rewards                [  34.87812531   30.39754355 -857.88993896   18.04937879   55.07818463
  -17.32285444   22.14989481 -898.67370537   35.23274045   16.06294954]
total_rewards_mean           -156.20376817020394
total_rewards_std            361.5775640755166
total_rewards_max            55.07818462988379
total_rewards_min            -898.6737053701648
Number of train steps total  1960000
Number of env steps total    3720403
Number of rollouts total     0
Train Time (s)               192.63181051192805
(Previous) Eval Time (s)     14.798370007891208
Sample Time (s)              7.740780467167497
Epoch Time (s)               215.17096098698676
Total Train Time (s)         110834.83789948653
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:58:57.810507 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #489 | Epoch Duration: 215.2694230079651
2020-01-12 22:58:57.810702 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #489 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1695416
Z variance train             0.5810525
KL Divergence                54.465824
KL Loss                      5.4465823
QF Loss                      565659.4
VF Loss                      12056.094
Policy Loss                  -8873.235
Q Predictions Mean           8764.138
Q Predictions Std            1203.5215
Q Predictions Max            14295.142
Q Predictions Min            -497.9794
V Predictions Mean           8804.02
V Predictions Std            1165.8551
V Predictions Max            14269.344
V Predictions Min            275.38116
Log Pis Mean                 10.366393
Log Pis Std                  4.530897
Log Pis Max                  32.766453
Log Pis Min                  -0.47489047
Policy mu Mean               0.092510134
Policy mu Std                1.3118495
Policy mu Max                4.778193
Policy mu Min                -4.11022
Policy log std Mean          -1.5862095
Policy log std Std           0.535713
Policy log std Max           0.1849109
Policy log std Min           -4.7376146
Z mean eval                  2.222508
Z variance eval              0.6540348
total_rewards                [142.94767375 151.16580254 185.59613415 103.07911343 161.92906732
 100.61075271 197.57425156 202.02461575 237.41501979 193.95479891]
total_rewards_mean           167.6297229904056
total_rewards_std            41.876673601617874
total_rewards_max            237.41501978555328
total_rewards_min            100.61075270688352
Number of train steps total  1964000
Number of env steps total    3731701
Number of rollouts total     0
Train Time (s)               193.97623106604442
(Previous) Eval Time (s)     34.218775696121156
Sample Time (s)              7.761790340300649
Epoch Time (s)               235.95679710246623
Total Train Time (s)         111070.95878850389
Epoch                        490
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:02:53.955249 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #490 | Epoch Duration: 236.14435529708862
2020-01-12 23:02:53.955590 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2226136
Z variance train             0.6556984
KL Divergence                55.246204
KL Loss                      5.5246205
QF Loss                      26137.57
VF Loss                      4460.6675
Policy Loss                  -8331.407
Q Predictions Mean           8265.039
Q Predictions Std            1055.925
Q Predictions Max            12588.355
Q Predictions Min            6368.689
V Predictions Mean           8358.662
V Predictions Std            1052.8372
V Predictions Max            12652.078
V Predictions Min            6169.703
Log Pis Mean                 7.6355124
Log Pis Std                  3.5350919
Log Pis Max                  20.581657
Log Pis Min                  -3.5840757
Policy mu Mean               0.23334005
Policy mu Std                0.9473051
Policy mu Max                3.652907
Policy mu Min                -3.1866443
Policy log std Mean          -1.6875029
Policy log std Std           0.43752655
Policy log std Max           -0.063917875
Policy log std Min           -3.196003
Z mean eval                  2.130899
Z variance eval              0.71037155
total_rewards                [-245.84053221 -160.18421887 -512.2282448  -360.13025651 -554.62149742
 -198.58534158 -442.28045048 -362.89865328 -644.58879764 -380.22949411]
total_rewards_mean           -386.1587486907675
total_rewards_std            148.7951930456443
total_rewards_max            -160.18421887218187
total_rewards_min            -644.588797644742
Number of train steps total  1968000
Number of env steps total    3741925
Number of rollouts total     0
Train Time (s)               192.39852887298912
(Previous) Eval Time (s)     34.307163963094354
Sample Time (s)              7.029111327603459
Epoch Time (s)               233.73480416368693
Total Train Time (s)         111304.80256932043
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:06:47.782579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #491 | Epoch Duration: 233.82675886154175
2020-01-12 23:06:47.782721 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1293483
Z variance train             0.71315235
KL Divergence                48.072826
KL Loss                      4.807283
QF Loss                      10444.03
VF Loss                      1974.9319
Policy Loss                  -7843.613
Q Predictions Mean           7812.1025
Q Predictions Std            632.0048
Q Predictions Max            11918.611
Q Predictions Min            5282.7515
V Predictions Mean           7847.744
V Predictions Std            638.6112
V Predictions Max            12166.065
V Predictions Min            5365.766
Log Pis Mean                 6.7705503
Log Pis Std                  3.6142313
Log Pis Max                  21.908195
Log Pis Min                  -3.063189
Policy mu Mean               0.23095906
Policy mu Std                0.8611811
Policy mu Max                4.052648
Policy mu Min                -3.3628047
Policy log std Mean          -1.6917752
Policy log std Std           0.3956393
Policy log std Max           0.20507967
Policy log std Min           -3.9358883
Z mean eval                  2.0426788
Z variance eval              0.43671417
total_rewards                [-282.43757334 -602.32887328  480.05048984 -777.89273164 -253.01377304
   61.43406167  -99.77641491  388.80199376  363.1311635   514.68517779]
total_rewards_mean           -20.734647965167653
total_rewards_std            435.8342441381883
total_rewards_max            514.685177785649
total_rewards_min            -777.892731639526
Number of train steps total  1972000
Number of env steps total    3753180
Number of rollouts total     0
Train Time (s)               193.57547172624618
(Previous) Eval Time (s)     31.132266412954777
Sample Time (s)              7.0348091488704085
Epoch Time (s)               231.74254728807136
Total Train Time (s)         111536.63572507445
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:10:39.627986 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #492 | Epoch Duration: 231.84513783454895
2020-01-12 23:10:39.628185 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.037047
Z variance train             0.4336427
KL Divergence                42.931076
KL Loss                      4.2931075
QF Loss                      11488.916
VF Loss                      3945.0205
Policy Loss                  -7117.498
Q Predictions Mean           7050.3105
Q Predictions Std            642.417
Q Predictions Max            12235.951
Q Predictions Min            5697.7065
V Predictions Mean           7084.9473
V Predictions Std            666.39075
V Predictions Max            12279.619
V Predictions Min            5693.0625
Log Pis Mean                 8.707691
Log Pis Std                  4.6804876
Log Pis Max                  29.509087
Log Pis Min                  -3.8291552
Policy mu Mean               0.06697017
Policy mu Std                1.2587862
Policy mu Max                4.871582
Policy mu Min                -3.7166586
Policy log std Mean          -1.4225324
Policy log std Std           0.44785038
Policy log std Max           -0.039138198
Policy log std Min           -3.1861918
Z mean eval                  1.8914315
Z variance eval              0.28443044
total_rewards                [-737.72896508   63.83900794 -929.600594    199.63925201 -184.00735382
 -402.28608605 -434.85794543 -132.392523   -466.70068876 -541.84294551]
total_rewards_mean           -356.593884170094
total_rewards_std            330.8271274405835
total_rewards_max            199.63925200854558
total_rewards_min            -929.6005940008433
Number of train steps total  1976000
Number of env steps total    3763456
Number of rollouts total     0
Train Time (s)               193.33683512266725
(Previous) Eval Time (s)     30.56055735098198
Sample Time (s)              7.482133526820689
Epoch Time (s)               231.37952600046992
Total Train Time (s)         111768.1094980673
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:14:31.105346 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #493 | Epoch Duration: 231.4770152568817
2020-01-12 23:14:31.105523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8958088
Z variance train             0.2835125
KL Divergence                38.90511
KL Loss                      3.890511
QF Loss                      8040.51
VF Loss                      2504.5364
Policy Loss                  -6628.8086
Q Predictions Mean           6590.6533
Q Predictions Std            866.90375
Q Predictions Max            11610.57
Q Predictions Min            5198.925
V Predictions Mean           6644.708
V Predictions Std            877.0437
V Predictions Max            11705.524
V Predictions Min            5305.364
Log Pis Mean                 7.371002
Log Pis Std                  3.9325542
Log Pis Max                  20.542555
Log Pis Min                  -1.609133
Policy mu Mean               0.24426101
Policy mu Std                1.0864162
Policy mu Max                3.9768648
Policy mu Min                -3.4483376
Policy log std Mean          -1.5118079
Policy log std Std           0.43517315
Policy log std Max           0.0013449192
Policy log std Min           -3.1434374
Z mean eval                  1.8292286
Z variance eval              0.14469358
total_rewards                [  -51.81336788 -1094.73251429 -1172.85289978  -624.97924002
  -704.40813025   -11.97611531 -1157.01393671 -1103.30083199
 -1110.37143797  -757.51112995]
total_rewards_mean           -778.8959604140617
total_rewards_std            419.47035241689923
total_rewards_max            -11.976115309653348
total_rewards_min            -1172.8528997759613
Number of train steps total  1980000
Number of env steps total    3774193
Number of rollouts total     0
Train Time (s)               193.1196254058741
(Previous) Eval Time (s)     27.456065783742815
Sample Time (s)              7.232394399121404
Epoch Time (s)               227.80808558873832
Total Train Time (s)         111996.0098819416
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:18:19.013165 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #494 | Epoch Duration: 227.9074935913086
2020-01-12 23:18:19.013373 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8260332
Z variance train             0.14528684
KL Divergence                40.95406
KL Loss                      4.095406
QF Loss                      14157.598
VF Loss                      1930.5558
Policy Loss                  -6579.5547
Q Predictions Mean           6515.658
Q Predictions Std            777.98944
Q Predictions Max            11755.119
Q Predictions Min            4798.2715
V Predictions Mean           6575.6807
V Predictions Std            766.03107
V Predictions Max            11832.88
V Predictions Min            4857.3584
Log Pis Mean                 9.307838
Log Pis Std                  4.724609
Log Pis Max                  31.245697
Log Pis Min                  -0.9993284
Policy mu Mean               0.3253857
Policy mu Std                1.27223
Policy mu Max                4.8407145
Policy mu Min                -4.8488836
Policy log std Mean          -1.4477882
Policy log std Std           0.502436
Policy log std Max           0.21406686
Policy log std Min           -2.8640947
Z mean eval                  1.7868315
Z variance eval              0.24698205
total_rewards                [   1.79506846 -529.96841904 -478.68339893 -284.12910182 -226.95114341
 -127.92853399 -119.03962433   12.48466269   -1.514018   -490.20393614]
total_rewards_mean           -224.41384445204025
total_rewards_std            202.3912488409607
total_rewards_max            12.484662689632327
total_rewards_min            -529.9684190359317
Number of train steps total  1984000
Number of env steps total    3786312
Number of rollouts total     0
Train Time (s)               193.64897924195975
(Previous) Eval Time (s)     22.93147394992411
Sample Time (s)              6.4826762354932725
Epoch Time (s)               223.06312942737713
Total Train Time (s)         112219.16648367886
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:22:02.174557 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #495 | Epoch Duration: 223.16102242469788
2020-01-12 23:22:02.174758 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7924391
Z variance train             0.24528822
KL Divergence                38.44943
KL Loss                      3.8449428
QF Loss                      5589.8384
VF Loss                      9163.498
Policy Loss                  -6197.351
Q Predictions Mean           6181.5254
Q Predictions Std            470.4487
Q Predictions Max            10626.346
Q Predictions Min            4908.7246
V Predictions Mean           6286.4014
V Predictions Std            481.25723
V Predictions Max            11009.176
V Predictions Min            5094.5425
Log Pis Mean                 7.0286303
Log Pis Std                  3.6163929
Log Pis Max                  23.441664
Log Pis Min                  -7.2037973
Policy mu Mean               0.35582757
Policy mu Std                1.0524757
Policy mu Max                4.984494
Policy mu Min                -5.7850256
Policy log std Mean          -1.4228644
Policy log std Std           0.4226797
Policy log std Max           0.073429346
Policy log std Min           -2.6064835
Z mean eval                  1.8843981
Z variance eval              0.5916701
total_rewards                [-355.88905543 -348.99735736 -327.02564289 -337.33597954 -385.23662815
 -365.43404533 -365.42477883 -367.94132994 -257.4671056  -195.44978485]
total_rewards_mean           -330.6201707915924
total_rewards_std            56.085521618836204
total_rewards_max            -195.44978485163392
total_rewards_min            -385.23662815371637
Number of train steps total  1988000
Number of env steps total    3797081
Number of rollouts total     0
Train Time (s)               191.7466694302857
(Previous) Eval Time (s)     29.092243359889835
Sample Time (s)              6.863179707434028
Epoch Time (s)               227.70209249760956
Total Train Time (s)         112446.96838477813
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:49.983499 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #496 | Epoch Duration: 227.8085687160492
2020-01-12 23:25:49.983759 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8887413
Z variance train             0.5912138
KL Divergence                37.028076
KL Loss                      3.7028077
QF Loss                      3508.0557
VF Loss                      1284.4365
Policy Loss                  -5507.4043
Q Predictions Mean           5486.24
Q Predictions Std            537.34906
Q Predictions Max            10366.811
Q Predictions Min            4327.1
V Predictions Mean           5526.421
V Predictions Std            538.1245
V Predictions Max            10387.066
V Predictions Min            4413.562
Log Pis Mean                 5.1471806
Log Pis Std                  2.9777026
Log Pis Max                  15.175468
Log Pis Min                  -3.052793
Policy mu Mean               0.22099441
Policy mu Std                0.8749323
Policy mu Max                3.065575
Policy mu Min                -3.4879057
Policy log std Mean          -1.3991604
Policy log std Std           0.325979
Policy log std Max           -0.18841922
Policy log std Min           -2.5558789
Z mean eval                  1.6123072
Z variance eval              0.33947816
total_rewards                [-673.69773313  -44.40681961 -341.94226539 -476.50144621 -663.57510494
   -3.99850117  -37.05645485 -466.84974638 -477.38631275 -893.68975956]
total_rewards_mean           -407.91041439989294
total_rewards_std            286.7330697696883
total_rewards_max            -3.998501170002466
total_rewards_min            -893.6897595616499
Number of train steps total  1992000
Number of env steps total    3807748
Number of rollouts total     0
Train Time (s)               192.4566911761649
(Previous) Eval Time (s)     24.69610058888793
Sample Time (s)              7.6297311671078205
Epoch Time (s)               224.78252293216065
Total Train Time (s)         112671.83122610906
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:29:34.853820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #497 | Epoch Duration: 224.86988425254822
2020-01-12 23:29:34.853975 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #497 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6136646
Z variance train             0.3367433
KL Divergence                30.870487
KL Loss                      3.0870488
QF Loss                      8372.606
VF Loss                      1211.8235
Policy Loss                  -4892.4976
Q Predictions Mean           4868.5737
Q Predictions Std            536.795
Q Predictions Max            9819.286
Q Predictions Min            3991.0188
V Predictions Mean           4886.9062
V Predictions Std            533.6889
V Predictions Max            9927.499
V Predictions Min            4139.7646
Log Pis Mean                 5.8080816
Log Pis Std                  4.459282
Log Pis Max                  35.13434
Log Pis Min                  -4.347142
Policy mu Mean               0.32605076
Policy mu Std                1.0276169
Policy mu Max                4.956944
Policy mu Min                -3.6853983
Policy log std Mean          -1.2501547
Policy log std Std           0.36442035
Policy log std Max           0.16752005
Policy log std Min           -2.4752736
Z mean eval                  1.8800905
Z variance eval              0.47316036
total_rewards                [ -924.39890254    -2.45631382    -3.95028723     4.4399522
     4.96596945   -10.07011116    -7.41796234 -1137.12969505
  -270.03935577    -8.01949393]
total_rewards_mean           -235.4076200187542
total_rewards_std            408.2423067571152
total_rewards_max            4.965969452046482
total_rewards_min            -1137.1296950473347
Number of train steps total  1996000
Number of env steps total    3818852
Number of rollouts total     0
Train Time (s)               192.20721524162218
(Previous) Eval Time (s)     11.028434076812118
Sample Time (s)              6.988685658201575
Epoch Time (s)               210.22433497663587
Total Train Time (s)         112882.16608921904
Epoch                        498
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:33:05.197869 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #498 | Epoch Duration: 210.34377789497375
2020-01-12 23:33:05.198054 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8788446
Z variance train             0.47246593
KL Divergence                29.533203
KL Loss                      2.9533203
QF Loss                      5375.427
VF Loss                      1330.102
Policy Loss                  -4415.892
Q Predictions Mean           4395.6177
Q Predictions Std            477.34848
Q Predictions Max            8411.771
Q Predictions Min            3900.4014
V Predictions Mean           4414.153
V Predictions Std            473.54523
V Predictions Max            8314.569
V Predictions Min            3938.719
Log Pis Mean                 4.602786
Log Pis Std                  3.6746266
Log Pis Max                  18.356514
Log Pis Min                  -5.4311843
Policy mu Mean               0.15391374
Policy mu Std                0.95396715
Policy mu Max                3.5227373
Policy mu Min                -3.1820323
Policy log std Mean          -1.269581
Policy log std Std           0.36922398
Policy log std Max           -0.08074784
Policy log std Min           -2.4811504
Z mean eval                  1.6560724
Z variance eval              0.4425001
total_rewards                [ -334.83168709   -12.40758874 -1394.22871324  -257.31263062
   -27.41226862 -1333.91788414  -251.02273028  -374.29892779
    -3.98674736    -4.80170351]
total_rewards_mean           -399.4220881384319
total_rewards_std            501.0198658498232
total_rewards_max            -3.986747356243806
total_rewards_min            -1394.2287132357756
Number of train steps total  2000000
Number of env steps total    3829828
Number of rollouts total     0
Train Time (s)               191.8595570619218
(Previous) Eval Time (s)     18.45334893791005
Sample Time (s)              6.27131067821756
Epoch Time (s)               216.58421667804942
Total Train Time (s)         113098.84491732111
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:36:41.882709 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #499 | Epoch Duration: 216.68450927734375
2020-01-12 23:36:41.882903 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Iteration #499 | Started Training: True
2020-01-12 23:36:42.579266 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] Variant:
2020-01-12 23:36:42.579783 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 100,
    "embedding_mini_batch_size": 100,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-100",
    "use_gpu": true,
    "gpu_id": 1,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018217813
Z variance train             0.69422555
KL Divergence                0.14797209
KL Loss                      0.01479721
QF Loss                      46.70729
VF Loss                      16.16856
Policy Loss                  -3.9819906
Q Predictions Mean           -0.0022512947
Q Predictions Std            0.0025138475
Q Predictions Max            0.004002746
Q Predictions Min            -0.01302879
V Predictions Mean           -0.0015676554
V Predictions Std            0.0012872805
V Predictions Max            0.002257069
V Predictions Min            -0.0043354146
Log Pis Mean                 -4.0087533
Log Pis Std                  0.5476844
Log Pis Max                  -2.222971
Log Pis Min                  -5.732667
Policy mu Mean               -0.000108715765
Policy mu Std                0.0013636658
Policy mu Max                0.004181002
Policy mu Min                -0.0046730456
Policy log std Mean          -0.0005662386
Policy log std Std           0.0011472128
Policy log std Max           0.0024465274
Policy log std Min           -0.005169934
Z mean eval                  1.116185
Z variance eval              0.0277536
total_rewards                [-176.68147304 -162.82313212 -131.92605433 -134.69176998 -145.40821626
 -166.60860951 -144.72816838 -159.0413528  -162.65548998 -163.03671473]
total_rewards_mean           -154.76009811369642
total_rewards_std            13.954726129258347
total_rewards_max            -131.9260543302745
total_rewards_min            -176.68147303840618
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               186.53654375625774
(Previous) Eval Time (s)     0
Sample Time (s)              12.13370274938643
Epoch Time (s)               198.67024650564417
Total Train Time (s)         224.2318981741555
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:40:26.898523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #0 | Epoch Duration: 224.23730158805847
2020-01-12 23:40:26.898933 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1214924
Z variance train             0.027339641
KL Divergence                10.77993
KL Loss                      1.077993
QF Loss                      66.98274
VF Loss                      11.140207
Policy Loss                  -45.446598
Q Predictions Mean           40.777805
Q Predictions Std            17.961557
Q Predictions Max            102.1574
Q Predictions Min            -15.156419
V Predictions Mean           46.68647
V Predictions Std            18.072783
V Predictions Max            106.22539
V Predictions Min            -10.304118
Log Pis Mean                 -3.4148583
Log Pis Std                  1.1387757
Log Pis Max                  0.4574468
Log Pis Min                  -6.0104647
Policy mu Mean               0.0055068075
Policy mu Std                0.3501075
Policy mu Max                1.7192687
Policy mu Min                -1.1769842
Policy log std Mean          -0.29517165
Policy log std Std           0.07782974
Policy log std Max           -0.15623376
Policy log std Min           -0.65803015
Z mean eval                  1.2590775
Z variance eval              0.03814055
total_rewards                [-107.53743752  -80.08427627 -109.28842128  -75.67491544  -69.15325952
 -146.80039312 -118.89520327  -99.35622364 -107.56259512 -107.76168299]
total_rewards_mean           -102.21144081826144
total_rewards_std            21.67765378570854
total_rewards_max            -69.15325951912568
total_rewards_min            -146.8003931184388
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               187.03156457981095
(Previous) Eval Time (s)     30.042155583389103
Sample Time (s)              6.247888636775315
Epoch Time (s)               223.32160879997537
Total Train Time (s)         447.6399909341708
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:10.306265 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #1 | Epoch Duration: 223.40710163116455
2020-01-12 23:44:10.306489 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.277373
Z variance train             0.032901075
KL Divergence                11.767029
KL Loss                      1.1767029
QF Loss                      67.1552
VF Loss                      14.082468
Policy Loss                  -99.247925
Q Predictions Mean           94.26979
Q Predictions Std            31.237263
Q Predictions Max            183.1977
Q Predictions Min            36.05584
V Predictions Mean           100.23398
V Predictions Std            31.542786
V Predictions Max            189.27489
V Predictions Min            44.259483
Log Pis Mean                 -3.0476556
Log Pis Std                  1.5417147
Log Pis Max                  2.564364
Log Pis Min                  -6.804138
Policy mu Mean               -0.029190028
Policy mu Std                0.4472133
Policy mu Max                1.6589332
Policy mu Min                -1.6432871
Policy log std Mean          -0.33671793
Policy log std Std           0.08637738
Policy log std Max           -0.08763477
Policy log std Min           -0.716629
Z mean eval                  1.4096673
Z variance eval              0.02574269
total_rewards                [-33.76866321 -16.98020005 -77.1960117  -54.66192864 -20.25635187
 -81.87233324 -44.45306427 -25.35346134 -23.96772246 -24.38064153]
total_rewards_mean           -40.28903783060967
total_rewards_std            22.460796620418655
total_rewards_max            -16.980200047569635
total_rewards_min            -81.8723332425624
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               186.47235961584374
(Previous) Eval Time (s)     30.114270615857095
Sample Time (s)              6.181578679941595
Epoch Time (s)               222.76820891164243
Total Train Time (s)         670.4931228985079
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:53.158674 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #2 | Epoch Duration: 222.85204982757568
2020-01-12 23:47:53.158805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4093043
Z variance train             0.025942218
KL Divergence                13.281265
KL Loss                      1.3281265
QF Loss                      62.632263
VF Loss                      17.808714
Policy Loss                  -133.93066
Q Predictions Mean           129.27301
Q Predictions Std            42.240784
Q Predictions Max            271.20953
Q Predictions Min            46.216522
V Predictions Mean           135.80557
V Predictions Std            43.28236
V Predictions Max            266.66885
V Predictions Min            67.841064
Log Pis Mean                 -3.2598743
Log Pis Std                  1.3449094
Log Pis Max                  1.7769213
Log Pis Min                  -7.628059
Policy mu Mean               -0.07194036
Policy mu Std                0.40809822
Policy mu Max                1.6317571
Policy mu Min                -1.7478905
Policy log std Mean          -0.34424224
Policy log std Std           0.08867723
Policy log std Max           -0.14676315
Policy log std Min           -0.73211396
Z mean eval                  1.4753469
Z variance eval              0.023215115
total_rewards                [ 10.54584085  37.27142214 200.56970817  19.33331714  36.11372866
  35.56601372  13.04012965 -39.66171746  40.32447268 104.09874044]
total_rewards_mean           45.720165599299854
total_rewards_std            61.62294510274914
total_rewards_max            200.56970816923382
total_rewards_min            -39.66171746003335
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               187.00732743926346
(Previous) Eval Time (s)     29.70598462410271
Sample Time (s)              6.11197341280058
Epoch Time (s)               222.82528547616675
Total Train Time (s)         893.4041896606795
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:36.072915 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #3 | Epoch Duration: 222.91401386260986
2020-01-12 23:51:36.073049 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4669424
Z variance train             0.02384245
KL Divergence                14.946822
KL Loss                      1.4946822
QF Loss                      127.47774
VF Loss                      12.95183
Policy Loss                  -162.3078
Q Predictions Mean           156.99051
Q Predictions Std            48.539085
Q Predictions Max            283.41388
Q Predictions Min            85.95802
V Predictions Mean           162.06754
V Predictions Std            49.139782
V Predictions Max            298.8394
V Predictions Min            91.71025
Log Pis Mean                 -3.2184267
Log Pis Std                  1.3948534
Log Pis Max                  1.9477053
Log Pis Min                  -6.8302593
Policy mu Mean               0.046453606
Policy mu Std                0.39981836
Policy mu Max                1.758706
Policy mu Min                -1.2574633
Policy log std Mean          -0.33202043
Policy log std Std           0.09875174
Policy log std Max           -0.15120758
Policy log std Min           -0.7950415
Z mean eval                  1.5570865
Z variance eval              0.021421911
total_rewards                [140.07979102 240.58030136 168.53211327 108.01399601 146.93479265
  91.1531475  361.85942735  -4.80900143 154.47942644 502.0021912 ]
total_rewards_mean           190.88261853666575
total_rewards_std            137.82009273189257
total_rewards_max            502.00219120208794
total_rewards_min            -4.8090014258084315
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               187.89768052566797
(Previous) Eval Time (s)     29.900995818898082
Sample Time (s)              6.131760641001165
Epoch Time (s)               223.9304369855672
Total Train Time (s)         1117.4176962003112
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:55:20.086338 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #4 | Epoch Duration: 224.01317739486694
2020-01-12 23:55:20.086531 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5505717
Z variance train             0.021375576
KL Divergence                16.483246
KL Loss                      1.6483246
QF Loss                      181.74393
VF Loss                      14.498477
Policy Loss                  -194.50089
Q Predictions Mean           190.82387
Q Predictions Std            54.94892
Q Predictions Max            327.63672
Q Predictions Min            97.83941
V Predictions Mean           196.74324
V Predictions Std            54.995605
V Predictions Max            326.5769
V Predictions Min            112.95401
Log Pis Mean                 -3.1192887
Log Pis Std                  1.2693834
Log Pis Max                  2.7853668
Log Pis Min                  -7.658803
Policy mu Mean               0.024820572
Policy mu Std                0.42808315
Policy mu Max                1.7239971
Policy mu Min                -1.3266675
Policy log std Mean          -0.34526873
Policy log std Std           0.10341434
Policy log std Max           -0.05072297
Policy log std Min           -0.87378
Z mean eval                  1.5336038
Z variance eval              0.03014021
total_rewards                [1125.81580222 1057.41400578 1009.91205917 1029.08728079 1120.49020476
 1217.52115024 1088.9481573  1035.32626134   18.09231069  956.59804938]
total_rewards_mean           965.9205281664656
total_rewards_std            323.33816636329624
total_rewards_max            1217.5211502440886
total_rewards_min            18.09231069439796
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               187.03594610933214
(Previous) Eval Time (s)     29.98667796002701
Sample Time (s)              6.215880207251757
Epoch Time (s)               223.2385042766109
Total Train Time (s)         1340.7547774175182
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:59:03.423487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #5 | Epoch Duration: 223.33680272102356
2020-01-12 23:59:03.423621 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5315522
Z variance train             0.030231914
KL Divergence                14.619421
KL Loss                      1.4619421
QF Loss                      53.48102
VF Loss                      12.250276
Policy Loss                  -209.51338
Q Predictions Mean           203.33054
Q Predictions Std            60.78292
Q Predictions Max            362.1008
Q Predictions Min            110.38847
V Predictions Mean           208.46619
V Predictions Std            61.18456
V Predictions Max            358.91928
V Predictions Min            117.53277
Log Pis Mean                 -3.1357718
Log Pis Std                  1.3853381
Log Pis Max                  1.5750802
Log Pis Min                  -7.57645
Policy mu Mean               -0.021327076
Policy mu Std                0.4213952
Policy mu Max                2.038096
Policy mu Min                -1.5391566
Policy log std Mean          -0.33819246
Policy log std Std           0.09634786
Policy log std Max           -0.13392954
Policy log std Min           -0.87926114
Z mean eval                  1.5770445
Z variance eval              0.03206729
total_rewards                [ 345.42046229 1477.05803139 1564.00451053 1404.98583175 1488.64931956
 1544.67485028 1424.39850163 1424.8591545  1595.52064989  264.6393122 ]
total_rewards_mean           1253.4210624009754
total_rewards_std            478.26973818349325
total_rewards_max            1595.5206498943685
total_rewards_min            264.63931219771666
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               186.6105377781205
(Previous) Eval Time (s)     30.22968444507569
Sample Time (s)              6.121593052987009
Epoch Time (s)               222.9618152761832
Total Train Time (s)         1563.8031677026302
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:02:46.473205 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #6 | Epoch Duration: 223.049485206604
2020-01-13 00:02:46.473334 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7119061
Z variance train             0.028880779
KL Divergence                17.330532
KL Loss                      1.7330532
QF Loss                      75.96162
VF Loss                      16.831284
Policy Loss                  -250.59352
Q Predictions Mean           243.78476
Q Predictions Std            78.02409
Q Predictions Max            488.13678
Q Predictions Min            139.87979
V Predictions Mean           248.8775
V Predictions Std            77.33309
V Predictions Max            481.83664
V Predictions Min            146.5045
Log Pis Mean                 -2.931977
Log Pis Std                  1.8771968
Log Pis Max                  4.560878
Log Pis Min                  -7.9214497
Policy mu Mean               0.013531075
Policy mu Std                0.48068175
Policy mu Max                1.8789439
Policy mu Min                -1.817888
Policy log std Mean          -0.3477986
Policy log std Std           0.10738941
Policy log std Max           -0.106454074
Policy log std Min           -0.8842462
Z mean eval                  1.6044209
Z variance eval              0.032340888
total_rewards                [1970.5148904  1372.75320807 2215.78543196 1963.63863784 2058.69719251
 1063.31804796 1895.21395774 1995.04105522 2051.12480895 2057.45835971]
total_rewards_mean           1864.3545590351994
total_rewards_std            339.990427674023
total_rewards_max            2215.7854319637536
total_rewards_min            1063.3180479597474
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               187.76601395895705
(Previous) Eval Time (s)     29.743452484253794
Sample Time (s)              6.424291969276965
Epoch Time (s)               223.9337584124878
Total Train Time (s)         1787.8204043027945
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:30.493668 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #7 | Epoch Duration: 224.02020740509033
2020-01-13 00:06:30.493878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.589783
Z variance train             0.03279521
KL Divergence                15.835573
KL Loss                      1.5835574
QF Loss                      218.69362
VF Loss                      32.113552
Policy Loss                  -263.87924
Q Predictions Mean           257.44363
Q Predictions Std            89.77086
Q Predictions Max            520.4503
Q Predictions Min            119.80067
V Predictions Mean           265.21332
V Predictions Std            90.05559
V Predictions Max            512.62756
V Predictions Min            156.82222
Log Pis Mean                 -2.5035925
Log Pis Std                  1.9016542
Log Pis Max                  4.918833
Log Pis Min                  -6.6424823
Policy mu Mean               -0.018255034
Policy mu Std                0.5411281
Policy mu Max                2.111793
Policy mu Min                -1.7452115
Policy log std Mean          -0.37741408
Policy log std Std           0.12737581
Policy log std Max           -0.11921927
Policy log std Min           -0.9974625
Z mean eval                  1.7442287
Z variance eval              0.015829071
total_rewards                [2646.95519982 2754.29749052 2623.06783296 2433.71559212 2774.78783467
 2680.9185814  2615.13462743 2639.81544799 2620.69247865 2594.9336539 ]
total_rewards_mean           2638.4318739465734
total_rewards_std            88.76475854145443
total_rewards_max            2774.7878346698167
total_rewards_min            2433.715592118263
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               186.6866666013375
(Previous) Eval Time (s)     25.83375793788582
Sample Time (s)              6.29637974081561
Epoch Time (s)               218.81680428003892
Total Train Time (s)         2006.7256689369678
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:10:09.401821 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #8 | Epoch Duration: 218.90774655342102
2020-01-13 00:10:09.402163 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7438787
Z variance train             0.015827738
KL Divergence                19.349184
KL Loss                      1.9349184
QF Loss                      111.800705
VF Loss                      28.382107
Policy Loss                  -309.6039
Q Predictions Mean           303.37518
Q Predictions Std            122.33781
Q Predictions Max            668.27966
Q Predictions Min            164.52547
V Predictions Mean           311.71466
V Predictions Std            121.580025
V Predictions Max            662.92017
V Predictions Min            178.52582
Log Pis Mean                 -2.1862736
Log Pis Std                  2.3340807
Log Pis Max                  7.8983955
Log Pis Min                  -10.536825
Policy mu Mean               -0.055970844
Policy mu Std                0.61097825
Policy mu Max                2.001724
Policy mu Min                -2.1186988
Policy log std Mean          -0.4013512
Policy log std Std           0.14681602
Policy log std Max           -0.15798664
Policy log std Min           -1.1409681
Z mean eval                  1.7837355
Z variance eval              0.01542698
total_rewards                [1276.97403439  367.35047825 1772.36154443 2813.16835161 3053.24239124
 2760.184908   3039.91557931 2616.18406667 1177.46491639 2531.74304968]
total_rewards_mean           2140.8589319969483
total_rewards_std            883.7750355690176
total_rewards_max            3053.2423912401996
total_rewards_min            367.3504782461374
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               185.49465434718877
(Previous) Eval Time (s)     30.160845027770847
Sample Time (s)              6.231713667977601
Epoch Time (s)               221.88721304293722
Total Train Time (s)         2228.6971222078428
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:13:51.370805 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #9 | Epoch Duration: 221.96841263771057
2020-01-13 00:13:51.370934 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #9 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7859663
Z variance train             0.014814961
KL Divergence                19.979666
KL Loss                      1.9979666
QF Loss                      120.06738
VF Loss                      53.428066
Policy Loss                  -347.4014
Q Predictions Mean           337.53662
Q Predictions Std            152.54999
Q Predictions Max            769.77405
Q Predictions Min            151.52318
V Predictions Mean           342.24234
V Predictions Std            152.05516
V Predictions Max            773.64294
V Predictions Min            180.33894
Log Pis Mean                 -2.0268993
Log Pis Std                  2.4630027
Log Pis Max                  9.491957
Log Pis Min                  -7.661101
Policy mu Mean               0.043916147
Policy mu Std                0.6222217
Policy mu Max                2.2540858
Policy mu Min                -2.0819285
Policy log std Mean          -0.41828707
Policy log std Std           0.16492899
Policy log std Max           -0.16385925
Policy log std Min           -1.6652082
Z mean eval                  1.8893547
Z variance eval              0.016804403
total_rewards                [3068.09985618 3049.59900571 3180.42414713 3094.60470583 3146.76408737
  600.97132866 3111.64923698 3163.91059613 2852.58824421 3098.42609561]
total_rewards_mean           2836.7037303800803
total_rewards_std            750.3047566991081
total_rewards_max            3180.424147126171
total_rewards_min            600.9713286554063
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               186.7728245612234
(Previous) Eval Time (s)     26.895107528194785
Sample Time (s)              6.095901035703719
Epoch Time (s)               219.7638331251219
Total Train Time (s)         2448.54417149676
Epoch                        10
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:17:31.222632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #10 | Epoch Duration: 219.85155034065247
2020-01-13 00:17:31.222946 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.891436
Z variance train             0.016796809
KL Divergence                21.023157
KL Loss                      2.1023157
QF Loss                      180.0159
VF Loss                      39.736877
Policy Loss                  -382.6513
Q Predictions Mean           374.97528
Q Predictions Std            190.58624
Q Predictions Max            938.9675
Q Predictions Min            175.8277
V Predictions Mean           381.53558
V Predictions Std            192.32536
V Predictions Max            942.4062
V Predictions Min            189.90099
Log Pis Mean                 -1.7657788
Log Pis Std                  2.5921702
Log Pis Max                  8.858339
Log Pis Min                  -6.0932655
Policy mu Mean               -0.024738736
Policy mu Std                0.6804228
Policy mu Max                2.9768522
Policy mu Min                -2.2770364
Policy log std Mean          -0.4335903
Policy log std Std           0.17940935
Policy log std Max           -0.11497718
Policy log std Min           -1.5650802
Z mean eval                  2.0247645
Z variance eval              0.015901688
total_rewards                [3160.53150922 3003.27225475 3167.41556881 3322.43987268 2718.69844918
 3071.41050664 3088.17472558 3139.5209638  3266.31342574 1141.10959544]
total_rewards_mean           2907.8886871847435
total_rewards_std            609.1632670466593
total_rewards_max            3322.4398726765103
total_rewards_min            1141.1095954446848
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               181.0774380369112
(Previous) Eval Time (s)     29.73015234619379
Sample Time (s)              6.354548334144056
Epoch Time (s)               217.16213871724904
Total Train Time (s)         2665.8011199748144
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:21:08.481369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #11 | Epoch Duration: 217.25814771652222
2020-01-13 00:21:08.481699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0246956
Z variance train             0.015901621
KL Divergence                22.988487
KL Loss                      2.2988489
QF Loss                      480.6017
VF Loss                      35.59488
Policy Loss                  -432.46765
Q Predictions Mean           428.03546
Q Predictions Std            235.05957
Q Predictions Max            1093.5465
Q Predictions Min            184.93785
V Predictions Mean           434.73413
V Predictions Std            235.142
V Predictions Max            1078.0251
V Predictions Min            192.9292
Log Pis Mean                 -1.9976823
Log Pis Std                  2.5082452
Log Pis Max                  8.574451
Log Pis Min                  -7.493491
Policy mu Mean               -0.06352374
Policy mu Std                0.64334637
Policy mu Max                2.5146782
Policy mu Min                -2.2544422
Policy log std Mean          -0.41897556
Policy log std Std           0.16602577
Policy log std Max           -0.14639097
Policy log std Min           -1.622341
Z mean eval                  2.1087298
Z variance eval              0.0116963405
total_rewards                [1019.1783857  3347.7468043  3506.69591821 3460.71163905 3375.64391368
 3417.51155772 3414.77353964 3166.85200656 3597.33476437 3275.09425769]
total_rewards_mean           3158.154278692132
total_rewards_std            721.8889748502587
total_rewards_max            3597.3347643698244
total_rewards_min            1019.1783857016727
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               188.10277517605573
(Previous) Eval Time (s)     30.36489338707179
Sample Time (s)              6.14567069336772
Epoch Time (s)               224.61333925649524
Total Train Time (s)         2890.5043285316788
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:24:53.182419 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #12 | Epoch Duration: 224.70049381256104
2020-01-13 00:24:53.182560 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1094308
Z variance train             0.011721242
KL Divergence                23.507256
KL Loss                      2.3507257
QF Loss                      150.19496
VF Loss                      60.16285
Policy Loss                  -486.8051
Q Predictions Mean           476.276
Q Predictions Std            273.098
Q Predictions Max            1112.9072
Q Predictions Min            204.20078
V Predictions Mean           484.13757
V Predictions Std            276.6998
V Predictions Max            1094.7489
V Predictions Min            204.03912
Log Pis Mean                 -1.5187105
Log Pis Std                  2.7121627
Log Pis Max                  8.633623
Log Pis Min                  -6.066738
Policy mu Mean               -0.01230276
Policy mu Std                0.7073393
Policy mu Max                2.450392
Policy mu Min                -2.921397
Policy log std Mean          -0.4382129
Policy log std Std           0.18554692
Policy log std Max           -0.17161568
Policy log std Min           -1.5247829
Z mean eval                  2.1768234
Z variance eval              0.025125396
total_rewards                [3269.60409341 3267.86187593 3700.81070812 3347.35163308 3261.25738771
 3322.92876695 1786.0913654  3395.8835569  3283.19835793 3125.58990528]
total_rewards_mean           3176.057765071547
total_rewards_std            484.25946559135747
total_rewards_max            3700.8107081224634
total_rewards_min            1786.0913653988653
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               187.567043278832
(Previous) Eval Time (s)     30.137128888163716
Sample Time (s)              6.27261994080618
Epoch Time (s)               223.97679210780188
Total Train Time (s)         3114.573692628648
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:28:37.253461 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #13 | Epoch Duration: 224.07080149650574
2020-01-13 00:28:37.253596 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.176237
Z variance train             0.025049541
KL Divergence                22.087545
KL Loss                      2.2087545
QF Loss                      259.75006
VF Loss                      88.34802
Policy Loss                  -534.9407
Q Predictions Mean           527.81274
Q Predictions Std            318.22385
Q Predictions Max            1213.525
Q Predictions Min            171.7709
V Predictions Mean           540.0761
V Predictions Std            319.4243
V Predictions Max            1208.6572
V Predictions Min            212.47977
Log Pis Mean                 -1.536995
Log Pis Std                  2.9946065
Log Pis Max                  9.443102
Log Pis Min                  -7.33166
Policy mu Mean               0.0038221169
Policy mu Std                0.7270519
Policy mu Max                2.585394
Policy mu Min                -2.663643
Policy log std Mean          -0.4403347
Policy log std Std           0.18258862
Policy log std Max           -0.16253981
Policy log std Min           -1.6651633
Z mean eval                  2.211615
Z variance eval              0.020401081
total_rewards                [3723.03073849 3603.66449613 3764.20571669 3618.05663487 3667.59985553
 3717.78943052 3701.44305275 3601.13564836 3710.99177891 3691.3517524 ]
total_rewards_mean           3679.926910466681
total_rewards_std            52.8742197563692
total_rewards_max            3764.205716692099
total_rewards_min            3601.135648359524
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               187.87872691685334
(Previous) Eval Time (s)     29.843519946094602
Sample Time (s)              6.278170013800263
Epoch Time (s)               224.0004168767482
Total Train Time (s)         3338.6618537814356
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:21.342213 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #14 | Epoch Duration: 224.08852195739746
2020-01-13 00:32:21.342347 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2120032
Z variance train             0.020392409
KL Divergence                22.747505
KL Loss                      2.2747505
QF Loss                      633.9502
VF Loss                      55.496944
Policy Loss                  -574.5079
Q Predictions Mean           566.9468
Q Predictions Std            352.69473
Q Predictions Max            1302.4519
Q Predictions Min            174.30328
V Predictions Mean           573.47095
V Predictions Std            353.21124
V Predictions Max            1281.8687
V Predictions Min            184.46327
Log Pis Mean                 -1.374733
Log Pis Std                  2.9607677
Log Pis Max                  8.685177
Log Pis Min                  -6.1761203
Policy mu Mean               -0.062980905
Policy mu Std                0.73179746
Policy mu Max                2.053347
Policy mu Min                -2.4549959
Policy log std Mean          -0.4637089
Policy log std Std           0.21578759
Policy log std Max           -0.16246958
Policy log std Min           -2.0182223
Z mean eval                  2.2524695
Z variance eval              0.025954206
total_rewards                [3599.46511177 3495.65297287 3506.29352231 3568.78448325 3573.08857242
 3480.97652285 3458.91412585 3580.29543605 3310.31792946 3491.64596235]
total_rewards_mean           3506.5434639186833
total_rewards_std            80.08949088347336
total_rewards_max            3599.465111770938
total_rewards_min            3310.3179294592533
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               186.49432657612488
(Previous) Eval Time (s)     25.16356263216585
Sample Time (s)              6.202448897995055
Epoch Time (s)               217.86033810628578
Total Train Time (s)         3556.6045449827798
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:59.286878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #15 | Epoch Duration: 217.94442057609558
2020-01-13 00:35:59.287064 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2449193
Z variance train             0.02606223
KL Divergence                22.704262
KL Loss                      2.2704263
QF Loss                      321.19604
VF Loss                      130.42993
Policy Loss                  -620.48065
Q Predictions Mean           619.6658
Q Predictions Std            371.2636
Q Predictions Max            1319.6528
Q Predictions Min            189.48015
V Predictions Mean           626.31445
V Predictions Std            373.13342
V Predictions Max            1323.444
V Predictions Min            198.1707
Log Pis Mean                 -1.3852212
Log Pis Std                  2.8412874
Log Pis Max                  8.169683
Log Pis Min                  -7.1011944
Policy mu Mean               -0.07810334
Policy mu Std                0.7424491
Policy mu Max                2.3256822
Policy mu Min                -2.9819806
Policy log std Mean          -0.4581561
Policy log std Std           0.19999918
Policy log std Max           -0.16172321
Policy log std Min           -1.7762144
Z mean eval                  2.261516
Z variance eval              0.015488988
total_rewards                [4183.23786865 3941.1741746  3610.30698055 4083.71603214 3872.43085499
 3536.99661784 3816.26316335 3768.14363093 3542.8688872  3471.65483963]
total_rewards_mean           3782.679304985538
total_rewards_std            230.19618922266517
total_rewards_max            4183.237868645795
total_rewards_min            3471.6548396307676
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               186.67199097806588
(Previous) Eval Time (s)     30.24549579806626
Sample Time (s)              6.1165554746985435
Epoch Time (s)               223.03404225083068
Total Train Time (s)         3779.720407000277
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:39:42.406253 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #16 | Epoch Duration: 223.11901926994324
2020-01-13 00:39:42.406510 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.263801
Z variance train             0.0154396845
KL Divergence                24.949615
KL Loss                      2.4949615
QF Loss                      264.20636
VF Loss                      79.59962
Policy Loss                  -638.6625
Q Predictions Mean           628.7418
Q Predictions Std            397.19168
Q Predictions Max            1389.3214
Q Predictions Min            164.77641
V Predictions Mean           639.2584
V Predictions Std            398.33002
V Predictions Max            1388.1776
V Predictions Min            165.8346
Log Pis Mean                 -1.02048
Log Pis Std                  2.9857101
Log Pis Max                  7.908613
Log Pis Min                  -6.353056
Policy mu Mean               -0.10867701
Policy mu Std                0.75677997
Policy mu Max                2.658464
Policy mu Min                -2.3880491
Policy log std Mean          -0.46155748
Policy log std Std           0.18664218
Policy log std Max           -0.18469605
Policy log std Min           -1.8360735
Z mean eval                  2.288576
Z variance eval              0.0174272
total_rewards                [3587.72322897 3935.7429478  3891.82583655 3578.29827853 3664.70206816
 3766.40348016 3738.36572434 3844.12638014 4002.49639562 3648.1150465 ]
total_rewards_mean           3765.7799386774905
total_rewards_std            140.93086751815196
total_rewards_max            4002.4963956241522
total_rewards_min            3578.2982785270947
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               189.30844140192494
(Previous) Eval Time (s)     29.913965615909547
Sample Time (s)              6.206548125017434
Epoch Time (s)               225.42895514285192
Total Train Time (s)         4005.239073525183
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:43:27.924554 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #17 | Epoch Duration: 225.517835855484
2020-01-13 00:43:27.924742 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2886565
Z variance train             0.017387219
KL Divergence                25.591887
KL Loss                      2.5591886
QF Loss                      530.316
VF Loss                      78.51382
Policy Loss                  -609.876
Q Predictions Mean           598.0649
Q Predictions Std            407.74643
Q Predictions Max            1386.2427
Q Predictions Min            157.39949
V Predictions Mean           606.092
V Predictions Std            409.9614
V Predictions Max            1377.4961
V Predictions Min            172.20157
Log Pis Mean                 -1.556395
Log Pis Std                  3.0015988
Log Pis Max                  8.716555
Log Pis Min                  -6.95507
Policy mu Mean               -0.068068035
Policy mu Std                0.70571715
Policy mu Max                2.5368295
Policy mu Min                -2.466396
Policy log std Mean          -0.43164238
Policy log std Std           0.18899567
Policy log std Max           -0.17674501
Policy log std Min           -1.5848029
Z mean eval                  2.3105023
Z variance eval              0.010757058
total_rewards                [4226.01843403 3764.97218208 3993.01697507 4196.76704704 4074.25407067
 3890.86997122  805.47941214 3994.4598708  4017.23666302 4277.70362098]
total_rewards_mean           3724.0778247049902
total_rewards_std            984.0523302194757
total_rewards_max            4277.7036209759335
total_rewards_min            805.4794121395455
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               186.94253124576062
(Previous) Eval Time (s)     25.0320803867653
Sample Time (s)              5.707792361266911
Epoch Time (s)               217.68240399379283
Total Train Time (s)         4223.010848558042
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:47:05.697256 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #18 | Epoch Duration: 217.772367477417
2020-01-13 00:47:05.697439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3100994
Z variance train             0.0107383635
KL Divergence                26.958645
KL Loss                      2.6958644
QF Loss                      571.3604
VF Loss                      117.107
Policy Loss                  -606.83496
Q Predictions Mean           596.9114
Q Predictions Std            435.22836
Q Predictions Max            1509.9663
Q Predictions Min            165.03804
V Predictions Mean           602.5526
V Predictions Std            435.4951
V Predictions Max            1493.4252
V Predictions Min            138.9097
Log Pis Mean                 -1.5195312
Log Pis Std                  3.0494
Log Pis Max                  8.867
Log Pis Min                  -6.6088767
Policy mu Mean               -0.07922266
Policy mu Std                0.7014404
Policy mu Max                2.924916
Policy mu Min                -2.467827
Policy log std Mean          -0.45660266
Policy log std Std           0.20826872
Policy log std Max           -0.18040217
Policy log std Min           -1.8927178
Z mean eval                  2.3214297
Z variance eval              0.005295939
total_rewards                [3732.04063315 4042.83622372 3973.07808004 3867.91139309 3837.59913227
 3797.16437855 3967.28132165 3838.82212135 3955.12069293 3922.73527263]
total_rewards_mean           3893.4589249400146
total_rewards_std            89.915788039988
total_rewards_max            4042.8362237233164
total_rewards_min            3732.0406331531644
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               186.82468362292275
(Previous) Eval Time (s)     24.907658644020557
Sample Time (s)              6.148829197045416
Epoch Time (s)               217.88117146398872
Total Train Time (s)         4440.978407247923
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:50:43.666141 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #19 | Epoch Duration: 217.9685685634613
2020-01-13 00:50:43.666301 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3191516
Z variance train             0.0053063594
KL Divergence                29.117947
KL Loss                      2.9117947
QF Loss                      489.07672
VF Loss                      56.891838
Policy Loss                  -640.7434
Q Predictions Mean           634.59106
Q Predictions Std            435.94543
Q Predictions Max            1452.5421
Q Predictions Min            131.45174
V Predictions Mean           641.65656
V Predictions Std            436.95038
V Predictions Max            1443.6765
V Predictions Min            147.40692
Log Pis Mean                 -1.6666484
Log Pis Std                  2.7677267
Log Pis Max                  6.8426704
Log Pis Min                  -8.418087
Policy mu Mean               -0.05384789
Policy mu Std                0.6949866
Policy mu Max                2.407179
Policy mu Min                -2.2716298
Policy log std Mean          -0.46303257
Policy log std Std           0.20818408
Policy log std Max           -0.18124741
Policy log std Min           -1.78318
Z mean eval                  2.3277297
Z variance eval              0.0149137275
total_rewards                [3993.26864031 3944.34701195 4021.44033132 3875.07091588 3814.82408355
 4047.78482285 4014.22635278 3933.39180902 3981.8534912  3944.96542943]
total_rewards_mean           3957.1172888306
total_rewards_std            67.37277659523573
total_rewards_max            4047.784822852857
total_rewards_min            3814.824083551536
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               187.65797957405448
(Previous) Eval Time (s)     24.9993724450469
Sample Time (s)              6.251295767724514
Epoch Time (s)               218.9086477868259
Total Train Time (s)         4659.96800582204
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:54:22.656830 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #20 | Epoch Duration: 218.99039316177368
2020-01-13 00:54:22.657024 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3264294
Z variance train             0.014927971
KL Divergence                27.34947
KL Loss                      2.734947
QF Loss                      289.753
VF Loss                      94.99451
Policy Loss                  -614.63763
Q Predictions Mean           605.6223
Q Predictions Std            484.44156
Q Predictions Max            1573.2803
Q Predictions Min            127.767075
V Predictions Mean           619.0281
V Predictions Std            488.72177
V Predictions Max            1589.7064
V Predictions Min            135.85036
Log Pis Mean                 -1.5285537
Log Pis Std                  3.1283247
Log Pis Max                  8.49852
Log Pis Min                  -6.866958
Policy mu Mean               -0.055716615
Policy mu Std                0.7067929
Policy mu Max                2.462692
Policy mu Min                -2.5983481
Policy log std Mean          -0.45136622
Policy log std Std           0.19398353
Policy log std Max           -0.14673728
Policy log std Min           -1.6784351
Z mean eval                  2.3162942
Z variance eval              0.005999145
total_rewards                [4139.27787273 4273.61350732 4073.00992073 4144.84936946 4291.86685504
 4277.3926231  4096.05565419 4099.71171015 4329.60084847 4142.7624769 ]
total_rewards_mean           4186.814083809094
total_rewards_std            90.49825018752351
total_rewards_max            4329.6008484663125
total_rewards_min            4073.009920734343
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               186.42733592027798
(Previous) Eval Time (s)     30.15746512217447
Sample Time (s)              5.373653799761087
Epoch Time (s)               221.95845484221354
Total Train Time (s)         4882.009542124346
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:04.699212 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #21 | Epoch Duration: 222.04204082489014
2020-01-13 00:58:04.699391 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3164
Z variance train             0.0060035205
KL Divergence                28.208942
KL Loss                      2.8208942
QF Loss                      276.72644
VF Loss                      47.434357
Policy Loss                  -630.17786
Q Predictions Mean           624.7716
Q Predictions Std            481.44864
Q Predictions Max            1566.7751
Q Predictions Min            120.09857
V Predictions Mean           627.7665
V Predictions Std            482.4407
V Predictions Max            1546.0876
V Predictions Min            121.17372
Log Pis Mean                 -1.3333086
Log Pis Std                  3.2297473
Log Pis Max                  11.456031
Log Pis Min                  -6.1094756
Policy mu Mean               -0.02914352
Policy mu Std                0.7192949
Policy mu Max                2.7500486
Policy mu Min                -2.5695138
Policy log std Mean          -0.44085327
Policy log std Std           0.20478645
Policy log std Max           -0.18517657
Policy log std Min           -1.796461
Z mean eval                  2.3043346
Z variance eval              0.0049277926
total_rewards                [3997.02778602 4210.81239736 4186.95632417 4205.42266936 4158.70007702
 4182.94776908 4073.80362034 4076.48026889 4180.01934211 4094.22261095]
total_rewards_mean           4136.639286529485
total_rewards_std            67.92316648109443
total_rewards_max            4210.8123973645725
total_rewards_min            3997.0277860190004
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               187.95090110227466
(Previous) Eval Time (s)     29.94375248020515
Sample Time (s)              6.120700127445161
Epoch Time (s)               224.01535370992497
Total Train Time (s)         5106.105995318387
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:48.795949 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #22 | Epoch Duration: 224.09643411636353
2020-01-13 01:01:48.796088 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.305245
Z variance train             0.0049202703
KL Divergence                28.735903
KL Loss                      2.8735902
QF Loss                      436.59326
VF Loss                      99.59502
Policy Loss                  -679.84576
Q Predictions Mean           670.43286
Q Predictions Std            496.41782
Q Predictions Max            1577.5027
Q Predictions Min            96.47561
V Predictions Mean           674.77795
V Predictions Std            497.34665
V Predictions Max            1569.4574
V Predictions Min            108.01477
Log Pis Mean                 -1.4531237
Log Pis Std                  2.942501
Log Pis Max                  8.869861
Log Pis Min                  -5.70525
Policy mu Mean               -0.0751229
Policy mu Std                0.71413004
Policy mu Max                2.8821368
Policy mu Min                -2.6274374
Policy log std Mean          -0.45087016
Policy log std Std           0.20952474
Policy log std Max           -0.13065869
Policy log std Min           -1.8851628
Z mean eval                  2.315546
Z variance eval              0.013189207
total_rewards                [4083.97078388 4304.99553856 3903.8149814  4087.94726519 4081.0484921
 4033.77922189 4010.40728439 4297.036935   4105.34366905 3771.19263945]
total_rewards_mean           4067.9536810884756
total_rewards_std            151.7833540557973
total_rewards_max            4304.995538558535
total_rewards_min            3771.192639449912
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               185.56851681694388
(Previous) Eval Time (s)     24.87897790502757
Sample Time (s)              6.1629876885563135
Epoch Time (s)               216.61048241052777
Total Train Time (s)         5322.798249765299
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:05:25.489794 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #23 | Epoch Duration: 216.69359374046326
2020-01-13 01:05:25.489983 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3142838
Z variance train             0.013170253
KL Divergence                27.193293
KL Loss                      2.7193294
QF Loss                      585.23834
VF Loss                      100.74838
Policy Loss                  -650.06757
Q Predictions Mean           642.3779
Q Predictions Std            502.4591
Q Predictions Max            1627.6528
Q Predictions Min            81.06851
V Predictions Mean           645.9719
V Predictions Std            503.12927
V Predictions Max            1594.9814
V Predictions Min            91.03906
Log Pis Mean                 -1.7477769
Log Pis Std                  3.1237414
Log Pis Max                  10.180765
Log Pis Min                  -6.878917
Policy mu Mean               -0.020679621
Policy mu Std                0.69261795
Policy mu Max                2.709046
Policy mu Min                -2.3528333
Policy log std Mean          -0.4355676
Policy log std Std           0.19218686
Policy log std Max           -0.16579375
Policy log std Min           -1.73683
Z mean eval                  2.3194337
Z variance eval              0.00823963
total_rewards                [4153.29011193 4403.39512872 4456.19643842 4332.49338886 4393.99365619
 4262.78559652 4299.66927174 4207.26656603 4308.7260779  4472.5938192 ]
total_rewards_mean           4329.041005552007
total_rewards_std            98.95341369040558
total_rewards_max            4472.593819201539
total_rewards_min            4153.290111933738
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               187.08238202612847
(Previous) Eval Time (s)     30.04587208572775
Sample Time (s)              6.497146645095199
Epoch Time (s)               223.62540075695142
Total Train Time (s)         5546.506484525278
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:09:09.198168 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #24 | Epoch Duration: 223.70805382728577
2020-01-13 01:09:09.198304 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3184438
Z variance train             0.008213124
KL Divergence                28.533037
KL Loss                      2.8533037
QF Loss                      564.8596
VF Loss                      126.466324
Policy Loss                  -642.5711
Q Predictions Mean           638.8376
Q Predictions Std            532.31885
Q Predictions Max            1718.728
Q Predictions Min            62.376743
V Predictions Mean           644.5123
V Predictions Std            532.78986
V Predictions Max            1737.1183
V Predictions Min            70.85693
Log Pis Mean                 -1.5995727
Log Pis Std                  3.1531978
Log Pis Max                  14.670595
Log Pis Min                  -6.885838
Policy mu Mean               -0.07969507
Policy mu Std                0.68582773
Policy mu Max                2.9096346
Policy mu Min                -3.6570435
Policy log std Mean          -0.43911204
Policy log std Std           0.20627983
Policy log std Max           -0.10463607
Policy log std Min           -1.6892155
Z mean eval                  2.330049
Z variance eval              0.0061633587
total_rewards                [4509.12848326 4576.40772385 4393.02316762 4557.9297     4571.29280349
 4407.25930958 4754.62208135 3481.37137649 4526.75913341 4244.69372211]
total_rewards_mean           4402.2487501165915
total_rewards_std            332.74401826705054
total_rewards_max            4754.622081354163
total_rewards_min            3481.3713764920853
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               186.8241559569724
(Previous) Eval Time (s)     30.140699800103903
Sample Time (s)              6.138523204252124
Epoch Time (s)               223.10337896132842
Total Train Time (s)         5769.695867217146
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:12:52.388721 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #25 | Epoch Duration: 223.1903178691864
2020-01-13 01:12:52.388854 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #25 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.330504
Z variance train             0.0061747106
KL Divergence                28.213871
KL Loss                      2.821387
QF Loss                      262.80353
VF Loss                      66.44122
Policy Loss                  -651.41254
Q Predictions Mean           642.7795
Q Predictions Std            524.6292
Q Predictions Max            1683.4128
Q Predictions Min            58.501682
V Predictions Mean           648.7357
V Predictions Std            526.6549
V Predictions Max            1700.7849
V Predictions Min            72.66127
Log Pis Mean                 -1.4557703
Log Pis Std                  3.0919495
Log Pis Max                  8.744531
Log Pis Min                  -6.481897
Policy mu Mean               -0.026587805
Policy mu Std                0.714499
Policy mu Max                2.4621568
Policy mu Min                -2.220748
Policy log std Mean          -0.4411539
Policy log std Std           0.20593071
Policy log std Max           -0.13197672
Policy log std Min           -1.788646
Z mean eval                  2.3216047
Z variance eval              0.0071570603
total_rewards                [4879.90109853 2464.85464299 4731.57374161 4906.74033148 4967.3561752
 4660.75830541 4585.11550567 4691.73864123 4771.7757351  4753.5320949 ]
total_rewards_mean           4541.334627211941
total_rewards_std            701.0373746263828
total_rewards_max            4967.356175195747
total_rewards_min            2464.8546429937546
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               187.01149049773812
(Previous) Eval Time (s)     30.14511080412194
Sample Time (s)              6.218156006652862
Epoch Time (s)               223.37475730851293
Total Train Time (s)         5993.160859564319
Epoch                        26
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:16:35.856850 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #26 | Epoch Duration: 223.46789383888245
2020-01-13 01:16:35.856991 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #26 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3173606
Z variance train             0.0071580643
KL Divergence                27.510548
KL Loss                      2.7510548
QF Loss                      387.6197
VF Loss                      143.2634
Policy Loss                  -697.31116
Q Predictions Mean           689.0975
Q Predictions Std            557.8832
Q Predictions Max            1724.3652
Q Predictions Min            41.05411
V Predictions Mean           703.2322
V Predictions Std            561.965
V Predictions Max            1744.769
V Predictions Min            70.959656
Log Pis Mean                 -1.3588502
Log Pis Std                  3.1929367
Log Pis Max                  11.402835
Log Pis Min                  -5.949246
Policy mu Mean               -0.10711238
Policy mu Std                0.7602245
Policy mu Max                2.7025316
Policy mu Min                -2.7145007
Policy log std Mean          -0.44289777
Policy log std Std           0.2136182
Policy log std Max           -0.1316817
Policy log std Min           -2.0961628
Z mean eval                  2.3126376
Z variance eval              0.006795822
total_rewards                [4331.11138113 4637.55258539 4551.371881   4466.37229792 4640.2982273
 4588.84953939 4331.96892517 4505.16752374 4597.45730491 4528.58445419]
total_rewards_mean           4517.873412012124
total_rewards_std            106.85193456764048
total_rewards_max            4640.298227295942
total_rewards_min            4331.111381133988
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               185.89875526493415
(Previous) Eval Time (s)     30.18023105384782
Sample Time (s)              6.126893553882837
Epoch Time (s)               222.2058798726648
Total Train Time (s)         6215.448753379285
Epoch                        27
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:20:18.147870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #27 | Epoch Duration: 222.29073667526245
2020-01-13 01:20:18.148212 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3122964
Z variance train             0.0067739426
KL Divergence                28.202017
KL Loss                      2.8202016
QF Loss                      187.64554
VF Loss                      66.25015
Policy Loss                  -644.45264
Q Predictions Mean           634.1639
Q Predictions Std            547.639
Q Predictions Max            1733.746
Q Predictions Min            42.16256
V Predictions Mean           642.4997
V Predictions Std            548.8915
V Predictions Max            1731.6792
V Predictions Min            45.083725
Log Pis Mean                 -1.9114116
Log Pis Std                  2.851612
Log Pis Max                  10.692981
Log Pis Min                  -6.3030787
Policy mu Mean               0.04013412
Policy mu Std                0.6544269
Policy mu Max                2.3784354
Policy mu Min                -2.239336
Policy log std Mean          -0.41836438
Policy log std Std           0.21093018
Policy log std Max           -0.052181453
Policy log std Min           -1.9986122
Z mean eval                  2.329613
Z variance eval              0.012489265
total_rewards                [4879.29789344 4679.6394709  4733.15168829 4536.39849542 4725.81094665
 4690.8413323  4805.77859494 4845.92448287 4574.7601608  4433.64359372]
total_rewards_mean           4690.524665933156
total_rewards_std            133.93761884229548
total_rewards_max            4879.297893437456
total_rewards_min            4433.643593724557
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               187.47356081241742
(Previous) Eval Time (s)     24.92675506696105
Sample Time (s)              6.183142495341599
Epoch Time (s)               218.58345837472007
Total Train Time (s)         6434.117592837196
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:23:56.815822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #28 | Epoch Duration: 218.66738724708557
2020-01-13 01:23:56.816020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3300292
Z variance train             0.012573646
KL Divergence                26.975061
KL Loss                      2.6975062
QF Loss                      718.88354
VF Loss                      121.78664
Policy Loss                  -664.93646
Q Predictions Mean           657.0244
Q Predictions Std            556.4698
Q Predictions Max            1780.8668
Q Predictions Min            6.621465
V Predictions Mean           670.9398
V Predictions Std            556.42316
V Predictions Max            1805.3578
V Predictions Min            50.17897
Log Pis Mean                 -1.7280895
Log Pis Std                  2.830935
Log Pis Max                  7.2222033
Log Pis Min                  -7.1920924
Policy mu Mean               -0.059956204
Policy mu Std                0.6583313
Policy mu Max                2.5414426
Policy mu Min                -2.276971
Policy log std Mean          -0.4485413
Policy log std Std           0.22364527
Policy log std Max           -0.1507526
Policy log std Min           -1.9537852
Z mean eval                  2.3427641
Z variance eval              0.007835761
total_rewards                [4895.85020005 5019.48212621 4769.90472431 4653.82933058 4694.49296335
 4866.3468425  4941.32807649 4901.11472869 4757.87261829 4755.23891756]
total_rewards_mean           4825.546052804496
total_rewards_std            110.73164376107488
total_rewards_max            5019.482126214742
total_rewards_min            4653.829330580395
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               187.26852755900472
(Previous) Eval Time (s)     25.436344997026026
Sample Time (s)              6.154297543223947
Epoch Time (s)               218.8591700992547
Total Train Time (s)         6653.063456165604
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:35.765044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #29 | Epoch Duration: 218.94885277748108
2020-01-13 01:27:35.765314 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #29 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3426569
Z variance train             0.007836952
KL Divergence                27.993116
KL Loss                      2.7993116
QF Loss                      281.51324
VF Loss                      117.535164
Policy Loss                  -688.4225
Q Predictions Mean           680.83527
Q Predictions Std            579.2952
Q Predictions Max            1807.273
Q Predictions Min            20.66165
V Predictions Mean           688.93054
V Predictions Std            580.4161
V Predictions Max            1800.971
V Predictions Min            38.20938
Log Pis Mean                 -1.6919024
Log Pis Std                  2.941293
Log Pis Max                  10.095071
Log Pis Min                  -6.533963
Policy mu Mean               0.030880474
Policy mu Std                0.6854854
Policy mu Max                2.1951728
Policy mu Min                -2.4901652
Policy log std Mean          -0.43843198
Policy log std Std           0.21352407
Policy log std Max           -0.16088086
Policy log std Min           -1.9750581
Z mean eval                  2.3132346
Z variance eval              0.020698402
total_rewards                [4789.19348481 4749.39278349 4380.56875027 4560.89215787 4727.7758475
 4993.78874059 4547.27654476 4751.25006433 4472.9353313  4580.29652978]
total_rewards_mean           4655.337023469126
total_rewards_std            170.5157630085754
total_rewards_max            4993.788740588783
total_rewards_min            4380.568750269931
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               183.3120746887289
(Previous) Eval Time (s)     29.075818239711225
Sample Time (s)              6.283630318008363
Epoch Time (s)               218.6715232464485
Total Train Time (s)         6871.831360136624
Epoch                        30
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:31:14.533055 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #30 | Epoch Duration: 218.76754474639893
2020-01-13 01:31:14.533234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3171222
Z variance train             0.02061833
KL Divergence                25.600906
KL Loss                      2.5600908
QF Loss                      582.8331
VF Loss                      113.656746
Policy Loss                  -702.6074
Q Predictions Mean           694.8131
Q Predictions Std            585.4956
Q Predictions Max            1842.825
Q Predictions Min            7.9172697
V Predictions Mean           698.4264
V Predictions Std            586.9429
V Predictions Max            1815.3865
V Predictions Min            25.055412
Log Pis Mean                 -1.4997058
Log Pis Std                  3.2585316
Log Pis Max                  12.715376
Log Pis Min                  -7.489197
Policy mu Mean               -0.048964426
Policy mu Std                0.70062125
Policy mu Max                2.2993186
Policy mu Min                -2.7932374
Policy log std Mean          -0.45395932
Policy log std Std           0.22768855
Policy log std Max           -0.08278164
Policy log std Min           -1.802273
Z mean eval                  2.3369956
Z variance eval              0.015816316
total_rewards                [3982.93051937 4763.31869222 4735.15573606 4838.83478269 4663.75104404
 4607.58384216 4832.51325266 4957.02845654 4820.99972947 4733.64550882]
total_rewards_mean           4693.576156402562
total_rewards_std            254.4695147304463
total_rewards_max            4957.028456541642
total_rewards_min            3982.9305193681816
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               187.16768873576075
(Previous) Eval Time (s)     29.737560973968357
Sample Time (s)              6.081514759454876
Epoch Time (s)               222.98676446918398
Total Train Time (s)         7094.903266110923
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:34:57.604820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #31 | Epoch Duration: 223.07144570350647
2020-01-13 01:34:57.604952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3347492
Z variance train             0.01587791
KL Divergence                26.517792
KL Loss                      2.6517792
QF Loss                      187.72403
VF Loss                      49.03009
Policy Loss                  -702.4566
Q Predictions Mean           695.73676
Q Predictions Std            590.8636
Q Predictions Max            1897.7203
Q Predictions Min            16.83227
V Predictions Mean           703.71155
V Predictions Std            592.2119
V Predictions Max            1889.2379
V Predictions Min            20.433128
Log Pis Mean                 -1.3930576
Log Pis Std                  3.2353072
Log Pis Max                  8.643176
Log Pis Min                  -7.065298
Policy mu Mean               -0.09651235
Policy mu Std                0.72297233
Policy mu Max                2.5366404
Policy mu Min                -2.5932775
Policy log std Mean          -0.4388311
Policy log std Std           0.22131898
Policy log std Max           -0.16971855
Policy log std Min           -1.8646345
Z mean eval                  2.338468
Z variance eval              0.020055538
total_rewards                [4936.91390974 5051.57021611 5032.11536225 4893.4240536  4792.14027906
 5018.40207157 4868.94856339 5174.52962576 5086.98220947 4974.32882208]
total_rewards_mean           4982.935511304217
total_rewards_std            107.48092218945354
total_rewards_max            5174.529625762707
total_rewards_min            4792.140279060133
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               186.32978921895847
(Previous) Eval Time (s)     30.02685507107526
Sample Time (s)              6.097308437805623
Epoch Time (s)               222.45395272783935
Total Train Time (s)         7317.4438992901705
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:40.147996 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #32 | Epoch Duration: 222.54291105270386
2020-01-13 01:38:40.148221 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3391907
Z variance train             0.02006136
KL Divergence                25.483387
KL Loss                      2.5483387
QF Loss                      185.87115
VF Loss                      81.43358
Policy Loss                  -670.9217
Q Predictions Mean           662.0318
Q Predictions Std            603.5328
Q Predictions Max            1971.8575
Q Predictions Min            12.264779
V Predictions Mean           670.6202
V Predictions Std            604.7636
V Predictions Max            1974.203
V Predictions Min            14.023031
Log Pis Mean                 -1.8478699
Log Pis Std                  2.891262
Log Pis Max                  11.158294
Log Pis Min                  -7.3678703
Policy mu Mean               -0.09721344
Policy mu Std                0.6448879
Policy mu Max                2.4899616
Policy mu Min                -2.6294246
Policy log std Mean          -0.44090104
Policy log std Std           0.21214953
Policy log std Max           -0.17215446
Policy log std Min           -1.9087644
Z mean eval                  2.3459783
Z variance eval              0.008068812
total_rewards                [5083.82826427 4909.12466546 5083.4100348  4863.03159672 4908.84202665
 5032.99868764 4653.38679722 4865.21922883 5056.90369512 5162.72916153]
total_rewards_mean           4961.947415823532
total_rewards_std            142.81006923207315
total_rewards_max            5162.729161532076
total_rewards_min            4653.386797216218
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               187.49626199807972
(Previous) Eval Time (s)     30.226757966913283
Sample Time (s)              6.18790445337072
Epoch Time (s)               223.91092441836372
Total Train Time (s)         7541.4429838988
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:42:24.146886 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #33 | Epoch Duration: 223.99851250648499
2020-01-13 01:42:24.147034 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3464637
Z variance train             0.008091072
KL Divergence                27.94888
KL Loss                      2.794888
QF Loss                      599.40686
VF Loss                      120.0859
Policy Loss                  -740.4086
Q Predictions Mean           734.5757
Q Predictions Std            613.80597
Q Predictions Max            1933.6918
Q Predictions Min            2.0934012
V Predictions Mean           744.87506
V Predictions Std            615.8289
V Predictions Max            1974.7507
V Predictions Min            6.5645022
Log Pis Mean                 -1.5697724
Log Pis Std                  3.075431
Log Pis Max                  13.732288
Log Pis Min                  -7.181999
Policy mu Mean               -0.04293451
Policy mu Std                0.7206104
Policy mu Max                2.8725667
Policy mu Min                -2.385202
Policy log std Mean          -0.45940104
Policy log std Std           0.23571487
Policy log std Max           -0.1503782
Policy log std Min           -1.9708989
Z mean eval                  2.36405
Z variance eval              0.0073919417
total_rewards                [5258.54103639 5130.02787987 5247.28464297 5259.65850398 5113.17470315
 5139.90322872 5094.10303476 5030.61547756 4969.17648678 5100.72709493]
total_rewards_mean           5134.321208910935
total_rewards_std            92.28826080377434
total_rewards_max            5259.658503976155
total_rewards_min            4969.176486779153
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               187.69980221800506
(Previous) Eval Time (s)     29.973763442132622
Sample Time (s)              6.186746422201395
Epoch Time (s)               223.86031208233908
Total Train Time (s)         7765.3922274122015
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:46:08.098127 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #34 | Epoch Duration: 223.95099425315857
2020-01-13 01:46:08.098252 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3634734
Z variance train             0.0073644714
KL Divergence                29.044054
KL Loss                      2.9044054
QF Loss                      275.70905
VF Loss                      83.3893
Policy Loss                  -637.4176
Q Predictions Mean           636.4957
Q Predictions Std            608.2523
Q Predictions Max            2020.6548
Q Predictions Min            -1.7746849
V Predictions Mean           640.6804
V Predictions Std            606.5931
V Predictions Max            1996.138
V Predictions Min            -3.5636826
Log Pis Mean                 -2.0169568
Log Pis Std                  2.8388083
Log Pis Max                  8.716924
Log Pis Min                  -7.043212
Policy mu Mean               -0.04487887
Policy mu Std                0.6539405
Policy mu Max                2.8050547
Policy mu Min                -2.3702679
Policy log std Mean          -0.42507228
Policy log std Std           0.20880415
Policy log std Max           -0.16477898
Policy log std Min           -2.1978662
Z mean eval                  2.3751564
Z variance eval              0.0051404512
total_rewards                [5085.45915173 4778.87132882 5163.09908113 5110.47851012 4962.55282942
 5191.85872595 5027.24316654 4991.60882336 4925.56073001 5103.29749399]
total_rewards_mean           5034.002984108074
total_rewards_std            117.7633977404768
total_rewards_max            5191.8587259529595
total_rewards_min            4778.871328819641
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               187.28343902667984
(Previous) Eval Time (s)     30.23688960680738
Sample Time (s)              5.496251503471285
Epoch Time (s)               223.0165801369585
Total Train Time (s)         7988.493226320483
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:49:51.199815 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #35 | Epoch Duration: 223.10146975517273
2020-01-13 01:49:51.199942 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.37167
Z variance train             0.005128695
KL Divergence                30.556913
KL Loss                      3.0556915
QF Loss                      264.30374
VF Loss                      77.42591
Policy Loss                  -721.1884
Q Predictions Mean           712.20483
Q Predictions Std            612.4665
Q Predictions Max            1975.2062
Q Predictions Min            -24.62529
V Predictions Mean           722.0718
V Predictions Std            616.64343
V Predictions Max            2008.0333
V Predictions Min            -14.772296
Log Pis Mean                 -1.4067945
Log Pis Std                  3.3761795
Log Pis Max                  14.118653
Log Pis Min                  -5.840829
Policy mu Mean               -0.02733124
Policy mu Std                0.747882
Policy mu Max                2.77735
Policy mu Min                -2.861706
Policy log std Mean          -0.4483637
Policy log std Std           0.2232943
Policy log std Max           -0.122823775
Policy log std Min           -1.9150996
Z mean eval                  2.351812
Z variance eval              0.0077859843
total_rewards                [5394.22680331 5002.13728627 5138.36341304 5162.4120592  5333.39291634
 5082.48991764 5202.78549353 5350.77919776 5095.11861923 5237.3422392 ]
total_rewards_mean           5199.904794552888
total_rewards_std            121.99364656151877
total_rewards_max            5394.226803313408
total_rewards_min            5002.137286270244
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               187.80885988287628
(Previous) Eval Time (s)     25.092445333022624
Sample Time (s)              6.261330905370414
Epoch Time (s)               219.16263612126932
Total Train Time (s)         8207.738460185006
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:30.448841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #36 | Epoch Duration: 219.24878597259521
2020-01-13 01:53:30.449015 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3497493
Z variance train             0.0076900846
KL Divergence                30.745499
KL Loss                      3.07455
QF Loss                      221.7937
VF Loss                      39.922184
Policy Loss                  -677.49005
Q Predictions Mean           669.8917
Q Predictions Std            635.98346
Q Predictions Max            2016.0519
Q Predictions Min            -35.785034
V Predictions Mean           676.38367
V Predictions Std            638.5241
V Predictions Max            2030.0347
V Predictions Min            -13.127423
Log Pis Mean                 -1.9140017
Log Pis Std                  3.0650356
Log Pis Max                  10.992925
Log Pis Min                  -8.7159605
Policy mu Mean               -0.039244533
Policy mu Std                0.6653469
Policy mu Max                2.9484842
Policy mu Min                -3.2016077
Policy log std Mean          -0.43083477
Policy log std Std           0.2150667
Policy log std Max           -0.1473774
Policy log std Min           -1.8662146
Z mean eval                  2.355947
Z variance eval              0.006538826
total_rewards                [5063.26564059 5284.74346358 5041.44982917 5240.66591778 5096.92954168
 5148.73219477 5335.58753538 5055.57838299 5245.00459007 5151.69133057]
total_rewards_mean           5166.364842657147
total_rewards_std            99.10045722236464
total_rewards_max            5335.58753538016
total_rewards_min            5041.449829171061
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               187.6026408718899
(Previous) Eval Time (s)     30.10955789592117
Sample Time (s)              6.180371064692736
Epoch Time (s)               223.8925698325038
Total Train Time (s)         8431.722772260662
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:57:14.433495 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #37 | Epoch Duration: 223.98435735702515
2020-01-13 01:57:14.433629 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3589053
Z variance train             0.0065583056
KL Divergence                30.747536
KL Loss                      3.0747535
QF Loss                      285.38916
VF Loss                      169.21497
Policy Loss                  -718.3474
Q Predictions Mean           709.5893
Q Predictions Std            651.55365
Q Predictions Max            2051.1838
Q Predictions Min            -19.941395
V Predictions Mean           709.81433
V Predictions Std            652.7802
V Predictions Max            2029.8353
V Predictions Min            -20.760965
Log Pis Mean                 -1.5681865
Log Pis Std                  3.0643296
Log Pis Max                  11.942179
Log Pis Min                  -6.1460824
Policy mu Mean               -0.11640236
Policy mu Std                0.7039405
Policy mu Max                2.705859
Policy mu Min                -2.35048
Policy log std Mean          -0.43285346
Policy log std Std           0.20993826
Policy log std Max           -0.14159463
Policy log std Min           -2.0136814
Z mean eval                  2.362326
Z variance eval              0.0066272514
total_rewards                [5061.64914204 5034.93074564 5201.43937984 5150.65746934 5051.78564064
 5203.67624286 5121.21770366 5089.80824071 5200.5189584  5023.25675526]
total_rewards_mean           5113.8940278402315
total_rewards_std            68.0084703223034
total_rewards_max            5203.676242863217
total_rewards_min            5023.256755255725
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               186.03238970180973
(Previous) Eval Time (s)     29.755556287709624
Sample Time (s)              6.309569858480245
Epoch Time (s)               222.0975158479996
Total Train Time (s)         8653.91114527965
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:00:56.622509 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #38 | Epoch Duration: 222.1887800693512
2020-01-13 02:00:56.622654 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3614924
Z variance train             0.0066348263
KL Divergence                29.657108
KL Loss                      2.9657109
QF Loss                      270.9249
VF Loss                      101.17924
Policy Loss                  -712.41046
Q Predictions Mean           704.51697
Q Predictions Std            653.6545
Q Predictions Max            2039.1741
Q Predictions Min            -44.137974
V Predictions Mean           713.69366
V Predictions Std            660.0907
V Predictions Max            2054.9377
V Predictions Min            -31.023829
Log Pis Mean                 -1.7057719
Log Pis Std                  3.1638482
Log Pis Max                  13.94822
Log Pis Min                  -6.475436
Policy mu Mean               -0.04601699
Policy mu Std                0.71736574
Policy mu Max                2.529251
Policy mu Min                -2.5844107
Policy log std Mean          -0.43965778
Policy log std Std           0.23647435
Policy log std Max           -0.14813411
Policy log std Min           -2.080164
Z mean eval                  2.3609142
Z variance eval              0.0075599076
total_rewards                [5150.8934109  5212.51957026 5325.73019732 5122.92887898 5199.20623068
 1271.55164716 5409.42298559 5266.0592481  5445.85356167 5246.44554692]
total_rewards_mean           4865.061127757658
total_rewards_std            1201.9153805632382
total_rewards_max            5445.853561666168
total_rewards_min            1271.5516471573972
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               187.26287537394091
(Previous) Eval Time (s)     29.919473734218627
Sample Time (s)              6.101108793634921
Epoch Time (s)               223.28345790179446
Total Train Time (s)         8877.281923444942
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:04:39.994803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #39 | Epoch Duration: 223.37205266952515
2020-01-13 02:04:39.994939 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3584332
Z variance train             0.0075560054
KL Divergence                29.040283
KL Loss                      2.9040284
QF Loss                      243.08179
VF Loss                      124.79726
Policy Loss                  -787.9191
Q Predictions Mean           777.5768
Q Predictions Std            680.0288
Q Predictions Max            2052.6404
Q Predictions Min            179.94734
V Predictions Mean           782.23315
V Predictions Std            682.6645
V Predictions Max            2059.7122
V Predictions Min            180.437
Log Pis Mean                 -1.3805761
Log Pis Std                  3.2801957
Log Pis Max                  10.020891
Log Pis Min                  -7.345269
Policy mu Mean               -0.061813787
Policy mu Std                0.7418588
Policy mu Max                2.2255409
Policy mu Min                -2.5994189
Policy log std Mean          -0.45273992
Policy log std Std           0.22853363
Policy log std Max           -0.1534728
Policy log std Min           -1.9543458
Z mean eval                  2.3614738
Z variance eval              0.009289267
total_rewards                [5183.59159834 5173.21116115 5150.97853248 5078.01209606 5144.06040629
 5107.89051406 5228.03267184 5196.63783919 5125.66987071 5208.76964735]
total_rewards_mean           5159.6854337468385
total_rewards_std            44.75577414334385
total_rewards_max            5228.032671841797
total_rewards_min            5078.01209605682
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               187.43691158667207
(Previous) Eval Time (s)     25.745965865906328
Sample Time (s)              9.35299962386489
Epoch Time (s)               222.53587707644328
Total Train Time (s)         9099.906909294892
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:08:22.625924 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #40 | Epoch Duration: 222.63086771965027
2020-01-13 02:08:22.626130 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3616543
Z variance train             0.0092370305
KL Divergence                30.185707
KL Loss                      3.0185707
QF Loss                      254.75703
VF Loss                      181.35594
Policy Loss                  -710.9673
Q Predictions Mean           707.72974
Q Predictions Std            680.5433
Q Predictions Max            2067.04
Q Predictions Min            -32.84908
V Predictions Mean           720.2508
V Predictions Std            686.83923
V Predictions Max            2081.6824
V Predictions Min            -21.194248
Log Pis Mean                 -1.5130305
Log Pis Std                  3.4708452
Log Pis Max                  18.01634
Log Pis Min                  -5.50316
Policy mu Mean               -0.06095312
Policy mu Std                0.70422345
Policy mu Max                3.6581645
Policy mu Min                -2.9677498
Policy log std Mean          -0.43296456
Policy log std Std           0.23787466
Policy log std Max           -0.10976985
Policy log std Min           -2.0640688
Z mean eval                  2.3688579
Z variance eval              0.0096537685
total_rewards                [5476.80359246 5468.63908429 4216.7495802  5455.84050507 5717.08142162
 5339.6669654  5373.30070276 5385.12968222 5427.45285238 5225.71630499]
total_rewards_mean           5308.638069141059
total_rewards_std            382.9599139377829
total_rewards_max            5717.081421621387
total_rewards_min            4216.749580204429
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               188.13359254179522
(Previous) Eval Time (s)     25.380558740813285
Sample Time (s)              6.260247926227748
Epoch Time (s)               219.77439920883626
Total Train Time (s)         9319.798933295067
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:12:02.515098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #41 | Epoch Duration: 219.88881969451904
2020-01-13 02:12:02.515297 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3668494
Z variance train             0.009619373
KL Divergence                29.654888
KL Loss                      2.965489
QF Loss                      728.6374
VF Loss                      96.790985
Policy Loss                  -749.4183
Q Predictions Mean           741.1487
Q Predictions Std            706.76984
Q Predictions Max            2126.7317
Q Predictions Min            -39.323013
V Predictions Mean           750.10474
V Predictions Std            709.538
V Predictions Max            2138.0894
V Predictions Min            -31.119305
Log Pis Mean                 -1.489522
Log Pis Std                  3.3590004
Log Pis Max                  11.610472
Log Pis Min                  -6.4218206
Policy mu Mean               -0.08293486
Policy mu Std                0.70937765
Policy mu Max                2.6021912
Policy mu Min                -2.834172
Policy log std Mean          -0.44863495
Policy log std Std           0.23534204
Policy log std Max           -0.13685474
Policy log std Min           -2.1676292
Z mean eval                  2.3692708
Z variance eval              0.009304547
total_rewards                [5313.01701401 5357.75658983 5285.18921886 5247.99600818 5344.40396325
 5241.1343022  5390.82799345 5221.21004701 5050.4623938  5099.26686901]
total_rewards_mean           5255.126439958842
total_rewards_std            104.2832426698034
total_rewards_max            5390.82799344711
total_rewards_min            5050.462393802077
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               187.41065345471725
(Previous) Eval Time (s)     29.822080318350345
Sample Time (s)              6.129695099778473
Epoch Time (s)               223.36242887284607
Total Train Time (s)         9543.249841254205
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:15:45.966114 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #42 | Epoch Duration: 223.45068097114563
2020-01-13 02:15:45.966244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3640056
Z variance train             0.00934312
KL Divergence                28.912216
KL Loss                      2.8912218
QF Loss                      454.80273
VF Loss                      303.97406
Policy Loss                  -846.66736
Q Predictions Mean           835.37335
Q Predictions Std            706.31506
Q Predictions Max            2145.0984
Q Predictions Min            -57.83733
V Predictions Mean           854.8692
V Predictions Std            713.3689
V Predictions Max            2156.912
V Predictions Min            -29.084175
Log Pis Mean                 -1.1577747
Log Pis Std                  3.617947
Log Pis Max                  20.17926
Log Pis Min                  -6.443304
Policy mu Mean               -0.038590882
Policy mu Std                0.76156914
Policy mu Max                2.6811428
Policy mu Min                -3.0567656
Policy log std Mean          -0.4684956
Policy log std Std           0.22341982
Policy log std Max           -0.09503573
Policy log std Min           -2.1153886
Z mean eval                  2.4190316
Z variance eval              0.0060305935
total_rewards                [5446.35712219 5442.67705062 5512.76479938 5530.58118766 5320.46491814
 5393.03311896 5729.78689183 5343.63595555 5712.256212   5548.96558781]
total_rewards_mean           5498.052284413179
total_rewards_std            132.5143425000901
total_rewards_max            5729.78689183084
total_rewards_min            5320.46491814486
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               185.82769717881456
(Previous) Eval Time (s)     29.63274941779673
Sample Time (s)              6.108668661676347
Epoch Time (s)               221.56911525828764
Total Train Time (s)         9764.959478844889
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:27.677292 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #43 | Epoch Duration: 221.71093344688416
2020-01-13 02:19:27.677487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4174528
Z variance train             0.006037337
KL Divergence                31.881355
KL Loss                      3.1881356
QF Loss                      397.1281
VF Loss                      95.25561
Policy Loss                  -788.4522
Q Predictions Mean           778.66315
Q Predictions Std            699.39545
Q Predictions Max            2161.8882
Q Predictions Min            -71.66083
V Predictions Mean           788.6885
V Predictions Std            703.6272
V Predictions Max            2163.9878
V Predictions Min            -61.477367
Log Pis Mean                 -1.3472238
Log Pis Std                  3.2004662
Log Pis Max                  8.157423
Log Pis Min                  -5.828005
Policy mu Mean               -0.03359602
Policy mu Std                0.72512156
Policy mu Max                2.6467614
Policy mu Min                -2.4927764
Policy log std Mean          -0.44833735
Policy log std Std           0.22547333
Policy log std Max           -0.12073308
Policy log std Min           -1.9132137
Z mean eval                  2.3710697
Z variance eval              0.0039550294
total_rewards                [5252.70477873 5360.16165982 5354.78379076 5465.48633095 5563.29355473
 5490.23399232 5322.3884207  5543.10612448 5366.52232952 5466.83364736]
total_rewards_mean           5418.551462937533
total_rewards_std            96.4736970581384
total_rewards_max            5563.293554734538
total_rewards_min            5252.704778726285
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               187.84508305089548
(Previous) Eval Time (s)     29.82595001719892
Sample Time (s)              6.308025212492794
Epoch Time (s)               223.9790582805872
Total Train Time (s)         9989.021726958454
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:23:11.741285 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #44 | Epoch Duration: 224.06366419792175
2020-01-13 02:23:11.741430 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4239824
Z variance train             0.003744693
KL Divergence                32.034245
KL Loss                      3.2034245
QF Loss                      315.80847
VF Loss                      78.230286
Policy Loss                  -724.29614
Q Predictions Mean           714.53906
Q Predictions Std            719.5357
Q Predictions Max            2191.6653
Q Predictions Min            -58.56738
V Predictions Mean           718.9481
V Predictions Std            720.3429
V Predictions Max            2184.8896
V Predictions Min            -58.60312
Log Pis Mean                 -1.5470811
Log Pis Std                  3.343618
Log Pis Max                  9.26613
Log Pis Min                  -6.7944727
Policy mu Mean               -0.038163476
Policy mu Std                0.70936304
Policy mu Max                2.4173522
Policy mu Min                -3.4935577
Policy log std Mean          -0.43227646
Policy log std Std           0.22288401
Policy log std Max           -0.1015341
Policy log std Min           -1.9387414
Z mean eval                  2.4376724
Z variance eval              0.0023813762
total_rewards                [5604.68745265 5616.33670972 5543.62715372 5667.48876636 5322.84915259
 5687.79290754 5339.70907672 5686.73235544 5557.85593163 5506.92872027]
total_rewards_mean           5553.400822664511
total_rewards_std            125.11558538438177
total_rewards_max            5687.792907539727
total_rewards_min            5322.849152589541
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               186.27469555614516
(Previous) Eval Time (s)     30.010172876995057
Sample Time (s)              6.164170057978481
Epoch Time (s)               222.4490384911187
Total Train Time (s)         10211.553189969156
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:26:54.274498 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #45 | Epoch Duration: 222.53296566009521
2020-01-13 02:26:54.274632 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3707442
Z variance train             0.0025392706
KL Divergence                32.80424
KL Loss                      3.280424
QF Loss                      218.80316
VF Loss                      158.72804
Policy Loss                  -776.4017
Q Predictions Mean           763.90027
Q Predictions Std            707.8289
Q Predictions Max            2195.3713
Q Predictions Min            -62.244125
V Predictions Mean           775.0311
V Predictions Std            709.8807
V Predictions Max            2192.7153
V Predictions Min            -55.456547
Log Pis Mean                 -1.3459849
Log Pis Std                  3.4292464
Log Pis Max                  13.870514
Log Pis Min                  -6.4399204
Policy mu Mean               -0.09310526
Policy mu Std                0.73553663
Policy mu Max                3.3553903
Policy mu Min                -3.2963946
Policy log std Mean          -0.44744024
Policy log std Std           0.22392221
Policy log std Max           -0.15496275
Policy log std Min           -2.1442668
Z mean eval                  2.3824496
Z variance eval              0.008315819
total_rewards                [5776.36003197 5496.44263323 5479.61099669 4408.32545886 5547.14095731
 5357.59575284 5515.68896344 5537.43267016 3473.88793282 4185.78609126]
total_rewards_mean           5077.827148857476
total_rewards_std            730.9373618487468
total_rewards_max            5776.360031967753
total_rewards_min            3473.8879328224557
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               187.4213638510555
(Previous) Eval Time (s)     29.86919728992507
Sample Time (s)              6.253788835834712
Epoch Time (s)               223.54434997681528
Total Train Time (s)         10435.175599944778
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:37.898372 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #46 | Epoch Duration: 223.62362480163574
2020-01-13 02:30:37.898571 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3822732
Z variance train             0.008272995
KL Divergence                33.139206
KL Loss                      3.3139207
QF Loss                      237.86632
VF Loss                      65.518974
Policy Loss                  -767.9112
Q Predictions Mean           756.9458
Q Predictions Std            724.54034
Q Predictions Max            2263.134
Q Predictions Min            -75.85742
V Predictions Mean           769.06055
V Predictions Std            726.93
V Predictions Max            2245.8254
V Predictions Min            -65.195206
Log Pis Mean                 -1.5511365
Log Pis Std                  3.345251
Log Pis Max                  19.585936
Log Pis Min                  -6.955123
Policy mu Mean               -0.0014785659
Policy mu Std                0.6955076
Policy mu Max                3.7488348
Policy mu Min                -3.1610377
Policy log std Mean          -0.46611166
Policy log std Std           0.25068644
Policy log std Max           -0.15089905
Policy log std Min           -2.1429658
Z mean eval                  2.3952305
Z variance eval              0.021143887
total_rewards                [5811.63408185 5629.96645669 5673.87775889 5701.63246019 5316.65634387
 5454.39836084 5466.52699234 5655.96473918 5610.59103921 5772.916265  ]
total_rewards_mean           5609.4164498065265
total_rewards_std            145.95551496690265
total_rewards_max            5811.634081854503
total_rewards_min            5316.656343873898
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               184.9775400799699
(Previous) Eval Time (s)     25.4176829890348
Sample Time (s)              6.254399398807436
Epoch Time (s)               216.64962246781215
Total Train Time (s)         10651.910857778043
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:34:14.637160 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #47 | Epoch Duration: 216.7384181022644
2020-01-13 02:34:14.637438 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3891132
Z variance train             0.020983655
KL Divergence                30.345417
KL Loss                      3.0345418
QF Loss                      985.9297
VF Loss                      347.98706
Policy Loss                  -703.6261
Q Predictions Mean           694.5601
Q Predictions Std            705.77594
Q Predictions Max            2162.5452
Q Predictions Min            -83.197845
V Predictions Mean           707.8051
V Predictions Std            709.2615
V Predictions Max            2174.227
V Predictions Min            -73.05306
Log Pis Mean                 -1.5754405
Log Pis Std                  3.1798344
Log Pis Max                  13.511213
Log Pis Min                  -6.412565
Policy mu Mean               -0.06522762
Policy mu Std                0.70701987
Policy mu Max                3.0875208
Policy mu Min                -2.6817691
Policy log std Mean          -0.4441743
Policy log std Std           0.22624432
Policy log std Max           -0.15550548
Policy log std Min           -1.8382909
Z mean eval                  2.400104
Z variance eval              0.017684087
total_rewards                [5633.0727579  5547.64150276 5387.17167553 5685.00104423 5654.22512444
 5740.98795463 5666.54842195 5696.0034432  5669.67599641 5708.11088094]
total_rewards_mean           5638.843880198393
total_rewards_std            97.09472208770134
total_rewards_max            5740.987954625214
total_rewards_min            5387.171675525068
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               186.2389863235876
(Previous) Eval Time (s)     29.889542726799846
Sample Time (s)              6.171431785915047
Epoch Time (s)               222.2999608363025
Total Train Time (s)         10874.595788502134
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:37:57.321374 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #48 | Epoch Duration: 222.68374252319336
2020-01-13 02:37:57.321528 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4033253
Z variance train             0.017709818
KL Divergence                30.8609
KL Loss                      3.08609
QF Loss                      791.4275
VF Loss                      127.09065
Policy Loss                  -725.4306
Q Predictions Mean           719.43994
Q Predictions Std            707.8625
Q Predictions Max            2236.7498
Q Predictions Min            -69.37448
V Predictions Mean           728.81067
V Predictions Std            709.3252
V Predictions Max            2225.1711
V Predictions Min            -64.68082
Log Pis Mean                 -1.605813
Log Pis Std                  3.2643402
Log Pis Max                  14.297088
Log Pis Min                  -9.263687
Policy mu Mean               -0.051000763
Policy mu Std                0.7403378
Policy mu Max                3.8343883
Policy mu Min                -2.9764898
Policy log std Mean          -0.45969474
Policy log std Std           0.23508367
Policy log std Max           -0.14691462
Policy log std Min           -2.051124
Z mean eval                  2.4149373
Z variance eval              0.009930139
total_rewards                [5574.96773318 5595.77060143 5634.15674    5831.4692461  5665.65323501
 5833.32319959 5453.95280721 5412.63637113 5752.88211705 4595.82514978]
total_rewards_mean           5535.06372004949
total_rewards_std            340.60931265042643
total_rewards_max            5833.323199594375
total_rewards_min            4595.825149780579
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               187.68239828478545
(Previous) Eval Time (s)     25.091157615184784
Sample Time (s)              6.120279508177191
Epoch Time (s)               218.89383540814742
Total Train Time (s)         11093.577175447252
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:36.304795 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #49 | Epoch Duration: 218.98314690589905
2020-01-13 02:41:36.304990 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4162889
Z variance train             0.0099574905
KL Divergence                30.261993
KL Loss                      3.0261993
QF Loss                      285.3009
VF Loss                      84.069435
Policy Loss                  -780.5323
Q Predictions Mean           772.4857
Q Predictions Std            756.4514
Q Predictions Max            2313.1672
Q Predictions Min            -68.39605
V Predictions Mean           776.7488
V Predictions Std            754.3113
V Predictions Max            2287.3123
V Predictions Min            -71.143
Log Pis Mean                 -1.4025378
Log Pis Std                  3.3443189
Log Pis Max                  10.315491
Log Pis Min                  -7.106841
Policy mu Mean               -0.01922196
Policy mu Std                0.7407352
Policy mu Max                2.79578
Policy mu Min                -2.5082207
Policy log std Mean          -0.45403942
Policy log std Std           0.21974629
Policy log std Max           -0.1835373
Policy log std Min           -1.7632263
Z mean eval                  2.4098716
Z variance eval              0.012762261
total_rewards                [5765.6148071  5877.08904629 5837.65709814 5698.21833882 5909.76640606
 6051.0459743  6105.82068099 5938.47559349 5863.63563618 5896.45231148]
total_rewards_mean           5894.377589284916
total_rewards_std            114.43705656685762
total_rewards_max            6105.820680993063
total_rewards_min            5698.218338824145
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               186.43790297675878
(Previous) Eval Time (s)     30.254214324988425
Sample Time (s)              6.14051748579368
Epoch Time (s)               222.83263478754088
Total Train Time (s)         11316.500898300204
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:45:19.230200 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #50 | Epoch Duration: 222.92500042915344
2020-01-13 02:45:19.230504 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #50 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4132237
Z variance train             0.012806797
KL Divergence                28.246328
KL Loss                      2.824633
QF Loss                      392.67755
VF Loss                      213.91095
Policy Loss                  -826.67096
Q Predictions Mean           815.3597
Q Predictions Std            753.7222
Q Predictions Max            2281.3235
Q Predictions Min            -67.1555
V Predictions Mean           821.41614
V Predictions Std            751.3567
V Predictions Max            2271.9094
V Predictions Min            -72.72993
Log Pis Mean                 -1.5005624
Log Pis Std                  3.1420014
Log Pis Max                  9.49777
Log Pis Min                  -5.7915087
Policy mu Mean               -0.09238615
Policy mu Std                0.7402435
Policy mu Max                2.418401
Policy mu Min                -2.786629
Policy log std Mean          -0.46180534
Policy log std Std           0.23953268
Policy log std Max           -0.10065186
Policy log std Min           -1.9378566
Z mean eval                  2.4063053
Z variance eval              0.017880313
total_rewards                [5071.08110075 5538.95343491 5459.79510716 5611.47835621 5475.2292243
 5238.88584135 3286.51143843 5532.87989491 4340.01866582 5632.28347609]
total_rewards_mean           5118.711653993638
total_rewards_std            712.6140000094011
total_rewards_max            5632.283476085522
total_rewards_min            3286.511438427471
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               188.07947316300124
(Previous) Eval Time (s)     25.099488477688283
Sample Time (s)              6.398998690303415
Epoch Time (s)               219.57796033099294
Total Train Time (s)         11536.169902853668
Epoch                        51
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:58.899918 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #51 | Epoch Duration: 219.66922187805176
2020-01-13 02:48:58.900140 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.407617
Z variance train             0.01792757
KL Divergence                28.600338
KL Loss                      2.8600338
QF Loss                      230.44044
VF Loss                      44.49787
Policy Loss                  -804.64575
Q Predictions Mean           800.0997
Q Predictions Std            768.87463
Q Predictions Max            2299.8223
Q Predictions Min            -63.562927
V Predictions Mean           802.4674
V Predictions Std            768.8571
V Predictions Max            2277.0493
V Predictions Min            -72.16001
Log Pis Mean                 -1.6324639
Log Pis Std                  3.100915
Log Pis Max                  9.827938
Log Pis Min                  -6.879979
Policy mu Mean               -0.044882517
Policy mu Std                0.7173642
Policy mu Max                2.5078826
Policy mu Min                -2.6357632
Policy log std Mean          -0.4446074
Policy log std Std           0.21584314
Policy log std Max           -0.14540258
Policy log std Min           -2.1008115
Z mean eval                  2.4158103
Z variance eval              0.0204042
total_rewards                [5541.24712474 6021.18881863 5922.58595873 5651.45867005 5801.04747216
 5755.95284072 5883.51891267 5795.55451458 5780.40219042 5896.84491101]
total_rewards_mean           5804.980141369399
total_rewards_std            130.92776684927827
total_rewards_max            6021.188818625098
total_rewards_min            5541.247124742611
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               185.98303209617734
(Previous) Eval Time (s)     25.048811009153724
Sample Time (s)              6.56935424124822
Epoch Time (s)               217.60119734657928
Total Train Time (s)         11753.854759290814
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:52:36.589757 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #52 | Epoch Duration: 217.68938446044922
2020-01-13 02:52:36.590152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4172795
Z variance train             0.020343397
KL Divergence                29.92098
KL Loss                      2.992098
QF Loss                      823.2987
VF Loss                      107.86604
Policy Loss                  -830.2411
Q Predictions Mean           820.7412
Q Predictions Std            766.1321
Q Predictions Max            2297.1562
Q Predictions Min            -98.742226
V Predictions Mean           831.91
V Predictions Std            766.9009
V Predictions Max            2283.5576
V Predictions Min            -89.97578
Log Pis Mean                 -1.180562
Log Pis Std                  3.4359107
Log Pis Max                  14.085802
Log Pis Min                  -8.393363
Policy mu Mean               -0.055846293
Policy mu Std                0.75830096
Policy mu Max                2.721046
Policy mu Min                -2.768252
Policy log std Mean          -0.4683756
Policy log std Std           0.23229782
Policy log std Max           -0.13658595
Policy log std Min           -2.2511196
Z mean eval                  2.4329562
Z variance eval              0.017811544
total_rewards                [5788.04678046 5738.36865062 6033.08609358 6049.39101195 5851.53975442
 2570.34193043 5880.08815175 6003.13894673 5834.68897167 6085.47464055]
total_rewards_mean           5583.41649321556
total_rewards_std            1010.6981935233288
total_rewards_max            6085.474640545198
total_rewards_min            2570.3419304338536
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               187.6082933647558
(Previous) Eval Time (s)     29.918249714188278
Sample Time (s)              6.239514440763742
Epoch Time (s)               223.76605751970783
Total Train Time (s)         11977.93731464399
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:56:20.671500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #53 | Epoch Duration: 224.0810685157776
2020-01-13 02:56:20.671726 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4345744
Z variance train             0.017822567
KL Divergence                30.587145
KL Loss                      3.0587146
QF Loss                      691.7591
VF Loss                      49.52264
Policy Loss                  -748.4092
Q Predictions Mean           739.7345
Q Predictions Std            749.82544
Q Predictions Max            2377.5457
Q Predictions Min            -77.49824
V Predictions Mean           747.3501
V Predictions Std            753.36066
V Predictions Max            2377.5352
V Predictions Min            -77.81072
Log Pis Mean                 -1.6909995
Log Pis Std                  3.3890202
Log Pis Max                  15.760572
Log Pis Min                  -6.4056926
Policy mu Mean               -0.010802709
Policy mu Std                0.7133555
Policy mu Max                2.8147779
Policy mu Min                -2.673869
Policy log std Mean          -0.44819656
Policy log std Std           0.21460296
Policy log std Max           -0.1516096
Policy log std Min           -2.108212
Z mean eval                  2.4219162
Z variance eval              0.018000547
total_rewards                [5844.55686864 5781.23829157 5770.32512156 5767.3241933  5825.61994519
 5677.3705698  5752.9686167  5609.61544777 5889.38604022 5785.16043966]
total_rewards_mean           5770.356553441033
total_rewards_std            76.06638415254804
total_rewards_max            5889.386040215507
total_rewards_min            5609.615447774476
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               187.7026898758486
(Previous) Eval Time (s)     29.810591076035053
Sample Time (s)              6.284710684791207
Epoch Time (s)               223.79799163667485
Total Train Time (s)         12201.817136217374
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:00:04.554003 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #54 | Epoch Duration: 223.8821063041687
2020-01-13 03:00:04.554263 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #54 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4185386
Z variance train             0.01798318
KL Divergence                29.980762
KL Loss                      2.9980762
QF Loss                      230.69289
VF Loss                      70.60527
Policy Loss                  -760.65155
Q Predictions Mean           752.9823
Q Predictions Std            745.6717
Q Predictions Max            2346.6917
Q Predictions Min            -87.63566
V Predictions Mean           765.49664
V Predictions Std            743.9023
V Predictions Max            2354.3625
V Predictions Min            -95.91559
Log Pis Mean                 -1.7221103
Log Pis Std                  2.7803776
Log Pis Max                  7.611027
Log Pis Min                  -6.420254
Policy mu Mean               -0.06492108
Policy mu Std                0.66961384
Policy mu Max                2.2860217
Policy mu Min                -2.1397767
Policy log std Mean          -0.45217457
Policy log std Std           0.22989108
Policy log std Max           -0.120602444
Policy log std Min           -2.0656178
Z mean eval                  2.3752666
Z variance eval              0.0045114737
total_rewards                [6021.24156528 6073.45284334 6161.63487915 6123.56979356 6067.8540557
 6078.70257209 6259.4608765  6051.724177   6097.60021638 3698.29977539]
total_rewards_mean           5863.354075438229
total_rewards_std            724.4766453240242
total_rewards_max            6259.46087649743
total_rewards_min            3698.299775388022
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               186.9413216789253
(Previous) Eval Time (s)     30.015761643182486
Sample Time (s)              5.184444929007441
Epoch Time (s)               222.14152825111523
Total Train Time (s)         12424.041295584291
Epoch                        55
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:03:46.779782 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #55 | Epoch Duration: 222.22532200813293
2020-01-13 03:03:46.780055 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #55 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3823981
Z variance train             0.004483
KL Divergence                31.857677
KL Loss                      3.185768
QF Loss                      369.6329
VF Loss                      74.01573
Policy Loss                  -719.674
Q Predictions Mean           712.898
Q Predictions Std            741.27673
Q Predictions Max            2395.396
Q Predictions Min            -64.411606
V Predictions Mean           722.4626
V Predictions Std            741.68134
V Predictions Max            2395.5955
V Predictions Min            -81.49657
Log Pis Mean                 -1.3440955
Log Pis Std                  3.3619215
Log Pis Max                  12.041818
Log Pis Min                  -7.070809
Policy mu Mean               -0.041795563
Policy mu Std                0.73741055
Policy mu Max                2.733506
Policy mu Min                -2.940049
Policy log std Mean          -0.43204215
Policy log std Std           0.21448088
Policy log std Max           -0.12023057
Policy log std Min           -2.159181
Z mean eval                  2.4222453
Z variance eval              0.002684382
total_rewards                [5837.96147503 5958.44053963 5963.94546036 5865.14207281 5999.9704002
 6019.90667447 5831.02206694 5833.17985781 5909.66622993 5955.29298409]
total_rewards_mean           5917.452776127009
total_rewards_std            68.02022238639186
total_rewards_max            6019.906674469551
total_rewards_min            5831.022066939676
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               187.82332108682021
(Previous) Eval Time (s)     29.714234991930425
Sample Time (s)              6.178860838059336
Epoch Time (s)               223.71641691680998
Total Train Time (s)         12647.850048990455
Epoch                        56
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:07:30.588168 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #56 | Epoch Duration: 223.80794548988342
2020-01-13 03:07:30.588309 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4680152
Z variance train             0.0026188942
KL Divergence                34.438614
KL Loss                      3.4438615
QF Loss                      214.84642
VF Loss                      58.356316
Policy Loss                  -730.6177
Q Predictions Mean           723.71564
Q Predictions Std            709.34576
Q Predictions Max            2387.1204
Q Predictions Min            -97.41751
V Predictions Mean           730.57214
V Predictions Std            713.1427
V Predictions Max            2360.2334
V Predictions Min            -88.82741
Log Pis Mean                 -1.6511474
Log Pis Std                  3.1292806
Log Pis Max                  9.356824
Log Pis Min                  -6.65555
Policy mu Mean               -0.01967318
Policy mu Std                0.6968759
Policy mu Max                2.4349372
Policy mu Min                -2.5521388
Policy log std Mean          -0.44301084
Policy log std Std           0.23214185
Policy log std Max           -0.13459331
Policy log std Min           -2.137845
Z mean eval                  2.3993518
Z variance eval              0.011217145
total_rewards                [5702.41097301 5621.56648999 5522.87846523 5395.35298196 5659.08180754
 5698.63056891 5555.51899965 5688.20885325 5563.84785369 5736.61402409]
total_rewards_mean           5614.411101730696
total_rewards_std            99.82626659315146
total_rewards_max            5736.614024090868
total_rewards_min            5395.352981961576
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               188.17416345281526
(Previous) Eval Time (s)     30.052103001624346
Sample Time (s)              6.2276957565918565
Epoch Time (s)               224.45396221103147
Total Train Time (s)         12872.389014812652
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:15.128868 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #57 | Epoch Duration: 224.54040813446045
2020-01-13 03:11:15.129108 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #57 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.394729
Z variance train             0.011229368
KL Divergence                29.292364
KL Loss                      2.9292364
QF Loss                      796.96515
VF Loss                      232.04993
Policy Loss                  -773.5665
Q Predictions Mean           765.68286
Q Predictions Std            791.86176
Q Predictions Max            2356.1155
Q Predictions Min            -114.10052
V Predictions Mean           780.9175
V Predictions Std            794.65515
V Predictions Max            2372.1914
V Predictions Min            -94.585724
Log Pis Mean                 -1.5748606
Log Pis Std                  3.5144866
Log Pis Max                  16.594885
Log Pis Min                  -7.4844112
Policy mu Mean               -0.053701133
Policy mu Std                0.7473339
Policy mu Max                2.5522528
Policy mu Min                -2.8658338
Policy log std Mean          -0.45589685
Policy log std Std           0.24414164
Policy log std Max           -0.15025455
Policy log std Min           -2.151228
Z mean eval                  2.4559357
Z variance eval              0.02524751
total_rewards                [6377.22944469 6212.59822463 6085.95251577 6378.21370426 6085.4910081
 6174.59336936 5914.57932569 5840.7229261  6168.55943057 6129.9880424 ]
total_rewards_mean           6136.792799157358
total_rewards_std            163.271984388458
total_rewards_max            6378.213704256258
total_rewards_min            5840.7229260997
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               188.3026502407156
(Previous) Eval Time (s)     24.70129062514752
Sample Time (s)              6.162199261598289
Epoch Time (s)               219.1661401274614
Total Train Time (s)         13091.637116295286
Epoch                        58
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:54.380314 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #58 | Epoch Duration: 219.25102758407593
2020-01-13 03:14:54.380600 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #58 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4408898
Z variance train             0.024933737
KL Divergence                29.48146
KL Loss                      2.948146
QF Loss                      199.6922
VF Loss                      51.874435
Policy Loss                  -800.68805
Q Predictions Mean           791.8583
Q Predictions Std            820.0874
Q Predictions Max            2447.536
Q Predictions Min            -101.70539
V Predictions Mean           796.3973
V Predictions Std            817.67834
V Predictions Max            2445.8657
V Predictions Min            -94.43703
Log Pis Mean                 -1.4783727
Log Pis Std                  3.3681705
Log Pis Max                  10.880018
Log Pis Min                  -7.395627
Policy mu Mean               -0.07149107
Policy mu Std                0.7297866
Policy mu Max                2.5769818
Policy mu Min                -2.4165413
Policy log std Mean          -0.45966554
Policy log std Std           0.23371007
Policy log std Max           -0.15312603
Policy log std Min           -2.2977226
Z mean eval                  2.3764367
Z variance eval              0.013419652
total_rewards                [5750.59561328 5693.96201894 5718.84775894 5737.51942807 5780.226284
 5868.2932524  5635.78680244 5677.66343033 5664.2216719  5736.19925325]
total_rewards_mean           5726.331551356149
total_rewards_std            62.76736417801166
total_rewards_max            5868.2932523957525
total_rewards_min            5635.786802441267
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               188.59358926583081
(Previous) Eval Time (s)     30.567091414239258
Sample Time (s)              6.299307469744235
Epoch Time (s)               225.4599881498143
Total Train Time (s)         13317.193011524621
Epoch                        59
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:18:39.935369 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #59 | Epoch Duration: 225.55457615852356
2020-01-13 03:18:39.935509 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3777962
Z variance train             0.013402419
KL Divergence                28.978098
KL Loss                      2.8978097
QF Loss                      225.28296
VF Loss                      37.506363
Policy Loss                  -706.53656
Q Predictions Mean           698.5772
Q Predictions Std            727.9814
Q Predictions Max            2405.426
Q Predictions Min            -95.00376
V Predictions Mean           706.5227
V Predictions Std            731.0507
V Predictions Max            2409.7207
V Predictions Min            -104.6995
Log Pis Mean                 -1.6892135
Log Pis Std                  2.877324
Log Pis Max                  9.584259
Log Pis Min                  -6.675419
Policy mu Mean               -0.002542463
Policy mu Std                0.67550516
Policy mu Max                2.4831126
Policy mu Min                -2.5414176
Policy log std Mean          -0.44050714
Policy log std Std           0.21526296
Policy log std Max           -0.14759234
Policy log std Min           -2.1111445
Z mean eval                  2.4170582
Z variance eval              0.0061714374
total_rewards                [6070.47205246 6012.9522242  6101.98083896 6136.98202105 2240.06976851
 5744.71547875 5972.63249619 6103.59416063 6074.67126279 6150.36302761]
total_rewards_mean           5660.843333115198
total_rewards_std            1145.6848122141312
total_rewards_max            6150.363027605096
total_rewards_min            2240.0697685092673
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               186.64848724612966
(Previous) Eval Time (s)     29.855086382944137
Sample Time (s)              7.514069646131247
Epoch Time (s)               224.01764327520505
Total Train Time (s)         13541.299193346407
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:24.042696 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #60 | Epoch Duration: 224.10708618164062
2020-01-13 03:22:24.042820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4186044
Z variance train             0.0060142665
KL Divergence                31.286446
KL Loss                      3.1286447
QF Loss                      361.5055
VF Loss                      97.50837
Policy Loss                  -846.4148
Q Predictions Mean           836.44434
Q Predictions Std            798.33057
Q Predictions Max            2457.94
Q Predictions Min            -115.63688
V Predictions Mean           843.299
V Predictions Std            799.5073
V Predictions Max            2439.5713
V Predictions Min            -134.94722
Log Pis Mean                 -1.2145281
Log Pis Std                  3.5824015
Log Pis Max                  14.437563
Log Pis Min                  -8.233348
Policy mu Mean               -0.12624179
Policy mu Std                0.7707158
Policy mu Max                3.0216608
Policy mu Min                -3.195116
Policy log std Mean          -0.44568813
Policy log std Std           0.22377536
Policy log std Max           -0.035897553
Policy log std Min           -2.1042163
Z mean eval                  2.3872137
Z variance eval              0.0068397536
total_rewards                [5709.55215659 5727.83927559 5513.26093451 5572.65780786 5634.15251296
 5717.42876185 5611.66816672 5502.92566719 5718.97430213 5562.52422003]
total_rewards_mean           5627.098380543185
total_rewards_std            83.27508221345062
total_rewards_max            5727.83927558907
total_rewards_min            5502.925667194192
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               187.9925628551282
(Previous) Eval Time (s)     30.148482660762966
Sample Time (s)              6.137740980368108
Epoch Time (s)               224.27878649625927
Total Train Time (s)         13765.668768367264
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:26:08.416322 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #61 | Epoch Duration: 224.3733742237091
2020-01-13 03:26:08.416577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3858867
Z variance train             0.0068444414
KL Divergence                32.805763
KL Loss                      3.2805765
QF Loss                      209.72528
VF Loss                      105.94847
Policy Loss                  -764.51587
Q Predictions Mean           755.84753
Q Predictions Std            772.1166
Q Predictions Max            2443.795
Q Predictions Min            -110.25078
V Predictions Mean           761.7869
V Predictions Std            767.99725
V Predictions Max            2400.9292
V Predictions Min            -110.772446
Log Pis Mean                 -1.4946594
Log Pis Std                  3.1974585
Log Pis Max                  10.268626
Log Pis Min                  -6.929656
Policy mu Mean               -0.05547144
Policy mu Std                0.716625
Policy mu Max                2.2603452
Policy mu Min                -2.582688
Policy log std Mean          -0.44167376
Policy log std Std           0.21908772
Policy log std Max           -0.12808758
Policy log std Min           -2.290547
Z mean eval                  2.3897653
Z variance eval              0.008569826
total_rewards                [6160.24325809 6171.41421641 6151.44957153 6054.60819564 6032.30289266
 6115.4645797  5987.49069728 5790.41308063 6043.64163595 5894.50073039]
total_rewards_mean           6040.152885827346
total_rewards_std            116.76926583359503
total_rewards_max            6171.414216407587
total_rewards_min            5790.41308063217
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               186.730641042348
(Previous) Eval Time (s)     29.91351104201749
Sample Time (s)              6.076122652273625
Epoch Time (s)               222.7202747366391
Total Train Time (s)         13988.471289599314
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:29:51.219189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #62 | Epoch Duration: 222.80241870880127
2020-01-13 03:29:51.219370 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3890877
Z variance train             0.008639792
KL Divergence                33.08727
KL Loss                      3.308727
QF Loss                      269.77203
VF Loss                      199.41914
Policy Loss                  -807.3063
Q Predictions Mean           803.4875
Q Predictions Std            809.42065
Q Predictions Max            2502.2432
Q Predictions Min            -113.89395
V Predictions Mean           818.3779
V Predictions Std            815.795
V Predictions Max            2520.215
V Predictions Min            -111.673836
Log Pis Mean                 -1.222328
Log Pis Std                  3.2606483
Log Pis Max                  11.806016
Log Pis Min                  -6.593865
Policy mu Mean               0.0059359595
Policy mu Std                0.7690601
Policy mu Max                2.6348867
Policy mu Min                -3.3578389
Policy log std Mean          -0.46734187
Policy log std Std           0.2454035
Policy log std Max           -0.037298977
Policy log std Min           -2.0184257
Z mean eval                  2.423922
Z variance eval              0.017593164
total_rewards                [5381.63581114 6297.29328948 6110.84029227 6105.40027958 5092.75556348
 4609.89595557 6378.41618638 6132.52439837 5929.97142515 5923.92038866]
total_rewards_mean           5796.265359007499
total_rewards_std            548.2708889531251
total_rewards_max            6378.416186375862
total_rewards_min            4609.895955565042
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               184.78909204388037
(Previous) Eval Time (s)     30.11633804719895
Sample Time (s)              6.293021673336625
Epoch Time (s)               221.19845176441595
Total Train Time (s)         14209.74754405301
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:33:32.496744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #63 | Epoch Duration: 221.27724409103394
2020-01-13 03:33:32.496877 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4248402
Z variance train             0.017598173
KL Divergence                29.35921
KL Loss                      2.935921
QF Loss                      693.9475
VF Loss                      132.6536
Policy Loss                  -813.1869
Q Predictions Mean           804.7069
Q Predictions Std            793.9799
Q Predictions Max            2459.782
Q Predictions Min            -115.42399
V Predictions Mean           811.1515
V Predictions Std            794.03827
V Predictions Max            2445.9133
V Predictions Min            -103.94168
Log Pis Mean                 -1.3539191
Log Pis Std                  3.3639278
Log Pis Max                  14.547317
Log Pis Min                  -6.901544
Policy mu Mean               -0.031777803
Policy mu Std                0.7626281
Policy mu Max                3.8937304
Policy mu Min                -3.100086
Policy log std Mean          -0.4694045
Policy log std Std           0.2300873
Policy log std Max           -0.15268262
Policy log std Min           -2.0503042
Z mean eval                  2.3712795
Z variance eval              0.019231234
total_rewards                [6071.34454816 6271.51235163 6210.94956856 6331.18718357 6625.94868852
 6361.80251647 6441.67447148 6329.46288898 6410.50039181 6383.71576586]
total_rewards_mean           6343.809837505704
total_rewards_std            138.93341759151417
total_rewards_max            6625.948688524013
total_rewards_min            6071.344548159205
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               186.28503796597943
(Previous) Eval Time (s)     29.810289926826954
Sample Time (s)              6.317941215354949
Epoch Time (s)               222.41326910816133
Total Train Time (s)         14432.246422992554
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:37:14.999121 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #64 | Epoch Duration: 222.50211787223816
2020-01-13 03:37:14.999356 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.359745
Z variance train             0.019650247
KL Divergence                30.138496
KL Loss                      3.0138497
QF Loss                      502.02545
VF Loss                      337.1417
Policy Loss                  -877.4549
Q Predictions Mean           871.87805
Q Predictions Std            827.642
Q Predictions Max            2441.7034
Q Predictions Min            -109.69705
V Predictions Mean           889.2473
V Predictions Std            834.77747
V Predictions Max            2456.3506
V Predictions Min            -102.8182
Log Pis Mean                 -1.2732406
Log Pis Std                  3.3807056
Log Pis Max                  11.678955
Log Pis Min                  -10.730068
Policy mu Mean               -0.050059874
Policy mu Std                0.7726734
Policy mu Max                3.046837
Policy mu Min                -2.8757114
Policy log std Mean          -0.4674554
Policy log std Std           0.23380652
Policy log std Max           -0.118224055
Policy log std Min           -2.1714919
Z mean eval                  2.358163
Z variance eval              0.006485434
total_rewards                [5953.64692014 5893.01275951 5607.60296982 5950.3491492  5980.90487892
 5901.20521941 5931.09691229 6005.54124577 6097.42879696 5874.91276393]
total_rewards_mean           5919.570161593418
total_rewards_std            120.57714758050122
total_rewards_max            6097.428796955432
total_rewards_min            5607.602969816702
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               187.83497433410957
(Previous) Eval Time (s)     24.9456902788952
Sample Time (s)              6.10947335138917
Epoch Time (s)               218.89013796439394
Total Train Time (s)         14651.225688688923
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:40:53.981733 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #65 | Epoch Duration: 218.98219513893127
2020-01-13 03:40:53.981937 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3474975
Z variance train             0.006657602
KL Divergence                31.815937
KL Loss                      3.1815937
QF Loss                      193.41861
VF Loss                      66.30578
Policy Loss                  -756.3035
Q Predictions Mean           749.3548
Q Predictions Std            776.6974
Q Predictions Max            2455.4968
Q Predictions Min            -140.79414
V Predictions Mean           755.3783
V Predictions Std            778.27893
V Predictions Max            2430.6038
V Predictions Min            -120.94453
Log Pis Mean                 -1.5276365
Log Pis Std                  3.1590214
Log Pis Max                  9.344141
Log Pis Min                  -6.3552027
Policy mu Mean               -0.08263319
Policy mu Std                0.6996278
Policy mu Max                2.3763134
Policy mu Min                -2.6267061
Policy log std Mean          -0.4513552
Policy log std Std           0.23325387
Policy log std Max           -0.08411935
Policy log std Min           -2.2423096
Z mean eval                  2.3638089
Z variance eval              0.01374543
total_rewards                [5870.7773472  5862.14248766 5929.32884651 5884.86198266 6057.48404387
 5911.39730999 5837.21117545 5656.59505225 6027.97099544 5954.71017645]
total_rewards_mean           5899.247941747322
total_rewards_std            105.29014506306054
total_rewards_max            6057.484043870576
total_rewards_min            5656.595052249281
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               188.0287812212482
(Previous) Eval Time (s)     25.319307531695813
Sample Time (s)              6.212527679279447
Epoch Time (s)               219.56061643222347
Total Train Time (s)         14870.873629646376
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:44:33.633613 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #66 | Epoch Duration: 219.65149760246277
2020-01-13 03:44:33.633947 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3589544
Z variance train             0.013750893
KL Divergence                32.303722
KL Loss                      3.2303722
QF Loss                      255.79582
VF Loss                      174.76811
Policy Loss                  -822.80005
Q Predictions Mean           817.1772
Q Predictions Std            794.24786
Q Predictions Max            2474.4214
Q Predictions Min            -130.80072
V Predictions Mean           831.1282
V Predictions Std            799.8485
V Predictions Max            2461.6987
V Predictions Min            -116.563866
Log Pis Mean                 -1.208628
Log Pis Std                  3.493672
Log Pis Max                  10.598558
Log Pis Min                  -7.842445
Policy mu Mean               -0.057117973
Policy mu Std                0.7567594
Policy mu Max                2.5699635
Policy mu Min                -2.6594007
Policy log std Mean          -0.48897243
Policy log std Std           0.2434632
Policy log std Max           -0.13783087
Policy log std Min           -2.1528716
Z mean eval                  2.3480186
Z variance eval              0.018309932
total_rewards                [2528.06670893 6243.57931495 6378.41913935 6210.16551937 6220.50905382
 6310.38119174 6147.87511108 6202.53654786 6224.39303699 6186.94811168]
total_rewards_mean           5865.287373578007
total_rewards_std            1114.1228834324465
total_rewards_max            6378.419139348064
total_rewards_min            2528.066708933844
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               188.1673838668503
(Previous) Eval Time (s)     29.75428160605952
Sample Time (s)              6.1528732613660395
Epoch Time (s)               224.07453873427585
Total Train Time (s)         15095.03897343669
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:17.798910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #67 | Epoch Duration: 224.16473960876465
2020-01-13 03:48:17.799044 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.347347
Z variance train             0.0182846
KL Divergence                30.62833
KL Loss                      3.062833
QF Loss                      324.07568
VF Loss                      123.35798
Policy Loss                  -764.12036
Q Predictions Mean           752.8854
Q Predictions Std            782.7439
Q Predictions Max            2527.969
Q Predictions Min            -113.03267
V Predictions Mean           758.2476
V Predictions Std            780.53204
V Predictions Max            2543.5754
V Predictions Min            -125.067375
Log Pis Mean                 -1.1401472
Log Pis Std                  3.812455
Log Pis Max                  20.234825
Log Pis Min                  -7.6890106
Policy mu Mean               8.77101e-05
Policy mu Std                0.7951635
Policy mu Max                3.6261878
Policy mu Min                -3.6706023
Policy log std Mean          -0.46469846
Policy log std Std           0.24061549
Policy log std Max           -0.10185714
Policy log std Min           -2.2670624
Z mean eval                  2.372252
Z variance eval              0.019833742
total_rewards                [6267.78025057 6430.50701373 6414.21235906 6512.63634964 6170.79767208
 6274.18646347 6321.9283168  6379.09155925 6356.8619876  6406.8009951 ]
total_rewards_mean           6353.480296729422
total_rewards_std            92.98553429159536
total_rewards_max            6512.6363496423355
total_rewards_min            6170.797672075066
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               186.75817075604573
(Previous) Eval Time (s)     30.17160046612844
Sample Time (s)              6.224948122166097
Epoch Time (s)               223.15471934434026
Total Train Time (s)         15318.289904132951
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:52:01.051243 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #68 | Epoch Duration: 223.25208258628845
2020-01-13 03:52:01.051442 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3710232
Z variance train             0.019907514
KL Divergence                29.780386
KL Loss                      2.9780385
QF Loss                      173.9462
VF Loss                      36.677547
Policy Loss                  -819.9799
Q Predictions Mean           811.0487
Q Predictions Std            832.507
Q Predictions Max            2602.7378
Q Predictions Min            -130.29144
V Predictions Mean           819.2676
V Predictions Std            835.41235
V Predictions Max            2582.1504
V Predictions Min            -124.48591
Log Pis Mean                 -1.0182364
Log Pis Std                  3.6155934
Log Pis Max                  21.739529
Log Pis Min                  -7.333329
Policy mu Mean               -0.094935
Policy mu Std                0.7854345
Policy mu Max                2.7563736
Policy mu Min                -3.481133
Policy log std Mean          -0.46576533
Policy log std Std           0.2210289
Policy log std Max           -0.06901276
Policy log std Min           -2.335439
Z mean eval                  2.3554006
Z variance eval              0.01686182
total_rewards                [6180.02087311 6159.74505673 6183.39201641 6270.32557261 6378.72280081
 6108.92562228 6096.44845029 5914.65077107 6143.10092139 6029.80835064]
total_rewards_mean           6146.514043532895
total_rewards_std            119.67449695934178
total_rewards_max            6378.722800812186
total_rewards_min            5914.650771066295
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               186.99435090692714
(Previous) Eval Time (s)     30.14867762522772
Sample Time (s)              6.414986478164792
Epoch Time (s)               223.55801501031965
Total Train Time (s)         15541.94618464727
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:55:44.707873 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #69 | Epoch Duration: 223.65629172325134
2020-01-13 03:55:44.708025 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3574796
Z variance train             0.01685493
KL Divergence                31.981262
KL Loss                      3.1981263
QF Loss                      436.30237
VF Loss                      75.66874
Policy Loss                  -795.2056
Q Predictions Mean           787.1103
Q Predictions Std            810.22906
Q Predictions Max            2570.332
Q Predictions Min            -117.868866
V Predictions Mean           794.7187
V Predictions Std            813.75543
V Predictions Max            2577.0261
V Predictions Min            -117.465126
Log Pis Mean                 -1.2509468
Log Pis Std                  3.2248554
Log Pis Max                  12.712981
Log Pis Min                  -7.7459927
Policy mu Mean               0.027641967
Policy mu Std                0.75884396
Policy mu Max                2.6628919
Policy mu Min                -2.8339252
Policy log std Mean          -0.47239783
Policy log std Std           0.24126779
Policy log std Max           -0.13287985
Policy log std Min           -2.3453705
Z mean eval                  2.3468366
Z variance eval              0.014217136
total_rewards                [6096.51893407 6168.65722274 6143.30946568 6082.57267142 6325.17076502
 6198.63458537 6136.44968103 6128.3305535  6121.44110893 6105.50953492]
total_rewards_mean           6150.659452267762
total_rewards_std            66.55334935062358
total_rewards_max            6325.170765016041
total_rewards_min            6082.572671416414
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               187.91823762236163
(Previous) Eval Time (s)     29.701641481835395
Sample Time (s)              6.258788112550974
Epoch Time (s)               223.878667216748
Total Train Time (s)         15765.907869180199
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:59:28.670734 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #70 | Epoch Duration: 223.96260809898376
2020-01-13 03:59:28.670870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3467724
Z variance train             0.014160773
KL Divergence                31.097965
KL Loss                      3.1097965
QF Loss                      508.61124
VF Loss                      99.038956
Policy Loss                  -869.2666
Q Predictions Mean           857.90906
Q Predictions Std            838.8051
Q Predictions Max            2564.3342
Q Predictions Min            -132.35233
V Predictions Mean           873.9904
V Predictions Std            840.29205
V Predictions Max            2578.5896
V Predictions Min            -130.1423
Log Pis Mean                 -0.8830212
Log Pis Std                  3.660553
Log Pis Max                  13.926894
Log Pis Min                  -7.457249
Policy mu Mean               -0.025361678
Policy mu Std                0.8169325
Policy mu Max                3.153495
Policy mu Min                -3.4993956
Policy log std Mean          -0.47904643
Policy log std Std           0.22478168
Policy log std Max           -0.1540376
Policy log std Min           -1.9000876
Z mean eval                  2.3175232
Z variance eval              0.03364452
total_rewards                [6524.02243463 6317.74357721 6286.84223727 6356.82136701 6207.69696605
 6334.67978581 6366.01137728 6245.80068577 6227.4907569  6255.0870162 ]
total_rewards_mean           6312.219620412247
total_rewards_std            87.57959845212527
total_rewards_max            6524.022434628004
total_rewards_min            6207.696966050486
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               186.6636098367162
(Previous) Eval Time (s)     25.242909736
Sample Time (s)              5.9698840086348355
Epoch Time (s)               217.87640358135104
Total Train Time (s)         15983.872641241644
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:06.639021 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #71 | Epoch Duration: 217.96802878379822
2020-01-13 04:03:06.639245 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3148694
Z variance train             0.03360928
KL Divergence                29.314878
KL Loss                      2.9314878
QF Loss                      936.5145
VF Loss                      318.80933
Policy Loss                  -877.0834
Q Predictions Mean           862.963
Q Predictions Std            871.062
Q Predictions Max            2628.4817
Q Predictions Min            -127.735664
V Predictions Mean           871.24567
V Predictions Std            871.4121
V Predictions Max            2619.0913
V Predictions Min            -123.6258
Log Pis Mean                 -0.85039294
Log Pis Std                  4.1410136
Log Pis Max                  22.247116
Log Pis Min                  -7.4592257
Policy mu Mean               -0.04091577
Policy mu Std                0.825434
Policy mu Max                4.2792835
Policy mu Min                -3.6096597
Policy log std Mean          -0.48424622
Policy log std Std           0.25045267
Policy log std Max           -0.1302652
Policy log std Min           -2.2602856
Z mean eval                  2.3305237
Z variance eval              0.024451135
total_rewards                [6448.27104524 6477.03518544 6412.82985787 6431.69152085 6479.98192202
 6405.87592937 6489.12435416 6498.44912311 6840.68720324 6370.31804701]
total_rewards_mean           6485.426418830696
total_rewards_std            124.7437313800075
total_rewards_max            6840.6872032424235
total_rewards_min            6370.318047005435
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               188.00310559617355
(Previous) Eval Time (s)     24.562292706221342
Sample Time (s)              6.167634325101972
Epoch Time (s)               218.73303262749687
Total Train Time (s)         16202.685830384027
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:45.454256 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #72 | Epoch Duration: 218.8147747516632
2020-01-13 04:06:45.454565 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3302615
Z variance train             0.024387382
KL Divergence                30.045906
KL Loss                      3.0045907
QF Loss                      198.09451
VF Loss                      96.61368
Policy Loss                  -852.64374
Q Predictions Mean           842.7521
Q Predictions Std            851.6439
Q Predictions Max            2645.5398
Q Predictions Min            -138.99606
V Predictions Mean           846.91394
V Predictions Std            852.1459
V Predictions Max            2653.1511
V Predictions Min            -124.273605
Log Pis Mean                 -1.1481243
Log Pis Std                  3.2427814
Log Pis Max                  17.298122
Log Pis Min                  -8.752647
Policy mu Mean               -0.044123497
Policy mu Std                0.7618923
Policy mu Max                3.1236758
Policy mu Min                -2.4736793
Policy log std Mean          -0.47333083
Policy log std Std           0.24979326
Policy log std Max           -0.046910763
Policy log std Min           -2.2464192
Z mean eval                  2.3149173
Z variance eval              0.009175141
total_rewards                [6242.30623179 6390.35332659 6410.47346258 6464.46247534 6478.67157243
 6474.01302441 6646.48820927 6558.7655532  6458.83572876 6643.54156403]
total_rewards_mean           6476.791114837759
total_rewards_std            114.30702186360993
total_rewards_max            6646.48820926691
total_rewards_min            6242.30623178509
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               187.36251603392884
(Previous) Eval Time (s)     25.885234151035547
Sample Time (s)              6.223514537326992
Epoch Time (s)               219.47126472229138
Total Train Time (s)         16422.2424745257
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:10:25.015407 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #73 | Epoch Duration: 219.5606210231781
2020-01-13 04:10:25.015741 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3145413
Z variance train             0.009225064
KL Divergence                32.066635
KL Loss                      3.2066636
QF Loss                      195.84853
VF Loss                      61.973595
Policy Loss                  -803.36285
Q Predictions Mean           792.35913
Q Predictions Std            808.0722
Q Predictions Max            2569.9539
Q Predictions Min            -143.96129
V Predictions Mean           799.094
V Predictions Std            808.56024
V Predictions Max            2545.4214
V Predictions Min            -121.23529
Log Pis Mean                 -0.7989782
Log Pis Std                  3.3736653
Log Pis Max                  22.786783
Log Pis Min                  -5.7989244
Policy mu Mean               -0.024643742
Policy mu Std                0.7912162
Policy mu Max                3.2584932
Policy mu Min                -3.3031466
Policy log std Mean          -0.46805152
Policy log std Std           0.207691
Policy log std Max           -0.11826259
Policy log std Min           -2.1020055
Z mean eval                  2.3211906
Z variance eval              0.009191343
total_rewards                [6186.49627071 6195.66173632 6176.9572376  5978.60601148 6133.39366539
 6299.77961765 6261.58721831 6192.62315424 6062.46447119 6225.51737266]
total_rewards_mean           6171.308675556176
total_rewards_std            89.0631542881807
total_rewards_max            6299.779617653021
total_rewards_min            5978.606011482679
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               187.91640697000548
(Previous) Eval Time (s)     30.21908902609721
Sample Time (s)              6.177818384021521
Epoch Time (s)               224.3133143801242
Total Train Time (s)         16646.64289480215
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:14:09.415282 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #74 | Epoch Duration: 224.39929842948914
2020-01-13 04:14:09.415478 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.320126
Z variance train             0.009201612
KL Divergence                33.85476
KL Loss                      3.3854759
QF Loss                      344.01086
VF Loss                      108.347046
Policy Loss                  -834.32874
Q Predictions Mean           828.266
Q Predictions Std            865.65314
Q Predictions Max            2593.3071
Q Predictions Min            -175.36786
V Predictions Mean           835.8054
V Predictions Std            866.03564
V Predictions Max            2575.0327
V Predictions Min            -145.48077
Log Pis Mean                 -0.8439014
Log Pis Std                  3.7916675
Log Pis Max                  12.527181
Log Pis Min                  -7.657691
Policy mu Mean               -0.018107133
Policy mu Std                0.8224649
Policy mu Max                3.7209418
Policy mu Min                -2.672105
Policy log std Mean          -0.46968606
Policy log std Std           0.23877181
Policy log std Max           -0.10371685
Policy log std Min           -2.2833257
Z mean eval                  2.3068848
Z variance eval              0.017468853
total_rewards                [5899.01456406 5771.69370131 5838.62331901 5915.45834181 5993.76221538
 6057.27542938 6021.17454882 5917.2314199  5877.30179505 5962.78833455]
total_rewards_mean           5925.432366926352
total_rewards_std            81.83286142596664
total_rewards_max            6057.275429383566
total_rewards_min            5771.693701309531
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               186.54150621592999
(Previous) Eval Time (s)     29.66691958811134
Sample Time (s)              5.296154275536537
Epoch Time (s)               221.50458007957786
Total Train Time (s)         16868.232646904886
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:51.009514 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #75 | Epoch Duration: 221.59385561943054
2020-01-13 04:17:51.009837 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3083467
Z variance train             0.017477468
KL Divergence                33.040756
KL Loss                      3.3040757
QF Loss                      963.52625
VF Loss                      101.68433
Policy Loss                  -908.1293
Q Predictions Mean           902.04846
Q Predictions Std            858.151
Q Predictions Max            2657.494
Q Predictions Min            -129.98488
V Predictions Mean           905.6851
V Predictions Std            854.5807
V Predictions Max            2607.8938
V Predictions Min            -124.76458
Log Pis Mean                 -0.8649101
Log Pis Std                  3.6288497
Log Pis Max                  12.24091
Log Pis Min                  -7.780403
Policy mu Mean               -0.028320992
Policy mu Std                0.8144808
Policy mu Max                3.1976714
Policy mu Min                -2.6893885
Policy log std Mean          -0.48916575
Policy log std Std           0.24291867
Policy log std Max           -0.103580594
Policy log std Min           -1.9538101
Z mean eval                  2.2968848
Z variance eval              0.020519938
total_rewards                [6188.06331216 6285.75475257 5923.42142014 6335.43791203 6109.96600479
 6668.10987157 6245.30885446 6091.00432383 5959.42528998 5812.57340341]
total_rewards_mean           6161.906514496357
total_rewards_std            231.7252349854874
total_rewards_max            6668.109871569147
total_rewards_min            5812.573403412262
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               186.94992478191853
(Previous) Eval Time (s)     30.21073160227388
Sample Time (s)              6.179829629138112
Epoch Time (s)               223.34048601333052
Total Train Time (s)         17091.67013027752
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:34.447283 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #76 | Epoch Duration: 223.437171459198
2020-01-13 04:21:34.447538 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2980907
Z variance train             0.020675037
KL Divergence                31.863327
KL Loss                      3.1863327
QF Loss                      482.0022
VF Loss                      140.97357
Policy Loss                  -839.79913
Q Predictions Mean           834.33154
Q Predictions Std            862.9886
Q Predictions Max            2603.5344
Q Predictions Min            -139.32217
V Predictions Mean           834.5583
V Predictions Std            859.01605
V Predictions Max            2599.4316
V Predictions Min            -132.69312
Log Pis Mean                 -0.9648772
Log Pis Std                  3.3515282
Log Pis Max                  9.666773
Log Pis Min                  -7.123507
Policy mu Mean               -0.019650174
Policy mu Std                0.7890567
Policy mu Max                2.7198925
Policy mu Min                -2.3181617
Policy log std Mean          -0.47309998
Policy log std Std           0.23562622
Policy log std Max           -0.13621974
Policy log std Min           -1.9443295
Z mean eval                  2.3319159
Z variance eval              0.011418047
total_rewards                [6710.80642732 6474.47760675 6317.2546995  6453.68808377 6622.13918514
 6531.55734673 6639.5067453  5474.745193   6476.80350718 6433.98886427]
total_rewards_mean           6413.496765896212
total_rewards_std            331.2434498915697
total_rewards_max            6710.806427321111
total_rewards_min            5474.74519299642
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               187.61130295461044
(Previous) Eval Time (s)     29.69713157368824
Sample Time (s)              6.229361119214445
Epoch Time (s)               223.53779564751312
Total Train Time (s)         17315.303539927118
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:25:18.085038 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #77 | Epoch Duration: 223.63734889030457
2020-01-13 04:25:18.085234 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3296292
Z variance train             0.011476527
KL Divergence                33.39257
KL Loss                      3.339257
QF Loss                      175.44933
VF Loss                      203.09462
Policy Loss                  -848.5214
Q Predictions Mean           846.088
Q Predictions Std            833.7375
Q Predictions Max            2603.375
Q Predictions Min            -146.42192
V Predictions Mean           859.0996
V Predictions Std            839.548
V Predictions Max            2623.292
V Predictions Min            -133.81804
Log Pis Mean                 -0.8667901
Log Pis Std                  3.3441424
Log Pis Max                  12.005741
Log Pis Min                  -6.1380553
Policy mu Mean               -0.019803248
Policy mu Std                0.7858943
Policy mu Max                2.5676227
Policy mu Min                -2.6285186
Policy log std Mean          -0.4860693
Policy log std Std           0.24165413
Policy log std Max           -0.07737237
Policy log std Min           -2.3280113
Z mean eval                  2.348563
Z variance eval              0.009749065
total_rewards                [6306.58761063 6244.77408861 6232.64026819 6336.2872617  3980.29828423
 6415.06518617 6428.48781995 2335.28353703 6116.32169391 6105.45766876]
total_rewards_mean           5650.12034192037
total_rewards_std            1303.3356411316217
total_rewards_max            6428.487819946768
total_rewards_min            2335.283537034675
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               187.753035150934
(Previous) Eval Time (s)     25.292109600268304
Sample Time (s)              6.153411553706974
Epoch Time (s)               219.1985563049093
Total Train Time (s)         17534.597525184043
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:28:57.379765 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #78 | Epoch Duration: 219.29438591003418
2020-01-13 04:28:57.379956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.348301
Z variance train             0.009758553
KL Divergence                35.11766
KL Loss                      3.5117662
QF Loss                      807.72314
VF Loss                      157.86668
Policy Loss                  -730.25977
Q Predictions Mean           726.294
Q Predictions Std            805.37854
Q Predictions Max            2599.7397
Q Predictions Min            -134.74936
V Predictions Mean           740.1377
V Predictions Std            810.1362
V Predictions Max            2610.8562
V Predictions Min            -149.75743
Log Pis Mean                 -1.189068
Log Pis Std                  3.339233
Log Pis Max                  15.4629
Log Pis Min                  -5.8122077
Policy mu Mean               -0.0026043227
Policy mu Std                0.758264
Policy mu Max                2.8484251
Policy mu Min                -3.2117941
Policy log std Mean          -0.47136632
Policy log std Std           0.23852056
Policy log std Max           -0.073294416
Policy log std Min           -2.2548232
Z mean eval                  2.3616357
Z variance eval              0.014461666
total_rewards                [6384.48947218 1570.86292111 6534.26320546 6430.08691265 6450.57675825
 6570.27495518 6606.48670029 6499.39096563 6258.16102486 6631.00958132]
total_rewards_mean           5993.560249692189
total_rewards_std            1478.0174301866882
total_rewards_max            6631.0095813208145
total_rewards_min            1570.8629211088385
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               183.07885195314884
(Previous) Eval Time (s)     31.542519560549408
Sample Time (s)              6.110026977956295
Epoch Time (s)               220.73139849165455
Total Train Time (s)         17755.422124903183
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:32:38.206105 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #79 | Epoch Duration: 220.82598233222961
2020-01-13 04:32:38.206312 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3615487
Z variance train             0.014446586
KL Divergence                34.247868
KL Loss                      3.4247868
QF Loss                      784.51685
VF Loss                      130.85277
Policy Loss                  -807.2466
Q Predictions Mean           801.0978
Q Predictions Std            847.08734
Q Predictions Max            2640.2656
Q Predictions Min            -148.8181
V Predictions Mean           800.96704
V Predictions Std            842.70715
V Predictions Max            2634.8174
V Predictions Min            -137.2716
Log Pis Mean                 -1.3312734
Log Pis Std                  3.1893349
Log Pis Max                  11.274904
Log Pis Min                  -6.368061
Policy mu Mean               -0.054482255
Policy mu Std                0.7466958
Policy mu Max                2.5705614
Policy mu Min                -2.5462592
Policy log std Mean          -0.46443033
Policy log std Std           0.23180914
Policy log std Max           -0.13742694
Policy log std Min           -2.3264027
Z mean eval                  2.3553576
Z variance eval              0.010489114
total_rewards                [6683.82125374 6558.58938088 6777.06037604 6518.69489052 6626.83915435
 6668.22502323 6638.79366212 6852.11990266 6621.75779362 6807.47333149]
total_rewards_mean           6675.337476863727
total_rewards_std            101.93495854834326
total_rewards_max            6852.119902660945
total_rewards_min            6518.694890516369
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               200.7156035369262
(Previous) Eval Time (s)     31.448364545125514
Sample Time (s)              10.477529996540397
Epoch Time (s)               242.64149807859212
Total Train Time (s)         17998.141931990627
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:36:40.927862 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #80 | Epoch Duration: 242.72133040428162
2020-01-13 04:36:40.928190 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3533509
Z variance train             0.010489372
KL Divergence                34.648552
KL Loss                      3.4648552
QF Loss                      222.77513
VF Loss                      91.09363
Policy Loss                  -872.0332
Q Predictions Mean           861.30237
Q Predictions Std            865.9509
Q Predictions Max            2707.5852
Q Predictions Min            242.95177
V Predictions Mean           865.2023
V Predictions Std            867.1558
V Predictions Max            2686.4365
V Predictions Min            247.08351
Log Pis Mean                 -0.852456
Log Pis Std                  3.572194
Log Pis Max                  19.207779
Log Pis Min                  -7.8121777
Policy mu Mean               -0.07282914
Policy mu Std                0.8185904
Policy mu Max                3.182598
Policy mu Min                -2.64822
Policy log std Mean          -0.4821354
Policy log std Std           0.25234863
Policy log std Max           -0.1267047
Policy log std Min           -2.3645098
Z mean eval                  2.3129559
Z variance eval              0.008772245
total_rewards                [6660.07538576 6458.67581128 6593.68945261 6777.61767034 6632.65331835
 6547.13777954 6449.47074699 6860.55734363 6787.58871481 6692.74675574]
total_rewards_mean           6646.0212979047255
total_rewards_std            131.22163122770328
total_rewards_max            6860.557343631944
total_rewards_min            6449.470746985328
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               198.4758815416135
(Previous) Eval Time (s)     31.971007734071463
Sample Time (s)              6.500837113242596
Epoch Time (s)               236.94772638892755
Total Train Time (s)         18235.17316064099
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:37.960060 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #81 | Epoch Duration: 237.03167486190796
2020-01-13 04:40:37.960263 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3112931
Z variance train             0.008735628
KL Divergence                33.106663
KL Loss                      3.3106663
QF Loss                      264.67438
VF Loss                      74.39027
Policy Loss                  -860.8088
Q Predictions Mean           852.5184
Q Predictions Std            880.76587
Q Predictions Max            2681.151
Q Predictions Min            -150.01291
V Predictions Mean           859.94836
V Predictions Std            880.5763
V Predictions Max            2669.7341
V Predictions Min            -137.3824
Log Pis Mean                 -0.97026896
Log Pis Std                  3.1730576
Log Pis Max                  8.960858
Log Pis Min                  -6.735859
Policy mu Mean               0.012121402
Policy mu Std                0.79164827
Policy mu Max                2.4792817
Policy mu Min                -2.6431954
Policy log std Mean          -0.47166857
Policy log std Std           0.21886879
Policy log std Max           -0.15527897
Policy log std Min           -2.2021158
Z mean eval                  2.3683963
Z variance eval              0.007167949
total_rewards                [6408.77287455 6711.35238334 6656.62264612 6629.96363267 6977.21829592
 6818.53487634 7019.80273653 6573.72468659 6453.67749179 6869.79675537]
total_rewards_mean           6711.946637921719
total_rewards_std            197.21233302379
total_rewards_max            7019.802736530285
total_rewards_min            6408.772874547014
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               202.84032157901675
(Previous) Eval Time (s)     34.791180999949574
Sample Time (s)              8.200882754754275
Epoch Time (s)               245.8323853337206
Total Train Time (s)         18481.099270169158
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:44:43.887885 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #82 | Epoch Duration: 245.92746138572693
2020-01-13 04:44:43.888104 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3733568
Z variance train             0.007215789
KL Divergence                34.62836
KL Loss                      3.462836
QF Loss                      413.83508
VF Loss                      133.93056
Policy Loss                  -876.4042
Q Predictions Mean           876.9203
Q Predictions Std            872.2022
Q Predictions Max            2705.126
Q Predictions Min            -143.8182
V Predictions Mean           882.55707
V Predictions Std            875.51733
V Predictions Max            2695.1335
V Predictions Min            -139.00107
Log Pis Mean                 -0.6754694
Log Pis Std                  3.457252
Log Pis Max                  16.337368
Log Pis Min                  -6.938815
Policy mu Mean               -0.07311972
Policy mu Std                0.80532825
Policy mu Max                2.7363665
Policy mu Min                -2.5974333
Policy log std Mean          -0.48919332
Policy log std Std           0.23858532
Policy log std Max           -0.1438463
Policy log std Min           -2.3101337
Z mean eval                  2.325477
Z variance eval              0.026475415
total_rewards                [6637.25738002 6445.44020475 6440.37496544 4225.4775035  6358.31955017
 6884.23957679 6385.219956   5376.0455547  6459.83464101 6863.81437163]
total_rewards_mean           6207.602370402561
total_rewards_std            769.5450579682009
total_rewards_max            6884.23957679107
total_rewards_min            4225.477503497674
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               201.73859556997195
(Previous) Eval Time (s)     30.79800917999819
Sample Time (s)              7.179852378554642
Epoch Time (s)               239.71645712852478
Total Train Time (s)         18720.939781317487
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:43.730609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #83 | Epoch Duration: 239.842355966568
2020-01-13 04:48:43.730802 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.323978
Z variance train             0.026389971
KL Divergence                32.406635
KL Loss                      3.2406635
QF Loss                      957.07007
VF Loss                      99.77453
Policy Loss                  -867.6194
Q Predictions Mean           859.123
Q Predictions Std            867.15924
Q Predictions Max            2628.4863
Q Predictions Min            -148.22925
V Predictions Mean           867.99536
V Predictions Std            867.9048
V Predictions Max            2600.4187
V Predictions Min            -130.83382
Log Pis Mean                 -0.6827365
Log Pis Std                  3.8744302
Log Pis Max                  18.959948
Log Pis Min                  -6.604789
Policy mu Mean               -0.041131925
Policy mu Std                0.8313554
Policy mu Max                3.7795773
Policy mu Min                -2.9963682
Policy log std Mean          -0.48615947
Policy log std Std           0.24695367
Policy log std Max           -0.0887599
Policy log std Min           -2.0311153
Z mean eval                  2.3550925
Z variance eval              0.012958184
total_rewards                [6330.55569254 6609.0994838  6758.95646679 6622.80402016 6523.40541328
 6487.92624996 6623.14951159 6393.2667346  6539.311564   6732.48413796]
total_rewards_mean           6562.095927468535
total_rewards_std            129.24394071012566
total_rewards_max            6758.956466793455
total_rewards_min            6330.555692537803
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               200.42171562090516
(Previous) Eval Time (s)     30.52643159357831
Sample Time (s)              6.649308313149959
Epoch Time (s)               237.59745552763343
Total Train Time (s)         18958.6211718102
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:41.413918 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #84 | Epoch Duration: 237.68296074867249
2020-01-13 04:52:41.414130 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3565927
Z variance train             0.012952313
KL Divergence                32.53212
KL Loss                      3.253212
QF Loss                      248.24298
VF Loss                      44.82451
Policy Loss                  -879.91473
Q Predictions Mean           871.31885
Q Predictions Std            885.0069
Q Predictions Max            2728.7
Q Predictions Min            -164.73035
V Predictions Mean           878.4268
V Predictions Std            884.81
V Predictions Max            2735.9822
V Predictions Min            -151.25217
Log Pis Mean                 -0.9814535
Log Pis Std                  3.0167892
Log Pis Max                  11.224752
Log Pis Min                  -5.881946
Policy mu Mean               -0.02297806
Policy mu Std                0.79430693
Policy mu Max                2.6219642
Policy mu Min                -2.9624581
Policy log std Mean          -0.48151124
Policy log std Std           0.22320172
Policy log std Max           -0.0546782
Policy log std Min           -1.8904176
Z mean eval                  2.3647544
Z variance eval              0.007866129
total_rewards                [6591.73118519 6534.91474443 6656.90251447 6587.52939043 6754.60645545
 6813.29762194 3458.38326632 3126.56598804 6656.66486275 6963.34317267]
total_rewards_mean           6014.393920169465
total_rewards_std            1368.1184453424505
total_rewards_max            6963.343172670856
total_rewards_min            3126.5659880375497
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               201.26589742908254
(Previous) Eval Time (s)     33.26621924014762
Sample Time (s)              7.222366330679506
Epoch Time (s)               241.75448299990967
Total Train Time (s)         19200.455833804794
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:56:43.250492 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #85 | Epoch Duration: 241.8361999988556
2020-01-13 04:56:43.250672 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364522
Z variance train             0.007862948
KL Divergence                34.28977
KL Loss                      3.4289768
QF Loss                      157.33578
VF Loss                      45.353703
Policy Loss                  -738.547
Q Predictions Mean           730.4009
Q Predictions Std            803.0427
Q Predictions Max            2755.332
Q Predictions Min            -159.36592
V Predictions Mean           734.46436
V Predictions Std            804.518
V Predictions Max            2732.5964
V Predictions Min            -131.85593
Log Pis Mean                 -1.0641458
Log Pis Std                  2.9348757
Log Pis Max                  9.501788
Log Pis Min                  -6.02244
Policy mu Mean               -0.04915452
Policy mu Std                0.7463765
Policy mu Max                2.8948781
Policy mu Min                -2.3147488
Policy log std Mean          -0.4658698
Policy log std Std           0.23472808
Policy log std Max           -0.14119044
Policy log std Min           -2.387084
Z mean eval                  2.369685
Z variance eval              0.01612093
total_rewards                [6872.34001238 6808.73475924 6777.72570365 6446.16685667 6443.50931445
 6820.93657636 6909.55146403 6542.42823566 6597.53817192 6833.51102567]
total_rewards_mean           6705.244212002415
total_rewards_std            170.05860291581405
total_rewards_max            6909.551464030929
total_rewards_min            6443.509314451054
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               204.18677414907143
(Previous) Eval Time (s)     35.66582896793261
Sample Time (s)              7.52831033943221
Epoch Time (s)               247.38091345643625
Total Train Time (s)         19447.941985568497
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:00:50.742133 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #86 | Epoch Duration: 247.49126839637756
2020-01-13 05:00:50.742392 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3674388
Z variance train             0.016162552
KL Divergence                33.257698
KL Loss                      3.32577
QF Loss                      192.98482
VF Loss                      76.59275
Policy Loss                  -837.46765
Q Predictions Mean           830.8843
Q Predictions Std            828.88654
Q Predictions Max            2635.635
Q Predictions Min            249.00005
V Predictions Mean           843.13574
V Predictions Std            833.1979
V Predictions Max            2643.9905
V Predictions Min            256.6544
Log Pis Mean                 -0.9327228
Log Pis Std                  3.0593798
Log Pis Max                  12.216226
Log Pis Min                  -6.8364344
Policy mu Mean               -0.06831687
Policy mu Std                0.7943538
Policy mu Max                2.4663858
Policy mu Min                -2.378608
Policy log std Mean          -0.47337136
Policy log std Std           0.22782686
Policy log std Max           -0.14141855
Policy log std Min           -1.9650924
Z mean eval                  2.3983932
Z variance eval              0.01679206
total_rewards                [6527.62890806 6627.92895534 6268.39843934 6323.91086977 4056.85797122
 6633.98269761 6365.35980408 6198.37017206  555.44864113 6413.38035617]
total_rewards_mean           5597.126681477943
total_rewards_std            1827.3251007505728
total_rewards_max            6633.98269760976
total_rewards_min            555.4486411292056
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               203.33887098310515
(Previous) Eval Time (s)     32.18195858504623
Sample Time (s)              6.752130837645382
Epoch Time (s)               242.27296040579677
Total Train Time (s)         19690.32599128317
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:53.126560 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #87 | Epoch Duration: 242.38400173187256
2020-01-13 05:04:53.126739 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3955243
Z variance train             0.016769053
KL Divergence                33.066353
KL Loss                      3.3066354
QF Loss                      1173.8623
VF Loss                      44.677395
Policy Loss                  -771.57983
Q Predictions Mean           761.8165
Q Predictions Std            817.64526
Q Predictions Max            2673.1672
Q Predictions Min            -119.01561
V Predictions Mean           771.713
V Predictions Std            821.5773
V Predictions Max            2662.3608
V Predictions Min            -140.55602
Log Pis Mean                 -0.72785366
Log Pis Std                  3.6718338
Log Pis Max                  14.633949
Log Pis Min                  -6.786699
Policy mu Mean               -0.014661147
Policy mu Std                0.8228223
Policy mu Max                2.7830482
Policy mu Min                -2.814448
Policy log std Mean          -0.4764392
Policy log std Std           0.22012262
Policy log std Max           -0.1580219
Policy log std Min           -1.7998827
Z mean eval                  2.3470118
Z variance eval              0.010960404
total_rewards                [6659.00258243 6767.44856753 6829.53756904 6613.68914239 6729.50436765
 6542.06789578 6788.57848763 6691.16782189 6757.50168085 6772.84627615]
total_rewards_mean           6715.134439133855
total_rewards_std            83.97581038999745
total_rewards_max            6829.537569037407
total_rewards_min            6542.067895783752
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               204.95688334992155
(Previous) Eval Time (s)     31.86853663995862
Sample Time (s)              8.00919144321233
Epoch Time (s)               244.8346114330925
Total Train Time (s)         19935.240214903373
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:08:58.042792 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #88 | Epoch Duration: 244.9158365726471
2020-01-13 05:08:58.043103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3494518
Z variance train             0.010983435
KL Divergence                33.58957
KL Loss                      3.358957
QF Loss                      166.32773
VF Loss                      63.965916
Policy Loss                  -904.52014
Q Predictions Mean           896.8652
Q Predictions Std            924.4244
Q Predictions Max            2792.0918
Q Predictions Min            -140.49463
V Predictions Mean           903.1787
V Predictions Std            923.6712
V Predictions Max            2784.2585
V Predictions Min            -134.0725
Log Pis Mean                 -0.73609143
Log Pis Std                  3.742187
Log Pis Max                  19.662498
Log Pis Min                  -9.020263
Policy mu Mean               -0.055629443
Policy mu Std                0.81691116
Policy mu Max                3.6645586
Policy mu Min                -2.9501295
Policy log std Mean          -0.51087874
Policy log std Std           0.23968273
Policy log std Max           -0.18596146
Policy log std Min           -2.2585382
Z mean eval                  2.3671784
Z variance eval              0.012610148
total_rewards                [6967.73384505 6902.47905046 6707.6785338  6921.55607106 6773.50179045
 6797.32671373 6846.98339838 7092.96854547 6641.11798708 6957.00962872]
total_rewards_mean           6860.835556420806
total_rewards_std            127.89406097006798
total_rewards_max            7092.968545473493
total_rewards_min            6641.117987078796
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               204.02642784407362
(Previous) Eval Time (s)     31.700698437169194
Sample Time (s)              7.57142372475937
Epoch Time (s)               243.2985500060022
Total Train Time (s)         20178.641228915658
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:01.444812 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #89 | Epoch Duration: 243.40151405334473
2020-01-13 05:13:01.445013 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3719134
Z variance train             0.012652022
KL Divergence                33.730976
KL Loss                      3.3730977
QF Loss                      283.6479
VF Loss                      67.50827
Policy Loss                  -893.6465
Q Predictions Mean           882.963
Q Predictions Std            899.2093
Q Predictions Max            2753.6284
Q Predictions Min            -148.53154
V Predictions Mean           895.057
V Predictions Std            902.5732
V Predictions Max            2745.4524
V Predictions Min            -130.8657
Log Pis Mean                 -0.8655071
Log Pis Std                  3.360842
Log Pis Max                  13.683126
Log Pis Min                  -7.3961773
Policy mu Mean               -0.023482338
Policy mu Std                0.8128081
Policy mu Max                2.459829
Policy mu Min                -3.1158624
Policy log std Mean          -0.4921647
Policy log std Std           0.23718745
Policy log std Max           -0.11847465
Policy log std Min           -2.168447
Z mean eval                  2.379026
Z variance eval              0.028692905
total_rewards                [6737.03481152 6727.22169904 6933.07759547 6755.74680936 6797.55036269
 6784.25243511 6930.79896822 6839.77449676 6959.37442434 6818.0321296 ]
total_rewards_mean           6828.286373210246
total_rewards_std            80.99248748181842
total_rewards_max            6959.374424335007
total_rewards_min            6727.2216990447705
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               205.04304860392585
(Previous) Eval Time (s)     32.42285351967439
Sample Time (s)              7.234269161242992
Epoch Time (s)               244.70017128484324
Total Train Time (s)         20423.426514148246
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:17:06.235428 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #90 | Epoch Duration: 244.79022240638733
2020-01-13 05:17:06.235760 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.375523
Z variance train             0.0283718
KL Divergence                33.548077
KL Loss                      3.3548076
QF Loss                      1069.4583
VF Loss                      60.05433
Policy Loss                  -768.0455
Q Predictions Mean           761.3895
Q Predictions Std            821.34265
Q Predictions Max            2724.1853
Q Predictions Min            263.85696
V Predictions Mean           764.4943
V Predictions Std            826.7352
V Predictions Max            2724.7217
V Predictions Min            270.6095
Log Pis Mean                 -0.9534801
Log Pis Std                  3.549314
Log Pis Max                  19.618587
Log Pis Min                  -8.283438
Policy mu Mean               -0.02622895
Policy mu Std                0.7850082
Policy mu Max                3.2724805
Policy mu Min                -2.8410215
Policy log std Mean          -0.46793976
Policy log std Std           0.2320136
Policy log std Max           -0.124568224
Policy log std Min           -2.0670805
Z mean eval                  2.4350648
Z variance eval              0.012663426
total_rewards                [6695.92542089 6586.60080677 6592.21114096 6562.35608694 6740.77280512
 6538.03715136 6502.73545595 6743.35315907 6579.02061923 6637.10407895]
total_rewards_mean           6617.8116725253185
total_rewards_std            79.4796468261482
total_rewards_max            6743.353159074975
total_rewards_min            6502.735455954529
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               203.8174838279374
(Previous) Eval Time (s)     33.026006660889834
Sample Time (s)              6.473623080179095
Epoch Time (s)               243.31711356900632
Total Train Time (s)         20666.83382451441
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:09.643956 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #91 | Epoch Duration: 243.40793871879578
2020-01-13 05:21:09.644199 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4320912
Z variance train             0.012693768
KL Divergence                35.19599
KL Loss                      3.5195992
QF Loss                      1782.2726
VF Loss                      187.0058
Policy Loss                  -763.8334
Q Predictions Mean           762.9214
Q Predictions Std            851.99927
Q Predictions Max            2844.0142
Q Predictions Min            -143.3552
V Predictions Mean           774.1498
V Predictions Std            852.87103
V Predictions Max            2847.286
V Predictions Min            -132.64839
Log Pis Mean                 -1.1840848
Log Pis Std                  3.3436208
Log Pis Max                  20.167492
Log Pis Min                  -6.610156
Policy mu Mean               0.003100127
Policy mu Std                0.7819725
Policy mu Max                3.7193415
Policy mu Min                -3.3758895
Policy log std Mean          -0.49204603
Policy log std Std           0.22426318
Policy log std Max           -0.060394466
Policy log std Min           -2.1047611
Z mean eval                  2.3857055
Z variance eval              0.0069057085
total_rewards                [5724.93571092 6198.62941066 6533.98442417 6644.25296423 6092.29519716
 6274.25497179 5388.71184675 6436.59859918 2235.66962894 6270.26154976]
total_rewards_mean           5779.959430355756
total_rewards_std            1233.7903757956553
total_rewards_max            6644.252964227555
total_rewards_min            2235.669628935201
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               206.42531239287928
(Previous) Eval Time (s)     31.03212659107521
Sample Time (s)              6.4456794881261885
Epoch Time (s)               243.90311847208068
Total Train Time (s)         20910.814759533852
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:25:13.624957 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #92 | Epoch Duration: 243.9805874824524
2020-01-13 05:25:13.625098 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.384962
Z variance train             0.006913723
KL Divergence                36.57022
KL Loss                      3.6570222
QF Loss                      249.95111
VF Loss                      149.4236
Policy Loss                  -844.3343
Q Predictions Mean           835.97156
Q Predictions Std            874.56067
Q Predictions Max            2781.3718
Q Predictions Min            -192.96011
V Predictions Mean           836.07056
V Predictions Std            873.6846
V Predictions Max            2754.295
V Predictions Min            -136.9001
Log Pis Mean                 -0.62106097
Log Pis Std                  3.2670605
Log Pis Max                  14.598035
Log Pis Min                  -7.7227087
Policy mu Mean               -0.02442577
Policy mu Std                0.8219035
Policy mu Max                2.5885
Policy mu Min                -2.6800516
Policy log std Mean          -0.49260005
Policy log std Std           0.22274731
Policy log std Max           -0.09149191
Policy log std Min           -1.8265103
Z mean eval                  2.361319
Z variance eval              0.009872237
total_rewards                [6586.91751415 6719.39676132 6679.82144815 6535.52583252 6584.78310521
 6848.07994857 6571.64299125 6207.45879256 6495.34568877 6661.79671871]
total_rewards_mean           6589.076880120059
total_rewards_std            159.75020124648245
total_rewards_max            6848.079948571606
total_rewards_min            6207.458792560799
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               202.64757318189368
(Previous) Eval Time (s)     34.254506001248956
Sample Time (s)              5.968918161001056
Epoch Time (s)               242.8709973441437
Total Train Time (s)         21153.772460835055
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:16.585162 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #93 | Epoch Duration: 242.95989966392517
2020-01-13 05:29:16.585406 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3580136
Z variance train             0.009899354
KL Divergence                35.389717
KL Loss                      3.5389717
QF Loss                      203.95111
VF Loss                      180.65181
Policy Loss                  -843.6977
Q Predictions Mean           841.18164
Q Predictions Std            884.3919
Q Predictions Max            2784.806
Q Predictions Min            270.3841
V Predictions Mean           851.0521
V Predictions Std            888.96686
V Predictions Max            2801.8635
V Predictions Min            282.26086
Log Pis Mean                 -0.8371486
Log Pis Std                  3.3231714
Log Pis Max                  13.317524
Log Pis Min                  -8.236119
Policy mu Mean               -0.009895221
Policy mu Std                0.7852466
Policy mu Max                2.439017
Policy mu Min                -2.6961455
Policy log std Mean          -0.49742606
Policy log std Std           0.24760167
Policy log std Max           -0.15302593
Policy log std Min           -2.282616
Z mean eval                  2.425017
Z variance eval              0.028974097
total_rewards                [6511.01279148 6656.31097701 6601.13743337 6558.97998629 6530.66951669
 6212.25852402 6693.49966666 6358.65300993 6660.57956592 6619.99164065]
total_rewards_mean           6540.309311202722
total_rewards_std            142.60227077178854
total_rewards_max            6693.499666659604
total_rewards_min            6212.2585240223925
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               202.388077233918
(Previous) Eval Time (s)     31.941479715984315
Sample Time (s)              8.397796029690653
Epoch Time (s)               242.72735297959298
Total Train Time (s)         21396.58412717143
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:33:19.399069 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #94 | Epoch Duration: 242.81353116035461
2020-01-13 05:33:19.399244 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4230518
Z variance train             0.02888174
KL Divergence                31.789898
KL Loss                      3.17899
QF Loss                      274.36823
VF Loss                      43.048424
Policy Loss                  -795.6621
Q Predictions Mean           791.60974
Q Predictions Std            832.17365
Q Predictions Max            2723.8047
Q Predictions Min            276.78894
V Predictions Mean           794.0979
V Predictions Std            836.74084
V Predictions Max            2724.9705
V Predictions Min            279.1059
Log Pis Mean                 -0.62367713
Log Pis Std                  3.639028
Log Pis Max                  12.342768
Log Pis Min                  -9.304031
Policy mu Mean               0.022327498
Policy mu Std                0.8315546
Policy mu Max                2.7438254
Policy mu Min                -2.54195
Policy log std Mean          -0.48986495
Policy log std Std           0.22263567
Policy log std Max           -0.15073748
Policy log std Min           -2.2165322
Z mean eval                  2.3665853
Z variance eval              0.026343197
total_rewards                [6874.55363979 6802.67713437 6698.22953567 6892.11307323 6834.64585916
 6912.90630302 6848.50283901 6587.94753985 6745.60809541 6835.53375652]
total_rewards_mean           6803.271777602774
total_rewards_std            94.75678331324427
total_rewards_max            6912.906303016389
total_rewards_min            6587.9475398526465
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               201.35341135086492
(Previous) Eval Time (s)     32.141588957980275
Sample Time (s)              6.780369719490409
Epoch Time (s)               240.2753700283356
Total Train Time (s)         21636.951351107098
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:19.768284 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #95 | Epoch Duration: 240.36890959739685
2020-01-13 05:37:19.768450 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3662536
Z variance train             0.02638262
KL Divergence                31.602198
KL Loss                      3.16022
QF Loss                      240.80794
VF Loss                      81.27557
Policy Loss                  -836.8326
Q Predictions Mean           831.5445
Q Predictions Std            885.1375
Q Predictions Max            2817.8728
Q Predictions Min            280.044
V Predictions Mean           836.06165
V Predictions Std            887.4904
V Predictions Max            2827.5413
V Predictions Min            275.66803
Log Pis Mean                 -0.6739047
Log Pis Std                  3.4296062
Log Pis Max                  15.225002
Log Pis Min                  -6.939065
Policy mu Mean               -0.0004470572
Policy mu Std                0.818613
Policy mu Max                2.6885583
Policy mu Min                -3.3772502
Policy log std Mean          -0.48697332
Policy log std Std           0.2446726
Policy log std Max           -0.07919744
Policy log std Min           -2.3412964
Z mean eval                  2.3628273
Z variance eval              0.041732103
total_rewards                [6798.11291202 6524.53044405 6690.65362546 6766.3342921  6929.58979018
 6799.47830762 6686.64201742 6827.01569123 6655.28907364 6680.55270054]
total_rewards_mean           6735.819885425686
total_rewards_std            106.47476275032028
total_rewards_max            6929.589790178311
total_rewards_min            6524.530444047049
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               203.15459493082017
(Previous) Eval Time (s)     31.63638826692477
Sample Time (s)              6.672255116514862
Epoch Time (s)               241.4632383142598
Total Train Time (s)         21878.507663437165
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:21.326485 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #96 | Epoch Duration: 241.55788826942444
2020-01-13 05:41:21.326694 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.363662
Z variance train             0.041621502
KL Divergence                30.498762
KL Loss                      3.0498762
QF Loss                      247.2196
VF Loss                      163.76462
Policy Loss                  -848.5394
Q Predictions Mean           850.4668
Q Predictions Std            921.7949
Q Predictions Max            2906.6287
Q Predictions Min            -148.27243
V Predictions Mean           853.01086
V Predictions Std            921.60876
V Predictions Max            2893.912
V Predictions Min            -147.77628
Log Pis Mean                 -0.8794662
Log Pis Std                  3.4390848
Log Pis Max                  13.941726
Log Pis Min                  -7.0264487
Policy mu Mean               0.02647891
Policy mu Std                0.8106562
Policy mu Max                2.7293775
Policy mu Min                -2.568254
Policy log std Mean          -0.49286905
Policy log std Std           0.24602859
Policy log std Max           -0.13581958
Policy log std Min           -2.220014
Z mean eval                  2.3832974
Z variance eval              0.024201635
total_rewards                [6841.28361745 6473.51916317 6464.88438056 6385.9075101  6920.75372322
 6943.81582821 6675.59100055 6284.20082613 6584.648418   6796.61256388]
total_rewards_mean           6637.121703127897
total_rewards_std            221.3491283408484
total_rewards_max            6943.815828213668
total_rewards_min            6284.200826131823
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               203.97605715040118
(Previous) Eval Time (s)     31.942157605662942
Sample Time (s)              7.34215563070029
Epoch Time (s)               243.2603703867644
Total Train Time (s)         22121.852327222936
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:45:24.677320 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #97 | Epoch Duration: 243.35043501853943
2020-01-13 05:45:24.677647 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3844173
Z variance train             0.024086837
KL Divergence                32.27231
KL Loss                      3.2272308
QF Loss                      443.00397
VF Loss                      47.76012
Policy Loss                  -737.3822
Q Predictions Mean           737.4891
Q Predictions Std            839.9886
Q Predictions Max            2822.2273
Q Predictions Min            -175.37024
V Predictions Mean           739.8911
V Predictions Std            841.0503
V Predictions Max            2824.6265
V Predictions Min            -159.17097
Log Pis Mean                 -1.1216062
Log Pis Std                  3.0678582
Log Pis Max                  14.840046
Log Pis Min                  -5.808484
Policy mu Mean               -0.045261934
Policy mu Std                0.75181454
Policy mu Max                2.2229536
Policy mu Min                -3.2123919
Policy log std Mean          -0.48743138
Policy log std Std           0.2209498
Policy log std Max           -0.15445682
Policy log std Min           -2.3627424
Z mean eval                  2.4132202
Z variance eval              0.018739639
total_rewards                [3705.19431348 4248.69864727 6688.77268075 6829.4518855  6428.98414818
 6167.62468464 6545.27204214 6508.0492702  6472.74719017 6569.89510438]
total_rewards_mean           6016.468996670485
total_rewards_std            1039.6493137383684
total_rewards_max            6829.4518855003425
total_rewards_min            3705.1943134782605
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               206.71996050467715
(Previous) Eval Time (s)     29.885251682251692
Sample Time (s)              6.587447431404144
Epoch Time (s)               243.19265961833298
Total Train Time (s)         22365.13003765326
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:27.953745 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #98 | Epoch Duration: 243.2758469581604
2020-01-13 05:49:27.953936 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4137986
Z variance train             0.018699652
KL Divergence                33.972275
KL Loss                      3.3972275
QF Loss                      1203.5117
VF Loss                      112.80144
Policy Loss                  -802.4972
Q Predictions Mean           798.7526
Q Predictions Std            855.7807
Q Predictions Max            2855.9236
Q Predictions Min            277.47134
V Predictions Mean           806.28674
V Predictions Std            857.1411
V Predictions Max            2862.6772
V Predictions Min            284.45938
Log Pis Mean                 -0.98594284
Log Pis Std                  3.3361793
Log Pis Max                  14.653837
Log Pis Min                  -5.828022
Policy mu Mean               0.0046478533
Policy mu Std                0.8108913
Policy mu Max                3.270932
Policy mu Min                -2.8124857
Policy log std Mean          -0.48263136
Policy log std Std           0.23311946
Policy log std Max           -0.14046508
Policy log std Min           -2.0177977
Z mean eval                  2.389764
Z variance eval              0.0115949465
total_rewards                [6560.13498455 6471.35487187 6718.89096056 6582.54605146 6883.11690237
 6643.48231123 6825.96262733 6594.74056097 6539.73473651 6423.50182213]
total_rewards_mean           6624.346582897089
total_rewards_std            139.48731107322786
total_rewards_max            6883.116902372615
total_rewards_min            6423.501822129562
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               204.5148045560345
(Previous) Eval Time (s)     31.344727660994977
Sample Time (s)              6.3814738327637315
Epoch Time (s)               242.2410060497932
Total Train Time (s)         22607.457964670844
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:30.284590 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #99 | Epoch Duration: 242.33049964904785
2020-01-13 05:53:30.284799 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.387817
Z variance train             0.011644918
KL Divergence                35.019302
KL Loss                      3.5019302
QF Loss                      351.14816
VF Loss                      118.258705
Policy Loss                  -797.3743
Q Predictions Mean           791.1144
Q Predictions Std            874.5187
Q Predictions Max            2839.2654
Q Predictions Min            -180.9697
V Predictions Mean           794.49457
V Predictions Std            874.5572
V Predictions Max            2824.479
V Predictions Min            -161.7268
Log Pis Mean                 -0.7183402
Log Pis Std                  3.6747825
Log Pis Max                  20.970806
Log Pis Min                  -6.704914
Policy mu Mean               -0.0024137888
Policy mu Std                0.82477295
Policy mu Max                3.2898653
Policy mu Min                -3.7733629
Policy log std Mean          -0.48549235
Policy log std Std           0.2436331
Policy log std Max           -0.014108419
Policy log std Min           -2.3379164
Z mean eval                  2.3863149
Z variance eval              0.01161121
total_rewards                [6901.64113113 6933.75361306 6870.49556031 6827.23125272 6667.98149373
 7070.15209861 6925.40101306 7083.91541612 6896.19596109 6952.85406898]
total_rewards_mean           6912.962160880161
total_rewards_std            112.11158061712008
total_rewards_max            7083.915416117974
total_rewards_min            6667.981493727656
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               201.35358797432855
(Previous) Eval Time (s)     33.81339654605836
Sample Time (s)              10.474116881377995
Epoch Time (s)               245.6411014017649
Total Train Time (s)         22853.18851219397
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:57:36.016395 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #100 | Epoch Duration: 245.73143219947815
2020-01-13 05:57:36.016576 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.388354
Z variance train             0.011595137
KL Divergence                35.418995
KL Loss                      3.5418994
QF Loss                      179.11923
VF Loss                      40.055264
Policy Loss                  -753.4954
Q Predictions Mean           753.0633
Q Predictions Std            860.145
Q Predictions Max            2884.3105
Q Predictions Min            -146.24277
V Predictions Mean           756.219
V Predictions Std            861.5544
V Predictions Max            2899.2278
V Predictions Min            -169.83629
Log Pis Mean                 -0.923892
Log Pis Std                  3.0548482
Log Pis Max                  10.833756
Log Pis Min                  -7.2876415
Policy mu Mean               -0.060387403
Policy mu Std                0.791221
Policy mu Max                2.842186
Policy mu Min                -2.8637357
Policy log std Mean          -0.48383474
Policy log std Std           0.20363136
Policy log std Max           -0.10869944
Policy log std Min           -2.0265505
Z mean eval                  2.3922436
Z variance eval              0.030791009
total_rewards                [6759.97782609 6905.63504083 6441.41733696 7070.74883323 6422.56436922
 6841.38400977 6045.71087197 6622.08279239 6532.33317264 6428.71499029]
total_rewards_mean           6607.056924341379
total_rewards_std            282.25018878878006
total_rewards_max            7070.748833234144
total_rewards_min            6045.710871971817
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               196.44738067081198
(Previous) Eval Time (s)     32.26851587416604
Sample Time (s)              7.951601675245911
Epoch Time (s)               236.66749822022393
Total Train Time (s)         23089.94290129654
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:32.772611 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #101 | Epoch Duration: 236.75583267211914
2020-01-13 06:01:32.772799 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3932629
Z variance train             0.03068992
KL Divergence                35.4974
KL Loss                      3.5497398
QF Loss                      106.31552
VF Loss                      89.892654
Policy Loss                  -794.31433
Q Predictions Mean           787.8451
Q Predictions Std            883.59247
Q Predictions Max            2945.4492
Q Predictions Min            306.38617
V Predictions Mean           790.1347
V Predictions Std            883.17316
V Predictions Max            2933.873
V Predictions Min            310.1211
Log Pis Mean                 -0.8460406
Log Pis Std                  3.3387902
Log Pis Max                  12.110802
Log Pis Min                  -6.9130297
Policy mu Mean               0.008616771
Policy mu Std                0.7991277
Policy mu Max                2.4644036
Policy mu Min                -2.661543
Policy log std Mean          -0.48690844
Policy log std Std           0.2277359
Policy log std Max           -0.1153692
Policy log std Min           -2.1493495
Z mean eval                  2.414444
Z variance eval              0.011531283
total_rewards                [7070.2713204  7216.40399785 7004.68165565 7067.8990637  7312.78870075
 7112.24850029 6898.96994815 7058.97120573 6778.9809096  6982.33241248]
total_rewards_mean           7050.354771461369
total_rewards_std            142.94323104271294
total_rewards_max            7312.78870075349
total_rewards_min            6778.980909596796
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               192.16465406306088
(Previous) Eval Time (s)     33.888792499899864
Sample Time (s)              7.294973976910114
Epoch Time (s)               233.34842053987086
Total Train Time (s)         23323.372631798964
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:05:26.204718 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #102 | Epoch Duration: 233.4317820072174
2020-01-13 06:05:26.204884 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.418464
Z variance train             0.011551134
KL Divergence                36.36499
KL Loss                      3.6364992
QF Loss                      105.68399
VF Loss                      126.23605
Policy Loss                  -715.61505
Q Predictions Mean           712.05756
Q Predictions Std            817.0381
Q Predictions Max            2971.6345
Q Predictions Min            -184.13545
V Predictions Mean           708.8699
V Predictions Std            813.79047
V Predictions Max            2950.038
V Predictions Min            -183.51294
Log Pis Mean                 -1.3684905
Log Pis Std                  2.7545745
Log Pis Max                  8.540494
Log Pis Min                  -6.638674
Policy mu Mean               0.02443637
Policy mu Std                0.7228085
Policy mu Max                2.7999775
Policy mu Min                -2.0711179
Policy log std Mean          -0.47181022
Policy log std Std           0.22088917
Policy log std Max           -0.033525348
Policy log std Min           -2.090894
Z mean eval                  2.378338
Z variance eval              0.013070807
total_rewards                [7051.96271376 6873.65602867 6987.73987131 7027.10622137 7036.4218181
 6919.19002065 6811.82497712 6805.88571266 6968.77685787 6455.33905402]
total_rewards_mean           6893.790327552563
total_rewards_std            168.91431660831591
total_rewards_max            7051.962713757463
total_rewards_min            6455.3390540210585
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               190.02535403333604
(Previous) Eval Time (s)     33.95617962675169
Sample Time (s)              7.7773574171587825
Epoch Time (s)               231.75889107724652
Total Train Time (s)         23555.20930683613
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:09:18.041714 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #103 | Epoch Duration: 231.8367063999176
2020-01-13 06:09:18.041835 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3784494
Z variance train             0.01309256
KL Divergence                35.71952
KL Loss                      3.571952
QF Loss                      868.44836
VF Loss                      76.86656
Policy Loss                  -805.3964
Q Predictions Mean           801.4947
Q Predictions Std            890.4968
Q Predictions Max            2958.115
Q Predictions Min            306.38977
V Predictions Mean           807.2226
V Predictions Std            893.38104
V Predictions Max            2938.694
V Predictions Min            309.61658
Log Pis Mean                 -0.8566755
Log Pis Std                  3.225834
Log Pis Max                  11.947108
Log Pis Min                  -7.188681
Policy mu Mean               -0.04219689
Policy mu Std                0.80588883
Policy mu Max                3.3510723
Policy mu Min                -2.8099263
Policy log std Mean          -0.49232808
Policy log std Std           0.23690887
Policy log std Max           -0.13239133
Policy log std Min           -2.1525943
Z mean eval                  2.358934
Z variance eval              0.020671627
total_rewards                [7273.29633519 7454.33154305 7262.59374868 7367.45800395 7257.90584434
 7354.36216906 6940.2548896  7223.68686797 7039.46163959 7367.80148475]
total_rewards_mean           7254.115252618132
total_rewards_std            148.95358368610513
total_rewards_max            7454.331543051222
total_rewards_min            6940.254889599223
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               191.72671205783263
(Previous) Eval Time (s)     32.700087409000844
Sample Time (s)              7.198141371365637
Epoch Time (s)               231.6249408381991
Total Train Time (s)         23786.914208399132
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:09.748223 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #104 | Epoch Duration: 231.70628356933594
2020-01-13 06:13:09.748386 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.361504
Z variance train             0.020725274
KL Divergence                33.161633
KL Loss                      3.3161633
QF Loss                      221.46973
VF Loss                      87.74388
Policy Loss                  -796.5973
Q Predictions Mean           792.97485
Q Predictions Std            864.8543
Q Predictions Max            2903.9338
Q Predictions Min            161.41087
V Predictions Mean           794.5958
V Predictions Std            861.46747
V Predictions Max            2904.4016
V Predictions Min            269.36768
Log Pis Mean                 -0.9323631
Log Pis Std                  3.1601436
Log Pis Max                  11.047701
Log Pis Min                  -7.504847
Policy mu Mean               -0.032931443
Policy mu Std                0.817764
Policy mu Max                2.7110815
Policy mu Min                -2.7429137
Policy log std Mean          -0.48864472
Policy log std Std           0.23489806
Policy log std Max           -0.14632381
Policy log std Min           -2.2949617
Z mean eval                  2.3826942
Z variance eval              0.015521385
total_rewards                [7182.34823347 7320.99949192 7265.35790874 7297.81669905 7029.46871988
 7380.97958039 7536.12114104 7141.0462106  6992.74761527 7211.23226329]
total_rewards_mean           7235.8117863654825
total_rewards_std            154.05667651771483
total_rewards_max            7536.121141041676
total_rewards_min            6992.747615273648
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               189.67490923590958
(Previous) Eval Time (s)     35.32636819873005
Sample Time (s)              8.886279276106507
Epoch Time (s)               233.88755671074614
Total Train Time (s)         24020.895813302603
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:17:03.734439 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #105 | Epoch Duration: 233.98592019081116
2020-01-13 06:17:03.734609 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3815804
Z variance train             0.015637513
KL Divergence                32.754326
KL Loss                      3.2754326
QF Loss                      132.00208
VF Loss                      76.55717
Policy Loss                  -707.21277
Q Predictions Mean           702.3894
Q Predictions Std            785.5563
Q Predictions Max            2931.8928
Q Predictions Min            312.79013
V Predictions Mean           700.52747
V Predictions Std            783.1085
V Predictions Max            2921.6143
V Predictions Min            316.78177
Log Pis Mean                 -0.6584857
Log Pis Std                  3.2991357
Log Pis Max                  18.47282
Log Pis Min                  -7.6448145
Policy mu Mean               -0.026562853
Policy mu Std                0.82893264
Policy mu Max                3.341986
Policy mu Min                -3.5332196
Policy log std Mean          -0.4846878
Policy log std Std           0.21796627
Policy log std Max           -0.13645774
Policy log std Min           -1.9300215
Z mean eval                  2.3694859
Z variance eval              0.017617473
total_rewards                [7034.38937559 6906.82559093 7031.77284158 7057.47705346 6995.67698588
 6706.24943007 7104.09594208 6640.4688662  7241.81472091 6990.40256166]
total_rewards_mean           6970.91733683685
total_rewards_std            170.49702901076452
total_rewards_max            7241.814720911
total_rewards_min            6640.4688661956325
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               191.13372090877965
(Previous) Eval Time (s)     32.508604214992374
Sample Time (s)              7.621427648235112
Epoch Time (s)               231.26375277200714
Total Train Time (s)         24252.245819556993
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:20:55.084539 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #106 | Epoch Duration: 231.34979438781738
2020-01-13 06:20:55.084724 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.370705
Z variance train             0.017603427
KL Divergence                32.534077
KL Loss                      3.2534077
QF Loss                      1331.4939
VF Loss                      201.6685
Policy Loss                  -771.21857
Q Predictions Mean           766.5398
Q Predictions Std            854.3406
Q Predictions Max            3037.5989
Q Predictions Min            290.53415
V Predictions Mean           769.949
V Predictions Std            851.935
V Predictions Max            3011.3418
V Predictions Min            300.00723
Log Pis Mean                 -0.87039155
Log Pis Std                  3.535173
Log Pis Max                  17.080967
Log Pis Min                  -6.906127
Policy mu Mean               -0.03617994
Policy mu Std                0.7898009
Policy mu Max                4.5647993
Policy mu Min                -3.4456816
Policy log std Mean          -0.48417893
Policy log std Std           0.22091027
Policy log std Max           -0.039164364
Policy log std Min           -1.9312203
Z mean eval                  2.3540754
Z variance eval              0.018892206
total_rewards                [6889.47387523 6711.81750841 6781.31321618 7083.3560212  7025.57596806
 7248.3238509  6909.95380295 7023.45959058 7182.75623854 6899.20689314]
total_rewards_mean           6975.523696518307
total_rewards_std            160.80517474983446
total_rewards_max            7248.323850897556
total_rewards_min            6711.817508407623
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               191.20607724273577
(Previous) Eval Time (s)     32.01565364887938
Sample Time (s)              6.622633465565741
Epoch Time (s)               229.8443643571809
Total Train Time (s)         24482.175286583602
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:45.016793 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #107 | Epoch Duration: 229.93186259269714
2020-01-13 06:24:45.017081 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3541234
Z variance train             0.01890589
KL Divergence                32.636955
KL Loss                      3.2636955
QF Loss                      390.0594
VF Loss                      177.33688
Policy Loss                  -755.0678
Q Predictions Mean           749.35675
Q Predictions Std            817.67206
Q Predictions Max            2964.769
Q Predictions Min            295.95847
V Predictions Mean           755.17834
V Predictions Std            818.73334
V Predictions Max            2960.4053
V Predictions Min            303.01538
Log Pis Mean                 -1.2748742
Log Pis Std                  2.7262783
Log Pis Max                  10.891305
Log Pis Min                  -6.732515
Policy mu Mean               0.013607343
Policy mu Std                0.72658527
Policy mu Max                2.9442992
Policy mu Min                -2.4171
Policy log std Mean          -0.49372652
Policy log std Std           0.22336586
Policy log std Max           0.2742077
Policy log std Min           -2.1077695
Z mean eval                  2.367269
Z variance eval              0.027645368
total_rewards                [6927.65014712 6670.27171216 6907.16928837 6749.72366947 6828.52303873
 6813.91260302 6574.75080859 6621.48071738 6569.14286688 6885.21586222]
total_rewards_mean           6754.784071395043
total_rewards_std            130.71433293911306
total_rewards_max            6927.65014712208
total_rewards_min            6569.142866880143
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               192.8684380291961
(Previous) Eval Time (s)     33.918316673953086
Sample Time (s)              7.588387432042509
Epoch Time (s)               234.3751421351917
Total Train Time (s)         24716.62931264192
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:39.472196 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #108 | Epoch Duration: 234.45493078231812
2020-01-13 06:28:39.472389 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3669689
Z variance train             0.027669784
KL Divergence                31.717817
KL Loss                      3.1717818
QF Loss                      278.96848
VF Loss                      95.796936
Policy Loss                  -890.78577
Q Predictions Mean           888.24915
Q Predictions Std            948.17236
Q Predictions Max            3027.3835
Q Predictions Min            -278.43814
V Predictions Mean           886.06506
V Predictions Std            943.2837
V Predictions Max            3007.9446
V Predictions Min            -258.09055
Log Pis Mean                 -0.61698806
Log Pis Std                  3.643743
Log Pis Max                  17.690384
Log Pis Min                  -6.048314
Policy mu Mean               -0.02026139
Policy mu Std                0.83752716
Policy mu Max                3.0834017
Policy mu Min                -2.8996773
Policy log std Mean          -0.49108052
Policy log std Std           0.24731086
Policy log std Max           0.060806513
Policy log std Min           -2.2407994
Z mean eval                  2.378159
Z variance eval              0.030442495
total_rewards                [7534.45706247 7337.83591459 7124.58567951 7060.72599026 7330.63666721
 7019.79323161 7166.54099209 7273.37952128 7346.67681532 7225.0818179 ]
total_rewards_mean           7241.971369225027
total_rewards_std            147.1450102629547
total_rewards_max            7534.457062474099
total_rewards_min            7019.79323161285
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               194.73271376406774
(Previous) Eval Time (s)     35.37994905281812
Sample Time (s)              8.465059744659811
Epoch Time (s)               238.57772256154567
Total Train Time (s)         24955.444329527672
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:32:38.288957 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #109 | Epoch Duration: 238.81641364097595
2020-01-13 06:32:38.289169 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3781993
Z variance train             0.03056768
KL Divergence                32.524994
KL Loss                      3.2524993
QF Loss                      1407.2146
VF Loss                      81.31914
Policy Loss                  -913.54913
Q Predictions Mean           914.15845
Q Predictions Std            964.8417
Q Predictions Max            3114.6812
Q Predictions Min            -238.6327
V Predictions Mean           919.76636
V Predictions Std            967.5894
V Predictions Max            3116.7458
V Predictions Min            -246.78432
Log Pis Mean                 -0.7852782
Log Pis Std                  3.485668
Log Pis Max                  10.85703
Log Pis Min                  -8.014543
Policy mu Mean               -0.056499377
Policy mu Std                0.8470789
Policy mu Max                3.0653214
Policy mu Min                -2.965252
Policy log std Mean          -0.49739084
Policy log std Std           0.22863056
Policy log std Max           -0.14284486
Policy log std Min           -2.2083967
Z mean eval                  2.4433422
Z variance eval              0.041374773
total_rewards                [7355.97429283 7052.65765995 7015.35640316 7122.14362177 7273.52333541
 7371.48935702 7065.39913262 7136.2350221  7244.12487037 7203.27511335]
total_rewards_mean           7184.017880858788
total_rewards_std            119.4126099861237
total_rewards_max            7371.489357022442
total_rewards_min            7015.356403158984
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               188.28392108203843
(Previous) Eval Time (s)     34.6724556889385
Sample Time (s)              7.185761785600334
Epoch Time (s)               230.14213855657727
Total Train Time (s)         25185.677163151093
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:36:28.524604 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #110 | Epoch Duration: 230.23527336120605
2020-01-13 06:36:28.524822 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.443294
Z variance train             0.04116947
KL Divergence                34.679256
KL Loss                      3.4679258
QF Loss                      291.22113
VF Loss                      115.878204
Policy Loss                  -780.46356
Q Predictions Mean           774.3237
Q Predictions Std            868.28253
Q Predictions Max            3023.226
Q Predictions Min            -293.1857
V Predictions Mean           775.91895
V Predictions Std            867.0656
V Predictions Max            3012.9924
V Predictions Min            -278.30783
Log Pis Mean                 -0.98798287
Log Pis Std                  2.9642038
Log Pis Max                  9.402335
Log Pis Min                  -8.635218
Policy mu Mean               -0.012122206
Policy mu Std                0.7803394
Policy mu Max                2.6410635
Policy mu Min                -2.337457
Policy log std Mean          -0.48807955
Policy log std Std           0.24442835
Policy log std Max           -0.09819105
Policy log std Min           -2.2578611
Z mean eval                  2.4192326
Z variance eval              0.028861891
total_rewards                [7068.33436456 7159.20927192 7112.55936145 7113.77438731 7058.30421565
 6951.41346364 6981.02652941 7043.38931766 6992.96605261 6849.03103708]
total_rewards_mean           7033.00080012868
total_rewards_std            86.93942336011588
total_rewards_max            7159.209271921316
total_rewards_min            6849.031037082559
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               193.8409417490475
(Previous) Eval Time (s)     35.30200512893498
Sample Time (s)              7.417535507585853
Epoch Time (s)               236.56048238556832
Total Train Time (s)         25422.321258524433
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:25.169291 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #111 | Epoch Duration: 236.6443088054657
2020-01-13 06:40:25.169491 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4209316
Z variance train             0.028787836
KL Divergence                34.627586
KL Loss                      3.4627588
QF Loss                      207.79854
VF Loss                      86.50105
Policy Loss                  -982.4785
Q Predictions Mean           979.9088
Q Predictions Std            1010.82666
Q Predictions Max            3095.1865
Q Predictions Min            -275.95193
V Predictions Mean           981.5476
V Predictions Std            1012.6515
V Predictions Max            3103.13
V Predictions Min            -267.7409
Log Pis Mean                 -0.20073465
Log Pis Std                  3.6470885
Log Pis Max                  12.243752
Log Pis Min                  -6.120733
Policy mu Mean               -0.05497692
Policy mu Std                0.8741391
Policy mu Max                2.5170817
Policy mu Min                -2.4823592
Policy log std Mean          -0.5028198
Policy log std Std           0.24419916
Policy log std Max           -0.06372966
Policy log std Min           -2.2856388
Z mean eval                  2.4121456
Z variance eval              0.009360919
total_rewards                [7265.83010177 7091.35374225 7448.15332663 7057.9389155  7663.94138247
 7094.6613302  7106.53718262 7323.8075213  7191.91478832 7141.00049692]
total_rewards_mean           7238.513878795611
total_rewards_std            183.57930236503296
total_rewards_max            7663.941382466083
total_rewards_min            7057.938915496997
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               190.7003251328133
(Previous) Eval Time (s)     35.69212589971721
Sample Time (s)              8.329258158802986
Epoch Time (s)               234.7217091913335
Total Train Time (s)         25657.13911930658
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:44:19.993517 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #112 | Epoch Duration: 234.82383036613464
2020-01-13 06:44:19.993851 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.413935
Z variance train             0.009356315
KL Divergence                36.27749
KL Loss                      3.627749
QF Loss                      162.16724
VF Loss                      235.72177
Policy Loss                  -856.9343
Q Predictions Mean           847.19604
Q Predictions Std            944.8027
Q Predictions Max            3046.371
Q Predictions Min            -298.50327
V Predictions Mean           844.31177
V Predictions Std            940.7422
V Predictions Max            3034.8696
V Predictions Min            -276.46323
Log Pis Mean                 -0.79422057
Log Pis Std                  3.2855537
Log Pis Max                  11.674738
Log Pis Min                  -6.6747
Policy mu Mean               0.0125026405
Policy mu Std                0.8179594
Policy mu Max                2.5601666
Policy mu Min                -2.7900164
Policy log std Mean          -0.49602243
Policy log std Std           0.23585992
Policy log std Max           -0.13856037
Policy log std Min           -2.301085
Z mean eval                  2.3965256
Z variance eval              0.020117419
total_rewards                [6756.18448181 6503.17616711 6782.60520333 6982.11950792 6867.16512866
 6775.237981   6772.46100648 6686.69642359 6772.67254572 7005.95876207]
total_rewards_mean           6790.427720768969
total_rewards_std            135.81760060418696
total_rewards_max            7005.958762068265
total_rewards_min            6503.176167106339
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               193.12521798396483
(Previous) Eval Time (s)     35.604141862131655
Sample Time (s)              6.842854545451701
Epoch Time (s)               235.5722143915482
Total Train Time (s)         25892.793375784997
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:48:15.646518 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #113 | Epoch Duration: 235.65240359306335
2020-01-13 06:48:15.646719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3971345
Z variance train             0.020160925
KL Divergence                34.52762
KL Loss                      3.452762
QF Loss                      117.26252
VF Loss                      41.92177
Policy Loss                  -784.6341
Q Predictions Mean           779.56165
Q Predictions Std            875.6504
Q Predictions Max            3026.2507
Q Predictions Min            -275.08417
V Predictions Mean           783.7565
V Predictions Std            876.65106
V Predictions Max            3037.6035
V Predictions Min            -263.03946
Log Pis Mean                 -0.9905231
Log Pis Std                  2.9734793
Log Pis Max                  16.961308
Log Pis Min                  -7.1211233
Policy mu Mean               -0.024763698
Policy mu Std                0.80313
Policy mu Max                3.6572993
Policy mu Min                -3.3668737
Policy log std Mean          -0.4810531
Policy log std Std           0.22551511
Policy log std Max           -0.08403307
Policy log std Min           -2.2513313
Z mean eval                  2.3850007
Z variance eval              0.044242334
total_rewards                [6904.73868365 7181.53573159 6922.51075075 6859.12408182 7163.20331116
 7023.77955628 7077.15901523 6824.91679822 6749.76557553 6681.75223083]
total_rewards_mean           6938.848573506516
total_rewards_std            160.68382547753134
total_rewards_max            7181.535731587146
total_rewards_min            6681.752230834412
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               194.137844319921
(Previous) Eval Time (s)     33.06217734888196
Sample Time (s)              6.376210088375956
Epoch Time (s)               233.5762317571789
Total Train Time (s)         26126.449211459607
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:09.304586 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #114 | Epoch Duration: 233.6577124595642
2020-01-13 06:52:09.304785 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.381967
Z variance train             0.04426367
KL Divergence                32.2134
KL Loss                      3.2213402
QF Loss                      111.18854
VF Loss                      108.68267
Policy Loss                  -778.9085
Q Predictions Mean           775.4499
Q Predictions Std            873.9197
Q Predictions Max            3071.524
Q Predictions Min            -256.7075
V Predictions Mean           772.5237
V Predictions Std            871.07104
V Predictions Max            3035.2168
V Predictions Min            -255.20293
Log Pis Mean                 -0.6367619
Log Pis Std                  3.277388
Log Pis Max                  14.957436
Log Pis Min                  -6.823497
Policy mu Mean               -0.012257658
Policy mu Std                0.8357858
Policy mu Max                3.2809157
Policy mu Min                -2.7691698
Policy log std Mean          -0.48935232
Policy log std Std           0.23605226
Policy log std Max           -0.13481084
Policy log std Min           -2.3111713
Z mean eval                  2.4261234
Z variance eval              0.04033663
total_rewards                [7120.02177511 7297.4905346  7115.98915807 6996.00010022 7147.56156851
 6866.0815257  7115.78782622 7032.68751309 7344.09000369 7104.96838497]
total_rewards_mean           7114.067839016747
total_rewards_std            130.33064514518398
total_rewards_max            7344.090003692769
total_rewards_min            6866.081525698259
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               191.18915978260338
(Previous) Eval Time (s)     35.37314118631184
Sample Time (s)              7.900508771184832
Epoch Time (s)               234.46280974010006
Total Train Time (s)         26361.007478269283
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:03.865494 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #115 | Epoch Duration: 234.56054639816284
2020-01-13 06:56:03.865739 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4248593
Z variance train             0.040337563
KL Divergence                32.51196
KL Loss                      3.251196
QF Loss                      631.2743
VF Loss                      234.13187
Policy Loss                  -802.7943
Q Predictions Mean           799.3718
Q Predictions Std            904.5726
Q Predictions Max            2981.9612
Q Predictions Min            139.30292
V Predictions Mean           802.86145
V Predictions Std            900.5644
V Predictions Max            2976.9521
V Predictions Min            312.5637
Log Pis Mean                 -0.73243415
Log Pis Std                  3.2061098
Log Pis Max                  16.677006
Log Pis Min                  -7.0559683
Policy mu Mean               0.03655225
Policy mu Std                0.8175828
Policy mu Max                2.8702884
Policy mu Min                -2.870557
Policy log std Mean          -0.49237204
Policy log std Std           0.23172052
Policy log std Max           -0.11878353
Policy log std Min           -2.271602
Z mean eval                  2.4535842
Z variance eval              0.012866093
total_rewards                [7120.34985805 6759.56413111 7130.90395561 6914.59161499 6944.84791925
 6559.9851037  6939.59287714 7252.53981264 6952.60328124 6857.81667358]
total_rewards_mean           6943.279522731349
total_rewards_std            187.37518338604147
total_rewards_max            7252.539812639309
total_rewards_min            6559.985103698569
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               197.2910282718949
(Previous) Eval Time (s)     32.39110016962513
Sample Time (s)              6.735159168019891
Epoch Time (s)               236.41728760953993
Total Train Time (s)         26597.504297574982
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:00:00.364383 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #116 | Epoch Duration: 236.49846267700195
2020-01-13 07:00:00.364585 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4512992
Z variance train             0.012826955
KL Divergence                36.53527
KL Loss                      3.653527
QF Loss                      160.30984
VF Loss                      72.768906
Policy Loss                  -1003.4687
Q Predictions Mean           997.23914
Q Predictions Std            1051.4114
Q Predictions Max            3046.5815
Q Predictions Min            339.49005
V Predictions Mean           1007.3169
V Predictions Std            1052.3134
V Predictions Max            3051.7224
V Predictions Min            351.2664
Log Pis Mean                 -0.6720926
Log Pis Std                  3.5570939
Log Pis Max                  15.118576
Log Pis Min                  -7.6116924
Policy mu Mean               -0.04812457
Policy mu Std                0.8563458
Policy mu Max                2.9112308
Policy mu Min                -2.8727508
Policy log std Mean          -0.5030327
Policy log std Std           0.22656447
Policy log std Max           -0.11188197
Policy log std Min           -2.3697202
Z mean eval                  2.4661376
Z variance eval              0.013591366
total_rewards                [6733.78653123 7230.10231084 6923.36697462 7259.02285627 6874.42653217
 6944.96106915 6914.07302752 7232.72421827 7476.28739697 7365.73404315]
total_rewards_mean           7095.4484960178725
total_rewards_std            233.8014225925144
total_rewards_max            7476.28739696544
total_rewards_min            6733.786531228109
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               197.06571602402255
(Previous) Eval Time (s)     31.722718778066337
Sample Time (s)              7.939997537527233
Epoch Time (s)               236.72843233961612
Total Train Time (s)         26834.332154254895
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:03:57.193499 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #117 | Epoch Duration: 236.8287525177002
2020-01-13 07:03:57.193709 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5470912
Z variance train             0.013230838
KL Divergence                38.238754
KL Loss                      3.8238754
QF Loss                      220.24188
VF Loss                      89.56567
Policy Loss                  -842.2801
Q Predictions Mean           840.4824
Q Predictions Std            928.1642
Q Predictions Max            3160.676
Q Predictions Min            -261.78152
V Predictions Mean           847.7411
V Predictions Std            931.4107
V Predictions Max            3188.6458
V Predictions Min            -278.0122
Log Pis Mean                 -0.7795371
Log Pis Std                  2.9611828
Log Pis Max                  10.0101795
Log Pis Min                  -7.190307
Policy mu Mean               -0.08420965
Policy mu Std                0.79333454
Policy mu Max                2.5771384
Policy mu Min                -2.8210459
Policy log std Mean          -0.4956653
Policy log std Std           0.23992583
Policy log std Max           -0.10236251
Policy log std Min           -2.3547637
Z mean eval                  2.451123
Z variance eval              0.017584525
total_rewards                [6980.31103562 7093.46546203 6899.4092605  7005.77952482 7052.19456334
 7132.29849194 7142.62301285 7366.12688912 6907.17213658 7131.77606566]
total_rewards_mean           7071.115644247619
total_rewards_std            130.11545987295887
total_rewards_max            7366.12688912411
total_rewards_min            6899.409260502795
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               194.5534824617207
(Previous) Eval Time (s)     33.53108900692314
Sample Time (s)              7.918449178803712
Epoch Time (s)               236.00302064744756
Total Train Time (s)         27070.414185508154
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:07:53.278270 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #118 | Epoch Duration: 236.08440494537354
2020-01-13 07:07:53.278458 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.446478
Z variance train             0.017608121
KL Divergence                37.456924
KL Loss                      3.7456925
QF Loss                      168.94112
VF Loss                      86.06381
Policy Loss                  -920.89276
Q Predictions Mean           916.50757
Q Predictions Std            992.26465
Q Predictions Max            3184.4668
Q Predictions Min            323.6163
V Predictions Mean           923.2513
V Predictions Std            995.2878
V Predictions Max            3158.7498
V Predictions Min            338.1707
Log Pis Mean                 -0.53434384
Log Pis Std                  3.3653452
Log Pis Max                  12.235519
Log Pis Min                  -6.8263674
Policy mu Mean               -0.0088265585
Policy mu Std                0.83797115
Policy mu Max                2.3474405
Policy mu Min                -2.4327996
Policy log std Mean          -0.50317955
Policy log std Std           0.23592989
Policy log std Max           -0.07045491
Policy log std Min           -2.1554966
Z mean eval                  2.5039933
Z variance eval              0.0225075
total_rewards                [7619.61975311 7490.91251699 7345.4825999  7298.54141663 7456.68544172
 7680.44432005 7623.58045154 7175.78710287 7419.49469339 7331.8897375 ]
total_rewards_mean           7444.243803369539
total_rewards_std            154.05509398217467
total_rewards_max            7680.444320047855
total_rewards_min            7175.7871028693835
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               190.27488333033398
(Previous) Eval Time (s)     32.040421115234494
Sample Time (s)              6.743371340911835
Epoch Time (s)               229.0586757864803
Total Train Time (s)         27299.55584243452
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:11:42.421665 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #119 | Epoch Duration: 229.1430003643036
2020-01-13 07:11:42.421960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.502811
Z variance train             0.022553295
KL Divergence                37.725533
KL Loss                      3.7725532
QF Loss                      130.76013
VF Loss                      50.44587
Policy Loss                  -853.3321
Q Predictions Mean           852.14886
Q Predictions Std            923.2249
Q Predictions Max            3090.6929
Q Predictions Min            345.47528
V Predictions Mean           850.7677
V Predictions Std            920.1241
V Predictions Max            3069.1072
V Predictions Min            352.12756
Log Pis Mean                 -0.63186353
Log Pis Std                  3.096471
Log Pis Max                  11.231658
Log Pis Min                  -6.635481
Policy mu Mean               0.0052467114
Policy mu Std                0.8275258
Policy mu Max                2.2901185
Policy mu Min                -3.3014033
Policy log std Mean          -0.5096056
Policy log std Std           0.24082276
Policy log std Max           -0.043775335
Policy log std Min           -2.1969786
Z mean eval                  2.4625854
Z variance eval              0.025190407
total_rewards                [7038.06986599 6943.96848463 6927.54899793 6932.76305822 6951.72333427
 6922.05587071 7028.12682957 7002.83782588 7188.05071438 7445.30463603]
total_rewards_mean           7038.044961762311
total_rewards_std            155.80404163202775
total_rewards_max            7445.304636029082
total_rewards_min            6922.055870712341
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               189.70620628912002
(Previous) Eval Time (s)     34.44886833708733
Sample Time (s)              10.309682470280677
Epoch Time (s)               234.46475709648803
Total Train Time (s)         27534.105234036688
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:15:36.975466 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #120 | Epoch Duration: 234.55331993103027
2020-01-13 07:15:36.975673 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4641755
Z variance train             0.025230538
KL Divergence                37.120888
KL Loss                      3.7120888
QF Loss                      1448.3958
VF Loss                      141.01942
Policy Loss                  -894.6742
Q Predictions Mean           888.01733
Q Predictions Std            970.3733
Q Predictions Max            3192.2834
Q Predictions Min            350.69525
V Predictions Mean           886.70154
V Predictions Std            967.2319
V Predictions Max            3186.5967
V Predictions Min            357.69086
Log Pis Mean                 -0.5810605
Log Pis Std                  3.126819
Log Pis Max                  9.841087
Log Pis Min                  -5.9886637
Policy mu Mean               -0.02489233
Policy mu Std                0.83094823
Policy mu Max                2.462107
Policy mu Min                -2.8846338
Policy log std Mean          -0.50090235
Policy log std Std           0.23703615
Policy log std Max           -0.107239366
Policy log std Min           -2.2466424
Z mean eval                  2.457745
Z variance eval              0.013334738
total_rewards                [7143.51102058 7047.99239209 6946.26885371 7023.90652994 7132.34936068
 6886.9491902  6740.16918891 6980.59403902 6637.6479837  6470.47586318]
total_rewards_mean           6900.986442202612
total_rewards_std            209.33243190491532
total_rewards_max            7143.511020584448
total_rewards_min            6470.475863184947
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               191.92024299874902
(Previous) Eval Time (s)     35.4315516250208
Sample Time (s)              7.1857058010064065
Epoch Time (s)               234.53750042477623
Total Train Time (s)         27768.72876377264
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:31.600537 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #121 | Epoch Duration: 234.62465953826904
2020-01-13 07:19:31.600813 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4591484
Z variance train             0.013335099
KL Divergence                37.6566
KL Loss                      3.76566
QF Loss                      109.7713
VF Loss                      38.01153
Policy Loss                  -898.6013
Q Predictions Mean           891.8047
Q Predictions Std            951.05774
Q Predictions Max            3145.3374
Q Predictions Min            358.83734
V Predictions Mean           896.0027
V Predictions Std            950.9467
V Predictions Max            3164.9192
V Predictions Min            369.30896
Log Pis Mean                 -0.82444566
Log Pis Std                  3.0924194
Log Pis Max                  11.866415
Log Pis Min                  -7.4264226
Policy mu Mean               0.02357936
Policy mu Std                0.798696
Policy mu Max                2.8069038
Policy mu Min                -2.479508
Policy log std Mean          -0.5032208
Policy log std Std           0.23425971
Policy log std Max           -0.1512093
Policy log std Min           -2.1961017
Z mean eval                  2.417719
Z variance eval              0.014644456
total_rewards                [7190.76855561 7329.66585562 7216.03298548 7439.29125205 7258.27408259
 7274.83580798 7053.38415541 7317.87832327 7224.242508   7135.83288491]
total_rewards_mean           7244.020641092667
total_rewards_std            102.04437019315789
total_rewards_max            7439.291252052277
total_rewards_min            7053.38415541308
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               187.76156838284805
(Previous) Eval Time (s)     35.610060011036694
Sample Time (s)              7.015000315848738
Epoch Time (s)               230.3866287097335
Total Train Time (s)         27999.212290767115
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:23:22.085327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #122 | Epoch Duration: 230.48433637619019
2020-01-13 07:23:22.085523 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4210868
Z variance train             0.014740078
KL Divergence                36.893402
KL Loss                      3.6893404
QF Loss                      242.87186
VF Loss                      116.67157
Policy Loss                  -833.7343
Q Predictions Mean           825.1681
Q Predictions Std            905.9327
Q Predictions Max            3161.4004
Q Predictions Min            357.5486
V Predictions Mean           829.15405
V Predictions Std            904.4042
V Predictions Max            3154.8904
V Predictions Min            364.16904
Log Pis Mean                 -0.8687284
Log Pis Std                  3.0787735
Log Pis Max                  13.4268
Log Pis Min                  -9.04739
Policy mu Mean               -0.01842077
Policy mu Std                0.8045889
Policy mu Max                2.360936
Policy mu Min                -2.4812202
Policy log std Mean          -0.4929787
Policy log std Std           0.23718998
Policy log std Max           -0.14313978
Policy log std Min           -2.3694804
Z mean eval                  2.4740384
Z variance eval              0.02143723
total_rewards                [6574.15490649 6368.25581443 6740.08936574 6785.2073048  6682.62855122
 6717.5083777  6626.07436649 6726.58672689 7203.11780636 6904.83510344]
total_rewards_mean           6732.845832355958
total_rewards_std            206.35776160871498
total_rewards_max            7203.117806359173
total_rewards_min            6368.255814431361
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               193.53449158603325
(Previous) Eval Time (s)     33.07755645830184
Sample Time (s)              8.245606448501348
Epoch Time (s)               234.85765449283645
Total Train Time (s)         28234.151601534802
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:27:17.030278 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #123 | Epoch Duration: 234.94459700584412
2020-01-13 07:27:17.030497 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4762387
Z variance train             0.02148075
KL Divergence                35.25986
KL Loss                      3.5259862
QF Loss                      261.03583
VF Loss                      44.647213
Policy Loss                  -870.393
Q Predictions Mean           863.74347
Q Predictions Std            947.9611
Q Predictions Max            3169.6643
Q Predictions Min            351.0817
V Predictions Mean           869.2042
V Predictions Std            945.70844
V Predictions Max            3129.4685
V Predictions Min            360.53778
Log Pis Mean                 -0.7258871
Log Pis Std                  3.0551257
Log Pis Max                  10.926655
Log Pis Min                  -6.833131
Policy mu Mean               -0.06284975
Policy mu Std                0.7986264
Policy mu Max                3.0591025
Policy mu Min                -2.476301
Policy log std Mean          -0.51398164
Policy log std Std           0.22930689
Policy log std Max           -0.053965554
Policy log std Min           -2.2157884
Z mean eval                  2.4474645
Z variance eval              0.01925805
total_rewards                [7235.35682105 7459.21198166 7523.33621058 7453.29098875 7385.75217018
 7344.06816721 7354.26937916 7256.69944434 7396.04819658 7199.93752482]
total_rewards_mean           7360.797088431978
total_rewards_std            99.6467876817751
total_rewards_max            7523.3362105825145
total_rewards_min            7199.9375248201
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               188.88691015029326
(Previous) Eval Time (s)     35.08550047222525
Sample Time (s)              6.887063923291862
Epoch Time (s)               230.85947454581037
Total Train Time (s)         28465.19680999685
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:08.091058 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #124 | Epoch Duration: 231.0603382587433
2020-01-13 07:31:08.091344 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4461942
Z variance train             0.019272555
KL Divergence                35.810673
KL Loss                      3.5810673
QF Loss                      219.4707
VF Loss                      64.52697
Policy Loss                  -867.90985
Q Predictions Mean           863.5167
Q Predictions Std            941.94446
Q Predictions Max            3186.6865
Q Predictions Min            332.20648
V Predictions Mean           865.77765
V Predictions Std            940.7089
V Predictions Max            3154.154
V Predictions Min            344.3431
Log Pis Mean                 -0.7331747
Log Pis Std                  3.3181336
Log Pis Max                  16.170578
Log Pis Min                  -7.798026
Policy mu Mean               -0.044524636
Policy mu Std                0.8374811
Policy mu Max                3.3222663
Policy mu Min                -3.308507
Policy log std Mean          -0.5011994
Policy log std Std           0.24728324
Policy log std Max           -0.11119887
Policy log std Min           -2.4763885
Z mean eval                  2.4045615
Z variance eval              0.021993678
total_rewards                [7464.7494534  7374.29867784 7435.97970593 7089.61486213 7382.67233538
 7369.54763311 7142.54129608 7421.20872734 7513.55004637 7491.37284817]
total_rewards_mean           7368.55355857513
total_rewards_std            134.83424464946228
total_rewards_max            7513.550046368148
total_rewards_min            7089.614862134812
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               190.77930505992845
(Previous) Eval Time (s)     33.19064713874832
Sample Time (s)              7.473704228643328
Epoch Time (s)               231.4436564273201
Total Train Time (s)         28696.74836745998
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:34:59.630327 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #125 | Epoch Duration: 231.5387921333313
2020-01-13 07:34:59.630551 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4030807
Z variance train             0.021952173
KL Divergence                34.489845
KL Loss                      3.4489846
QF Loss                      216.41927
VF Loss                      45.129993
Policy Loss                  -724.059
Q Predictions Mean           722.17395
Q Predictions Std            793.4808
Q Predictions Max            3048.9194
Q Predictions Min            364.76337
V Predictions Mean           728.32324
V Predictions Std            794.42413
V Predictions Max            3041.5505
V Predictions Min            370.39633
Log Pis Mean                 -0.93715
Log Pis Std                  2.9993885
Log Pis Max                  10.717724
Log Pis Min                  -8.140587
Policy mu Mean               -0.024168344
Policy mu Std                0.77527267
Policy mu Max                2.6761494
Policy mu Min                -2.6305413
Policy log std Mean          -0.5033559
Policy log std Std           0.2313647
Policy log std Max           -0.019349188
Policy log std Min           -2.4357204
Z mean eval                  2.4232469
Z variance eval              0.02758593
total_rewards                [7643.25111735 7280.11109397 7416.88805517 7470.29513278 7528.90348408
 7505.35035565 7751.53223447 7438.47573367 7208.29104044 7558.16043918]
total_rewards_mean           7480.125868677564
total_rewards_std            151.3626998183603
total_rewards_max            7751.5322344710985
total_rewards_min            7208.291040441649
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               192.960303963162
(Previous) Eval Time (s)     30.55027084099129
Sample Time (s)              6.837589093018323
Epoch Time (s)               230.34816389717162
Total Train Time (s)         28927.181998297106
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:50.068920 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #126 | Epoch Duration: 230.4381947517395
2020-01-13 07:38:50.069181 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4255905
Z variance train             0.027630214
KL Divergence                33.658546
KL Loss                      3.3658547
QF Loss                      1410.0148
VF Loss                      34.421013
Policy Loss                  -766.585
Q Predictions Mean           764.8273
Q Predictions Std            859.55884
Q Predictions Max            3197.2134
Q Predictions Min            362.27512
V Predictions Mean           767.0297
V Predictions Std            855.79126
V Predictions Max            3176.2502
V Predictions Min            365.02847
Log Pis Mean                 -0.71227527
Log Pis Std                  3.3979764
Log Pis Max                  17.40755
Log Pis Min                  -6.133987
Policy mu Mean               -0.027078174
Policy mu Std                0.81527615
Policy mu Max                3.2794163
Policy mu Min                -3.005434
Policy log std Mean          -0.48613906
Policy log std Std           0.23574962
Policy log std Max           -0.09327668
Policy log std Min           -2.3513727
Z mean eval                  2.4754734
Z variance eval              0.018523816
total_rewards                [7276.96163296 7257.0238101  7304.2528697  7435.322195   7357.94242729
 7110.94044633 7735.27755325 7217.2209633  7526.77220978 7463.84989358]
total_rewards_mean           7368.5564001294815
total_rewards_std            169.52884190516423
total_rewards_max            7735.277553250771
total_rewards_min            7110.940446333561
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               194.303839283064
(Previous) Eval Time (s)     35.030622026883066
Sample Time (s)              6.595488550607115
Epoch Time (s)               235.9299498605542
Total Train Time (s)         29163.196554731112
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:46.084100 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #127 | Epoch Duration: 236.01472520828247
2020-01-13 07:42:46.084304 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4776998
Z variance train             0.01850706
KL Divergence                35.640053
KL Loss                      3.5640054
QF Loss                      148.5813
VF Loss                      205.0873
Policy Loss                  -735.649
Q Predictions Mean           735.42456
Q Predictions Std            817.0636
Q Predictions Max            3168.4587
Q Predictions Min            376.1633
V Predictions Mean           733.4231
V Predictions Std            816.6545
V Predictions Max            3165.8518
V Predictions Min            375.51053
Log Pis Mean                 -0.89564157
Log Pis Std                  3.4575205
Log Pis Max                  17.958845
Log Pis Min                  -7.5867305
Policy mu Mean               0.050168287
Policy mu Std                0.78528315
Policy mu Max                3.1833475
Policy mu Min                -3.03195
Policy log std Mean          -0.48041978
Policy log std Std           0.23481864
Policy log std Max           -0.03936343
Policy log std Min           -2.3092434
Z mean eval                  2.4371362
Z variance eval              0.026284471
total_rewards                [7177.41420757 7349.84074038 7312.50818994 7292.19317463 6908.24532416
 7068.01135248 7203.67087312 7290.72899985 7350.97630586 7271.71432189]
total_rewards_mean           7222.530348986923
total_rewards_std            133.32954776261553
total_rewards_max            7350.976305856888
total_rewards_min            6908.245324156087
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               193.06879666028544
(Previous) Eval Time (s)     29.757026112172753
Sample Time (s)              7.884273801930249
Epoch Time (s)               230.71009657438844
Total Train Time (s)         29393.986422378104
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:36.875878 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #128 | Epoch Duration: 230.79141187667847
2020-01-13 07:46:36.876126 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4372897
Z variance train             0.026292956
KL Divergence                34.9248
KL Loss                      3.49248
QF Loss                      149.7567
VF Loss                      93.63142
Policy Loss                  -962.9175
Q Predictions Mean           960.8802
Q Predictions Std            1015.7506
Q Predictions Max            3171.3281
Q Predictions Min            377.18732
V Predictions Mean           957.91956
V Predictions Std            1009.90607
V Predictions Max            3158.1516
V Predictions Min            381.39813
Log Pis Mean                 -0.7789993
Log Pis Std                  3.3093607
Log Pis Max                  12.328398
Log Pis Min                  -7.4859962
Policy mu Mean               -0.048295934
Policy mu Std                0.81616193
Policy mu Max                2.8668725
Policy mu Min                -2.5024474
Policy log std Mean          -0.50264174
Policy log std Std           0.23551688
Policy log std Max           -0.098140344
Policy log std Min           -2.3461149
Z mean eval                  2.477528
Z variance eval              0.027736124
total_rewards                [7181.09400046 7830.71829477 7556.50873283 7665.30515666 7469.62322919
 7584.34301613 7578.7155426  7788.94401191 7342.96882528 7562.46805666]
total_rewards_mean           7556.06888664866
total_rewards_std            183.422947697311
total_rewards_max            7830.718294767605
total_rewards_min            7181.094000462379
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               190.57355182804167
(Previous) Eval Time (s)     31.653969989623874
Sample Time (s)              7.858579942025244
Epoch Time (s)               230.0861017596908
Total Train Time (s)         29624.15429467708
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:50:27.045796 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #129 | Epoch Duration: 230.16944551467896
2020-01-13 07:50:27.046103 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4767082
Z variance train             0.027664278
KL Divergence                34.750652
KL Loss                      3.4750652
QF Loss                      141.20514
VF Loss                      64.75785
Policy Loss                  -845.4765
Q Predictions Mean           842.64197
Q Predictions Std            926.4444
Q Predictions Max            3303.8218
Q Predictions Min            366.29898
V Predictions Mean           850.2631
V Predictions Std            927.0852
V Predictions Max            3300.7485
V Predictions Min            380.8138
Log Pis Mean                 -0.7806845
Log Pis Std                  2.9306226
Log Pis Max                  10.161748
Log Pis Min                  -6.720813
Policy mu Mean               0.014839809
Policy mu Std                0.81302214
Policy mu Max                2.4697895
Policy mu Min                -2.777885
Policy log std Mean          -0.4979647
Policy log std Std           0.22252026
Policy log std Max           -0.028190136
Policy log std Min           -2.219459
Z mean eval                  2.4484143
Z variance eval              0.023233961
total_rewards                [7491.52183121 8072.41766306 7650.42361142 7865.08094655 7845.90900259
 7849.72686729 7499.26861198 7599.9950294  7817.77481646 7665.36127823]
total_rewards_mean           7735.7479658177035
total_rewards_std            175.54510354326584
total_rewards_max            8072.417663057286
total_rewards_min            7491.521831206622
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               188.6964161451906
(Previous) Eval Time (s)     32.178974559064955
Sample Time (s)              6.281613556668162
Epoch Time (s)               227.1570042609237
Total Train Time (s)         29851.40135108307
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:54:14.294472 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #130 | Epoch Duration: 227.24817872047424
2020-01-13 07:54:14.294653 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.450655
Z variance train             0.023228213
KL Divergence                35.260006
KL Loss                      3.5260007
QF Loss                      1432.2106
VF Loss                      39.696934
Policy Loss                  -823.4955
Q Predictions Mean           823.42334
Q Predictions Std            897.30896
Q Predictions Max            3258.434
Q Predictions Min            379.13675
V Predictions Mean           823.13916
V Predictions Std            899.3799
V Predictions Max            3258.5564
V Predictions Min            385.7205
Log Pis Mean                 -0.84372807
Log Pis Std                  3.170863
Log Pis Max                  15.094231
Log Pis Min                  -8.510298
Policy mu Mean               -0.0028061469
Policy mu Std                0.80029017
Policy mu Max                2.5664272
Policy mu Min                -2.4473035
Policy log std Mean          -0.51014775
Policy log std Std           0.23785482
Policy log std Max           0.049128413
Policy log std Min           -2.2977107
Z mean eval                  2.4555252
Z variance eval              0.022890832
total_rewards                [6921.63743092 6771.93132432 7412.11614907 6986.20896487 7170.22889979
 6864.21723387 7220.13452331 7037.2438952  6458.78983841 6988.14867438]
total_rewards_mean           6983.065693413252
total_rewards_std            248.11857357776879
total_rewards_max            7412.116149067102
total_rewards_min            6458.789838414956
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               189.30306193511933
(Previous) Eval Time (s)     38.06319053284824
Sample Time (s)              7.987594302743673
Epoch Time (s)               235.35384677071124
Total Train Time (s)         30086.888803570066
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:58:09.786826 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #131 | Epoch Duration: 235.491952419281
2020-01-13 07:58:09.787147 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4562953
Z variance train             0.02290542
KL Divergence                36.754208
KL Loss                      3.6754208
QF Loss                      144.95868
VF Loss                      57.039764
Policy Loss                  -908.5803
Q Predictions Mean           905.9636
Q Predictions Std            973.1926
Q Predictions Max            3229.6501
Q Predictions Min            371.79172
V Predictions Mean           907.05005
V Predictions Std            972.17664
V Predictions Max            3209.3108
V Predictions Min            379.6445
Log Pis Mean                 -0.51649535
Log Pis Std                  3.4321113
Log Pis Max                  11.916042
Log Pis Min                  -7.0673046
Policy mu Mean               0.005678946
Policy mu Std                0.8512118
Policy mu Max                3.4510798
Policy mu Min                -2.3994315
Policy log std Mean          -0.5002398
Policy log std Std           0.25500613
Policy log std Max           -0.08002818
Policy log std Min           -2.341215
Z mean eval                  2.4465814
Z variance eval              0.019378057
total_rewards                [7721.09108706 7904.66814807 7909.27249817 7644.30621306 7831.49840246
 7708.09181348 7952.94148244 7733.69075476 7627.42520222 7642.76305731]
total_rewards_mean           7767.57486590397
total_rewards_std            116.00947066240556
total_rewards_max            7952.941482437968
total_rewards_min            7627.425202222777
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               189.11666351370513
(Previous) Eval Time (s)     31.971911906264722
Sample Time (s)              7.9062557383440435
Epoch Time (s)               228.9948311583139
Total Train Time (s)         30315.968470343854
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:01:58.868042 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #132 | Epoch Duration: 229.08071184158325
2020-01-13 08:01:58.868213 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4474494
Z variance train             0.019371036
KL Divergence                35.342236
KL Loss                      3.5342236
QF Loss                      140.04102
VF Loss                      233.89517
Policy Loss                  -931.2677
Q Predictions Mean           928.26117
Q Predictions Std            996.4317
Q Predictions Max            3230.367
Q Predictions Min            378.14444
V Predictions Mean           934.02386
V Predictions Std            995.24554
V Predictions Max            3226.0344
V Predictions Min            387.00104
Log Pis Mean                 -0.64281577
Log Pis Std                  3.7668803
Log Pis Max                  20.586906
Log Pis Min                  -9.431591
Policy mu Mean               -0.06869237
Policy mu Std                0.85560215
Policy mu Max                4.322344
Policy mu Min                -2.6249797
Policy log std Mean          -0.50483745
Policy log std Std           0.23560962
Policy log std Max           -0.103358656
Policy log std Min           -2.4018009
Z mean eval                  2.4328003
Z variance eval              0.026255766
total_rewards                [7903.76431678 7911.01965076 7877.05450948 7817.00499963 7724.75351238
 7896.28189337 7511.24350813 7998.79925952 7820.03017425 7727.16675936]
total_rewards_mean           7818.711858367475
total_rewards_std            130.13731601471545
total_rewards_max            7998.799259515201
total_rewards_min            7511.243508129725
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               189.55462410021573
(Previous) Eval Time (s)     36.454414926003665
Sample Time (s)              6.686941240914166
Epoch Time (s)               232.69598026713356
Total Train Time (s)         30548.747103607748
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:05:51.650400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #133 | Epoch Duration: 232.78204989433289
2020-01-13 08:05:51.650578 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.431623
Z variance train             0.026194971
KL Divergence                35.237278
KL Loss                      3.523728
QF Loss                      125.67196
VF Loss                      67.03149
Policy Loss                  -822.3804
Q Predictions Mean           819.624
Q Predictions Std            879.54767
Q Predictions Max            3265.5037
Q Predictions Min            388.7754
V Predictions Mean           825.1521
V Predictions Std            883.0724
V Predictions Max            3275.0405
V Predictions Min            399.10233
Log Pis Mean                 -0.97450364
Log Pis Std                  3.0215118
Log Pis Max                  10.9647045
Log Pis Min                  -8.376728
Policy mu Mean               -0.041651078
Policy mu Std                0.795867
Policy mu Max                2.8953733
Policy mu Min                -3.0237324
Policy log std Mean          -0.49717033
Policy log std Std           0.22705382
Policy log std Max           -0.11983664
Policy log std Min           -1.7565595
Z mean eval                  2.4256644
Z variance eval              0.020035971
total_rewards                [7954.04193616 7663.93882188 7777.41000498 7932.68090471 7775.93755671
 7823.62739109 8012.8995662  7927.23449033 7581.0225834  7926.91727698]
total_rewards_mean           7837.5710532435405
total_rewards_std            131.51100790283036
total_rewards_max            8012.899566195437
total_rewards_min            7581.022583398252
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               190.0154283400625
(Previous) Eval Time (s)     31.881938779260963
Sample Time (s)              6.725245937239379
Epoch Time (s)               228.62261305656284
Total Train Time (s)         30777.47495298274
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:09:40.382342 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #134 | Epoch Duration: 228.73156237602234
2020-01-13 08:09:40.382661 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4221902
Z variance train             0.02002517
KL Divergence                35.38349
KL Loss                      3.5383492
QF Loss                      107.16957
VF Loss                      80.483765
Policy Loss                  -869.18665
Q Predictions Mean           866.7479
Q Predictions Std            943.27765
Q Predictions Max            3254.3313
Q Predictions Min            367.3563
V Predictions Mean           862.7296
V Predictions Std            941.9106
V Predictions Max            3233.729
V Predictions Min            350.5362
Log Pis Mean                 -0.57971156
Log Pis Std                  2.930399
Log Pis Max                  9.2863655
Log Pis Min                  -6.946933
Policy mu Mean               -0.00019873276
Policy mu Std                0.83694357
Policy mu Max                2.5726922
Policy mu Min                -2.5350008
Policy log std Mean          -0.5072461
Policy log std Std           0.21986483
Policy log std Max           0.0049846172
Policy log std Min           -1.9898134
Z mean eval                  2.466182
Z variance eval              0.023430552
total_rewards                [7244.2488405  7279.82108385 7354.67293188 7278.20000269 7109.80825757
 7142.46862247 7326.67375881 7223.28789289 7234.63832137 7074.13026871]
total_rewards_mean           7226.794998074988
total_rewards_std            87.32959513345394
total_rewards_max            7354.672931879524
total_rewards_min            7074.130268710139
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               193.0228235339746
(Previous) Eval Time (s)     35.253034298773855
Sample Time (s)              6.683221708983183
Epoch Time (s)               234.95907954173163
Total Train Time (s)         31012.516765431035
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:13:35.425174 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #135 | Epoch Duration: 235.0422558784485
2020-01-13 08:13:35.425400 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4662967
Z variance train             0.023424279
KL Divergence                36.942844
KL Loss                      3.6942844
QF Loss                      269.49786
VF Loss                      92.18722
Policy Loss                  -984.8265
Q Predictions Mean           983.8144
Q Predictions Std            1036.3064
Q Predictions Max            3300.3352
Q Predictions Min            388.84915
V Predictions Mean           981.02423
V Predictions Std            1028.7145
V Predictions Max            3266.3438
V Predictions Min            390.92328
Log Pis Mean                 -0.51775813
Log Pis Std                  3.5239716
Log Pis Max                  19.464539
Log Pis Min                  -7.684331
Policy mu Mean               -0.08515817
Policy mu Std                0.8599556
Policy mu Max                4.0368114
Policy mu Min                -3.580235
Policy log std Mean          -0.5069782
Policy log std Std           0.24938972
Policy log std Max           0.08385277
Policy log std Min           -2.3750927
Z mean eval                  2.4320889
Z variance eval              0.02129041
total_rewards                [7512.2061653  7667.73493915 8204.1839676  7853.8447456  7862.04412237
 7839.38920337 7752.81750618 7863.79191728 7902.50959573 7896.16165523]
total_rewards_mean           7835.468381783348
total_rewards_std            168.9541573602017
total_rewards_max            8204.183967603107
total_rewards_min            7512.206165304212
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               189.44145905273035
(Previous) Eval Time (s)     33.42576832603663
Sample Time (s)              7.106218527536839
Epoch Time (s)               229.97344590630382
Total Train Time (s)         31242.861330807675
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:17:25.771998 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #136 | Epoch Duration: 230.34640526771545
2020-01-13 08:17:25.772232 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4335542
Z variance train             0.021385022
KL Divergence                37.801205
KL Loss                      3.7801206
QF Loss                      82.99725
VF Loss                      59.36881
Policy Loss                  -929.6671
Q Predictions Mean           926.0463
Q Predictions Std            971.38165
Q Predictions Max            3336.7021
Q Predictions Min            384.78812
V Predictions Mean           928.18677
V Predictions Std            969.5138
V Predictions Max            3332.8232
V Predictions Min            389.5609
Log Pis Mean                 -0.43788916
Log Pis Std                  3.1867318
Log Pis Max                  9.983719
Log Pis Min                  -6.3121934
Policy mu Mean               -0.01704075
Policy mu Std                0.8673193
Policy mu Max                2.4992304
Policy mu Min                -2.6740441
Policy log std Mean          -0.50610906
Policy log std Std           0.24066505
Policy log std Max           -0.09979309
Policy log std Min           -2.5353322
Z mean eval                  2.4565077
Z variance eval              0.034558736
total_rewards                [7602.54236237 7793.89610619 7501.1264053  7827.50089521 7331.55685168
 7393.75886701 7166.00950398 7228.01105857 7806.61495705 7536.49323906]
total_rewards_mean           7518.751024640592
total_rewards_std            228.29024285790751
total_rewards_max            7827.500895207607
total_rewards_min            7166.0095039820435
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               189.2565226070583
(Previous) Eval Time (s)     36.0262319650501
Sample Time (s)              7.485669102985412
Epoch Time (s)               232.7684236750938
Total Train Time (s)         31476.01911923196
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:18.933614 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #137 | Epoch Duration: 233.16120290756226
2020-01-13 08:21:18.933816 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4617565
Z variance train             0.03458554
KL Divergence                36.12047
KL Loss                      3.612047
QF Loss                      124.19447
VF Loss                      142.68533
Policy Loss                  -882.2224
Q Predictions Mean           880.3359
Q Predictions Std            933.4264
Q Predictions Max            3314.1235
Q Predictions Min            378.59253
V Predictions Mean           883.70996
V Predictions Std            938.9664
V Predictions Max            3315.6516
V Predictions Min            388.24362
Log Pis Mean                 -0.7481433
Log Pis Std                  3.20961
Log Pis Max                  11.926431
Log Pis Min                  -7.0103416
Policy mu Mean               0.03915384
Policy mu Std                0.81581557
Policy mu Max                2.486092
Policy mu Min                -2.6313822
Policy log std Mean          -0.5131919
Policy log std Std           0.2321751
Policy log std Max           -0.16179207
Policy log std Min           -2.598116
Z mean eval                  2.4392478
Z variance eval              0.020503895
total_rewards                [7604.14928229 7769.66437874 7975.94798392 7763.2963247  7728.80765351
 7594.65702458 7379.90570538 7686.30679997 8144.24992978 7573.89394741]
total_rewards_mean           7722.087903028287
total_rewards_std            204.24276409574364
total_rewards_max            8144.249929783005
total_rewards_min            7379.905705384697
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               189.43001968832687
(Previous) Eval Time (s)     33.18735185125843
Sample Time (s)              7.756384338252246
Epoch Time (s)               230.37375587783754
Total Train Time (s)         31706.489751793444
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:25:09.406577 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #138 | Epoch Duration: 230.4726104736328
2020-01-13 08:25:09.406766 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.438496
Z variance train             0.020534988
KL Divergence                36.425552
KL Loss                      3.6425552
QF Loss                      161.83325
VF Loss                      33.84757
Policy Loss                  -865.9298
Q Predictions Mean           859.0038
Q Predictions Std            905.93604
Q Predictions Max            3325.0935
Q Predictions Min            398.91727
V Predictions Mean           868.3714
V Predictions Std            909.4867
V Predictions Max            3318.9927
V Predictions Min            397.6663
Log Pis Mean                 -0.5559671
Log Pis Std                  3.4494925
Log Pis Max                  16.035597
Log Pis Min                  -7.135111
Policy mu Mean               0.025845012
Policy mu Std                0.80608386
Policy mu Max                3.316081
Policy mu Min                -3.0123026
Policy log std Mean          -0.5184739
Policy log std Std           0.24393946
Policy log std Max           -0.07308194
Policy log std Min           -2.4605505
Z mean eval                  2.460364
Z variance eval              0.018056598
total_rewards                [8110.50435416 8198.40613089 7811.57293849 8046.178153   8022.59043619
 7909.73388213 8033.2435753  7825.2804999  7960.47457992 7970.39089214]
total_rewards_mean           7988.837544213011
total_rewards_std            114.32264742961827
total_rewards_max            8198.406130894346
total_rewards_min            7811.572938489722
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               188.97370677767321
(Previous) Eval Time (s)     32.69222002290189
Sample Time (s)              6.975355749949813
Epoch Time (s)               228.64128255052492
Total Train Time (s)         31935.21349175414
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:28:58.135804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #139 | Epoch Duration: 228.72885584831238
2020-01-13 08:28:58.136145 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4574103
Z variance train             0.018050782
KL Divergence                37.485855
KL Loss                      3.7485855
QF Loss                      170.8916
VF Loss                      27.772957
Policy Loss                  -910.01013
Q Predictions Mean           909.45874
Q Predictions Std            965.26385
Q Predictions Max            3397.035
Q Predictions Min            407.82214
V Predictions Mean           909.1755
V Predictions Std            965.88275
V Predictions Max            3393.5674
V Predictions Min            409.93094
Log Pis Mean                 -0.8289524
Log Pis Std                  3.262939
Log Pis Max                  10.08011
Log Pis Min                  -7.895606
Policy mu Mean               0.02527651
Policy mu Std                0.8047192
Policy mu Max                2.3351636
Policy mu Min                -2.3687425
Policy log std Mean          -0.50888485
Policy log std Std           0.25027916
Policy log std Max           -0.058358535
Policy log std Min           -2.2670329
Z mean eval                  2.4420943
Z variance eval              0.042781565
total_rewards                [7326.86868833 7904.25261942 7238.24047055 7192.41373939 7670.46644805
 8015.03215464 7707.09260857 7752.03810904 7801.69277102 7935.66266472]
total_rewards_mean           7654.376027371558
total_rewards_std            282.79858287512536
total_rewards_max            8015.032154639624
total_rewards_min            7192.4137393850515
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               192.4433170990087
(Previous) Eval Time (s)     33.42434324789792
Sample Time (s)              12.456587087828666
Epoch Time (s)               238.3242474347353
Total Train Time (s)         32173.61901639169
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:32:56.541758 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #140 | Epoch Duration: 238.40536761283875
2020-01-13 08:32:56.541946 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.443235
Z variance train             0.042679798
KL Divergence                36.962013
KL Loss                      3.6962013
QF Loss                      2250.8833
VF Loss                      98.22241
Policy Loss                  -1018.2259
Q Predictions Mean           1016.6842
Q Predictions Std            1067.6129
Q Predictions Max            3424.75
Q Predictions Min            407.1838
V Predictions Mean           1019.1126
V Predictions Std            1067.016
V Predictions Max            3415.0557
V Predictions Min            411.83786
Log Pis Mean                 -0.41632098
Log Pis Std                  3.6328635
Log Pis Max                  14.661454
Log Pis Min                  -6.718545
Policy mu Mean               -0.040629182
Policy mu Std                0.8511532
Policy mu Max                3.3413663
Policy mu Min                -2.7644846
Policy log std Mean          -0.5097678
Policy log std Std           0.24557161
Policy log std Max           -0.1262691
Policy log std Min           -2.5021577
Z mean eval                  2.450964
Z variance eval              0.020245757
total_rewards                [7610.16400264 8167.85715014 8034.43545976 7973.06420345 8079.10232722
 7668.3936797  8287.01715892 8142.57249517 8224.32171959 7755.98394437]
total_rewards_mean           7994.29121409643
total_rewards_std            225.94763295242015
total_rewards_max            8287.017158923045
total_rewards_min            7610.164002639821
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               189.51768141891807
(Previous) Eval Time (s)     34.67302854685113
Sample Time (s)              7.918000520672649
Epoch Time (s)               232.10871048644185
Total Train Time (s)         32405.80845826678
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:48.733769 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #141 | Epoch Duration: 232.19162130355835
2020-01-13 08:36:48.734071 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.453533
Z variance train             0.020252999
KL Divergence                38.274616
KL Loss                      3.8274617
QF Loss                      1760.5719
VF Loss                      44.706528
Policy Loss                  -938.49005
Q Predictions Mean           938.78796
Q Predictions Std            992.0003
Q Predictions Max            3400.3496
Q Predictions Min            406.25668
V Predictions Mean           935.177
V Predictions Std            991.7609
V Predictions Max            3403.9744
V Predictions Min            406.4542
Log Pis Mean                 -0.8421882
Log Pis Std                  3.111061
Log Pis Max                  14.715842
Log Pis Min                  -6.1397905
Policy mu Mean               0.0029104936
Policy mu Std                0.8215266
Policy mu Max                2.753829
Policy mu Min                -2.6995716
Policy log std Mean          -0.502732
Policy log std Std           0.2382841
Policy log std Max           0.051635206
Policy log std Min           -2.2169936
Z mean eval                  2.434545
Z variance eval              0.040427107
total_rewards                [7790.91079799 8042.89089209 8214.28243082 8017.16301193 7877.70984398
 7834.79202495 8047.1823645  7796.98632955 8214.24350261 7520.74103466]
total_rewards_mean           7935.690223307813
total_rewards_std            202.90162538690484
total_rewards_max            8214.282430823994
total_rewards_min            7520.741034655006
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               185.78949133306742
(Previous) Eval Time (s)     33.94437266467139
Sample Time (s)              7.203561139293015
Epoch Time (s)               226.93742513703182
Total Train Time (s)         32632.86572125554
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:40:35.793416 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #142 | Epoch Duration: 227.0591516494751
2020-01-13 08:40:35.793637 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4347901
Z variance train             0.040363967
KL Divergence                37.73094
KL Loss                      3.7730942
QF Loss                      148.65163
VF Loss                      99.083176
Policy Loss                  -945.47943
Q Predictions Mean           940.76715
Q Predictions Std            990.2711
Q Predictions Max            3418.6802
Q Predictions Min            414.7929
V Predictions Mean           945.3793
V Predictions Std            990.7983
V Predictions Max            3423.4075
V Predictions Min            419.57837
Log Pis Mean                 -0.44598737
Log Pis Std                  3.7620082
Log Pis Max                  18.813274
Log Pis Min                  -7.0585403
Policy mu Mean               -0.005984714
Policy mu Std                0.84403205
Policy mu Max                3.233542
Policy mu Min                -3.4572248
Policy log std Mean          -0.49363685
Policy log std Std           0.23793834
Policy log std Max           -0.0809108
Policy log std Min           -1.925804
Z mean eval                  2.4549763
Z variance eval              0.017129304
total_rewards                [7737.09118946 7583.49023642 7650.84979556 7302.64672881 7491.7471492
 7541.79455348 7560.37120202 7213.37205078 7531.92797035 7654.91718625]
total_rewards_mean           7526.820806233556
total_rewards_std            151.76533106681867
total_rewards_max            7737.091189459248
total_rewards_min            7213.37205078124
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               188.75108023919165
(Previous) Eval Time (s)     35.66905409377068
Sample Time (s)              7.871927188709378
Epoch Time (s)               232.2920615216717
Total Train Time (s)         32865.56003696658
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:44:28.489667 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #143 | Epoch Duration: 232.6958508491516
2020-01-13 08:44:28.489895 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.451989
Z variance train             0.01711126
KL Divergence                39.821247
KL Loss                      3.9821248
QF Loss                      240.22223
VF Loss                      65.36259
Policy Loss                  -955.2248
Q Predictions Mean           950.4901
Q Predictions Std            996.91473
Q Predictions Max            3432.1245
Q Predictions Min            402.91113
V Predictions Mean           960.33856
V Predictions Std            999.9071
V Predictions Max            3452.8645
V Predictions Min            419.00024
Log Pis Mean                 -0.8537336
Log Pis Std                  3.3091247
Log Pis Max                  13.799517
Log Pis Min                  -6.630972
Policy mu Mean               -0.015833778
Policy mu Std                0.8154041
Policy mu Max                2.8509712
Policy mu Min                -2.6844065
Policy log std Mean          -0.49694407
Policy log std Std           0.25097498
Policy log std Max           -0.06532925
Policy log std Min           -2.313974
Z mean eval                  2.3969705
Z variance eval              0.019061312
total_rewards                [8568.9938069  7670.36866068 7906.98265771 8013.59059721 8041.69852393
 8239.03319678 7855.79988142 8321.37216784 8280.70745707 8003.72521667]
total_rewards_mean           8090.227216621459
total_rewards_std            249.3186977483785
total_rewards_max            8568.993806896346
total_rewards_min            7670.368660684604
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               190.45833809580654
(Previous) Eval Time (s)     32.91480550682172
Sample Time (s)              7.236598138231784
Epoch Time (s)               230.60974174086004
Total Train Time (s)         33096.2489828337
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:48:19.180681 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #144 | Epoch Duration: 230.69063353538513
2020-01-13 08:48:19.180861 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.397958
Z variance train             0.019052982
KL Divergence                37.735416
KL Loss                      3.7735417
QF Loss                      416.45023
VF Loss                      170.37645
Policy Loss                  -873.056
Q Predictions Mean           869.2311
Q Predictions Std            929.8266
Q Predictions Max            3327.671
Q Predictions Min            387.02536
V Predictions Mean           880.9005
V Predictions Std            932.17334
V Predictions Max            3376.3616
V Predictions Min            406.09457
Log Pis Mean                 -1.0316837
Log Pis Std                  2.9424853
Log Pis Max                  16.590715
Log Pis Min                  -7.343934
Policy mu Mean               0.013464904
Policy mu Std                0.79654145
Policy mu Max                3.2063694
Policy mu Min                -2.4172504
Policy log std Mean          -0.50581557
Policy log std Std           0.24459854
Policy log std Max           -0.10103984
Policy log std Min           -2.7340689
Z mean eval                  2.3820121
Z variance eval              0.059666127
total_rewards                [8072.96970911 8313.27596896 7908.51073152 7899.99938429 8274.93323358
 7828.5869357  8027.39210784 8340.92667529 8107.51634279 8019.0415114 ]
total_rewards_mean           8079.315260047753
total_rewards_std            171.11461245557987
total_rewards_max            8340.926675289884
total_rewards_min            7828.586935697267
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               186.23980388743803
(Previous) Eval Time (s)     32.78355517424643
Sample Time (s)              6.790265255142003
Epoch Time (s)               225.81362431682646
Total Train Time (s)         33322.15053420514
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:52:05.083992 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #145 | Epoch Duration: 225.9029791355133
2020-01-13 08:52:05.084194 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.381345
Z variance train             0.05970981
KL Divergence                35.502483
KL Loss                      3.5502484
QF Loss                      110.070786
VF Loss                      31.60647
Policy Loss                  -931.32355
Q Predictions Mean           926.9535
Q Predictions Std            989.7077
Q Predictions Max            3352.3958
Q Predictions Min            417.36783
V Predictions Mean           931.5297
V Predictions Std            990.55255
V Predictions Max            3364.5774
V Predictions Min            425.23624
Log Pis Mean                 -0.54084647
Log Pis Std                  3.2436376
Log Pis Max                  11.507826
Log Pis Min                  -7.3960524
Policy mu Mean               0.013650741
Policy mu Std                0.82934767
Policy mu Max                2.5116994
Policy mu Min                -2.6647336
Policy log std Mean          -0.5124822
Policy log std Std           0.23803727
Policy log std Max           -0.12310234
Policy log std Min           -2.226531
Z mean eval                  2.455525
Z variance eval              0.028949032
total_rewards                [8041.6611443  8256.68601524 8217.67818411 8347.32058597 8402.46381841
 8573.36348262 8453.13539869 8235.67459436 8250.80846909 8229.26026431]
total_rewards_mean           8300.805195710282
total_rewards_std            140.6638739119889
total_rewards_max            8573.36348261686
total_rewards_min            8041.661144303913
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               187.87249122187495
(Previous) Eval Time (s)     32.77034089015797
Sample Time (s)              8.95713967224583
Epoch Time (s)               229.59997178427875
Total Train Time (s)         33551.848078162875
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:55:54.783715 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #146 | Epoch Duration: 229.69936656951904
2020-01-13 08:55:54.783911 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4549236
Z variance train             0.028992202
KL Divergence                38.878845
KL Loss                      3.8878846
QF Loss                      217.43782
VF Loss                      207.55768
Policy Loss                  -1069.8531
Q Predictions Mean           1065.5911
Q Predictions Std            1081.9735
Q Predictions Max            3373.544
Q Predictions Min            431.80606
V Predictions Mean           1073.9252
V Predictions Std            1082.7177
V Predictions Max            3376.5896
V Predictions Min            434.49365
Log Pis Mean                 -0.25295907
Log Pis Std                  3.8075497
Log Pis Max                  17.167421
Log Pis Min                  -6.754788
Policy mu Mean               -0.028548831
Policy mu Std                0.8840449
Policy mu Max                2.6410277
Policy mu Min                -2.675428
Policy log std Mean          -0.5257455
Policy log std Std           0.26357454
Policy log std Max           -0.08410376
Policy log std Min           -2.647852
Z mean eval                  2.43463
Z variance eval              0.04611974
total_rewards                [8088.65154537 8477.31308694 8291.42955463 8265.65274929 8103.65677057
 8244.83042986 8050.8538815  8393.78054313 8044.82815809 8266.34847725]
total_rewards_mean           8222.734519663049
total_rewards_std            140.13199472354734
total_rewards_max            8477.313086935903
total_rewards_min            8044.8281580934245
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               187.70842300308868
(Previous) Eval Time (s)     32.99558160593733
Sample Time (s)              7.324870076030493
Epoch Time (s)               228.0288746850565
Total Train Time (s)         33779.958659215365
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:59:42.896428 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #147 | Epoch Duration: 228.11234664916992
2020-01-13 08:59:42.896656 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4343686
Z variance train             0.0460349
KL Divergence                37.58741
KL Loss                      3.7587411
QF Loss                      1631.6514
VF Loss                      34.817684
Policy Loss                  -847.2244
Q Predictions Mean           846.75415
Q Predictions Std            902.2144
Q Predictions Max            3402.5667
Q Predictions Min            429.11472
V Predictions Mean           845.21643
V Predictions Std            902.64325
V Predictions Max            3411.0537
V Predictions Min            433.6635
Log Pis Mean                 -0.77142334
Log Pis Std                  3.1848004
Log Pis Max                  11.495791
Log Pis Min                  -6.208587
Policy mu Mean               0.01816806
Policy mu Std                0.8013299
Policy mu Max                2.6846983
Policy mu Min                -2.5337532
Policy log std Mean          -0.48598364
Policy log std Std           0.23951514
Policy log std Max           -0.09510419
Policy log std Min           -2.5827498
Z mean eval                  2.4011712
Z variance eval              0.066891775
total_rewards                [7591.44820583 7873.88138835 7892.00863662 8019.31542717 7669.80907053
 8002.387592   7976.39889044 7821.13713216 8141.68812838 7819.65352762]
total_rewards_mean           7880.772799909294
total_rewards_std            157.1259064532741
total_rewards_max            8141.688128376465
total_rewards_min            7591.448205827566
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               188.2878153352067
(Previous) Eval Time (s)     32.323953073937446
Sample Time (s)              6.726804852485657
Epoch Time (s)               227.3385732616298
Total Train Time (s)         34007.3859658842
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:03:30.327005 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #148 | Epoch Duration: 227.43017482757568
2020-01-13 09:03:30.327248 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4021747
Z variance train             0.06688098
KL Divergence                34.427364
KL Loss                      3.4427364
QF Loss                      195.75233
VF Loss                      54.435364
Policy Loss                  -1023.6353
Q Predictions Mean           1023.0609
Q Predictions Std            1055.9033
Q Predictions Max            3417.2322
Q Predictions Min            423.89938
V Predictions Mean           1020.86005
V Predictions Std            1053.4274
V Predictions Max            3416.551
V Predictions Min            421.51306
Log Pis Mean                 -0.33206195
Log Pis Std                  3.7508535
Log Pis Max                  15.281734
Log Pis Min                  -7.7785177
Policy mu Mean               -0.029444553
Policy mu Std                0.8632292
Policy mu Max                2.6837106
Policy mu Min                -2.3424075
Policy log std Mean          -0.5165652
Policy log std Std           0.23452973
Policy log std Max           -0.133264
Policy log std Min           -2.2750778
Z mean eval                  2.4419208
Z variance eval              0.026683161
total_rewards                [7456.09690126 6959.95167564 6831.45323564 7252.66427049 7102.63070254
 7400.4018499  8130.75286323 7141.32157154 7415.21181649 7418.39661665]
total_rewards_mean           7310.888150339783
total_rewards_std            339.4475194990347
total_rewards_max            8130.752863228237
total_rewards_min            6831.4532356412155
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               187.4606619873084
(Previous) Eval Time (s)     33.798020243644714
Sample Time (s)              7.493794263806194
Epoch Time (s)               228.75247649475932
Total Train Time (s)         34236.222359329
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:19.164633 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #149 | Epoch Duration: 228.8371958732605
2020-01-13 09:07:19.164828 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4428735
Z variance train             0.026665887
KL Divergence                38.256687
KL Loss                      3.8256688
QF Loss                      142.20737
VF Loss                      47.71485
Policy Loss                  -1025.1183
Q Predictions Mean           1022.65466
Q Predictions Std            1061.2374
Q Predictions Max            3618.6147
Q Predictions Min            424.19476
V Predictions Mean           1023.0142
V Predictions Std            1059.1815
V Predictions Max            3619.723
V Predictions Min            431.23138
Log Pis Mean                 -0.46575317
Log Pis Std                  3.400404
Log Pis Max                  13.370354
Log Pis Min                  -6.076937
Policy mu Mean               -0.08069101
Policy mu Std                0.8571596
Policy mu Max                2.7518475
Policy mu Min                -2.4584832
Policy log std Mean          -0.4880176
Policy log std Std           0.23299603
Policy log std Max           -0.100791186
Policy log std Min           -1.9172451
Z mean eval                  2.4408023
Z variance eval              0.02176003
total_rewards                [8012.8623353  8570.18949731 8553.25280326 8184.4029022  8362.21486546
 8531.68994633 8252.6310239  8063.44793361 8611.00960383 8222.28413419]
total_rewards_mean           8336.39850453931
total_rewards_std            209.3370280669032
total_rewards_max            8611.009603829803
total_rewards_min            8012.862335301304
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               183.67122075613588
(Previous) Eval Time (s)     34.78408143715933
Sample Time (s)              7.472439868375659
Epoch Time (s)               225.92774206167087
Total Train Time (s)         34462.22815411212
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:11:05.173030 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #150 | Epoch Duration: 226.00800490379333
2020-01-13 09:11:05.173297 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.441103
Z variance train             0.021792684
KL Divergence                37.85436
KL Loss                      3.785436
QF Loss                      171.13858
VF Loss                      49.920563
Policy Loss                  -1059.4562
Q Predictions Mean           1054.5092
Q Predictions Std            1086.8147
Q Predictions Max            3438.136
Q Predictions Min            418.77826
V Predictions Mean           1064.0557
V Predictions Std            1086.221
V Predictions Max            3435.1338
V Predictions Min            428.84702
Log Pis Mean                 -0.7647376
Log Pis Std                  2.9567878
Log Pis Max                  9.30682
Log Pis Min                  -5.814426
Policy mu Mean               -8.238541e-05
Policy mu Std                0.84509826
Policy mu Max                2.5636578
Policy mu Min                -2.4686785
Policy log std Mean          -0.5109148
Policy log std Std           0.23620805
Policy log std Max           -0.11414762
Policy log std Min           -2.2356033
Z mean eval                  2.4274163
Z variance eval              0.041576754
total_rewards                [8215.79406033 8585.76661177 8406.57707302 8429.32342471 8409.39854779
 8346.30453804 8708.24889517 8581.55332089 8569.86395624 8409.28916278]
total_rewards_mean           8466.211959073136
total_rewards_std            136.159658250957
total_rewards_max            8708.24889516517
total_rewards_min            8215.794060330676
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               187.20649427827448
(Previous) Eval Time (s)     32.65581464767456
Sample Time (s)              6.519315097946674
Epoch Time (s)               226.3816240238957
Total Train Time (s)         34688.69071672438
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:14:51.636544 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #151 | Epoch Duration: 226.46307635307312
2020-01-13 09:14:51.636705 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4261456
Z variance train             0.041571252
KL Divergence                36.496033
KL Loss                      3.6496034
QF Loss                      309.8502
VF Loss                      56.867958
Policy Loss                  -940.3989
Q Predictions Mean           937.5719
Q Predictions Std            1016.1579
Q Predictions Max            3657.469
Q Predictions Min            433.12418
V Predictions Mean           940.6489
V Predictions Std            1010.85767
V Predictions Max            3648.3335
V Predictions Min            441.00647
Log Pis Mean                 -0.5808267
Log Pis Std                  3.7169852
Log Pis Max                  16.899899
Log Pis Min                  -6.126029
Policy mu Mean               -0.013443855
Policy mu Std                0.84090656
Policy mu Max                3.422895
Policy mu Min                -3.0878437
Policy log std Mean          -0.4859991
Policy log std Std           0.24320543
Policy log std Max           -0.03610775
Policy log std Min           -2.8200157
Z mean eval                  2.385617
Z variance eval              0.029302651
total_rewards                [8723.18447131 8576.2884879  8433.59246222 8752.97662148 8955.44079117
 8815.46926711 8604.48545638 8797.86625242 8501.78399497 8768.09782022]
total_rewards_mean           8692.918562518586
total_rewards_std            151.7665864387429
total_rewards_max            8955.440791171464
total_rewards_min            8433.592462216811
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               183.7330760443583
(Previous) Eval Time (s)     32.80384503304958
Sample Time (s)              8.241053423378617
Epoch Time (s)               224.7779745007865
Total Train Time (s)         34913.54829000402
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:18:36.497820 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #152 | Epoch Duration: 224.86091589927673
2020-01-13 09:18:36.498135 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3842824
Z variance train             0.029244754
KL Divergence                36.329823
KL Loss                      3.6329823
QF Loss                      201.95436
VF Loss                      113.00283
Policy Loss                  -939.2903
Q Predictions Mean           937.0554
Q Predictions Std            1006.74445
Q Predictions Max            3570.082
Q Predictions Min            437.32504
V Predictions Mean           943.7345
V Predictions Std            1008.5738
V Predictions Max            3517.6672
V Predictions Min            442.40747
Log Pis Mean                 -0.653438
Log Pis Std                  3.1569183
Log Pis Max                  13.77956
Log Pis Min                  -6.6531563
Policy mu Mean               0.024634367
Policy mu Std                0.81865054
Policy mu Max                2.5277913
Policy mu Min                -2.1321766
Policy log std Mean          -0.48390737
Policy log std Std           0.25890428
Policy log std Max           -0.039681047
Policy log std Min           -2.429492
Z mean eval                  2.4107382
Z variance eval              0.026703525
total_rewards                [8438.40078423 8504.81689201 8329.44927514 8226.71461269 8401.13465788
 8201.05172343 8236.17663464 8644.30588384 8546.28802501 8113.00261428]
total_rewards_mean           8364.13411031553
total_rewards_std            162.62707667268072
total_rewards_max            8644.305883844898
total_rewards_min            8113.002614284515
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               188.59276571730152
(Previous) Eval Time (s)     31.05930149089545
Sample Time (s)              7.769247747492045
Epoch Time (s)               227.421314955689
Total Train Time (s)         35141.05434795609
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:24.006650 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #153 | Epoch Duration: 227.50828576087952
2020-01-13 09:22:24.006907 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.410052
Z variance train             0.026729828
KL Divergence                37.61958
KL Loss                      3.761958
QF Loss                      147.77911
VF Loss                      73.10322
Policy Loss                  -936.21747
Q Predictions Mean           931.9667
Q Predictions Std            985.10284
Q Predictions Max            3549.561
Q Predictions Min            447.737
V Predictions Mean           934.5985
V Predictions Std            980.8498
V Predictions Max            3545.6052
V Predictions Min            447.82178
Log Pis Mean                 -0.6068728
Log Pis Std                  3.617838
Log Pis Max                  16.975918
Log Pis Min                  -6.466221
Policy mu Mean               0.015531495
Policy mu Std                0.84715074
Policy mu Max                3.678093
Policy mu Min                -2.7194126
Policy log std Mean          -0.51668686
Policy log std Std           0.28193113
Policy log std Max           -0.13571486
Policy log std Min           -2.8680441
Z mean eval                  2.4010205
Z variance eval              0.024351044
total_rewards                [7656.43719101 7557.13793908 7605.70411354 7926.46195233 7470.30065966
 8121.96623449 7785.07206253 7762.65231795 7587.3479471  7406.72045645]
total_rewards_mean           7687.980087415548
total_rewards_std            205.35882457555238
total_rewards_max            8121.966234493
total_rewards_min            7406.720456447448
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               194.02972084190696
(Previous) Eval Time (s)     37.44425646774471
Sample Time (s)              6.820239259395748
Epoch Time (s)               238.29421656904742
Total Train Time (s)         35379.42982444726
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:26:22.384422 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #154 | Epoch Duration: 238.37723994255066
2020-01-13 09:26:22.384723 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4001315
Z variance train             0.024456937
KL Divergence                38.30935
KL Loss                      3.830935
QF Loss                      160.75885
VF Loss                      39.77053
Policy Loss                  -1011.9108
Q Predictions Mean           1012.45544
Q Predictions Std            1050.9266
Q Predictions Max            3714.857
Q Predictions Min            455.2223
V Predictions Mean           1009.239
V Predictions Std            1050.7587
V Predictions Max            3694.9321
V Predictions Min            452.19968
Log Pis Mean                 -0.3893494
Log Pis Std                  3.471801
Log Pis Max                  17.568985
Log Pis Min                  -6.6641197
Policy mu Mean               0.037640605
Policy mu Std                0.8472282
Policy mu Max                3.0713859
Policy mu Min                -2.5487046
Policy log std Mean          -0.5033818
Policy log std Std           0.2611123
Policy log std Max           -0.120228365
Policy log std Min           -2.1504774
Z mean eval                  2.4318862
Z variance eval              0.01848026
total_rewards                [8359.09960631 8462.57461542 8429.85127414 8504.57245606 8440.36888673
 8809.06571382 8744.53914393 8637.7102056  8206.04511215 8567.22120854]
total_rewards_mean           8516.104822271029
total_rewards_std            170.9885446987031
total_rewards_max            8809.065713822216
total_rewards_min            8206.045112152382
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               193.49760560085997
(Previous) Eval Time (s)     37.44096833700314
Sample Time (s)              6.835883586201817
Epoch Time (s)               237.77445752406493
Total Train Time (s)         35617.289683518466
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:30:20.246811 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #155 | Epoch Duration: 237.86189937591553
2020-01-13 09:30:20.246955 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.43255
Z variance train             0.01847331
KL Divergence                39.420536
KL Loss                      3.9420536
QF Loss                      180.69563
VF Loss                      65.22434
Policy Loss                  -1026.6808
Q Predictions Mean           1022.5934
Q Predictions Std            1055.5748
Q Predictions Max            3545.8652
Q Predictions Min            425.91577
V Predictions Mean           1028.4902
V Predictions Std            1057.2191
V Predictions Max            3565.6418
V Predictions Min            437.90088
Log Pis Mean                 -0.2282753
Log Pis Std                  3.562007
Log Pis Max                  12.933177
Log Pis Min                  -6.538318
Policy mu Mean               -0.0042193406
Policy mu Std                0.8617969
Policy mu Max                3.3179014
Policy mu Min                -2.7087696
Policy log std Mean          -0.5037536
Policy log std Std           0.25482628
Policy log std Max           -0.12580195
Policy log std Min           -2.5462065
Z mean eval                  2.3822465
Z variance eval              0.03597284
total_rewards                [8481.09808554 8270.09869373 8673.26617131 8651.53449512 8656.50862302
 8731.10812268 8549.93414666 8708.37942249 8760.98534585 8605.59437788]
total_rewards_mean           8608.850748428016
total_rewards_std            138.1288339015502
total_rewards_max            8760.985345848352
total_rewards_min            8270.098693729471
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               188.84211618313566
(Previous) Eval Time (s)     32.17677267920226
Sample Time (s)              6.602204966824502
Epoch Time (s)               227.62109382916242
Total Train Time (s)         35844.99907166185
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:07.962901 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #156 | Epoch Duration: 227.71571254730225
2020-01-13 09:34:07.963348 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806229
Z variance train             0.035813265
KL Divergence                37.53037
KL Loss                      3.753037
QF Loss                      142.60754
VF Loss                      25.143818
Policy Loss                  -992.08435
Q Predictions Mean           988.6426
Q Predictions Std            1028.2407
Q Predictions Max            3539.6765
Q Predictions Min            412.41006
V Predictions Mean           992.99817
V Predictions Std            1026.6748
V Predictions Max            3523.2766
V Predictions Min            432.79877
Log Pis Mean                 -0.43874836
Log Pis Std                  3.3540568
Log Pis Max                  11.986463
Log Pis Min                  -7.2687507
Policy mu Mean               0.002115335
Policy mu Std                0.82752615
Policy mu Max                2.4634027
Policy mu Min                -2.3892293
Policy log std Mean          -0.4954954
Policy log std Std           0.2454772
Policy log std Max           -0.065368116
Policy log std Min           -2.4388871
Z mean eval                  2.4083314
Z variance eval              0.016944638
total_rewards                [8595.30874942 8569.19385631 8255.92559792 8863.72118696 8468.13717251
 8530.85397587 8651.09075762 8499.91467964 8317.40424212 8526.61270685]
total_rewards_mean           8527.816292521702
total_rewards_std            160.2637141216548
total_rewards_max            8863.721186956189
total_rewards_min            8255.925597924868
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               198.0911775860004
(Previous) Eval Time (s)     34.16549845645204
Sample Time (s)              6.083365375176072
Epoch Time (s)               238.34004141762853
Total Train Time (s)         36083.432064890396
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:38:06.397579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #157 | Epoch Duration: 238.43394899368286
2020-01-13 09:38:06.397782 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.408617
Z variance train             0.016952338
KL Divergence                39.224167
KL Loss                      3.9224167
QF Loss                      101.90656
VF Loss                      140.85748
Policy Loss                  -950.86444
Q Predictions Mean           947.59143
Q Predictions Std            1019.0214
Q Predictions Max            3654.6829
Q Predictions Min            449.51288
V Predictions Mean           952.0108
V Predictions Std            1017.97253
V Predictions Max            3653.8074
V Predictions Min            456.22366
Log Pis Mean                 -0.75190586
Log Pis Std                  3.4940977
Log Pis Max                  16.975677
Log Pis Min                  -7.0850964
Policy mu Mean               -0.017157141
Policy mu Std                0.8105603
Policy mu Max                2.8199656
Policy mu Min                -3.3168278
Policy log std Mean          -0.48851982
Policy log std Std           0.26559094
Policy log std Max           -0.047459215
Policy log std Min           -2.4339108
Z mean eval                  2.3644786
Z variance eval              0.033531446
total_rewards                [8194.79258731 7876.31937821 7705.81824568 7855.08232812 7785.27381777
 7732.28856559 8035.15333762 7876.09757788 7908.55425106 7654.49161247]
total_rewards_mean           7862.387170171007
total_rewards_std            152.8119297673611
total_rewards_max            8194.792587305226
total_rewards_min            7654.491612465896
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               197.94975996157154
(Previous) Eval Time (s)     33.53783855214715
Sample Time (s)              7.061828764155507
Epoch Time (s)               238.5494272778742
Total Train Time (s)         36322.06512250425
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:42:05.062770 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #158 | Epoch Duration: 238.66466903686523
2020-01-13 09:42:05.063267 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3643682
Z variance train             0.033506535
KL Divergence                37.90095
KL Loss                      3.790095
QF Loss                      162.48286
VF Loss                      42.545288
Policy Loss                  -1053.8499
Q Predictions Mean           1053.6443
Q Predictions Std            1076.2333
Q Predictions Max            3641.429
Q Predictions Min            452.18573
V Predictions Mean           1052.4365
V Predictions Std            1074.5343
V Predictions Max            3625.8093
V Predictions Min            454.8034
Log Pis Mean                 -0.4804741
Log Pis Std                  3.3176181
Log Pis Max                  14.158477
Log Pis Min                  -7.702931
Policy mu Mean               -0.03570349
Policy mu Std                0.8579585
Policy mu Max                2.5928962
Policy mu Min                -3.30721
Policy log std Mean          -0.5012321
Policy log std Std           0.23586692
Policy log std Max           -0.022967935
Policy log std Min           -2.246514
Z mean eval                  2.401785
Z variance eval              0.033095773
total_rewards                [8720.7373714  8788.79512857 8743.20980018 8919.29352166 8709.11913637
 9007.21325828 8577.27248909 8847.03159211 8852.16503881 8588.6427259 ]
total_rewards_mean           8775.348006237775
total_rewards_std            129.6904953012659
total_rewards_max            9007.21325827836
total_rewards_min            8577.272489094672
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               194.09355587605387
(Previous) Eval Time (s)     33.81753265298903
Sample Time (s)              6.451299498323351
Epoch Time (s)               234.36238802736625
Total Train Time (s)         36556.5367479478
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:45:59.506429 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #159 | Epoch Duration: 234.4428472518921
2020-01-13 09:45:59.506621 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.39893
Z variance train             0.03311574
KL Divergence                39.204338
KL Loss                      3.9204338
QF Loss                      1039.0142
VF Loss                      29.610615
Policy Loss                  -929.02167
Q Predictions Mean           926.9936
Q Predictions Std            969.4419
Q Predictions Max            3717.7683
Q Predictions Min            444.6311
V Predictions Mean           929.7678
V Predictions Std            968.43665
V Predictions Max            3714.0378
V Predictions Min            449.60745
Log Pis Mean                 -0.6953819
Log Pis Std                  3.3092232
Log Pis Max                  12.766029
Log Pis Min                  -6.328636
Policy mu Mean               0.032873247
Policy mu Std                0.8220893
Policy mu Max                2.412716
Policy mu Min                -2.544317
Policy log std Mean          -0.49159908
Policy log std Std           0.2448608
Policy log std Max           -0.048644423
Policy log std Min           -2.5689132
Z mean eval                  2.3931782
Z variance eval              0.030150067
total_rewards                [8502.30169584 8809.74648762 8747.01601004 8457.26619662 8597.08295006
 8857.59577888 8429.22602336 8696.61254487 8542.76407006 8679.02189081]
total_rewards_mean           8631.863364816025
total_rewards_std            141.33460074263786
total_rewards_max            8857.595778878405
total_rewards_min            8429.226023360043
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               199.36772057414055
(Previous) Eval Time (s)     30.6291898121126
Sample Time (s)              10.921960877254605
Epoch Time (s)               240.91887126350775
Total Train Time (s)         36797.55748072732
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:50:00.529753 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #160 | Epoch Duration: 241.0229833126068
2020-01-13 09:50:00.529945 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.391074
Z variance train             0.030182594
KL Divergence                40.595993
KL Loss                      4.0595994
QF Loss                      101.57713
VF Loss                      45.682747
Policy Loss                  -929.54724
Q Predictions Mean           927.82416
Q Predictions Std            998.7584
Q Predictions Max            3749.7153
Q Predictions Min            446.6535
V Predictions Mean           930.10345
V Predictions Std            998.7908
V Predictions Max            3756.7117
V Predictions Min            461.16095
Log Pis Mean                 -0.7244947
Log Pis Std                  3.5495493
Log Pis Max                  14.913955
Log Pis Min                  -9.039433
Policy mu Mean               -0.027271008
Policy mu Std                0.83883435
Policy mu Max                2.6207418
Policy mu Min                -2.6898532
Policy log std Mean          -0.48002324
Policy log std Std           0.25564134
Policy log std Max           -0.089483336
Policy log std Min           -2.4878428
Z mean eval                  2.3704395
Z variance eval              0.021429483
total_rewards                [8188.00993228 7992.45706183 8226.80487096 8256.82734137 8112.56173741
 7912.66786965 8329.2987943  8370.57838679 8043.92822212 8043.94152134]
total_rewards_mean           8147.707573806115
total_rewards_std            143.02227732933807
total_rewards_max            8370.578386786183
total_rewards_min            7912.667869649577
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               196.66255162470043
(Previous) Eval Time (s)     31.88932300079614
Sample Time (s)              7.597680341918021
Epoch Time (s)               236.1495549674146
Total Train Time (s)         37033.787976080086
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:53:56.762371 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #161 | Epoch Duration: 236.23227095603943
2020-01-13 09:53:56.762572 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3699584
Z variance train             0.02142394
KL Divergence                41.927197
KL Loss                      4.19272
QF Loss                      247.38304
VF Loss                      91.23015
Policy Loss                  -1028.1499
Q Predictions Mean           1028.2803
Q Predictions Std            1051.1515
Q Predictions Max            3684.1255
Q Predictions Min            462.44177
V Predictions Mean           1028.582
V Predictions Std            1051.2755
V Predictions Max            3683.3772
V Predictions Min            461.41437
Log Pis Mean                 -0.52615726
Log Pis Std                  3.536072
Log Pis Max                  11.857637
Log Pis Min                  -7.487826
Policy mu Mean               0.047933694
Policy mu Std                0.83790576
Policy mu Max                3.1756723
Policy mu Min                -2.3073497
Policy log std Mean          -0.5018073
Policy log std Std           0.25625205
Policy log std Max           -0.08374104
Policy log std Min           -2.5049448
Z mean eval                  2.3613133
Z variance eval              0.018735815
total_rewards                [8185.10359605 8087.73635594 8249.80893125 8101.40697076 7874.59815712
 8461.98525439 8099.91360149 8219.9847572  8325.72027137 8221.54500142]
total_rewards_mean           8182.780289699423
total_rewards_std            149.42236904869657
total_rewards_max            8461.98525439442
total_rewards_min            7874.598157124048
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               195.7335666557774
(Previous) Eval Time (s)     30.269435283727944
Sample Time (s)              7.665997886098921
Epoch Time (s)               233.66899982560426
Total Train Time (s)         37267.55272126151
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:57:50.528963 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #162 | Epoch Duration: 233.76624059677124
2020-01-13 09:57:50.529152 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3633246
Z variance train             0.01876519
KL Divergence                41.70572
KL Loss                      4.170572
QF Loss                      2303.0132
VF Loss                      340.29535
Policy Loss                  -1043.9248
Q Predictions Mean           1040.8677
Q Predictions Std            1083.8179
Q Predictions Max            3830.6365
Q Predictions Min            464.54535
V Predictions Mean           1034.9988
V Predictions Std            1078.4384
V Predictions Max            3832.4985
V Predictions Min            460.17862
Log Pis Mean                 -0.64613813
Log Pis Std                  3.72247
Log Pis Max                  12.42642
Log Pis Min                  -6.4657655
Policy mu Mean               0.056518864
Policy mu Std                0.8576335
Policy mu Max                3.3148782
Policy mu Min                -2.5855777
Policy log std Mean          -0.4943339
Policy log std Std           0.28522155
Policy log std Max           -0.117195725
Policy log std Min           -3.0814805
Z mean eval                  2.3622513
Z variance eval              0.02696138
total_rewards                [9059.56231234 8693.73896234 8996.9747272  8979.50167516 9108.76749884
 8827.81607944 8983.03567991 8617.54763339 8747.03333544 8605.48655568]
total_rewards_mean           8861.946445972413
total_rewards_std            177.44104693075488
total_rewards_max            9108.767498840212
total_rewards_min            8605.486555676236
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               200.35125959012657
(Previous) Eval Time (s)     32.11348411999643
Sample Time (s)              8.15147953806445
Epoch Time (s)               240.61622324818745
Total Train Time (s)         37508.24896263983
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:01:51.227405 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #163 | Epoch Duration: 240.69810438156128
2020-01-13 10:01:51.227601 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3636382
Z variance train             0.026809925
KL Divergence                40.019215
KL Loss                      4.0019217
QF Loss                      107.16016
VF Loss                      87.99205
Policy Loss                  -1001.6045
Q Predictions Mean           997.0319
Q Predictions Std            1052.9489
Q Predictions Max            3597.122
Q Predictions Min            456.28268
V Predictions Mean           1003.1428
V Predictions Std            1049.4785
V Predictions Max            3595.3853
V Predictions Min            468.79407
Log Pis Mean                 -0.43760437
Log Pis Std                  3.6693695
Log Pis Max                  17.908785
Log Pis Min                  -9.939147
Policy mu Mean               0.0039303224
Policy mu Std                0.870735
Policy mu Max                3.4142442
Policy mu Min                -2.9731653
Policy log std Mean          -0.48996362
Policy log std Std           0.25046095
Policy log std Max           -0.097969115
Policy log std Min           -2.2883236
Z mean eval                  2.3103528
Z variance eval              0.11827862
total_rewards                [8656.70730681 9193.40196892 8831.70032493 8975.86154642 8904.33779721
 9012.80527612 8830.09845887 9149.67973896 9104.37747677 9077.53677042]
total_rewards_mean           8973.650666542047
total_rewards_std            159.5967308912919
total_rewards_max            9193.401968917371
total_rewards_min            8656.707306806567
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               196.02842684229836
(Previous) Eval Time (s)     35.70406479202211
Sample Time (s)              6.472682774066925
Epoch Time (s)               238.2051744083874
Total Train Time (s)         37746.53782926407
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:49.518711 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #164 | Epoch Duration: 238.29096579551697
2020-01-13 10:05:49.518871 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3114974
Z variance train             0.117971204
KL Divergence                36.609097
KL Loss                      3.6609097
QF Loss                      446.14557
VF Loss                      182.06702
Policy Loss                  -1112.0112
Q Predictions Mean           1106.369
Q Predictions Std            1141.9031
Q Predictions Max            3652.7163
Q Predictions Min            455.81494
V Predictions Mean           1105.0681
V Predictions Std            1136.7875
V Predictions Max            3617.5466
V Predictions Min            453.9754
Log Pis Mean                 -0.18663669
Log Pis Std                  4.0769515
Log Pis Max                  14.794214
Log Pis Min                  -7.209957
Policy mu Mean               -0.0018674601
Policy mu Std                0.9294503
Policy mu Max                3.4533246
Policy mu Min                -3.052772
Policy log std Mean          -0.5008688
Policy log std Std           0.2832429
Policy log std Max           -0.0703316
Policy log std Min           -3.2746363
Z mean eval                  2.3182282
Z variance eval              0.051657032
total_rewards                [8566.42716807 8809.92943072 8724.7797057  8759.01628593 8718.96590759
 8581.3215382  8771.42591539 8395.68643011 8719.12859853 8637.78669957]
total_rewards_mean           8668.446767980206
total_rewards_std            118.51420322617773
total_rewards_max            8809.929430716506
total_rewards_min            8395.686430110623
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               197.59099452989176
(Previous) Eval Time (s)     33.323704125825316
Sample Time (s)              6.526736920699477
Epoch Time (s)               237.44143557641655
Total Train Time (s)         37984.264979748055
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:09:47.262157 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #165 | Epoch Duration: 237.7430717945099
2020-01-13 10:09:47.262540 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.314942
Z variance train             0.0516333
KL Divergence                37.548103
KL Loss                      3.7548103
QF Loss                      99.59041
VF Loss                      59.97848
Policy Loss                  -1118.8385
Q Predictions Mean           1116.389
Q Predictions Std            1119.8564
Q Predictions Max            3798.8843
Q Predictions Min            470.59732
V Predictions Mean           1122.4496
V Predictions Std            1116.5457
V Predictions Max            3792.187
V Predictions Min            475.96896
Log Pis Mean                 -0.23142137
Log Pis Std                  3.4500542
Log Pis Max                  12.430486
Log Pis Min                  -9.187861
Policy mu Mean               -0.06709383
Policy mu Std                0.89722794
Policy mu Max                2.532171
Policy mu Min                -2.5341225
Policy log std Mean          -0.4787682
Policy log std Std           0.24378482
Policy log std Max           -0.07532662
Policy log std Min           -2.5524812
Z mean eval                  2.3003447
Z variance eval              0.049869917
total_rewards                [7210.31501149 7385.0904048  7377.73855514 7349.05264029 7288.06871709
 7448.18574639 7309.04079067 7369.54716227 7281.29335468 7163.84031494]
total_rewards_mean           7318.21726977558
total_rewards_std            81.43945142422258
total_rewards_max            7448.18574639256
total_rewards_min            7163.840314941377
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               199.43184405192733
(Previous) Eval Time (s)     32.31514943391085
Sample Time (s)              6.853175998199731
Epoch Time (s)               238.6001694840379
Total Train Time (s)         38222.958453329746
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:13:45.961388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #166 | Epoch Duration: 238.69857382774353
2020-01-13 10:13:45.961737 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.303522
Z variance train             0.049889337
KL Divergence                38.856995
KL Loss                      3.8856995
QF Loss                      300.61078
VF Loss                      80.0616
Policy Loss                  -1003.47485
Q Predictions Mean           999.67554
Q Predictions Std            1029.0963
Q Predictions Max            3845.4558
Q Predictions Min            466.86002
V Predictions Mean           1004.9242
V Predictions Std            1023.5431
V Predictions Max            3825.0598
V Predictions Min            474.35315
Log Pis Mean                 -0.5781963
Log Pis Std                  3.448686
Log Pis Max                  10.962179
Log Pis Min                  -7.8570313
Policy mu Mean               0.0016051643
Policy mu Std                0.83515924
Policy mu Max                3.9298348
Policy mu Min                -3.3689697
Policy log std Mean          -0.4892186
Policy log std Std           0.25589645
Policy log std Max           -0.10398428
Policy log std Min           -2.341651
Z mean eval                  2.2710292
Z variance eval              0.026781734
total_rewards                [8694.44809912 8685.99666984 9081.98116063 8972.58432532 8958.48494829
 9040.28648814 8950.6418254  8941.2565976  8773.24332103 8556.23798707]
total_rewards_mean           8865.51614224411
total_rewards_std            166.17771763314994
total_rewards_max            9081.981160632307
total_rewards_min            8556.23798707052
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               198.89671636605635
(Previous) Eval Time (s)     34.86238725995645
Sample Time (s)              6.234475594013929
Epoch Time (s)               239.99357922002673
Total Train Time (s)         38463.05960456934
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:46.051273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #167 | Epoch Duration: 240.08925819396973
2020-01-13 10:17:46.051579 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2699733
Z variance train             0.026800832
KL Divergence                39.189034
KL Loss                      3.9189034
QF Loss                      128.55154
VF Loss                      237.43484
Policy Loss                  -1034.8257
Q Predictions Mean           1032.4663
Q Predictions Std            1107.5192
Q Predictions Max            3884.0688
Q Predictions Min            485.05707
V Predictions Mean           1042.114
V Predictions Std            1110.1802
V Predictions Max            3907.3179
V Predictions Min            496.65436
Log Pis Mean                 -0.19098741
Log Pis Std                  3.798803
Log Pis Max                  16.456995
Log Pis Min                  -6.408305
Policy mu Mean               -0.0144683
Policy mu Std                0.8950655
Policy mu Max                3.5859604
Policy mu Min                -2.78806
Policy log std Mean          -0.5076646
Policy log std Std           0.26436257
Policy log std Max           -0.11920874
Policy log std Min           -2.5923493
Z mean eval                  2.2807145
Z variance eval              0.037931226
total_rewards                [9180.81612288 8970.39454771 8993.39471913 8727.8705477  8906.35381969
 8246.13775575 8593.41534246 8935.36251388 8973.43490433 8716.72736237]
total_rewards_mean           8824.390763590223
total_rewards_std            250.35955200667317
total_rewards_max            9180.816122881255
total_rewards_min            8246.137755749294
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               198.89640342770144
(Previous) Eval Time (s)     30.812013930641115
Sample Time (s)              6.347304398659617
Epoch Time (s)               236.05572175700217
Total Train Time (s)         38699.20297008287
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:21:42.196205 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #168 | Epoch Duration: 236.14438772201538
2020-01-13 10:21:42.196401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2802823
Z variance train             0.03773505
KL Divergence                39.588104
KL Loss                      3.9588106
QF Loss                      178.4272
VF Loss                      103.415245
Policy Loss                  -1088.6335
Q Predictions Mean           1087.0883
Q Predictions Std            1095.2692
Q Predictions Max            3747.6643
Q Predictions Min            482.1916
V Predictions Mean           1090.4331
V Predictions Std            1092.4391
V Predictions Max            3726.0815
V Predictions Min            480.59924
Log Pis Mean                 -0.31209958
Log Pis Std                  3.9853609
Log Pis Max                  23.534504
Log Pis Min                  -6.8441353
Policy mu Mean               0.040179763
Policy mu Std                0.8767543
Policy mu Max                3.1056058
Policy mu Min                -3.0495837
Policy log std Mean          -0.47908762
Policy log std Std           0.26310545
Policy log std Max           -0.11580089
Policy log std Min           -2.6125348
Z mean eval                  2.2833133
Z variance eval              0.029147863
total_rewards                [8962.98494372 9035.55390409 9021.71851021 8909.30098531 9191.39149857
 8965.3932313  9076.29841486 8957.56355805 9418.65681098 8874.59389496]
total_rewards_mean           9041.345575205763
total_rewards_std            151.88432571685905
total_rewards_max            9418.656810976787
total_rewards_min            8874.59389496461
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               196.0498073170893
(Previous) Eval Time (s)     33.40418306645006
Sample Time (s)              7.710145119111985
Epoch Time (s)               237.16413550265133
Total Train Time (s)         38936.44999478897
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:25:39.445910 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #169 | Epoch Duration: 237.24937295913696
2020-01-13 10:25:39.446082 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2837746
Z variance train             0.02921823
KL Divergence                38.939167
KL Loss                      3.8939168
QF Loss                      146.66638
VF Loss                      56.60215
Policy Loss                  -956.54407
Q Predictions Mean           952.97546
Q Predictions Std            1008.6818
Q Predictions Max            3842.9302
Q Predictions Min            475.41208
V Predictions Mean           952.98425
V Predictions Std            1005.7913
V Predictions Max            3835.8267
V Predictions Min            476.27457
Log Pis Mean                 -0.61904925
Log Pis Std                  3.2093074
Log Pis Max                  11.307009
Log Pis Min                  -6.6387596
Policy mu Mean               8.5386135e-05
Policy mu Std                0.8261019
Policy mu Max                2.6744175
Policy mu Min                -2.3883657
Policy log std Mean          -0.47562027
Policy log std Std           0.24505259
Policy log std Max           -0.10382673
Policy log std Min           -2.3426585
Z mean eval                  2.3087955
Z variance eval              0.025946636
total_rewards                [8674.60088603 9264.95772349 9040.71744719 8875.32368912 9039.18840732
 9071.70940525 9207.48600539 8689.95433086 8548.246682   8754.30124146]
total_rewards_mean           8916.648581810927
total_rewards_std            231.11043944340977
total_rewards_max            9264.957723491116
total_rewards_min            8548.246681998251
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               194.3323347843252
(Previous) Eval Time (s)     32.99638127209619
Sample Time (s)              7.386443657334894
Epoch Time (s)               234.7151597137563
Total Train Time (s)         39171.25486123795
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:34.253053 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #170 | Epoch Duration: 234.8068470954895
2020-01-13 10:29:34.253184 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3091404
Z variance train             0.025981912
KL Divergence                39.71903
KL Loss                      3.9719028
QF Loss                      140.35406
VF Loss                      40.886326
Policy Loss                  -1001.37994
Q Predictions Mean           998.2178
Q Predictions Std            1044.3698
Q Predictions Max            3827.6138
Q Predictions Min            479.10153
V Predictions Mean           999.66504
V Predictions Std            1044.1139
V Predictions Max            3822.946
V Predictions Min            479.4585
Log Pis Mean                 -0.9838983
Log Pis Std                  3.2781224
Log Pis Max                  11.944997
Log Pis Min                  -8.56932
Policy mu Mean               -0.006694184
Policy mu Std                0.80537736
Policy mu Max                2.5846968
Policy mu Min                -2.9820664
Policy log std Mean          -0.4588132
Policy log std Std           0.23783255
Policy log std Max           -0.03527522
Policy log std Min           -2.461133
Z mean eval                  2.359784
Z variance eval              0.025709853
total_rewards                [8818.33547326 8492.13792654 8898.48301566 8578.84471955 8958.81423834
 8845.76924414 8596.4209952  8942.66124381 8748.43915313 8801.803892  ]
total_rewards_mean           8768.17099016182
total_rewards_std            153.41712820807751
total_rewards_max            8958.814238337623
total_rewards_min            8492.137926535344
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               196.17916781408712
(Previous) Eval Time (s)     30.792167284991592
Sample Time (s)              7.899895780719817
Epoch Time (s)               234.87123087979853
Total Train Time (s)         39406.204473697115
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:33:29.204315 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #171 | Epoch Duration: 234.95102429389954
2020-01-13 10:33:29.204476 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.357312
Z variance train             0.025624022
KL Divergence                41.346775
KL Loss                      4.1346774
QF Loss                      199.03947
VF Loss                      41.989563
Policy Loss                  -1077.2268
Q Predictions Mean           1074.8757
Q Predictions Std            1112.8358
Q Predictions Max            3921.1882
Q Predictions Min            485.56845
V Predictions Mean           1077.0552
V Predictions Std            1112.4027
V Predictions Max            3917.8225
V Predictions Min            487.9644
Log Pis Mean                 -0.13116074
Log Pis Std                  3.990454
Log Pis Max                  14.355639
Log Pis Min                  -8.463099
Policy mu Mean               0.014093048
Policy mu Std                0.90597266
Policy mu Max                3.3322797
Policy mu Min                -3.1072917
Policy log std Mean          -0.4757352
Policy log std Std           0.2720169
Policy log std Max           -0.055715263
Policy log std Min           -2.845032
Z mean eval                  2.2898388
Z variance eval              0.05128888
total_rewards                [8134.74931742 8272.56360352 8032.84040544 8151.28031079 8206.25503352
 8078.19573641 8122.13338502 8289.74541197 8009.64379549 8017.90058632]
total_rewards_mean           8131.530758590983
total_rewards_std            95.57574479910735
total_rewards_max            8289.745411969663
total_rewards_min            8009.643795492832
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               193.452646327205
(Previous) Eval Time (s)     33.01866207597777
Sample Time (s)              7.36119319871068
Epoch Time (s)               233.83250160189345
Total Train Time (s)         39640.12133622402
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:37:23.124611 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #172 | Epoch Duration: 233.9200098514557
2020-01-13 10:37:23.124803 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2924302
Z variance train             0.051306866
KL Divergence                39.188835
KL Loss                      3.9188836
QF Loss                      153.90193
VF Loss                      94.07384
Policy Loss                  -1077.3982
Q Predictions Mean           1075.2045
Q Predictions Std            1124.3301
Q Predictions Max            3974.9548
Q Predictions Min            491.27002
V Predictions Mean           1076.7498
V Predictions Std            1119.2214
V Predictions Max            3930.162
V Predictions Min            493.89807
Log Pis Mean                 -0.15096813
Log Pis Std                  3.5597012
Log Pis Max                  13.984491
Log Pis Min                  -5.750243
Policy mu Mean               0.058429927
Policy mu Std                0.8852834
Policy mu Max                2.8424041
Policy mu Min                -2.9688127
Policy log std Mean          -0.49357298
Policy log std Std           0.2525545
Policy log std Max           -0.116827965
Policy log std Min           -2.4122944
Z mean eval                  2.3078835
Z variance eval              0.03721481
total_rewards                [8963.34439023 8670.90603288 8771.70969248 8674.54314814 8397.75687322
 8920.24549284 8519.67379112 8729.8549317  8535.08869988 8801.30083703]
total_rewards_mean           8698.442388952504
total_rewards_std            169.31870434746696
total_rewards_max            8963.344390231083
total_rewards_min            8397.756873220582
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               197.8335533021018
(Previous) Eval Time (s)     32.14479268388823
Sample Time (s)              7.247579722199589
Epoch Time (s)               237.2259257081896
Total Train Time (s)         39877.42880550772
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:20.437096 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #173 | Epoch Duration: 237.31214594841003
2020-01-13 10:41:20.437287 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3094192
Z variance train             0.03737718
KL Divergence                40.899113
KL Loss                      4.0899115
QF Loss                      484.09918
VF Loss                      36.22066
Policy Loss                  -1033.8115
Q Predictions Mean           1032.7866
Q Predictions Std            1077.9518
Q Predictions Max            3956.049
Q Predictions Min            498.20474
V Predictions Mean           1031.6249
V Predictions Std            1075.3484
V Predictions Max            3940.4712
V Predictions Min            497.98578
Log Pis Mean                 -0.1735796
Log Pis Std                  3.9081006
Log Pis Max                  16.397823
Log Pis Min                  -6.5450354
Policy mu Mean               0.0037498798
Policy mu Std                0.89895463
Policy mu Max                2.9203167
Policy mu Min                -2.752336
Policy log std Mean          -0.5025267
Policy log std Std           0.25291178
Policy log std Max           -0.09131494
Policy log std Min           -2.4862514
Z mean eval                  2.343226
Z variance eval              0.068926506
total_rewards                [8744.48583983 9101.33876328 8723.45275846 9008.38073501 8844.42175016
 8745.8343286  8790.94241495 9099.5310072  8824.63898044 8719.44524933]
total_rewards_mean           8860.247182725201
total_rewards_std            144.45617884325878
total_rewards_max            9101.33876327881
total_rewards_min            8719.445249328468
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               195.12323524383828
(Previous) Eval Time (s)     28.12844387581572
Sample Time (s)              6.517639393918216
Epoch Time (s)               229.76931851357222
Total Train Time (s)         40107.279744552914
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:10.291299 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #174 | Epoch Duration: 229.8538179397583
2020-01-13 10:45:10.291649 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3389204
Z variance train             0.06899841
KL Divergence                39.0654
KL Loss                      3.90654
QF Loss                      176.08322
VF Loss                      53.10522
Policy Loss                  -1029.9786
Q Predictions Mean           1029.4973
Q Predictions Std            1063.8231
Q Predictions Max            3883.9258
Q Predictions Min            495.3691
V Predictions Mean           1027.7915
V Predictions Std            1063.8817
V Predictions Max            3878.3232
V Predictions Min            494.9773
Log Pis Mean                 -0.6727686
Log Pis Std                  3.446114
Log Pis Max                  12.878304
Log Pis Min                  -5.6949406
Policy mu Mean               0.057530493
Policy mu Std                0.83889645
Policy mu Max                2.768176
Policy mu Min                -2.438661
Policy log std Mean          -0.49087262
Policy log std Std           0.24473692
Policy log std Max           -0.13019444
Policy log std Min           -2.5593834
Z mean eval                  2.3681538
Z variance eval              0.109321475
total_rewards                [9179.42395981 9091.00237103 9251.76079925 8883.71331038 8940.40068896
 9138.00908588 9112.95725029 9074.57368561 8958.7793845  9251.68938674]
total_rewards_mean           9088.230992245433
total_rewards_std            120.62307008397289
total_rewards_max            9251.760799249112
total_rewards_min            8883.713310382524
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               197.5254672942683
(Previous) Eval Time (s)     30.837706588208675
Sample Time (s)              8.624143915716559
Epoch Time (s)               236.98731779819354
Total Train Time (s)         40344.367971040774
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:49:07.384487 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #175 | Epoch Duration: 237.09252262115479
2020-01-13 10:49:07.384719 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3682654
Z variance train             0.10974483
KL Divergence                41.305637
KL Loss                      4.1305637
QF Loss                      155.4617
VF Loss                      47.836025
Policy Loss                  -1056.6034
Q Predictions Mean           1054.4651
Q Predictions Std            1109.5928
Q Predictions Max            3955.884
Q Predictions Min            498.40414
V Predictions Mean           1053.9542
V Predictions Std            1109.1448
V Predictions Max            3938.949
V Predictions Min            499.01935
Log Pis Mean                 -0.84310573
Log Pis Std                  3.6217184
Log Pis Max                  13.898384
Log Pis Min                  -7.5195312
Policy mu Mean               0.056850433
Policy mu Std                0.85179275
Policy mu Max                3.0497873
Policy mu Min                -2.9114144
Policy log std Mean          -0.48587584
Policy log std Std           0.24326774
Policy log std Max           -0.10178128
Policy log std Min           -2.6411989
Z mean eval                  2.3578823
Z variance eval              0.08422201
total_rewards                [9449.83121062 9337.51807639 9244.21798403 9393.29693313 5486.31430348
 9334.81316699 9283.12124911 9456.63716497 9415.07266468 9316.79254187]
total_rewards_mean           8971.761529526888
total_rewards_std            1163.701953401468
total_rewards_max            9456.637164965025
total_rewards_min            5486.314303482218
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               197.9632556163706
(Previous) Eval Time (s)     36.2925906162709
Sample Time (s)              8.177079770248383
Epoch Time (s)               242.43292600288987
Total Train Time (s)         40586.89197028754
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:09.909132 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #176 | Epoch Duration: 242.52417039871216
2020-01-13 10:53:09.909452 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3562572
Z variance train             0.08468657
KL Divergence                41.264973
KL Loss                      4.1264973
QF Loss                      76.04454
VF Loss                      75.56843
Policy Loss                  -927.90063
Q Predictions Mean           924.6224
Q Predictions Std            958.12964
Q Predictions Max            3937.5962
Q Predictions Min            495.21268
V Predictions Mean           922.8439
V Predictions Std            953.89825
V Predictions Max            3908.3904
V Predictions Min            496.81165
Log Pis Mean                 -0.7244475
Log Pis Std                  3.0936513
Log Pis Max                  13.179373
Log Pis Min                  -7.632245
Policy mu Mean               0.053211674
Policy mu Std                0.8211501
Policy mu Max                3.070564
Policy mu Min                -2.3502564
Policy log std Mean          -0.49579993
Policy log std Std           0.24871673
Policy log std Max           -0.092000306
Policy log std Min           -2.626874
Z mean eval                  2.3649364
Z variance eval              0.08436237
total_rewards                [8760.45598647 8615.7440391  8826.68647303 8762.05404292 8791.09239557
 8895.6295646  8771.56275341 8660.41083232 8721.7535207  9130.66078769]
total_rewards_mean           8793.605039581515
total_rewards_std            134.9941984872432
total_rewards_max            9130.660787686355
total_rewards_min            8615.744039104004
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               195.45036283927038
(Previous) Eval Time (s)     32.32362456386909
Sample Time (s)              7.126255128998309
Epoch Time (s)               234.90024253213778
Total Train Time (s)         40821.87402334763
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:57:04.893122 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #177 | Epoch Duration: 234.98348188400269
2020-01-13 10:57:04.893310 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #177 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364962
Z variance train             0.08419279
KL Divergence                38.73901
KL Loss                      3.8739011
QF Loss                      555.95984
VF Loss                      47.925434
Policy Loss                  -1025.5249
Q Predictions Mean           1021.458
Q Predictions Std            1074.389
Q Predictions Max            3916.4417
Q Predictions Min            507.925
V Predictions Mean           1023.17505
V Predictions Std            1071.8136
V Predictions Max            3913.1392
V Predictions Min            509.5965
Log Pis Mean                 -0.5243333
Log Pis Std                  3.3430274
Log Pis Max                  16.457365
Log Pis Min                  -6.862321
Policy mu Mean               0.040033214
Policy mu Std                0.8438345
Policy mu Max                3.4411666
Policy mu Min                -3.3528495
Policy log std Mean          -0.4862926
Policy log std Std           0.25589362
Policy log std Max           -0.12389217
Policy log std Min           -2.4172962
Z mean eval                  2.3875651
Z variance eval              0.07194315
total_rewards                [8871.05892346 9281.79543326 9170.92855801 9217.43399196 9178.9466165
 8933.77566136 9099.15263321 8998.08841932 9173.82975847 8957.45179516]
total_rewards_mean           9088.246179071652
total_rewards_std            131.50067949848128
total_rewards_max            9281.795433261937
total_rewards_min            8871.058923460205
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               194.72038896894082
(Previous) Eval Time (s)     36.13250879524276
Sample Time (s)              6.969183281995356
Epoch Time (s)               237.82208104617894
Total Train Time (s)         41059.78170217993
Epoch                        178
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:01:02.806807 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #178 | Epoch Duration: 237.91323804855347
2020-01-13 11:01:02.807247 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3897436
Z variance train             0.0719074
KL Divergence                39.270245
KL Loss                      3.9270246
QF Loss                      507.62158
VF Loss                      39.65754
Policy Loss                  -1046.1512
Q Predictions Mean           1045.5496
Q Predictions Std            1070.3596
Q Predictions Max            4030.1887
Q Predictions Min            522.72156
V Predictions Mean           1045.6643
V Predictions Std            1070.9613
V Predictions Max            4012.0583
V Predictions Min            523.43756
Log Pis Mean                 -0.71079004
Log Pis Std                  3.379068
Log Pis Max                  11.891918
Log Pis Min                  -7.207199
Policy mu Mean               0.02919921
Policy mu Std                0.8311736
Policy mu Max                2.707872
Policy mu Min                -2.9856994
Policy log std Mean          -0.4756404
Policy log std Std           0.2469254
Policy log std Max           -0.09751761
Policy log std Min           -2.4466841
Z mean eval                  2.3682697
Z variance eval              0.043527268
total_rewards                [8735.07419231 8509.20303536 8767.04949921 8943.61500093 8818.03291428
 8490.58425159 8807.85767147 8474.89690396 8290.90840022 8570.98511287]
total_rewards_mean           8640.820698221603
total_rewards_std            192.4962001968341
total_rewards_max            8943.615000932388
total_rewards_min            8290.90840022325
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               195.43024510424584
(Previous) Eval Time (s)     32.68013679375872
Sample Time (s)              7.097317824605852
Epoch Time (s)               235.2076997226104
Total Train Time (s)         41295.12322419882
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:04:58.151323 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #179 | Epoch Duration: 235.3437843322754
2020-01-13 11:04:58.151587 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3651485
Z variance train             0.043712884
KL Divergence                40.067127
KL Loss                      4.006713
QF Loss                      112.251785
VF Loss                      50.990166
Policy Loss                  -957.12384
Q Predictions Mean           957.0607
Q Predictions Std            1009.67206
Q Predictions Max            4004.353
Q Predictions Min            505.54034
V Predictions Mean           960.984
V Predictions Std            1010.44977
V Predictions Max            3996.398
V Predictions Min            508.30478
Log Pis Mean                 -0.74656963
Log Pis Std                  3.175733
Log Pis Max                  10.655453
Log Pis Min                  -8.167763
Policy mu Mean               0.001932978
Policy mu Std                0.8418178
Policy mu Max                2.7178326
Policy mu Min                -2.4440608
Policy log std Mean          -0.4933013
Policy log std Std           0.24981159
Policy log std Max           -0.12329364
Policy log std Min           -2.8165975
Z mean eval                  2.3404956
Z variance eval              0.019968811
total_rewards                [9289.8031044  9663.00236951 9458.46741204 9673.0847231  9501.34171516
 9149.74437415 9469.14496772 9555.32668776 9596.38150284 9498.81072197]
total_rewards_mean           9485.510757864291
total_rewards_std            153.72738556977382
total_rewards_max            9673.084723095564
total_rewards_min            9149.744374154994
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               199.09679378801957
(Previous) Eval Time (s)     36.165040674153715
Sample Time (s)              10.662934507708997
Epoch Time (s)               245.92476896988228
Total Train Time (s)         41541.12898805132
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:04.162642 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #180 | Epoch Duration: 246.0108449459076
2020-01-13 11:09:04.162843 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3404963
Z variance train             0.01990588
KL Divergence                42.12699
KL Loss                      4.2126994
QF Loss                      2607.061
VF Loss                      82.18762
Policy Loss                  -1103.7286
Q Predictions Mean           1100.7778
Q Predictions Std            1132.986
Q Predictions Max            4045.5864
Q Predictions Min            504.82565
V Predictions Mean           1101.3787
V Predictions Std            1134.9015
V Predictions Max            4031.5596
V Predictions Min            506.20343
Log Pis Mean                 -0.4496723
Log Pis Std                  3.5047183
Log Pis Max                  10.791496
Log Pis Min                  -9.0592575
Policy mu Mean               -0.0012815073
Policy mu Std                0.85642934
Policy mu Max                2.7316482
Policy mu Min                -2.5072553
Policy log std Mean          -0.5020817
Policy log std Std           0.27505633
Policy log std Max           -0.086660564
Policy log std Min           -2.6794057
Z mean eval                  2.325675
Z variance eval              0.028969437
total_rewards                [9454.47045383 8895.69014442 9044.74476337 9352.18296908 9200.6200045
 9257.43122145 9221.94254883 9258.20798189 8966.69977295 9270.51139267]
total_rewards_mean           9192.250125299546
total_rewards_std            164.49685885189854
total_rewards_max            9454.470453826707
total_rewards_min            8895.690144420056
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               193.54775823000818
(Previous) Eval Time (s)     36.5919778579846
Sample Time (s)              7.347154021263123
Epoch Time (s)               237.4868901092559
Total Train Time (s)         41778.70514441747
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:13:01.740772 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #181 | Epoch Duration: 237.57777214050293
2020-01-13 11:13:01.740952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3246136
Z variance train             0.028941948
KL Divergence                41.14902
KL Loss                      4.114902
QF Loss                      71.63379
VF Loss                      63.279808
Policy Loss                  -874.465
Q Predictions Mean           869.8053
Q Predictions Std            909.2192
Q Predictions Max            3810.5908
Q Predictions Min            479.2965
V Predictions Mean           874.1233
V Predictions Std            906.6177
V Predictions Max            3796.4966
V Predictions Min            488.32666
Log Pis Mean                 -0.9630003
Log Pis Std                  3.1055448
Log Pis Max                  14.797337
Log Pis Min                  -8.5580225
Policy mu Mean               -0.0053083613
Policy mu Std                0.7979719
Policy mu Max                3.8892438
Policy mu Min                -3.238409
Policy log std Mean          -0.4941754
Policy log std Std           0.27337456
Policy log std Max           -0.07473646
Policy log std Min           -3.0326204
Z mean eval                  2.3618453
Z variance eval              0.028526064
total_rewards                [9155.51543516 9243.65516278 9096.0662158  9142.83527011 8789.66963443
 9393.02818195 9211.53807395 9313.63304777 9232.77407008 9347.72467988]
total_rewards_mean           9192.643977190863
total_rewards_std            160.93066277757248
total_rewards_max            9393.028181954636
total_rewards_min            8789.669634430637
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               195.55711871990934
(Previous) Eval Time (s)     31.17698450991884
Sample Time (s)              7.028492461424321
Epoch Time (s)               233.7625956912525
Total Train Time (s)         42012.55557222292
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:16:55.591594 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #182 | Epoch Duration: 233.85049962997437
2020-01-13 11:16:55.591777 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3612041
Z variance train             0.028543513
KL Divergence                42.02036
KL Loss                      4.202036
QF Loss                      114.85153
VF Loss                      62.616753
Policy Loss                  -1009.4642
Q Predictions Mean           1007.29834
Q Predictions Std            1040.5133
Q Predictions Max            3968.747
Q Predictions Min            522.11786
V Predictions Mean           1004.16797
V Predictions Std            1039.2086
V Predictions Max            3939.5686
V Predictions Min            530.3583
Log Pis Mean                 -0.4399762
Log Pis Std                  3.412522
Log Pis Max                  14.102625
Log Pis Min                  -6.460994
Policy mu Mean               -0.021317622
Policy mu Std                0.8617114
Policy mu Max                3.0762935
Policy mu Min                -2.8615162
Policy log std Mean          -0.4897578
Policy log std Std           0.24148908
Policy log std Max           -0.05374056
Policy log std Min           -2.6651566
Z mean eval                  2.3313406
Z variance eval              0.03575007
total_rewards                [9394.17973594 9117.50228394 9160.541132   9331.01140419 9060.23537465
 9197.59125649 9028.54341647 9085.80917295 9124.54359397 9376.73250218]
total_rewards_mean           9187.668987277002
total_rewards_std            126.73476186379303
total_rewards_max            9394.179735935013
total_rewards_min            9028.543416470686
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               196.28275192994624
(Previous) Eval Time (s)     32.723115116823465
Sample Time (s)              6.626898911315948
Epoch Time (s)               235.63276595808566
Total Train Time (s)         42248.29936787393
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:51.336744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #183 | Epoch Duration: 235.74483060836792
2020-01-13 11:20:51.336892 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3322492
Z variance train             0.035630114
KL Divergence                41.76643
KL Loss                      4.176643
QF Loss                      269.70367
VF Loss                      96.57024
Policy Loss                  -1189.5696
Q Predictions Mean           1182.8826
Q Predictions Std            1220.2384
Q Predictions Max            3993.1895
Q Predictions Min            503.40826
V Predictions Mean           1184.577
V Predictions Std            1215.7865
V Predictions Max            3958.8838
V Predictions Min            504.36282
Log Pis Mean                 0.06853464
Log Pis Std                  3.997225
Log Pis Max                  17.068802
Log Pis Min                  -6.175335
Policy mu Mean               0.037234515
Policy mu Std                0.9275935
Policy mu Max                3.2156656
Policy mu Min                -3.1284397
Policy log std Mean          -0.528178
Policy log std Std           0.3041473
Policy log std Max           -0.11875394
Policy log std Min           -2.8539553
Z mean eval                  2.3544145
Z variance eval              0.05076114
total_rewards                [9519.55200878 9588.11546725 9245.14298724 9546.79803891 9581.26847582
 9554.62852686 9397.66427958 9548.45585438 9620.7184494  9499.7112934 ]
total_rewards_mean           9510.205538163644
total_rewards_std            105.46548151362869
total_rewards_max            9620.71844940435
total_rewards_min            9245.142987238853
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               196.1926587941125
(Previous) Eval Time (s)     30.643963272683322
Sample Time (s)              7.951398191973567
Epoch Time (s)               234.7880202587694
Total Train Time (s)         42483.1818630551
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:46.225154 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #184 | Epoch Duration: 234.8881323337555
2020-01-13 11:24:46.225361 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.352823
Z variance train             0.050807774
KL Divergence                41.359863
KL Loss                      4.1359863
QF Loss                      2440.667
VF Loss                      44.275246
Policy Loss                  -1009.2772
Q Predictions Mean           1011.0812
Q Predictions Std            1059.8021
Q Predictions Max            3901.2322
Q Predictions Min            518.06036
V Predictions Mean           1010.7401
V Predictions Std            1055.8822
V Predictions Max            3889.5964
V Predictions Min            515.98224
Log Pis Mean                 -0.6152626
Log Pis Std                  3.3431647
Log Pis Max                  11.686294
Log Pis Min                  -6.991334
Policy mu Mean               0.09035567
Policy mu Std                0.8369027
Policy mu Max                2.5932798
Policy mu Min                -2.4114063
Policy log std Mean          -0.49345264
Policy log std Std           0.26267377
Policy log std Max           -0.051678658
Policy log std Min           -2.5566027
Z mean eval                  2.3417907
Z variance eval              0.059282504
total_rewards                [9409.54030483 9264.21900849 9089.22118808 9481.01094429 9574.91658995
 9332.09556092 9245.62334394 9363.32538991 9525.85656746 9572.78526281]
total_rewards_mean           9385.859416068803
total_rewards_std            150.250725400147
total_rewards_max            9574.916589949018
total_rewards_min            9089.221188080159
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               196.36968523124233
(Previous) Eval Time (s)     32.48384229000658
Sample Time (s)              7.58120169211179
Epoch Time (s)               236.4347292133607
Total Train Time (s)         42719.69983329112
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:42.744652 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #185 | Epoch Duration: 236.51913595199585
2020-01-13 11:28:42.744841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3403482
Z variance train             0.059325766
KL Divergence                40.58191
KL Loss                      4.058191
QF Loss                      212.2445
VF Loss                      69.50513
Policy Loss                  -1047.3875
Q Predictions Mean           1044.5897
Q Predictions Std            1097.2023
Q Predictions Max            4079.0474
Q Predictions Min            506.7822
V Predictions Mean           1052.5375
V Predictions Std            1098.2747
V Predictions Max            4076.4248
V Predictions Min            517.3215
Log Pis Mean                 -0.5186356
Log Pis Std                  3.6294613
Log Pis Max                  14.2994995
Log Pis Min                  -6.149392
Policy mu Mean               0.0019906356
Policy mu Std                0.86247426
Policy mu Max                3.049921
Policy mu Min                -2.9593554
Policy log std Mean          -0.4885924
Policy log std Std           0.2699246
Policy log std Max           -0.058009505
Policy log std Min           -2.561809
Z mean eval                  2.3681004
Z variance eval              0.058739044
total_rewards                [8641.97764157 8223.97308728 8280.83888131 8812.62340745 8805.75153039
 7992.44376026 8279.17262205 8237.59997697 8228.15378803 8413.62552442]
total_rewards_mean           8391.616021971717
total_rewards_std            259.75361054639797
total_rewards_max            8812.623407446341
total_rewards_min            7992.443760258882
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               195.6841295468621
(Previous) Eval Time (s)     32.90039739198983
Sample Time (s)              6.855395201127976
Epoch Time (s)               235.4399221399799
Total Train Time (s)         42955.22168440092
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:32:38.269515 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #186 | Epoch Duration: 235.52453637123108
2020-01-13 11:32:38.269683 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.368241
Z variance train             0.058682095
KL Divergence                40.663834
KL Loss                      4.0663834
QF Loss                      190.59494
VF Loss                      44.907013
Policy Loss                  -1153.7201
Q Predictions Mean           1150.4088
Q Predictions Std            1179.792
Q Predictions Max            3973.588
Q Predictions Min            509.30795
V Predictions Mean           1155.9043
V Predictions Std            1180.5265
V Predictions Max            3983.7434
V Predictions Min            516.30676
Log Pis Mean                 -0.35869968
Log Pis Std                  3.4656475
Log Pis Max                  11.154762
Log Pis Min                  -5.5102153
Policy mu Mean               0.05528908
Policy mu Std                0.87815785
Policy mu Max                3.1176233
Policy mu Min                -2.5381432
Policy log std Mean          -0.51153344
Policy log std Std           0.27603218
Policy log std Max           -0.014272153
Policy log std Min           -2.6316347
Z mean eval                  2.3657556
Z variance eval              0.064892136
total_rewards                [8608.91448419 8773.62010486 8853.34900773 8819.47272818 8724.94235992
 9083.5796749  8752.45984179 9061.07821103 8618.69820707 8327.57784595]
total_rewards_mean           8762.369246559641
total_rewards_std            209.47557207639295
total_rewards_max            9083.57967489664
total_rewards_min            8327.577845946158
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               195.31667242618278
(Previous) Eval Time (s)     31.206304964609444
Sample Time (s)              6.666143889538944
Epoch Time (s)               233.18912128033116
Total Train Time (s)         43188.49111136794
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:31.540639 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #187 | Epoch Duration: 233.27081990242004
2020-01-13 11:36:31.540804 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #187 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3655837
Z variance train             0.06489935
KL Divergence                40.682476
KL Loss                      4.068248
QF Loss                      143.45584
VF Loss                      74.50597
Policy Loss                  -1150.0604
Q Predictions Mean           1146.8062
Q Predictions Std            1203.0219
Q Predictions Max            4141.8647
Q Predictions Min            514.64764
V Predictions Mean           1151.4204
V Predictions Std            1206.2262
V Predictions Max            4147.5786
V Predictions Min            524.29535
Log Pis Mean                 -0.17327344
Log Pis Std                  3.7422612
Log Pis Max                  13.66614
Log Pis Min                  -9.269585
Policy mu Mean               0.059938192
Policy mu Std                0.8943024
Policy mu Max                2.7013958
Policy mu Min                -2.5142655
Policy log std Mean          -0.5105701
Policy log std Std           0.26624337
Policy log std Max           -0.14720133
Policy log std Min           -2.4341984
Z mean eval                  2.403944
Z variance eval              0.05675576
total_rewards                [8825.09249369 9375.83154944 9232.6841775  9278.49532385 9092.18995
 9572.37030468 9255.93111417 9669.36504722 9817.37245788 9456.33281909]
total_rewards_mean           9357.566523751218
total_rewards_std            274.04375617358335
total_rewards_max            9817.372457882091
total_rewards_min            8825.092493694128
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               196.49476894922554
(Previous) Eval Time (s)     34.24799347203225
Sample Time (s)              7.020607649348676
Epoch Time (s)               237.76337007060647
Total Train Time (s)         43426.338152546436
Epoch                        188
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:40:29.389870 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #188 | Epoch Duration: 237.84893107414246
2020-01-13 11:40:29.390041 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4021149
Z variance train             0.056984086
KL Divergence                41.93605
KL Loss                      4.193605
QF Loss                      127.29078
VF Loss                      75.160034
Policy Loss                  -1132.3429
Q Predictions Mean           1133.2374
Q Predictions Std            1176.9775
Q Predictions Max            4101.3228
Q Predictions Min            528.1935
V Predictions Mean           1138.9001
V Predictions Std            1177.3298
V Predictions Max            4086.3323
V Predictions Min            535.1124
Log Pis Mean                 -0.5810492
Log Pis Std                  3.776583
Log Pis Max                  16.62828
Log Pis Min                  -6.7842464
Policy mu Mean               0.014035188
Policy mu Std                0.8464262
Policy mu Max                3.0436695
Policy mu Min                -2.8239121
Policy log std Mean          -0.50852287
Policy log std Std           0.26015088
Policy log std Max           -0.10715349
Policy log std Min           -2.6100898
Z mean eval                  2.383393
Z variance eval              0.034094267
total_rewards                [9522.39834249 9180.69086288 9418.73406872 9082.21109948 9181.84042333
 9055.38668768 9441.92806359 9437.186917   9492.32699168 9295.44573172]
total_rewards_mean           9310.814918854496
total_rewards_std            165.47732447431275
total_rewards_max            9522.398342491764
total_rewards_min            9055.386687677477
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               196.49217834230512
(Previous) Eval Time (s)     35.89029821520671
Sample Time (s)              7.03850485291332
Epoch Time (s)               239.42098141042516
Total Train Time (s)         43665.84477289766
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:44:28.901949 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #189 | Epoch Duration: 239.51172804832458
2020-01-13 11:44:28.902300 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806307
Z variance train             0.03416244
KL Divergence                42.82197
KL Loss                      4.2821975
QF Loss                      95.20988
VF Loss                      67.0311
Policy Loss                  -1208.1188
Q Predictions Mean           1207.3545
Q Predictions Std            1220.9912
Q Predictions Max            4098.0083
Q Predictions Min            512.36316
V Predictions Mean           1213.7397
V Predictions Std            1222.4268
V Predictions Max            4090.5256
V Predictions Min            523.05054
Log Pis Mean                 -0.05549048
Log Pis Std                  3.4807446
Log Pis Max                  12.342579
Log Pis Min                  -5.7298465
Policy mu Mean               0.0109849945
Policy mu Std                0.88339883
Policy mu Max                2.5949845
Policy mu Min                -2.569033
Policy log std Mean          -0.51387537
Policy log std Std           0.28160575
Policy log std Max           -0.07037632
Policy log std Min           -2.6221852
Z mean eval                  2.3746004
Z variance eval              0.061400145
total_rewards                [9439.52122128 9211.88150825 9428.51877392 9489.53696574 9678.67408414
 9498.49316425 9260.90819745 9426.27312434 9413.65388503 9465.62201485]
total_rewards_mean           9431.30829392534
total_rewards_std            121.6010783125786
total_rewards_max            9678.674084139971
total_rewards_min            9211.88150825419
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               196.51231682812795
(Previous) Eval Time (s)     35.08706777309999
Sample Time (s)              6.799885699991137
Epoch Time (s)               238.39927030121908
Total Train Time (s)         43904.3501604842
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:27.410968 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #190 | Epoch Duration: 238.5084047317505
2020-01-13 11:48:27.411190 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3735797
Z variance train             0.0613536
KL Divergence                42.327995
KL Loss                      4.2327995
QF Loss                      247.96207
VF Loss                      148.09006
Policy Loss                  -948.4408
Q Predictions Mean           943.31946
Q Predictions Std            957.2378
Q Predictions Max            4067.2493
Q Predictions Min            519.8059
V Predictions Mean           943.7511
V Predictions Std            954.2044
V Predictions Max            4052.9675
V Predictions Min            520.1062
Log Pis Mean                 -0.5248268
Log Pis Std                  3.212253
Log Pis Max                  12.227437
Log Pis Min                  -6.6149225
Policy mu Mean               0.030492345
Policy mu Std                0.828775
Policy mu Max                2.6929328
Policy mu Min                -2.7062078
Policy log std Mean          -0.48141864
Policy log std Std           0.2355231
Policy log std Max           -0.021471798
Policy log std Min           -2.5915623
Z mean eval                  2.3655086
Z variance eval              0.0396479
total_rewards                [9379.35399583 9509.06749338 9363.65614737 9403.50221162 9134.43325854
 9313.81904779 9379.98849172 9249.03615765 9304.35759035 9177.39647545]
total_rewards_mean           9321.461086969468
total_rewards_std            105.74247048054073
total_rewards_max            9509.067493382143
total_rewards_min            9134.433258537132
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               198.39122917223722
(Previous) Eval Time (s)     30.907971957232803
Sample Time (s)              7.8516645627096295
Epoch Time (s)               237.15086569217965
Total Train Time (s)         44141.584272291046
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:24.647729 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #191 | Epoch Duration: 237.23637199401855
2020-01-13 11:52:24.647904 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3663304
Z variance train             0.039501093
KL Divergence                41.60468
KL Loss                      4.160468
QF Loss                      183.04074
VF Loss                      60.635937
Policy Loss                  -1164.5304
Q Predictions Mean           1162.7112
Q Predictions Std            1182.4387
Q Predictions Max            4242.846
Q Predictions Min            524.5032
V Predictions Mean           1163.2654
V Predictions Std            1181.4783
V Predictions Max            4213.47
V Predictions Min            519.67084
Log Pis Mean                 -0.13029796
Log Pis Std                  3.9726293
Log Pis Max                  16.392315
Log Pis Min                  -7.7797613
Policy mu Mean               0.06907829
Policy mu Std                0.8970711
Policy mu Max                2.7503388
Policy mu Min                -3.0247083
Policy log std Mean          -0.5118243
Policy log std Std           0.25575176
Policy log std Max           -0.050135136
Policy log std Min           -2.2679605
Z mean eval                  2.31978
Z variance eval              0.046694063
total_rewards                [9723.35157121 9464.54568484 9179.19904087 9274.34741344 9394.5188801
 9483.07488088 9232.15406019 9089.78336122 9530.26888969 9153.4628238 ]
total_rewards_mean           9352.470660624713
total_rewards_std            189.6740105941735
total_rewards_max            9723.351571211482
total_rewards_min            9089.783361218551
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               194.37319021625444
(Previous) Eval Time (s)     33.92444388009608
Sample Time (s)              6.665647005662322
Epoch Time (s)               234.96328110201284
Total Train Time (s)         44376.637189983856
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:56:19.704172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #192 | Epoch Duration: 235.05610370635986
2020-01-13 11:56:19.704358 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.323752
Z variance train             0.046862043
KL Divergence                41.372643
KL Loss                      4.1372643
QF Loss                      2606.4204
VF Loss                      47.99762
Policy Loss                  -1143.5713
Q Predictions Mean           1139.6772
Q Predictions Std            1144.1174
Q Predictions Max            4012.3901
Q Predictions Min            518.0958
V Predictions Mean           1140.8711
V Predictions Std            1141.3381
V Predictions Max            4000.1277
V Predictions Min            517.609
Log Pis Mean                 -0.40321684
Log Pis Std                  3.683666
Log Pis Max                  13.900585
Log Pis Min                  -6.409444
Policy mu Mean               0.025048673
Policy mu Std                0.86395013
Policy mu Max                2.6797197
Policy mu Min                -2.631922
Policy log std Mean          -0.5105376
Policy log std Std           0.25888392
Policy log std Max           -0.10524064
Policy log std Min           -2.4018798
Z mean eval                  2.3446803
Z variance eval              0.051783077
total_rewards                [8318.57379554 8330.14233396 8617.11502043 8063.27371921 8950.02644477
 8864.26356427 8939.36163131 8844.17930335 8703.6936182  8098.69153084]
total_rewards_mean           8572.932096187556
total_rewards_std            325.92504028734635
total_rewards_max            8950.026444771021
total_rewards_min            8063.273719207273
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               197.80285135889426
(Previous) Eval Time (s)     34.07929621404037
Sample Time (s)              6.807236083317548
Epoch Time (s)               238.68938365625218
Total Train Time (s)         44615.442579227965
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:00:18.510289 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #193 | Epoch Duration: 238.80579733848572
2020-01-13 12:00:18.510430 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3440099
Z variance train             0.051768295
KL Divergence                41.746796
KL Loss                      4.1746798
QF Loss                      198.04553
VF Loss                      45.106827
Policy Loss                  -1039.8092
Q Predictions Mean           1038.3015
Q Predictions Std            1102.3195
Q Predictions Max            4068.1045
Q Predictions Min            506.17493
V Predictions Mean           1039.0161
V Predictions Std            1098.2311
V Predictions Max            4033.156
V Predictions Min            511.04205
Log Pis Mean                 -0.2777874
Log Pis Std                  3.62537
Log Pis Max                  21.35176
Log Pis Min                  -5.839252
Policy mu Mean               0.048130456
Policy mu Std                0.8771811
Policy mu Max                4.47602
Policy mu Min                -2.9126084
Policy log std Mean          -0.4951525
Policy log std Std           0.26146787
Policy log std Max           -0.030338228
Policy log std Min           -2.7699327
Z mean eval                  2.3307354
Z variance eval              0.04095624
total_rewards                [9260.88413021 9444.82202124 9127.22016762 9416.77552774 9638.64787412
 9436.03558632 9302.46209823 9283.25160639 9355.89766449 9358.35242118]
total_rewards_mean           9362.434909753429
total_rewards_std            129.23462069504643
total_rewards_max            9638.647874117578
total_rewards_min            9127.220167622501
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               196.59347250591964
(Previous) Eval Time (s)     31.814988404046744
Sample Time (s)              7.19865071401
Epoch Time (s)               235.60711162397638
Total Train Time (s)         44851.313944912516
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:14.393522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #194 | Epoch Duration: 235.88295078277588
2020-01-13 12:04:14.393800 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3306785
Z variance train             0.04094363
KL Divergence                42.164967
KL Loss                      4.216497
QF Loss                      2891.1646
VF Loss                      69.402596
Policy Loss                  -1230.9479
Q Predictions Mean           1227.5845
Q Predictions Std            1234.8037
Q Predictions Max            4067.6313
Q Predictions Min            523.77747
V Predictions Mean           1235.5273
V Predictions Std            1237.1929
V Predictions Max            4066.2307
V Predictions Min            528.8043
Log Pis Mean                 -0.11903061
Log Pis Std                  3.6373668
Log Pis Max                  12.905974
Log Pis Min                  -8.496889
Policy mu Mean               0.01776875
Policy mu Std                0.91985446
Policy mu Max                2.8299332
Policy mu Min                -3.1149204
Policy log std Mean          -0.5204403
Policy log std Std           0.2591991
Policy log std Max           -0.101044
Policy log std Min           -2.3140025
Z mean eval                  2.3778
Z variance eval              0.06607994
total_rewards                [9243.59578202 9543.0157531  9546.95913314 9469.69333044 9409.19104447
 9181.07232471 9293.15777133 9262.70433107 9267.13064387 9181.6501834 ]
total_rewards_mean           9339.817029755714
total_rewards_std            133.70119899825048
total_rewards_max            9546.959133142864
total_rewards_min            9181.072324710056
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               194.5609214757569
(Previous) Eval Time (s)     31.28904126631096
Sample Time (s)              6.917036384809762
Epoch Time (s)               232.76699912687764
Total Train Time (s)         45084.16868727794
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:08:07.244913 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #195 | Epoch Duration: 232.85090613365173
2020-01-13 12:08:07.245096 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3773086
Z variance train             0.06601741
KL Divergence                42.68558
KL Loss                      4.268558
QF Loss                      427.13757
VF Loss                      48.18004
Policy Loss                  -1175.6017
Q Predictions Mean           1176.1062
Q Predictions Std            1215.801
Q Predictions Max            4140.253
Q Predictions Min            525.3767
V Predictions Mean           1175.884
V Predictions Std            1211.0388
V Predictions Max            4124.9233
V Predictions Min            535.14496
Log Pis Mean                 -0.015427515
Log Pis Std                  3.8675008
Log Pis Max                  13.68766
Log Pis Min                  -7.0998864
Policy mu Mean               0.06713538
Policy mu Std                0.9104153
Policy mu Max                3.3421152
Policy mu Min                -2.9468482
Policy log std Mean          -0.51575315
Policy log std Std           0.28048518
Policy log std Max           -0.10811339
Policy log std Min           -2.8144975
Z mean eval                  2.3425498
Z variance eval              0.058491837
total_rewards                [9744.58885411 9491.55112089 9744.6710699  9674.12409871 9749.75601227
 9674.27143306 9654.78778833 9412.69224071 9664.17903892 9808.71546977]
total_rewards_mean           9661.93371266701
total_rewards_std            115.94975322115575
total_rewards_max            9808.715469767862
total_rewards_min            9412.692240710805
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               193.10018029995263
(Previous) Eval Time (s)     29.85309000732377
Sample Time (s)              6.968828381970525
Epoch Time (s)               229.92209868924692
Total Train Time (s)         45314.17858810723
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:57.260982 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #196 | Epoch Duration: 230.01570796966553
2020-01-13 12:11:57.261305 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.342463
Z variance train             0.05842524
KL Divergence                42.941734
KL Loss                      4.2941737
QF Loss                      89.30239
VF Loss                      77.76656
Policy Loss                  -1050.7592
Q Predictions Mean           1047.3887
Q Predictions Std            1077.9612
Q Predictions Max            4081.5376
Q Predictions Min            521.30426
V Predictions Mean           1053.8513
V Predictions Std            1078.4175
V Predictions Max            4093.4072
V Predictions Min            533.8463
Log Pis Mean                 -0.49942574
Log Pis Std                  3.5579367
Log Pis Max                  26.497742
Log Pis Min                  -7.2952886
Policy mu Mean               0.04477528
Policy mu Std                0.8501153
Policy mu Max                4.7743626
Policy mu Min                -2.6151242
Policy log std Mean          -0.50182885
Policy log std Std           0.26258832
Policy log std Max           -0.052553833
Policy log std Min           -2.682726
Z mean eval                  2.3578386
Z variance eval              0.06740702
total_rewards                [8960.63726275 9195.11799587 9051.67934499 9262.85930864 9131.2323432
 8940.59352675 9047.55952075 9165.63972245 8996.99504584 9369.72542158]
total_rewards_mean           9112.203949281866
total_rewards_std            131.39420292937777
total_rewards_max            9369.72542157922
total_rewards_min            8940.593526746026
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               197.21336832083762
(Previous) Eval Time (s)     33.38288265187293
Sample Time (s)              6.3826864953152835
Epoch Time (s)               236.97893746802583
Total Train Time (s)         45551.31993742753
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:15:54.402952 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #197 | Epoch Duration: 237.14141082763672
2020-01-13 12:15:54.403128 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3561606
Z variance train             0.06745019
KL Divergence                42.83439
KL Loss                      4.283439
QF Loss                      3004.911
VF Loss                      121.367424
Policy Loss                  -974.5796
Q Predictions Mean           974.45483
Q Predictions Std            993.6393
Q Predictions Max            4133.8936
Q Predictions Min            527.46716
V Predictions Mean           982.63074
V Predictions Std            996.52856
V Predictions Max            4154.0684
V Predictions Min            526.1649
Log Pis Mean                 -0.7791941
Log Pis Std                  3.4416518
Log Pis Max                  15.468447
Log Pis Min                  -6.750371
Policy mu Mean               0.050475344
Policy mu Std                0.8262003
Policy mu Max                3.4859524
Policy mu Min                -3.0873773
Policy log std Mean          -0.49005976
Policy log std Std           0.25973716
Policy log std Max           -0.10392845
Policy log std Min           -2.7497165
Z mean eval                  2.359917
Z variance eval              0.074436374
total_rewards                [9376.68036745 9540.71912991 9598.76299854 9623.17153312 9784.27049326
 9241.64678018 9681.87847109 9503.70715301 9541.60549905 9294.77346572]
total_rewards_mean           9518.721589133096
total_rewards_std            162.10636182902937
total_rewards_max            9784.270493259515
total_rewards_min            9241.646780175422
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               196.06266003660858
(Previous) Eval Time (s)     31.206191719044
Sample Time (s)              5.953605487477034
Epoch Time (s)               233.2224572431296
Total Train Time (s)         45784.63198094675
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:19:47.718500 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #198 | Epoch Duration: 233.31522727012634
2020-01-13 12:19:47.718677 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3608952
Z variance train             0.07499403
KL Divergence                42.829437
KL Loss                      4.2829437
QF Loss                      248.21564
VF Loss                      73.278946
Policy Loss                  -1206.0967
Q Predictions Mean           1201.0846
Q Predictions Std            1240.6113
Q Predictions Max            4189.821
Q Predictions Min            518.2576
V Predictions Mean           1210.6196
V Predictions Std            1241.4244
V Predictions Max            4200.8374
V Predictions Min            525.9913
Log Pis Mean                 0.010441929
Log Pis Std                  3.9679022
Log Pis Max                  15.274396
Log Pis Min                  -5.9215465
Policy mu Mean               0.009853925
Policy mu Std                0.90550137
Policy mu Max                2.7352605
Policy mu Min                -2.673469
Policy log std Mean          -0.5011136
Policy log std Std           0.27851906
Policy log std Max           0.06579995
Policy log std Min           -2.8025823
Z mean eval                  2.3811822
Z variance eval              0.08804292
total_rewards                [9521.65487917 9683.31003929 9685.54170128 9662.06301329 9712.18984479
 9497.41767186 9692.4802086  9623.51735924 9546.03879664 9608.33629802]
total_rewards_mean           9623.254981219981
total_rewards_std            73.50947910673543
total_rewards_max            9712.189844788909
total_rewards_min            9497.417671864216
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               197.4615757302381
(Previous) Eval Time (s)     30.607211170252413
Sample Time (s)              7.239091456402093
Epoch Time (s)               235.30787835689262
Total Train Time (s)         46020.05770620238
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:23:43.145699 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #199 | Epoch Duration: 235.42687511444092
2020-01-13 12:23:43.145906 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3807902
Z variance train             0.08830996
KL Divergence                43.05302
KL Loss                      4.305302
QF Loss                      264.41217
VF Loss                      194.33864
Policy Loss                  -1254.873
Q Predictions Mean           1253.1
Q Predictions Std            1259.63
Q Predictions Max            4265.4287
Q Predictions Min            532.48773
V Predictions Mean           1246.4897
V Predictions Std            1253.9014
V Predictions Max            4257.3477
V Predictions Min            532.7251
Log Pis Mean                 0.38294572
Log Pis Std                  4.069057
Log Pis Max                  14.928526
Log Pis Min                  -7.816333
Policy mu Mean               0.027249439
Policy mu Std                0.94706285
Policy mu Max                3.1481903
Policy mu Min                -3.508844
Policy log std Mean          -0.5366691
Policy log std Std           0.2866643
Policy log std Max           -0.101685256
Policy log std Min           -2.9021246
Z mean eval                  2.3228583
Z variance eval              0.16166346
total_rewards                [8577.22984088 9789.41644989 9694.57864267 9091.73891831 9444.81931506
 9033.07051737 9486.76032223 9477.14878888 9782.50319005 9186.27082598]
total_rewards_mean           9356.353681132154
total_rewards_std            365.165924132182
total_rewards_max            9789.416449885524
total_rewards_min            8577.22984087605
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               195.91828371910378
(Previous) Eval Time (s)     34.17196895740926
Sample Time (s)              10.089390392415226
Epoch Time (s)               240.17964306892827
Total Train Time (s)         46260.34019062994
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:27:43.433722 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #200 | Epoch Duration: 240.2875850200653
2020-01-13 12:27:43.434056 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.321506
Z variance train             0.16204916
KL Divergence                38.851418
KL Loss                      3.8851418
QF Loss                      4908.929
VF Loss                      70.79598
Policy Loss                  -1085.9962
Q Predictions Mean           1082.9573
Q Predictions Std            1146.9974
Q Predictions Max            4133.5156
Q Predictions Min            521.4335
V Predictions Mean           1080.4565
V Predictions Std            1144.0497
V Predictions Max            4118.6826
V Predictions Min            515.7908
Log Pis Mean                 -0.3189606
Log Pis Std                  3.6580966
Log Pis Max                  12.405842
Log Pis Min                  -9.049832
Policy mu Mean               0.07187034
Policy mu Std                0.86424416
Policy mu Max                2.8797224
Policy mu Min                -2.305129
Policy log std Mean          -0.51223063
Policy log std Std           0.2834127
Policy log std Max           -0.08425683
Policy log std Min           -2.5215838
Z mean eval                  2.3460467
Z variance eval              0.09898951
total_rewards                [9852.37559133 9797.42663738 9459.87850058 9775.09706372 9875.05142424
 9649.08718748 9637.61412176 9492.36858538 9741.4495661  9623.17891742]
total_rewards_mean           9690.352759539684
total_rewards_std            135.2534452390618
total_rewards_max            9875.051424241752
total_rewards_min            9459.878500576438
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               197.3692497271113
(Previous) Eval Time (s)     34.56238829297945
Sample Time (s)              7.602177802938968
Epoch Time (s)               239.53381582302973
Total Train Time (s)         46499.96239004657
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:31:43.061668 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #201 | Epoch Duration: 239.62741231918335
2020-01-13 12:31:43.061860 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.344434
Z variance train             0.09871207
KL Divergence                41.1741
KL Loss                      4.11741
QF Loss                      263.70712
VF Loss                      185.08154
Policy Loss                  -1247.8557
Q Predictions Mean           1250.1144
Q Predictions Std            1266.1664
Q Predictions Max            4295.3296
Q Predictions Min            505.00626
V Predictions Mean           1254.6014
V Predictions Std            1271.5872
V Predictions Max            4300.673
V Predictions Min            516.19147
Log Pis Mean                 0.0029628873
Log Pis Std                  3.8740184
Log Pis Max                  13.7572155
Log Pis Min                  -5.932822
Policy mu Mean               0.023885204
Policy mu Std                0.9163347
Policy mu Max                3.119235
Policy mu Min                -2.4227676
Policy log std Mean          -0.51967996
Policy log std Std           0.28210893
Policy log std Max           -0.11449246
Policy log std Min           -2.5953598
Z mean eval                  2.3724658
Z variance eval              0.13387232
total_rewards                [9484.17831889 9706.70848287 9692.56662283 9368.03059982 9776.87958754
 9466.91338115 9592.94322799 9662.42918774 9411.19590081 9947.02973042]
total_rewards_mean           9610.887504007615
total_rewards_std            171.76048054300944
total_rewards_max            9947.029730420178
total_rewards_min            9368.03059981709
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               192.1639361283742
(Previous) Eval Time (s)     33.7557159033604
Sample Time (s)              6.608291095122695
Epoch Time (s)               232.52794312685728
Total Train Time (s)         46732.57894561812
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:35.675925 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #202 | Epoch Duration: 232.6139211654663
2020-01-13 12:35:35.676101 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.370464
Z variance train             0.1342449
KL Divergence                42.19132
KL Loss                      4.219132
QF Loss                      151.89374
VF Loss                      100.13189
Policy Loss                  -1144.8055
Q Predictions Mean           1145.1707
Q Predictions Std            1212.5536
Q Predictions Max            4256.056
Q Predictions Min            523.95404
V Predictions Mean           1152.0527
V Predictions Std            1215.4729
V Predictions Max            4279.5063
V Predictions Min            529.98517
Log Pis Mean                 -0.33459902
Log Pis Std                  3.9139597
Log Pis Max                  17.710548
Log Pis Min                  -8.203734
Policy mu Mean               0.035810098
Policy mu Std                0.878141
Policy mu Max                3.2574751
Policy mu Min                -2.624202
Policy log std Mean          -0.5078617
Policy log std Std           0.29122525
Policy log std Max           -0.10014397
Policy log std Min           -2.7607818
Z mean eval                  2.3814054
Z variance eval              0.09706648
total_rewards                [9511.84313358 9583.70553645 9174.02388929 9668.08083799 9235.65032514
 9516.94153858 9273.13256027 9531.0481112  9330.65633609 9621.14142695]
total_rewards_mean           9444.622369553394
total_rewards_std            166.41657325554146
total_rewards_max            9668.080837993675
total_rewards_min            9174.023889289241
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               196.50879424065351
(Previous) Eval Time (s)     28.461804450955242
Sample Time (s)              6.573631635867059
Epoch Time (s)               231.54423032747582
Total Train Time (s)         46964.20503364643
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:39:27.304295 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #203 | Epoch Duration: 231.62804579734802
2020-01-13 12:39:27.304495 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3764434
Z variance train             0.097459264
KL Divergence                41.640457
KL Loss                      4.164046
QF Loss                      105.27887
VF Loss                      152.69402
Policy Loss                  -1197.4595
Q Predictions Mean           1202.5785
Q Predictions Std            1234.8566
Q Predictions Max            4262.131
Q Predictions Min            531.1196
V Predictions Mean           1205.2148
V Predictions Std            1237.2225
V Predictions Max            4290.79
V Predictions Min            530.5142
Log Pis Mean                 0.09714187
Log Pis Std                  3.8213356
Log Pis Max                  11.91896
Log Pis Min                  -7.710458
Policy mu Mean               0.014900376
Policy mu Std                0.9217618
Policy mu Max                2.557114
Policy mu Min                -2.670986
Policy log std Mean          -0.5070312
Policy log std Std           0.26746172
Policy log std Max           -0.10490677
Policy log std Min           -2.7920926
Z mean eval                  2.3931854
Z variance eval              0.10536343
total_rewards                [9278.28738483 9656.46691868 9576.40933606 9382.15801957 9505.75962173
 9511.82796393 9466.80564605 9362.00066755 9515.8667374  9543.56669203]
total_rewards_mean           9479.914898783813
total_rewards_std            105.73455032197975
total_rewards_max            9656.466918678572
total_rewards_min            9278.287384833835
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               196.86867831088603
(Previous) Eval Time (s)     31.611285253893584
Sample Time (s)              7.2026204145513475
Epoch Time (s)               235.68258397933096
Total Train Time (s)         47199.984645104036
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:43:23.086189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #204 | Epoch Duration: 235.7815399169922
2020-01-13 12:43:23.086388 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3929048
Z variance train             0.1061305
KL Divergence                41.070393
KL Loss                      4.1070395
QF Loss                      139.95537
VF Loss                      69.77413
Policy Loss                  -1222.0981
Q Predictions Mean           1216.5239
Q Predictions Std            1237.5746
Q Predictions Max            4309.7803
Q Predictions Min            537.3694
V Predictions Mean           1220.9397
V Predictions Std            1238.6174
V Predictions Max            4299.5674
V Predictions Min            539.12213
Log Pis Mean                 0.10863441
Log Pis Std                  3.8629417
Log Pis Max                  14.837879
Log Pis Min                  -7.739481
Policy mu Mean               -0.009355065
Policy mu Std                0.92675716
Policy mu Max                2.6749964
Policy mu Min                -2.41089
Policy log std Mean          -0.51674473
Policy log std Std           0.28248426
Policy log std Max           -0.048550636
Policy log std Min           -2.6347017
Z mean eval                  2.3911452
Z variance eval              0.08869241
total_rewards                [9363.49686813 9466.44789852 9520.01520651 9510.15107593 9640.61285866
 9469.89569425 9486.77732338 9452.99769112 9592.85588119 9717.3757073 ]
total_rewards_mean           9522.06262049953
total_rewards_std            97.12446827883258
total_rewards_max            9717.375707300514
total_rewards_min            9363.496868131037
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               197.130171273835
(Previous) Eval Time (s)     31.13417045492679
Sample Time (s)              7.088534634560347
Epoch Time (s)               235.35287636332214
Total Train Time (s)         47435.42585941078
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:18.531059 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #205 | Epoch Duration: 235.44451451301575
2020-01-13 12:47:18.531273 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #205 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3969886
Z variance train             0.08813298
KL Divergence                41.40408
KL Loss                      4.140408
QF Loss                      176.24568
VF Loss                      202.77347
Policy Loss                  -1128.4076
Q Predictions Mean           1123.0745
Q Predictions Std            1176.9501
Q Predictions Max            4269.321
Q Predictions Min            529.9783
V Predictions Mean           1116.6274
V Predictions Std            1170.5452
V Predictions Max            4249.967
V Predictions Min            529.1355
Log Pis Mean                 -0.5299915
Log Pis Std                  3.4515479
Log Pis Max                  14.265929
Log Pis Min                  -6.1686096
Policy mu Mean               0.0515424
Policy mu Std                0.8590332
Policy mu Max                2.7504187
Policy mu Min                -2.7396379
Policy log std Mean          -0.4969274
Policy log std Std           0.25773427
Policy log std Max           -0.095601305
Policy log std Min           -2.5379524
Z mean eval                  2.361887
Z variance eval              0.08234035
total_rewards                [ 9952.5918113   9855.41539697  9833.62571865  9894.26689376
 10094.2702043   9605.47789702 10020.82731197  9884.26951797
  9809.06020761  9719.61298705]
total_rewards_mean           9866.941794659342
total_rewards_std            133.56797477464005
total_rewards_max            10094.270204297018
total_rewards_min            9605.47789702461
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               192.5060055698268
(Previous) Eval Time (s)     33.71947978390381
Sample Time (s)              8.110527695156634
Epoch Time (s)               234.33601304888725
Total Train Time (s)         47669.892360715196
Epoch                        206
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:51:13.000401 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #206 | Epoch Duration: 234.46896815299988
2020-01-13 12:51:13.000581 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3637958
Z variance train             0.08244461
KL Divergence                41.42488
KL Loss                      4.142488
QF Loss                      248.23485
VF Loss                      39.415264
Policy Loss                  -1008.6428
Q Predictions Mean           1006.0989
Q Predictions Std            1057.5309
Q Predictions Max            4300.7637
Q Predictions Min            540.99854
V Predictions Mean           1007.2248
V Predictions Std            1055.6859
V Predictions Max            4281.6377
V Predictions Min            551.0641
Log Pis Mean                 -0.65624255
Log Pis Std                  3.1645947
Log Pis Max                  12.036101
Log Pis Min                  -7.3222923
Policy mu Mean               -0.011202439
Policy mu Std                0.82209045
Policy mu Max                2.7993393
Policy mu Min                -2.4523249
Policy log std Mean          -0.51570874
Policy log std Std           0.25484607
Policy log std Max           -0.10310304
Policy log std Min           -2.7425895
Z mean eval                  2.365963
Z variance eval              0.06243979
total_rewards                [ 9677.41492663  9409.77430963  9642.62856649  9544.06455915
  9666.17679656 10029.10700514  9697.36803721  9837.88270014
  9583.18091331  9494.80574767]
total_rewards_mean           9658.240356193932
total_rewards_std            167.07336048293365
total_rewards_max            10029.107005142256
total_rewards_min            9409.774309634622
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               194.18150487029925
(Previous) Eval Time (s)     34.20940967602655
Sample Time (s)              7.630823771469295
Epoch Time (s)               236.0217383177951
Total Train Time (s)         47905.992961213924
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:09.103635 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #207 | Epoch Duration: 236.1029074192047
2020-01-13 12:55:09.103841 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.364978
Z variance train             0.06237177
KL Divergence                41.1943
KL Loss                      4.11943
QF Loss                      189.15195
VF Loss                      107.25026
Policy Loss                  -1060.0845
Q Predictions Mean           1059.1289
Q Predictions Std            1111.4215
Q Predictions Max            4221.361
Q Predictions Min            527.388
V Predictions Mean           1065.988
V Predictions Std            1112.4993
V Predictions Max            4248.939
V Predictions Min            540.2156
Log Pis Mean                 -0.11394047
Log Pis Std                  3.7959068
Log Pis Max                  18.111189
Log Pis Min                  -5.792542
Policy mu Mean               0.014688738
Policy mu Std                0.88799703
Policy mu Max                2.863607
Policy mu Min                -3.1002705
Policy log std Mean          -0.5044163
Policy log std Std           0.2562308
Policy log std Max           0.2617241
Policy log std Min           -2.2731295
Z mean eval                  2.3815465
Z variance eval              0.086417384
total_rewards                [9666.37126526 9965.44572734 9910.41229108 9844.54429946 9938.73516508
 9776.06579738 9768.85070058 9831.90882407 9902.3056304  9861.60826367]
total_rewards_mean           9846.624796430591
total_rewards_std            85.86969419745047
total_rewards_max            9965.445727342514
total_rewards_min            9666.371265256406
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               193.33769765123725
(Previous) Eval Time (s)     36.57446942618117
Sample Time (s)              6.347179894335568
Epoch Time (s)               236.25934697175398
Total Train Time (s)         48142.342309506144
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:59:05.454254 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #208 | Epoch Duration: 236.3502733707428
2020-01-13 12:59:05.454408 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #208 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3814197
Z variance train             0.086310685
KL Divergence                40.96343
KL Loss                      4.096343
QF Loss                      195.34886
VF Loss                      46.102585
Policy Loss                  -1137.2583
Q Predictions Mean           1134.9519
Q Predictions Std            1180.1469
Q Predictions Max            4331.7363
Q Predictions Min            555.4265
V Predictions Mean           1138.6388
V Predictions Std            1178.4805
V Predictions Max            4344.413
V Predictions Min            547.1596
Log Pis Mean                 -0.25121796
Log Pis Std                  3.8391175
Log Pis Max                  16.848969
Log Pis Min                  -5.6944656
Policy mu Mean               -0.032834496
Policy mu Std                0.8766588
Policy mu Max                3.0217671
Policy mu Min                -3.2792869
Policy log std Mean          -0.49791732
Policy log std Std           0.2764027
Policy log std Max           -0.054453015
Policy log std Min           -2.795714
Z mean eval                  2.367709
Z variance eval              0.083346434
total_rewards                [9664.02797282 9575.18368524 9686.89146737 9418.61135172 9417.9848642
 9637.30176892 9449.72991231 9509.46540799 9649.95181885 9664.7735246 ]
total_rewards_mean           9567.392177401689
total_rewards_std            103.21048182530875
total_rewards_max            9686.891467365242
total_rewards_min            9417.984864203632
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               195.93584007769823
(Previous) Eval Time (s)     30.985991314984858
Sample Time (s)              7.020067872479558
Epoch Time (s)               233.94189926516265
Total Train Time (s)         48376.37126434781
Epoch                        209
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:02:59.486698 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #209 | Epoch Duration: 234.03211522102356
2020-01-13 13:02:59.486960 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3699334
Z variance train             0.08348967
KL Divergence                40.182884
KL Loss                      4.0182886
QF Loss                      209.90569
VF Loss                      59.298996
Policy Loss                  -1106.8552
Q Predictions Mean           1102.1873
Q Predictions Std            1140.0571
Q Predictions Max            4292.4136
Q Predictions Min            534.7798
V Predictions Mean           1103.6968
V Predictions Std            1138.196
V Predictions Max            4273.3496
V Predictions Min            538.27734
Log Pis Mean                 -0.35097295
Log Pis Std                  3.8380613
Log Pis Max                  16.771626
Log Pis Min                  -7.4791374
Policy mu Mean               0.0073901913
Policy mu Std                0.8921599
Policy mu Max                3.8344486
Policy mu Min                -3.6880882
Policy log std Mean          -0.5274003
Policy log std Std           0.29121962
Policy log std Max           0.050424933
Policy log std Min           -2.8251896
Z mean eval                  2.3953285
Z variance eval              0.08192095
total_rewards                [9194.4266181  9384.97133902 9172.37804264 9215.95064673 9217.70785105
 9191.59804837 9375.64809553 9254.11141315 9021.02748114 9182.91539679]
total_rewards_mean           9221.073493252105
total_rewards_std            98.64554666833394
total_rewards_max            9384.971339022604
total_rewards_min            9021.027481143083
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               192.09275465505198
(Previous) Eval Time (s)     30.720669914968312
Sample Time (s)              8.6426423615776
Epoch Time (s)               231.4560669315979
Total Train Time (s)         48607.90824969951
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:51.027522 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #210 | Epoch Duration: 231.54037976264954
2020-01-13 13:06:51.027742 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3913798
Z variance train             0.0813347
KL Divergence                41.748478
KL Loss                      4.174848
QF Loss                      115.48562
VF Loss                      126.99902
Policy Loss                  -1309.0742
Q Predictions Mean           1308.0918
Q Predictions Std            1293.4707
Q Predictions Max            4439.2886
Q Predictions Min            542.1568
V Predictions Mean           1314.0562
V Predictions Std            1295.8794
V Predictions Max            4436.2437
V Predictions Min            546.4589
Log Pis Mean                 -0.04537572
Log Pis Std                  3.8043137
Log Pis Max                  19.459082
Log Pis Min                  -6.471422
Policy mu Mean               -0.00825988
Policy mu Std                0.92964023
Policy mu Max                3.8777637
Policy mu Min                -2.9387953
Policy log std Mean          -0.50828916
Policy log std Std           0.2784738
Policy log std Max           0.40763587
Policy log std Min           -2.6488674
Z mean eval                  2.401567
Z variance eval              0.064511925
total_rewards                [ 9921.93718429 10135.74271791  9960.44717235  9958.12785908
  9695.94708253  6667.09416578  9879.90402023  9667.36175267
  9836.31277671  9921.10569305]
total_rewards_mean           9564.398042460054
total_rewards_std            974.122450208172
total_rewards_max            10135.74271790887
total_rewards_min            6667.094165777532
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               193.63102536508814
(Previous) Eval Time (s)     31.431543877813965
Sample Time (s)              7.9429297666065395
Epoch Time (s)               233.00549900950864
Total Train Time (s)         48841.00886760419
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:44.131241 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #211 | Epoch Duration: 233.1033375263214
2020-01-13 13:10:44.131416 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3972347
Z variance train             0.06431613
KL Divergence                42.061
KL Loss                      4.2061
QF Loss                      2915.0588
VF Loss                      112.82703
Policy Loss                  -1064.0155
Q Predictions Mean           1065.2834
Q Predictions Std            1117.1743
Q Predictions Max            4343.3623
Q Predictions Min            563.1755
V Predictions Mean           1068.8777
V Predictions Std            1120.07
V Predictions Max            4352.4346
V Predictions Min            571.84705
Log Pis Mean                 -0.9108555
Log Pis Std                  3.108888
Log Pis Max                  12.525963
Log Pis Min                  -8.681697
Policy mu Mean               0.06757532
Policy mu Std                0.83588743
Policy mu Max                2.6483588
Policy mu Min                -2.3473952
Policy log std Mean          -0.4917264
Policy log std Std           0.2571502
Policy log std Max           0.12800527
Policy log std Min           -2.5545135
Z mean eval                  2.4272206
Z variance eval              0.07410838
total_rewards                [9804.5167291  9652.18724248 9679.05362608 9871.71700939 9757.64876986
 9834.61805982 9808.26414159 9704.82127281 9673.76051338 9549.59570717]
total_rewards_mean           9733.618307167771
total_rewards_std            93.98569904489304
total_rewards_max            9871.717009393453
total_rewards_min            9549.595707171138
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               197.59790648939088
(Previous) Eval Time (s)     32.88015077775344
Sample Time (s)              8.193725450430065
Epoch Time (s)               238.6717827175744
Total Train Time (s)         49079.76451358665
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:14:42.889567 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #212 | Epoch Duration: 238.75801181793213
2020-01-13 13:14:42.889744 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #212 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4291644
Z variance train             0.07414045
KL Divergence                43.136284
KL Loss                      4.3136287
QF Loss                      214.37552
VF Loss                      43.471252
Policy Loss                  -1106.2263
Q Predictions Mean           1105.7496
Q Predictions Std            1159.3663
Q Predictions Max            4473.9233
Q Predictions Min            554.51685
V Predictions Mean           1102.2856
V Predictions Std            1153.4385
V Predictions Max            4455.9307
V Predictions Min            555.2538
Log Pis Mean                 -0.40712038
Log Pis Std                  3.4205093
Log Pis Max                  13.339331
Log Pis Min                  -6.1068964
Policy mu Mean               0.0034241274
Policy mu Std                0.87360555
Policy mu Max                3.3781745
Policy mu Min                -2.8659842
Policy log std Mean          -0.495039
Policy log std Std           0.2678651
Policy log std Max           0.1315727
Policy log std Min           -3.0624812
Z mean eval                  2.4006236
Z variance eval              0.054712348
total_rewards                [ 9977.82973155  9837.71631995  9739.40078662  9707.45634483
  9961.82304172  9838.06447988 10013.04188473  9507.30530726
  9881.06580601  9845.21055944]
total_rewards_mean           9830.891426198858
total_rewards_std            142.4949170031183
total_rewards_max            10013.041884727809
total_rewards_min            9507.305307263136
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               196.29146390408278
(Previous) Eval Time (s)     33.52027611574158
Sample Time (s)              6.40070890635252
Epoch Time (s)               236.21244892617688
Total Train Time (s)         49316.06313459156
Epoch                        213
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:39.193172 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #213 | Epoch Duration: 236.30328559875488
2020-01-13 13:18:39.193371 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3996491
Z variance train             0.054622192
KL Divergence                41.843002
KL Loss                      4.1843004
QF Loss                      208.61826
VF Loss                      74.17007
Policy Loss                  -1355.8491
Q Predictions Mean           1358.0286
Q Predictions Std            1366.9224
Q Predictions Max            4435.0117
Q Predictions Min            551.6612
V Predictions Mean           1357.2897
V Predictions Std            1360.7406
V Predictions Max            4407.352
V Predictions Min            550.73444
Log Pis Mean                 0.18897292
Log Pis Std                  4.037646
Log Pis Max                  13.671999
Log Pis Min                  -6.6684866
Policy mu Mean               0.068535596
Policy mu Std                0.93551046
Policy mu Max                2.7632394
Policy mu Min                -3.234562
Policy log std Mean          -0.537909
Policy log std Std           0.3074948
Policy log std Max           0.12843478
Policy log std Min           -2.9771025
Z mean eval                  2.3698163
Z variance eval              0.058105987
total_rewards                [9191.98546656 9481.0720188  9131.86537204 8954.32624131 9149.78587567
 9251.27174513 9612.32653381 9400.04695827 9503.62234987 9154.66316522]
total_rewards_mean           9283.096572668353
total_rewards_std            196.07075199975887
total_rewards_max            9612.326533807847
total_rewards_min            8954.326241314704
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               195.09279798297212
(Previous) Eval Time (s)     32.367227524053305
Sample Time (s)              7.190275221131742
Epoch Time (s)               234.65030072815716
Total Train Time (s)         49550.85383482231
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:33.989020 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #214 | Epoch Duration: 234.7954888343811
2020-01-13 13:22:33.989189 UTC | [2020_01_10_08_53_31] [2020_01_11_16_11_41] [2020_01_12_23_36_42] Iteration #214 | Started Training: True
